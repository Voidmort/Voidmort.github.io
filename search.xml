<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Jetson NanoÂ≠¶‰π†Á¨îËÆ∞]]></title>
    <url>%2F2021%2F04%2F30%2FJetson%20Nano%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ÂâçË®ÄJetsonNanoÊòØNvidiaÁöÑ‰∏Ä‰∏™ÂµåÂÖ•ÂºèÂºÄÂèëÊùøÔºåÂÖ∑Â§áMaxwell128Ê†∏ÂøÉÁöÑGPUÂíå4Ê†∏ÂøÉ ARM A57ÁöÑCPUÔºåÂèØËøêË°åUbuntu(Linux for TegraÔºåL4T)ÔºåÊµÆÁÇπËøêÁÆóËÉΩÂäõ‰∏∫472GFLOPS(FP16)ÔºåÂÆòÊñπÁªôÂá∫ÁöÑÂäüÁéá‰∏∫10W„ÄÇJetsonNanoÂèØ‰ª•Áî®Êù•Êêû‰∫õÊú∫Âô®Â≠¶‰π†Áõ∏ÂÖ≥ÂÜÖÂÆπ„ÄÇ JetsonNanoÂπ≥Âè∞Âè™ÊîØÊåÅPython3.6ÁöÑTensorFlow„ÄÇ JetsonNanoÈïúÂÉèÁâàÊú¨ÔºöJetPack4.4 TensroFlow APIÁâàÊú¨Ôºör2.1.0 ‰ª•‰∏ä‰ø°ÊÅØ‰∏∫ÂΩìÂâçÊó∂Èó¥Êõ¥Êñ∞„ÄÇ ÂÖ≥‰∫éJetson Nano Developer Kit Á°¨‰ª∂ ÈÖçÁΩÆ GPU NVIDIA Maxwell‚Ñ¢ Êû∂ÊûÑÔºåÈÖçÂ§á 128 ‰∏™ NVIDIA CUDA¬Æ Ê†∏ÂøÉ CPU ÂõõÊ†∏ ARM¬Æ Cortex¬Æ-A57 MPCore Â§ÑÁêÜÂô® ÂÜÖÂ≠ò 4 GB 64 ‰Ωç LPDDR4 Â≠òÂÇ® Micro SD Âç°Âç°ÊßΩÔºàÈúÄË¶ÅÂè¶Ë¥≠16G‰ª•‰∏äSDÂç°Êé•ÂÖ•Ôºâ Micro SD Âç°Âç°ÊßΩ: ÂèØÊé•ÂÖ•TFÂç°Ôºà16G‰ª•‰∏äÔºâÔºåÁÉßÂÜôÁ≥ªÁªüÈïúÂÉè 40PIN GPIOÊâ©Â±ïÊé•Âè£ÔºàÂÖºÂÆπÊ†ëËéìÊ¥æ40PINÊé•Âè£Ôºâ Micro USBÊé•Âè£ÔºöÁî®‰∫é5VÁîµÊ∫êËæìÂÖ•ÊàñËÄÖUSBÊï∞ÊçÆ‰º†Ëæì ÂçÉÂÖÜ‰ª•Â§™ÁΩëÂè£: 10/100/1000Base-T Ëá™ÈÄÇÂ∫î‰ª•Â§™ÁΩëÁ´ØÂè£ USB3.0Êé•Âè£Ôºö4‰∏™USB3.0Êé•Âè£ HDMIÈ´òÊ∏ÖÊé•Âè£ÔºöÁî®‰∫éÂ§ñÊé•HDMIÂ±èÂπï DisplayPortÊé•Âè£ÔºöÁî®‰∫éÂ§ñÊé•DPÂ±èÂπï DCÁîµÊ∫êÊé•Âè£ÔºöÁî®‰∫éÂ§ñÊé•5VÁîµÊ∫êÔºàÂ§ñÂæÑ5.5Ôºå ÂÜÖÂæÑ2.1Ôºâ MIPS CSI ÊëÑÂÉèÂ§¥Êé•Âè£ÔºöÂÖºÂÆπÊ†ëËéìÊ¥æÊëÑÂÉèÂ§¥Êé•Âè£ ÁÉßÂÜôÈïúÂÉèÂÆòÊñπÊïôÁ®ã Êé®Ëçê‰ΩøÁî®EtcherÁÉßÂÜô ÈïúÂÉèÂæàÂ§ßÔºåÊúâ14GÔºåÁÉßÂÜôÂæàÊÖ¢Ôºå‰ΩÜÂÆâË£ÖÁ≥ªÁªüÂæàÂø´„ÄÇ Á≥ªÁªüÁâàÊú¨‰∏∫ Ubuntu 18.04.4 LTS (GNU/Linux 4.9.140-tegra aarch64) ÂÆâË£ÖtensorflowÂÆâË£ÖÊñπÊ≥ï‰∏∫ÂÆòÊñπÁªôÂá∫ link ÂÆâË£ÖÁâàÊú¨‰∏∫ Python 3.6 + JetPack4.4 1234567$ sudo apt-get update$ sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran$ sudo apt-get install python3-pip$ sudo pip3 install -U pip ÂÆâË£Öh5py‰ºöÂá∫ÈîôÔºåÂ∞ùËØïÈáçÂêØÂçïÁã¨ÂÆâË£ÖÔºåËøô‰∏™ÊúâÁÇπÁéÑÂ≠¶ÔºåÊàëÈáçÂà∑‰∫Ü‰∏§Ê¨°ÔºåÂçïÁã¨ÂÆâË£ÖÊâçÂÆâË£ÖÊàêÂäü 1$ sudo pip3 install -U pip testresources setuptools numpy==1.16.1 future==0.17.1 mock==3.0.5 h5py==2.9.0 keras_preprocessing==1.0.5 keras_applications==1.0.8 gast==0.2.2 futures protobuf pybind11 Êé•‰∏ãÊù•ÊòØÊº´ÈïøÁöÑÁ≠âÂæÖ 12345# TF-2.x$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 tensorflow==2.2.0+nv20.6# TF-1.15$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 ‚Äòtensorflow&lt;2‚Äô 12345678Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.19.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.30.0 h5py-2.10.0 importlib-metadata-1.7.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.24.0 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 six-1.15.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-2.2.0+nv20.6 tensorflow-estimator-2.2.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.1.0nano@jetson:~$ python3Python 3.6.9 (default, Apr 18 2020, 01:56:04)[GCC 8.4.0] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import tensorflow2020-07-16 08:53:15.536130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10. ÂÆâË£ÖjupyterËÉΩÂê¶ÂÆâË£ÖÊàêÂäü‰πüÊúâ‰∏ÄÂÆöÁöÑÁéÑÂ≠¶ÔºåÈÅáÂà∞ÁöÑÈóÆÈ¢òÊúâÔºåpyzmqÁºñËØëÂá∫ÈîôÔºåËøúÁ®ãÁôªÂΩïÊó†Ê≥ïËØÜÂà´ÂØÜÁ†Å„ÄÇ ÂÆâË£ÖÊñπÊ≥ïÂêåÊ†∑Êù•Ëá™ÂÆòÊñπ 12345678910111213141516ÂÆâË£Önodejs$ sudo apt install nodejs npmÂÆâË£Öjupyter$ sudo pip3 install jupyter jupyterlab$ sudo jupyter labextension install @jupyter-widgets/jupyterlab-manager$ sudo jupyter labextension install @jupyterlab/statusbarÁîüÊàêjupyterÈÖçÁΩÆÊñá‰ª∂$ jupyter lab --generate-config$ jupyter notebook passwordËæìÂÖ•ÁôªÈôÜÂØÜÁ†ÅÁîüÊàêjupyter_notebook_config.jsonÊñá‰ª∂ ‰øÆÊîπjupyter_notebook_config.pyÁöÑÈÖçÁΩÆÔºåÊ∑ªÂä†‰ª•‰∏ãÂÜÖÂÆπ 1234c.NotebookApp.ip = '*' # Â∞±ÊòØËÆæÁΩÆÊâÄÊúâipÁöÜÂèØËÆøÈóÆc.NotebookApp.password = u'sha1:0fb67bb71f8f:9525f730807d01c04ea963492b0e3340de7b9d67' #jupyter_notebook_config.jsonÈáåÁöÑsha1ÂØÜÊñác.NotebookApp.open_browser = False # Á¶ÅÊ≠¢Ëá™Âä®ÊâìÂºÄÊµèËßàÂô®c.NotebookApp.port = 8888 #ÊåáÂÆö‰∏∫NATÁ´ØÂè£Êò†Â∞ÑÁöÑÁ´ØÂè£Âè∑ ÂêØÂä®1$ jupyter-lab ÂÆâË£ÖopenCVËá™Â∏¶opencvÔºåÂ≠òÂú®‰∏Ä‰∏™bugÔºåÂ¶ÇÊûúÂÖàÂØºÂÖ•tensorflow‰ºöÂá∫ÈîôÔºå‰ΩÜÂÖàÂØºÂÖ•cv2ÔºåÂÜçÂØºÂÖ•tensorflowÂàôÊ≤°ÊúâÈîôËØØ„ÄÇ 12345678910111213141516171819&gt;&gt;&gt; import tensorflow2020-07-16 08:53:15.536130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2&gt;&gt;&gt;&gt;&gt;&gt; import cv2Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/lib/python3.6/dist-packages/cv2/__init__.py", line 89, in &lt;module&gt; bootstrap() File "/usr/lib/python3.6/dist-packages/cv2/__init__.py", line 79, in bootstrap import cv2ImportError: /usr/lib/aarch64-linux-gnu/libgomp.so.1: cannot allocate memory in static TLS blockÂÖàÂØºÂÖ•cv2Âàô‰∏ç‰ºöÂá∫Èîô&gt;&gt;&gt; import cv2&gt;&gt;&gt; import tensorflow2020-07-16 08:56:07.842807: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2&gt;&gt;&gt; ÊµãËØïTensorflowÈ¶ñÂÖàÂØºÂÖ•tensorflow1import tensorflow as tf Áúã‰∏ãÁâàÊú¨1tf.__version__ &apos;2.2.0&apos; ËΩΩÂÖ•Âπ∂ÂáÜÂ§áÂ•Ω MNISTÊï∞ÊçÆÈõÜ„ÄÇÂ∞ÜÊ†∑Êú¨‰ªéÊï¥Êï∞ËΩ¨Êç¢‰∏∫ÊµÆÁÇπÊï∞Ôºö 1234mnist = tf.keras.datasets.mnist(x_train, y_train), (x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0 Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11493376/11490434 [==============================] - 1s 0us/step Áî®tf.keras.SequentialÊûÑÂª∫‰∏Ä‰∏™Ê®°Âûã„ÄÇ‰∏∫Ê®°ÂûãÈÄâÊã©‰ºòÂåñÂô®ÂíåÊçüÂ§±ÂáΩÊï∞Ôºö 12345678910model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation='softmax')])model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) ÂºÄÂßãËÆ≠ÁªÉ 1model.fit(x_train, y_train, epochs=5) Epoch 1/5 1875/1875 [==============================] - 26s 14ms/step - loss: 0.2933 - accuracy: 0.9154 Epoch 2/5 1875/1875 [==============================] - 26s 14ms/step - loss: 0.1426 - accuracy: 0.9577 Epoch 3/5 1875/1875 [==============================] - 26s 14ms/step - loss: 0.1062 - accuracy: 0.9676 Epoch 4/5 1875/1875 [==============================] - 26s 14ms/step - loss: 0.0870 - accuracy: 0.9731 Epoch 5/5 1875/1875 [==============================] - 25s 14ms/step - loss: 0.0734 - accuracy: 0.9771 &lt;tensorflow.python.keras.callbacks.History at 0x7f4c402710&gt; ÈÄüÂ∫¶‰∏çÊòØÂ§™ÊÖ¢ÔºåÊúÄÂêéÁúã‰∏ãÂáÜÁ°ÆÂ∫¶ 1model.evaluate(x_test, y_test, verbose=2) 313/313 - 2s - loss: 0.0704 - accuracy: 0.9803 [0.07044795155525208, 0.9803000092506409] 98%ÁöÑÂáÜÁ°ÆÂ∫¶ jetson nano ÂÆåÁæéËøêË°åtensorflow2 ÂùëÊàëÊÉ≥ÈÄöËøásshËøúÁ®ãËøêË°åÂõæÂΩ¢Á®ãÂ∫èÔºåÂ¶Ç‰ΩïÂ∞ùËØïÈÉΩ‰∏çË°åÔºåÁõ¥Âà∞Âú®NVIDIA Metropolis DocumentationÂèëÁé∞‰∫ÜËøôÂè•ËØù„ÄÇ ReleaseNotes 2.0 LIMITATIONS 12On Jetson, running a DeepStream application over SSH (via putty) with X11 forwardingdoes not work ÊÄªÁªìËøô‰∏™‰∏úË•øËøòÊòØÂ≠òÂú®ÁùÄËÆ∏Â§öbugÔºåÁ≥ªÁªü‰πü‰∏çÊòØÈùûÂ∏∏Á®≥ÂÆöÔºåÂºÄÂèë‰πüÂæàÈ∫ªÁÉ¶ÔºåÂ¶ÇÊûúÊòØÊÉ≥Áé©Áé©ËøòÊòØÊé®ËçêÊ†ëËéìÊ¥æ„ÄÇ]]></content>
      <categories>
        <category>ÂµåÂÖ•Âºè</category>
      </categories>
      <tags>
        <tag>Jetson Nano</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker + TensorFlow2.0 + jupyter lab]]></title>
    <url>%2F2020%2F08%2F20%2Fdocker%20%2B%20TensorFlow2.0%20%2B%20jupyter%20lab%2F</url>
    <content type="text"><![CDATA[ÊúçÂä°Âô®‰∏∫ Ubuntu È¶ñÂÖàÂΩìÁÑ∂ÈúÄË¶ÅÊúâDocker ÂÆâË£Ödocker tensorflow jupyterÂèÇËÄÉtensorflowÂÆâË£ÖÊïôÁ®ã ËæìÂÖ•‰∏Ä‰∏ãÂëΩ‰ª§Ôºö 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748$ sudo docker run -it -p 8888:8888 tensorflow/tensorflow:nightly-py3-jupyterUnable to find image 'tensorflow/tensorflow:nightly-py3-jupyter' locallynightly-py3-jupyter: Pulling from tensorflow/tensorflow5bed26d33875: Pull completef11b29a9c730: Pull complete930bda195c84: Pull complete78bf9a5ad49e: Pull complete84227541b6bb: Pull complete4f31c9672ae8: Pull complete3ab00ff69975: Pull completeba1f9a4960a4: Pull complete1e2e9ebd327e: Extracting [==================================================&gt;] 590.2MB/590.2MB1e2e9ebd327e: Pull complete5dbeace46811: Pull complete236b4193378a: Pull complete94c8012aaf41: Pull complete8978cb54431f: Pull completea32047d10082: Pull complete4bfab90cc021: Pull completedb51178e67ae: Pull completec582e0693d6e: Pull completed9275e9db168: Pull complete48835526d3e2: Pull complete5287adc8a8f2: Pull complete525c81ec54db: Pull complete0161c3804581: Pull completeebfa1948cb3e: Pull complete933aa5af1920: Pull completea600cede3739: Pull complete1d8aeacd0c4f: Pull complete683a7567eeea: Pull completeDigest: sha256:0b59d7826a07049f013c171bb96c26c0d4a6222f856e6520a6cd70d7be5ecdecStatus: Downloaded newer image for tensorflow/tensorflow:nightly-py3-jupyter[I 07:24:55.849 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secretjupyter_http_over_ws extension initialized. Listening on /http_over_websocket[I 07:24:56.134 NotebookApp] Serving notebooks from local directory: /tf[I 07:24:56.134 NotebookApp] The Jupyter Notebook is running at:[I 07:24:56.134 NotebookApp] http://1d6d334faf94:8888/?token=ec98c98ec99956afa3a078ce9ae5e34f11a88b6bf92f0ac8[I 07:24:56.134 NotebookApp] or http://127.0.0.1:8888/?token=ec98c98ec99956afa3a078ce9ae5e34f11a88b6bf92f0ac8[I 07:24:56.134 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 07:24:56.138 NotebookApp] To access the notebook, open this file in a browser: file:///root/.local/share/jupyter/runtime/nbserver-1-open.html Or copy and paste one of these URLs: http://1d6d334faf94:8888/?token=ec98c98ec99956afa3a078ce9ae5e34f11a88b6bf92f0ac8 or http://127.0.0.1:8888/?token=ec98c98ec99956afa3a078ce9ae5e34f11a88b6bf92f0ac8 Á≠âÂæÖ‰∏Ä‰ºö ÂÆâË£ÖÂπ∂ÊàêÂäüÂêØÂä®‰∫Üjupyter notebookÔºåÂú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄÊèêÁ§∫ÁöÑÁΩëÂùÄÔºöhttp://127.0.0.1:8888/?token=... Êåâ‰Ωè ctrl + c ÈÄÄÂá∫ Êé•‰∏ãÊù•ÊòØÈáçÁÇπ ÂÆâË£Öjupyter labÊü•ÁúãdockerÈïúÂÉè 123$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtensorflow/tensorflow nightly-py3-jupyter 37b1af999efc 4 months ago 2.42GB ÂÖàÂà†Èô§ÂàöÂêØÂä®ÁöÑÂÆπÂô® 12sudo docker stop 37b1af999efc #ÂÖ≥Èó≠sudo docker container rm 37b1af999efc #Âà†Èô§ Âú®Êú¨Êú∫‰∏äÊñ∞Âª∫‰∏Ä‰∏™Êñá‰ª∂Â§πÔºåÂíå‰∏Ä‰∏™jsonÊñá‰ª∂ 123$ mkdir jupyter_config$ cd jupyter_config/~/jupyter_config$ vim config.json Ëøô‰∏™Êñá‰ª∂ÂÜÖÂÆπÊòØjupyter-labÁöÑÈÖçÁΩÆ‰ø°ÊÅØ 12345678910&#123; "NotebookApp":&#123; "ip":"*", "port":8888, "password":"", "open_browser":false, "token":"", "allow_root":true &#125;&#125; Âú®docker‰∏≠ÂàõÂª∫ÊåÇËΩΩjupyter_configÊñá‰ª∂Â§πÁöÑÂÆπÂô® 123456$ sudo docker run -itd -p 8888:8888 -v ~/„Äê‰∏ªÊú∫ÁöÑÁõÆÂΩï„Äë:/home/user„ÄêÂÆπÂô®ÁöÑÁõÆÂΩï„Äë tensorflow/tensorflow:nightly-py3-jupyter bash$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe72acb760f91 tensorflow/tensorflow:nightly-py3-jupyter "bash" About a minute ago Up About a ËøõÂÖ•ËØ•ÂÆπÂô® 1234567$ sudo docker exec -it e72acb760f91 bash________ __________________ __/__________________________________ ____/__ /________ ____ / _ _ \_ __ \_ ___/ __ \_ ___/_ /_ __ /_ __ \_ | /| / /_ / / __/ / / /(__ )/ /_/ / / _ __/ _ / / /_/ /_ |/ |/ //_/ \___//_/ /_//____/ \____//_/ /_/ /_/ \____/____/|__/ Âú®ÂÆπÂô®‰∏≠ÂÆâË£Öjupyter lab 1root@e72acb760f91:/tf# pip3 install jupyterlab ÂàáÊç¢Âà∞Êàë‰ª¨ÊåÇËΩΩÁöÑjupyter_configÊñá‰ª∂Â§πÂéª 123root@e72acb760f91:/tf# cd /home/user/root@e72acb760f91:/home/user# lsjupyter_config ÂêØÂä®jupyter lab 1234567891011# jupyter-lab --config ./jupyter_config/config.json[I 08:44:59.650 LabApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret[W 08:44:59.906 LabApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.[W 08:44:59.906 LabApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.jupyter_http_over_ws extension initialized. Listening on /http_over_websocket[I 08:44:59.917 LabApp] JupyterLab extension loaded from /usr/local/lib/python3.6/dist-packages/jupyterlab[I 08:44:59.917 LabApp] JupyterLab application directory is /usr/local/share/jupyter/lab[I 08:44:59.920 LabApp] Serving notebooks from local directory: /home/xujie[I 08:44:59.920 LabApp] The Jupyter Notebook is running at:[I 08:44:59.920 LabApp] http://e72acb760f91:8888/[I 08:44:59.920 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). Áî®ÊµèËßàÂô®ÊâìÂºÄ 1http:// docker IP :8888/ ipÊü•ÁúãÊñπÂºèÔºö 12345678910$ ifconfigdocker0 Link encap:Ethernet HWaddr 02:42:52:46:56:2f inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 inet6 addr: fe80::42:52ff:fe46:562f/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:13461 errors:0 dropped:0 overruns:0 frame:0 TX packets:17994 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:20897178 (20.8 MB) TX bytes:114945170 (114.9 MB) ÂÆåÁªìÔºåÂºÄÂßãÂ∑•‰Ωú„ÄÇ]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>TensorFlow2</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KerasÂ≠¶‰π†Á¨îËÆ∞]]></title>
    <url>%2F2020%2F08%2F01%2FKeras%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[123import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras import layers ‰ΩøÁî®SequentialÊ®°Âûã‰∏Ä‰∏™SequentialÊ®°ÂûãÈÄÇÁî®‰∫éÁÆÄÂçïÁöÑÂ±ÇÂ†ÜÂè†Ôºå ÂÖ∂‰∏≠ÊØè‰∏ÄÂ±ÇÊ≠£Â•ΩÊúâ‰∏Ä‰∏™ËæìÂÖ•Âº†ÈáèÂíå‰∏Ä‰∏™ËæìÂá∫Âº†Èáè„ÄÇ 1234567model = keras.Sequential( [ layers.Dense(2, activation="relu", name="layer1"), layers.Dense(3, activation="relu", name="layer2"), layers.Dense(4, name="layer3"), ]) 12x = tf.ones((3, 3))x &lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy= array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=float32)&gt; 1y = model(x) 1y &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], dtype=float32)&gt; ‰∏äËø∞‰ª£Á†ÅÁ≠âÊïà‰∫é‰∏Ä‰∏ã‰ª£Á†ÅÔºö 12345678# Create 3 layerslayer1 = layers.Dense(2, activation="relu", name="layer1")layer2 = layers.Dense(3, activation="relu", name="layer2")layer3 = layers.Dense(4, name="layer3")# Call layers on a test inputx = tf.ones((3, 3))y = layer3(layer2(layer1(x))) 1y &lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy= array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], dtype=float32)&gt; Sequential‰∏çÈÄÇÁî®‰∫é‰ª•‰∏ãÊÉÖÂÜµÔºö Ê®°ÂûãÊúâÂ§ö‰∏™ËæìÂÖ•ÊàñÂ§ö‰∏™ËæìÂá∫ ‰ªª‰Ωï‰∏ÄÂ±ÇÈÉΩÊúâÂ§ö‰∏™ËæìÂÖ•ÊàñÂ§ö‰∏™ËæìÂá∫ ÈúÄË¶ÅËøõË°åÂõæÂ±ÇÂÖ±‰∫´ ÈúÄË¶ÅÈùûÁ∫øÊÄßÊãìÊâëÔºà‰æãÂ¶ÇÔºåÊÆã‰ΩôËøûÊé•ÔºåÂ§öÂàÜÊîØÊ®°ÂûãÔºâ ÂèØÈÄöËøá‰ª•‰∏ãlayersÂ±ûÊÄßËÆøÈóÆÂÖ∂ÂõæÂ±Ç 1model.layers [&lt;tensorflow.python.keras.layers.core.Dense at 0x1ee679d3cf8&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x1ee679f3a90&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x1ee67a0c208&gt;] ËøòÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãadd()ÊñπÊ≥ïÈÄêÊ≠•ÂàõÂª∫‰∏Ä‰∏™È°∫Â∫èÊ®°ÂûãÔºö 1234model = keras.Sequential()model.add(layers.Dense(2, activation="relu"))model.add(layers.Dense(3, activation="relu"))model.add(layers.Dense(4)) ËøòÊúâ‰∏ÄÁßçÁõ∏Â∫îÁöÑpop()ÊñπÊ≥ïÂèØ‰ª•Âà†Èô§ÂõæÂ±ÇÔºöÈ°∫Â∫èÊ®°ÂûãÁöÑË°å‰∏∫ÈùûÂ∏∏Á±ª‰ºº‰∫éÂõæÂ±ÇÂàóË°®„ÄÇ 1print(len(model.layers)) 3 1model.pop() 1print(len(model.layers)) 2 SequentialÊûÑÈÄ†ÂáΩÊï∞Êé•ÂèónameÂèÇÊï∞ÔºåÂ∞±ÂÉèKeras‰∏≠ÁöÑ‰ªª‰ΩïÂ±ÇÊàñÊ®°Âûã‰∏ÄÊ†∑„ÄÇËøôÂØπ‰∫éÁî®ËØ≠‰πâ‰∏äÊúâÊÑè‰πâÁöÑÂêçÁß∞Ê≥®ÈáäTensorBoardÂõæÂæàÊúâÁî®„ÄÇ 1234model = keras.Sequential(name="my_sequential")model.add(layers.Dense(2, activation="relu", name="layer1"))model.add(layers.Dense(3, activation="relu", name="layer2"))model.add(layers.Dense(4, name="layer3")) È¢ÑÂÖàÊåáÂÆöËæìÂÖ•ÂΩ¢Áä∂Keras‰∏≠ÁöÑÊâÄÊúâÂõæÂ±ÇÈÉΩÈúÄË¶ÅÁü•ÈÅìÂÖ∂ËæìÂÖ•ÁöÑÂΩ¢Áä∂Ôºå‰ª•‰æøËÉΩÂ§üÂàõÂª∫ÂÖ∂ÊùÉÈáç„ÄÇÂõ†Ê≠§ÔºåÂΩìÂàõÂª∫ËøôÊ†∑ÁöÑÂõæÂ±ÇÊó∂ÔºåÊúÄÂàùÊ≤°ÊúâÊùÉÈáçÔºö 12layer = layers.Dense(3)layer.weights [] Áî±‰∫éÊùÉÈáçÁöÑÂΩ¢Áä∂ÂèñÂÜ≥‰∫éËæìÂÖ•ÁöÑÂΩ¢Áä∂ÔºåÂõ†Ê≠§‰ºöÂú®È¶ñÊ¨°Ë∞ÉÁî®ËæìÂÖ•Êó∂ÂàõÂª∫ÂÖ∂ÊùÉÈáçÔºö 123x = tf.ones((1, 4))y = layer(x)layer.weights [&lt;tf.Variable &apos;dense_3/kernel:0&apos; shape=(4, 3) dtype=float32, numpy= array([[-0.23496091, -0.42415935, -0.38969237], [ 0.47878957, 0.6321573 , 0.53070235], [-0.57678986, 0.5862113 , -0.5439472 ], [-0.8276289 , 0.88936853, -0.6267946 ]], dtype=float32)&gt;, &lt;tf.Variable &apos;dense_3/bias:0&apos; shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)&gt;] Ëøô‰πüÈÄÇÁî®‰∫éÈ°∫Â∫èÊ®°Âûã„ÄÇÂΩìÂÆû‰æãÂåñÊ≤°ÊúâËæìÂÖ•ÂΩ¢Áä∂ÁöÑÈ°∫Â∫èÊ®°ÂûãÊó∂ÔºåÂÆÉ‰∏çÊòØ‚ÄúÊûÑÂª∫‚ÄùÁöÑÔºöÂÆÉÊ≤°ÊúâÊùÉÈáçÔºàÂπ∂‰∏îË∞ÉÁî® model.weightsÁªìÊûú‰ªÖËØ¥Êòé‰∫ÜËøô‰∏ÄÁÇπÔºâ„ÄÇÊùÉÈáçÊòØÂú®Ê®°ÂûãÈ¶ñÊ¨°ÁúãÂà∞‰∏Ä‰∫õËæìÂÖ•Êï∞ÊçÆÊó∂ÂàõÂª∫ÁöÑÔºö 1234567891011model = keras.Sequential( [ layers.Dense(2, activation="relu"), layers.Dense(3, activation="relu"), layers.Dense(4), ])x = tf.ones((1, 4))y = model(x)print("Number of weights after calling the model:", len(model.weights)) # 6 Number of weights after calling the model: 6 ‰∏ÄÊó¶‚ÄúÊûÑÂª∫‚Äù‰∫ÜÊ®°ÂûãÔºåÂ∞±ÂèØ‰ª•Ë∞ÉÁî®ÂÖ∂summary()ÊñπÊ≥ï‰ª•ÊòæÁ§∫ÂÖ∂ÂÜÖÂÆπÔºö 1model.summary() Model: &quot;sequential_6&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_4 (Dense) (1, 2) 10 _________________________________________________________________ dense_5 (Dense) (1, 3) 9 _________________________________________________________________ dense_6 (Dense) (1, 4) 16 ================================================================= Total params: 35 Trainable params: 35 Non-trainable params: 0 _________________________________________________________________ ‰ΩÜÊòØÔºåÂΩìÈÄêÊ≠•ÊûÑÂª∫È°∫Â∫èÊ®°ÂûãÊó∂ÔºåËÉΩÂ§üÊòæÁ§∫Âà∞ÁõÆÂâç‰∏∫Ê≠¢ÁöÑÊ®°ÂûãÊëòË¶ÅÔºàÂåÖÊã¨ÂΩìÂâçËæìÂá∫ÂΩ¢Áä∂ÔºâÈùûÂ∏∏ÊúâÁî®„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂ∫îËØ•ÈÄöËøáÂ∞Ü‰∏Ä‰∏™Input ÂØπË±°‰º†ÈÄíÁªôÊ®°ÂûãÊù•ÂêØÂä®Ê®°ÂûãÔºå‰ª•‰ΩøÂÆÉ‰ªé‰∏ÄÂºÄÂßãÂ∞±Áü•ÈÅìÂÖ∂ËæìÂÖ•ÂΩ¢Áä∂Ôºö 12345model = keras.Sequential()model.add(keras.Input(shape=(4,)))model.add(layers.Dense(2, activation="relu"))model.summary() Model: &quot;sequential_8&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_10 (Dense) (None, 2) 10 ================================================================= Total params: 10 Trainable params: 10 Non-trainable params: 0 _________________________________________________________________ Áî±‰∫éËØ•InputÂØπË±°model.layers‰∏çÊòØÂõæÂ±ÇÔºåÂõ†Ê≠§‰∏ç‰ºöÊòæÁ§∫‰∏∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºö 1model.layers [&lt;tensorflow.python.keras.layers.core.Dense at 0x1ee68ade4e0&gt;] ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊõø‰ª£ÊñπÊ≥ïÊòØÂ∞Ü‰∏Ä‰∏™input_shapeÂèÇÊï∞‰º†ÈÄíÁªôÁ¨¨‰∏ÄÂ±ÇÔºö 1234model = keras.Sequential()model.add(layers.Dense(2, activation="relu", input_shape=(4,)))model.summary() Model: &quot;sequential_9&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_11 (Dense) (None, 2) 10 ================================================================= Total params: 10 Trainable params: 10 Non-trainable params: 0 _________________________________________________________________ ‰ΩøÁî®ËøôÊ†∑ÁöÑÈ¢ÑÂÆö‰πâËæìÂÖ•ÂΩ¢Áä∂ÊûÑÂª∫ÁöÑÊ®°ÂûãÂßãÁªàÂÖ∑ÊúâÊùÉÈáçÔºàÁîöËá≥Âú®Êü•Áúã‰ªª‰ΩïÊï∞ÊçÆ‰πãÂâçÔºâÔºåÂπ∂‰∏îÂßãÁªàÂÖ∑ÊúâÂÆö‰πâÁöÑËæìÂá∫ÂΩ¢Áä∂„ÄÇ ÈÄöÂ∏∏ÔºåÂª∫ËÆÆÁöÑÊúÄ‰Ω≥ÂÅöÊ≥ïÊòØÂßãÁªà‰∫ãÂÖàÊåáÂÆöÈ°∫Â∫èÊ®°ÂûãÁöÑËæìÂÖ•ÂΩ¢Áä∂ÔºàÂ¶ÇÊûúÈ¢ÑÂÖàÁü•ÈÅìÂÆÉÊòØ‰ªÄ‰πàÔºâ„ÄÇ Â∏∏ËßÅÁöÑË∞ÉËØïÂ∑•‰ΩúÊµÅÁ®ãÔºöadd()+summary()Âú®ÊûÑÂª∫Êñ∞ÁöÑÈ°∫Â∫è‰ΩìÁ≥ªÁªìÊûÑÊó∂Ôºå‰ª•Ê∏êËøõÊñπÂºèÂ†ÜÂè†Â±Çadd()Âπ∂ÁªèÂ∏∏ÊâìÂç∞Ê®°ÂûãÊëòË¶ÅÂæàÊúâÁî®„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•ÁõëËßÜÂ†ÜÊ†àConv2DÂíåMaxPooling2DÂõæÂ±ÇÂ¶Ç‰ΩïÂØπÂõæÂÉèÁâπÂæÅË¥¥ÂõæËøõË°å‰∏ãÈááÊ†∑Ôºö 123456789101112131415161718192021222324model = keras.Sequential()model.add(keras.Input(shape=(250, 250, 3))) # 250x250 RGB imagesmodel.add(layers.Conv2D(32, 5, strides=2, activation="relu"))model.add(layers.Conv2D(32, 3, activation="relu"))model.add(layers.MaxPooling2D(3))model.summary()# (40, 40, 32)model.add(layers.Conv2D(32, 3, activation="relu"))model.add(layers.Conv2D(32, 3, activation="relu"))model.add(layers.MaxPooling2D(3))model.add(layers.Conv2D(32, 3, activation="relu"))model.add(layers.Conv2D(32, 3, activation="relu"))model.add(layers.MaxPooling2D(2))model.summary()# Áé∞Âú®Êàë‰ª¨Êúâ‰∫Ü4x4ÁöÑÁâπÂæÅÂõæÔºåÊòØÊó∂ÂÄôÂ∫îÁî®MaxPooling‰∫Ü„ÄÇmodel.add(layers.GlobalMaxPooling2D())# ÊúÄÂêéÔºåÊàë‰ª¨Ê∑ªÂä†‰∏Ä‰∏™ÂàÜÁ±ªÂ±Ç„ÄÇmodel.add(layers.Dense(10)) Model: &quot;sequential_11&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_6 (Conv2D) (None, 123, 123, 32) 2432 _________________________________________________________________ conv2d_7 (Conv2D) (None, 121, 121, 32) 9248 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 40, 40, 32) 0 ================================================================= Total params: 11,680 Trainable params: 11,680 Non-trainable params: 0 _________________________________________________________________ Model: &quot;sequential_11&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_6 (Conv2D) (None, 123, 123, 32) 2432 _________________________________________________________________ conv2d_7 (Conv2D) (None, 121, 121, 32) 9248 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 40, 40, 32) 0 _________________________________________________________________ conv2d_8 (Conv2D) (None, 38, 38, 32) 9248 _________________________________________________________________ conv2d_9 (Conv2D) (None, 36, 36, 32) 9248 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32) 0 _________________________________________________________________ conv2d_10 (Conv2D) (None, 10, 10, 32) 9248 _________________________________________________________________ conv2d_11 (Conv2D) (None, 8, 8, 32) 9248 _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32) 0 ================================================================= Total params: 48,672 Trainable params: 48,672 Non-trainable params: 0 _________________________________________________________________ Êã•ÊúâÊ®°ÂûãÂêéËØ•ÊÄé‰πàÂäû‰∏ÄÊó¶Ê®°ÂûãÊû∂ÊûÑÂáÜÂ§áÂ∞±Áª™ÔºåÂ∞ÜÈúÄË¶ÅÔºö ËÆ≠ÁªÉÊ®°ÂûãÔºåËØÑ‰º∞Ê®°ÂûãÂπ∂ËøõË°åÊé®ÁêÜ„ÄÇ Â∞ÜÊ®°Âûã‰øùÂ≠òÂà∞Á£ÅÁõòÂπ∂ËøòÂéü„ÄÇ ÈÄöËøáÂà©Áî®Â§ö‰∏™GPUÊù•Âä†ÈÄüÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ ‰ΩøÁî®È°∫Â∫èÊ®°ÂûãËøõË°åÁâπÂæÅÊèêÂèñ‰∏ÄÊó¶Âª∫Á´ã‰∫ÜÈ°∫Â∫èÊ®°ÂûãÔºåÂÆÉÁöÑË°å‰∏∫Â∞±Á±ª‰ºº‰∫éÂäüËÉΩAPIÊ®°Âûã„ÄÇËøôÊÑèÂë≥ÁùÄÊØè‰∏™Â±ÇÈÉΩÊúâ‰∏Ä‰∏™input and outputÂ±ûÊÄß„ÄÇËøô‰∫õÂ±ûÊÄßÂèØ‰ª•ÂÅö‰∏Ä‰∫õ‰∫ãÊÉÖÔºå‰æãÂ¶ÇÂø´ÈÄüÂàõÂª∫‰∏Ä‰∏™Ê®°ÂûãÔºå‰ª•ÊèêÂèñÈ°∫Â∫èÊ®°Âûã‰∏≠ÊâÄÊúâ‰∏≠Èó¥Â±ÇÁöÑËæìÂá∫Ôºö 12345678910111213141516initial_model = keras.Sequential( [ keras.Input(shape=(250, 250, 3)), layers.Conv2D(32, 5, strides=2, activation="relu"), layers.Conv2D(32, 3, activation="relu"), layers.Conv2D(32, 3, activation="relu"), ])feature_extractor = keras.Model( inputs=initial_model.inputs, outputs=[layer.output for layer in initial_model.layers],)# Call feature extractor on test input.x = tf.ones((1, 250, 250, 3))features = feature_extractor(x) ËøôÊòØ‰∏Ä‰∏™Á±ª‰ººÁöÑÁ§∫‰æãÔºå‰ªÖ‰ªé‰∏ÄÂ±Ç‰∏≠ÊèêÂèñË¶ÅÁ¥†Ôºö 123456789101112131415initial_model = keras.Sequential( [ keras.Input(shape=(250, 250, 3)), layers.Conv2D(32, 5, strides=2, activation="relu"), layers.Conv2D(32, 3, activation="relu", name="my_intermediate_layer"), layers.Conv2D(32, 3, activation="relu"), ])feature_extractor = keras.Model( inputs=initial_model.inputs, outputs=initial_model.get_layer(name="my_intermediate_layer").output,)# Call feature extractor on test input.x = tf.ones((1, 250, 250, 3))features = feature_extractor(x)]]></content>
      <categories>
        <category>tensorflow2</category>
        <category>keras</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[‰øùÂ≠ò‰∏éÂä†ËΩΩTensorflowÊ®°Âûã]]></title>
    <url>%2F2020%2F08%2F01%2F%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BDTensorflow%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[‰øùÂ≠ò‰∏éÂä†ËΩΩÊ®°ÂûãÂÆâË£Ötensorflow-datasetsÔºåÂØºÂÖ•‰æùËµñÈ°πÔºö 1%pip install tensorflow-datasets 1234import tensorflow_datasets as tfdsimport tensorflow as tftfds.disable_progress_bar() 1tf.__version__ &apos;2.3.0&apos; 1mirrored_strategy = tf.distribute.MirroredStrategy() WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices (&apos;/job:localhost/replica:0/task:0/device:CPU:0&apos;,) ÂàõÂª∫‰∏Ä‰∏™ÂàÜÂèëÂèòÈáèÂíåÂõæÂΩ¢ÁöÑÁ≠ñÁï• tf.distribute.MirroredStrategy Á≠ñÁï•ÊòØÂ¶Ç‰ΩïËøê‰ΩúÁöÑÔºü ÊâÄÊúâÂèòÈáèÂíåÊ®°ÂûãÂõæÈÉΩÂ§çÂà∂Âú®ÂâØÊú¨‰∏ä„ÄÇ ËæìÂÖ•ÈÉΩÂùáÂåÄÂàÜÂ∏ÉÂú®ÂâØÊú¨‰∏≠„ÄÇ ÊØè‰∏™ÂâØÊú¨Âú®Êî∂Âà∞ËæìÂÖ•ÂêéËÆ°ÁÆóËæìÂÖ•ÁöÑÊçüÂ§±ÂíåÊ¢ØÂ∫¶„ÄÇ ÈÄöËøáÊ±ÇÂíåÔºåÊØè‰∏Ä‰∏™ÂâØÊú¨‰∏äÁöÑÊ¢ØÂ∫¶ÈÉΩËÉΩÂêåÊ≠•„ÄÇ ÂêåÊ≠•ÂêéÔºåÊØè‰∏™ÂâØÊú¨‰∏äÁöÑÂ§çÂà∂ÁöÑÂèòÈáèÈÉΩÂèØ‰ª•ÂêåÊ†∑Êõ¥Êñ∞„ÄÇ 12345678910111213141516171819def get_data(): datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True) mnist_train, mnist_test = datasets['train'], datasets['test'] BUFFER_SIZE = 10000 BATCH_SIZE_PER_REPLICA = 64 BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync def scale(image, label): image = tf.cast(image, tf.float32) image /= 255 return image, label train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE) eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE) return train_dataset, eval_dataset 1234567891011121314def get_model(): with mirrored_strategy.scope(): model = tf.keras.Sequential([ tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)), tf.keras.layers.MaxPool2D(), tf.keras.layers.Flatten(), tf.keras.layers.Dense(64, activation='relu'), tf.keras.layers.Dense(10) ]) model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy']) return model ËÆ≠ÁªÉÊ®°Âûã1model = get_model() 1train_dataset, eval_dataset = get_data() [1mDownloading and preparing dataset mnist/3.0.1 (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\Users\v-xujwan\tensorflow_datasets\mnist\3.0.1...[0m Shuffling and writing examples to C:\Users\v-xujwan\tensorflow_datasets\mnist\3.0.1.incompleteI371SH\mnist-train.tfrecord Shuffling and writing examples to C:\Users\v-xujwan\tensorflow_datasets\mnist\3.0.1.incompleteI371SH\mnist-test.tfrecord [1mDataset mnist downloaded and prepared to C:\Users\v-xujwan\tensorflow_datasets\mnist\3.0.1. Subsequent calls will reuse this data.[0m 1model.fit(train_dataset, epochs=2) Epoch 1/2 WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\data\ops\multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.data.Iterator.get_next_as_optional()` instead. WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\data\ops\multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.data.Iterator.get_next_as_optional()` instead. 938/938 [==============================] - 18s 19ms/step - loss: 0.2089 - accuracy: 0.9389 Epoch 2/2 938/938 [==============================] - 19s 20ms/step - loss: 0.0689 - accuracy: 0.97980s - los &lt;tensorflow.python.keras.callbacks.History at 0x2b4c939e278&gt; ‰øùÂ≠òÂπ∂Âä†ËΩΩÊ®°ÂûãÁé∞Âú®Êúâ‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊ®°ÂûãÂèØ‰ª•‰ΩøÁî®ÔºåËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏ã‰øùÂ≠ò/Âä†ËΩΩAPI„ÄÇÊúâ‰∏§Â•óÂèØÁî®ÁöÑAPIÔºö È´òÁ∫ßÁöÑkeras model.saveÂíåtf.keras.models.load_model ‰ΩéÁ∫ßÁöÑtf.saved_model.saveÂíåtf.saved_model.load ‰ΩøÁî®keras API12keras_model_path = "./tmp/keras_save"model.save(keras_model_path) WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version. Instructions for updating: This property should not be used in TensorFlow 2.0, as updates are applied automatically. WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version. Instructions for updating: This property should not be used in TensorFlow 2.0, as updates are applied automatically. WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating: This property should not be used in TensorFlow 2.0, as updates are applied automatically. WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating: This property should not be used in TensorFlow 2.0, as updates are applied automatically. INFO:tensorflow:Assets written to: ./tmp/keras_save\assets INFO:tensorflow:Assets written to: ./tmp/keras_save\assets Ê®°Âûã‰øùÂ≠òÊàêÂäüÔºåÁúã‰∏Ä‰∏ã‰øùÂ≠òÁöÑÊñá‰ª∂ ‚îî‚îÄ‚îÄ‚îÄtmp ‚îî‚îÄ‚îÄ‚îÄkeras_save ‚îú‚îÄ‚îÄ‚îÄassets ‚îî‚îÄ‚îÄ‚îÄvariables ‚îî‚îÄ‚îÄ‚îÄvariables.data-00000-of-00001 ‚îî‚îÄ‚îÄ‚îÄvariables.index ‚îî‚îÄ‚îÄ‚îÄsaved_model.pb Êé•ÁùÄËøòÂéüÊ®°Âûã 1restored_keras_model = tf.keras.models.load_model(keras_model_path) ËøòÂéüÂêéÁöÑÊ®°ÂûãÂèØ‰ª•ÁªßÁª≠ËÆ≠ÁªÉ 1restored_keras_model.fit(train_dataset, epochs=2) Epoch 1/2 938/938 [==============================] - 16s 17ms/step - loss: 0.0494 - accuracy: 0.09890s - loss: 0.0493 - accuracy: 0.09 Epoch 2/2 938/938 [==============================] - 16s 17ms/step - loss: 0.0353 - accuracy: 0.0989 &lt;tensorflow.python.keras.callbacks.History at 0x2b4c5b5a128&gt; Áé∞Âú®Âä†ËΩΩÊ®°ÂûãÂπ∂‰ΩøÁî®ËøõË°åËÆ≠ÁªÉtf.distribute.Strategy 1234another_strategy = tf.distribute.OneDeviceStrategy("/cpu:0")with another_strategy.scope(): restored_keras_model_ds = tf.keras.models.load_model(keras_model_path) restored_keras_model_ds.fit(train_dataset, epochs=2) Epoch 1/2 938/938 [==============================] - 16s 17ms/step - loss: 0.0501 - accuracy: 0.0990 Epoch 2/2 938/938 [==============================] - 16s 17ms/step - loss: 0.0354 - accuracy: 0.0989 1restored_keras_model_ds.predict &lt;tensorflow.python.keras.engine.sequential.Sequential at 0x2b4c75ea2b0&gt; ‰ΩøÁî®tf.saved_model APIÁé∞Âú®‰ΩøÁî®‰ΩéÁ∫ßÁöÑapiÔºå‰øùÂ≠òÊñπÊ≥ïÂíåkerasÁ±ª‰ºº 123model = get_model()saved_model_path = "./tmp/tf_save"tf.saved_model.save(model, saved_model_path) INFO:tensorflow:Assets written to: ./tmp/tf_save\assets INFO:tensorflow:Assets written to: ./tmp/tf_save\assets ÂèØ‰ª•‰ΩøÁî®ËøõË°åÂä†ËΩΩtf.saved_model.load()„ÄÇ‰ΩÜÊòØÔºåÁî±‰∫éÂÆÉÊòØ‰∏Ä‰∏™ËæÉ‰ΩéÁ∫ßÂà´ÁöÑAPIÔºàÂõ†Ê≠§ÂÖ∑ÊúâÊõ¥ÂπøÊ≥õÁöÑÁî®‰æãËåÉÂõ¥ÔºâÔºåÂõ†Ê≠§ÂÆÉ‰∏ç‰ºöËøîÂõûKerasÊ®°Âûã„ÄÇÁõ∏ÂèçÔºåÂÆÉËøîÂõû‰∏Ä‰∏™ÂØπË±°ÔºåËØ•ÂØπË±°ÂåÖÂê´ÂèØÁî®‰∫éËøõË°åÊé®Êñ≠ÁöÑÂáΩÊï∞„ÄÇ‰æãÂ¶ÇÔºö ËøòÂèØ‰ª•‰ª•ÂàÜÂ∏ÉÂºèÊñπÂºèÂä†ËΩΩÂíåËøõË°åÊé®Êñ≠Ôºö 1234567891011another_strategy = tf.distribute.MirroredStrategy()with another_strategy.scope(): loaded = tf.saved_model.load(saved_model_path) inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY] dist_predict_dataset = another_strategy.experimental_distribute_dataset( predict_dataset) # Calling the function in a distributed manner for batch in dist_predict_dataset: another_strategy.run(inference_func,args=(batch,)) WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices (&apos;/job:localhost/replica:0/task:0/device:CPU:0&apos;,) INFO:tensorflow:Using MirroredStrategy with devices (&apos;/job:localhost/replica:0/task:0/device:CPU:0&apos;,) WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance. ‰øùÂ≠òÊ£ÄÊü•ÁÇπÊ£ÄÊü•Á´ôÊçïËé∑ÊâÄÊúâÂèÇÊï∞ÔºàÁöÑÁ≤æÁ°ÆÂÄºtf.VariableÁî±Ê®°Âûã‰∏≠‰ΩøÁî®ÁöÑÂØπË±°Ôºâ„ÄÇÊ£ÄÊü•ÁÇπ‰∏çÂåÖÂê´Áî±Ê®°ÂûãÊâÄÂÆö‰πâÁöÑËÆ°ÁÆóÁöÑ‰ªª‰ΩïÊèèËø∞ÔºåÂõ†Ê≠§ÈÄöÂ∏∏‰ªÖÂΩìÂ∞Ü‰ΩøÁî®‰øùÂ≠òÁöÑÂèÇÊï∞ÂÄºÊ∫ê‰ª£Á†ÅÂèØÁî®ÊúâÁî®„ÄÇ Âú®Âè¶‰∏ÄÊñπÈù¢‰∏≠SavedModelÊ†ºÂºèÂåÖÊã¨Áî±Èô§‰∫ÜÂèÇÊï∞ÂÄºÔºàÊ£ÄÊü•ÁÇπÔºâÊ®°Âûã‰∏≠ÂÆö‰πâÁöÑËÆ°ÁÆóÁöÑÂ∫èÂàóÂåñÊèèËø∞„ÄÇËøôÁßçÊ†ºÂºèÁöÑÊ®°ÂûãÊòØÁã¨Á´ã‰∫éÂàõÂª∫Ê®°ÂûãÁöÑÊ∫ê‰ª£Á†Å„ÄÇÂõ†Ê≠§ÔºåÂÆÉ‰ª¨ÈÄÇÁî®‰∫éÈÄöËøáTensorFlowÈÉ®ÁΩ≤ÊúçÂä°ÔºåTensorFlowÁ≤æÁÆÄÁâàÔºåTensorFlow.jsÔºåÊàñÂú®ÂÖ∂‰ªñÁºñÁ®ãËØ≠Ë®ÄÔºàÁöÑCÔºåC ++ÔºåJAVAÔºåÂõ¥Ê£ãÔºåÈò≤ÈîàÔºåCÔºÉÁ≠âTensorFlow APIÔºâÁöÑÁ®ãÂ∫è„ÄÇ Êú¨ÊåáÂçóÊ∂µÁõñAPIËøõË°åÂÜôÂÖ•ÂíåËØªÂá∫Ê£ÄÊü•Á´ô„ÄÇ Âª∫Á´ã123456789class Net(tf.keras.Model): # ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ∫øÊÄßÊ®°Âûã def __init__(self): super(Net, self).__init__() self.l1 = tf.keras.layers.Dense(5) def call(self, x): return self.l1(x) 1net = Net() 1net.save_weights('./tmp/easy_checkpoint') ÂÜôÊ£ÄÊü•Á´ô‰∏Ä‰∏™TensorFlowÊ®°ÂûãÁöÑÊåÅ‰πÖÁä∂ÊÄÅË¢´Â≠òÂÇ®Âú®tf.VariableÂØπË±°„ÄÇËøô‰∫õÂèØ‰ª•Áõ¥Êé•ÊûÑÈÄ†Ôºå‰ΩÜÈÄöÂ∏∏ÈÄöËøáÈ´òÁ∫ßAPIÁ≠âÁîüÊàêtf.keras.layersÊàñtf.keras.Model „ÄÇ ÁÆ°ÁêÜÂèòÈáèÊúÄÁÆÄÂçïÁöÑÊñπÊ≥ïÊòØÂ∞ÜÂÖ∂ÂÆâË£ÖÂà∞PythonÂØπË±°ÔºåÁÑ∂ÂêéÂºïÁî®Ëøô‰∫õÂØπË±°„ÄÇ ÁöÑÂ≠êÁ±ªtf.train.Checkpoint Ôºå tf.keras.layers.LayerÂíåtf.keras.ModelËá™Âä®Ë∑üË∏™ÂàÜÈÖçÁªôÂÆÉ‰ª¨ÁöÑÂ±ûÊÄßÂèòÈáè„ÄÇ‰∏ãÈù¢ÁöÑ‰æãÂ≠êÊûÑÈÄ†‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ∫øÊÄßÊ®°ÂûãÔºåÁÑ∂ÂêéÂÜôÂÖ•ÂÖ∂‰∏≠ÂåÖÂê´ÊâÄÊúâÊ®°ÂûãÁöÑÂèòÈáèÂÄºÁöÑÊ£ÄÊü•Á´ô„ÄÇ ÊÇ®ÂèØ‰ª•ËΩªÊùæÂú∞‰øùÂ≠òÊ®°ÂûãÊ£ÄÊü•ÁÇπ‰∏éModel.save_weights ÊâãÂä®Ê£ÄÊü•ÁÇπ1234def toy_dataset(): inputs = tf.range(10.)[:, None] labels = inputs * 5. + tf.range(5.)[None, :] return tf.data.Dataset.from_tensor_slices(dict(x=inputs, y=labels)).repeat().batch(2) 12345678def train_step(net, example, optimizer): with tf.GradientTape() as tape: output = net(example['x']) loss = tf.reduce_mean(tf.abs(output - example['y'])) variables = net.trainable_variables gradients = tape.gradient(loss, variables) optimizer.apply_gradients(zip(gradients, variables)) return loss ÂàõÂª∫Ê£ÄÊü•ÁÇπÁöÑÂØπË±°ÊâãÂä®ËøõË°åÊ£ÄÊü•ÁÇπÔºåÊÇ®Â∞ÜÈúÄË¶Å‰∏Ä‰∏™tf.train.CheckpointÂØπË±°„ÄÇÂá°Ê£ÄÊü•ÁÇπ‰Ω†ÊÉ≥Ë¶ÅÁöÑÂØπË±°Ë¢´ËÆæÁΩÆ‰∏∫ÂØπË±°ÁöÑÂ±ûÊÄß„ÄÇ ‰∏Ä‰∏™tf.train.CheckpointManager‰πüÂèØÁî®‰∫éÁÆ°ÁêÜÂ§ö‰∏™Ê£ÄÊü•ÁÇπÊúâÂ∏ÆÂä©„ÄÇ 12345opt = tf.keras.optimizers.Adam(0.1)dataset = toy_dataset()iterator = iter(dataset)ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)manager = tf.train.CheckpointManager(ckpt, './tmp/tf_ckpts', max_to_keep=3) ËÆ≠ÁªÉÂíå‰øùÂ≠òÊ£ÄÊü•ÁÇπÊ®°Âûã‰∏ãÈù¢ÁöÑËÆ≠ÁªÉÂæ™ÁéØÂàõÂª∫Ê®°ÂûãÁöÑÂÆû‰æãÂíå‰ºòÂåñÁöÑÔºåÁÑ∂ÂêéÊî∂ÈõÜ‰ªñ‰ª¨ÂÖ•tf.train.CheckpointÂØπË±°„ÄÇÂÆÉÂú®Âæ™ÁéØ‰∏≠Ë∞ÉÁî®Êï∞ÊçÆÁöÑÊØèÊâπËÆ≠ÁªÉÊ≠•È™§ÔºåÂπ∂ÂÆöÊúüÊ£ÄÊü•ÁÇπÂÜôÂÖ•Âà∞Á£ÅÁõò„ÄÇ 123456789101112131415def train_and_checkpoint(net, manager): ckpt.restore(manager.latest_checkpoint) if manager.latest_checkpoint: print("ÊÅ¢Â§çÁÇπÔºö&#123;&#125;".format(manager.latest_checkpoint)) else: print("ÂºÄÂßãÂàùÂßãÂåñ") for _ in range(50): example = next(iterator) loss = train_step(net, example, opt) ckpt.step.assign_add(1) if int(ckpt.step) % 10 == 0: save_path = manager.save() print("‰øùÂ≠òÊ£ÄÊü•ÁÇπ &#123;&#125;: &#123;&#125;".format(int(ckpt.step), save_path)) print("loss &#123;:1.2f&#125;".format(loss.numpy())) 1train_and_checkpoint(net, manager) ÂºÄÂßãÂàùÂßãÂåñ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 10: ./tmp/tf_ckpts\ckpt-1 loss 29.78 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 20: ./tmp/tf_ckpts\ckpt-2 loss 23.19 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 30: ./tmp/tf_ckpts\ckpt-3 loss 16.63 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 40: ./tmp/tf_ckpts\ckpt-4 loss 10.17 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 50: ./tmp/tf_ckpts\ckpt-5 loss 4.09 ÊÅ¢Â§çÂíåÁªßÁª≠ËÆ≠ÁªÉ12345opt = tf.keras.optimizers.Adam(0.1)dataset = toy_dataset()iterator = iter(dataset)ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)manager = tf.train.CheckpointManager(ckpt, './tmp/tf_ckpts', max_to_keep=3) 1train_and_checkpoint(net, manager) ÊÅ¢Â§çÁÇπÔºö./tmp/tf_ckpts\ckpt-10 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 110: ./tmp/tf_ckpts\ckpt-11 loss 0.27 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 120: ./tmp/tf_ckpts\ckpt-12 loss 0.20 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 130: ./tmp/tf_ckpts\ckpt-13 loss 0.16 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 140: ./tmp/tf_ckpts\ckpt-14 loss 0.21 ‰øùÂ≠òÊ£ÄÊü•ÁÇπ 150: ./tmp/tf_ckpts\ckpt-15 loss 0.20 1print(manager.checkpoints) [&apos;./tmp/tf_ckpts\\ckpt-13&apos;, &apos;./tmp/tf_ckpts\\ckpt-14&apos;, &apos;./tmp/tf_ckpts\\ckpt-15&apos;] Ëøô‰∫õË∑ØÂæÑÔºåÂ¶Ç‚Äô./tf_ckpts/ckpt-10‚Äô Ôºå‰∏çÊòØÁ£ÅÁõò‰∏äÁöÑÊñá‰ª∂„ÄÇÁõ∏ÂèçÔºåÂÆÉ‰ª¨ÊòØ‰∏Ä‰∏™ÂâçÁºÄindexÊñá‰ª∂ÂíåÂåÖÂê´ÂèØÂèòÂÄºÁöÑ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Êï∞ÊçÆÊñá‰ª∂„ÄÇËøô‰∫õÂâçÁºÄÂú®Âçï‰∏™ÁªÑÂêàÂú®‰∏ÄËµ∑checkpointÊñá‰ª∂Ôºà ‚Äò./tf_ckpts/checkpoint‚Äô ÔºâÔºåÂÖ∂‰∏≠CheckpointManager‰øùÂ≠òÂÖ∂Áä∂ÊÄÅ„ÄÇ ÊâãÂä®Ê£ÄÊü•tf.train.list_variablesÂàóÂá∫‰∫ÜÊ£ÄÊü•ÁÇπÈîÆÂíåÂèòÈáèÁöÑÂΩ¢Áä∂Âú®‰∏Ä‰∏™Ê£ÄÊü•ÁÇπ„ÄÇÊ£ÄÊü•ÁÇπÈîÆÊòØÊòæÁ§∫Âú®‰ª•‰∏äÂõæ‰∏äÁöÑË∑ØÂæÑ„ÄÇ 1tf.train.list_variables(tf.train.latest_checkpoint('./tmp/tf_ckpts')) [(&apos;_CHECKPOINTABLE_OBJECT_GRAPH&apos;, []), (&apos;iterator/.ATTRIBUTES/ITERATOR_STATE&apos;, [1]), (&apos;net/l1/bias/.ATTRIBUTES/VARIABLE_VALUE&apos;, [5]), (&apos;net/l1/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE&apos;, [5]), (&apos;net/l1/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE&apos;, [5]), (&apos;net/l1/kernel/.ATTRIBUTES/VARIABLE_VALUE&apos;, [1, 5]), (&apos;net/l1/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE&apos;, [1, 5]), (&apos;net/l1/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE&apos;, [1, 5]), (&apos;optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE&apos;, []), (&apos;optimizer/beta_2/.ATTRIBUTES/VARIABLE_VALUE&apos;, []), (&apos;optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE&apos;, []), (&apos;optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE&apos;, []), (&apos;optimizer/learning_rate/.ATTRIBUTES/VARIABLE_VALUE&apos;, []), (&apos;save_counter/.ATTRIBUTES/VARIABLE_VALUE&apos;, []), (&apos;step/.ATTRIBUTES/VARIABLE_VALUE&apos;, [])] ‰øùÂ≠ò‰∏é‰º∞ËÆ°Âü∫‰∫éÂØπË±°ÁöÑÊ£ÄÊü•Á´ôÈÄöËøáÈªòËÆ§‰øùÂ≠òÂèòÈáèÂêçÔºåËÄå‰∏çÊòØÂú®ÂâçÈù¢ÁöÑÁ´†ËäÇ‰∏≠ÊèèËø∞ÁöÑÂØπË±°ÂõæÊ£ÄÊü•ÁÇπ‰º∞ËÆ°„ÄÇ tf.train.CheckpointÂ∞ÜÊé•ÂèóÂü∫‰∫éÂüüÂêçÁöÑÊ£ÄÊü•ÁÇπÔºå‰ΩÜÁßªÂä®‰º∞ËÆ°ÁöÑÊ®°Âûã‰ª•Â§ñÁöÑÈÉ®‰ΩçÊó∂ÔºåÂèòÈáèÂêçÂèØ‰ª•Êõ¥Êîπmodel_fn „ÄÇ‰øùÂ≠òÂü∫‰∫éÂØπË±°ÁöÑÊ£ÄÊü•Á´ôÔºå‰ΩøÂæóÂÆÉÊõ¥ÂÆπÊòìÂüπÂÖªÁöÑ‰º∞ÁÆóÂÜÖÈÉ®Ê®°ÂûãÔºåÁÑ∂ÂêéÂ§ñÈù¢Áî®ÂÆÉ‰πã‰∏Ä„ÄÇ 1import tensorflow.compat.v1 as tf_compat 123456789101112131415def model_fn(features, labels, mode): net = Net() opt = tf.keras.optimizers.Adam(0.1) ckpt = tf.train.Checkpoint(step=tf_compat.train.get_global_step(), optimizers=opt, net=net) with tf.GradientTape()as tape: output = net(features['x']) loss = tf.reduce_mean(tf.abs(output - features['y'])) variables = net.trainable_variables gradients = tape.gradient(loss, variables) return tf.estimator.EstimatorSpec( mode, loss=loss, train_op=tf.group(opt.apply_gradients(zip(gradients, variables)), ckpt.step.assign_add(1)),scaffold=tf_compat.train.Scaffold(saver=ckpt)) 123tf.keras.backend.clear_session()est = tf.estimator.Estimator(model_fn, './tmp/tf_estimator_example/')est.train(toy_dataset, steps=10) INFO:tensorflow:Using default config. INFO:tensorflow:Using default config. INFO:tensorflow:Using config: {&apos;_model_dir&apos;: &apos;./tmp/tf_estimator_example/&apos;, &apos;_tf_random_seed&apos;: None, &apos;_save_summary_steps&apos;: 100, &apos;_save_checkpoints_steps&apos;: None, &apos;_save_checkpoints_secs&apos;: 600, &apos;_session_config&apos;: allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } } , &apos;_keep_checkpoint_max&apos;: 5, &apos;_keep_checkpoint_every_n_hours&apos;: 10000, &apos;_log_step_count_steps&apos;: 100, &apos;_train_distribute&apos;: None, &apos;_device_fn&apos;: None, &apos;_protocol&apos;: None, &apos;_eval_distribute&apos;: None, &apos;_experimental_distribute&apos;: None, &apos;_experimental_max_worker_delay_secs&apos;: None, &apos;_session_creation_timeout_secs&apos;: 7200, &apos;_service&apos;: None, &apos;_cluster_spec&apos;: ClusterSpec({}), &apos;_task_type&apos;: &apos;worker&apos;, &apos;_task_id&apos;: 0, &apos;_global_id_in_cluster&apos;: 0, &apos;_master&apos;: &apos;&apos;, &apos;_evaluation_master&apos;: &apos;&apos;, &apos;_is_chief&apos;: True, &apos;_num_ps_replicas&apos;: 0, &apos;_num_worker_replicas&apos;: 1} INFO:tensorflow:Using config: {&apos;_model_dir&apos;: &apos;./tmp/tf_estimator_example/&apos;, &apos;_tf_random_seed&apos;: None, &apos;_save_summary_steps&apos;: 100, &apos;_save_checkpoints_steps&apos;: None, &apos;_save_checkpoints_secs&apos;: 600, &apos;_session_config&apos;: allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } } , &apos;_keep_checkpoint_max&apos;: 5, &apos;_keep_checkpoint_every_n_hours&apos;: 10000, &apos;_log_step_count_steps&apos;: 100, &apos;_train_distribute&apos;: None, &apos;_device_fn&apos;: None, &apos;_protocol&apos;: None, &apos;_eval_distribute&apos;: None, &apos;_experimental_distribute&apos;: None, &apos;_experimental_max_worker_delay_secs&apos;: None, &apos;_session_creation_timeout_secs&apos;: 7200, &apos;_service&apos;: None, &apos;_cluster_spec&apos;: ClusterSpec({}), &apos;_task_type&apos;: &apos;worker&apos;, &apos;_task_id&apos;: 0, &apos;_global_id_in_cluster&apos;: 0, &apos;_master&apos;: &apos;&apos;, &apos;_evaluation_master&apos;: &apos;&apos;, &apos;_is_chief&apos;: True, &apos;_num_ps_replicas&apos;: 0, &apos;_num_worker_replicas&apos;: 1} WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version. Instructions for updating: Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts. WARNING:tensorflow:From D:\Anaconda3\envs\py36_tf2\lib\site-packages\tensorflow\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version. Instructions for updating: Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts. INFO:tensorflow:Calling model_fn. INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Create CheckpointSaverHook. INFO:tensorflow:Create CheckpointSaverHook. INFO:tensorflow:Graph was finalized. INFO:tensorflow:Graph was finalized. INFO:tensorflow:Running local_init_op. INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0... INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0... INFO:tensorflow:Saving checkpoints for 0 into ./tmp/tf_estimator_example/model.ckpt. INFO:tensorflow:Saving checkpoints for 0 into ./tmp/tf_estimator_example/model.ckpt. INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0... INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0... INFO:tensorflow:loss = 4.505075, step = 1 INFO:tensorflow:loss = 4.505075, step = 1 INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10... INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10... INFO:tensorflow:Saving checkpoints for 10 into ./tmp/tf_estimator_example/model.ckpt. INFO:tensorflow:Saving checkpoints for 10 into ./tmp/tf_estimator_example/model.ckpt. INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10... INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10... INFO:tensorflow:Loss for final step: 36.96539. INFO:tensorflow:Loss for final step: 36.96539. &lt;tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x2b4ccb5f588&gt; 1tf.train.latest_checkpoint('./tmp/tf_estimator_example') &apos;./tmp/tf_estimator_example\\model.ckpt-10&apos; tf.train.CheckpointÂàôÂèØ‰ª•‰ªéÂÖ∂Âä†ËΩΩ‰º∞ËÆ°ÁöÑÊ£ÄÊü•Á´ômodel_dir „ÄÇ12345opt = tf.keras.optimizers.Adam(0.1)net = Net()ckpt = tf.train.Checkpoint(step=tf.Variable(1, dtype=tf.int64), optimizer=opt, net=net)ckpt.restore(tf.train.latest_checkpoint('./tmp/tf_estimator_example/'))ckpt.step.numpy() 10]]></content>
      <categories>
        <category>tensorflow2</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[gRPC]]></title>
    <url>%2F2020%2F07%2F24%2FgRPC%2F</url>
    <content type="text"><![CDATA[‰ªÄ‰πàÊòØRPCÂèÇËÄÉÁü•‰πé Ë∞ÅËÉΩÁî®ÈÄö‰øóÁöÑËØ≠Ë®ÄËß£Èáä‰∏Ä‰∏ã‰ªÄ‰πàÊòØ RPC Ê°ÜÊû∂Ôºü ‰πãÂâçÂè™Áü•ÈÅìIPCÔºåÊòØÊåáËøõÁ®ãÈó¥ÈÄö‰ø°(Inter Process Communication)ÔºåËá≥Â∞ë‰∏§‰∏™ËøõÁ®ãÊàñÁ∫øÁ®ãÈó¥‰º†ÈÄÅÊï∞ÊçÆÊàñ‰ø°Âè∑ÁöÑ‰∏Ä‰∫õÊäÄÊúØÊàñÊñπÊ≥ïÔºåRPCÂíåIPCÁ±ª‰ººÔºåÁôæÁßëËß£ÈáäRPCÔºàRemote Procedure CallÔºâ‰∏∫ËøúÁ®ãËøáÁ®ãË∞ÉÁî®ÔºåÁÆÄÂçïÁêÜËß£‰∏∫ÔºåÂ∞±ÊòØÂÉèË∞ÉÁî®Êú¨Âú∞ÂáΩÊï∞‰∏ÄÊ†∑Ë∞ÉÁî®ËøúÁ®ãÂáΩÊï∞Ôºå‰æãÂ¶ÇÔºåÊúâ‰∏§Âè∞ÊúçÂä°Âô®A,BÔºå‰∏Ä‰∏™Â∫îÁî®ÈÉ®ÁΩ≤Âú®AÊúçÂä°Âô®‰∏äÔºåÊÉ≥Ë¶ÅË∞ÉÁî®BÊúçÂä°Âô®‰∏äÁöÑÂáΩÊï∞ÂíåÊñπÊ≥ïÔºåÁî±‰∫é‰∏çÂú®‰∏Ä‰∏™ÂÜÖÂ≠òÁ©∫Èó¥Ôºå‰∏çËÉΩÁõ¥Êé•Ë∞ÉÁî®ÔºåÈúÄË¶ÅÈÄöËøáÁΩëÁªúÊù•Ë°®ËææË∞ÉÁî®ÁöÑËØ≠‰πâÂíå‰º†ËææË∞ÉÁî®ÁöÑÊï∞ÊçÆ„ÄÇ RPCÂéüÁêÜÈ¶ñÂÖàÂÆ¢Êà∑Á´ØÈúÄË¶ÅÂëäËØâÊúçÂä°Âô®ÔºåÈúÄË¶ÅË∞ÉÁî®ÁöÑÂáΩÊï∞ÔºåËøôÈáåÂáΩÊï∞ÂíåËøõÁ®ãIDÂ≠òÂú®‰∏Ä‰∏™Êò†Â∞ÑÔºåÂÆ¢Êà∑Á´ØËøúÁ®ãË∞ÉÁî®Êó∂ÔºåÈúÄË¶ÅÊü•‰∏Ä‰∏ãÂáΩÊï∞ÔºåÊâæÂà∞ÂØπÂ∫îÁöÑIDÔºåÁÑ∂ÂêéÊâßË°åÂáΩÊï∞ÁöÑ‰ª£Á†Å„ÄÇ ÂÆ¢Êà∑Á´ØÈúÄË¶ÅÊääÊú¨Âú∞ÂèÇÊï∞‰º†ÁªôËøúÁ®ãÂáΩÊï∞ÔºåÊú¨Âú∞Ë∞ÉÁî®ÁöÑËøáÁ®ã‰∏≠ÔºåÁõ¥Êé•ÂéãÊ†àÂç≥ÂèØÔºå‰ΩÜÊòØÂú®ËøúÁ®ãË∞ÉÁî®ËøáÁ®ã‰∏≠‰∏çÂÜçÂêå‰∏Ä‰∏™ÂÜÖÂ≠òÈáåÔºåÊó†Ê≥ïÁõ¥Êé•‰º†ÈÄíÂáΩÊï∞ÁöÑÂèÇÊï∞ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂÆ¢Êà∑Á´ØÊääÂèÇÊï∞ËΩ¨Êç¢ÊàêÂ≠óËäÇÊµÅÔºå‰º†ÁªôÊúçÂä°Á´ØÔºåÁÑ∂ÂêéÊúçÂä°Á´ØÂ∞ÜÂ≠óËäÇÊµÅËΩ¨Êç¢ÊàêËá™Ë∫´ËÉΩËØªÂèñÁöÑÊ†ºÂºèÔºåÊòØ‰∏Ä‰∏™Â∫èÂàóÂåñÂíåÂèçÂ∫èÂàóÂåñÁöÑËøáÁ®ã„ÄÇ Êï∞ÊçÆÂáÜÂ§áÂ•Ω‰∫Ü‰πãÂêéÔºåÁΩëÁªú‰º†ËæìÂ±ÇÈúÄË¶ÅÊääË∞ÉÁî®ÁöÑIDÂíåÂ∫èÂàóÂåñÂêéÁöÑÂèÇÊï∞‰º†ÁªôÊúçÂä°Á´ØÔºåÁÑ∂ÂêéÊääËÆ°ÁÆóÂ•ΩÁöÑÁªìÊûúÂ∫èÂàóÂåñ‰º†ÁªôÂÆ¢Êà∑Á´ØÔºåÂõ†Ê≠§TCPÂ±ÇÂç≥ÂèØÂÆåÊàê‰∏äËø∞ËøáÁ®ãÔºågRPC‰∏≠ÈááÁî®ÁöÑÊòØHTTP2ÂçèËÆÆ„ÄÇ RPCÊ°ÜÊû∂ÂØπÊØîDubbo ÊòØÈòøÈáåÂ∑¥Â∑¥ÂÖ¨Âè∏ÂºÄÊ∫êÁöÑ‰∏Ä‰∏™JavaÈ´òÊÄßËÉΩ‰ºòÁßÄÁöÑÊúçÂä°Ê°ÜÊû∂Ôºå‰ΩøÂæóÂ∫îÁî®ÂèØÈÄöËøáÈ´òÊÄßËÉΩÁöÑRPC ÂÆûÁé∞ÊúçÂä°ÁöÑËæìÂá∫ÂíåËæìÂÖ•ÂäüËÉΩÔºåÂèØ‰ª•ÂíåSpringÊ°ÜÊû∂Êó†ÁºùÈõÜÊàê„ÄÇ‰∏çËøáÔºåÁï•ÊúâÈÅóÊÜæÁöÑÊòØÔºåÊçÆËØ¥Âú®Ê∑òÂÆùÂÜÖÈÉ®ÔºådubboÁî±‰∫éË∑üÊ∑òÂÆùÂè¶‰∏Ä‰∏™Á±ª‰ººÁöÑÊ°ÜÊû∂HSFÔºàÈùûÂºÄÊ∫êÔºâÊúâÁ´û‰∫âÂÖ≥Á≥ªÔºåÂØºËá¥dubboÂõ¢ÈòüÂ∑≤ÁªèËß£Êï£ÔºåÂèçÂà∞ÊòØÂΩìÂΩìÁΩëÁöÑÊâ©Â±ïÁâàÊú¨Dubbox‰ªçÂú®ÊåÅÁª≠ÂèëÂ±ïÔºåÂ¢ôÂÜÖÂºÄËä±Â¢ôÂ§ñÈ¶ô„ÄÇDubboxÂíåDubboÊú¨Ë¥®‰∏äÊ≤°ÊúâÂå∫Âà´ÔºåÂêçÂ≠óÁöÑÂê´‰πâÊâ©Â±ï‰∫ÜDubboËÄåÂ∑≤Ôºå‰ª•‰∏ãÊâ©Â±ïÂá∫Êù•ÁöÑÂäüËÉΩÔºå‰πüÊòØÈÄâÊã©DubboxÂæàÈáçË¶ÅÁöÑËÄÉÂØüÁÇπ„ÄÇ Motan ÊòØÊñ∞Êµ™ÂæÆÂçöÂºÄÊ∫êÁöÑ‰∏Ä‰∏™JavaÊ°ÜÊû∂„ÄÇÂÆÉËØûÁîüÁöÑÊØîËæÉÊôöÔºåËµ∑‰∫é2013Âπ¥Ôºå2016Âπ¥5ÊúàÂºÄÊ∫ê„ÄÇMotan Âú®ÂæÆÂçöÂπ≥Âè∞‰∏≠Â∑≤ÁªèÂπøÊ≥õÂ∫îÁî®ÔºåÊØèÂ§©‰∏∫Êï∞Áôæ‰∏™ÊúçÂä°ÂÆåÊàêËøëÂçÉ‰∫øÊ¨°ÁöÑË∞ÉÁî®„ÄÇ‰∏éDubboÁõ∏ÊØîÔºåMotanÂú®ÂäüËÉΩÊñπÈù¢Âπ∂Ê≤°ÊúâÈÇ£‰πàÂÖ®Èù¢Ôºå‰πüÊ≤°ÊúâÂÆûÁé∞ÁâπÂà´Â§öÁöÑÊâ©Â±ï„ÄÇÁî®ÁöÑ‰∫∫ÊØîËæÉÂ∞ëÔºåÂäüËÉΩÂíåÁ®≥ÂÆöÊÄßÊúâÂæÖËßÇÊúõ„ÄÇÂØπË∑®ËØ≠Ë®ÄË∞ÉÁî®ÊîØÊåÅËæÉÂ∑ÆÔºå‰∏ªË¶ÅÊîØÊåÅjava„ÄÇ Hessian ÈááÁî®ÁöÑÊòØ‰∫åËøõÂà∂RPCÂçèËÆÆÔºåÈÄÇÁî®‰∫éÂèëÈÄÅ‰∫åËøõÂà∂Êï∞ÊçÆ„ÄÇ‰ΩÜÊú¨Ë∫´‰πüÊòØ‰∏Ä‰∏™Web ServiceÊ°ÜÊû∂ÂØπRPCË∞ÉÁî®Êèê‰æõÊîØÊåÅÔºåÂäüËÉΩÁÆÄÂçïÔºå‰ΩøÁî®Ëµ∑Êù•‰πüÊñπ‰æø„ÄÇÂü∫‰∫éHttpÂçèËÆÆËøõË°å‰º†Ëæì„ÄÇÈÄöËøáServletÊèê‰æõËøúÁ®ãÊúçÂä°„ÄÇÈÄöËøáHessainÊú¨Ë∫´Êèê‰æõÁöÑAPIÊù•ÂèëËµ∑ËØ∑Ê±Ç„ÄÇÂìçÂ∫îÁ´ØÊ†πÊçÆHessianÊèê‰æõÁöÑAPIÊù•Êé•ÂèóËØ∑Ê±Ç„ÄÇ rpcx ÊòØGoËØ≠Ë®ÄÁîüÊÄÅÂúàÁöÑDubboÔºå ÊØîDubboÊõ¥ËΩªÈáèÔºåÂÆûÁé∞‰∫ÜDubboÁöÑËÆ∏Â§öÁâπÊÄßÔºåÂÄüÂä©‰∫éGoËØ≠Ë®Ä‰ºòÁßÄÁöÑÂπ∂ÂèëÁâπÊÄßÂíåÁÆÄÊ¥ÅËØ≠Ê≥ïÔºåÂèØ‰ª•‰ΩøÁî®ËæÉÂ∞ëÁöÑ‰ª£Á†ÅÂÆûÁé∞ÂàÜÂ∏ÉÂºèÁöÑRPCÊúçÂä°„ÄÇ gRPC ÊòØGoogleÂºÄÂèëÁöÑÈ´òÊÄßËÉΩ„ÄÅÈÄöÁî®ÁöÑÂºÄÊ∫êRPCÊ°ÜÊû∂ÔºåÂÖ∂Áî±Google‰∏ªË¶ÅÈù¢ÂêëÁßªÂä®Â∫îÁî®ÂºÄÂèëÂπ∂Âü∫‰∫éHTTP/2ÂçèËÆÆÊ†áÂáÜËÄåËÆæËÆ°ÔºåÂü∫‰∫éProtoBuf(Protocol Buffers)Â∫èÂàóÂåñÂçèËÆÆÂºÄÂèëÔºå‰∏îÊîØÊåÅ‰ºóÂ§öÂºÄÂèëËØ≠Ë®Ä„ÄÇÊú¨Ë∫´ÂÆÉ‰∏çÊòØÂàÜÂ∏ÉÂºèÁöÑÔºåÊâÄ‰ª•Ë¶ÅÂÆûÁé∞‰∏äÈù¢ÁöÑÊ°ÜÊû∂ÁöÑÂäüËÉΩÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÁöÑÂºÄÂèë„ÄÇ thrift ÊòØApacheÁöÑ‰∏Ä‰∏™Ë∑®ËØ≠Ë®ÄÁöÑÈ´òÊÄßËÉΩÁöÑÊúçÂä°Ê°ÜÊû∂Ôºå‰πüÂæóÂà∞‰∫ÜÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇ ÂäüËÉΩ Hessian Montan rpcx gRPC Thrift Dubbo Dubbox Spring Cloud ÂºÄÂèëËØ≠Ë®Ä Ë∑®ËØ≠Ë®Ä Java Go Ë∑®ËØ≠Ë®Ä Ë∑®ËØ≠Ë®Ä Java Java Java ÂàÜÂ∏ÉÂºè(ÊúçÂä°Ê≤ªÁêÜ) √ó ‚àö ‚àö √ó √ó ‚àö ‚àö ‚àö Â§öÂ∫èÂàóÂåñÊ°ÜÊû∂ÊîØÊåÅ hessian ‚àö(ÊîØÊåÅHessian2„ÄÅJson,ÂèØÊâ©Â±ï) ‚àö √ó Âè™ÊîØÊåÅprotobuf) √ó(thriftÊ†ºÂºè) ‚àö ‚àö ‚àö Â§öÁßçÊ≥®ÂÜå‰∏≠ÂøÉ √ó ‚àö ‚àö √ó √ó ‚àö ‚àö ‚àö ÁÆ°ÁêÜ‰∏≠ÂøÉ √ó ‚àö ‚àö √ó √ó ‚àö ‚àö ‚àö Ë∑®ÁºñÁ®ãËØ≠Ë®Ä ‚àö √ó(ÊîØÊåÅphp clientÂíåC server) √ó ‚àö ‚àö √ó √ó √ó ÊîØÊåÅREST √ó √ó √ó √ó √ó √ó ‚àö ‚àö ÂÖ≥Ê≥®Â∫¶ ‰Ωé ‰∏≠ ‰Ωé ‰∏≠ ‰∏≠ ‰∏≠ È´ò ‰∏≠ ‰∏äÊâãÈöæÂ∫¶ ‰Ωé ‰Ωé ‰∏≠ ‰∏≠ ‰∏≠ ‰Ωé ‰Ωé ‰∏≠ ËøêÁª¥ÊàêÊú¨ ‰Ωé ‰∏≠ ‰∏≠ ‰∏≠ ‰Ωé ‰∏≠ ‰∏≠ ‰∏≠ ÂºÄÊ∫êÊú∫ÊûÑ Caucho Weibo Apache Google Apache Alibaba Dangdang Apache ÂèÇËÄÉ gRPCÁÆÄ‰ªãhttps://grpc.io/ gRPCÊòØÂèØ‰ª•Âú®‰ªª‰ΩïÁéØÂ¢É‰∏≠ËøêË°åÁöÑÁé∞‰ª£ÂºÄÊ∫êÈ´òÊÄßËÉΩRPCÊ°ÜÊû∂„ÄÇÂÆÉÂèØ‰ª•ÈÄöËøáÂèØÊèíÊãîÁöÑÊîØÊåÅÊù•ÊúâÊïàÂú∞ËøûÊé•Êï∞ÊçÆ‰∏≠ÂøÉÂÜÖÂíåË∑®Êï∞ÊçÆ‰∏≠ÂøÉÁöÑÊúçÂä°Ôºå‰ª•ÂÆûÁé∞Ë¥üËΩΩÂπ≥Ë°°ÔºåË∑üË∏™ÔºåËøêË°åÁä∂ÂÜµÊ£ÄÊü•ÂíåË∫´‰ªΩÈ™åËØÅ„ÄÇÂÆÉ‰πüÈÄÇÁî®‰∫éÂàÜÂ∏ÉÂºèËÆ°ÁÆóÁöÑÊúÄÂêé‰∏ÄËã±ÈáåÔºå‰ª•Â∞ÜËÆæÂ§áÔºåÁßªÂä®Â∫îÁî®Á®ãÂ∫èÂíåÊµèËßàÂô®ËøûÊé•Âà∞ÂêéÁ´ØÊúçÂä°„ÄÇ Âú®gRPC‰∏≠ÔºåÂÆ¢Êà∑Á´ØÂ∫îÁî®Á®ãÂ∫èÂèØ‰ª•Áõ¥Êé•Âú®ÂÖ∂‰ªñËÆ°ÁÆóÊú∫‰∏äÁöÑÊúçÂä°Âô®Â∫îÁî®Á®ãÂ∫è‰∏äË∞ÉÁî®ÊñπÊ≥ïÔºåÂ∞±Â•ΩÂÉèÂÆÉÊòØÊú¨Âú∞ÂØπË±°‰∏ÄÊ†∑Ôºå‰ªéËÄå‰ΩøÊÇ®Êõ¥ËΩªÊùæÂú∞ÂàõÂª∫ÂàÜÂ∏ÉÂºèÂ∫îÁî®Á®ãÂ∫èÂíåÊúçÂä°„ÄÇ‰∏éËÆ∏Â§öRPCÁ≥ªÁªü‰∏ÄÊ†∑ÔºågRPCÂõ¥ÁªïÂÆö‰πâÊúçÂä°ÁöÑÊÄùÊÉ≥ÔºåÊåáÂÆöÂèØÈÄöËøáÂÖ∂ÂèÇÊï∞ÂíåËøîÂõûÁ±ªÂûãËøúÁ®ãË∞ÉÁî®ÁöÑÊñπÊ≥ï„ÄÇÂú®ÊúçÂä°Âô®Á´ØÔºåÊúçÂä°Âô®ÂÆûÁé∞Ê≠§Êé•Âè£Âπ∂ËøêË°ågRPCÊúçÂä°Âô®‰ª•Â§ÑÁêÜÂÆ¢Êà∑Á´ØË∞ÉÁî®„ÄÇÂú®ÂÆ¢Êà∑Á´ØÔºåÂÆ¢Êà∑Á´ØÂÖ∑Êúâ‰∏Ä‰∏™Â≠òÊ†πÔºàÂú®Êüê‰∫õËØ≠Ë®Ä‰∏≠‰ªÖÁß∞‰∏∫ÂÆ¢Êà∑Á´ØÔºâÔºåÊèê‰æõ‰∏éÊúçÂä°Âô®Áõ∏ÂêåÁöÑÊñπÊ≥ï„ÄÇ ‰ªéGoogleÂÜÖÈÉ®ÁöÑÊúçÂä°Âô®Âà∞ÊÇ®Ëá™Â∑±ÁöÑÂè∞ÂºèÊú∫ÔºågRPCÂÆ¢Êà∑Á´ØÂíåÊúçÂä°Âô®ÈÉΩÂèØ‰ª•Âú®ÂêÑÁßçÁéØÂ¢É‰∏≠ËøêË°åÂπ∂Áõ∏‰∫íÈÄö‰ø°ÔºåÂπ∂‰∏îÂèØ‰ª•‰ΩøÁî®gRPCÊîØÊåÅÁöÑ‰ªª‰ΩïËØ≠Ë®ÄÁºñÂÜô„ÄÇÂõ†Ê≠§Ôºå‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®GoÔºåPythonÊàñRubyÁöÑÂÆ¢Êà∑Á´ØËΩªÊùæÂú∞Áî®JavaÂàõÂª∫gRPCÊúçÂä°Âô®„ÄÇÊ≠§Â§ñÔºåÊúÄÊñ∞ÁöÑGoogle APIÁöÑÊé•Âè£Â∞ÜÂÖ∑ÊúâgRPCÁâàÊú¨ÔºåÂèØËÆ©ÊÇ®ËΩªÊùæÂú∞Âú®Â∫îÁî®Á®ãÂ∫è‰∏≠ÂÜÖÁΩÆGoogleÂäüËÉΩ„ÄÇ ProtobufÂú®ÂÜôgPRCÂâçËøòÈúÄË¶ÅÁü•ÈÅìProtobufÔºåProtocol BufferÁöÑÁøªËØë‰∏∫ÂçèËÆÆÁºìÂÜ≤Âå∫Ôºå ÊòØGoogleÁöÑ‰∏éËØ≠Ë®ÄÊó†ÂÖ≥Ôºå‰∏éÂπ≥Âè∞Êó†ÂÖ≥ÔºåÂèØÊâ©Â±ïÁöÑÊú∫Âà∂ÔºåÁî®‰∫éÂØπÁªìÊûÑÂåñÊï∞ÊçÆËøõË°åÂ∫èÂàóÂåñÔºà‰æãÂ¶ÇXMLÔºâÔºå‰ΩÜÊõ¥Â∞èÔºåÊõ¥Âø´ÔºåÊõ¥ÁÆÄÂçï„ÄÇÊÇ®ÂÆö‰πâË¶Å‰∏ÄÊ¨°ÊûÑÈÄ†Êï∞ÊçÆÁöÑÊñπÂºèÔºåÁÑ∂ÂêéÂèØ‰ª•‰ΩøÁî®ÁîüÊàêÁöÑÁâπÊÆäÊ∫ê‰ª£Á†ÅËΩªÊùæÂú∞‰ΩøÁî®ÂêÑÁßçËØ≠Ë®ÄÂú®ÂêÑÁßçÊï∞ÊçÆÊµÅ‰∏≠ÂÜôÂÖ•ÂíåËØªÂèñÁªìÊûÑÂåñÊï∞ÊçÆ„ÄÇ Áúã‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑ‰æãÂ≠ê„ÄÇÂÅáËÆæË¶ÅÂÆö‰πâ‰∏Ä‰∏™ÊêúÁ¥¢ËØ∑Ê±ÇÊ∂àÊÅØÊ†ºÂºèÔºåÂÖ∂‰∏≠ÊØè‰∏™ÊêúÁ¥¢ËØ∑Ê±ÇÈÉΩÊúâ‰∏Ä‰∏™Êü•ËØ¢Â≠óÁ¨¶‰∏≤ÔºåÊÇ®ÊÑüÂÖ¥Ë∂£ÁöÑÁâπÂÆöÁªìÊûúÈ°µÈù¢‰ª•ÂèäÊØèÈ°µÁªìÊûúÊï∞Èáè„ÄÇËøôÊòØ.protoÁî®‰∫éÂÆö‰πâÊ∂àÊÅØÁ±ªÂûãÁöÑÊñá‰ª∂„ÄÇ 1234567syntax = "proto3";message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125; Êñá‰ª∂ÁöÑÁ¨¨‰∏ÄË°åÊåáÂÆöÊ≠£Âú®‰ΩøÁî®proto3ËØ≠Ê≥ïÔºöÂ¶ÇÊûú‰∏çËøôÊ†∑ÂÅöÔºåÂàôÂçèËÆÆÁºìÂÜ≤Âå∫ÁºñËØëÂô®Â∞ÜÂÅáÂÆöÊÇ®Ê≠£Âú®‰ΩøÁî®proto2„ÄÇËøôÂøÖÈ°ªÊòØÊñá‰ª∂ÁöÑÁ¨¨‰∏ÄË°åÔºåÈùûÁ©∫ÔºåÈùûÊ≥®ÈáäË°å„ÄÇ ÊâÄËø∞SearchRequestÊ∂àÊÅØÂÆö‰πâÊåáÂÆö‰∫Ü‰∏â‰∏™Â≠óÊÆµÔºàÂêçÁß∞/ÂÄºÂØπÔºâÔºå‰∏Ä‰∏™Áî®‰∫éÊØèÊù°Êï∞ÊçÆË¶ÅÂú®Ê≠§Á±ªÂûãÁöÑÊ∂àÊÅØÂåÖÊã¨„ÄÇÊØè‰∏™Â≠óÊÆµÈÉΩÊúâ‰∏Ä‰∏™ÂêçÁß∞ÂíåÁ±ªÂûã„ÄÇ .protoÊñá‰ª∂ÊúÄÁªàÁîüÊàê‰ªÄ‰πà ÂΩì‰Ω†‰ΩøÁî®protocÊù•ÁºñËØë‰∏Ä‰∏™.protoÊñá‰ª∂ÁöÑÊó∂ÂÄôÔºåÁºñËØëÂô®Â∞ÜÂà©Áî®‰Ω†Âú®Êñá‰ª∂‰∏≠ÂÆö‰πâÁöÑÁ±ªÂûãÁîüÊàê‰Ω†ÊâìÁÆó‰ΩøÁî®ÁöÑËØ≠Ë®ÄÁöÑ‰ª£Á†ÅÊñá‰ª∂„ÄÇÁîüÊàêÁöÑ‰ª£Á†ÅÂåÖÊã¨getting setting Êé•Âè£ÂíåÂ∫èÂàóÂåñÔºåÂèçÂ∫èÂàóÂåñÊé•Âè£„ÄÇ ÂØπ‰∫éC ++ÔºåÁºñËØëÂô®‰ºö‰ªéÊØè‰∏™.protoÊñá‰ª∂ÁîüÊàê‰∏Ä‰∏™.hÂíå‰∏Ä‰∏™.ccÊñá‰ª∂ÔºåÂπ∂‰∏∫ÊÇ®Êñá‰ª∂‰∏≠ÊèèËø∞ÁöÑÊØèÁßçÊ∂àÊÅØÁ±ªÂûãÊèê‰æõ‰∏Ä‰∏™Á±ª„ÄÇ ÂØπ‰∫éJavaÔºåÁºñËØëÂô®ÁîüÊàê‰∏Ä‰∏™.javaÊñá‰ª∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊØèÁßçÊ∂àÊÅØÁ±ªÂûãÁöÑÁ±ªÔºå‰ª•ÂèäBuilderÁî®‰∫éÂàõÂª∫Ê∂àÊÅØÁ±ªÂÆû‰æãÁöÑÁâπÊÆäÁ±ª„ÄÇ PythonÊúâÁÇπ‰∏çÂêå - PythonÁºñËØëÂô®ÁîüÊàê‰∏Ä‰∏™Ê®°ÂùóÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊØè‰∏™Ê∂àÊÅØÁ±ªÂûãÁöÑÈùôÊÄÅÊèèËø∞Á¨¶ÔºåÁÑ∂ÂêéÔºåÁî®‰∏Ä‰∏™ÂÖÉÁ±ªÂú®ËøêË°åÊó∂ÂàõÂª∫ÂøÖË¶ÅÁöÑPythonÊï∞ÊçÆËÆøÈóÆÁ±ª„ÄÇ ÂØπ‰∫éGoÔºåÁºñËØëÂô®‰ºö‰∏∫.pb.goÊñá‰ª∂‰∏≠ÁöÑÊØèÁßçÊ∂àÊÅØÁ±ªÂûãÁîüÊàê‰∏Ä‰∏™Á±ªÂûãÁöÑÊñá‰ª∂„ÄÇ ÂØπ‰∫éRubyÔºåÁºñËØëÂô®ÁîüÊàê‰∏Ä‰∏™.rbÂåÖÂê´Ê∂àÊÅØÁ±ªÂûãÁöÑRubyÊ®°ÂùóÁöÑÊñá‰ª∂„ÄÇ ÂØπ‰∫éObjective-CÔºåÁºñËØëÂô®‰ªéÊØè‰∏™.protoÊñá‰ª∂ÁîüÊàê‰∏Ä‰∏™pbobjc.hÂíå‰∏Ä‰∏™pbobjc.mÊñá‰ª∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´Êñá‰ª∂‰∏≠ÊèèËø∞ÁöÑÊØèÁßçÊ∂àÊÅØÁ±ªÂûãÁöÑÁ±ª„ÄÇ ÂØπ‰∫éCÔºÉÔºåÁºñËØëÂô®‰ºö‰ªéÊØè‰∏™.protoÊñá‰ª∂ÁîüÊàê‰∏Ä‰∏™.csÊñá‰ª∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´Êñá‰ª∂‰∏≠ÊèèËø∞ÁöÑÊØèÁßçÊ∂àÊÅØÁ±ªÂûãÁöÑÁ±ª„ÄÇ gPRCÁöÑHelloWordËÆ∞ÂΩï‰ΩøÁî®pythonÁöÑgRPC ÂÆâË£ÖgPRCÂíågRPCÂ∑•ÂÖ∑ 12$ python -m pip install grpcio$ python -m pip install grpcio-tools gRPCÂ∑•ÂÖ∑ÂåÖÊã¨ÂçèËÆÆÁºìÂÜ≤Âå∫ÁºñËØëÂô®protocÂíåÁî®‰∫éÊ†πÊçÆ.protoÊúçÂä°ÂÆö‰πâÁîüÊàêÊúçÂä°Âô®ÂíåÂÆ¢Êà∑Á´Ø‰ª£Á†ÅÁöÑÁâπÊÆäÊèí‰ª∂„ÄÇ È¶ñÂÖàÊñ∞Âª∫‰∏Ä‰∏™protosÁöÑÊñá‰ª∂Â§πÁºñÂÜôhelloworld.proto12345678910111213141516171819202122232425#protos\helloworld.protosyntax = "proto3";option java_multiple_files = true;option java_package = "io.grpc.examples.helloworld";option java_outer_classname = "HelloWorldProto";option objc_class_prefix = "HLW";package helloworld;// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user's name.message HelloRequest &#123; string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123; string message = 1;&#125; Êé•‰∏ãÊù•ÔºåÊàë‰ª¨ÈúÄË¶ÅÁîüÊàêÂ∫îÁî®Á®ãÂ∫è‰ΩøÁî®ÁöÑgRPC‰ª£Á†Å„ÄÇ 1$ python -m grpc_tools.protoc -I./protos --python_out=. --grpc_python_out=. ./protos/helloworld.proto ÁõÆÂΩï‰∏ã‰ºöÁîüÊàê‰∏§‰∏™Êñá‰ª∂ helloworld_pb2.py helloworld_pb2_grpc.py ÁÑ∂ÂêéÊàë‰ª¨Â∞±ÂèØ‰ª•Ë∞ÉÁî®Ëøô‰∏§‰∏™Êñá‰ª∂ÁöÑÁîüÊàêÁöÑÊé•Âè£‰∫ÜÔºå Âú®ServerÁ´ØÂÆö‰πâÊé•Âè£ÁöÑÂÆûÁé∞ 1234567891011121314151617181920212223242526272829# greeter_server.py"""The Python implementation of the GRPC helloworld.Greeter server."""from concurrent import futuresimport loggingimport grpcimport helloworld_pb2import helloworld_pb2_grpcclass Greeter(helloworld_pb2_grpc.GreeterServicer): def SayHello(self, request, context): return helloworld_pb2.HelloReply(message='Hello, %s!' % request.name)def serve(): server = grpc.server(futures.ThreadPoolExecutor(max_workers=10)) helloworld_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server) server.add_insecure_port('[::]:50051') server.start() server.wait_for_termination()if __name__ == '__main__': logging.basicConfig() serve() ClientÁ´ØË∞ÉÁî®ËøúÁ®ãÊñπÊ≥ï 12345678910111213141516171819202122232425# greeter_client.py"""The Python implementation of the GRPC helloworld.Greeter client."""from __future__ import print_functionimport loggingimport grpcimport helloworld_pb2import helloworld_pb2_grpcdef run(): # NOTE(gRPC Python Team): .close() is possible on a channel and should be # used in circumstances in which the with statement does not fit the needs # of the code. with grpc.insecure_channel('localhost:50051') as channel: stub = helloworld_pb2_grpc.GreeterStub(channel) response = stub.SayHello(helloworld_pb2.HelloRequest(name='you')) print("Greeter client received: " + response.message)if __name__ == '__main__': logging.basicConfig() run() 12345678È¶ñÂÖàÂêØÂä®server$ python greeter_server.pyËøêË°åclient$ python greeter_client.pyËæìÂá∫ÔºöGreeter client received: Hello, you! Ë∑®ËØ≠Ë®ÄË∞ÉÁî®gRPCÊòØÊîØÊåÅ‰∏çÂêåËØ≠Ë®ÄË∞ÉÁî®ÁöÑÔºåC#ÂÜô‰∏Ä‰∏™ServerÔºåÁî®pythonÁöÑClientË∞ÉÁî®„ÄÇ È¶ñÂÖàÁî®Visual StudioÊñ∞Âª∫‰∏Ä‰∏™Â∑•Á®ãÔºåÊ∑ªÂä†GreeterÂíåGreeterServer‰∏§‰∏™È°πÁõÆ GreeterÊ∑ªÂä†GrpcÁöÑNuGetÂåÖ Goggle.Protobuf Grpc Grpc.Tools ÈÄâÊã©.protoÁöÑpropertiesÔºåbuildÊîπ‰∏∫Protobuf Áé∞Âú®ÈÄâÊã©GreeterÈ°πÁõÆÔºåÁîüÊàê‰ºöbuildÂá∫ Helloworld.cs Âíå HelloworldGrpc.cs‰∏§‰∏™Êñá‰ª∂„ÄÇ ËØ¶ÊÉÖ ÁºñÂÜôGreeterServerÁöÑProgram.csÔºåËÆ∞ÂæóË¶ÅÂºïÁî®Greeter 1234567891011121314151617181920212223242526272829303132333435363738// GreeterServer/Program.csusing System;using System.Threading.Tasks;using Grpc.Core;using Helloworld;namespace GreeterServer&#123; class GreeterImpl : Greeter.GreeterBase &#123; // Server side handler of the SayHello RPC public override Task&lt;HelloReply&gt; SayHello(HelloRequest request, ServerCallContext context) &#123; return Task.FromResult(new HelloReply &#123; Message = &quot;Hello &quot; + request.Name &#125;); &#125;&#125; class Program &#123; const int Port = 50051; public static void Main(string[] args) &#123; Server server = new Server &#123; Services = &#123; Greeter.BindService(new GreeterImpl()) &#125;, Ports = &#123; new ServerPort(&quot;localhost&quot;, Port, ServerCredentials.Insecure) &#125; &#125;; server.Start(); Console.WriteLine(&quot;Greeter server listening on port &quot; + Port); Console.WriteLine(&quot;Press any key to stop the server...&quot;); Console.ReadKey(); server.ShutdownAsync().Wait(); &#125; &#125;&#125; ÁÑ∂ÂêéÂ∞±ÂèØ‰ª•ÊûÑÂª∫Âπ∂ÊâßË°åC#ÁöÑServer‰∫Ü 12345&gt; dotnet build Greeter.sln&gt; cd GreeterServer\&gt; dotnet runGreeter server listening on port 51062Press any key to stop the server... ÂÜçÊâßË°å‰πãÂâçÁî®pythonÂÜôÁöÑclient12python greeter_client.pyGreeter client received: Hello you]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂçÅÂõõÔºâ]]></title>
    <url>%2F2020%2F06%2F08%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Âà©Áî®SVDÁÆÄÂåñÊï∞ÊçÆÂ•áÂºÇÂÄºÂàÜËß£Ôºàsingular value decompositionÔºåSVDÔºâ SVDÁöÑÂ∫îÁî®Â•áÂºÇÂÄºÂàÜËß£ ‰ºòÁÇπÔºöÁÆÄÂåñÊï∞ÊçÆÔºåÂéªÈô§Âô™Â£∞ÔºåÊèêÈ´òÁÆóÊ≥ïÁöÑÁªìÊûú Áº∫ÁÇπÔºöÊï∞ÊçÆÁöÑËΩ¨Êç¢ÂèØËÉΩÈöæ‰ª•ÁêÜËß£ ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÊï∞ÊçÆ Âà©Áî®SVDÂÆûÁé∞ÔºåÊàë‰ª¨ËÉΩÂ§üÁî®Â∞èÂæóÂ§öÁöÑÊï∞ÊçÆÈõÜÊù•Ë°®Á§∫ÂéüÂßãÊï∞ÊçÆÈõÜ„ÄÇËøôÊ†∑ÂÅöÔºåÂÆûÈôÖ‰∏äÊòØÂéªÈô§Âô™Â£∞ÂíåÂÜó‰Ωô‰ø°ÊÅØ„ÄÇ ÈöêÊÄßËØ≠‰πâÁ¥¢ÂºïSVDÁöÑÂ∫îÁî®‰πã‰∏ÄÂ∞±ÊòØ‰ø°ÊÅØÊ£ÄÁ¥¢„ÄÇÊàë‰ª¨Áß∞Âà©Áî®SVDÁöÑÊñπÊ≥ï‰∏∫ÈöêÊÄßËØ≠‰πâÁ¥¢ÂºïÔºàLatent Semantic IndexingÔºåLSIÔºâ„ÄÇ Âú®LSI‰∏≠Ôºå‰∏Ä‰∏™Áü©ÈòµÊòØÁî±ÊñáÊ°£ÂíåËØçËØ≠ÁªÑÊàêÁöÑ„ÄÇÂΩìÊàë‰ª¨Âú®ËØ•Áü©Èòµ‰∏äÂ∫îÁî®SVDÊó∂ÔºåÂ∞±‰ºöÊûÑÂª∫Âá∫Â§ö‰∏™Â•áÂºÇÂÄº„ÄÇËøô‰∫õÂ•áÂºÇÂÄº‰ª£Ë°®‰∫ÜÊñáÊ°£‰∏≠ÁöÑÊ¶ÇÂøµÊàñ‰∏ªÈ¢òÔºåËøô‰∏ÄÁâπÁÇπÂèØ‰ª•Áî®‰∫éÊõ¥È´òÊïàÁöÑÊñáÊ°£ÊêúÁ¥¢„ÄÇÂú®ËØçËØ≠ÊãºÂÜôÈîôËØØÊó∂ÔºåÂè™Âü∫‰∫éËØçËØ≠Â≠òÂú®‰∏éÂê¶ÁöÑÁÆÄÂçïÊêúÁ¥¢ÊñπÊ≥ï‰ºöÈÅáÂà∞ÈóÆÈ¢ò„ÄÇÁÆÄÂçïÊêúÁ¥¢ÁöÑÂè¶‰∏Ä‰∏™ÈóÆÈ¢òÂ∞±ÊòØÂêå‰πâËØçÁöÑ‰ΩøÁî®„ÄÇ Êé®ËçêÁ≥ªÁªüSVDÁöÑÂè¶‰∏Ä‰∏™Â∫îÁî®Â∞±ÊòØÊé®ËçêÁ≥ªÁªü„ÄÇÁÆÄÂçïÁâàÊú¨ÁöÑÊé®ËçêÁ≥ªÁªüËÉΩÂ§üËÆ°ÁÆóÈ°πÊàñ‰∫∫‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÇÊõ¥ÂÖàËøõÁöÑÊñπÊ≥ïÂàôÂÖàÂà©Áî®SVD‰ªéÊï∞ÊçÆ‰∏≠ÊûÑÂª∫‰∏Ä‰∏™‰∏ªÈ¢òÁ©∫Èó¥ÔºåÁÑ∂ÂêéÂÜçÂÜçËØ•Á©∫Èó¥‰∏ãËÆ°ÁÆóÁõ∏‰ººÂ∫¶„ÄÇ Áü©ÈòµÂàÜËß£SVDÊòØÁü©ÈòµÂàÜËß£ÁöÑ‰∏ÄÁßçÁ±ªÂûãÔºåÁü©ÈòµÂàÜËß£ÊòØÂ∞ÜÊï∞ÊçÆÁü©ÈòµÂàÜËß£‰∏∫Â§ö‰∏™Áã¨Á´ãÈÉ®ÂàÜÁöÑËøáÁ®ã„ÄÇSVDÂ∞ÜÂéüÂßãÁöÑÊï∞ÊçÆÈõÜÁü©ÈòµDataÂàÜËß£Êàê‰∏â‰∏™Áü©Èòµ$U,\Sigma,V^T$„ÄÇÂ¶ÇÊûúÂéüÂßãÁü©ÈòµDataÊòØmË°ånÂàóÔºåÈÇ£‰πà$U,\Sigma,V^T$ÂàÜÂà´ÊòØmË°åmÂàóÔºåmË°ånÂàóÔºånË°ånÂàó„ÄÇ‰∏äËø∞ËøáÁ®ãÂèØ‰ª•ÂÜôÊàê‰∏ãÈù¢ÁªìÊûúÔºö $$Data_{m√ón}=U_{m√óm}\Sigma_{m√ón}V^T_{n√ón}$$‰∏äËø∞ÂàÜËß£‰∏≠‰ºöÊûÑÂª∫‰∏Ä‰∏™Áü©Èòµ$\Sigma$ÔºåËØ•Áü©ÈòµÂè™ÊúâÂØπËßíÂÖÉÁ¥†ÔºåÂÖ∂‰ªñÂÖÉÁ¥†Âùá‰∏∫0„ÄÇÂè¶‰∏Ä‰∏™ÊÉØ‰æãÂ∞±ÊòØ$\Sigma$ÁöÑÂØπËßíÂÖÉÁ¥†ÊòØ‰ªéÂ§ßÂà∞Â∞èÊéíÂàóÁöÑ„ÄÇËøô‰∫õÂØπËßíÂÖÉÁ¥†Áß∞‰∏∫Â•áÂºÇÂÄºÔºàSingular ValueÔºâÔºåÂÆÉ‰ª¨ÂØπÂ∫î‰∫ÜÂéüÂßãÊï∞ÊçÆÁü©ÈòµDataÁöÑÂ•áÂºÇÂÄº„ÄÇÂ•áÂºÇÂÄºÂíåÁâπÂæÅÂÄºÊòØÊúâÂÖ≥Á≥ªÁöÑÔºåËøôÈáåÁöÑÂ•áÂºÇÂÄºÂ∞±ÊòØÁü©Èòµ$Data*Data^T$ÁâπÂæÅÂÄºÁöÑÂπ≥ÊñπÊ†π„ÄÇ Âà©Áî®PythonÂÆûÁé∞SVDÂú®numpy‰∏≠Êèê‰æõ‰∫ÜsvdÁöÑÂÆûÁé∞123from numpy import *U, Sigma, VT = linalg.svd([[1, 1], [7, 7]]) 1U array([[-0.14142136, -0.98994949], [-0.98994949, 0.14142136]]) 1Sigma array([10., 0.]) 1VT array([[-0.70710678, -0.70710678], [-0.70710678, 0.70710678]]) Ê≥®ÊÑèÂà∞ÔºåÁü©ÈòµSigma‰ª•Ë°åÂêëÈáèarray([10., 0.])ËøîÂõûÔºåËÄåÈùûÂ¶Ç‰∏ãÁü©Èòµ array([[10, 0], [ 0, 0]]) ËøôÊòØÁî±‰∫éÁü©ÈòµÂ§ÑÁêÜÂØπËßíÂÖÉÁ¥†ÂÖ∂‰ªñÂùá‰∏∫0ÔºåÂõ†Ê≠§ËøôÁßç‰ªÖËøîÂõûÂØπËßíÂÖÉÁ¥†ÁöÑÊñπÂºèËÉΩËäÇÁúÅÁ©∫Èó¥ÔºåÊàë‰ª¨ÈúÄË¶ÅÁü•ÈÅìSigmaÊòØ‰∏Ä‰∏™Áü©Èòµ„ÄÇ ÊûÑÂª∫‰ª•‰∏ãÁü©Èòµ 12345678def loadExData(): return[[0, 0, 0, 2, 2], [0, 0, 0, 3, 3], [0, 0, 0, 1, 1], [1, 1, 1, 0, 0], [2, 2, 2, 0, 0], [5, 5, 5, 0, 0], [1, 1, 1, 0, 0]] 1Data = loadExData() 1U, Sigma, VT = linalg.svd(Data) 1Sigma array([9.64365076e+00, 5.29150262e+00, 7.40623935e-16, 4.05103551e-16, 2.21838243e-32]) Ââç‰∏â‰∏™Êï∞ÂÄºÊØîÂÖ∂‰ªñÂÄºÂ§ß‰∫ÜÂæàÂ§öÔºå‰∫éÊòØÊàë‰ª¨ÂèØ‰ª•Â∞ÜÊúÄÂêé‰∏§‰∏™Êï∞ÂÄºÂéªÊéâ‰∫Ü„ÄÇ Êé•‰∏ãÊù•Êàë‰ª¨ÁöÑÂéüÂßãÊï∞ÊçÆÈõÜÂ∞±ÂèØ‰ª•Áî®Â¶Ç‰∏ãÁªìÊûúÊù•Ëøë‰ºº $$Data_{m√ón}‚âàU_{m√ó3}\Sigma_{3√ó3}V^T_{3√ón}$$ SVDÁ§∫ÊÑèÂõæ„ÄÇÁü©ÈòµDataË¢´ÂàÜËß£„ÄÇÊµÖÁÅ∞Ëâ≤Âå∫ÂüüÊòØÂéüÂßãÊï∞ÊçÆÔºåÊ∑±ÁÅ∞Ëâ≤Âå∫ÂüüÊòØÁü©ÈòµËøë‰ººËÆ°ÁÆó‰ªÖÈúÄÁöÑÊï∞ÊçÆ Êàë‰ª¨ËØïÂõæÈáçÊûÑÂéüÂßãÁü©ÈòµÔºåÈ¶ñÂÖàÊûÑÂª∫‰∏Ä‰∏™3√ó3ÁöÑÁü©ÈòµSig3 123Sig3 = mat([[Sigma[0], 0, 0], [0, Sigma[1], 0], [0, 0, Sigma[2]]]) Êé•‰∏ãÊù•ÈáçÊûÑÂéüÂßãÁü©ÈòµÁöÑËøë‰ººÁü©Èòµ„ÄÇÁî±‰∫éSig3‰ªÖ‰∏∫3√ó3ÁöÑÁü©ÈòµÔºåÂõ†ËÄåÊàë‰ª¨Âè™ÈúÄË¶Å‰ΩøÁî®Áü©ÈòµUÁöÑÂâç3ÂàóÂíå$V^T$ÁöÑÂâç3Ë°å„ÄÇ12data = U[:, :3]*Sig3*VT[:3, :]data.astype('int') matrix([[0, 0, 0, 2, 2], [0, 0, 0, 3, 3], [0, 0, 0, 1, 1], [1, 1, 1, 0, 0], [2, 2, 2, 0, 0], [5, 5, 5, 0, 0], [1, 1, 1, 0, 0]]) 1Data [[0, 0, 0, 2, 2], [0, 0, 0, 3, 3], [0, 0, 0, 1, 1], [1, 1, 1, 0, 0], [2, 2, 2, 0, 0], [5, 5, 5, 0, 0], [1, 1, 1, 0, 0]] ÈÄöËøáSVDÊàë‰ª¨ÂèØ‰ª•Áî®‰∏Ä‰∏™Â∞èÂæàÂ§öÁöÑÁü©ÈòµÊù•Ë°®Á§∫‰∏Ä‰∏™Â§ßÁü©Èòµ„ÄÇ Âü∫‰∫éÂçèÂêåËøáÊª§ÁöÑÊé®ËçêÂºïÊìéÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊ¨ßÊ∞èË∑ùÁ¶ª ÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥Á≥ªÊï∞Ôºàpearson correlationÔºâ ‰ΩôÂº¶Áõ∏‰ººÂ∫¶Ôºàcosine similarityÔºâ Áõ∏‰ººÂ∫¶ËÆ°ÁÆó123456789101112131415from numpy import *from numpy import linalg as ladef eulidSim(inA, inB): return 1.0/(1.0+la.norm(inA - inB))def pearsSim(inA, inB): if len(inA) &lt; 3: return 1.0 return 0.5+0.5*corrcoef(inA, inB, rowvar=0)[0][1]def cosSim(inA, inB): num = float(inA.T * inB) denom = la.norm(inA) * la.norm(inB) return 0.5+0.5*(num/denom) ÊµãËØï‰∏Ä‰∏ãËøô‰∏â‰∏™ÂáΩÊï∞1myMat = mat(loadExData()) Ê¨ßÊ∞èË∑ùÁ¶ªÔºö1ecludSim(myMat[:, 0], myMat[:, 4]) 0.12973190755680383 1ecludSim(myMat[:, 0], myMat[:, 0]) 1.0 ‰ΩôÂº¶Áõ∏‰ººÂ∫¶1cosSim(myMat[:, 0], myMat[:, 4]) 0.5 1cosSim(myMat[:, 0], myMat[:, 0]) 1.0 ÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥Á≥ªÊï∞1pearsSim(myMat[:, 0], myMat[:, 4]) 0.20596538173840329 1pearsSim(myMat[:, 0], myMat[:, 0]) 1.0 ‰∏äÈù¢ÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÈÉΩÊòØÂÅáËÆæÊï∞ÊçÆÈááÁî®‰∫ÜÂàóÂêëÈáèÊñπÂºèËøõË°åË°®Á§∫„ÄÇÂ¶ÇÊûúÂà©Áî®‰∏äËø∞ÂáΩÊï∞Êù•ËÆ°ÁÆó‰∏§‰∏™ÂêëÈáèÁöÑÁõ∏‰ººÂ∫¶Â∞±‰ºöÈÅáÂà∞ÈóÆÈ¢òÔºàÊàë‰ª¨ÂæàÂÆπÊòìÂØπ‰∏äËø∞ÂáΩÊï∞ËøõË°å‰øÆÊîπ‰ª•ËÆ°ÁÆóË°åÂêëÈáè‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶Ôºâ„ÄÇËøôÈáåÈááÁî®ÂàóÂêëÈáèÁöÑË°®Á§∫ÊñπÊ≥ïÔºåÊöóÁ§∫ÁùÄÊàë‰ª¨Â∞ÜÂà©Áî®Âü∫‰∫éÁâ©ÂìÅÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ï„ÄÇ Âü∫‰∫éÁâ©ÂìÅÁöÑÁõ∏‰ººÂ∫¶ËøòÊòØÂü∫‰∫éÁî®Êà∑ÁöÑÁõ∏‰ººÂ∫¶Êàë‰ª¨ËÆ°ÁÆó‰∫Ü‰∏§‰∏™È§êÈ¶ÜËèúËÇ¥‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåËøôÁß∞‰∏∫Âü∫‰∫éÁâ©ÂìÅÔºàitem-basedÔºâÁöÑÁõ∏‰ººÂ∫¶„ÄÇÂè¶‰∏ÄÁßçËÆ°ÁÆóÁî®Êà∑Ë∑ùÁ¶ªÁöÑÊñπÊ≥ïÁß∞‰∏∫Âü∫‰∫éÁî®Êà∑Ôºàuser-basedÔºâ„ÄÇÂü∫‰∫éÁâ©ÂìÅÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÁöÑÊó∂Èó¥‰ºöÈöèÁùÄÁâ©ÂìÅÊï∞ÈáèÁöÑÂ¢ûÂä†ËÄåÂ¢ûÂä†ÔºåÂü∫‰∫éÁî®Êà∑ÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊó∂Èó¥Âàô‰ºöÈöèÁî®Êà∑Êï∞ÈáèÁöÑÂ¢ûÂä†ËÄåÂ¢ûÂä†„ÄÇ Êé®ËçêÂºïÊìéÁöÑËØÑ‰ª∑ÈÄöÂ∏∏Áî®‰∫éÊé®ËçêÂºïÊìéÁöÑËØÑ‰ª∑ÊåáÊ†áÁß∞‰∏∫ÊúÄÂ∞èÂùáÊñπÊ†πËØØÂ∑ÆÔºàRoot Mean Squared ErrorÔºåRMSEÔºâÁöÑÊåáÊ†áÔºåÂÆÉÈ¶ñÂÖàËÆ°ÁÆóÂùáÊñπËØØÂ∑ÆÁöÑÂπ≥ÂùáÂÄºÂÜçÂèñÂÖ∂Âπ≥ÊñπÊ†π„ÄÇ ÂÆû‰æãÔºöÈ§êÈ¶ÜËèúËÇ¥Êé®ËçêÂºïÊìéÊé®ËçêÊú™Â∞ùËøáÁöÑËèúËÇ¥ ÂØªÊâæÁî®Êà∑Ê≤°ÊúâËØÑÁ∫ßÁöÑËèúËÇ¥ÔºåÂç≥Âú®Áî®Êà∑Áâ©ÂìÅÁü©Èòµ‰∏≠ÁöÑ0ÂÄº Âú®Áî®Êà∑Ê≤°ÊúâËØÑÁ∫ßÁöÑÊâÄÊúâÁâ©ÂìÅ‰∏≠ÔºåÂØπÊØè‰∏™Áâ©ÂìÅÈ¢ÑËÆ°‰∏Ä‰∏™ÂèØËÉΩÁöÑËØÑÁ∫ßÂàÜÊï∞„ÄÇÔºàÊàë‰ª¨ËÆ§‰∏∫Áî®Êà∑ÂèØËÉΩÂØπÁâ©ÂìÅÁöÑÊâìÂàÜÔºâ ÂØπËøô‰∫õÁâ©ÂìÅÁöÑËØÑÂàÜ‰ªéÈ´òÂà∞‰ΩéÊéíÂ∫èÔºåËøîÂõûÂâçN‰∏™Áâ©ÂìÅ123456789101112131415161718192021222324252627282930def standEst(dataMat, user, simMeas, item): n = shape(dataMat)[1] simTotal = 0.0 ratSimTotal = 0.0 for j in range(n): userRating = dataMat[user, j] if userRating == 0: continue overLap = nonzero(logical_and(dataMat[:,item].A&gt;0, dataMat[:,j].A&gt;0))[0] if len(overLap) == 0: similarity = 0 else: similarity = simMeas(dataMat[overLap,item], dataMat[overLap,j]) print('the %d and %d similarity is: %f' % (item, j, similarity)) simTotal += similarity ratSimTotal += similarity * userRating if simTotal == 0: return 0 else: return ratSimTotal/simTotaldef recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst): unratedItems = nonzero(dataMat[user, :].A==0)[1] if len(unratedItems) == 0: return 'you rated everything' itemScores = [] for item in unratedItems: estimatedScore = estMethod(dataMat, user, simMeas, item) itemScores.append((item, estimatedScore)) return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N] Á¨¨‰∏Ä‰∏™ÂáΩÊï∞standEst()Áî®Êù•ËÆ°ÁÆóÁªôÂÆöÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÁöÑÊù°‰ª∂‰∏ãÔºåÁî®Êà∑ÂØπÁâ©ÂìÅÁöÑËØÑ‰º∞ÂàÜÂÄº„ÄÇÁ¨¨‰∫å‰∏™ÂáΩÊï∞recommend()‰πüÂ∞±ÊòØÊé®ËçêÂºïÊìéÔºå‰ªñ‰ºöË∞ÉÁî®standEst()ÂáΩÊï∞„ÄÇ123myMat = mat(loadExData())myMat[0, 1] = myMat[0, 0] = myMat[1, 0] = myMat[2, 0] = 4myMat[3, 3] = 2 1myMat matrix([[4, 4, 0, 2, 2], [4, 0, 0, 3, 3], [4, 0, 0, 1, 1], [1, 1, 1, 2, 0], [2, 2, 2, 0, 0], [5, 5, 5, 0, 0], [1, 1, 1, 0, 0]]) 1recommend(myMat, 2) the 1 and 0 similarity is: 1.000000 the 1 and 3 similarity is: 0.928746 the 1 and 4 similarity is: 1.000000 the 2 and 0 similarity is: 1.000000 the 2 and 3 similarity is: 1.000000 the 2 and 4 similarity is: 0.000000 [(2, 2.5), (1, 2.0243290220056256)] 1recommend(myMat, 2, simMeas=ecludSim) the 1 and 0 similarity is: 1.000000 the 1 and 3 similarity is: 0.309017 the 1 and 4 similarity is: 0.333333 the 2 and 0 similarity is: 1.000000 the 2 and 3 similarity is: 0.500000 the 2 and 4 similarity is: 0.000000 [(2, 3.0), (1, 2.8266504712098603)] 1recommend(myMat, 2, simMeas=pearsSim) the 1 and 0 similarity is: 1.000000 the 1 and 3 similarity is: 1.000000 the 1 and 4 similarity is: 1.000000 the 2 and 0 similarity is: 1.000000 the 2 and 3 similarity is: 1.000000 the 2 and 4 similarity is: 0.000000 [(2, 2.5), (1, 2.0)] Ëøô‰∏™‰æãÂ≠êÁªôÂá∫‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Âü∫‰∫éÁâ©ÂìÅÁõ∏‰ººÂ∫¶ÂíåÂ§ö‰∏™Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÊù•ËøõË°åÊé®ËçêÁöÑËøáÁ®ã„ÄÇ Âà©Áî®SVDÊèêÈ´òÊé®ËçêÊïàÊûú‰∏ãÈù¢ÊòØ‰∏Ä‰∏™Êõ¥Â§ßÁöÑÁü©Èòµ123456789101112def loadExData2(): return[[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5], [0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3], [0, 0, 0, 0, 4, 0, 0, 1, 0, 4, 0], [3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0], [5, 4, 5, 0, 0, 0, 0, 5, 5, 0, 0], [0, 0, 0, 0, 5, 0, 1, 0, 0, 5, 0], [4, 3, 4, 0, 0, 0, 0, 5, 5, 0, 1], [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4], [0, 0, 0, 2, 0, 2, 5, 0, 0, 1, 2], [0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0], [1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]] 1U, Sigma, VT = la.svd(mat(loadExData2())) 1Sigma array([15.77075346, 11.40670395, 11.03044558, 4.84639758, 3.09292055, 2.58097379, 1.00413543, 0.72817072, 0.43800353, 0.22082113, 0.07367823]) È¶ñÂÖàÂØπSigma‰∏≠ÁöÑÂÄºÊ±ÇÂπ≥Êñπ1Sig2 = Sigma**2 1sum(Sig2) 541.9999999999995 Âú®ËÆ°ÁÆóÊÄªËÉΩÈáèÁöÑ90%1sum(Sig2)*0.9 487.7999999999996 ÁÑ∂ÂêéËÆ°ÁÆóÂâç‰∏§‰∏™ÂÖÉÁ¥†ÂåÖÂê´ÁöÑËÉΩÈáè1sum(Sig2[:2]) 378.8295595113579 ËØ•ÂÄº‰Ωé‰∫éÊÄªËÉΩÈáèÁöÑ90%Ôºå‰∫éÊòØËÆ°ÁÆóÂâç‰∏â‰∏™ÂÖÉÁ¥†ÊâÄÂåÖÂê´ÁöÑËÉΩÈáè1sum(Sig2[:3]) 500.50028912757926 ËØ•ÂÄºÈ´ò‰∫é90%ÔºåËøôÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇ‰∫éÊòØÊàë‰ª¨Â∞Ü‰∏Ä‰∏™11Áª¥ÁöÑÁü©ÈòµËΩ¨Êç¢‰∏∫‰∏Ä‰∏™3Áª¥ÁöÑÁü©ÈòµÔºå‰∏ãÈù¢ÂØπËΩ¨Êç¢ÂêéÁöÑ‰∏âÁª¥Á©∫Èó¥ÊûÑÈÄ†‰∏Ä‰∏™Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÂáΩÊï∞„ÄÇÊàë‰ª¨Âà©Áî®SVDÂ∞ÜÊâÄÊúâÁöÑËèúËÇ¥Êò†Â∞ÑÂà∞‰∏Ä‰∏™‰ΩéÁª¥Á©∫Èó¥‰∏≠Âéª„ÄÇ12345678910111213141516171819def svdEst(dataMat, user, simMeas, item): n = shape(dataMat)[1] simTotal = 0.0 ratSimTotal = 0.0 U,Sigma,VT = la.svd(dataMat) Sig4 = mat(eye(4)*Sigma[:4]) xformedItems = dataMat.T * U[:,:4] * Sig4.I for j in range(n): userRating = dataMat[user, j] if userRating == 0 or j==item: continue similarity = simMeas(xformedItems[item,:].T, xformedItems[j,:].T) print('the %d and %d similarity is: %f' % (item, j, similarity)) simTotal += similarity ratSimTotal += similarity * userRating if simTotal == 0: return 0 else: return ratSimTotal/simTotal 12myMat = mat(loadExData2())recommend(myMat, 1, estMethod=svdEst) the 0 and 3 similarity is: 0.490950 the 0 and 5 similarity is: 0.484274 the 0 and 10 similarity is: 0.512755 the 1 and 3 similarity is: 0.491294 the 1 and 5 similarity is: 0.481516 the 1 and 10 similarity is: 0.509709 the 2 and 3 similarity is: 0.491573 the 2 and 5 similarity is: 0.482346 the 2 and 10 similarity is: 0.510584 the 4 and 3 similarity is: 0.450495 the 4 and 5 similarity is: 0.506795 the 4 and 10 similarity is: 0.512896 the 6 and 3 similarity is: 0.743699 the 6 and 5 similarity is: 0.468366 the 6 and 10 similarity is: 0.439465 the 7 and 3 similarity is: 0.482175 the 7 and 5 similarity is: 0.494716 the 7 and 10 similarity is: 0.524970 the 8 and 3 similarity is: 0.491307 the 8 and 5 similarity is: 0.491228 the 8 and 10 similarity is: 0.520290 the 9 and 3 similarity is: 0.522379 the 9 and 5 similarity is: 0.496130 the 9 and 10 similarity is: 0.493617 [(4, 3.344714938469228), (7, 3.329402072452697), (9, 3.328100876390069)] Â∞ùËØïÂè¶‰∏ÄÁßçÊñπÊ≥ï1recommend(myMat, 1, simMeas=pearsSim, estMethod=svdEst) the 0 and 3 similarity is: 0.341942 the 0 and 5 similarity is: 0.124132 the 0 and 10 similarity is: 0.116698 the 1 and 3 similarity is: 0.345560 the 1 and 5 similarity is: 0.126456 the 1 and 10 similarity is: 0.118892 the 2 and 3 similarity is: 0.345149 the 2 and 5 similarity is: 0.126190 the 2 and 10 similarity is: 0.118640 the 4 and 3 similarity is: 0.450126 the 4 and 5 similarity is: 0.528504 the 4 and 10 similarity is: 0.544647 the 6 and 3 similarity is: 0.923822 the 6 and 5 similarity is: 0.724840 the 6 and 10 similarity is: 0.710896 the 7 and 3 similarity is: 0.319482 the 7 and 5 similarity is: 0.118324 the 7 and 10 similarity is: 0.113370 the 8 and 3 similarity is: 0.334910 the 8 and 5 similarity is: 0.119673 the 8 and 10 similarity is: 0.112497 the 9 and 3 similarity is: 0.566918 the 9 and 5 similarity is: 0.590049 the 9 and 10 similarity is: 0.602380 [(4, 3.346952186702173), (9, 3.3353796573274694), (6, 3.3071930278130366)] ÂÆû‰æãÔºöÂü∫‰∫éSVDÁöÑÂõæÂÉèÂéãÁº©Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®SVDÊù•ÂØπÊï∞ÊçÆÈôçÁª¥Ôºå‰ªéËÄåÂÆûÁé∞ÂõæÂÉèÁöÑÂéãÁº©„ÄÇ1234567891011121314151617181920212223242526def printMat(inMat, thresh=0.8): for i in range(32): for k in range(32): if float(inMat[i, k] &gt; thresh): print(1, end='') else: print(0, end='') print('')def imgCompress(numSV=3, thresh=0.8): myl = [] for line in open('MLiA_SourceCode/Ch14/0_5.txt').readlines(): newRow = [] for i in range(32): newRow.append(int(line[i])) myl.append(newRow) myMat = mat(myl) print('***originam matrix*****') printMat(myMat, thresh) U, Sigma, VT = la.svd(myMat) SigRecon = mat(zeros((numSV, numSV))) for k in range(numSV): SigRecon[k, k] = Sigma[k] reconMat = U[:, :numSV] * SigRecon*VT[:numSV, :] print("****reconstructed matrix using %d singular values******" % numSV) printMat(reconMat, thresh) 1imgCompress(2) ***originam matrix***** 00000000000000110000000000000000 00000000000011111100000000000000 00000000000111111110000000000000 00000000001111111111000000000000 00000000111111111111100000000000 00000001111111111111110000000000 00000000111111111111111000000000 00000000111111100001111100000000 00000001111111000001111100000000 00000011111100000000111100000000 00000011111100000000111110000000 00000011111100000000011110000000 00000011111100000000011110000000 00000001111110000000001111000000 00000011111110000000001111000000 00000011111100000000001111000000 00000001111100000000001111000000 00000011111100000000001111000000 00000001111100000000001111000000 00000001111100000000011111000000 00000000111110000000001111100000 00000000111110000000001111100000 00000000111110000000001111100000 00000000111110000000011111000000 00000000111110000000111111000000 00000000111111000001111110000000 00000000011111111111111110000000 00000000001111111111111110000000 00000000001111111111111110000000 00000000000111111111111000000000 00000000000011111111110000000000 00000000000000111111000000000000 ****reconstructed matrix using 2 singular values****** 00000000000000000000000000000000 00000000000000000000000000000000 00000000000001111100000000000000 00000000000011111111000000000000 00000000000111111111100000000000 00000000001111111111110000000000 00000000001111111111110000000000 00000000011110000000001000000000 00000000111100000000001100000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001110000000 00000000111100000000001100000000 00000000001111111111111000000000 00000000001111111111110000000000 00000000001111111111110000000000 00000000000011111111100000000000 00000000000011111111000000000000 00000000000000000000000000000000 ÂèØ‰ª•ÁúãÂà∞ÔºåÂè™ÈúÄË¶Å‰∏§‰∏™Â•áÂºÇÂÄºÂ∞±ËÉΩÁõ∏ÂΩìÁ≤æÁ°ÆÁöÑÂØπÂõæÂÉèÂÆûÁé∞ÈáçÊûÑ„ÄÇ ÊÄªÁªìSVDÊòØ‰∏ÄÁßçÂº∫Â§ßÁöÑÈôçÁª¥Â∑•ÂÖ∑ÔºåÊàë‰ª¨ÂèØ‰ª•Âà©Áî®SVDÊù•ÈÄºËøëÁü©ÈòµÂπ∂‰ªé‰∏≠ÊèêÂèñÈáçË¶ÅÁâπÂæÅ„ÄÇÈÄöËøá‰øùÁïôÁü©Èòµ80%~90%ÁöÑËÉΩÈáèÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞ÈáçË¶ÅÁöÑÁâπÂæÅÂπ∂ÂéªÊéâÂô™Â£∞„ÄÇSVDÂ∑≤ÁªèËøêÁî®Âà∞‰∫ÜÂ§ö‰∏™Â∫îÁî®‰∏≠ÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÊàêÂäüÁöÑÊ°à‰æãÂ∞±ÊòØÊé®ËçêÂºïÊìé„ÄÇ Êé®ËçêÂºïÊìéÂ∞ÜÁâ©ÂìÅÊé®ËçêÁªôÁî®Êà∑ÔºåÂçèË∞ÉËøáÊª§ÂàôÊòØ‰∏ÄÁßçÂü∫‰∫éÁî®Êà∑ÂñúÂ•ΩÊàñË°å‰∏∫Êï∞ÊçÆÁöÑÊé®ËçêÂÆûÁé∞ÊñπÊ≥ï„ÄÇÂçèË∞ÉËøáÊª§ÁöÑÊ†∏ÂøÉÊòØÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÔºåÂæàÂ§öÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÈÉΩÂèØ‰ª•Áî®ËÆ°ÁÆóÁâ©ÂìÅÊàñÁî®Êà∑‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÇÈÄöËøáÈôç‰ΩéÁ©∫Èó¥‰∏ãËÆ°ÁÆóÁõ∏‰ººÂ∫¶ÔºåSVDÊèêÈ´ò‰∫ÜÊé®ËçêÂºïÊìéÁöÑÊïàÊûú„ÄÇ Âú®Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äÔºåSVDÁöÑËÆ°ÁÆóÂíåÊé®ËçêÂèØËÉΩÊòØ‰∏Ä‰∏™ÂæàÂõ∞ÈöæÁöÑÂ∑•Á®ãÈóÆÈ¢ò„ÄÇÈÄöËøáÁ¶ªÁ∫øÊñπÂºèÊù•ËøõË°åÂàÜËß£ÂíåÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÔºåÊòØ‰∏ÄÁßçÂáèÂ∞ëÂÜó‰ΩôËÆ°ÁÆóÂíåÊé®ËçêÊâÄÈúÄÊó∂Èó¥ÁöÑÂäûÊ≥ï„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂçÅ‰∏âÔºâ]]></title>
    <url>%2F2020%2F06%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Âà©Áî®PCAÊù•ÁÆÄÂåñÊï∞ÊçÆÈôçÁª¥Ôºàdimensionality reductionÔºâÔºåÊï∞ÊçÆÂú®‰ΩéÁ∫¨Â∫¶Êó∂Êõ¥ÂÆπÊòìÂ§ÑÁêÜ„ÄÇ ÈôçÁª¥ÊäÄÊúØÊï∞ÊçÆËøõË°åÁÆÄÂåñÁöÑÂéüÂõ†Ôºö ‰ΩøÂæóÊï∞ÊçÆÈõÜÊõ¥ÂÆπÊòì‰ΩøÁî® Èôç‰ΩéÂæàÂ§öÁÆóÊ≥ïÁöÑËÆ°ÁÆóÂºÄÈîÄ ÂéªÈô§Âô™Â£∞ ‰ΩøÂæóÁªìÊûúÊòìÊáÇ ÈôçÁª¥ÊñπÊ≥ïÔºå‰∏ªÊàêÂàÜÂàÜÊûêÔºàPrincipal Component AnalysisÔºåPCAÔºâÔºåÊï∞ÊçÆ‰ªéÂéüÊù•ÁöÑÂùêÊ†áÁ≥ªËΩ¨Êç¢Âà∞Êñ∞ÁöÑÂùêÊ†áÁ≥ªÔºåÊñ∞ÁöÑÂùêÊ†áÁ≥ªÁöÑÈÄâÊã©Áî±Êï∞ÊçÆÊú¨Ë∫´ÂÜ≥ÂÆöÁöÑ„ÄÇÁ¨¨‰∏Ä‰∏™Êñ∞ÂùêÊ†áËΩ¥ÈÄâÊã©ÁöÑÊòØÂéüÂßãÊï∞ÊçÆ‰∏≠ÊñπÂ∑ÆÊúÄÂ§ßÁöÑÊñπÂêëÔºåÁ¨¨‰∫å‰∏™Êñ∞ÂùêÊ†áËΩ¥ÁöÑÈÄâÊã©ÂíåÁ¨¨‰∏Ä‰∏™ÂùêÊ†áËΩ¥Ê≠£‰∫§‰∏îÂÖ∑ÊúâÊúÄÂ§ßÊñπÂ∑ÆÁöÑÊñπÂêë„ÄÇËØ•ËøáÁ®ã‰∏ÄÁõ¥ÈáçÂ§çÔºåÈáçÂ§çÊ¨°Êï∞‰∏∫ÂéüÂßãÊï∞ÊçÆ‰∏≠ÁâπÂæÅÁöÑÊï∞ÁõÆ„ÄÇ Âè¶‰∏ÄÁßçÈôçÁª¥ÊäÄÊúØÊòØÔºåÂõ†Â≠êÂàÜÊûêÔºàFactor AnalysisÔºâÔºåÂú®Âõ†Â≠êÂàÜÊûê‰∏≠ÔºåÊàë‰ª¨ÂÅáËÆæÂú®ËßÇÂØüÊï∞ÊçÆÁöÑÁîüÊàê‰∏≠Êúâ‰∏Ä‰∫õËßÇÂØü‰∏çÂà∞ÁöÑÈöêÂèòÈáèÔºàlatent variableÔºâ„ÄÇÂÅáËÆæËßÇÂØüÊï∞ÊçÆÊòØËøô‰∫õÈöêÂèòÈáèÂíåÊüê‰∫õÂô™Â£∞ÁöÑÁ∫øÊÄßÁªÑÂêà„ÄÇÈÇ£‰πàÈöêÂèòÈáèÁöÑÊï∞ÊçÆÂèØËÉΩÊØîËßÇÂØüÊï∞ÊçÆÁöÑÊï∞ÁõÆÂ∞ëÔºå‰πüÂ∞±ÊòØËØ¥ÈÄöËøáÊâæÂà∞ÈöêÂèòÈáèÂ∞±ÂèØ‰ª•ÂÆûÁé∞Êï∞ÊçÆÁöÑÈôçÁª¥„ÄÇ ËøòÊúâ‰∏ÄÁßçÈôçÁª¥ÊäÄÊúØÂ∞±ÊòØÁã¨Á´ãÊàêÂàÜÂàÜÊûêÔºàIndependent Component AnalysisÔºåICAÔºâÔºåICAÂÅáËÆæÊï∞ÊçÆÊòØ‰ªéN‰∏™Êï∞ÊçÆÊ∫êÁîüÊàêÁöÑÔºåËøô‰∏ÄÁÇπÂíåÂõ†Â≠êÂàÜÊûêÊúâ‰∫õÁ±ª‰ºº„ÄÇÂÅáËÆæÊï∞ÊçÆ‰∏∫Â§ö‰∏™Êï∞ÊçÆÊ∫êÁöÑÊ∑∑ÂêàËßÇÂØüÁªìÊûúÔºåËøô‰∫õÊï∞ÊçÆÊ∫ê‰πãÈó¥Âú®ÁªüËÆ°‰∏äÊòØÁõ∏‰∫íÁã¨Á´ãÁöÑÔºåËÄåÂú®PCA‰∏≠ÂÅáËÆæÊï∞ÊçÆÊòØ‰∏çÁõ∏ÂÖ≥ÁöÑ„ÄÇÂêåÂõ†Â≠êÂàÜÊûê‰∏ÄÊ†∑ÔºåÂ¶ÇÊûúÊï∞ÊçÆÊ∫êÁöÑÊï∞ÁõÆÂ∞ë‰∫éËßÇÂØüÊï∞ÊçÆÁöÑÊï∞ÁõÆÔºåÂàôÂèØ‰ª•ÂÆûÁé∞ÈôçÁª¥ËøáÁ®ã„ÄÇ PCA‰∏ªÊàêÂàÜÂàÜÊûê ‰ºòÁÇπÔºöÈôç‰ΩéÊï∞ÊçÆÁöÑÂ§çÊùÇÊÄßÔºåËØÜÂà´ÊúÄÈáçË¶ÅÁöÑÂ§ö‰∏™ÁâπÂæÅ Áº∫ÁÇπÔºö‰∏ç‰∏ÄÂÆöÈúÄË¶ÅÔºå‰∏îÂèØËÉΩÊçüÂ§±ÊúâÁî®ÁöÑ‰ø°ÊÅØ ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÊï∞ÊçÆ Âú®Numpy‰∏≠ÂÆûÁé∞PCA‰º™‰ª£Á†ÅÂ§ßËá¥Â¶Ç‰∏ãÔºö ÂéªÈô§Âπ≥ÂùáÂÄº ËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©Èòµ ËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©ÈòµÁöÑÁâπÂæÅÂÄºÂíåÁâπÂæÅÂêëÈáè Â∞ÜÁâπÂæÅÂÄº‰ªéÂ§ßÂà∞Â∞èÊéíÂ∫è ‰øùÁïôÊúÄ‰∏äÈù¢ÁöÑN‰∏™ÁâπÂæÅÂêëÈáè Â∞ÜÊï∞ÊçÆËΩ¨Êç¢Âà∞‰∏äËø∞N‰∏™ÁâπÂæÅÂêëÈáèÊûÑÂª∫ÁöÑÁ©∫Èó¥‰∏≠ 12345678910111213141516171819from numpy import *def loadDataSet(fileName, delim='\t'): fr = open(fileName) stringArr = [line.strip().split(delim) for line in fr.readlines()] datArr = [list(map(float, line)) for line in stringArr] return mat(datArr)def pca(dataMat, topNfeat=9999999): meanVals = mean(dataMat, axis=0) meanRemoved = dataMat - meanVals # ÂéªÂπ≥ÂùáÂÄº covMat = cov(meanRemoved, rowvar=0) eigVals, eigVects = linalg.eig(mat(covMat)) eigValInd = argsort(eigVals) # ‰ªéÂ∞èÂà∞Â§ßÊéíÂ∫è eigValInd = eigValInd[: -(topNfeat+1): -1] # ÂéªÊéâÂ§ö‰ΩôÁöÑ redEigVects = eigVects[:, eigValInd] lowDDataMat = meanRemoved * redEigVects # Â∞ÜÊï∞ÊçÆËΩ¨Êç¢‰∏∫Êñ∞ÁöÑÁª¥Â∫¶ reconMat = (lowDDataMat * redEigVects.T) + meanVals return lowDDataMat, reconMat 1dataMat = loadDataSet('MLiA_SourceCode/Ch13/testSet.txt') 1lowDMat, reconMat = pca(dataMat, 1) 1shape(lowDMat) (1000, 1) Â∞ÜÂéüÂßãÊï∞ÊçÆÂíåÈôçÁª¥ÂêéÁöÑÊï∞ÊçÆÁªòÂà∂Âá∫Êù• 12345678import matplotlibimport matplotlib.pyplot as pltfig = plt.figure()ax = fig.add_subplot(111)ax.scatter(dataMat[:, 0].flatten().A[0], dataMat[:, 1].flatten().A[0], marker='^', s=90)ax.scatter(reconMat[:, 0].flatten().A[0], reconMat[:, 1].flatten().A[0], marker='o', s=90)plt.show() ÂÆû‰æãÔºöÂà©Áî®PCAÂØπÂçäÂØº‰ΩìÂà∂ÈÄ†Êï∞ÊçÆÈôçÁª¥Êï∞ÊçÆÊã•Êúâ590‰∏™ÁâπÂæÅÔºåÂåÖÂê´ËÆ∏Â§öÁöÑÁº∫Â§±ÂÄºÔºåËøô‰∫õÁº∫Â§±ÂÄºÊòØ‰ª•NaNÊ†áËØÜÁöÑ„ÄÇÁî®Âπ≥ÂùáÂÄºÊù•‰ª£ÊõøÁº∫Â§±ÂÄº„ÄÇ 1234567def replaceNanWithMean(): datMat = loadDataSet('MLiA_SourceCode/Ch13/secom.data', ' ') numFeat = shape(datMat)[1] for i in range(numFeat): meanVal = mean(datMat[nonzero(~isnan(datMat[:,i].A))[0],i]) # ËÆ°ÁÆóÊâÄÊúâÈùûNanÁöÑÂπ≥ÂùáÂÄº datMat[nonzero(isnan(datMat[:,i].A))[0],i] = meanVal # Â∞ÜÊâÄÊúâÁöÑNanËÆæÁΩÆ‰∏∫Âπ≥ÂùáÂÄº return datMat 1dataMat = replaceNanWithMean() ËßÇÂØüpca()ÁöÑÂ∑•‰ΩúËøáÁ®ã È¶ñÂÖàÊòØÂéªÈô§ÂùáÂÄº 12meanVals = mean(dataMat, axis=0)meanRemoved = dataMat - meanVals ÁÑ∂ÂêéËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©ÈòµÔºö 1covMat = cov(meanRemoved, rowvar=0) ÂØπËØ•Áü©ÈòµËøõË°åÁâπÂæÅÂÄºÂàÜÊûê 1eigVals, eigVects = linalg.eig(mat(covMat)) ËßÇÂØüÁâπÂæÅÂÄºÁªìÊûú 1eigVals array([ 5.34151979e+07+0.00000000e+00j, 2.17466719e+07+0.00000000e+00j, 8.24837662e+06+0.00000000e+00j, 2.07388086e+06+0.00000000e+00j, ... ... 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j, 0.00000000e+00+0.00000000e+00j]) Êàë‰ª¨ÂèØ‰ª•ÁúãÂà∞‰∏ÄÂ†ÜÁöÑÂÄºÔºåÂèëÁé∞ÂÖ∂‰∏≠ÊúâË∂ÖËøá20%ÁöÑÁâπÂæÅÂÄºÈÉΩÊòØ0„ÄÇËøôÂ∞±ÊÑèÂë≥ÁùÄËøô‰∫õÁâπÂæÅÈÉΩÊòØÂÖ∂‰ªñÁâπÂæÅÁöÑÂâØÊú¨Ôºå‰πüÂ∞±ÊòØËØ¥Ôºå‰ªñ‰ª¨ÂèØ‰ª•ÈÄöËøáÂÖ∂‰ªñÁâπÂæÅÊù•Ë°®Á§∫ÔºåËÄåÊú¨Ë∫´Âπ∂Ê≤°ÊúâÊèê‰æõÈ¢ùÂ§ñÁöÑ‰ø°ÊÅØ„ÄÇ ÊÄªÁªìÈôçÁª¥ÊäÄÊúØ‰ΩøÂæóÊï∞ÊçÆÂèòÂæóÊõ¥Êòì‰ΩøÁî®ÔºåÂπ∂‰∏îÂÆÉ‰ª¨ÂæÄÂæÄËÉΩÂ§üÂéªÈô§Êï∞ÊçÆ‰∏≠ÁöÑÂô™Â£∞Ôºå‰ΩøÂæóÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†‰ªªÂä°Êõ¥Âä†Á≤æÁ°Æ„ÄÇÈôçÁª¥ÂæÄÂæÄ‰Ωú‰∏∫iÈ¢ÑÂ§ÑÁêÜÁöÑÊ≠•È™§ÔºåÂú®Êï∞ÊçÆÂ∫îÁî®Âà∞ÂÖ∂‰ªñÁÆóÊ≥ï‰πãÂâçÊ∏ÖÊ¥óÊï∞ÊçÆ„ÄÇÂæàÂ§öÊäÄÊúØÂèØ‰ª•Áî®‰∫éÊï∞ÊçÆÈôçÁª¥ÔºåÂú®Ëøô‰∫õÊäÄÊúØ‰∏≠ÔºåÁã¨Á´ãÊàêÂàÜÂàÜÊûêÔºåÂõ†Â≠êÂàÜÊûêÂíå‰∏ªÊàêÂàÜÂàÜÊûêÊØîËæÉÊµÅË°åÔºåÂÖ∂‰∏≠Âèà‰ª•‰∏ªÊàêÂàÜÂàÜÊûêÂ∫îÁî®ÊúÄÂπøÊ≥õ„ÄÇ PCAÂèØ‰ª•‰ªéÊï∞ÊçÆ‰∏≠ËØÜÂà´ÂÖ∂‰∏ªË¶ÅÁâπÂæÅÔºå‰ªñÊòØÈÄöËøáÊ≤øÁùÄÊï∞ÊçÆÊúÄÂ§ßÊñπÂ∑ÆÊñπÂêëÊóãËΩ¨ÂùêÊ†áËΩ¥Êù•ÂÆûÁé∞ÁöÑ„ÄÇÈÄâÊã©ÊñπÂ∑ÆÊúÄÂ§ßÁöÑÊñπÂêë‰Ωú‰∏∫Á¨¨‰∏ÄÊù°ÂùêÊ†áËΩ¥ÔºåÂêéÁª≠ÂùêÊ†áËΩ¥Âàô‰∏éÂâçÈù¢ÁöÑÂùêÊ†áËΩ¥Ê≠£‰∫§„ÄÇÂçèÊñπÂ∑ÆÁü©Èòµ‰∏äÁöÑÁâπÂæÅÂÄºÂàÜÊûêÂèØ‰ª•Áî®‰∏ÄÁ≥ªÂàóÁöÑÊ≠£‰∫§ÂùêÊ†áËΩ¥Êù•Ëé∑Âèñ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>PCA</tag>
        <tag>ÈôçÁª¥</tag>
        <tag>‰∏ªÊàêÂàÜÂàÜÊûê</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂçÅ‰∫åÔºâ]]></title>
    <url>%2F2020%2F06%2F02%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[‰ΩøÁî®FP-growthÁÆóÊ≥ïÊù•È´òÊïàÂèëÁé∞È¢ëÁπÅÈ°πÈõÜFP-growthÁÆóÊ≥ïÂè™‰ºöÂØπÊï∞ÊçÆÂ∫ìËøõË°å‰∏§Ê¨°Êâ´ÊèèÔºåËÄåAprioriÁÆóÊ≥ïÂØπ‰∫éÊØè‰∏™ÊΩúÂú®ÁöÑÈ¢ëÁπÅÈ°πÈõÜÈÉΩ‰ºöÊâ´ÊèèÊï∞ÊçÆÈõÜÂà§Êñ≠ÁªôÂÆöÊ®°ÂºèÊòØÂê¶È¢ëÁπÅÔºåÂõ†Ê≠§FP-growthÁÆóÊ≥ïÁöÑÈÄüÂ∫¶Ë¶ÅÊØîAprioriÁÆóÊ≥ïÂø´„ÄÇ FPÊ†ëÔºöÁî®‰∫éÁºñÁ†ÅÊï∞ÊçÆÈõÜÁöÑÊúâÊïàÊñπÂºèFP-growthÁÆóÊ≥ï ‰ºòÁÇπÔºö‰∏ÄËà¨Ë¶ÅÂø´‰∫éApriori Áº∫ÁÇπÔºöÂÆûÁé∞ÊØîËæÉÂõ∞ÈöæÔºåÂú®Êüê‰∫õÊï∞ÊçÆÈõÜ‰∏äÊÄßËÉΩ‰ºö‰∏ãÈôç ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊ†áÁß∞ÂûãÊï∞ÊçÆÁ±ªÂûã FP-growthÁÆóÊ≥ïÂ∞ÜÊï∞ÊçÆÂ≠òÂÇ®Âú®‰∏ÄÁßçÁß∞‰∏∫FPÊ†ëÁöÑÁ¥ßÂáëÊï∞ÊçÆÁªìÊûÑ‰∏≠„ÄÇFP‰ª£Ë°®È¢ëÁπÅÊ®°ÂºèÔºàFrequent PatternÔºâ„ÄÇ‰∏ÄÈ¢óFPÊ†ëÁúã‰∏äÂéª‰∏éËÆ°ÁÆóÊú∫ÁßëÂ≠¶‰∏≠ÁöÑÂÖ∂‰ªñÊ†ëÁªìÊûÑÁ±ª‰ººÔºå‰ΩÜÊòØÂÆÉÈÄöËøáÈìæÊé•ÔºàlinkÔºâÊù•ËøûÊé•Áõ∏‰ººÂÖÉÁ¥†ÔºåË¢´ËøûËµ∑Êù•ÁöÑÂÖÉÁ¥†È°πÂèØ‰ª•ÁúãÊàê‰∏Ä‰∏™ÈìæË°®„ÄÇ ÂêåÊêúÁ¥¢Ê†ë‰∏çÂêåÁöÑÊòØÔºå‰∏Ä‰∏™ÂÖÉÁ¥†ÂèØ‰ª•Âú®‰∏ÄÊ£µFPÊ†ë‰∏≠Âá∫Áé∞Â§öÊ¨°„ÄÇFPÊ†ë‰ºöÂ≠òÂÇ®È°πÈõÜÁöÑÂá∫Áé∞È¢ëÁéáÔºåËÄåÊØè‰∏™È°πÈõÜ‰ºö‰ª•Ë∑ØÂæÑÁöÑÊñπÂºèÂ≠òÂÇ®Âú®Ê†ë‰∏≠„ÄÇÂ≠òÂú®Áõ∏‰ººÂÖÉÁ¥†ÁöÑÈõÜÂêà‰ºöÂÖ±‰∫´Ê†ëÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÂè™ÊúâÂΩìÈõÜÂêà‰πãÈó¥ÂÆåÂÖ®‰∏çÂêåÊó∂ÔºåÊ†ëÊâç‰ºöÂàÜÂèâ„ÄÇÊ†ëËäÇÁÇπ‰∏äÁªôÂá∫ÈõÜÂêà‰∏≠ÁöÑÂçï‰∏™ÂÖÉÁ¥†‰ª•ÂèäÂú®Â∫èÂàó‰∏≠ÁöÑÂá∫Áé∞Ê¨°Êï∞ÔºåË∑ØÂæÑ‰ºöÁªôÂá∫ËØ•Â∫èÂàóÁöÑÂá∫Áé∞Ê¨°Êï∞„ÄÇ Áõ∏‰ººÈ°π‰πãÈó¥ÁöÑÈìæÊé•Âç≥ËäÇÁÇπÈìæÊé•Ôºànode linkÔºâÔºåÁî®‰∫éÂø´ÈÄüÂèëÁé∞Áõ∏‰ººÁöÑ‰ΩçÁΩÆ„ÄÇ ‰∫ãÂä°ID ‰∫ãÂä°‰∏≠ÁöÑÂÖÉÁ¥†È°πÁõÆ 001 r, z, h, j, p 002 z, y, x, w, v, u, t, s 003 z 004 r, x, n, o, s 005 y, r, x, z, q, t, p 006 y, z, x, e, q, s, t, m Âú®‰∏äË°®‰∏≠ÔºåÂÖÉÁ¥†zÂá∫Áé∞‰∫Ü5Ê¨°ÔºåÈõÜÂêà{r,z}Âá∫Áé∞‰∫Ü1Ê¨°Ôºà001Âíå005ÈÉΩÂá∫Áé∞‰∫ÜÔºå‰ΩÜ‰π¶‰∏≠ÂÜô1Ê¨°Ôºâ„ÄÇ‰∫éÊòØÂèØ‰ª•ÂæóÂá∫ÁªìËÆ∫Ôºöz‰∏ÄÂÆöÊòØËá™Â∑±Êú¨Ë∫´ÊàñËÄÖÂÖ∂‰ªñÁ¨¶Âè∑‰∏ÄËµ∑Âá∫Áé∞‰∫Ü3Ê¨°„ÄÇÊàë‰ª¨ÂÜçÁúã‰∏ãzÁöÑÂÖ∂‰ªñÂèØËÉΩÊÄß„ÄÇÈõÜÂêà{t,s,y,x,z}Âá∫Áé∞‰∫Ü2Ê¨°ÔºåÈõÜÂêà{t,r,y,x,z}Âá∫Áé∞‰∫Ü1Ê¨°„ÄÇÂÖÉÁ¥†È°πzÁöÑÂè≥ËæπÊ†áÁöÑÊòØ5ÔºåË°®Á§∫zÂá∫Áé∞‰∫Ü5Ê¨°ÔºåÂÖ∂‰∏≠ÂàöÊâçÂ∑≤ÁªèÁªôÂá∫‰∫Ü4Ê¨°Âá∫Áé∞ÔºåÊâÄ‰ª•ÂÆÉ‰∏ÄÂÆöÂçïÁã¨Âá∫Áé∞Ëøá1Ê¨°„ÄÇ ÂêêÊßΩÔºöËøô‰π¶Ëøô‰∏§Á´†ÂÜôÁöÑ‰∫ëÂ±±ÈõæÁªï FP-growthÁöÑ‰∏ÄËà¨ÊµÅÁ®ã Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÁî±‰∫éÂ≠òÂÇ®ÁöÑÊòØÈõÜÂêàÔºåÊâÄ‰ª•ÈúÄË¶ÅÁ¶ªÊï£Êï∞ÊçÆ„ÄÇÂ¶ÇÊûúË¶ÅÂ§ÑÁêÜËøûÁª≠Êï∞ÊçÆÔºåÈúÄË¶ÅÂ∞ÜÂÆÉ‰ª¨ÈáèÂåñ‰∏∫Á¶ªÊï£ÂÄº„ÄÇ ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÊûÑÂª∫‰∏Ä‰∏™FPÊ†ëÔºåÂπ∂ÂØπÊ†ëËøõË°åÊåñÊéò ÊµãËØïÁÆóÊ≥ïÔºöÊ≤°ÊúâÊµãËØïËøáÁ®ã ‰ΩøÁî®ÁÆóÊ≥ïÔºöÂèØÁî®‰∫éËØÜÂà´ÁªèÂ∏∏Âá∫Áé∞ÁöÑÂÖÉÁ¥†È°πÔºå‰ªéËÄåÁî®‰∫éÂà∂ÂÆöÂÜ≥Á≠ñÔºåÊé®ËçêÂÖÉÁ¥†ÊàñËÄÖËøõË°åÈ¢ÑÊµãÁ≠âÂ∫îÁî®‰∏≠„ÄÇ ÊûÑÂª∫FPÊ†ëFPÊ†ëÁöÑÁ±ªÂÆö‰πâ123456789101112131415class treeNode: def __init__(self, nameValue, numOccur, parentNode): self.name = nameValue self.count = numOccur self.nodeLink = None self.parent = parentNode self.children = &#123;&#125; def inc(self, numOccur): self.count += numOccur def disp(self, ind=1): print(' '*ind, self.name, ' ', self.count) for child in self.children.values(): child.disp(ind+1) ‰∏äÈù¢ÁöÑÁ®ãÂ∫èÁªôÂá∫‰∫ÜFPÊ†ë‰∏≠ÁªìÁÇπÁöÑÁ±ªÂÆö‰πâ„ÄÇÁ±ª‰∏≠ÂåÖÂê´Áî®‰∫éÂ≠òÊîæËäÇÁÇπÂêçÂ≠óÁöÑÂèòÈáèÂíå1‰∏™ËÆ°Êï∞ÂÄºÔºånodeLinkeÂèòÈáèÁî®‰∫éÈìæÊé•Áõ∏‰ººÁöÑÂÖÉÁ¥†È°π„ÄÇ 1rootNode = treeNode('pyramid', 9, None) 1rootNode.children['eye'] = treeNode('eye', 13, None) 1rootNode.disp() pyramid 9 eye 13 1rootNode.children['phoenix'] = treeNode('phoenix', 3, None) 1rootNode.disp() pyramid 9 eye 13 phoenix 3 ÊûÑÂª∫FPÊ†ëÈúÄË¶Å‰∏Ä‰∏™Â§¥ÊåáÈíàË°®Êù•ÊåáÂêëÁªôÂÆöÁ±ªÂûãÁöÑÁ¨¨‰∏Ä‰∏™ÂÆûÂàó„ÄÇÂà©Áî®Â§¥ÊåáÈíàË°®ÔºåÂèØ‰ª•Âø´ÈÄüËÆøÈóÆFPÊ†ë‰∏≠‰∏Ä‰∏™ÁªôÂÆöÁ±ªÂûãÁöÑÊâÄÊúâÂÖÉÁ¥†„ÄÇ ‰ΩøÁî®‰∏Ä‰∏™Â≠óÂÖ∏Êù•‰øùÂ≠òÂ§¥ÊåáÈíàË°®„ÄÇÂ§¥ÊåáÈíàË°®ËøòÂèØ‰ª•Áî®Êù•‰øùÂ≠òFPÊ†ë‰∏≠ÊØèÁ±ªÂÖÉÁ¥†ÁöÑÊÄªÊï∞„ÄÇ ÂØπ‰∏çÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÁöÑÊï∞ÊçÆËøõË°åÂéªÈô§ÔºåÁÑ∂ÂêéÂêéÈáçÊéíÂ∫èÂæóÂà∞‰∏ãË°® ‰∫ãÂä°ID ‰∫ãÂä°‰∏≠ÁöÑÂÖÉÁ¥†È°πÁõÆ ËøáÊª§ÂèäÈáçÊéíÂ∫èÂêéÁöÑ‰∫ãÂä° 001 r, z, h, j, p z,r 002 z, y, x, w, v, u, t, s z, x, y, s, t 003 z z 004 r, x, n, o, s x, s, r 005 y, r, x, z, q, t, p z, x, y, r, t 006 y, z, x, e, q, s, t, m z, x, y, s, t FPÊ†ëÊûÑÂª∫ÂáΩÊï∞ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def createTree(dataSet, minSup=1): headerTable = &#123;&#125; # Êü•ÁúãÊï∞ÊçÆÈõÜ‰∏§Ê¨° for trans in dataSet: # Á¨¨‰∏ÄÈÅçËÆ°Êï∞Âá∫Áé∞ÁöÑÈ¢ëÁéá for item in trans: headerTable[item] = headerTable.get(item, 0) + dataSet[trans] for k in list(headerTable.keys()): # Âà†Èô§‰∏çÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÁöÑÂÖÉÁ¥†È°π if headerTable[k] &lt; minSup: del(headerTable[k]) freqItemSet = set(headerTable.keys()) if len(freqItemSet) == 0: return None, None # Ê≤°ÊúâÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÁöÑÈ°πÁõÆÂàôËøîÂõû for k in headerTable: headerTable[k] = [headerTable[k], None] retTree = treeNode('Null Set', 1, None) # create tree for tranSet, count in dataSet.items(): # Á¨¨‰∫åÊ¨°ÈÅçÂéÜÊï∞ÊçÆÈõÜ localD = &#123;&#125; for item in tranSet: # Êõ¥ÂÖ∑ÂÖ®Â±ÄÈ¢ëÁéáÂØπÊØè‰∏™‰∫ãÂä°‰∏≠ÁöÑÂÖÉÁ¥†ËøõË°åÊéíÂ∫è if item in freqItemSet: localD[item] = headerTable[item][0] if len(localD) &gt; 0: orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)] updateTree(orderedItems, retTree, headerTable, count) # ÂØπÂâ©‰∏ãÁöÑÂÖÉÁ¥†Ëø≠‰ª£Ë∞ÉÁî®upadteTreeÂáΩÊï∞ return retTree, headerTabledef updateTree(items, inTree, headerTable, count): if items[0] in inTree.children: inTree.children[items[0]].inc(count) else: inTree.children[items[0]] = treeNode(items[0], count, inTree) if headerTable[items[0]][1] == None: headerTable[items[0]][1] = inTree.children[items[0]] else: updateHeader(headerTable[items[0]][1], inTree.children[items[0]]) if len(items) &gt; 1: updateTree(items[1::], inTree.children[items[0]], headerTable, count)def updateHeader(nodeToTest, targetNode): while (nodeToTest.nodeLink != None): nodeToTest = nodeToTest.nodeLink nodeToTest.nodeLink = targetNode 1234567891011121314def loadSimpDat(): simpDat = [['r', 'z', 'h', 'j', 'p'], ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'], ['z'], ['r', 'x', 'n', 'o', 's'], ['y', 'r', 'x', 'z', 'q', 't', 'p'], ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']] return simpDatdef createInitSet(dataSet): retDict = &#123;&#125; for trans in dataSet: retDict[frozenset(trans)] = 1 return retDict 12simpDat = loadSimpDat()simpDat [[&apos;r&apos;, &apos;z&apos;, &apos;h&apos;, &apos;j&apos;, &apos;p&apos;], [&apos;z&apos;, &apos;y&apos;, &apos;x&apos;, &apos;w&apos;, &apos;v&apos;, &apos;u&apos;, &apos;t&apos;, &apos;s&apos;], [&apos;z&apos;], [&apos;r&apos;, &apos;x&apos;, &apos;n&apos;, &apos;o&apos;, &apos;s&apos;], [&apos;y&apos;, &apos;r&apos;, &apos;x&apos;, &apos;z&apos;, &apos;q&apos;, &apos;t&apos;, &apos;p&apos;], [&apos;y&apos;, &apos;z&apos;, &apos;x&apos;, &apos;e&apos;, &apos;q&apos;, &apos;s&apos;, &apos;t&apos;, &apos;m&apos;]] 12initSet = createInitSet(simpDat)initSet {frozenset({&apos;h&apos;, &apos;j&apos;, &apos;p&apos;, &apos;r&apos;, &apos;z&apos;}): 1, frozenset({&apos;s&apos;, &apos;t&apos;, &apos;u&apos;, &apos;v&apos;, &apos;w&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;}): 1, frozenset({&apos;z&apos;}): 1, frozenset({&apos;n&apos;, &apos;o&apos;, &apos;r&apos;, &apos;s&apos;, &apos;x&apos;}): 1, frozenset({&apos;p&apos;, &apos;q&apos;, &apos;r&apos;, &apos;t&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;}): 1, frozenset({&apos;e&apos;, &apos;m&apos;, &apos;q&apos;, &apos;s&apos;, &apos;t&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;}): 1} 1myFPtree, myHeaderTab = createTree(initSet, 3) 1myFPtree.disp() Null Set 1 z 5 r 1 x 3 s 2 y 2 t 2 r 1 y 1 t 1 x 1 r 1 s 1 ‰∏äÈù¢ÁªôÂá∫ÁöÑÂÖÉÁ¥†È°πÂèäÂÖ∂ÂØπÂ∫îÁöÑÈ¢ëÁéáËÆ°Êï∞ÂÄºÔºåÂÖ∂‰∏≠ÊØè‰∏™Áº©ËøõË°®Á§∫ÊâÄÂ§ÑÁöÑÊ†ëÁöÑÊ∑±Â∫¶„ÄÇ ‰ªé‰∏ÄÊ£µFPÊ†ë‰∏≠ÊåñÊéòÈ¢ëÁπÅÈ°πÈõÜ‰ªéFPÊ†ë‰∏≠ÊäΩÂèñÈ¢ëÁπÅÈ°πÈõÜÁöÑ‰∏â‰∏™Âü∫Êú¨Ê≠•È™§Â¶Ç‰∏ãÔºö ‰ªéFPÊ†ë‰∏≠Ëé∑ÂæóÊù°‰ª∂Ê®°ÂºèÂü∫ Âà©Áî®Êù°‰ª∂Ê®°ÂºèÂü∫ÔºåÊûÑÂª∫‰∏Ä‰∏™Êù°‰ª∂FPÊ†ë Ëø≠‰ª£ÈáçÂ§ç1Ôºå2Ê≠•È™§ÔºåÁõ¥Âà∞Ê†ëÂåÖÂê´‰∏Ä‰∏™ÂÖÉÁ¥†‰∏∫Ê≠¢ ÊäΩÂèñË∞ÉÂâÇÊ®°ÂºèÂü∫ÂèëÁé∞‰ª•ÁªôÂÆöÂÖÉÁ¥†È°πÁªìÂ∞æÁöÑÊâÄÊúâË∑ØÂæÑÁöÑÂáΩÊï∞ 1234567891011121314def ascendTree(leafNode, prefixPath): if leafNode.parent != None: prefixPath.append(leafNode.name) ascendTree(leafNode.parent, prefixPath)def findPrefixPath(basePat, treeNode): condPats = &#123;&#125; while treeNode != None: prefixPath = [] ascendTree(treeNode, prefixPath) if len(prefixPath) &gt; 1: condPats[frozenset(prefixPath[1:])] = treeNode.count treeNode = treeNode.nodeLink return condPats ‰∏äËø∞‰ª£Á†ÅÁî®‰∫éÁªôÂÆöÂÖÉÁ¥†È°πÁîüÊàê‰∏Ä‰∏™Êù°‰ª∂Ê®°ÂºèÂü∫ÔºåËøôÈÄöËøáËÆøÈóÆÊ†ë‰∏≠ÊâÄÊúâÂåÖÂê´ÁªôÂÆöÂÖÉÁ¥†È°πÁöÑËäÇÁÇπÊù•ÂÆåÊàê„ÄÇ 1findPrefixPath('x', myHeaderTab['x'][1]) {frozenset({&apos;z&apos;}): 3} 1findPrefixPath('z', myHeaderTab['z'][1]) {} 1findPrefixPath('r', myHeaderTab['r'][1]) {frozenset({&apos;z&apos;}): 1, frozenset({&apos;x&apos;}): 1, frozenset({&apos;x&apos;, &apos;z&apos;}): 1} ÂàõÂª∫Êù°‰ª∂FPÊ†ëÈÄíÂΩíÊü•ÊâæÈ¢ëÁπÅÈ°πÈõÜÁöÑmineTreeÂáΩÊï∞ 123456789101112def mineTree(inTree, headerTable, minSup, preFix, freqItemList): bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p: p[1][0])] for basePat in bigL: newFreqSet = preFix.copy() newFreqSet.add(basePat) freqItemList.append(newFreqSet) condPattBases = findPrefixPath(basePat, headerTable[basePat][1]) myCondTree, myHead = createTree(condPattBases, minSup) if myHead != None: print('conditional tree for: ',newFreqSet) myCondTree.disp(1) mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList) 1freqItems = [] 1mineTree(myFPtree, myHeaderTab, 3, set([]), freqItems) conditional tree for: {&apos;s&apos;} Null Set 1 x 3 conditional tree for: {&apos;y&apos;} Null Set 1 x 3 z 3 conditional tree for: {&apos;y&apos;, &apos;z&apos;} Null Set 1 x 3 conditional tree for: {&apos;t&apos;} Null Set 1 y 3 x 3 z 3 conditional tree for: {&apos;t&apos;, &apos;x&apos;} Null Set 1 y 3 conditional tree for: {&apos;t&apos;, &apos;z&apos;} Null Set 1 y 3 x 3 conditional tree for: {&apos;t&apos;, &apos;x&apos;, &apos;z&apos;} Null Set 1 y 3 conditional tree for: {&apos;x&apos;} Null Set 1 z 3 1freqItems [{&apos;r&apos;}, {&apos;s&apos;}, {&apos;s&apos;, &apos;x&apos;}, {&apos;y&apos;}, {&apos;x&apos;, &apos;y&apos;}, {&apos;y&apos;, &apos;z&apos;}, {&apos;x&apos;, &apos;y&apos;, &apos;z&apos;}, {&apos;t&apos;}, {&apos;t&apos;, &apos;y&apos;}, {&apos;t&apos;, &apos;x&apos;}, {&apos;t&apos;, &apos;x&apos;, &apos;y&apos;}, {&apos;t&apos;, &apos;z&apos;}, {&apos;t&apos;, &apos;y&apos;, &apos;z&apos;}, {&apos;t&apos;, &apos;x&apos;, &apos;z&apos;}, {&apos;t&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;}, {&apos;x&apos;}, {&apos;x&apos;, &apos;z&apos;}, {&apos;z&apos;}] ÂÆû‰æãÔºö‰ªéÊñ∞ÈóªÁΩëÁ´ôÁÇπÂáªÊµÅ‰∏≠ÊåñÊéòÊúâËøë100‰∏áÊù°Áî®Êà∑ÊµèËßàÊï∞ÊçÆ„ÄÇ 1parsedDat = [line.split() for line in open('MLiA_SourceCode/Ch12/kosarak.dat').readlines()] 1initSet = createInitSet(parsedDat) 1myFPtree, myHeaderTab = createTree(initSet, 100000) 1myFreqList = [] 1mineTree(myFPtree, myHeaderTab, 100000, set([]), myFreqList) conditional tree for: {&apos;1&apos;} Null Set 1 6 107404 conditional tree for: {&apos;3&apos;} Null Set 1 6 186289 11 117401 11 9718 conditional tree for: {&apos;3&apos;, &apos;11&apos;} Null Set 1 6 117401 conditional tree for: {&apos;11&apos;} Null Set 1 6 261773 1myFreqList [{&apos;1&apos;}, {&apos;1&apos;, &apos;6&apos;}, {&apos;3&apos;}, {&apos;11&apos;, &apos;3&apos;}, {&apos;11&apos;, &apos;3&apos;, &apos;6&apos;}, {&apos;3&apos;, &apos;6&apos;}, {&apos;11&apos;}, {&apos;11&apos;, &apos;6&apos;}, {&apos;6&apos;}] ÊµãËØïÂ∫ìÂáΩÊï∞1%pip install pyfpgrowth Collecting pyfpgrowth Downloading https://files.pythonhosted.org/packages/d2/4c/8b7cd90b4118ff0286d6584909b99e1ca5642bdc9072fa5a8dd361c864a0/pyfpgrowth-1.0.tar.gz (1.6MB) Installing collected packages: pyfpgrowth Running setup.py install for pyfpgrowth: started Running setup.py install for pyfpgrowth: finished with status &apos;done&apos; Successfully installed pyfpgrowth-1.0 123import pyfpgrowthpatterns = pyfpgrowth.find_frequent_patterns(initSet, 100000)rules = pyfpgrowth.generate_association_rules(patterns, 0.7) 1patterns {(&apos;1&apos;,): 140597, (&apos;1&apos;, &apos;6&apos;): 107404, (&apos;11&apos;, &apos;3&apos;): 127119, (&apos;11&apos;, &apos;3&apos;, &apos;6&apos;): 117401, (&apos;3&apos;, &apos;6&apos;): 186289, (&apos;11&apos;,): 282963, (&apos;11&apos;, &apos;6&apos;): 261773, (&apos;6&apos;,): 412762} 1rules {(&apos;1&apos;,): ((&apos;6&apos;,), 0.7639138815195203), (&apos;11&apos;, &apos;3&apos;): ((&apos;6&apos;,), 0.9235519473878806), (&apos;11&apos;,): ((&apos;6&apos;,), 0.9251138841473974)} ÊÄªÁªìFP-growthÁÆóÊ≥ïÊòØ‰∏ÄÁßçÁî®‰∫éÂèëÁé∞Êï∞ÊçÆÈõÜ‰∏≠È¢ëÁπÅÊ®°ÂºèÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇFP-growthÁÆóÊ≥ïÂà©Áî®AprioriÂéüÂàôÔºåÊâßË°åÊõ¥Âø´„ÄÇAprioriÁÆóÊ≥ï‰∫ßÁîüÂÄôÈÄâÈ°πÈõÜÔºåÁÑ∂ÂêéÊâ´ÊèèÊï∞ÊçÆÈõÜÊù•Ê£ÄÊü•ÂÆÉ‰ª¨ÊòØÂê¶È¢ëÁπÅÂèë„ÄÇÁî±‰∫éÂè™ÂØπÊï∞ÊçÆÈõÜÊâ´Êèè‰∏§Ê¨°ÔºåÂõ†Ê≠§FP-growthÁÆóÊ≥ïÊâßË°åÊõ¥Âø´„ÄÇÂú®FP-growthÁÆóÊ≥ï‰∏≠ÔºåÊï∞ÊçÆÈõÜÂ≠òÂÇ®Âú®‰∏Ä‰∏™Áß∞‰∏∫FPÊ†ëÁöÑÁªìÊûÑ‰∏≠„ÄÇFPÊ†ëÊûÑÂª∫ÂÆåÊàêÂêéÔºåÂèØ‰ª•ÈÄöËøáÊü•ÊâæÂÖÉÁ¥†È°πÁöÑÊù°‰ª∂Âü∫ÂèäÊûÑÂª∫Êù°‰ª∂FPÊ†ëÊù•ÂèëÁé∞È¢ëÁπÅÈ°πÈõÜ„ÄÇËØ•ËøáÁ®ã‰∏çÊñ≠‰ª•Êõ¥Â§öÂÖÉÁ¥†‰Ωú‰∏∫Êù°‰ª∂ÈáçÂ§çËøõË°åÔºåÁü•ÈÅìFPÊ†ëÂè™ÂåÖÂê´‰∏Ä‰∏™ÂÖÉÁ¥†‰∏∫Ê≠¢„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>FP-growth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÊñáÊú¨ËΩ¨Emoji]]></title>
    <url>%2F2020%2F06%2F01%2FEmojiAnalysis%2F</url>
    <content type="text"><![CDATA[ÂàÜÊûêÂæÆÂçö‰∏≠ÁöÑemoji1234567891011# Êï∞ÊçÆÂàÜÊûêÂ∫ìimport pandas as pdimport numpy as npimport random# Êï∞ÊçÆÂèØËßÜÂåñimport seaborn as snsimport matplotlib.pyplot as pltplt.style.use('ggplot')import emoji Â§ÑÁêÜÊî∂ÈõÜÂà∞Âà∞ÂæÆÂçöËØÑËÆ∫12345678import osdef all_path(dirname): result = []#ÊâÄÊúâÁöÑÊñá‰ª∂ for maindir, subdir, file_name_list in os.walk(dirname): for filename in file_name_list: apath = os.path.join(maindir, filename)#ÂêàÂπ∂Êàê‰∏Ä‰∏™ÂÆåÊï¥Ë∑ØÂæÑ result.append(apath) return result 12filenames = all_path('WeiboData')filenames = filter(lambda x: 'WeiBoDataRet' in x, filenames) 12345data_list = []for filename in filenames: tmp = pd.read_csv(filename, sep='|', encoding="utf-8", names=['text', 'emoji']) data_list.append(tmp)data = pd.concat(data_list) # ÊääÊâÄÊúâÊï∞ÊçÆÊãºÊé•Ëµ∑Êù• 1data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji 0 heartbroken ‰º§ÂøÉ 1 Ëµ∞Â•Ω ÊÇ≤‰º§ 2 Ëµ∞Â•Ω ÂøÉ 3 Ëµ∞Â•Ω ÂøÉ 4 Ëµ∞Â•Ω ÂøÉ 1data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji count 1674858 1673955 unique 220772 1780 top ÂøÉ freq 228436 194223 Êï∞ÊçÆÊ∏ÖÊ¥óÂéªÈáç ÂéªÈô§ Á©∫Ê†º ÂéªÈô§Èùûemoji ÊûÑÂª∫emojiÂ≠óÂÖ∏ 1data = data.drop_duplicates() 12data.text = data.text.apply(lambda x: x.strip())data.emoji = data.emoji.apply(lambda x: str(x).strip()) 12345import jsondef GetEmojiDict(): fr = open('ImgName.txt', 'r') jsondata = fr.read() return json.loads(jsondata) 1emojiDict = GetEmojiDict() 1len(emojiDict) 149 ÂéªÈô§Èùû‰∏≠Êñátext123456789import rezhPattern=re.compile(u'[\u4e00-\u9fa5]+')def FilterEmoji(contents): if contents in emojiDict: return True else: if zhPattern.search(contents): return False return True 1data.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; Int64Index: 287976 entries, 0 to 703321 Data columns (total 2 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 text 287976 non-null object 1 emoji 287976 non-null object dtypes: object(2) memory usage: 6.6+ MB 1filterReg = data.emoji.apply(lambda x: FilterEmoji(x)) 1filterIndex = filterReg[filterReg==0].index 1filterIndex Int64Index([ 61, 374, 653, 816, 1428, 1503, 1772, 2093, 2382, 2697, ... 701750, 701882, 701894, 702185, 702186, 702380, 702501, 703077, 703095, 703096], dtype=&apos;int64&apos;, length=4556) 1data = data.drop(filterIndex) 123filterReg = data.text.apply(lambda x: FilterEmoji(x))filterIndex = filterReg[filterReg==1].indexfilterIndex Int64Index([ 0, 47, 56, 65, 144, 152, 159, 168, 174, 175, ... 700205, 700206, 700207, 700266, 700352, 702191, 702192, 702193, 702194, 702195], dtype=&apos;int64&apos;, length=3475) 1filterIndex Int64Index([ 0, 47, 56, 65, 144, 152, 159, 168, 174, 175, ... 700205, 700206, 700207, 700266, 700352, 702191, 702192, 702193, 702194, 702195], dtype=&apos;int64&apos;, length=3475) 1data = data.drop(filterIndex) 1data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji count 277826 277826 unique 215349 1339 top [Âä†Ê≤π] ÂÖÅÊÇ≤ freq 72 22486 1emoji_counts = data.emoji.value_counts() 1emoji_counts.describe() count 1339.000000 mean 207.487677 std 1196.566008 min 1.000000 25% 3.000000 50% 9.000000 75% 41.000000 max 22486.000000 Name: emoji, dtype: float64 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji 1 Ëµ∞Â•Ω ÊÇ≤‰º§ 2 Ëµ∞Â•Ω ÂøÉ 5 Ëµ∞Â•Ω Ëú°ÁÉõ 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà 7 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü ÁªôÂäõ ... ... ... 703299 ÊúüÂæÖËúúÊ°ÉÁ¨¨‰∫åÂ≠£ÔºåÊúüÂæÖÈÇì‰º¶ :peach: 703303 ÊúüÂæÖ‰º¶‰º¶ ÂøÉ 703315 Â∑ùË•øÁúüÁöÑÊòØÈöè‰æø‰∏Ä‰∏™Âú∞ÊñπÈÉΩÊòØÈ£éÊôØ ÈºìÊéå 703320 „ÅäÁñ≤„ÇåÊßò„Åß„Åó„Åü Ë∑™‰∫Ü 703321 Â§™Âø´‰∫ÜÔºÅÔºÅÔºÅ Ëµû 277826 rows √ó 2 columns Âà†Èô§ÈáçÂ§çÁöÑtext12dupdata = data.text.duplicated()dupIndex = dupdata[dupdata==1].index 1len(dupIndex) 62477 1data = data.drop(dupIndex) 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji 1 Ëµ∞Â•Ω ÊÇ≤‰º§ 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà 9 ËÄÅ‰∫∫ÂÆ∂ÂÄºÂæóÊâÄÊúâ‰∫∫Â∞äÈáç Ëµû 12 ËÄÅÁôæÂßìÁúüÂ•Ω ÂøÉ 14 ËôΩÁÑ∂Ë°å‰∏∫ÁÇπËµûÔºå‰ΩÜÊòØËøòÊòØË°∑ÂøÉÂ∏åÊúõËÄÅ‰∫∫ÔºåÊääËá™Â∑±ËøáÂ•Ω‰∫ÜÔºåÊúâËÉΩÂäõÔºåÂÜçÂéªÂ∏ÆÂä©Âà´‰∫∫„ÄÇ ÊëäÊâã ... ... ... 703298 ÊúüÂæÖËúúÊ°ÉÁ¨¨‰∫åÂ≠£ÔºåÊúüÂæÖÈÇì‰º¶ ÂøÉ 703303 ÊúüÂæÖ‰º¶‰º¶ ÂøÉ 703315 Â∑ùË•øÁúüÁöÑÊòØÈöè‰æø‰∏Ä‰∏™Âú∞ÊñπÈÉΩÊòØÈ£éÊôØ ÈºìÊéå 703320 „ÅäÁñ≤„ÇåÊßò„Åß„Åó„Åü Ë∑™‰∫Ü 703321 Â§™Âø´‰∫ÜÔºÅÔºÅÔºÅ Ëµû 203185 rows √ó 2 columns ÂçïËØçÂêëÈáè‰∏ãÈù¢ËøôÊÆµcodeÁöÑÂäüËÉΩÊòØËß£ÊûêËØçÁªÑÂØπÂ∫îÁöÑÂêëÈáèÁöÑ‰∏â‰∏™Â≠óÂÖ∏ word_to_index ÂçïËØçÊü•Á¥¢Âºï index_to_word Á¥¢ÂºïÊü•ÂçïËØç word_to_vec_map ÂçïËØçÊü•ÂêëÈáè 123456789101112131415161718def read_word_vecs(file): with open(file, 'r', encoding="utf-8") as f: words = set() word_to_vec_map = &#123;&#125; for line in f: line = line.strip().split() curr_word = line[0] words.add(curr_word) word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64) i = 1 words_to_index = &#123;&#125; index_to_words = &#123;&#125; for w in sorted(words): words_to_index[w] = i index_to_words[i] = w i = i + 1 return words_to_index, index_to_words, word_to_vec_map 1word_to_index, index_to_word, word_to_vec_map = read_word_vecs('sgns.weibo.word') 1word_to_vec_map['‰ªñ‰ª¨'] array([-0.058985, -0.095981, 0.213523, 0.078806, 0.090758, 0.303698, -0.080819, -0.070496, 0.100697, -0.014494, 0.105789, -0.081538, -0.220132, -0.001089, -0.010554, 0.045872, 0.020978, -0.078958, 0.310522, 0.026538, 0.116843, -0.012077, 0.091833, 0.199016, -0.253477, 0.105833, -0.079761, -0.114635, 0.437327, 0.003209, -0.191938, -0.292937, -0.042434, -0.092598, -0.031424, 0.232141, 0.175102, -0.028322, -0.182089, -0.127304, -0.105405, -0.0155 , -0.105409, 0.128716, 0.271304, -0.258079, 0.294854, -0.225564, 0.041693, 0.122313, -0.10642 , 0.218218, -0.061122, 0.032375, 0.061754, 0.060876, 0.177719, 0.080874, 0.040064, 0.028098, 0.181363, -0.073601, -0.009067, -0.031534, 0.190581, 0.175827, -0.003394, -0.120093, 0.136633, 0.22353 , -0.286703, -0.083716, 0.07307 , 0.290753, -0.073568, -0.146416, 0.287048, 0.177982, 0.159483, 0.033554, -0.113645, 0.086506, 0.182751, 0.222543, 0.069108, -0.005411, -0.117244, 0.278492, 0.292221, -0.277547, 0.035062, 0.05546 , 0.043035, 0.118464, -0.03085 , 0.163017, 0.032309, 0.238069, 0.164545, -0.162392, -0.093865, 0.358772, -0.138829, -0.27499 , -0.190523, -0.198303, -0.228555, 0.02823 , 0.12706 , -0.017478, 0.279601, -0.130354, 0.376413, 0.107592, 0.501358, -0.392651, 0.167826, 0.030806, -0.047537, 0.0542 , -0.027822, -0.177908, 0.436953, -0.139909, -0.205398, -0.069401, 0.210465, -0.09408 , -0.030155, -0.186514, -0.408763, 0.209337, 0.154496, -0.155053, -0.073264, -0.208221, 0.031705, 0.007868, 0.105028, -0.313043, -0.030095, 0.32314 , 0.039472, 0.056924, -0.029449, -0.18332 , 0.329696, -0.20353 , 0.079724, 0.005614, 0.033271, 0.129164, 0.06442 , -0.093268, -0.26306 , 0.042632, -0.066531, -0.25593 , -0.082908, -0.211791, 0.269096, -0.231714, 0.498682, 0.171995, -0.188561, -0.254678, 0.127424, 0.490121, -0.002619, -0.270687, -0.062654, -0.009806, 0.068663, -0.131597, 0.157276, -0.118741, 0.362313, -0.107524, -0.043709, 0.051271, 0.016886, -0.303519, -0.131623, -0.103483, 0.090379, 0.071147, 0.132338, -0.146149, -0.366627, -0.351044, -0.063839, 0.082302, 0.385776, 0.158985, 0.224325, -0.116336, -0.247472, -0.500043, -0.054399, -0.51975 , -0.165844, 0.067776, -0.311503, 0.160354, 0.310949, -0.158256, -0.13147 , -0.046553, -0.132425, -0.174187, 0.137154, 0.128941, 0.077095, 0.086764, -0.085013, -0.076975, 0.116672, -0.234487, -0.029225, -0.297913, 0.03733 , 0.07142 , -0.333047, 0.250342, 0.071834, -0.360994, 0.160254, -0.085961, -0.244442, -0.00217 , 0.016221, -0.25117 , 0.102826, -0.190794, -0.163422, 0.067348, -0.066799, -0.105879, 0.281125, -0.092643, 0.014463, -0.040031, -0.047755, -0.192767, 0.166827, -0.210013, -0.126185, 0.228651, 0.28803 , 0.045921, 0.15332 , 0.014357, -0.149424, -0.235598, -0.137925, -0.333645, 0.114881, 0.25207 , 0.046461, 0.00136 , 0.089115, -0.182189, -0.200544, 0.175124, 0.069565, -0.055904, 0.05993 , 0.067038, 0.119123, 0.143849, -0.182774, 0.354611, -0.137333, 0.157642, 0.028673, -0.504065, -0.006483, -0.056175, 0.131101, -0.106961, -0.07638 , 0.294719, 0.003378, 0.096714, -0.157428, -0.032374, -0.244506, 0.012603, 0.202828, 0.080087, 0.06369 , -0.315489, -0.087886, 0.172018, -0.135227, -0.168902, 0.25539 , -0.265512, -0.209118, 0.003291]) ÊñáÊú¨ÂàÜËØç‰ΩøÁî®jiebaÂØπtextÂàÜËØç 1import jieba 1words = data.text.apply(lambda x: list(jieba.cut(x))) Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.805 seconds. Prefix dict has been built successfully. 1words 1 [Ëµ∞, Â•Ω] 6 [ËàíÊúç, ‰∫Ü, Ôºå, ÁùÄÂ∞ºÂì•, Áªà‰∫é, Ê≠ª, ‰∫Ü] 9 [ËÄÅ‰∫∫ÂÆ∂, ÂÄºÂæó, ÊâÄÊúâ‰∫∫, Â∞äÈáç] 12 [ËÄÅÁôæÂßì, Áúü, Â•Ω] 14 [ËôΩÁÑ∂, Ë°å‰∏∫, ÁÇπËµû, Ôºå, ‰ΩÜÊòØ, ËøòÊòØ, Ë°∑ÂøÉÂ∏åÊúõ, ËÄÅ‰∫∫, Ôºå, Êää, Ëá™Â∑±, Ëøá,... ... 703298 [ÊúüÂæÖ, ËúúÊ°É, Á¨¨‰∫åÂ≠£, Ôºå, ÊúüÂæÖ, ÈÇì‰º¶] 703303 [ÊúüÂæÖ, ‰º¶‰º¶] 703315 [Â∑ùË•ø, ÁúüÁöÑ, ÊòØ, Èöè‰æø, ‰∏Ä‰∏™, Âú∞Êñπ, ÈÉΩ, ÊòØ, È£éÊôØ] 703320 [„Åä, Áñ≤, „Çå, Êßò, „Åß, „Åó, „Åü] 703321 [Â§™Âø´, ‰∫Ü, ÔºÅ, ÔºÅ, ÔºÅ] Name: text, Length: 203185, dtype: object 1data['words'] = words &lt;ipython-input-41-21ad536f0372&gt;:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy data[&apos;words&apos;] = words 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji words 1 Ëµ∞Â•Ω ÊÇ≤‰º§ [Ëµ∞, Â•Ω] 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà [ËàíÊúç, ‰∫Ü, Ôºå, ÁùÄÂ∞ºÂì•, Áªà‰∫é, Ê≠ª, ‰∫Ü] 9 ËÄÅ‰∫∫ÂÆ∂ÂÄºÂæóÊâÄÊúâ‰∫∫Â∞äÈáç Ëµû [ËÄÅ‰∫∫ÂÆ∂, ÂÄºÂæó, ÊâÄÊúâ‰∫∫, Â∞äÈáç] 12 ËÄÅÁôæÂßìÁúüÂ•Ω ÂøÉ [ËÄÅÁôæÂßì, Áúü, Â•Ω] 14 ËôΩÁÑ∂Ë°å‰∏∫ÁÇπËµûÔºå‰ΩÜÊòØËøòÊòØË°∑ÂøÉÂ∏åÊúõËÄÅ‰∫∫ÔºåÊääËá™Â∑±ËøáÂ•Ω‰∫ÜÔºåÊúâËÉΩÂäõÔºåÂÜçÂéªÂ∏ÆÂä©Âà´‰∫∫„ÄÇ ÊëäÊâã [ËôΩÁÑ∂, Ë°å‰∏∫, ÁÇπËµû, Ôºå, ‰ΩÜÊòØ, ËøòÊòØ, Ë°∑ÂøÉÂ∏åÊúõ, ËÄÅ‰∫∫, Ôºå, Êää, Ëá™Â∑±, Ëøá,... ... ... ... ... 703298 ÊúüÂæÖËúúÊ°ÉÁ¨¨‰∫åÂ≠£ÔºåÊúüÂæÖÈÇì‰º¶ ÂøÉ [ÊúüÂæÖ, ËúúÊ°É, Á¨¨‰∫åÂ≠£, Ôºå, ÊúüÂæÖ, ÈÇì‰º¶] 703303 ÊúüÂæÖ‰º¶‰º¶ ÂøÉ [ÊúüÂæÖ, ‰º¶‰º¶] 703315 Â∑ùË•øÁúüÁöÑÊòØÈöè‰æø‰∏Ä‰∏™Âú∞ÊñπÈÉΩÊòØÈ£éÊôØ ÈºìÊéå [Â∑ùË•ø, ÁúüÁöÑ, ÊòØ, Èöè‰æø, ‰∏Ä‰∏™, Âú∞Êñπ, ÈÉΩ, ÊòØ, È£éÊôØ] 703320 „ÅäÁñ≤„ÇåÊßò„Åß„Åó„Åü Ë∑™‰∫Ü [„Åä, Áñ≤, „Çå, Êßò, „Åß, „Åó, „Åü] 703321 Â§™Âø´‰∫ÜÔºÅÔºÅÔºÅ Ëµû [Â§™Âø´, ‰∫Ü, ÔºÅ, ÔºÅ, ÔºÅ] 203185 rows √ó 3 columns 1234567891011def ret_words_vector(words): vector = np.zeros(300) n = 0 for word in words: v = word_to_vec_map.get(word, None) if type(v) != type(None): n += 1 vector += v if not vector.all(): return None return vector/n 1vectors = data.words.apply(ret_words_vector) 1vectors 1 [-0.047105999999999995, 0.23246850000000002, 0... 6 [-0.027774333333333328, -0.114836, 0.062758, 0... 9 [-0.05153150000000001, 0.103688, 0.23323525, 0... 12 [-0.16598533333333335, 0.16545333333333334, 0.... 13 [-0.045179, 0.132102, 0.237468, 0.255355, -0.0... ... 53656 [-0.06892586111111111, -0.040252222222222224, ... 53666 [-0.124204, -0.0818, -0.02715266666666667, 0.0... 53669 [0.049611333333333334, 0.011862, 0.10510733333... 53683 [-0.01563454166666667, -0.008308624999999997, ... 53685 [-0.363667, -0.25396850000000004, 0.011313, -0... Name: words, Length: 6638, dtype: object 1data['vectors'] = vectors 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji words vectors 1 Ëµ∞Â•Ω ÊÇ≤‰º§ [Ëµ∞, Â•Ω] [-0.047105999999999995, 0.23246850000000002, 0... 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà [ËàíÊúç, ‰∫Ü, Ôºå, ÁùÄÂ∞ºÂì•, Áªà‰∫é, Ê≠ª, ‰∫Ü] [-0.027774333333333328, -0.114836, 0.062758, 0... 9 ËÄÅ‰∫∫ÂÆ∂ÂÄºÂæóÊâÄÊúâ‰∫∫Â∞äÈáç Ëµû [ËÄÅ‰∫∫ÂÆ∂, ÂÄºÂæó, ÊâÄÊúâ‰∫∫, Â∞äÈáç] [-0.05153150000000001, 0.103688, 0.23323525, 0... 12 ËÄÅÁôæÂßìÁúüÂ•Ω ÂøÉ [ËÄÅÁôæÂßì, Áúü, Â•Ω] [-0.16598533333333335, 0.16545333333333334, 0.... 13 Â•Ω‰∫∫ Ëµû [Â•Ω‰∫∫] [-0.045179, 0.132102, 0.237468, 0.255355, -0.0... ... ... ... ... ... 53656 ËøòÊúâÊàë‰ª¨sf9ÁöÑÊùéËææÊ∏ä‰ªñËÆ©Êàë‰ª¨ÊúâÈí±ÁöÑËØùÂÖàÂ≠ùÊï¨Áà∂ÊØçÁÑ∂ÂêéÊúâÂ§ö‰ΩôÁöÑÈí±ÂÜç‰π∞‰∏ìËæëÂ¶ÇÊûúËøòÊúâÂ§ö‰ΩôÁöÑÈí±ÂÜçÊù•Áúã... Ê≥™ [ËøòÊúâ, Êàë‰ª¨, sf9, ÁöÑ, ÊùéËææÊ∏ä, ‰ªñ, ËÆ©, Êàë‰ª¨, ÊúâÈí±, ÁöÑËØù, ÂÖà, Â≠ùÊï¨Áà∂... [-0.06892586111111111, -0.040252222222222224, ... 53666 ÂÖ®ÁêÉÁöÑÊåëÊàò ÂÖÅÊÇ≤ [ÂÖ®ÁêÉ, ÁöÑ, ÊåëÊàò] [-0.124204, -0.0818, -0.02715266666666667, 0.0... 53669 [Âä†Ê≤π] È≤úËä± [[, Âä†Ê≤π, ]] [0.049611333333333334, 0.011862, 0.10510733333... 53683 ÂÅáËÆæ‰∏çÁ¶ªÂ©öÔºÅÂêÑËøáÂêÑÁöÑÔºÅÂ•πÁöÑ‰∏öÂä°‰∏çÂÜçÁªô‰ªñÂá≠‰ªñÁöÑËÉΩÂäõÊó©ÊôöË¢´ËæûÈÄÄÁÑ∂ÂêéÊ≤°‰∫ÜÁîüËÆ°ÔºÅÊàøÂ≠êÁà±‰Ωè‰Ω†Â∞±‰ΩèÊ≤°‰∫∫ÁÆ°... doge [ÂÅáËÆæ, ‰∏ç, Á¶ªÂ©ö, ÔºÅ, ÂêÑËøá, ÂêÑ, ÁöÑ, ÔºÅ, Â•π, ÁöÑ, ‰∏öÂä°, ‰∏çÂÜç, Áªô, ‰ªñ... [-0.01563454166666667, -0.008308624999999997, ... 53685 Êàë‰∏çÈÖç ‰º§ÂøÉ [Êàë, ‰∏çÈÖç] [-0.363667, -0.25396850000000004, 0.011313, -0... 6638 rows √ó 4 columns 1data = data.dropna() 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji words vectors 1 Ëµ∞Â•Ω ÊÇ≤‰º§ [Ëµ∞, Â•Ω] [-0.047105999999999995, 0.23246850000000002, 0... 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà [ËàíÊúç, ‰∫Ü, Ôºå, ÁùÄÂ∞ºÂì•, Áªà‰∫é, Ê≠ª, ‰∫Ü] [-0.027774333333333328, -0.114836, 0.062758, 0... 9 ËÄÅ‰∫∫ÂÆ∂ÂÄºÂæóÊâÄÊúâ‰∫∫Â∞äÈáç Ëµû [ËÄÅ‰∫∫ÂÆ∂, ÂÄºÂæó, ÊâÄÊúâ‰∫∫, Â∞äÈáç] [-0.05153150000000001, 0.103688, 0.23323525, 0... 12 ËÄÅÁôæÂßìÁúüÂ•Ω ÂøÉ [ËÄÅÁôæÂßì, Áúü, Â•Ω] [-0.16598533333333335, 0.16545333333333334, 0.... 13 Â•Ω‰∫∫ Ëµû [Â•Ω‰∫∫] [-0.045179, 0.132102, 0.237468, 0.255355, -0.0... ... ... ... ... ... 53656 ËøòÊúâÊàë‰ª¨sf9ÁöÑÊùéËææÊ∏ä‰ªñËÆ©Êàë‰ª¨ÊúâÈí±ÁöÑËØùÂÖàÂ≠ùÊï¨Áà∂ÊØçÁÑ∂ÂêéÊúâÂ§ö‰ΩôÁöÑÈí±ÂÜç‰π∞‰∏ìËæëÂ¶ÇÊûúËøòÊúâÂ§ö‰ΩôÁöÑÈí±ÂÜçÊù•Áúã... Ê≥™ [ËøòÊúâ, Êàë‰ª¨, sf9, ÁöÑ, ÊùéËææÊ∏ä, ‰ªñ, ËÆ©, Êàë‰ª¨, ÊúâÈí±, ÁöÑËØù, ÂÖà, Â≠ùÊï¨Áà∂... [-0.06892586111111111, -0.040252222222222224, ... 53666 ÂÖ®ÁêÉÁöÑÊåëÊàò ÂÖÅÊÇ≤ [ÂÖ®ÁêÉ, ÁöÑ, ÊåëÊàò] [-0.124204, -0.0818, -0.02715266666666667, 0.0... 53669 [Âä†Ê≤π] È≤úËä± [[, Âä†Ê≤π, ]] [0.049611333333333334, 0.011862, 0.10510733333... 53683 ÂÅáËÆæ‰∏çÁ¶ªÂ©öÔºÅÂêÑËøáÂêÑÁöÑÔºÅÂ•πÁöÑ‰∏öÂä°‰∏çÂÜçÁªô‰ªñÂá≠‰ªñÁöÑËÉΩÂäõÊó©ÊôöË¢´ËæûÈÄÄÁÑ∂ÂêéÊ≤°‰∫ÜÁîüËÆ°ÔºÅÊàøÂ≠êÁà±‰Ωè‰Ω†Â∞±‰ΩèÊ≤°‰∫∫ÁÆ°... doge [ÂÅáËÆæ, ‰∏ç, Á¶ªÂ©ö, ÔºÅ, ÂêÑËøá, ÂêÑ, ÁöÑ, ÔºÅ, Â•π, ÁöÑ, ‰∏öÂä°, ‰∏çÂÜç, Áªô, ‰ªñ... [-0.01563454166666667, -0.008308624999999997, ... 53685 Êàë‰∏çÈÖç ‰º§ÂøÉ [Êàë, ‰∏çÈÖç] [-0.363667, -0.25396850000000004, 0.011313, -0... 6580 rows √ó 4 columns emojiÊò†Â∞Ñ‰∏∫Êï∞Â≠ó12345678910111213141516171819202122232425262728293031323334from sklearn.preprocessing import LabelEncoderclass NpEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, np.integer): return int(obj) elif isinstance(obj, np.floating): return float(obj) elif isinstance(obj, np.ndarray): return obj.tolist() else: return super(NpEncoder, self).default(obj)class EmojiMap: def generate(emoji_data): labelencoder = LabelEncoder() emoji_set = list(set(data.emoji)) x = labelencoder.fit_transform(emoji_set) emoji_to_index = dict(zip(emoji_set, x)) index_to_emoji = dict(zip(x, emoji_set)) return emoji_to_index, index_to_emoji def save(emoji_dictionary): fw = open('emoji_dictionary.json', 'w') data = json.dumps(emoji_dictionary, cls=NpEncoder) fw.write(data) fw.close() def read(filename): fr = open('emoji_dictionary.json', 'r') data = fr.read() emoji_dictionary = json.loads(data) fr.close() return emoji_dictionary 1emoji_to_index, index_to_emoji = EmojiMap.generate(data.emoji) 1len(emoji_to_index) 1043 ‰øùÂ≠òemoji_dictionary1#EmojiMap.save(emoji_to_index) 12emoji_vector = data.emoji.apply(lambda x: emoji_to_index[x])data['emoji_vector'] = emoji_vector &lt;ipython-input-52-2ca0af0b144e&gt;:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy data[&apos;emoji_vector&apos;] = emoji_vector 1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji words emoji_vector 1 Ëµ∞Â•Ω ÊÇ≤‰º§ [Ëµ∞, Â•Ω] 967 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà [ËàíÊúç, ‰∫Ü, Ôºå, ÁùÄÂ∞ºÂì•, Áªà‰∫é, Ê≠ª, ‰∫Ü] 1005 9 ËÄÅ‰∫∫ÂÆ∂ÂÄºÂæóÊâÄÊúâ‰∫∫Â∞äÈáç Ëµû [ËÄÅ‰∫∫ÂÆ∂, ÂÄºÂæó, ÊâÄÊúâ‰∫∫, Â∞äÈáç] 1023 12 ËÄÅÁôæÂßìÁúüÂ•Ω ÂøÉ [ËÄÅÁôæÂßì, Áúü, Â•Ω] 963 14 ËôΩÁÑ∂Ë°å‰∏∫ÁÇπËµûÔºå‰ΩÜÊòØËøòÊòØË°∑ÂøÉÂ∏åÊúõËÄÅ‰∫∫ÔºåÊääËá™Â∑±ËøáÂ•Ω‰∫ÜÔºåÊúâËÉΩÂäõÔºåÂÜçÂéªÂ∏ÆÂä©Âà´‰∫∫„ÄÇ ÊëäÊâã [ËôΩÁÑ∂, Ë°å‰∏∫, ÁÇπËµû, Ôºå, ‰ΩÜÊòØ, ËøòÊòØ, Ë°∑ÂøÉÂ∏åÊúõ, ËÄÅ‰∫∫, Ôºå, Êää, Ëá™Â∑±, Ëøá,... 977 ... ... ... ... ... 703298 ÊúüÂæÖËúúÊ°ÉÁ¨¨‰∫åÂ≠£ÔºåÊúüÂæÖÈÇì‰º¶ ÂøÉ [ÊúüÂæÖ, ËúúÊ°É, Á¨¨‰∫åÂ≠£, Ôºå, ÊúüÂæÖ, ÈÇì‰º¶] 963 703303 ÊúüÂæÖ‰º¶‰º¶ ÂøÉ [ÊúüÂæÖ, ‰º¶‰º¶] 963 703315 Â∑ùË•øÁúüÁöÑÊòØÈöè‰æø‰∏Ä‰∏™Âú∞ÊñπÈÉΩÊòØÈ£éÊôØ ÈºìÊéå [Â∑ùË•ø, ÁúüÁöÑ, ÊòØ, Èöè‰æø, ‰∏Ä‰∏™, Âú∞Êñπ, ÈÉΩ, ÊòØ, È£éÊôØ] 1041 703320 „ÅäÁñ≤„ÇåÊßò„Åß„Åó„Åü Ë∑™‰∫Ü [„Åä, Áñ≤, „Çå, Êßò, „Åß, „Åó, „Åü] 1025 703321 Â§™Âø´‰∫ÜÔºÅÔºÅÔºÅ Ëµû [Â§™Âø´, ‰∫Ü, ÔºÅ, ÔºÅ, ÔºÅ] 1023 203185 rows √ó 4 columns ÊñáÊú¨ËΩ¨ÂêëÈáè‰∏éÈ¢ÑÊµã12345678910def text_to_vector(txt): words = jieba.cut(txt) return ret_words_vector(words)def predict_emoji(txt, alg): X_test = text_to_vector(txt) X_test = np.array([X_test]) Y_pred = alg.predict(X_test) Y_pred = int(Y_pred) return index_to_emoji[Y_pred] ÊûÑÂª∫ËÆ≠ÁªÉÈõÜ12# shuffleÊï∞ÊçÆdata = data.sample(frac=1) 1data.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; Int64Index: 6580 entries, 30383 to 19525 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 text 6580 non-null object 1 emoji 6580 non-null object 2 words 6580 non-null object 3 vectors 6580 non-null object 4 emoji_vector 6580 non-null int64 dtypes: int64(1), object(4) memory usage: 308.4+ KB 12X_train = data.vectors.iloc[0: ]Y_train = np.array(data.emoji_vector.iloc[0: ]) 1X_train.shape, Y_train.shape ((6580,), (6580,)) 12345a = []for i in X_train: a.append(i)a = np.array(a)X_train = a 12345a = []for i in Y_train: a.append([i])a = np.array(a)Y_train = a SVM1from sklearn.svm import SVC, LinearSVC 12svm = SVC(C=100, gamma=10, probability=True)svm.fit(X_train, Y_train) 1predict_emoji('ËôΩÁÑ∂Ë°å‰∏∫ÁÇπËµûÔºå‰ΩÜÊòØËøòÊòØË°∑ÂøÉÂ∏åÊúõËÄÅ‰∫∫ÔºåÊääËá™Â∑±ËøáÂ•Ω‰∫ÜÔºåÊúâËÉΩÂäõÔºåÂÜçÂéªÂ∏ÆÂä©Âà´‰∫∫„ÄÇ', svm) &apos;ÂøÉ&apos; ÈöèÊú∫Ê£ÆÊûó1234567# Random Forestfrom sklearn.ensemble import RandomForestClassifierrandom_forest = RandomForestClassifier(max_depth=50)random_forest.fit(X_train, Y_train)random_forest.score(X_train, Y_train)acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)acc_random_forest 99.47 1predict_emoji('‰Ω†ÊòØ‰∏çÊòØÂÇª', random_forest) &apos;doge&apos; ‰øùÂ≠òÊ®°Âûã1234from sklearn.externals import joblibjoblib.dump(random_forest, 'random_forest.model')svm2 = joblib.load('random_forest.model') ‰ΩøÁî®kerasÊê≠Âª∫STMLÊ®°ÂûãÊûÑÂª∫FeatureÂíåLabe1data .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } text emoji 1 Ëµ∞Â•Ω ÊÇ≤‰º§ 6 ËàíÊúç‰∫ÜÔºåÁùÄÂ∞ºÂì•Áªà‰∫éÊ≠ª‰∫Ü Á¨ëÂìàÂìà 9 ËÄÅ‰∫∫ÂÆ∂ÂÄºÂæóÊâÄÊúâ‰∫∫Â∞äÈáç Ëµû 12 ËÄÅÁôæÂßìÁúüÂ•Ω ÂøÉ 14 ËôΩÁÑ∂Ë°å‰∏∫ÁÇπËµûÔºå‰ΩÜÊòØËøòÊòØË°∑ÂøÉÂ∏åÊúõËÄÅ‰∫∫ÔºåÊääËá™Â∑±ËøáÂ•Ω‰∫ÜÔºåÊúâËÉΩÂäõÔºåÂÜçÂéªÂ∏ÆÂä©Âà´‰∫∫„ÄÇ ÊëäÊâã ... ... ... 703298 ÊúüÂæÖËúúÊ°ÉÁ¨¨‰∫åÂ≠£ÔºåÊúüÂæÖÈÇì‰º¶ ÂøÉ 703303 ÊúüÂæÖ‰º¶‰º¶ ÂøÉ 703315 Â∑ùË•øÁúüÁöÑÊòØÈöè‰æø‰∏Ä‰∏™Âú∞ÊñπÈÉΩÊòØÈ£éÊôØ ÈºìÊéå 703320 „ÅäÁñ≤„ÇåÊßò„Åß„Åó„Åü Ë∑™‰∫Ü 703321 Â§™Âø´‰∫ÜÔºÅÔºÅÔºÅ Ëµû 203185 rows √ó 2 columns 1df = data 1max_len = df.words.map(lambda x: len(x)).max() 1max_len 215 Â∞Ü‰∏ÄÁªÑÂè•Â≠ê(Â≠óÁ¨¶‰∏≤)ËΩ¨Êç¢‰∏∫‰∏éÂè•Â≠ê‰∏≠ÁöÑÂçïËØçÂØπÂ∫îÁöÑÁ¥¢ÂºïÊï∞ÁªÑ„ÄÇËæìÂá∫ÂΩ¢Áä∂Â∫îËØ•ÊòØËøôÊ†∑ÁöÑÔºåÂÆÉÂèØ‰ª•Êèê‰æõÁªô‚Äô Embedding() ‚Äò 1234567891011121314151617181920212223242526272829303132333435def sentences_to_indices(X, word_to_index, max_len): """ Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences. The output shape should be such that it can be given to `Embedding()` Arguments: X -- array of sentences (strings), of shape (m, 1) word_to_index -- a dictionary containing the each word mapped to its index max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. Returns: X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len) """ m = X.shape[0] # number of training examples # Initialize X_indices as a numpy matrix of zeros and the correct shape (‚âà 1 line) X_indices = np.zeros((m, max_len)) for i in range(m): # loop over training examples # Convert the ith training sentence in lower case and split is into words. You should get a list of words. sentence_words = X[i] # Initialize j to 0 j = 0 # Loop over the words of sentence_words for w in sentence_words: # Set the (i,j)th entry of X_indices to the index of the correct word. X_indices[i, j] = word_to_index.get(w, 0) # Increment j to j + 1 j = j + 1 return X_indices 1X1_indices = sentences_to_indices(np.array(df.words), word_to_index, max_len) 1X_train = X1_indices 1Y_train = np.array(df.emoji_vector) Ê®°ÂûãÁªìÊûÑÂ¶Ç‰∏ãÂõæ 123456import numpy as npfrom keras.models import Modelfrom keras.layers import Dense, Input, Dropout, LSTM, Activationfrom keras.layers.embeddings import Embeddingfrom keras.preprocessing import sequencefrom keras.initializers import glorot_uniform Using TensorFlow backend. ÂÆûÁé∞pretrained_embedding_layer ()ÈúÄË¶ÅÊâßË°å‰ª•‰∏ãÊ≠•È™§: Â∞ÜÂµåÂÖ•Áü©ÈòµÂàùÂßãÂåñ‰∏∫ÂÖ∑ÊúâÊ≠£Á°ÆÂΩ¢Áä∂ÁöÑÈõ∂Êï∞ÁªÑ„ÄÇ Áî®‰ªé‚Äô word_to_vec_map ‚Äò‰∏≠ÊèêÂèñÁöÑÊâÄÊúâÂçïËØçÂµåÂÖ•Â°´ÂÖÖÂµåÂÖ•Áü©Èòµ„ÄÇ ÂÆö‰πâKerasÂµåÂÖ•Â±Ç„ÄÇ‰ΩøÁî®ÂµåÂÖ•()(https://keras.io/layers/embeddings/)„ÄÇÈÄöËøáÂú®Ë∞ÉÁî®‚ÄúEmbedding()‚ÄùÊó∂ËÆæÁΩÆ‚Äútrainable = False‚ÄùÔºåÁ°Æ‰øùËøô‰∏™Â±ÇÊòØ‰∏çÂèØËÆ≠ÁªÉÁöÑ„ÄÇÂ¶ÇÊûúÊÇ®ËÆæÁΩÆ‚Äô trainable = True ‚ÄòÔºåÈÇ£‰πàÂÆÉÂ∞ÜÂÖÅËÆ∏‰ºòÂåñÁÆóÊ≥ï‰øÆÊîπÂçïËØçembeddingsÁöÑÂÄº„ÄÇ ËÆæÂµåÂÖ•ÊùÉÈáçÁ≠â‰∫éÂµåÂÖ•Áü©Èòµ 12345678910111213141516171819202122232425262728293031323334# GRADED FUNCTION: È¢ÑÂ§ÑÁêÜ‰∏Ä‰∏™embeddingÂ±Çdef pretrained_embedding_layer(word_to_vec_map, word_to_index): """ ÂàõÂª∫‰∏Ä‰∏™ Keras Embedding() Â±Ç Arguments: word_to_vec_map -- dictionary mapping words to their GloVe vector representation. word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words) Returns: embedding_layer -- pretrained layer Keras instance """ vocab_len = len(word_to_index) + 1 # Â¢ûÂä†‰∏ÄÂ±Ç emb_dim = word_to_vec_map["Êàë"].shape[0] # ÈªòËÆ§ÁöÑÂêëÈáèÁª¥Â∫¶ # Â∞ÜÂµåÂÖ•Áü©ÈòµÂàùÂßãÂåñ‰∏∫‰∏Ä‰∏™ÂΩ¢Áä∂‰∏∫Èõ∂ÁöÑnumpyÊï∞ÁªÑ(vocab_lenÔºåÂçïËØçÂêëÈáèÁöÑÁª¥Êï∞= emb_dim) emb_matrix = np.zeros((vocab_len, emb_dim)) # Â∞ÜÂµåÂÖ•Áü©ÈòµÁöÑÊØè‰∏ÄË°å‚Äúindex‚ÄùËÆæ‰∏∫ËØçÊ±áË°®‰∏≠‚Äúindex‚ÄùÁ¨¨Âõõ‰∏™ÂçïËØçÁöÑÂçïËØçÂêëÈáèË°®Á§∫ for word, index in word_to_index.items(): emb_matrix[index, :] = word_to_vec_map[word] # ÂÆö‰πâKerasÂµåÂÖ•Â±Ç‰∏éÊ≠£Á°ÆÁöÑËæìÂá∫/ËæìÂÖ•Â§ßÂ∞èÔºå‰ΩøÂÖ∂ÂèØËÆ≠ÁªÉ„ÄÇ‰ΩøÁî®ÂµåÂÖ•(‚Ä¶)„ÄÇËÆæÁΩÆtrainable=False„ÄÇ embedding_layer = Embedding(vocab_len, emb_dim, trainable=False) # ÊûÑÂª∫ÂµåÂÖ•Â±ÇÔºåÂú®ËÆæÁΩÆÂµåÂÖ•Â±ÇÊùÉÈáç‰πãÂâçÈúÄË¶Å„ÄÇ‰∏çË¶Å‰øÆÊîπ‚ÄúNone‚Äù„ÄÇ embedding_layer.build((None,)) # Â∞ÜÂµåÂÖ•Â±ÇÁöÑÊùÉÈáçËÆæÁΩÆ‰∏∫ÂµåÂÖ•Áü©Èòµ„ÄÇÁé∞Âú®ÊòØÈ¢ÑÂÖàËÆ≠ÁªÉÂ•ΩÁöÑ„ÄÇ embedding_layer.set_weights([emb_matrix]) return embedding_layer 12embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)print("weights[0][1][3] =", embedding_layer.get_weights()[0][1][3]) weights[0][1][3] = 0.475248 123456789101112131415161718192021222324252627282930313233343536373839404142def Emojify(input_shape, word_to_vec_map, word_to_index): """ Function creating the Emojify-v2 model's graph. Arguments: input_shape -- shape of the input, usually (max_len,) word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation word_to_index -- dictionary mapping from words to their indices in the vocabulary Returns: model -- a model instance in Keras """ ### START CODE HERE ### # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices). sentence_indices = Input(shape=input_shape, dtype="int32") # Create the embedding layer pretrained with GloVe Vectors (‚âà1 line) embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index) # Propagate sentence_indices through your embedding layer, you get back the embeddings embeddings = embedding_layer(sentence_indices) # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state # Be careful, the returned output should be a batch of sequences. X = LSTM(units=128, return_sequences=True)(embeddings) # Add dropout with a probability of 0.5 X = Dropout(0.5)(X) # Propagate X trough another LSTM layer with 128-dimensional hidden state # Be careful, the returned output should be a single hidden state, not a batch of sequences. X = LSTM(units=128, return_sequences=False)(X) # Add dropout with a probability of 0.5 X = Dropout(0.5)(X) # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors. X = Dense(1)(X) # Add a softmax activation X = Activation("softmax")(X) # Create Model instance which converts sentence_indices into X. model = Model(inputs=sentence_indices, outputs=X) return model 123maxLen = len(max(X_train, key=len))model = Emojify((maxLen,), word_to_vec_map, word_to_index)model.summary() 1model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) 1X_train[0], Y_train[0] (array([170081., 75835., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 967) 1model.fit(X_train, Y_train, epochs = 5, batch_size = 32, shuffle=True) Epoch 1/5 33632/203185 [===&gt;..........................] - ETA: 32:43 - loss: -13765.9092 - accuracy: 0.0000e+00 È¢ÑÊµã12345x = list(jieba.cut('‰ªäÂ§©Â§©Ê∞î‰∏çÈîô'))x = np.array([x])x = sentences_to_indices(x, word_to_index, maxLen)p = model.predict(x)index_to_emoji[int(p)] ÊÄªÁªìÈöèÊú∫Ê£ÆÊûóÊïàÊûúÊúÄÂ•ΩÔºå‰ΩÜÊòØËÆ≠ÁªÉÈÄüÂ∫¶ÊúÄÊÖ¢ÔºåÂç†Áî®ÂÜÖÂ≠òÂ§™Â§ßÔºåSVMÁ®çÂø´ÔºåÂç†Áî®Á©∫Èó¥Â∞è„ÄÇ]]></content>
      <categories>
        <category>LSTM</category>
      </categories>
      <tags>
        <tag>Ê∑±Â∫¶Â≠¶‰π†</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂçÅ‰∏ÄÔºâ]]></title>
    <url>%2F2020%2F05%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[‰ΩøÁî®AprioriÁÆóÊ≥ïËøõË°åÂÖ≥ËÅîÂàÜÊûêÂú®Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏≠ÂØªÊâæÁâ©ÂìÅÁöÑÈöêÂê´ÂÖ≥Á≥ªË¢´Áß∞‰ΩúÂÖ≥ËÅîÂàÜÊûê(association analysis)ÊàñËÄÖÂÖ≥ËÅîËßÑÂàôÂ≠¶‰π†(association rule learning)Ôºå‰æãÂ¶ÇÂïÜÂìÅÁöÑÂÆöÂêëÊé®Ëçê„ÄÇ ÂÖ≥ËÅîÂàÜÊûêApriorÁÆóÊ≥ï ‰ºòÁÇπÔºöÊòìÁºñÁ†Å‰∫ãÂÖà Áº∫ÁÇπÔºöÂú®Â§ßÊï∞ÊçÆÈõÜ‰∏äÂèØËÉΩËæÉÊÖ¢ ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÊàñÊ†áÁß∞ÂûãÊï∞ÊçÆ ÂÖ≥ËÅîÂàÜÊûêÊòØ‰∏ÄÁßçÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏≠ÂØªÊâæÊúâË∂£ÂÖ≥Á≥ªÁöÑ‰ªªÂä°„ÄÇËøô‰∫õÂÖ≥Á≥ªÂèØ‰ª•Êúâ‰∏§ÁßçÂΩ¢ÂºèÔºöÈ¢ëÁπÅÈ°πÈõÜÊàñËÄÖÂÖ≥ËÅîËßÑÂàô„ÄÇÈ¢ëÁπÅÈ°πÈõÜÔºàfrequent item setsÔºâÊòØÁªèÂ∏∏Âá∫Áé∞Âú®‰∏ÄÂùóÁöÑÁâ©ÂìÅÁöÑÈõÜÂêàÔºåÂÖ≥ËÅîËßÑÂàôÔºàassociation rulesÔºâÊöóÁ§∫‰∏§ÁßçÁâ©ÂìÅ‰πãÈó¥ÂèØËÉΩÂ≠òÂú®ÂæàÂº∫ÁöÑÂÖ≥Á≥ª„ÄÇ È¢ëÁπÅÈ°πÈõÜÊòØÊåáÈÇ£‰∫õÁªèÂ∏∏Âá∫Áé∞Âú®‰∏ÄËµ∑ÁöÑÁâ©ÂìÅÈõÜÂêàÔºàÂï§ÈÖíÂíåÂ∞øÂ∏ÉÔºâ ‰∏Ä‰∏™È°πÈõÜÁöÑÊîØÊåÅÂ∫¶ÔºàsupportÔºâË¢´ÂÆö‰πâ‰∏∫Êï∞ÊçÆÈõÜ‰∏≠ÂåÖÂê´ËØ•È°πÈõÜÁöÑËÆ∞ÂΩïÊâÄÂç†ÊØî‰æã„ÄÇÊîØÊåÅÂ∫¶ÊòØÈíàÂØπÈ°πÈõÜÊù•ËØ¥ÁöÑÔºåÂõ†Ê≠§ÂèØ‰ª•ÂÆö‰πâ‰∏Ä‰∏™ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÔºåËÄåÂè™‰øùÁïôÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÁöÑÈ°πÈõÜ„ÄÇ ÂèØ‰ø°Â∫¶ÊàñÁΩÆ‰ø°Â∫¶ÔºàconfidenceÔºâÊòØÈíàÂØπ‰∏ÄÊù°ÂÖ≥ËÅîËßÑÂàôÊù•ÂÆö‰πâÁöÑ„ÄÇ ÊîØÊåÅÂ∫¶ÂíåÂèØ‰ø°Â∫¶ÊòØÁî®Êù•ÈáèÂåñÂÖ≥ËÅîÂàÜÊûêÊòØÂê¶ÊàêÂäüÁöÑÊñπÊ≥ï„ÄÇ AprioriÂéüÁêÜAprioriÁÆóÊ≥ïÁöÑ‰∏ÄËà¨ËøáÁ®ã Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆ ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÊï∞ÊçÆÔºö‰ΩøÁî®aprioriÁÆóÊ≥ïÊù•ÊâæÂà∞È¢ëÁπÅÈ°πÈõÜ ÊµãËØïÁÆóÊ≥ïÔºö‰∏çÈúÄË¶ÅÊµãËØïËøáÁ®ã ‰ΩøÁî®ÁÆóÊ≥ïÔºöÁî®Êù•ÂèëÁé∞È¢ëÁπÅÈ°πÈõÜ‰ª•ÂèäÁâ©ÂìÅ‰πãÈó¥ÁöÑÂÖ≥ËÅîËßÑÂàô AprioriÂéüÁêÜÔºåÂ¶ÇÊûúÊüê‰∏™È°πÈõÜÊòØÈ¢ëÁπÅÁöÑÔºåÈÇ£‰πà‰ªñÁöÑÊâÄÊúâÂ≠êÈõÜ‰πüÊòØÈ¢ëÁπÅÁöÑ„ÄÇÂØπ‰∫é‰∏ãÂõæÁöÑ‰æãÂ≠êÊÑèÂë≥ÁùÄÔºå{0, 1}ÊòØÈ¢ëÁπÅÁöÑÔºåÈÇ£‰πà{0}Ôºå{1}‰πüÊòØÈ¢ëÁπÅÁöÑÔºåËøô‰∏™ÂéüÁêÜÂèçËøáÊù•ÁúãÂ∞±ÊòØÔºåÂ¶ÇÊûúËØ¥‰∏Ä‰∏™È°πÈõÜÊòØÈ¢ëÁπÅÁöÑÔºåÈÇ£‰πàÂÆÉÁöÑÊâÄÊúâË∂ÖÈõÜ‰πüÊòØÈ¢ëÁπÅÁöÑ„ÄÇ ‰ΩøÁî®AprioriÁÆóÊ≥ïÊù•ÂèëÁé∞È¢ëÁπÅÈõÜAprioriÁÆóÊ≥ïÁöÑ‰∏§‰∏™ËæìÂÖ•ÂèÇÊï∞ÂàÜÂà´ÊòØÊúÄÂ∞èÊîØÊåÅÂ∫¶ÂíåÊï∞ÊçÆÈõÜ„ÄÇËØ•ÁÆóÊ≥ïÈ¶ñÂÖà‰ºöÁîüÊàêÊâÄÊúâÂçï‰∏™Áâ©ÂìÅÁöÑÈ°πÈõÜÂàóË°®„ÄÇÊé•ÁùÄÊâ´Êèè‰∫§ÊòìËÆ∞ÂΩïÊù•Êü•ÁúãÂì™‰∫õÈ°πÈõÜÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶Ë¶ÅÊ±ÇÔºåÈÇ£‰∫õ‰∏çÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÁöÑÈõÜÂêà‰ºöË¢´ÂéªÊéâ„ÄÇÁÑ∂ÂêéÂØπÂâ©‰∏ãÁöÑÈõÜÂêàËøõË°åÁªÑÂêàÁîüÊàêÂåÖÂê´‰∏§‰∏™ÂÖÉÁ¥†ÁöÑÈ°πÈõÜ„ÄÇÊé•‰∏ãÈáçÊñ∞Êâ´Êèè‰∫§ÊòìËÆ∞ÂΩïÔºåÂéªÊéâ‰∏çÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÁöÑÈ°πÈõÜ„ÄÇÈáçÂ§çËØ•ËøáÁ®ãÁõ¥Âà∞ÊâÄÊúâÈ°πÈõÜÈÉΩË¢´ÂéªÊéâ„ÄÇ ÁîüÊàêÂÄôÈÄâÈõÜÂàõÂª∫‰∏Ä‰∏™Áî®‰∫éÊûÑÂª∫ÂàùÂßãÈõÜÂêàÁöÑÂáΩÊï∞ÔºåÂíå‰∏Ä‰∏™ÈÄöËøáÊâ´ÊèèÊï∞ÊçÆÈõÜ‰ª•ÂØªÊâæ‰∫§ÊòìËÆ∞ÂΩïÂ≠êÈõÜÁöÑÂáΩÊï∞„ÄÇ Êï∞ÊçÆÈõÜÊâ´ÊèèÁöÑ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö ÂØπÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØèÊù°‰∫§ÊòìËÆ∞ÂΩïtran ÂØπÊØè‰∏™ÂÄôÈÄâÈ°πÈõÜcan: Ê£ÄÊü•‰∏Ä‰∏ãcanÊòØÂê¶ÊòØtranÁöÑÂ≠êÈõÜ: Â¶ÇÊûúÊòØÔºåÂàôÂ¢ûÂä†canÁöÑËÆ°Êï∞ÂÄº ÂØπÊØè‰∏™ÂÄôÈÄâÈõÜÔºö Â¶ÇÊûúÂÖ∂ÊîØÊåÅÂ∫¶‰∏ç‰Ωé‰∫éÊúÄÂ∞èÂÄºÔºåÂàô‰øùÁïôËØ•È°πÈõÜ ËøîÂõûÊâÄÊúâÈ¢ëÁπÅÈ°πÈõÜÂàóË°® 12345678910111213141516171819202122232425262728293031def loadDataSet(): return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]def createC1(dataSet): C1 = [] for transaction in dataSet: for item in transaction: if not [item] in C1: C1.append([item]) C1.sort() ret = map(frozenset, C1) # ËøîÂõû‰∏Ä‰∏™ÂÜªÁªìÁöÑÈõÜÂêà return list(ret)def scanD(D, Ck, minSupport): ssCnt = &#123;&#125; for tid in D: for can in Ck: if can.issubset(tid): if not can in ssCnt: ssCnt[can] = 1 else: ssCnt[can] += 1 numItems = float(len(D)) retList = [] supportData = &#123;&#125; for key in ssCnt: support = ssCnt[key]/numItems if support &gt;= minSupport: retList.insert(0, key) supportData[key] = support return retList, supportData C1ÊòØÂ§ßÂ∞è‰∏∫1ÁöÑÊâÄÊúâÂÄôÈÄâÈ°πÈõÜÁöÑÈõÜÂêà„ÄÇ L1ÊòØÊª°Ë∂≥ÊúÄ‰ΩéË¶ÅÊ±ÇÁöÑÈ°πÈõÜÊûÑÊàêÁöÑÈõÜÂêàL1„ÄÇ createC1()ÂáΩÊï∞Â∞ÜÊûÑÂª∫Á¨¨‰∏Ä‰∏™ÂÄôÈÄâÈ°πÈõÜÁöÑÂàóË°®C1ÔºåscanD()Êúâ‰∏â‰∏™ÂèÇÊï∞ÔºåÂàÜÂà´ÊòØÊï∞ÊçÆÈõÜÔºåÂÄôÈÄâÈ°πÈõÜÂàóË°®CkÔºå‰ª•ÂèäÊÑüÂÖ¥Ë∂£È°πÈõÜÁöÑÊúÄÂ∞èÊîØÊåÅÂ∫¶minSupport„ÄÇ 12dataSet = loadDataSet()dataSet [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]] 12C1 = createC1(dataSet)C1 [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})] 12D = list(map(set, dataSet))D [{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}] 12L1, suppData0 = scanD(D, C1, 0.5)suppData0, L1 ({frozenset({1}): 0.5, frozenset({3}): 0.75, frozenset({4}): 0.25, frozenset({2}): 0.75, frozenset({5}): 0.75}, [frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]) ‰∏äËø∞4‰∏™È°πÈõÜÊûÑÊàê‰∫ÜL1ÂàóË°®ÔºåËØ•ÂàóË°®‰∏≠ÁöÑÊØè‰∏™ÂçïÁâ©ÂìÅÈ°πÈõÜËá≥Â∞ëÂá∫Áé∞Âú®50%‰ª•‰∏äÁöÑËÆ∞ÂΩï‰∏≠„ÄÇÁî±‰∫éÁâ©ÂìÅ4Âπ∂Ê≤°ÊúâËææÂà∞ÊúÄÂ∞èÊîØÊåÅÂ∫¶ÔºåÊâÄ‰ª•‰∏çÂú®L1‰∏≠„ÄÇ ÁªÑÁªáÂÆåÊï¥ÁöÑAprioriÁÆóÊ≥ïÊï¥‰∏™AprioriÁÆóÊ≥ïÁöÑ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö ÂΩìÈõÜÂêà‰∏≠È°πÁöÑ‰∏™Êï∞Â§ß‰∫é0Êó∂ ÊûÑÂª∫‰∏Ä‰∏™k‰∏™È°πÁõÆÁªÑÊàêÁöÑÂÄôÈÄâÈ°πÈõÜÁöÑÂàóË°® Ê£ÄÊü•Êï∞ÊçÆ‰ª•Á°ÆËÆ§ÊØè‰∏™È°πÈõÜÈÉΩÊòØÈ¢ëÁπÅÁöÑ ‰øùÁïôÈ¢ëÁπÅÈ°πÈõÜÂπ∂ÊûÑÂª∫k+1È°πÁªÑÊàêÁöÑÂÄôÈÄâÈ°πÁöÑÂàóË°® 12345678910111213141516171819202122232425262728def aprioriGen(Lk, k): retList = [] lenLk = len(Lk) for i in range(lenLk): for j in range(i+1, lenLk): L1 = list(Lk[i])[: k-2] L2 = list(Lk[j])[: k-2] L1.sort() L2.sort() if L2 == L2: retList.append(Lk[i] | Lk[j]) return retListdef apriori(dataSet, minSupport=0.5): C1 = createC1(dataSet) D = map(set, dataSet) D = list(D) L1, supportData = scanD(D, C1, minSupport) L = [L1] k = 2 while (len(L[k-2]) &gt; 0): Ck = aprioriGen(L[k-2], k) Lk, supK = scanD(D, Ck, minSupport) supportData.update(supK) L.append(Lk) k += 1 return L, supportData 12L, suppData = apriori(dataSet)L [[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})], [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})], [frozenset({2, 3, 5})], []] 1L[0] [frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})] 1L[1] [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})] 1L[2] [frozenset({2, 3, 5})] 1L[3] [] ÊØè‰∏™È°πÈõÜÈÉΩÊòØÂú®apriori()‰∏≠Ë∞ÉÁî®ÂáΩÊï∞aprioriGen()Êù•ÁîüÊàêÁöÑ„ÄÇ 1aprioriGen(L[0], 2) [frozenset({2, 5}), frozenset({3, 5}), frozenset({1, 5}), frozenset({2, 3}), frozenset({1, 2}), frozenset({1, 3})] 12L, suppData = apriori(dataSet, minSupport=0.7)L [[frozenset({5}), frozenset({2}), frozenset({3})], [frozenset({2, 5})], []] ÂèòÈáèsuppDataÊòØ‰∏Ä‰∏™Â≠óÂÖ∏ÔºåÂÆÉÂåÖÂê´Êàë‰ª¨È°πÈõÜÁöÑÊîØÊåÅÂ∫¶ÂÄº„ÄÇ ‰ªéÈ¢ëÁπÅÈ°πÈõÜ‰∏≠ÊåñÊéòÂÖ≥ËÅîËßÑÂàôË¶ÅÊâæÂà∞ÂÖ≥ËÅîËßÑÂàôÔºåÊàë‰ª¨È¶ñÂÖà‰ªé‰∏Ä‰∏™È¢ëÁπÅÈ°πÈõÜÂºÄÂßã„ÄÇÊàë‰ª¨Áü•ÈÅìÈõÜÂêà‰∏≠ÁöÑÂÖÉÁ¥†ÊòØ‰∏çÈáçÂ§çÁöÑÔºå‰ΩÜÊàë‰ª¨ÊÉ≥Áü•ÈÅìÂü∫‰∫éËøô‰∫õÂÖÉÁ¥†ËÉΩÂê¶Ëé∑ÂæóÂÖ∂‰ªñÂÜÖÂÆπ„ÄÇÊüê‰∏™ÂÖÉÁ¥†ÊàñËÄÖÊüê‰∏™ÂÖÉÁ¥†ÈõÜÂêàÂèØËÉΩ‰ºöÊé®ÂØºÂá∫Âè¶‰∏Ä‰∏™ÂÖÉÁ¥†„ÄÇ ÂÖ≥ËÅîËßÑÂàôÁöÑÈáèÂåñÊåáÊ†áÊòØÔºåÂèØ‰ø°Â∫¶„ÄÇ‰∏ÄÊù°ËßÑÂàôP-&gt;HÁöÑÂèØ‰ø°Â∫¶ÂÆö‰πâ‰∏∫support(P|H)/support(P)„ÄÇ ÂØπ‰∫éÈ¢ëÁπÅÈ°πÈõÜ{0Ôºå1Ôºå2Ôºå3}ÁöÑÂÖ≥ËÅîËßÑÂàôÁΩëÁªúÁ§∫ÊÑèÂõæ„ÄÇÈò¥ÂΩ±Âå∫ÂüüÁªôÂá∫ÁöÑÊòØ‰ΩéÂèØ‰ø°Â∫¶ÁöÑËßÑÂàô„ÄÇÂ¶ÇÊûúÂèëÁé∞0Ôºå1Ôºå2‚Äî&gt;3ÊòØ‰∏ÄÊù°‰ΩéÂèØ‰ø°Â∫¶ËßÑÂàôÔºåÈÇ£‰πàÊâÄÊúâÂÖ∂‰ª•3‰Ωú‰∏∫Âêé‰ª∂ÁöÑËßÑÂàôÂèØ‰ø°Â∫¶‰πü‰ºöËæÉ‰Ωé„ÄÇ 12345678910111213141516171819202122232425262728def generateRules(L, supportData, minConf=0.7): bigRuleList = [] for i in range(1, len(L)): for freqSet in L[i]: H1 = [frozenset([item]) for item in freqSet] if (i &gt; 1): rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf) else: calcConf(freqSet, H1, supportData, bigRuleList, minConf) return bigRuleList def calcConf(freqSet, H, supportData, brl, minConf=0.7): prunedH = [] for conseq in H: conf = supportData[freqSet]/supportData[freqSet-conseq] if conf &gt;= minConf: print(freqSet-conseq,'--&gt;',conseq,'conf:',conf) brl.append((freqSet-conseq, conseq, conf)) prunedH.append(conseq) return prunedHdef rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7): m = len(H[0]) if (len(freqSet) &gt; (m + 1)): Hmp1 = aprioriGen(H, m+1) Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf) if (len(Hmp1) &gt; 1): rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf) 12L, suppData=apriori(dataSet, minSupport=0.5)rules = generateRules(L, suppData, minConf=0.7) frozenset({5}) --&gt; frozenset({2}) conf: 1.0 frozenset({2}) --&gt; frozenset({5}) conf: 1.0 frozenset({1}) --&gt; frozenset({3}) conf: 1.0 frozenset({5}) --&gt; frozenset({2, 3}) conf: 2.0 frozenset({3}) --&gt; frozenset({2, 5}) conf: 2.0 frozenset({2}) --&gt; frozenset({3, 5}) conf: 2.0 1rules = generateRules(L, suppData, minConf=0.5) frozenset({3}) --&gt; frozenset({2}) conf: 0.6666666666666666 frozenset({2}) --&gt; frozenset({3}) conf: 0.6666666666666666 frozenset({5}) --&gt; frozenset({3}) conf: 0.6666666666666666 frozenset({3}) --&gt; frozenset({5}) conf: 0.6666666666666666 frozenset({5}) --&gt; frozenset({2}) conf: 1.0 frozenset({2}) --&gt; frozenset({5}) conf: 1.0 frozenset({3}) --&gt; frozenset({1}) conf: 0.6666666666666666 frozenset({1}) --&gt; frozenset({3}) conf: 1.0 frozenset({5}) --&gt; frozenset({2, 3}) conf: 2.0 frozenset({3}) --&gt; frozenset({2, 5}) conf: 2.0 frozenset({2}) --&gt; frozenset({3, 5}) conf: 2.0 ‰∏ÄÊó¶Èôç‰ΩéÂèØ‰ø°Â∫¶ÈòàÂÄºÔºåÂ∞±ÂèØ‰ª•Ëé∑ÂæóÊõ¥Â§öÁöÑËßÑÂàô„ÄÇ ÂÆû‰æãÔºöÂèëÁé∞ÂõΩ‰ºöÊäïÁ•®‰∏≠ÁöÑÊ®°Âºè Êî∂ÈõÜÊï∞ÊçÆÔºö‰ΩøÁî®votesmartÊ®°ÂùóËÆøÈóÆÊäïÁ•®Á∫™ÂΩï ÂáÜÂ§áÊï∞ÊçÆÔºöÊûÑÈÄ†‰∏Ä‰∏™ÂáΩÊï∞Êù•Â∞ÜÊäïÁ•®ËΩ¨Âåñ‰∏∫‰∏Ä‰∏≤‰∫§ÊòìËÆ∞ÂΩï ÂàÜÊûêÊï∞ÊçÆÔºöÊü•ÁúãÂáÜÂ§áÁöÑÊï∞ÊçÆ‰ª•Á°Æ‰øùÂÖ∂Ê≠£Á°ÆÊÄß ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰ΩøÁî®aprioi()ÂíågenerateRules()ÂáΩÊï∞Êù•ÂèëÁé∞ÊäïÁ•®Á∫™ÂΩï‰∏≠ÁöÑÊúâË∂£‰ø°ÊÅØ ÊµãËØïÁÆóÊ≥ïÔºö‰∏çÈÄÇÁî®ÔºåÂç≥Ê≤°ÊúâÊµãËØïËøáÁ®ã ‰ΩøÁî®ÁÆóÊ≥ï ÂÆû‰æãÔºöÂèëÁé∞ÊØíËòëËèáÁöÑÁõ∏‰ººÁâπÂæÅ1mushDatSet = [line.split() for line in open('MLiA_SourceCode/Ch11/mushroom.dat').readlines()] Á¨¨‰∏Ä‰∏™ÁâπÂæÅË°®Á§∫ÊúâÊØíÊàñËÄÖÂèØ‰ΩøÁî®ÔºåÊúâÊØí‰∏∫2ÔºåÂèØÈ£üÁî®‰∏∫1Ôºå‰∏ã‰∏™ÁâπÂæÅÊòØËòëËèá‰ºûÁöÑÂΩ¢Áä∂ÔºåÊúâÂÖ≠ÁßçÂèØËÉΩÁöÑÂÄº„ÄÇ‰∏∫‰∫ÜÊâæÂà∞ÊØíËòëËèá‰∏≠Â≠òÂú®ÁöÑÂÖ¨ÂÖ±ÁâπÂæÅÔºåÂèØ‰ª•ËøêÁî®AprioriÁÆóÊ≥ïÊù•ÂØªÊâæÁâπÂæÅÂÄº‰∏∫2ÁöÑÈ¢ëÁπÅÈ°πÈõÜ„ÄÇ ‰ΩøÁî® Apriori Â∑•ÂÖ∑ÂåÖ 12from efficient_apriori import aprioriL, suppData = apriori(mushDatSet, min_support=0.3, min_confidence=1) 123for item in L[2]: if '2' in item: print(item) (&apos;2&apos;, &apos;23&apos;) (&apos;2&apos;, &apos;34&apos;) (&apos;2&apos;, &apos;36&apos;) (&apos;2&apos;, &apos;39&apos;) (&apos;2&apos;, &apos;59&apos;) (&apos;2&apos;, &apos;63&apos;) (&apos;2&apos;, &apos;67&apos;) (&apos;2&apos;, &apos;76&apos;) (&apos;2&apos;, &apos;85&apos;) (&apos;2&apos;, &apos;86&apos;) (&apos;2&apos;, &apos;90&apos;) (&apos;2&apos;, &apos;93&apos;) (&apos;2&apos;, &apos;28&apos;) (&apos;2&apos;, &apos;53&apos;) ÊÄªÁªìÂÖ≥ËÅîÂàÜÊûêÊòØÁî®‰∫éÂèëÁé∞Â§ßÊï∞ÊçÆÈõÜ‰∏≠ÂÖÉÁ¥†Èó¥ÊúâË∂£ÂÖ≥Á≥ªÁöÑ‰∏Ä‰∏™Â∑•ÂÖ∑ÈõÜÔºåÂèØ‰ª•ÈááÁî®‰∏§ÁßçÊñπÂºèÊù•ÈáèÂåñËøô‰∫õÂÖ≥Á≥ª„ÄÇÁ¨¨‰∏ÄÁßçÊñπÂºèÊòØÈ¢ëÁπÅÈ°πÈõÜÔºåÂÆÉ‰ºöÁªôÂá∫ÁªèÂ∏∏Âú®‰∏ÄËµ∑Âá∫Áé∞ÁöÑÂÖÉÁ¥†È°π„ÄÇÁ¨¨‰∫åÁßçÊñπÂºèÊòØÂÖ≥ËÅîËßÑÂàô„ÄÇ AprioriÂéüÁêÜÊòØËØ¥Â¶ÇÊûú‰∏Ä‰∏™ÂÖÉÁ¥†È°πÊòØ‰∏çÈ¢ëÁπÅÁöÑÔºåÈÇ£‰πàËøô‰∫õÂåÖÂê´ËØ•ÂÖÉÁ¥†ÁöÑË∂ÖÈõÜ‰πüÊòØ‰∏çÈ¢ëÁπÅÁöÑ„ÄÇAprioriÁÆóÊ≥ï‰ªéÂçïÂÖÉÁ¥†È°πÈõÜÂºÄÂßãÔºåÈÄöËøáÁªÑÂêàÊª°Ë∂≥ÊúÄÂ∞èÊîØÊåÅÂ∫¶Ë¶ÅÊ±ÇÁöÑÈ°πÈõÜÊù•ÂΩ¢ÊàêÊõ¥Â§ßÁöÑÈõÜÂêà„ÄÇÊîØÊåÅÂ∫¶Áî®Êù•Áã¨Á´ã‰∏Ä‰∏™ÈõÜÂêàÂú®ÂéüÂßãÊï∞ÊçÆ‰∏≠Âá∫Áé∞ÁöÑÈ¢ëÁéá„ÄÇ ÊØèÊ¨°Â¢ûÂä†È¢ëÁπÅÈ°πÈõÜÁöÑÂ§ßÂ∞èÔºåAprioriÁÆóÊ≥ïÈÉΩ‰ºöÈáçÊñ∞Êâ´ÊèèÊï¥‰∏™Êï∞ÊçÆÈõÜ„ÄÇÂΩìÊï∞ÊçÆÈõÜÂæàÂ§ßÊó∂ÔºåËøô‰ºöÊòæËëóÈôç‰ΩéÈ¢ëÁπÅÈ°πÈõÜÂèëÁé∞ÁöÑÈÄüÂ∫¶„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>ÂÖ≥ËÅîÂàÜÊûê</tag>
        <tag>AprioriÁÆóÊ≥ï</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂçÅÔºâ]]></title>
    <url>%2F2020%2F05%2F15%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Âà©Áî®K-ÂùáÂÄºËÅöÁ±ªÁÆóÊ≥ïÂØπÊú™Ê†áÊ≥®Êï∞ÊçÆÂàÜÁªÑËÅöÁ±ªÊòØ‰∏ÄÁßçÊó†ÁõëÁù£ÁöÑÂ≠¶‰π†ÔºåÂÆÉÂ∞ÜÁõ∏‰ººÁöÑÂØπË±°ÂΩíÂà∞Âêå‰∏Ä‰∏™Á∞á‰∏≠ÔºåÂÆÉÊúâÁÇπÂÉèÂÖ®Ëá™Âä®ÂàÜÁ±ª„ÄÇËÅöÁ±ªÊñπÊ≥ïÂá†‰πéÂèØ‰ª•Â∫îÁî®‰∫éÊâÄÊúâÂØπË±°ÔºåÁ∞áÂÜÖÁöÑÂØπË±°Ë∂äÁõ∏‰ººÔºåËÅöÁ±ªÁöÑÊïàÊûúË∂äÂ•Ω„ÄÇK-meansËÅöÁ±ªÁÆóÊ≥ïÔºåÂÆÉÂèØ‰ª•ÂèëÁé∞k‰∏™‰∏çÂêåÁöÑÁ∞áÔºå‰∏îÊØè‰∏™Á∞á‰∏≠ÂøÉÈááÁî®Á∞á‰∏≠ÊâÄÂê´ÂÄºÁöÑÂùáÂÄºËÆ°ÁÆóËÄåÊàê„ÄÇ Á∞áËØÜÂà´Ôºàcluster identificationÔºâ„ÄÇÁ∞áËØÜÂà´ÁªôÂá∫ËÅöÁ±ªÁªìÊûúÁöÑÂê´‰πâ„ÄÇÂÅáÂÆöÊúâ‰∏Ä‰∫õÊï∞ÊçÆÔºåÁé∞Âú®Â∞ÜÁõ∏‰ººÊï∞ÊçÆÂΩíÂà∞‰∏ÄËµ∑ÔºåÁ∞áËØÜÂà´‰ºöÂëäËØâÊàë‰ª¨Ëøô‰∫õÁ∞áÂà∞Â∫ïÈÉΩÊòØ‰∫õ‰ªÄ‰πà„ÄÇËÅöÁ±ª‰∏éÂàÜÁ±ªÁöÑÊúÄÂ§ß‰∏çÂêåÂú®‰∫éÔºåÂàÜÁ±ªÁöÑÁõÆÊ†á‰∫ãÂÖàÂ∑≤Áü•ÔºåËÄåËÅöÁ±ªÂàô‰∏ç‰∏ÄÊ†∑„ÄÇÂõ†‰∏∫ÂÖ∂‰∫ßÁîüÁöÑÁªìÊûú‰∏éÂàÜÁ±ªÁõ∏ÂêåÔºåËÄåÂè™ÊòØÁ±ªÂà´Ê≤°ÊúâÈ¢ÑÂÖàÂÆö‰πâÔºåËÅöÁ±ªÊúâÊó∂‰πüË¢´Áß∞‰∏∫Êó†ÁõëÁù£ÂàÜÁ±ªÔºàunsupervised classificationÔºâ„ÄÇ ËÅöÁ±ªÂàÜÊûêËØïÂõæÂ∞ÜÁõ∏‰ººÂØπË±°ÂΩíÂÖ•Âêå‰∏ÄÁ∞áÔºåÂ∞Ü‰∏çÁõ∏‰ººÂØπË±°ÂΩíÂà∞‰∏çÂêåÁ∞á„ÄÇ K-ÂùáÂÄºËÅöÁ±ªÁÆóÊ≥ï‰ºòÁÇπÔºöÂÆπÊòìÂÆûÁé∞ Áº∫ÁÇπÔºöÂèØËÉΩÊî∂ÊïõÂà∞Â±ÄÈÉ®ÊúÄÂ∞èÂÄºÔºåÂú®Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äÊî∂ÊïõËæÉÊÖ¢ ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÊï∞ÊçÆ K-meansÊòØÂèëÁé∞ÁªôÂÆöÊï∞ÊçÆÈõÜÁöÑk‰∏™Á∞áÁöÑÁÆóÊ≥ï„ÄÇÁ∞áÁöÑ‰∏™Êï∞kÊòØÁî®Êà∑ÁªôÂÆöÁöÑÔºåÊØè‰∏Ä‰∏™Á∞áÈÄöËøáÂÖ∂Ë¥®ÂøÉÔºàcentroidÔºâÔºåÂç≥Á∞á‰∏≠ÊâÄÊúâÁÇπÁöÑ‰∏≠ÂøÉÊù•ÊèèËø∞„ÄÇ K-meansÁÆóÊ≥ïÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÈ¶ñÂÖàÈöèÊú∫Á°ÆÂÆök‰∏™ÂàùÂßãÁÇπ‰Ωú‰∏∫Ë¥®ÂøÉÔºåÁÑ∂ÂêéÂ∞ÜÊï∞ÊçÆÈõÜÁöÑÊØè‰∏™ÁÇπÂàÜÈÖçÂà∞‰∏Ä‰∏™Á∞á‰∏≠ÔºåÂÖ∑‰ΩìÊù•ËÆ≤Ôºå‰∏∫ÊØè‰∏™ÁÇπÊâæË∑ùÂÖ∂ÊúÄËøëÁöÑË¥®ÂøÉÔºåÂπ∂Â∞ÜÂÖ∂ÂàÜÈÖçÁªôËØ•Ë¥®ÂøÉÊâÄÂØπÂ∫îÁöÑÁ∞á„ÄÇËøô‰∏ÄÊ≠•ÂÆåÊàê‰πãÂêéÔºåÊØè‰∏™Á∞áÁöÑË¥®ÂøÉÊõ¥Êñ∞‰∏∫ËØ•Á∞áÊâÄÊúâÁÇπÁöÑÂπ≥ÂùáÂÄº„ÄÇ ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö ÂàõÂª∫k‰∏™ÁÇπ‰Ωú‰∏∫ÂÖ∂ÂÆûË¥®ÂøÉ ÂΩì‰ªªÊÑè‰∏Ä‰∏™ÁÇπÁöÑÁ∞áÂàÜÈÖçÁªìÊûúÂèëÁîüÊîπÂèòÊó∂ ÂØπÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏™Êï∞ÊçÆÁÇπ ÂØπÊØè‰∏™Ë¥®ÂøÉ ËÆ°ÁÆóË¥®ÂøÉ‰∏éÊï∞ÊçÆÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ª Â∞ÜÊï∞ÊçÆÁÇπÂàÜÈÖçÂà∞Ë∑ùÁ¶ªÂÖ∂ÊúÄËøëÁöÑÁ∞á ÂØπÊØè‰∏Ä‰∏™Á∞áÔºåËÆ°ÁÆóÁ∞á‰∏≠ÊâÄÊúâÁÇπÁöÑÂùáÂÄºÂπ∂Â∞ÜÂùáÂÄº‰Ωú‰∏∫Ë¥®ÂøÉ K-meansËÅöÁ±ªÁöÑ‰∏ÄËà¨ÊµÅÁ®ã Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÈúÄË¶ÅÊï∞ÂÄºÂûãÊï∞ÊçÆÊù•ËÆ°ÁÆóË∑ùÁ¶ªÔºå‰πüÂèØ‰ª•Â∞ÜÊ†áÁß∞ÂûãÊï∞ÊçÆÊò†Â∞Ñ‰∏∫‰∫åÂÄºÂûãÊï∞ÊçÆÂÜçÁî®‰∫éË∑ùÁ¶ªËÆ°ÁÆó ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰∏çÈÄÇÁî®Êó†ÁõëÁù£Â≠¶‰π†ÔºåÂç≥Êó†ÁõëÁù£Â≠¶‰π†Ê≤°ÊúâËÆ≠ÁªÉËøáÁ®ã ÊµãËØïÁÆóÊ≥ïÔºöÂ∫îÁî®ËÅöÁ±ªÁÆóÊ≥ïÔºåËßÇÂØüÁªìÊûú„ÄÇÂèØ‰ª•‰ΩøÁî®ÈáèÂåñÁöÑËØØÂ∑ÆÊåáÊ†áÂ¶ÇËØØÂ∑ÆÂπ≥ÊñπÂíåÊù•ËØÑ‰ª∑ÁÆóÊ≥ïÁöÑÁªìÊûú ‰ΩøÁî®ÁÆóÊ≥ïÔºöÂèØ‰ª•Áî®‰∫éÊâÄÂ∏åÊúõÁöÑ‰ªª‰ΩïÂ∫îÁî®„ÄÇÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåÁ∞áË¥®ÂøÉÂèØ‰ª•‰ª£Ë°®Êï¥‰∏™Á∞áÁöÑÊï∞ÊçÆÊù•ÂÅöÂá∫ÂÜ≥Á≠ñ 1234567891011121314151617181920212223from numpy import *def loadDataSet(fileName): dataMat = [] fr = open(fileName) for line in fr.readlines(): curLine = line.strip().split('\t') fltLine = map(float, curLine) fltLine = list(fltLine) dataMat.append(fltLine) return dataMatdef distEclud(vecA, vecB): return sqrt(sum(power(vecA - vecB, 2)))def randCent(dataSet, k): n = shape(dataSet)[1] centroids = mat(zeros((k, n))) for j in range(n): minJ = min(dataSet[:, j]) rangeJ = float(max(dataSet[:, j]) - minJ) centroids[:, j] = minJ + rangeJ * random.rand(k, 1) return centroids distEclud()ÊòØËÆ°ÁÆó‰∏§‰∏™ÂêëÈáèÁöÑÊ¨ßÂºèË∑ùÁ¶ª randCent()ÊòØ‰∏∫ÁªôÂÆöÊï∞ÊçÆÈõÜÊûÑÂª∫‰∏Ä‰∏™ÂåÖÂê´k‰∏™ÈöèÊú∫Ë¥®ÂøÉÁöÑÈõÜÂêà„ÄÇÈöèÊú∫Ë¥®ÂøÉÂøÖÈ°ªË¶ÅÂú®Êï¥‰∏™Êï∞ÊçÆÈõÜÁöÑËæπÁïå‰πãÂÜÖÔºåËøôÂèØ‰ª•ÊâæÂà∞Êï∞ÊçÆÈõÜÊØè‰∏ÄÁª¥ÁöÑÊúÄÂ∞èÂÄºÂíåÊúÄÂ§ßÂÄºÊù•ÂÆåÊàê„ÄÇÁÑ∂ÂêéÈöèÊú∫ÁîüÊàê0Âà∞1.0‰πãÈó¥ÁöÑÈöèÊú∫Êï∞Âπ∂ÈÄöËøáÂèñÂÄºËåÉÂõ¥ÂíåÊúÄÂ∞èÂÄºÔºå‰ª•‰æøÁ°Æ‰øùÈöèÊú∫ÁÇπÂú®Êï∞ÊçÆÁöÑËæπÁïå‰πãÂÜÖ„ÄÇ 1datMat = mat(loadDataSet('MLiA_SourceCode/Ch10/testSet.txt')) 1min(datMat[:, 0]) matrix([[-5.379713]]) 1min(datMat[:, 1]) matrix([[-4.232586]]) 1max(datMat[:, 1]) matrix([[5.1904]]) 1max(datMat[:, 0]) matrix([[4.838138]]) Áúã‰∏ãrandCent()ÁîüÊàêÁöÑÂÄºÊòØÂê¶Âú®maxÂíåmin‰πãÈó¥„ÄÇ 1randCent(datMat, 2) matrix([[-0.55362342, -1.69185255], [ 0.43137443, -4.17749883]]) ÊµãËØïËÆ°ÁÆóË∑ùÁ¶ªÁöÑÂáΩÊï∞ 1distEclud(datMat[0], datMat[1]) 5.184632816681332 123456789101112131415161718192021222324def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent): m = shape(dataSet)[0] clusterAssment = mat(zeros((m, 2))) centroids = createCent(dataSet, k) clusterChanged = True while clusterChanged: clusterChanged = False for i in range(m): minDist = inf minIndex = -1 for j in range(k): # ÂØªÊâæÊúÄËøëÁöÑË¥®ÂøÉ distJI = distMeas(centroids[j, :], dataSet[i, :]) if distJI &lt; minDist: minDist = distJI minIndex = j if clusterAssment[i, 0] != minIndex: clusterChanged = True clusterAssment[i, :] = minIndex, minDist**2 print(centroids) for cent in range(k): ptsInClust = dataSet[nonzero(clusterAssment[:, 0].A == cent)[0]] # Êõ¥Êñ∞Ë¥®ÂøÉÁöÑ‰ΩçÁΩÆ centroids[cent, :] = mean(ptsInClust, axis=0) return centroids, clusterAssment 12centroids, clusterAssment = kMeans(datMat, 4)centroids [[ 4.01323567 3.90379869] [-3.02008248 -3.35713241] [ 0.85731381 0.6868651 ] [ 0.45281866 -3.89960214]] [[ 2.72275519 3.38230919] [-3.53973889 -2.89384326] [-0.92392975 2.12807596] [ 2.42776071 -3.19858565]] [[ 2.6265299 3.10868015] [-3.53973889 -2.89384326] [-2.31079352 2.63181095] [ 2.7481024 -2.90572575]] [[ 2.6265299 3.10868015] [-3.53973889 -2.89384326] [-2.46154315 2.78737555] [ 2.65077367 -2.79019029]] matrix([[ 2.6265299 , 3.10868015], [-3.53973889, -2.89384326], [-2.46154315, 2.78737555], [ 2.65077367, -2.79019029]]) 1234567import matplotlib.pyplot as pltdef plotScatter(data): fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(data[:, 0].T.tolist()[0], data[:, 1].T.tolist()[0], 10, c='red') ax.scatter(centroids[:, 0].T.tolist()[0], centroids[:, 1].T.tolist()[0], 50, marker='*') plt.show() 1plotScatter(datMat) ‰∏äÈù¢ÁöÑÁªìÊûúÂæóÂà∞Âõõ‰∏™Ë¥®ÂøÉ„ÄÇ ‰ΩøÁî®ÂêéÂ§ÑÁêÜÊù•ÊèêÈ´òËÅöÁ±ªÊÄßËÉΩÂà©Áî®ÁÇπÂà∞Ë¥®ÂøÉÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÂÄºÔºåÊù•ËØÑ‰ª∑ËÅöÁ±ªË¥®Èáè„ÄÇ Âè¶‰∏ÄÁßçÁî®‰∫éÂ∫¶ÈáèËÅöÁ±ªÊïàÊûúÁöÑÊåáÊ†áÊòØSSEÔºàsum of squared errorÔºåËØØÂ∑ÆÂπ≥ÊñπÂíåÔºâÔºåÂØπÂ∫îclusterAssmentÁü©ÈòµÁ¨¨‰∏ÄÂàó‰πãÂíå„ÄÇSSEÂÄºË∂äÂ∞èË°®Á§∫Êï∞ÊçÆÁÇπË∂äÊé•Ëøë‰∫é‰ªñ‰ª¨ÁöÑË¥®ÂøÉÔºåËÅöÁ±ªÊïàÊûú‰πüË∂äÂ•Ω„ÄÇÂõ†‰∏∫ÂØπËØØÂ∑ÆÂèñ‰∫ÜÂπ≥ÊñπÔºåÂõ†Ê≠§Êõ¥Âä†ÈáçËßÜÈÇ£‰∫õËøúÁ¶ª‰∏≠ÂøÉÁöÑÁÇπ„ÄÇ ‰∫åÂàÜK-ÂùáÂÄºÁÆóÊ≥ï‰∏∫‰∫ÜÂÖãÊúçK-ÂùáÂÄºÁÆóÊ≥ïÊî∂Êïõ‰∫éÂ±ÄÈÉ®ÊúÄÂ∞èÂÄºÁöÑÈóÆÈ¢òÔºåÊúâ‰∫∫ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áß∞‰∏∫‰∫åÂàÜK-ÂùáÂÄºÁöÑÁÆóÊ≥ï„ÄÇËØ•ÁÆóÊ≥ïÈ¶ñÂÖàÂ∞ÜÊâÄÊúâÁÇπ‰Ωú‰∏∫‰∏Ä‰∏™Á∞áÔºåÁÑ∂ÂêéÂ∞ÜËØ•Á∞á‰∏ÄÂàÜ‰∏∫‰∫å„ÄÇ‰πãÂêéÈÄâÊã©Âè¶‰∏Ä‰∏™Á∞áËøõË°åÂàíÂàÜÔºåÈÄâÊã©Âì™‰∏Ä‰∏™Á∞áËøõË°åÂàíÂàÜÂèñÂÜ≥‰∫éÂØπÂÖ∂ÂàíÂàÜÊòØÂê¶ÂèØ‰ª•ÊúÄÂ§ßÁ®ãÂ∫¶Èôç‰ΩéSSEÂÄº„ÄÇ ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö Â∞ÜÊâÄÊúâÁÇπÁúãÊàê‰∏Ä‰∏™Á∞á ÂΩìÁ∞áÊï∞ÁõÆÂ∞è‰∫ékÊó∂ ÂØπÊØè‰∏Ä‰∏™Á∞á ËÆ°ÁÆóÊÄªËØØÂ∑Æ Âú®ÁªôÂÆöÁöÑÁ∞á‰∏äÈù¢ËøõË°åK-ÂùáÂÄºËÅöÁ±ªÔºàk=2Ôºâ ËÆ°ÁÆóÂ∞ÜËØ•Á∞á‰∏ÄÂàÜ‰∏∫‰∫åÂêéÁöÑÊÄªËØØÂ∑Æ ÈÄâÊã©‰ΩøÂæóËØØÂ∑ÆÊúÄÂ∞èÁöÑÈÇ£‰∏™Á∞áËøõË°åÂàíÂàÜÊìç‰Ωú 12345678910111213141516171819202122232425262728293031def biKmeans(dataSet, k, distMeas=distEclud): m = shape(dataSet)[0] clusterAssment = mat(zeros((m,2))) centroid0 = mean(dataSet, axis=0).tolist()[0] centList = [centroid0] # ÂàõÂª∫‰∏Ä‰∏™ÂàùÂßãÁ∞á # ËÆ°ÁÆóÊØè‰∏™ÁÇπÂà∞Âπ≥ÂùáÂÄºÁöÑË∑ùÁ¶ªÁöÑÂπ≥Êñπ for j in range(m): clusterAssment[j, 1] = distMeas(mat(centroid0), dataSet[j, :])**2 while (len(centList) &lt; k): lowestSSE = inf for i in range(len(centList)): ptsInCurrCluster = dataSet[nonzero(clusterAssment[:, 0].A==i)[0], :] # Ëé∑ÂèñÂΩìÂâçÊï∞ÊçÆÈõÜi‰∏≠ÁöÑÊï∞ÊçÆÁÇπ centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas) sseSplit = sum(splitClustAss[:, 1]) # Â∞ÜSEE‰∏éÂΩìÂâçÁöÑÊúÄÂ∞èÂÄºËøõË°åÊØîËæÉ sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:, 0].A!=i)[0], 1]) print("sseSplit, and notSplit: ", sseSplit,sseNotSplit) if (sseSplit + sseNotSplit) &lt; lowestSSE: bestCentToSplit = i bestNewCents = centroidMat bestClustAss = splitClustAss.copy() lowestSSE = sseSplit + sseNotSplit bestClustAss[nonzero(bestClustAss[:,0].A == 1)[0],0] = len(centList) bestClustAss[nonzero(bestClustAss[:,0].A == 0)[0],0] = bestCentToSplit print('the bestCentToSplit is: ',bestCentToSplit) print('the len of bestClustAss is: ', len(bestClustAss)) centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0] # Áî®‰∏§‰∏™ÊúÄ‰Ω≥Ë¥®ÂøÉÊõøÊç¢‰∏Ä‰∏™Ë¥®ÂøÉ centList.append(bestNewCents[1,:].tolist()[0]) clusterAssment[nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss # Êõ¥Êñ∞Á∞áÁöÑÂàÜÈÖçÁªìÊûú return mat(centList), clusterAssment 1datMat3 = mat(loadDataSet('MLiA_SourceCode/Ch10/testSet2.txt')) 12centroids, clusterAssment = biKmeans(datMat3, 3)centroids [[ 0.94619158 -0.94117951] [ 3.40877878 -0.10489155]] [[-1.70351595 0.27408125] [ 2.93386365 3.12782785]] sseSplit, and notSplit: 541.2976292649145 0.0 the bestCentToSplit is: 0 the len of bestClustAss is: 60 [[-2.2226205 2.99958388] [-2.07781041 4.61823253]] [[-1.32962218 -0.58601139] [-3.466158 4.32880371]] [[-0.45965615 -2.7782156 ] [-2.94737575 3.3263781 ]] sseSplit, and notSplit: 67.2202000797829 39.52929868209309 [[3.31450775 4.54204866] [2.24406919 1.79975326]] [[3.26127644 3.86529411] [2.66598045 2.52444636]] [[3.43738162 3.905037 ] [2.598185 2.60968842]] sseSplit, and notSplit: 28.094839828868793 501.7683305828214 the bestCentToSplit is: 0 the len of bestClustAss is: 40 matrix([[-0.45965615, -2.7782156 ], [ 2.93386365, 3.12782785], [-2.94737575, 3.3263781 ]]) 1plotScatter(datMat3) ÂÆû‰æãÔºöÂØπÂú∞Âõæ‰∏äÁöÑÁÇπËøõË°åËÅöÁ±ª123456789101112131415161718192021222324252627282930def distSLC(vecA, vecB):#Spherical Law of Cosines a = sin(vecA[0,1]*pi/180) * sin(vecB[0,1]*pi/180) b = cos(vecA[0,1]*pi/180) * cos(vecB[0,1]*pi/180) * \ cos(pi * (vecB[0,0]-vecA[0,0]) /180) return arccos(a + b)*6371.0 #pi is imported with numpyimport matplotlibimport matplotlib.pyplot as pltdef clusterClubs(numClust=5): datList = [] for line in open('MLiA_SourceCode/Ch10/places.txt', 'r').readlines(): lineArr = line.split('\t') datList.append([float(lineArr[4]), float(lineArr[3])]) datMat = mat(datList) myCentroids, clustAssing = biKmeans(datMat, numClust, distMeas=distSLC) fig = plt.figure() rect=[0.1,0.1,0.8,0.8] scatterMarkers=['s', 'o', '^', '8', 'p', \ 'd', 'v', 'h', '&gt;', '&lt;'] axprops = dict(xticks=[], yticks=[]) ax0=fig.add_axes(rect, label='ax0', **axprops) imgP = plt.imread('MLiA_SourceCode/Ch10/Portland.png') ax0.imshow(imgP) ax1=fig.add_axes(rect, label='ax1', frameon=False) for i in range(numClust): ptsInCurrCluster = datMat[nonzero(clustAssing[:,0].A==i)[0],:] markerStyle = scatterMarkers[i % len(scatterMarkers)] ax1.scatter(ptsInCurrCluster[:,0].flatten().A[0], ptsInCurrCluster[:,1].flatten().A[0], marker=markerStyle, s=90) ax1.scatter(myCentroids[:,0].flatten().A[0], myCentroids[:,1].flatten().A[0], marker='+', s=300) plt.show() 1clusterClubs() [[-122.56739405 45.62557076] [-122.63486396 45.51036263]] [[-122.842918 45.646831 ] [-122.62856971 45.5103284 ]] [[-122.76690133 45.612314 ] [-122.62552961 45.50776091]] [[-122.729442 45.58514429] [-122.62063813 45.5040831 ]] [[-122.74941346 45.545862 ] [-122.60434434 45.50451707]] [[-122.74823556 45.52585431] [-122.59648847 45.50821685]] [[-122.72797062 45.51642875] [-122.58031918 45.51010827]] [[-122.7142141 45.51492203] [-122.56818551 45.5102949 ]] [[-122.70981637 45.51478609] [-122.56409551 45.51016235]] sseSplit, and notSplit: 3073.8303715312386 0.0 the bestCentToSplit is: 0 the len of bestClustAss is: 69 [[-122.74578835 45.53605534] [-122.83598851 45.6117388 ]] [[-122.70552277 45.51052658] [-122.842918 45.646831 ]] sseSplit, and notSplit: 1351.7802960650447 1388.799845546737 [[-122.51444985 45.56152247] [-122.6350006 45.49520857]] [[-122.54062592 45.52653233] [-122.607424 45.47994085]] [[-122.54052872 45.52505652] [-122.613193 45.47913283]] sseSplit, and notSplit: 917.0774766267409 1685.0305259845018 the bestCentToSplit is: 1 the len of bestClustAss is: 37 [[-122.79462233 45.64436218] [-122.77702826 45.44723276]] [[-122.72070683 45.59796783] [-122.70730319 45.49559031]] sseSplit, and notSplit: 1047.9405733077342 917.0774766267409 [[-122.52922184 45.56204495] [-122.41440445 45.48137939]] [[-122.55266787 45.52993361] [-122.4009285 45.46897 ]] sseSplit, and notSplit: 361.2106086859341 1898.9745985610039 [[-122.63507677 45.48340811] [-122.60541227 45.407053 ]] [[-122.6105264 45.4923452] [-122.626526 45.413071 ]] sseSplit, and notSplit: 81.83580692942014 2388.16393003474 the bestCentToSplit is: 0 the len of bestClustAss is: 32 [[-122.82888364 45.5832033 ] [-122.71555836 45.59441721]] [[-122.842918 45.646831 ] [-122.6962646 45.5881952]] sseSplit, and notSplit: 24.09829508946755 1797.0816445068451 [[-122.52145964 45.55057242] [-122.48348974 45.49208357]] [[-122.57237273 45.5439008 ] [-122.4927627 45.4967901 ]] sseSplit, and notSplit: 307.68720928070644 1261.8846458842365 [[-122.60429789 45.49458255] [-122.55803361 45.45874909]] [[-122.61647322 45.49408122] [-122.60335233 45.43428767]] [[-122.6105264 45.4923452] [-122.626526 45.413071 ]] sseSplit, and notSplit: 81.83580692942014 1751.0739773579726 [[-122.78221469 45.49159997] [-122.66948399 45.51952507]] [[-122.7680632 45.4665528 ] [-122.66932819 45.51373875]] [[-122.761804 45.46639582] [-122.66733593 45.5169996 ]] sseSplit, and notSplit: 335.01842722575645 1085.0138820543707 the bestCentToSplit is: 3 the len of bestClustAss is: 26 ÊÄªÁªìËÅöÁ±ªÊòØ‰∏ÄÁßçÊó†ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ï„ÄÇÊâÄË∞ìÊó†ÁõëÁù£Â≠¶‰π†ÊòØÊåá‰∫ãÂÖà‰∏çÁü•ÈÅìË¶ÅÂØªÊâæÁöÑÂÜÖÂÆπÔºåÂç≥Ê≤°ÊúâÁõÆÊ†áÂèòÈáè„ÄÇËÅöÁ±ªÂ∞ÜÊï∞ÊçÆÁÇπÂΩíÂà∞Â§ö‰∏™Á∞á‰∏≠ÔºåÂÖ∂‰∏≠Áõ∏‰ººÊï∞ÊçÆÁÇπÂ§Ñ‰∫éÂêå‰∏ÄÁ∞áÔºåËÄå‰∏çÁõ∏‰ººÊï∞ÊçÆÁÇπÂ§Ñ‰∫é‰∏çÂêåÁ∞á‰∏≠„ÄÇËÅöÁ±ªÂèØ‰ª•‰ΩøÁî®Â§öÁßç‰∏çÂêåÁöÑÊñπÊ≥ïÊù•ËÆ°ÁÆóÁõ∏‰ººÂ∫¶„ÄÇ ‰∏ÄÁßçÂπøÊ≥õ‰ΩøÁî®ÁöÑËÅöÁ±ªÁÆóÊ≥ïÊòØK-ÂùáÂÄºÁÆóÊ≥ïÔºåÂÖ∂‰∏≠kÊòØÁî®Êà∑ÊåáÂÆöÁöÑË¶ÅÂàõÂª∫ÁöÑÁ∞áÁöÑÊï∞ÁõÆ„ÄÇK-ÂùáÂÄºËÅöÁ±ªÁÆóÊ≥ï‰ª•k‰∏™ÈöèÊú∫Ë¥®ÂøÉÂºÄÂßã„ÄÇÁÆóÊ≥ï‰ºöËÆ°ÁÆóÊØè‰∏Ä‰∏™ÁÇπÂà∞Áõ¥Á∫øÁöÑË∑ùÁ¶ª„ÄÇÊØè‰∏™ÁÇπ‰ºöË¢´ÂàÜÈÖçÂà∞Ë∑ùÂÖ∂ÊúÄËøëÁöÑÁ∞áË¥®ÂøÉÔºåÁÑ∂ÂêéÁ¥ßÊé•ÁùÄÂü∫‰∫éÊñ∞ÂàÜÈÖçÂà∞Á∞áÁöÑÁÇπÊõ¥Êñ∞Á∞áË¥®ÂøÉ„ÄÇÈáçÂ§ç‰ª•‰∏äËøáÁ®ãÊï∞Ê¨°ÔºåÁõ¥Âà∞Ë¥®ÂøÉ‰∏çÂÜçÊîπÂèò„ÄÇ ‰∏∫Ëé∑ÂæóÊõ¥Â•ΩÁöÑËÅöÁ±ªÊïàÊûúÔºåÂèØ‰ª•‰ΩøÁî®‰∫åÂàÜK-ÂùáÂÄºÁöÑËÅöÁ±ªÁÆóÊ≥ï„ÄÇ‰∫åÂàÜK-ÂùáÂÄºÁÆóÊ≥ïÈ¶ñÂÖàÂ∞ÜÊâÄÊúâÁÇπ‰Ωú‰∏∫‰∏Ä‰∏™Á∞áÔºåÁÑ∂Âêé‰ΩøÁî®K-ÂùáÂÄºÁÆóÊ≥ï(k=2)ÂØπÂÖ∂ÂàíÂàÜ„ÄÇ‰∏ã‰∏ÄÊ¨°Ëø≠‰ª£Êó∂ÔºåÈÄâÊã©ÊúâÊúÄÂ§ßËØØÂ∑ÆÁöÑÁ∞áËøõË°åÂàíÂàÜ„ÄÇËØ•ËøáÁ®ãÈáçÂ§çÁõ¥Âà∞k‰∏™Á∞áÂàõÂª∫ÊàêÂäü‰∏∫Ê≠¢„ÄÇ ‰∫åÂàÜK-ÂùáÂÄºÁöÑËÅöÁ±ªÊïàÊûúË¶ÅÂ•Ω‰∫éK-ÂùáÂÄºÁÆóÊ≥ï„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>ËÅöÁ±ª</tag>
        <tag>K-ÂùáÂÄº</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàò‰∏≠ÁöÑÂáΩÊï∞Â≠¶‰π†ËÆ∞ÂΩï]]></title>
    <url>%2F2020%2F05%2F01%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[ËÆ∞ÂΩïÊú∫Âô®Â≠¶‰π†ÂÆûÊàò‰∏≠ÈÅáÂà∞ÁöÑÂáΩÊï∞1import numpy as np tile()tile(A, reps) tileÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØËÆ©Êüê‰∏™Êï∞ÁªÑÊàñÁü©ÈòµAÔºå‰ª•repsÁöÑÁª¥Â∫¶ÈáçÂ§çÔºåÊûÑÈÄ†Âá∫Êñ∞ÁöÑÊï∞ÁªÑÔºåÊâÄ‰ª•ËøîÂõûÂÄº‰πüÊòØ‰∏™Êï∞ÁªÑ„ÄÇ1234a = array([0, 1])b = np.tile(a, 2)c = np.tile(a, (2,2))b,c (array([0, 1, 0, 1]), array([[0, 1, 0, 1], [0, 1, 0, 1]])) argsort()12x = array([1,4,3,-1,6,9])x.argsort() array([3, 0, 2, 1, 4, 5], dtype=int64) argsort()ÂáΩÊï∞ÊòØÂ∞Üx‰∏≠ÁöÑÂÖÉÁ¥†‰ªéÂ∞èÂà∞Â§ßÊéíÂàóÔºåÊèêÂèñÂÖ∂ÂØπÂ∫îÁöÑindex(Á¥¢Âºï)ÔºåÁÑ∂ÂêéËæìÂá∫„ÄÇ‰æãÂ¶ÇÔºöx[3]=-1ÊúÄÂ∞èÔºåÊâÄ‰ª•y[0]=3,x[5]=9ÊúÄÂ§ßÔºåÊâÄ‰ª•y[5]=5„ÄÇ operator.itemgetterÂáΩÊï∞operatorÊ®°ÂùóÊèê‰æõÁöÑitemgetterÂáΩÊï∞Áî®‰∫éËé∑ÂèñÂØπË±°ÁöÑÂì™‰∫õÁª¥ÁöÑÊï∞ÊçÆÔºåÂèÇÊï∞‰∏∫‰∏Ä‰∫õÂ∫èÂè∑„ÄÇ Ë¶ÅÊ≥®ÊÑèÔºåoperator.itemgetterÂáΩÊï∞Ëé∑ÂèñÁöÑ‰∏çÊòØÂÄºÔºåËÄåÊòØÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÂáΩÊï∞ÔºåÈÄöËøáËØ•ÂáΩÊï∞‰ΩúÁî®Âà∞ÂØπË±°‰∏äÊâçËÉΩËé∑ÂèñÂÄº„ÄÇ sortedÂáΩÊï∞Áî®Êù•ÊéíÂ∫èÔºåsorted(iterable[, cmp[, key[, reverse]]]) ÂÖ∂‰∏≠keyÁöÑÂèÇÊï∞‰∏∫‰∏Ä‰∏™ÂáΩÊï∞ÊàñËÄÖlambdaÂáΩÊï∞„ÄÇÊâÄ‰ª•itemgetterÂèØ‰ª•Áî®Êù•ÂΩìkeyÁöÑÂèÇÊï∞1234import operatora = [1,2,3]b=operator.itemgetter(1) b(a) 2 12b=operator.itemgetter(1,0) #ÂÆö‰πâÂáΩÊï∞bÔºåËé∑ÂèñÂØπË±°ÁöÑÁ¨¨1‰∏™ÂüüÂíåÁ¨¨0‰∏™ÁöÑÂÄºb(a) (2, 1) 123students = [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]#Ê†πÊçÆÁ¨¨‰∫å‰∏™ÂüüËøõË°åÊéíÂ∫èsorted(students, key=operator.itemgetter(2)) [(&apos;dave&apos;, &apos;B&apos;, 10), (&apos;jane&apos;, &apos;B&apos;, 12), (&apos;john&apos;, &apos;A&apos;, 15)] pickleÊ®°ÂùóËØ•pickleÊ®°ÂùóÂÆûÁé∞‰∫ÜÁî®‰∫éÂ∫èÂàóÂåñÂíåÂèçÂ∫èÂàóÂåñPythonÂØπË±°ÁªìÊûÑÁöÑ‰∫åËøõÂà∂ÂçèËÆÆ„ÄÇ ‚ÄúPickling‚ÄùÊòØÂ∞ÜPythonÂØπË±°Â±ÇÊ¨°ÁªìÊûÑËΩ¨Êç¢‰∏∫Â≠óËäÇÊµÅÁöÑËøáÁ®ãÔºå ‚Äúunpickling‚ÄùÊòØÂèçÂêëÊìç‰ΩúÔºå‰ªéËÄåÂ∞ÜÂ≠óËäÇÊµÅÔºàÊù•Ëá™‰∫åËøõÂà∂Êñá‰ª∂ÊàñÁ±ª‰ººÂ≠óËäÇÁöÑÂØπË±°ÔºâËΩ¨Êç¢ÂõûÂØπË±°Â±ÇÊ¨°ÁªìÊûÑ„ÄÇpickleÊ®°ÂùóÂØπ‰∫éÈîôËØØÊàñÊÅ∂ÊÑèÊûÑÈÄ†ÁöÑÊï∞ÊçÆÊòØ‰∏çÂÆâÂÖ®ÁöÑ„ÄÇ pickleÂçèËÆÆÂíåJSONÔºàJavaScript Object NotationÔºâÁöÑÂå∫Âà´ Ôºö 1. JSONÊòØ‰∏ÄÁßçÊñáÊú¨Â∫èÂàóÂåñÊ†ºÂºèÔºàÂÆÉËæìÂá∫unicodeÊñáÊú¨ÔºåËôΩÁÑ∂Â§ßÈÉ®ÂàÜÊó∂Èó¥ÂÆÉË¢´ÁºñÁ†Åutf-8ÔºâÔºåËÄåpickleÊòØ‰∫åËøõÂà∂Â∫èÂàóÂåñÊ†ºÂºè; 2. JSONÊòØ‰∫∫Á±ªÂèØËØªÁöÑÔºåËÄåpickleÂàô‰∏çÊòØ; 3. JSONÊòØÂèØ‰∫íÊìç‰ΩúÁöÑÔºåÂπ∂‰∏îÂú®PythonÁîüÊÄÅÁ≥ªÁªü‰πãÂ§ñÂπøÊ≥õ‰ΩøÁî®ÔºåËÄåpickleÊòØÁâπÂÆö‰∫éPythonÁöÑ; ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåJSONÂè™ËÉΩË°®Á§∫PythonÂÜÖÁΩÆÁ±ªÂûãÁöÑÂ≠êÈõÜÔºåËÄå‰∏çËÉΩË°®Á§∫Ëá™ÂÆö‰πâÁ±ª; pickleÂèØ‰ª•Ë°®Á§∫ÊûÅÂÖ∂Â∫ûÂ§ßÁöÑPythonÁ±ªÂûãÔºàÂÖ∂‰∏≠ËÆ∏Â§öÊòØËá™Âä®ÁöÑÔºåÈÄöËøáÂ∑ßÂ¶ôÂú∞‰ΩøÁî®PythonÁöÑÂÜÖÁúÅÂ∑•ÂÖ∑;Â§çÊùÇÁöÑÊ°à‰æãÂèØ‰ª•ÈÄöËøáÂÆûÁé∞ÁâπÂÆöÁöÑÂØπË±°APIÊù•Ëß£ÂÜ≥Ôºâ„ÄÇ pickle Êï∞ÊçÆÊ†ºÂºèÊòØÁâπÂÆö‰∫éPythonÁöÑ„ÄÇÂÆÉÁöÑ‰ºòÁÇπÊòØÊ≤°ÊúâÂ§ñÈÉ®Ê†áÂáÜÂº∫Âä†ÁöÑÈôêÂà∂Ôºå‰æãÂ¶ÇJSONÊàñXDRÔºà‰∏çËÉΩ‰ª£Ë°®ÊåáÈíàÂÖ±‰∫´Ôºâ; ‰ΩÜÊòØËøôÊÑèÂë≥ÁùÄÈùûPythonÁ®ãÂ∫èÂèØËÉΩÊó†Ê≥ïÈáçÂª∫pickled PythonÂØπË±°„ÄÇ ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåpickleÊï∞ÊçÆÊ†ºÂºè‰ΩøÁî®Áõ∏ÂØπÁ¥ßÂáëÁöÑ‰∫åËøõÂà∂Ë°®Á§∫„ÄÇÂ¶ÇÊûúÊÇ®ÈúÄË¶ÅÊúÄ‰Ω≥Â∞∫ÂØ∏ÁâπÂæÅÔºåÂàôÂèØ‰ª•ÊúâÊïàÂú∞ÂéãÁº©Êï∞ÊçÆ„ÄÇ Ê®°ÂùóÊé•Âè£ Ë¶ÅÂ∫èÂàóÂåñÂØπË±°Â±ÇÊ¨°ÁªìÊûÑÔºåÂè™ÈúÄË∞ÉÁî®ËØ•dumps()ÂáΩÊï∞Âç≥ÂèØ„ÄÇÂêåÊ†∑ÔºåË¶ÅÂØπÊï∞ÊçÆÊµÅËøõË°åÂèçÂ∫èÂàóÂåñÔºåËØ∑Ë∞ÉÁî®ËØ•loads()ÂáΩÊï∞„ÄÇ‰ΩÜÊòØÔºåÂ¶ÇÊûúÊÇ®ÊÉ≥Ë¶ÅÊõ¥Â§öÂú∞ÊéßÂà∂Â∫èÂàóÂåñÂíåÂèçÂ∫èÂàóÂåñÔºåÂàôÂèØ‰ª•ÂàÜÂà´ÂàõÂª∫‰∏Ä‰∏™PicklerÊàñ‰∏Ä‰∏™UnpicklerÂØπË±°„ÄÇ pickleÊ®°ÂùóÊèê‰æõ‰ª•‰∏ãÂ∏∏ÈáèÔºö pickle.HIGHEST_PROTOCOLÊï¥Êï∞Ôºå ÂèØÁî®ÁöÑÊúÄÈ´òÂçèËÆÆÁâàÊú¨„ÄÇËøô‰∏™ÂÄºÂèØ‰ª•‰Ωú‰∏∫‰∏Ä‰∏™Ë¢´‰º†ÈÄíÂçèËÆÆÁöÑ‰ª∑ÂÄºÂáΩÊï∞ dump()Âíådumps()‰ª•ÂèäËØ•Pickler ÊûÑÈÄ†ÂáΩÊï∞„ÄÇ pickle.DEFAULT_PROTOCOLÊï¥Êï∞ÔºåÁî®‰∫éÁºñÁ†ÅÁöÑÈªòËÆ§ÂçèËÆÆÁâàÊú¨„ÄÇÂèØËÉΩ‰∏çÂà∞HIGHEST_PROTOCOL„ÄÇÁõÆÂâçÔºåÈªòËÆ§ÂçèËÆÆÊòØ3ÔºåËøôÊòØ‰∏∫Python 3ËÆæËÆ°ÁöÑÊñ∞ÂçèËÆÆ„ÄÇ pickleÊ®°ÂùóÊèê‰æõ‰ª•‰∏ãÂäüËÉΩÔºå‰ΩøÈÖ∏Ê¥óËøáÁ®ãÊõ¥Âä†Êñπ‰æøÔºö pickle.dumpÔºàobjÔºåfileÔºåprotocol = NoneÔºå*Ôºåfix_imports = True ÔºâÂ∞ÜobjÂØπË±°ÁöÑÁºñÁ†ÅpickleÁºñÁ†ÅË°®Á§∫ÂÜôÂÖ•Âà∞Êñá‰ª∂ÂØπË±°‰∏≠ÔºåÁõ∏ÂΩì‰∫éPickler(file,protocol).dump(obj) ÂèØ‰æõÈÄâÊã©ÁöÑÂçèËÆÆÂèÇÊï∞ÊòØ‰∏Ä‰∏™Êï¥Êï∞ÔºåÊåáÂÆöpickler‰ΩøÁî®ÁöÑÂçèËÆÆÁâàÊú¨ÔºåÊîØÊåÅÁöÑÂçèËÆÆÊòØ0Âà∞HIGHEST_PROTOCOL„ÄÇÂ¶ÇÊûúÊú™ÊåáÂÆöÔºåÂàôÈªòËÆ§‰∏∫DEFAULT_PROTOCOL„ÄÇÂ¶ÇÊûúÊåáÂÆö‰∏∫Ë¥üÊï∞ÔºåÂàôÈÄâÊã©HIGHEST_PROTOCOL„ÄÇ Êñá‰ª∂ÂèÇÊï∞ÂøÖÈ°ªÂÖ∑ÊúâÊé•ÂèóÂçï‰∏™Â≠óËäÇÁöÑÂèÇÊï∞ÂÜôÊñπÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂèØ‰ª•ÊòØ‰∏∫‰∫åËøõÂà∂ÂÜôÂÖ•ÊâìÂºÄÁöÑÁ£ÅÁõòÊñá‰ª∂Ôºå io.BytesIOÂÆû‰æãÊàñÊª°Ë∂≥Ê≠§Êé•Âè£ÁöÑ‰ªª‰ΩïÂÖ∂‰ªñËá™ÂÆö‰πâÂØπË±°„ÄÇ Â¶ÇÊûúfix_imports‰∏∫true‰∏îprotocolÂ∞è‰∫é3ÔºåÂàôpickleÂ∞ÜÂ∞ùËØïÂ∞ÜÊñ∞ÁöÑPython 3ÂêçÁß∞Êò†Â∞ÑÂà∞Python 2‰∏≠‰ΩøÁî®ÁöÑÊóßÊ®°ÂùóÂêçÁß∞Ôºå‰ª•‰æø‰ΩøÁî®Python 2ÂèØËØªÂèñpickleÊï∞ÊçÆÊµÅ„ÄÇ pickle.dumpsÔºàobjÔºåprotocol = NoneÔºå*Ôºåfix_imports = True ÔºâÂ∞ÜÂØπË±°ÁöÑpickledË°®Á§∫‰Ωú‰∏∫bytesÂØπË±°ËøîÂõûÔºåËÄå‰∏çÊòØÂ∞ÜÂÖ∂ÂÜôÂÖ•Êñá‰ª∂„ÄÇ ÂèÇÊï∞protocolÂíåfix_importsÂÖ∑Êúâ‰∏éin‰∏≠Áõ∏ÂêåÁöÑÂê´‰πâ dump()„ÄÇ pickle.loadÔºàfileÔºå*Ôºåfix_imports = TrueÔºåencoding =‚ÄúASCII‚ÄùÔºåerrors =‚Äústrict‚Äù Ôºâ‰ªéÊâìÂºÄÁöÑÊñá‰ª∂ÂØπË±° Êñá‰ª∂‰∏≠ËØªÂèñpickleÂØπË±°Ë°®Á§∫ÔºåÂπ∂ËøîÂõûÂÖ∂‰∏≠ÊåáÂÆöÁöÑÈáçÊûÑÂØπË±°Â±ÇÊ¨°ÁªìÊûÑ„ÄÇËøôÁõ∏ÂΩì‰∫éUnpickler(file).load()„ÄÇ pickleÁöÑÂçèËÆÆÁâàÊú¨ÊòØËá™Âä®Ê£ÄÊµãÁöÑÔºåÂõ†Ê≠§‰∏çÈúÄË¶ÅÂçèËÆÆÂèÇÊï∞„ÄÇË∂ÖËøápickleÂØπË±°ÁöÑË°®Á§∫ÁöÑÂ≠óËäÇÂ∞ÜË¢´ÂøΩÁï•„ÄÇ ÂèÇÊï∞Êñá‰ª∂ÂøÖÈ°ªÊúâ‰∏§‰∏™ÊñπÊ≥ïÔºå‰∏Ä‰∏™ÈááÁî®Êï¥Êï∞ÂèÇÊï∞ÁöÑread()ÊñπÊ≥ïÂíå‰∏Ä‰∏™‰∏çÈúÄË¶ÅÂèÇÊï∞ÁöÑreadline()ÊñπÊ≥ï„ÄÇ‰∏§ÁßçÊñπÊ≥ïÈÉΩÂ∫îËøîÂõûÂ≠óËäÇ„ÄÇÂõ†Ê≠§ÔºåÊñá‰ª∂ÂèØ‰ª•ÊòØ‰∏∫‰∫åËøõÂà∂ËØªÂèñËÄåÊâìÂºÄÁöÑÁ£ÅÁõòÊñá‰ª∂Ôºåio.BytesIOÂØπË±°ÊàñÊª°Ë∂≥Ê≠§Êé•Âè£ÁöÑ‰ªª‰ΩïÂÖ∂‰ªñËá™ÂÆö‰πâÂØπË±°„ÄÇ ÂèØÈÄâÁöÑÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ÊòØfix_importsÔºåencodingÂíåerrorsÔºåÁî®‰∫éÊéßÂà∂Python 2ÁîüÊàêÁöÑpickleÊµÅÁöÑÂÖºÂÆπÊÄßÊîØÊåÅ„ÄÇÂ¶ÇÊûúfix_imports‰∏∫trueÔºåÂàôpickleÂ∞ÜÂ∞ùËØïÂ∞ÜÊóßÁöÑPython 2ÂêçÁß∞Êò†Â∞ÑÂà∞Python 3‰∏≠‰ΩøÁî®ÁöÑÊñ∞ÂêçÁß∞„ÄÇÁºñÁ†ÅÂíå ÈîôËØØÂëäËØâpickleÂ¶Ç‰ΩïËß£Á†ÅPython 2ÁºñÁ†ÅÁöÑ8‰ΩçÂ≠óÁ¨¶‰∏≤ÂÆû‰æã; Ëøô‰∫õÈªòËÆ§ÂàÜÂà´‰∏∫‚ÄôASCII‚ÄôÂíå‚Äôstrict‚Äô„ÄÇËØ•ÁºñÁ†ÅÂèØ‰ª•ÊòØ‚ÄúÂ≠óËäÇ‚Äù‰Ωú‰∏∫Â≠óËäÇÂØπË±°ËØªÂèñËøô‰∫õ8‰Ωç‰∏≤ÁöÑÂÆû‰æã„ÄÇ‰ΩøÁî®encoding=‚Äôlatin1‚ÄôÊâÄÈúÄÁöÑÂèñÂÇ®Â≠òNumPyÁöÑÈòµÂàóÂíåÂÆû‰æãdatetimeÔºådateÂπ∂‰∏îtimeË¢´Python 2Ëß£Á†Å„ÄÇ pickle.loadsÔºàbytes_objectÔºå*Ôºåfix_imports = TrueÔºåencoding =‚ÄúASCII‚ÄùÔºåerrors =‚Äústrict‚Äù Ôºâ‰ªébytesÂØπË±°ËØªÂèñpickleÂØπË±°Â±ÇÊ¨°ÁªìÊûÑÂπ∂ËøîÂõûÂÖ∂‰∏≠ÊåáÂÆöÁöÑÈáçÊûÑÂØπË±°Â±ÇÊ¨°ÁªìÊûÑ„ÄÇ pickleÁöÑÂçèËÆÆÁâàÊú¨ÊòØËá™Âä®Ê£ÄÊµãÁöÑÔºåÂõ†Ê≠§‰∏çÈúÄË¶ÅÂçèËÆÆÂèÇÊï∞„ÄÇË∂ÖËøápickleÂØπË±°ÁöÑË°®Á§∫ÁöÑÂ≠óËäÇÂ∞ÜË¢´ÂøΩÁï•„ÄÇ12345678910111213import numpy as npimport pickleimport iopath = 'test'f = open(path, 'wb')data = &#123;'a':123, 'b':'ads', 'c':[[1,2],[3,4]]&#125;pickle.dump(data, f)f.close()f1 = open(path, 'rb')data1 = pickle.load(f1)print(data1) {&apos;a&apos;: 123, &apos;b&apos;: &apos;ads&apos;, &apos;c&apos;: [[1, 2], [3, 4]]} feedparser Ê®°ÂùófeedparserÊòØ‰∏Ä‰∏™PythonÁöÑFeedËß£ÊûêÂ∫ìÔºåÂèØ‰ª•Â§ÑÁêÜRSS ÔºåCDFÔºåAtom „ÄÇ‰ΩøÁî®ÂÆÉÊàë‰ª¨ÂèØ‰ªé‰ªª‰Ωï RSS Êàñ Atom ËÆ¢ÈòÖÊ∫êÂæóÂà∞Ê†áÈ¢ò„ÄÅÈìæÊé•ÂíåÊñáÁ´†ÁöÑÊù°ÁõÆ‰∫Ü„ÄÇRSS(Really Simple Syndication,ÁÆÄÊòì‰ø°ÊÅØËÅöÂêà)ÊòØ‰∏ÄÁßçÊèèËø∞ÂíåÂêåÊ≠•ÁΩëÁ´ôÂÜÖÂÆπÁöÑÊ†ºÂºè‰Ω†ÂèØ‰ª•ËÆ§‰∏∫ÊòØ‰∏ÄÁßçÂÆöÂà∂‰∏™ÊÄßÂåñÊé®ÈÄÅ‰ø°ÊÅØÁöÑÊúçÂä°„ÄÇÂÆÉËÉΩÂ§üËß£ÂÜ≥‰Ω†Êº´Êó†ÁõÆÁöÑÁöÑÊµèËßàÁΩëÈ°µÁöÑÈóÆÈ¢ò„ÄÇÂÆÉ‰∏ç‰ºöËøáÊó∂Ôºå‰ø°ÊÅØË∂äÊòØËøáÂâ©ÔºåÂÆÉÁöÑÊÑè‰πâ‰πüË∂äÂä†ÂΩ∞Êòæ„ÄÇÁΩëÁªú‰∏≠ÂÖÖÊñ•ÁùÄÂ§ßÈáèÁöÑ‰ø°ÊÅØÂûÉÂúæÔºåÊØèÂ§©ÊëÑÂÖ•‰∫ÜÂ§™Â§öËá™Â∑±Ê†πÊú¨‰∏çÂÖ≥ÂøÉÁöÑ‰ø°ÊÅØ„ÄÇËÆ©Ëá™Â∑±ÂÖ≥Ê≥®ÁöÑ‰ø°ÊÅØ‰∏ªÂä®Êù•ÊâæËá™Â∑±Ôºå‰∏îËøô‰∫õ‰ø°ÊÅØÈÉΩÊòØÁî®Êà∑Ëá™Â∑±ÊâÄÈúÄË¶ÅÁöÑÔºåËøôÂ∞±ÊòØRSSÁöÑÊÑè‰πâ„ÄÇ parse() ÊñπÊ≥ïfeedparser ÊúÄ‰∏∫Ê†∏ÂøÉÁöÑÂáΩÊï∞Ëá™ÁÑ∂ÊòØ parse() Ëß£Êûê URL Âú∞ÂùÄÁöÑÂáΩÊï∞„ÄÇÊàë‰ª¨Áü•ÈÅìÔºåÊØè‰∏™RSSÂíåAtomËÆ¢ÈòÖÊ∫êÈÉΩÂåÖÂê´‰∏Ä‰∏™Ê†áÈ¢òÔºàd.feed.titleÔºâÂíå‰∏ÄÁªÑÊñáÁ´†Êù°ÁõÆ(d.entries)ÈÄöÂ∏∏ÊØè‰∏™ÊñáÁ´†Êù°ÁõÆÈÉΩÊúâ‰∏ÄÊÆµÊëòË¶ÅÔºàd.entries[i].summaryÔºâ,ÊàñËÄÖÊòØÂåÖÂê´‰∫ÜÊù°ÁõÆ‰∏≠ÂÆûÈôÖÊñáÊú¨ÁöÑÊèèËø∞ÊÄßÊ†áÁ≠æÔºàd.entries[i].descriptionÔºâ123import feedparserd=feedparser.parse('http://xvjie.wang/atom.xml')d.feed # ÂØπÂ∫îÁöÑÂÄº‰πüÊòØ‰∏Ä‰∏™Â≠óÂÖ∏ {&apos;title&apos;: &apos;Voidmort&apos;, &apos;title_detail&apos;: {&apos;type&apos;: &apos;text/plain&apos;, &apos;language&apos;: None, &apos;base&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;value&apos;: &apos;Voidmort&apos;}, &apos;links&apos;: [{&apos;href&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;rel&apos;: &apos;self&apos;, &apos;type&apos;: &apos;application/atom+xml&apos;}, {&apos;href&apos;: &apos;https://xvjie.wang/&apos;, &apos;rel&apos;: &apos;alternate&apos;, &apos;type&apos;: &apos;text/html&apos;}], &apos;link&apos;: &apos;https://xvjie.wang/&apos;, &apos;updated&apos;: &apos;2020-03-15T06:43:28.902Z&apos;, &apos;updated_parsed&apos;: time.struct_time(tm_year=2020, tm_mon=3, tm_mday=15, tm_hour=6, tm_min=43, tm_sec=28, tm_wday=6, tm_yday=75, tm_isdst=0), &apos;id&apos;: &apos;https://xvjie.wang/&apos;, &apos;guidislink&apos;: False, &apos;authors&apos;: [{&apos;name&apos;: &apos;Voidmort&apos;}], &apos;author_detail&apos;: {&apos;name&apos;: &apos;Voidmort&apos;}, &apos;author&apos;: &apos;Voidmort&apos;, &apos;generator_detail&apos;: {&apos;href&apos;: &apos;http://hexo.io/&apos;, &apos;name&apos;: &apos;Hexo&apos;}, &apos;generator&apos;: &apos;Hexo&apos;} 1d['feed']['title'] &apos;Voidmort&apos; 1d.feed.title #ÈÄöËøáÂ±ûÊÄßÁöÑÊñπÂºèËÆøÈóÆ &apos;Voidmort&apos; 1d.feed.title_detail {&apos;type&apos;: &apos;text/plain&apos;, &apos;language&apos;: None, &apos;base&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;value&apos;: &apos;Voidmort&apos;} 1d.feed.link &apos;https://xvjie.wang/&apos; 12# ËØ•Â±ûÊÄßÁ±ªÂûã‰∏∫ÂàóË°®ÔºåË°®Á§∫‰∏ÄÁªÑÊñáÁ´†ÁöÑÊù°ÁõÆd.entries[:2] [{&apos;title&apos;: &apos;Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏âÔºâ&apos;, &apos;title_detail&apos;: {&apos;type&apos;: &apos;text/plain&apos;, &apos;language&apos;: None, &apos;base&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;value&apos;: &apos;Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏âÔºâ&apos;}, &apos;links&apos;: [{&apos;href&apos;: &apos;https://xvjie.wang/2020/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/&apos;, &apos;rel&apos;: &apos;alternate&apos;, &apos;type&apos;: &apos;text/html&apos;}], &apos;link&apos;: &apos;https://xvjie.wang/2020/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/&apos;, &apos;id&apos;: &apos;https://xvjie.wang/2020/03/06/Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏âÔºâ/&apos;, &apos;guidislink&apos;: False, &apos;published&apos;: &apos;2020-03-06T02:15:50.000Z&apos;, &apos;published_parsed&apos;: time.struct_time(tm_year=2020, tm_mon=3, tm_mday=6, tm_hour=2, tm_min=15, tm_sec=50, tm_wday=4, tm_yday=66, tm_isdst=0), &apos;updated&apos;: &apos;2020-03-15T06:43:28.902Z&apos;, &apos;updated_parsed&apos;: time.struct_time(tm_year=2020, tm_mon=3, tm_mday=15, tm_hour=6, tm_min=43, tm_sec=28, tm_wday=6, tm_yday=75, tm_isdst=0), &apos;summary&apos;: &apos;&lt;h1 id=&quot;ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã&quot;&gt;&lt;a href=&quot;#ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã&quot; class=&quot;headerlink&quot;&apos;, &apos;summary_detail&apos;: {&apos;type&apos;: &apos;text/html&apos;, &apos;language&apos;: None, &apos;base&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;value&apos;: &apos;&lt;h1 id=&quot;ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã&quot;&gt;&lt;a href=&quot;#ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã&quot; class=&quot;headerlink&quot;&apos;}, &apos;tags&apos;: [{&apos;term&apos;: &apos;Êú∫Âô®Â≠¶‰π†ÂÆûÊàò&apos;, &apos;scheme&apos;: &apos;https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/&apos;, &apos;label&apos;: None}, {&apos;term&apos;: &apos;ÂÜ≥Á≠ñÊ†ë&apos;, &apos;scheme&apos;: &apos;https://xvjie.wang/tags/%E5%86%B3%E7%AD%96%E6%A0%91/&apos;, &apos;label&apos;: None}, {&apos;term&apos;: &apos;ID3&apos;, &apos;scheme&apos;: &apos;https://xvjie.wang/tags/ID3/&apos;, &apos;label&apos;: None}]}, {&apos;title&apos;: &apos;PythonËôöÊãüÁéØÂ¢ÉÁöÑÊê≠Âª∫&apos;, &apos;title_detail&apos;: {&apos;type&apos;: &apos;text/plain&apos;, &apos;language&apos;: None, &apos;base&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;value&apos;: &apos;PythonËôöÊãüÁéØÂ¢ÉÁöÑÊê≠Âª∫&apos;}, &apos;links&apos;: [{&apos;href&apos;: &apos;https://xvjie.wang/2020/02/19/Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA/&apos;, &apos;rel&apos;: &apos;alternate&apos;, &apos;type&apos;: &apos;text/html&apos;}], &apos;link&apos;: &apos;https://xvjie.wang/2020/02/19/Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA/&apos;, &apos;id&apos;: &apos;https://xvjie.wang/2020/02/19/PythonËôöÊãüÁéØÂ¢ÉÁöÑÊê≠Âª∫/&apos;, &apos;guidislink&apos;: False, &apos;published&apos;: &apos;2020-02-19T03:03:50.000Z&apos;, &apos;published_parsed&apos;: time.struct_time(tm_year=2020, tm_mon=2, tm_mday=19, tm_hour=3, tm_min=3, tm_sec=50, tm_wday=2, tm_yday=50, tm_isdst=0), &apos;updated&apos;: &apos;2020-03-06T09:01:06.144Z&apos;, &apos;updated_parsed&apos;: time.struct_time(tm_year=2020, tm_mon=3, tm_mday=6, tm_hour=9, tm_min=1, tm_sec=6, tm_wday=4, tm_yday=66, tm_isdst=0), &apos;summary&apos;: &apos;&lt;p&gt;Êàë‰ΩøÁî®ÁöÑUbuntu18Â∑≤ÁªèËá™Â∏¶‰∫Üpyhon3.6ÔºåÁé∞Âú®ÊàëÊÉ≥Áî®pipÂÆâË£Ö‰∏Ä‰∫õÂÖ∂ÂÆÉÁöÑÂ∫îÁî®ÁöÑÁâàÊú¨ÂíåÁé∞ÊúâÁöÑÊúâÂÜ≤Á™ÅÔºå‰∏∫‰∫ÜÈò≤Ê≠¢ÂÜ≤Á™ÅÔºåÊàëÈúÄË¶ÅÂè¶‰∏Ä‰∏™pythonÁéØÂ¢É„ÄÇ&lt;/p&gt;\n&lt;h1 id=&quot;pythonÁöÑÂÆâË£Ö&quot;&gt;&lt;a href=&quot;#pythonÁöÑÂÆâË£Ö&quot;&apos;, &apos;summary_detail&apos;: {&apos;type&apos;: &apos;text/html&apos;, &apos;language&apos;: None, &apos;base&apos;: &apos;http://xvjie.wang/atom.xml&apos;, &apos;value&apos;: &apos;&lt;p&gt;Êàë‰ΩøÁî®ÁöÑUbuntu18Â∑≤ÁªèËá™Â∏¶‰∫Üpyhon3.6ÔºåÁé∞Âú®ÊàëÊÉ≥Áî®pipÂÆâË£Ö‰∏Ä‰∫õÂÖ∂ÂÆÉÁöÑÂ∫îÁî®ÁöÑÁâàÊú¨ÂíåÁé∞ÊúâÁöÑÊúâÂÜ≤Á™ÅÔºå‰∏∫‰∫ÜÈò≤Ê≠¢ÂÜ≤Á™ÅÔºåÊàëÈúÄË¶ÅÂè¶‰∏Ä‰∏™pythonÁéØÂ¢É„ÄÇ&lt;/p&gt;\n&lt;h1 id=&quot;pythonÁöÑÂÆâË£Ö&quot;&gt;&lt;a href=&quot;#pythonÁöÑÂÆâË£Ö&quot;&apos;}, &apos;tags&apos;: [{&apos;term&apos;: &apos;virtualenv&apos;, &apos;scheme&apos;: &apos;https://xvjie.wang/categories/virtualenv/&apos;, &apos;label&apos;: None}]}] 1len(d.entries) #‰∏ÄÂÖ±20ÁØáÊñáÁ´† 20 1[e.title for e in d.entries][:5] #ÂàóÂá∫Ââç5ÁØáÊñáÁ´†ÁöÑÊ†áÈ¢ò [&apos;Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏âÔºâ&apos;, &apos;PythonËôöÊãüÁéØÂ¢ÉÁöÑÊê≠Âª∫&apos;, &apos;Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∫åÔºâ&apos;, &apos;Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏ÄÔºâ&apos;, &apos;Django&apos;] 1d.entries[0].summary #Á¨¨‰∏ÄÁØáÊñáÁ´†ÁöÑÊëòË¶Å Âíåd.entries[0].descriptionÂäüËÉΩ‰∏ÄÊ†∑ &apos;&lt;h1 id=&quot;ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã&quot;&gt;&lt;a href=&quot;#ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã&quot; class=&quot;headerlink&quot;&apos; sign()sign()ÊòØPythonÁöÑNumpy‰∏≠ÁöÑÂèñÊï∞Â≠óÁ¨¶Âè∑ÔºàÊï∞Â≠óÂâçÁöÑÊ≠£Ë¥üÂè∑ÔºâÁöÑÂáΩÊï∞„ÄÇ 12345678910111213#ÂØºÂÖ•numpyÂ∫ìimport numpy as np #ËæìÂÖ•Êï∞ÊçÆdataArr = [-0.2, -1.1, 0, 2.3, 4.5, 0.0]print("ËæìÂÖ•Êï∞ÊçÆ‰∏∫Ôºö")print(dataArr) #‰ΩøÁî®numpyÁöÑsign(x)ÂáΩÊï∞Ê±ÇËæìÂÖ•Êï∞ÊçÆÁöÑÁ¨¶Âè∑signResult = np.sign(dataArr) #ÊâìÂç∞Âá∫sign()ÁöÑËæìÂá∫ÁªìÊûúprint("\n‰ΩøÁî®signÂáΩÊï∞ÁöÑËæìÂá∫Á¨¶Âè∑‰∏∫Ôºö",signResult) ËæìÂÖ•Êï∞ÊçÆ‰∏∫Ôºö [-0.2, -1.1, 0, 2.3, 4.5, 0.0] ‰ΩøÁî®signÂáΩÊï∞ÁöÑËæìÂá∫Á¨¶Âè∑‰∏∫Ôºö [-1. -1. 0. 1. 1. 0.] numpy.linalgnumpy.linalgÊ®°ÂùóÂåÖÂê´Á∫øÊÄß‰ª£Êï∞ÁöÑÂáΩÊï∞„ÄÇ‰ΩøÁî®Ëøô‰∏™Ê®°ÂùóÔºåÂèØ‰ª•ËÆ°ÁÆóÈÄÜÁü©Èòµ„ÄÅÊ±ÇÁâπÂæÅÂÄº„ÄÅËß£Á∫øÊÄßÊñπÁ®ãÁªÑ‰ª•ÂèäÊ±ÇËß£Ë°åÂàóÂºèÁ≠â„ÄÇ Ê±ÇÁü©ÈòµÁöÑÈÄÜÊ≥®ÔºöÁü©ÈòµÂøÖÈ°ªÊòØÊñπÈòµ‰∏îÂèØÈÄÜÔºåÂê¶Âàô‰ºöÊäõÂá∫LinAlgErrorÂºÇÂ∏∏„ÄÇ1234import numpy as npA = np.mat("0 1 2;1 0 3;4 -3 8")A matrix([[ 0, 1, 2], [ 1, 0, 3], [ 4, -3, 8]]) 123# ‰ΩøÁî®invÂáΩÊï∞ËÆ°ÁÆóÈÄÜÁü©Èòµinv = np.linalg.inv(A)inv matrix([[-4.5, 7. , -1.5], [-2. , 4. , -1. ], [ 1.5, -2. , 0.5]]) 12# Ê£ÄÊü•ÂéüÁü©ÈòµÂíåÊ±ÇÂæóÁöÑÈÄÜÁü©ÈòµÁõ∏‰πòÁöÑÁªìÊûú‰∏∫Âçï‰ΩçÁü©ÈòµA * inv matrix([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) Ê±ÇËß£Á∫øÊÄßÊñπÁ®ãÁªÑnumpy.linalg‰∏≠ÁöÑÂáΩÊï∞solveÂèØ‰ª•Ê±ÇËß£ÂΩ¢Â¶Ç Ax = b ÁöÑÁ∫øÊÄßÊñπÁ®ãÁªÑÔºåÂÖ∂‰∏≠ A ‰∏∫Áü©ÈòµÔºåb ‰∏∫‰∏ÄÁª¥Êàñ‰∫åÁª¥ÁöÑÊï∞ÁªÑÔºåx ÊòØÊú™Áü•ÂèòÈáè1234567#ÂàõÂª∫Áü©ÈòµÂíåÊï∞ÁªÑB = np.mat("1 -2 1;0 2 -8;-4 5 9")b = np.array([0,8,-9])# Ë∞ÉÁî®solveÂáΩÊï∞Ê±ÇËß£Á∫øÊÄßÊñπÁ®ãx = np.linalg.solve(B,b)x array([29., 16., 3.]) 12# ‰ΩøÁî®dotÂáΩÊï∞Ê£ÄÊü•Ê±ÇÂæóÁöÑËß£ÊòØÂê¶Ê≠£Á°Ænp.dot(B , x) matrix([[ 0., 8., -9.]]) ÁâπÂæÅÂÄºÂíåÁâπÂæÅÂêëÈáèÁâπÂæÅÂÄºÔºàeigenvalueÔºâÂç≥ÊñπÁ®ã Ax = ax ÁöÑÊ†πÔºåÊòØ‰∏Ä‰∏™Ê†áÈáè„ÄÇ ÂÖ∂‰∏≠ÔºåA ÊòØ‰∏Ä‰∏™‰∫åÁª¥Áü©ÈòµÔºåx ÊòØ‰∏Ä‰∏™‰∏ÄÁª¥ÂêëÈáè„ÄÇÁâπÂæÅÂêëÈáèÔºàeigenvectorÔºâÊòØÂÖ≥‰∫éÁâπÂæÅÂÄºÁöÑÂêëÈáè numpy.linalgÊ®°Âùó‰∏≠ÔºåeigvalsÂáΩÊï∞ÂèØ‰ª•ËÆ°ÁÆóÁü©ÈòµÁöÑÁâπÂæÅÂÄºÔºåËÄåeigÂáΩÊï∞ÂèØ‰ª•ËøîÂõû‰∏Ä‰∏™ÂåÖÂê´ÁâπÂæÅÂÄºÂíåÂØπÂ∫îÁöÑÁâπÂæÅÂêëÈáèÁöÑÂÖÉÁªÑ123456# ÂàõÂª∫‰∏Ä‰∏™Áü©ÈòµC = np.mat("3 -2;1 0") # Ë∞ÉÁî®eigvalsÂáΩÊï∞Ê±ÇËß£ÁâπÂæÅÂÄºc0 = np.linalg.eigvals(C)c0 array([2., 1.]) 1234# ‰ΩøÁî®eigÂáΩÊï∞Ê±ÇËß£ÁâπÂæÅÂÄºÂíåÁâπÂæÅÂêëÈáè #(ËØ•ÂáΩÊï∞Â∞ÜËøîÂõû‰∏Ä‰∏™ÂÖÉÁªÑÔºåÊåâÂàóÊéíÊîæÁùÄÁâπÂæÅÂÄºÂíåÂØπÂ∫îÁöÑÁâπÂæÅÂêëÈáèÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÂàó‰∏∫ÁâπÂæÅÂÄºÔºåÁ¨¨‰∫åÂàó‰∏∫ÁâπÂæÅÂêëÈáè)c1,c2 = np.linalg.eig(C)c1, c2 (array([2., 1.]), matrix([[0.89442719, 0.70710678], [0.4472136 , 0.70710678]])) 1234# ‰ΩøÁî®dotÂáΩÊï∞È™åËØÅÊ±ÇÂæóÁöÑËß£ÊòØÂê¶Ê≠£Á°Æfor i in range(len(c1)): print ("left:",np.dot(C,c2[:,i])) print ("right:",c1[i] * c2[:,i]) left: [[1.78885438] [0.89442719]] right: [[1.78885438] [0.89442719]] left: [[0.70710678] [0.70710678]] right: [[0.70710678] [0.70710678]] Â•áÂºÇÂÄºÂàÜËß£SVDÔºàSingular Value DecompositionÔºåÂ•áÂºÇÂÄºÂàÜËß£ÔºâÊòØ‰∏ÄÁßçÂõ†Â≠êÂàÜËß£ËøêÁÆóÔºåÂ∞Ü‰∏Ä‰∏™Áü©ÈòµÂàÜËß£‰∏∫3‰∏™Áü©ÈòµÁöÑ‰πòÁßØ numpy.linalgÊ®°Âùó‰∏≠ÁöÑsvdÂáΩÊï∞ÂèØ‰ª•ÂØπÁü©ÈòµËøõË°åÂ•áÂºÇÂÄºÂàÜËß£„ÄÇËØ•ÂáΩÊï∞ËøîÂõû3‰∏™Áü©Èòµ‚Äî‚ÄîU„ÄÅSigmaÂíåVÔºåÂÖ∂‰∏≠UÂíåVÊòØÊ≠£‰∫§Áü©ÈòµÔºåSigmaÂåÖÂê´ËæìÂÖ•Áü©ÈòµÁöÑÂ•áÂºÇÂÄº„ÄÇ12345# ÂàÜËß£Áü©ÈòµD = np.mat("4 11 14;8 7 -2")# ‰ΩøÁî®svdÂáΩÊï∞ÂàÜËß£Áü©ÈòµU,Sigma,V = np.linalg.svd(D,full_matrices=False)U, Sigma, V (matrix([[-0.9486833 , -0.31622777], [-0.31622777, 0.9486833 ]]), array([18.97366596, 9.48683298]), matrix([[-0.33333333, -0.66666667, -0.66666667], [ 0.66666667, 0.33333333, -0.66666667]])) ÁªìÊûúÂåÖÂê´Á≠âÂºè‰∏≠Â∑¶Âè≥‰∏§Á´ØÁöÑ‰∏§‰∏™Ê≠£‰∫§Áü©ÈòµUÂíåVÔºå‰ª•Âèä‰∏≠Èó¥ÁöÑÂ•áÂºÇÂÄºÁü©ÈòµSigma12# ‰ΩøÁî®diagÂáΩÊï∞ÁîüÊàêÂÆåÊï¥ÁöÑÂ•áÂºÇÂÄºÁü©Èòµ„ÄÇÂ∞ÜÂàÜËß£Âá∫ÁöÑ3‰∏™Áü©ÈòµÁõ∏‰πòU * np.diag(Sigma) * V matrix([[ 4., 11., 14.], [ 8., 7., -2.]]) Âπø‰πâÈÄÜÁü©Èòµ‰ΩøÁî®numpy.linalgÊ®°Âùó‰∏≠ÁöÑpinvÂáΩÊï∞ËøõË°åÊ±ÇËß£, Ê≥®ÔºöinvÂáΩÊï∞Âè™Êé•ÂèóÊñπÈòµ‰Ωú‰∏∫ËæìÂÖ•Áü©ÈòµÔºåËÄåpinvÂáΩÊï∞ÂàôÊ≤°ÊúâËøô‰∏™ÈôêÂà∂12345# ÂàõÂª∫‰∏Ä‰∏™Áü©ÈòµE = np.mat("4 11 14;8 7 -2")# ‰ΩøÁî®pinvÂáΩÊï∞ËÆ°ÁÆóÂπø‰πâÈÄÜÁü©Èòµpseudoinv = np.linalg.pinv(E)pseudoinv matrix([[-0.00555556, 0.07222222], [ 0.02222222, 0.04444444], [ 0.05555556, -0.05555556]]) 12# Â∞ÜÂéüÁü©ÈòµÂíåÂæóÂà∞ÁöÑÂπø‰πâÈÄÜÁü©ÈòµÁõ∏‰πòE * pseudoinv matrix([[ 1.00000000e+00, -9.29811783e-16], [-1.66533454e-16, 1.00000000e+00]]) Ë°åÂàóÂºènumpy.linalgÊ®°Âùó‰∏≠ÁöÑdetÂáΩÊï∞ÂèØ‰ª•ËÆ°ÁÆóÁü©ÈòµÁöÑË°åÂàóÂºè1234# ËÆ°ÁÆóÁü©ÈòµÁöÑË°åÂàóÂºèF = np.mat("3.0 4.0;5.0 6.0")# ‰ΩøÁî®detÂáΩÊï∞ËÆ°ÁÆóË°åÂàóÂºènp.linalg.det(F) -1.9999999999999971 3√ó6-4√ó5=-2 ?1np.eye((3)) array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) BeautifulSoupBeautiful Soup ÊòØ‰∏Ä‰∏™ÂèØ‰ª•‰ªéHTMLÊàñXMLÊñá‰ª∂‰∏≠ÊèêÂèñÊï∞ÊçÆÁöÑPythonÂ∫ì.ÂÆÉËÉΩÂ§üÈÄöËøá‰Ω†ÂñúÊ¨¢ÁöÑËΩ¨Êç¢Âô®ÂÆûÁé∞ÊÉØÁî®ÁöÑÊñáÊ°£ÂØºËà™,Êü•Êâæ,‰øÆÊîπÊñáÊ°£ÁöÑÊñπÂºè.Beautiful Soup‰ºöÂ∏Æ‰Ω†ËäÇÁúÅÊï∞Â∞èÊó∂ÁîöËá≥Êï∞Â§©ÁöÑÂ∑•‰ΩúÊó∂Èó¥. https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/ power()ÂáΩÊï∞Ëß£ÈáäÔºö power(A,B) ÔºöÊ±ÇAÁöÑBÊ¨°ÊñπÔºåÊï∞Â≠¶Á≠â‰ª∑‰∫é$A^B$ ÂÖ∂‰∏≠AÂíåBÊó¢ÂèØ‰ª•ÊòØÊï∞Â≠ó(Ê†áÈáè),‰πüÂèØ‰ª•ÊòØÂàóË°®(ÂêëÈáè)12a , b = 3, 4np.power(a, b) 81 12A, B = [1, 2, 3], 3np.power(A, B) array([ 1, 8, 27], dtype=int32) A BÈÉΩÊòØÂàóË°®(ÂêëÈáè)Êó∂ÂÄôÔºåÂøÖÈ°ªlen(A)=len(B)12A, B = [1, 2, 3], [4, 5, 6]np.power(A, B) array([ 1, 32, 729], dtype=int32) nonzero()nonzero(a) nonzeroÂáΩÊï∞ÊòØnumpy‰∏≠Áî®‰∫éÂæóÂà∞Êï∞ÁªÑarray‰∏≠ÈùûÈõ∂ÂÖÉÁ¥†ÁöÑ‰ΩçÁΩÆÔºàÊï∞ÁªÑÁ¥¢ÂºïÔºâÁöÑÂáΩÊï∞„ÄÇÂÆÉÁöÑËøîÂõûÂÄºÊòØ‰∏Ä‰∏™ÈïøÂ∫¶‰∏∫a.ndim(Êï∞ÁªÑaÁöÑËΩ¥Êï∞)ÁöÑÂÖÉÁªÑÔºåÂÖÉÁªÑÁöÑÊØè‰∏™ÂÖÉÁ¥†ÈÉΩÊòØ‰∏Ä‰∏™Êï¥Êï∞Êï∞ÁªÑÔºåÂÖ∂ÂÄº‰∏∫ÈùûÈõ∂ÂÖÉÁ¥†ÁöÑ‰∏ãÊ†áÂú®ÂØπÂ∫îËΩ¥‰∏äÁöÑÂÄº„ÄÇ Ôºà1ÔºâÂè™Êúâa‰∏≠ÈùûÈõ∂ÂÖÉÁ¥†Êâç‰ºöÊúâÁ¥¢ÂºïÂÄºÔºåÈÇ£‰∫õÈõ∂ÂÄºÂÖÉÁ¥†Ê≤°ÊúâÁ¥¢ÂºïÂÄºÔºõ Ôºà2ÔºâËøîÂõûÁöÑÁ¥¢ÂºïÂÄºÊï∞ÁªÑÊòØ‰∏Ä‰∏™2Áª¥tupleÊï∞ÁªÑÔºåËØ•tupleÊï∞ÁªÑ‰∏≠ÂåÖÂê´‰∏ÄÁª¥ÁöÑarrayÊï∞ÁªÑ„ÄÇÂÖ∂‰∏≠Ôºå‰∏ÄÁª¥arrayÂêëÈáèÁöÑ‰∏™Êï∞‰∏éaÁöÑÁª¥Êï∞ÊòØ‰∏ÄËá¥ÁöÑ„ÄÇ Ôºà3ÔºâÁ¥¢ÂºïÂÄºÊï∞ÁªÑÁöÑÊØè‰∏Ä‰∏™arrayÂùáÊòØ‰ªé‰∏Ä‰∏™Áª¥Â∫¶‰∏äÊù•ÊèèËø∞ÂÖ∂Á¥¢ÂºïÂÄº„ÄÇÊØîÂ¶ÇÔºåÂ¶ÇÊûúaÊòØ‰∏Ä‰∏™‰∫åÁª¥Êï∞ÁªÑÔºåÂàôÁ¥¢ÂºïÂÄºÊï∞ÁªÑÊúâ‰∏§‰∏™arrayÔºåÁ¨¨‰∏Ä‰∏™array‰ªéË°åÁª¥Â∫¶Êù•ÊèèËø∞Á¥¢ÂºïÂÄºÔºõÁ¨¨‰∫å‰∏™array‰ªéÂàóÁª¥Â∫¶Êù•ÊèèËø∞Á¥¢ÂºïÂÄº„ÄÇ Ôºà4Ôºâtranspose(np.nonzero(x))ÂáΩÊï∞ËÉΩÂ§üÊèèËø∞Âá∫ÊØè‰∏Ä‰∏™ÈùûÈõ∂ÂÖÉÁ¥†Âú®‰∏çÂêåÁª¥Â∫¶ÁöÑÁ¥¢ÂºïÂÄº„ÄÇ Ôºà5ÔºâÈÄöËøáa[nonzero(a)]ÂæóÂà∞ÊâÄÊúâa‰∏≠ÁöÑÈùûÈõ∂ÂÄº aÊòØ‰∏ÄÁª¥Êï∞ÁªÑ1234import numpy as npa = [0,2,3]b = np.nonzero(a)b (array([1, 2], dtype=int64),) 1np.array(b).ndim 2 aÊòØ‰∫åÁª¥Êï∞ÁªÑ123a = np.array([[0,0,3],[0,0,0],[0,0,9]])b = np.nonzero(a)a, b (array([[0, 0, 3], [0, 0, 0], [0, 0, 9]]), (array([0, 2], dtype=int64), array([2, 2], dtype=int64))) 1np.array(b).ndim 2 1np.transpose(np.nonzero(a)) array([[0, 2], [2, 2]], dtype=int64) frozenset()ÊèèËø∞frozenset() ËøîÂõû‰∏Ä‰∏™ÂÜªÁªìÁöÑÈõÜÂêàÔºåÂÜªÁªìÂêéÈõÜÂêà‰∏çËÉΩÂÜçÊ∑ªÂä†ÊàñÂà†Èô§‰ªª‰ΩïÂÖÉÁ¥†„ÄÇ ËØ≠Ê≥ïfrozenset() ÂáΩÊï∞ËØ≠Ê≥ïÔºö class frozenset([iterable]) ÂèÇÊï∞iterable ‚Äì ÂèØËø≠‰ª£ÁöÑÂØπË±°ÔºåÊØîÂ¶ÇÂàóË°®„ÄÅÂ≠óÂÖ∏„ÄÅÂÖÉÁªÑÁ≠âÁ≠â„ÄÇËøîÂõûÂÄºËøîÂõûÊñ∞ÁöÑ frozenset ÂØπË±°ÔºåÂ¶ÇÊûú‰∏çÊèê‰æõ‰ªª‰ΩïÂèÇÊï∞ÔºåÈªòËÆ§‰ºöÁîüÊàêÁ©∫ÈõÜÂêà„ÄÇ ÂÆû‰æã‰ª•‰∏ãÂÆû‰æãÂ±ïÁ§∫‰∫Ü frozenset() ÁöÑ‰ΩøÁî®ÊñπÊ≥ïÔºö12a = frozenset(range(10)) # ÁîüÊàê‰∏Ä‰∏™Êñ∞ÁöÑ‰∏çÂèØÂèòÈõÜÂêàa frozenset({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}) 12b = frozenset('voidmort')b # ÂàõÂª∫‰∏çÂèØÂèòÈõÜÂêà frozenset({&apos;d&apos;, &apos;i&apos;, &apos;m&apos;, &apos;o&apos;, &apos;r&apos;, &apos;t&apos;, &apos;v&apos;}) apriori ÂÖ≥ËÅîÂàÜÊûê1%pip install efficient-apriori Downloading https://files.pythonhosted.org/packages/5a/c6/ecdf3a32d23cada466634c649cf4f50fefe76f56eae53ecceff688b306be/efficient_apriori-1.1.1-py3-none-any.whl Installing collected packages: efficient-apriori Successfully installed efficient-apriori-1.1.1 123456from efficient_apriori import aprioritransactions = [('eggs', 'bacon', 'soup'), ('eggs', 'bacon', 'apple'), ('soup', 'bacon', 'banana')]itemsets, rules = apriori(transactions, min_support=0.5, min_confidence=1)print(rules) [{eggs} -&gt; {bacon}, {soup} -&gt; {bacon}] NumPy-corrcoef()numpy.corrcoef(x, y=None, rowvar=True, bias=, ddof=) ËøîÂõûÁöÆÂ∞îÈÄäÁßØÁü©Áõ∏ÂÖ≥Á≥ªÊï∞„ÄÇ Áõ∏ÂÖ≥Á≥ªÊï∞Áü©Èòµ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå ËøîÂõûÂÄºr‰ªã‰∫é-1Âíå1‰πãÈó¥ÔºàÂê´1Ôºâ„ÄÇr=0,Ê≤°ÊúâÁõ∏ÂÖ≥ÊÄß„ÄÇ ÂèÇÊï∞: x : array_like ÂåÖÂê´Â§ö‰∏™ÂèòÈáèÂíåËßÇÊµãÂÄºÁöÑ‰∏ÄÁª¥Êàñ‰∫åÁª¥Êï∞ÁªÑ„ÄÇÊØèË°å x Ë°®Á§∫‰∏Ä‰∏™ÂèòÈáèÔºåÊØèÂàóÈÉΩÊòØÂØπÊâÄÊúâËøô‰∫õÂèòÈáèÁöÑÂçï‰∏™ËßÇÂØü„ÄÇ‰πüÁúãÂà∞ rowvar ‰∏ãÈù¢„ÄÇ y : ÈòµÂàóÂºèÔºåÂèØÈÄâ ‰∏ÄÁªÑÈôÑÂä†ÁöÑÂèòÈáèÂíåËßÇÂØüÂÄº„ÄÇ y ÂΩ¢Áä∂‰∏é x . ÁΩóÁì¶Â∞î : ÂèØÈÄâÁöÑÂ∏ÉÂ∞î Â¶ÇÊûú rowvar ‰∏∫ÁúüÔºàÈªòËÆ§ÂÄºÔºâÔºåÂàôÊØèË°å‰ª£Ë°®‰∏Ä‰∏™ÂèòÈáèÔºåÂàó‰∏≠ÂåÖÂê´ËßÇÊµãÂÄº„ÄÇÂê¶ÂàôÔºåÂÖ≥Á≥ªÂ∞ÜË¢´ËΩ¨ÁΩÆÔºöÊØèÂàóË°®Á§∫‰∏Ä‰∏™ÂèòÈáèÔºåËÄåË°åÂåÖÂê´ËßÇÊµãÂÄº„ÄÇ ËøîÂõû: R : ÂèòÈáèÁöÑÁõ∏ÂÖ≥Á≥ªÊï∞Áü©Èòµ„ÄÇ 123456789import numpy as npa = np.array([1,2,3])b = np.array([3,4,5]) def correlation(x, y): return (((x-x.mean())/(x.std(ddof=0)))*((y-y.mean())/(y.std(ddof=0)))).mean() correlation(a,b) 0.9999999999999999 1np.corrcoef(a, b) array([[1., 1.], [1., 1.]])]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>pythonÂáΩÊï∞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰πùÔºâ]]></title>
    <url>%2F2020%2F05%2F01%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B9%9D%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Êï∞ÂõûÂΩíÂàÜÁ±ªÂõûÂΩíÊ†ë Classification And Regression Trees ÂàÜÁ±ªÂõûÂΩíÊ†ë„ÄÇËØ•ÁÆóÊ≥ïÊó¢ÂèØ‰ª•Áî®‰∫éÂõûÂΩíËøòÂèØ‰ª•Áî®‰∫éÂàÜÁ±ª„ÄÇ Â§çÊùÇÊï∞ÊçÆÁöÑÂ±ÄÈÉ®ÊÄßÂª∫Ê®°Êï∞ÂõûÂΩí ‰ºòÁÇπÔºöÂèØ‰ª•ÂØπÂ§çÊùÇÂíåÁ∫øÊÄßÁöÑÊï∞ÊçÆÂª∫Ê®° Áº∫ÁÇπÔºöÁªìÊûú‰∏çÊòìÁêÜËß£ ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞ÂûãÊï∞ÊçÆ Á¨¨‰∏âÁ´†‰ΩøÁî®ÁöÑÊ†ëÊûÑÂª∫ÁöÑÁÆóÊ≥ïÊòØID3„ÄÇID3ÁöÑÂÅöÊ≥ïÊòØÊØèÊ¨°ÈÄâÂèñÂΩìÂâçÊúÄ‰Ω≥ÁöÑÁâπÂæÅÊù•ÂàÜÂâ≤Êï∞ÊçÆÔºåÂπ∂ÊåâÁÖßËØ•ÁâπÂæÅÁöÑÊâÄÊúâÂèØËÉΩÂèñÂÄºÊù•ÂàáÂàÜ„ÄÇ‰πüÂ∞±ÂèñÂÄºÔºåÈÇ£‰πàÊï∞ÊçÆÂ∞ÜË¢´ÂàáÂàÜÊàê4‰ªΩÔºå‰∏Ä‰ΩÜÊåâÊüêÁßçÁâπÂæÅÂàáÂàÜÂêéÔºåËØ•ÁâπÂæÅÂú®‰πãÂêéÁöÑÁÆóÊ≥ïÊâßË°åËøáÁ®ã‰∏≠Â∞Ü‰∏ç‰ºöÂÜçËµ∑‰ΩúÁî®ÔºåÊâÄ‰ª•ÊúâËßÇÁÇπËÆ§‰∏∫ËøôÁßçÂàáÂàÜÊñπÂºèËøá‰∫éËøÖÈÄü„ÄÇÂè¶‰∏ÄÁßçÊñπÊ≥ïÊòØ‰∫åÂÖÉÂàáÂàÜÂèëÔºåÂç≥ÊØèÊ¨°ÂêßÊï∞ÊçÆÈõÜÂàáÂàÜÊàê‰∏§‰ªΩ„ÄÇÂ¶ÇÊûúÊï∞ÊçÆÁöÑÊüê‰∏™ÁâπÂæÅÁ≠â‰∫éÂàáÂàÜÊâÄË¶ÅÊ±ÇÁöÑÂÄºÔºåÈÇ£‰πàËøô‰∫õÊï∞ÊçÆÂ∞±ËøõÂÖ•Ê†ëÁöÑÂ∑¶Â≠êÊ†ëÔºåÂèç‰πãÂàôËøõÂÖ•Ê†ëÁöÑÂè≥Â≠êÊ†ë„ÄÇ Èô§‰∫ÜÂàáÂàÜËøá‰∫éËøÖÈÄüÂ§ñÔºåID3ÁÆóÊ≥ïËøòÂ≠òÂú®Âè¶‰∏Ä‰∏™ÈóÆÈ¢òÔºåÂÆÉ‰∏çËÉΩÁõ¥Êé•Â§ÑÁêÜËøûÁª≠ÂûãÁâπÂæÅ„ÄÇÂè™Êúâ‰∫ãÂÖàÂ∞ÜËøûÁª≠ÂûãÁâπÂæÅËΩ¨Êç¢ÊàêÁ¶ªÊï£ÂûãÔºåÊâçËÉΩÂú®ID3ÁÆóÊ≥ï‰∏≠‰ΩøÁî®„ÄÇ‰ΩÜËøôÁßçËΩ¨Êç¢ËøáÁ®ã‰ºöÁ†¥ÂùèËøûÁª≠ÂûãÂèòÈáèÁöÑÂÜÖÂú®ÊÄßË¥®„ÄÇËÄå‰ΩøÁî®‰∫åÂÖÉÂàáÂàÜÊ≥ïÂàôÂØπ‰∫éÊ†ëÊûÑÂª∫ËøáÁ®ãËøõË°åË∞ÉÊï¥‰ª•Â§ÑÁêÜËøûÁª≠ÂûãÁâπÂæÅ„ÄÇ ÂÖ∑‰ΩìÂ§ÑÁêÜÊñπÊ≥ïÊòØÔºö Â¶ÇÊûúÁâπÂæÅÂÄºÂ§ß‰∫éÁªôÂÆöÂÄºÂ∞±Ëµ∞Â∑¶Â≠êÊ†ëÔºåÂê¶ÂàôÂ∞±Ëµ∞Âè≥Â≠êÊ†ë„ÄÇ Âè¶Â§ñÔºå‰∫åÂÖÉÂàáÂàÜÊ≥ï‰πüËäÇÁúÅ‰∫ÜÊ†ëÁöÑÊûÑÂª∫Êó∂Èó¥Ôºå‰ΩÜËøôÁÇπÊÑè‰πâ‰πü‰∏çÊòØÁâπÂà´Â§ßÂõ†‰∏∫Ëøô‰∫õÊ†ëÁöÑÊûÑÂª∫‰∏ÄËà¨ÊòØÁ¶ªÁ∫øÂÆåÊàêÁöÑ„ÄÇ CARTÊòØÂçÅÂàÜËëóÂêç‰∏îÂπøÊ≥õËÆ∞ËΩΩÁöÑÊ†ëÊûÑÂª∫ÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî®‰∫åÂÖÉÂàáÂàÜÊù•Â§ÑÁêÜËøûÁª≠ÂûãÂèòÈáè„ÄÇÂØπCARTÁ®ç‰Ωú‰øÆÊîπÂ∞±ÂèØ‰ª•Â§ÑÁêÜÂõûÂΩíÈóÆÈ¢ò„ÄÇ ÂõûÂΩíÊ†ëÁöÑ‰∏ÄËà¨ÊñπÊ≥ïÔºö Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÈúÄË¶ÅÊï∞ÂÄºÂûãÁöÑÊï∞ÊçÆÔºåÊ†áÁß∞ÂûãÊï∞ÊçÆÂ∫îËØ•Êò†Â∞ÑÊàê‰∫åÂÄºÂûãÊï∞ÊçÆ ÂàÜÊûêÊï∞ÊçÆÔºöÁªòÂá∫Êï∞ÊçÆÁöÑ‰∫åÁª¥ÂèØËßÜÂåñÊòæÁ§∫ÁªìÊûúÔºå‰ª•Â≠óÂÖ∏ÊñπÂºèÁîüÊàêÊ†ë ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÂ§ßÈÉ®ÂàÜÊó∂Èó¥ÈÉΩËä±Ë¥πÂú®Âè∂ËäÇÁÇπÊ†ëÊ®°ÂûãÁöÑÊûÑÂª∫‰∏ä ÊµãËØïÁÆóÊ≥ïÔºö‰ΩøÁî®ÊµãËØïÊï∞ÊçÆ‰∏äÁöÑR^2ÂÄºÊù•ÂàÜÊûêÊ®°ÂûãÁöÑÊïàÊûú ‰ΩøÁî®ÁÆóÊ≥ïÔºö‰ΩøÁî®ËÆ≠ÁªÉÂá∫ÁöÑÊ†ëÂÅöÈ¢ÑÊµã ËøûÁª≠ÂíåÁ¶ªÊï£ÂûãÁâπÂæÅÁöÑÊ†ëÁöÑÊûÑÂª∫Âú®Ê†ëÁöÑÊûÑÂª∫ËøáÁ®ã‰∏≠ÔºåÈúÄË¶ÅËß£ÂÜ≥Â§öÁßçÁ±ªÂûãÊï∞ÊçÆÁöÑÂ≠òÂÇ®ÈóÆÈ¢ò„ÄÇËøôÈáåÂ∞Ü‰ΩøÁî®Â≠óÂÖ∏Êù•Â≠òÂÇ®Ê†ëÁöÑÊï∞ÊçÆÁªìÊûÑÔºåËØ•Â≠óÂÖ∏Â∞ÜÂåÖÂê´‰ª•‰∏ãÂõõÁßçÂÖÉÁ¥†„ÄÇ ÂæÖÂàáÂàÜÁöÑÁâπÂæÅ ÂæÖÂàáÂàÜÁöÑÁâπÂæÅÂÄº Âè≥Â≠êÊ†ë„ÄÇÂΩì‰∏çÈúÄË¶ÅÂàáÂàÜÊó∂Ôºå‰πüÂèØ‰ª•ÊòØÂçïÂÄº Â∑¶Â≠êÊ†ë„ÄÇ‰∏éÂè≥Â≠êÊ†ëÁ±ª‰ºº CARTÁÆóÊ≥ïÂè™ÂÅö‰∫åÂÖÉÂàáÂàÜÔºåÊâÄ‰ª•ËøôÈáåÂèØ‰ª•Âõ∫ÂÆöÊ†ëÁöÑÊï∞ÊçÆÁªìÊûÑ„ÄÇÊ†ëÂåÖÂê´Â∑¶ÈîÆÂíåÂè≥ÈîÆÔºåÂèØ‰ª•Â≠òÂÇ®Âè¶‰∏ÄÈ¢óÊ†ëÊàñËÄÖÂçï‰∏™ÂÄº„ÄÇÂ≠óÂÖ∏ËøòÂåÖÂê´ÁâπÂæÅÂíåÁâπÂæÅÂÄºËøô‰∏§‰∏™ÈîÆÔºåÂÆÉ‰ª¨ÁªôÂá∫ÁöÑÂàáÂàÜÁÆóÊ≥ïÊâÄÊúâÁöÑÁâπÂæÅÂíåÁâπÂæÅÂÄº„ÄÇ Êé•‰∏ãÊù•ÊûÑÂª∫‰∏§ÁßçÊ†ëÔºåÁ¨¨‰∏ÄÁßçÊòØÂõûÂΩíÊ†ëÔºàregression treeÔºâÂÖ∂‰∏≠ÊØè‰∏™Âè∂ËäÇÁÇπÂåÖÂê´Âçï‰∏™ÂÄºÔºåÁ¨¨‰∫åÁßçÊòØÊòØÊ®°ÂûãÊ†ëÔºàmodel treeÔºâÂÖ∂‰∏≠ÊØè‰∏™Âè∂ËäÇÁÇπÂåÖÂê´‰∏Ä‰∏™Á∫øÊÄßÊñπÁ®ã„ÄÇ createTree()ÁöÑ‰º™‰ª£Á†ÅÂ§ßËá¥Â¶Ç‰∏ãÔºö ÊâæÂà∞ÊúÄ‰Ω≥ÁöÑÂæÖÂàáÂàÜÁâπÂæÅÔºö Â¶ÇÊûúËØ•ËäÇÁÇπ‰∏çËÉΩÂÜçÂàÜÔºåÂ∞ÜËØ•ËäÇÁÇπÂ≠ò‰∏∫Âè∂ËäÇÁÇπ ÊâßË°å‰∫åÂÖÉÂàáÂàÜ Âú®Âè≥Â≠êÊ†ëË∞ÉÁî®createTree()ÊñπÊ≥ï Âú®Â∑¶Â≠êÊ†ëË∞ÉÁî®createTree()ÊñπÊ≥ï 1234567891011121314151617181920212223242526272829303132333435from numpy import *def loadDataSet(fileName): dataMat = [] fr = open(fileName) for line in fr.readlines(): curLine = line.strip().split('\t') fltLine = map(float, curLine) fltLine = list(fltLine) dataMat.append(fltLine) fr.close() return dataMatdef regLeaf(dataSet): # returns the value used for each leaf return mean(dataSet[:,-1])def regErr(dataSet): return var(dataSet[:,-1]) * shape(dataSet)[0]def createTree(dataSet, leafType=regLeaf, errType=regErr, ops=(1, 4)): feat, val = chooseBestSplit(dataSet, leafType, errType, ops) # Êª°Ë∂≥Êù°‰ª∂Êó∂ËøîÂõûÂè∂ËäÇÁÇπÂÄº if feat == None: return val retTree = &#123;&#125; retTree['spInd'] = feat retTree['spVal'] = val lSet, rSet = binSplitDataSet(dataSet, feat, val) retTree['left'] = createTree(lSet, leafType, errType, ops) retTree['right'] = createTree(rSet, leafType, errType, ops) return retTreedef binSplitDataSet(dataSet, feature, value): mat0 = dataSet[nonzero(dataSet[:, feature] &gt; value)[0], :] mat1 = dataSet[nonzero(dataSet[:, feature] &lt;= value)[0], :] return mat0, mat1 12testMat = mat(eye(4))testMat matrix([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]]) 1mat0, mat1 = binSplitDataSet(testMat, 1, 0.5) 1mat0 matrix([[0., 1., 0., 0.]]) 1mat1 matrix([[1., 0., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]]) 1nonzero(testMat[:, 1] &gt; 0.5)[0][0] 1 Â∞ÜCARTÁÆóÊ≥ïÁî®‰∫éÂõûÂΩíË¶ÅÂØπÊï∞ÊçÆÁöÑÂ§çÊùÇÂÖ≥Á≥ªÂª∫Ê®°ÔºåÊàë‰ª¨Â∑≤ÁªèÂÜ≥ÂÆöÂÄüÁî®Ê†ëÁªìÊûÑÊù•Â∏ÆÂä©ÂàáÂàÜÊï∞ÊçÆÔºåÈÇ£‰πàÂ¶Ç‰ΩïÂÆûÁé∞Êï∞ÊçÆÁöÑÂàáÂàÜÂë¢Ôºü ‰∏∫ÊàêÂäüÊûÑÂª∫‰ª•ÂàÜÊÆµÂ∏∏Êï∞‰∏∫Âè∂ËäÇÁÇπÁöÑÊ†ëÔºåÈúÄË¶ÅÂ∫¶ÈáèÂá∫Êï∞ÊçÆÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂú®ÁªôÂÆöÁöÑËäÇÁÇπËÆ°ÁÆóÊï∞ÊçÆÁöÑÊ∑∑‰π±Â∫¶ÔºåËÆ°ÁÆóÊï∞ÊçÆÊ∑∑‰π±Â∫¶ÁöÑÊñπÊ≥ïÔºåÈ¶ñÂÖàËÆ°ÁÆóÊâÄÊúâÊï∞ÊçÆÁöÑÂùáÂÄºÔºåÁÑ∂ÂêéËÆ°ÁÆóÊØèÊù°Êï∞ÊçÆÁöÑÂÄºÂà∞ÂùáÂÄºÁöÑÂ∑ÆÂÄºÔºå‰∏∫‰∫ÜÂØπÊ≠£Ë¥üÂ∑ÆÂÄºÂêåÁ≠âÁúãÂæÖÔºå‰∏ÄËà¨‰ΩøÁî®ÁªùÂØπÂÄºÊàñÂπ≥ÊñπÂÄºÊù•‰ª£Êõø‰∏äËø∞Â∑ÆÂÄº„ÄÇÁ±ª‰ººÊñπÂ∑ÆÁöÑËÆ°ÁÆóÔºåÂîØ‰∏Ä‰∏çÂêåÊòØÊñπÂ∑ÆÊòØÂπ≥ÊñπËØØÂ∑ÆÁöÑÂùáÂÄºÔºåËÄåËøôÈáåÈúÄË¶ÅÁöÑÊòØÂπ≥ÊñπËØØÂ∑ÆÁöÑÊÄªÂÄºÔºåÊÄªÊñπÂ∑ÆÂèØ‰ª•ÈÄöËøáÂùáÊñπÂ∑Æ‰πò‰ª•Êï∞ÊçÆÈõÜ‰∏≠Ê†∑Êú¨ÁÇπÁöÑ‰∏™Êï∞Êù•ÂæóÂà∞„ÄÇ ÊûÑÂª∫Ê†ëÊûÑÂª∫ÂõûÂΩíÊ†ëÔºåÈúÄË¶ÅË°•ÂÖÖ‰∏Ä‰∫õÊñ∞ÁöÑ‰ª£Á†ÅÔºåÈ¶ñÂÖàË¶ÅÂÅöÁöÑÂ∞±ÊòØÂÆûÁé∞chooseBestSplit()ÂáΩÊï∞ÔºåÁªôÂÆöÊüê‰∏™ËØØÂ∑ÆËÆ°ÁÆóÊñπÊ≥ïÔºåËØ•ÂáΩÊï∞‰ºöÊâæÂà∞Êï∞ÊçÆÈõÜ‰∏äÊúÄ‰Ω≥ÁöÑ‰∫åÂÖÉÂàáÂàÜÊñπÂºè„ÄÇÂè¶Â§ñËØ•ÂáΩÊï∞ËøòË¶ÅÁ°ÆÂÆö‰ªÄ‰πàÊó∂ÂÄôÂÅúÊ≠¢ÂàáÂàÜÔºå‰∏ÄÊó¶ÂÅúÊ≠¢ÂàáÂàÜ‰ºöÁîüÊàê‰∏Ä‰∏™Âè∂ËäÇÁÇπ„ÄÇÂõ†Ê≠§chooseBestSplit()ÂáΩÊï∞ÈúÄË¶ÅÂÆåÊàê‰∏§‰ª∂‰∫ãÔºöÁî®ÊúÄ‰Ω≥ÊñπÂºèÂàáÂàÜÊï∞ÊçÆÈõÜÂíåÁîüÊàêÁõ∏Â∫îÁöÑÂè∂ËäÇÁÇπ„ÄÇ leafTypeÊòØÂØπÂàõÂª∫Âè∂ËäÇÁÇπÁöÑÂáΩÊï∞ÁöÑÂºïÁî®ÔºåerrTypeÊòØÂØπÂâçÈù¢‰ªãÁªçÁöÑÊÄªÊñπÂ∑ÆËÆ°ÁÆóÂáΩÊï∞ÁöÑÂºïÁî®ÔºåËÄåopsÊòØ‰∏Ä‰∏™Áî®Êà∑ÂÆö‰πâÁöÑÂèÇÊï∞ÊûÑÊàêÁöÑÂÖÉÁªÑÔºåÁî®Â∑≤ÂÆåÊàêÊ†ëÁöÑÊûÑÂª∫„ÄÇ ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö ÂØπÊØè‰∏™ÁâπÂæÅÔºö ÂØπÊØè‰∏™ÁâπÂæÅÂÄºÔºö Â∞ÜÊï∞ÊçÆÈõÜÂàáÂàÜÊàê‰∏§‰ªΩ ËÆ°ÁÆóÂàáÂàÜÁöÑËØØÂ∑Æ Â¶ÇÊûúÂΩìÂâçËØØÂ∑ÆÂ∞è‰∫éÂΩìÂâçÊúÄÂ∞èËØØÂ∑ÆÔºåÈÇ£‰πàÂ∞ÜÂΩìÂâçÂàáÂàÜËÆæÂÆö‰∏∫ÊúÄ‰Ω≥ÂàáÂàÜÂπ∂Êõ¥Êñ∞ÊúÄÂ∞èËØØÂ∑Æ ËøîÂõûÊúÄ‰Ω≥ÂàáÂàÜÁöÑÁâπÂæÅÂíåÈòàÂÄº 123456789101112131415161718192021222324252627282930313233def chooseBestSplit(dataSet, leafType=regLeaf, errType=regErr, ops=(1, 4)): tolS = ops[0] tolN = ops[1] if len(set(dataSet[:, -1].T.tolist()[0])) == 1: # Â¶ÇÊûúÊâÄÊúâÂÄºÁõ∏Á≠âÂàôÈÄÄÂá∫ return None, leafType(dataSet) m, n = shape(dataSet) S = errType(dataSet) bestS = inf bestIndex = 0 bestValue = 0 for featIndex in range(n-1): for splitVal in set(dataSet[:, featIndex].tolist()[0]): mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal) if (shape(mat0)[0] &lt; tolN) or (shape(mat1)[0] &lt; tolN) : continue newS = errType(mat0) + errType(mat1) if newS &lt; bestS: bestIndex = featIndex bestValue = splitVal bestS = newS if (S - bestS) &lt; tolS: # Â¶ÇÊûúËØØÂ∑ÆÂáèÂ∞è‰∏çÂ§ßÂàôÈÄÄÂá∫ return None, leafType(dataSet) mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue) if (shape(mat0)[0] &lt; tolN) or (shape(mat1)[0] &lt; tolN): # Â¶ÇÊûúÂàáÂàÜÂá∫ÁöÑÊï∞ÊçÆÈõÜÂæàÂ∞èÂàôÈÄÄÂá∫ return None, leafType(dataSet) return bestIndex, bestValue regLeaf()ÂÆÉË¥üË¥£ÁîüÊàêÂè∂ËäÇÁÇπ„ÄÇÂΩìchooseBestSplit()ÂáΩÊï∞Á°ÆÂÆö‰∏çÂÜçÂØπÊï∞ÊçÆËøõË°åÂàáÂàÜÊó∂ÔºåÂ∞ÜË∞ÉÁî®ËØ•regLeaf()ÂáΩÊï∞Êù•ÂæóÂà∞Âè∂ËäÇÁÇπÁöÑÊ®°ÂûãÔºåÂú®ÂõûÂΩíÊ†ë‰∏≠ÔºåËØ•Ê®°ÂûãÂ∞±ÊòØÁõÆÊ†áÂèòÈáèÁöÑÂùáÂÄº„ÄÇ regErr()ÊòØËØØÂ∑Æ‰º∞ËÆ°ÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞Âú®ÁªôÂÆöÊï∞ÊçÆ‰∏äËÆ°ÁÆóÁõÆÊ†áÂèòÈáèÁöÑÂπ≥ÊñπËØØÂ∑ÆÔºåÂΩìÁÑ∂‰πüÂèØ‰ª•ÂÖàËÆ°ÁÆóÂá∫ÂùáÂÄºÔºåÁÑ∂ÂêéËÆ°ÁÆóÊØè‰∏™Â∑ÆÂÄºÂÜçÂπ≥Êñπ„ÄÇÂõ†‰∏∫ËøôÈáåÈúÄË¶ÅÊÄªÊñπÂ∑ÆÔºåÊâÄ‰ª•Áî®ÂùáÊñπÂ∑ÆÂáΩÊï∞var()ÁöÑÁªìÊûú‰πò‰ª•Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÊ†∑Êú¨‰∏™Êï∞„ÄÇ chooseBestSplit()ËØ•ÂáΩÊï∞ÁöÑÁõÆÁöÑÊòØÊâæÂà∞Êï∞ÊçÆÁöÑÊúÄ‰Ω≥‰∫åÂÖÉÂàáÂàÜÊñπÂºè„ÄÇÂ¶ÇÊûúÊâæ‰∏çÂà∞‰∏Ä‰∏™Â•ΩÁöÑ‰∫åÂÖÉÂàáÂàÜÔºåËØ•ÂáΩÊï∞ËøîÂõûNoneÂπ∂ÂêåÊó∂Ë∞ÉÁî®createTree()ÊñπÊ≥ïÊù•‰∫ßÁîüÂè∂ËäÇÁÇπÔºåÂè∂ËäÇÁÇπÁöÑÂÄº‰πüÂ∞ÜËøîÂõûNone„ÄÇopsËÆæÂÆö‰∫ÜtolSÂíåtolN‰∏§‰∏™ÂÄºÔºåtolSÊòØÂÆπËÆ∏ÁöÑËØØÂ∑Æ‰∏ãÈôçÂÄºÔºåtolNÊòØÂàáÂàÜÁöÑÊúÄÂ∞ëÊ†∑Êú¨Êï∞„ÄÇ ËøêË°å‰ª£Á†Å1myDat = loadDataSet('MLiA_SourceCode/Ch09/ex00.txt') 1myMat = mat(myDat) 1createTree(myMat) {&apos;spInd&apos;: 0, &apos;spVal&apos;: 0.036098, &apos;left&apos;: 0.5878577680412371, &apos;right&apos;: 0.050698999999999994} 1234567import matplotlib.pyplot as pltdef plotScatter(data): fig = plt.figure() ax = fig.add_subplot(111) #print(myMat) ax.scatter(data[:, 0].T.tolist()[0], data[:, 1].T.tolist()[0], 5, c='red') plt.show() 1plotScatter(myMat) 123myDat = loadDataSet('MLiA_SourceCode/Ch09/ex0.txt')myMat = mat(myDat)createTree(myMat) {&apos;spInd&apos;: 1, &apos;spVal&apos;: 0.409175, &apos;left&apos;: {&apos;spInd&apos;: 1, &apos;spVal&apos;: 0.663687, &apos;left&apos;: {&apos;spInd&apos;: 1, &apos;spVal&apos;: 0.725426, &apos;left&apos;: 3.7206952592592595, &apos;right&apos;: 2.998615611111111}, &apos;right&apos;: 2.2076016800000002}, &apos;right&apos;: 0.45470547435897446} 1plotScatter(myMat[:, 1:]) Ê†ëÂâ™ÊûùÈÄöËøáÈôç‰ΩéÂÜ≥Á≠ñÊ†ëÁöÑÂ§çÊùÇÂ∫¶Êù•ÈÅøÂÖçËøáÊãüÂêàÁöÑËøáÁ®ãÁß∞‰∏∫Ââ™ÊûùÔºàpruningÔºâ„ÄÇ È¢ÑÂâ™ÊûùÊ†ëÊûÑÂª∫ÁÆóÊ≥ïÂÖ∂ÂÆûÂØπËæìÂÖ•ÁöÑÂèÇÊï∞tolSÂíåtolNÈùûÂ∏∏ÊïèÊÑüÔºåÂØπopsÂèÇÊï∞Ë∞ÉÊï¥Â∞±ÊòØÈ¢ÑÂâ™Êûù„ÄÇ ÂêéÂâ™ÊûùÂà©Áî®ÊµãËØïÈõÜÊù•ÂØπÊ†ëËøõË°åÂâ™ÊûùÔºå‰∏çÈúÄË¶ÅÁî®Êà∑ÊåáÂÆöÂèÇÊï∞Ôºå‰∏∫ÂêéÂâ™Êûù„ÄÇ prune()‰º™‰ª£Á†ÅÂ¶Ç‰∏ã Âü∫‰∫éÂ∑≤ÊúâÁöÑÊ†ëÂàáÂàÜÊµãËØïÊï∞ÊçÆÔºö Â¶ÇÊûúÂ≠òÂú®‰ªª‰∏ÄÂ≠êÈõÜÊòØ‰∏ÄÊ£µÊ†ëÔºåÂàôÂú®ËØ•Â≠êÈõÜÈÄíÂΩíÂâ™ÊûùËøáÁ®ã ËÆ°ÁÆóÂ∞ÜÂΩìÂâç‰∏§‰∏™Âè∂ËäÇÁÇπÂêàÂπ∂ÂêéÁöÑËØØÂ∑Æ ËÆ°ÁÆó‰∏çÂêàÂπ∂ÁöÑËØØÂ∑Æ Â¶ÇÊûúÂêàÂπ∂Èôç‰ΩéËØØÂ∑ÆÔºåÂ∞±Â∞ÜÂè∂ËäÇÁÇπÂêàÂπ∂ 123456789101112131415161718192021222324252627282930def isTree(obj): return (type(obj).__name__=='dict')def getMean(tree): if isTree(tree['right']): tree['right'] = getMean(tree['right']) if isTree(tree['left']): tree['left'] = getMean(tree['left']) return (tree['left']+tree['right'])/2.0 def prune(tree, testData): if shape(testData)[0] == 0: return getMean(tree) # if we have no test data collapse the tree if (isTree(tree['right']) or isTree(tree['left'])): # if the branches are not trees try to prune them lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal']) if isTree(tree['left']): tree['left'] = prune(tree['left'], lSet) if isTree(tree['right']): tree['right'] = prune(tree['right'], rSet) # if they are now both leafs, see if we can merge them if not isTree(tree['left']) and not isTree(tree['right']): lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal']) errorNoMerge = sum(power(lSet[:,-1] - tree['left'],2)) +\ sum(power(rSet[:,-1] - tree['right'],2)) treeMean = (tree['left']+tree['right'])/2.0 errorMerge = sum(power(testData[:,-1] - treeMean,2)) if errorMerge &lt; errorNoMerge: return treeMean else: return tree else: return tree 12345myDat2 = loadDataSet('MLiA_SourceCode/Ch09/ex2.txt')myMat2 = mat(myDat2)myTree = createTree(myMat2, ops=(0, 1))myDatTest = loadDataSet('MLiA_SourceCode/Ch09/ex2test.txt')myMat2Test = mat(myDatTest) 1prune(myTree, myMat2Test) {&apos;spInd&apos;: 0, &apos;spVal&apos;: 0.228628, &apos;left&apos;: {&apos;spInd&apos;: 0, &apos;spVal&apos;: 0.965969, &apos;left&apos;: 92.5239915, &apos;right&apos;: 65.53919801898735}, &apos;right&apos;: -1.1055498250000002} Ê®°ÂûãÊ†ëÁî®Ê†ëÊù•ÂØπÊï∞ÊçÆÂª∫Ê®°ÔºåÈô§‰∫ÜÂêßÂè∂ËäÇÁÇπÁÆÄÂçïÂú∞ËÆæÂÆö‰∏∫Â∏∏Êï∞ÂÄº‰πãÂ§ñÔºåËøòÊúâ‰∏ÄÁßçÊñπÊ≥ïÊòØÊääÂè∂ËäÇÁÇπËÆæÂÆö‰∏∫ÂàÜÊÆµÁ∫øÊÄßÂáΩÊï∞ÔºåËøôÈáåÊâÄË∞ìÁöÑÂàÜÊÆµÊÄßÔºàpiecewise linearÔºâÊòØÊåáÊ®°ÂûãÁî±Â§ö‰∏™Á∫øÊÄßÁâáÊÆµÁªÑÊàê„ÄÇ ÂÜ≥Á≠ñÊ†ëÁõ∏ÊØîÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑ‰ºòÂäø‰πã‰∏ÄÂú®‰∫éÁªìÊûúÊõ¥ÊòìÁêÜËß£„ÄÇÂæàÊòæÁÑ∂Ôºå‰∏§Êù°Áõ¥Á∫øÊØîÂæàÂ§öËäÇÁÇπÁªÑÊàê‰∏ÄÊ£µÂ§ßÊ†ëÊõ¥ÂÆπÊòìËß£Èáä„ÄÇÊ®°ÂûãÊ†ëÁöÑÂèØËß£ÈáäÊÄßÊòØÂÆÉ‰ºò‰∫éÂõûÂΩíÊ†ëÁöÑÁâπÁÇπ‰πã‰∏Ä„ÄÇÂè¶Â§ñÔºåÊ®°ÂûãÊ†ë‰πüÂÖ∑ÊúâÊõ¥È´òÁöÑÈ¢ÑÊµãÂáÜÁ°ÆÂ∫¶„ÄÇ 12345678910111213141516171819202122def linearSolve(dataSet): m, n = shape(dataSet) X = mat(ones((m, n))) Y = mat(ones((m, 1))) X[:, 1:n] = dataSet[:, 0:n-1] Y = dataSet[:, -1] xTx = X.T*X if linalg.det(xTx) == 0.0: raise NameError('This matrix is singular, cannot do inverse,\ try increasing the second value of ops') ws = xTx.I * (X.T * Y) return ws, X, Ydef modelLeaf(dataSet): ws, X, Y = linearSolve(dataSet) def modelErr(dataSet): ws, X, Y = linearSolve(dataSet) yHat = X * ws return sum(power(Y - yHat, 2)) 1createTree(myMat2, modelLeaf, modelErr, (1, 10)) {&apos;spInd&apos;: 0, &apos;spVal&apos;: 0.228628, &apos;left&apos;: None, &apos;right&apos;: None} ÊÄªÁªìËøô‰∏ÄÁ´†Êèê‰æõÁöÑcodeÊúâÂæàÂ§öÈîôËØØÔºå‰øÆÊ≠£ÂêéÂπ∂‰∏çËÉΩÂæóÂà∞‰π¶‰∏≠ÁöÑÁ≠îÊ°à„ÄÇÂ¶ÇÊûúË¶Å‰ΩøÁî®Ê†ëÁÆóÊ≥ïÔºåËøòÊòØÂª∫ËÆÆ‰ΩøÁî®sklearnÔºåËÄåÈùûËá™Â∑±ÁºñÂÜô„ÄÇ CARTÁÆóÊ≥ïÂèØ‰ª•Áî®‰∫éÊûÑÂª∫‰∫åÂÖÉÊ†ëÂπ∂Â§ÑÁêÜÁ¶ªÊï£ÂûãÊàñËøûÁª≠ÂûãÊï∞ÊçÆÁöÑÂàáÂàÜ„ÄÇËã•‰ΩøÁî®‰∏çÂêåÁöÑËØØÂ∑ÆÂáÜÂàôÔºåÂ∞±ÂèØ‰ª•ÈÄöËøáCARTÁÆóÊ≥ïÊûÑÂª∫Ê®°ÂûãÊ†ëÂíåÂõûÂΩíÊ†ë„ÄÇËØ•ÁÆóÊ≥ïÊûÑÂª∫Âá∫ÁöÑÊ†ë‰ºöÂÄæÂêë‰∫éÂØπÊï∞ÊçÆËøáÊãüÂêà„ÄÇËøáÊãüÂêàÁöÑÊ†ëÂçÅÂàÜÂ§çÊùÇÔºåÂâ™ÊûùÂèØ‰ª•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>Ê†ëÂõûÂΩí</tag>
        <tag>CSRTÁÆóÊ≥ï</tag>
        <tag>Ê†ëÂâ™ÊûùÁÆóÊ≥ï</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂÖ´Ôºâ]]></title>
    <url>%2F2020%2F04%2F20%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%85%AB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[È¢ÑÊµãÊï∞ÂÄºÂûãÊï∞ÊçÆÔºöÂõûÂΩíÂàÜÁ±ªÁöÑÁõÆÊ†áÂèòÈáèÊòØÊ†áÁß∞ÂûãÊï∞ÊçÆÔºåËÄåÂõûÂΩíÊòØÂØπËøûÁª≠ÊÄßÊï∞ÊçÆÂÅöÂá∫È¢ÑÊµã„ÄÇ Áî®Á∫øÊÄßÂõûÂΩíÊâæÂà∞ÊúÄ‰Ω≥ÊãüÂêàÁõ¥Á∫øÁ∫øÊÄßÂõûÂΩí ‰ºòÁÇπÔºöÁªìÊûúÊòì‰∫éÁêÜËß£ÔºåËÆ°ÁÆó‰∏ä‰∏çÂ§çÊùÇ Áº∫ÁÇπÔºöÂØπÈùûÁ∫øÊÄßÁöÑÊï∞ÊçÆÊãüÂêà‰∏çÂ•Ω ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞ÂûãÊï∞ÊçÆ ÂõûÂΩíÁöÑÁõÆÁöÑÊòØÈ¢ÑÊµãÊï∞ÂÄºÂûãÁöÑÁõÆÊ†áÂÄº„ÄÇÊúÄÁõ¥Êé•ÁöÑÂäûÊ≥ïÊòØ‰æùÊçÆËæìÂÖ•ÂÜôÂá∫‰∏Ä‰∏™ÁõÆÊ†áÂÄºÁöÑËÆ°ÁÆóÂÖ¨Âºè„ÄÇ Z = 0.1*X + 0.2*Y ËøôÂ∞±ÊòØÊâÄË∞ìÁöÑÂõûÂΩíÊñπÁ®ãÔºàregression equationÔºâÂÖ∂‰∏≠0.1Âíå0.2Áß∞‰ΩúÂõûÂΩíÁ≥ªÊï∞Ôºàregression weightsÔºâÔºåÊ±ÇÂõûÂΩíÁ≥ªÊï∞ÁöÑËøáÁ®ãÂ∞±ÊòØÂõûÂΩí„ÄÇ ÂõûÂΩíÁöÑ‰∏ÄËà¨ÊñπÊ≥ïÔºö Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÂõûÂΩíÈúÄË¶ÅÊï∞ÂÄºÂûãÊï∞ÊçÆÔºåÊ†áÁß∞ÂûãÊï∞ÊçÆÂ∞ÜË¢´ËΩ¨Êç¢Êàê‰∫åËøõÂà∂Êï∞ÊçÆ ÂàÜÊûêÊï∞ÊçÆÔºöÁªòÂá∫Êï∞ÊçÆÁöÑÂèØËßÜÂåñ‰∫åÁª¥ÂõæÂ∞ÜÊúâÂä©‰∫éÂØπÊï∞ÊçÆÂÅöÂá∫ÁêÜËß£ÂíåÂàÜÊûêÔºåÂú®ÈááÁî®Áº©ÂáèÊ≥ïÊ±ÇÂæóÊñ∞ÂõûÂΩíÁ≥ªÊï∞‰πãÂêéÔºåÂèØ‰ª•Â∞ÜÊñ∞ÊãüÂêàÁ∫øÁªòÂà∂Âú®Âõæ‰∏ä‰Ωú‰∏∫ÂØπÊØî ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÊâæÂà∞ÂõûÂΩíÁ≥ªÊï∞ ÊµãËØïÁÆóÊ≥ïÔºöÈÄÇÁî®$R^2$ÊàñËÄÖÈ¢ÑÊµãÂÄºÂíåÊï∞ÊçÆÁöÑÊãüÂêàÂ∫¶ÔºåÊù•ÂàÜÊûêÊ®°ÂûãÁöÑÊïàÊûú ‰ΩøÁî®ÁÆóÊ≥ïÔºö‰ΩøÁî®ÂõûÂΩíÔºåÂèØ‰ª•Âú®ÁªôÂÆöËæìÂÖ•ÁöÑÊó∂ÂÄôÈ¢ÑÊµãÂá∫‰∏Ä‰∏™Êï∞ÂÄºÔºåËøôÊòØÂØπÂàÜÁ±ªÊñπÊ≥ïÁöÑÊèêÂçáÔºåÂõ†‰∏∫ËøôÊ†∑ÂèØ‰ª•È¢ÑÊµãËøûÁª≠ÊÄßÊï∞ÊçÆËÄå‰∏ç‰ªÖ‰ªÖÊòØÁ¶ªÊï£ÁöÑÁ±ªÂà´Ê†áÁ≠æ ÂÅáÂ¶ÇËæìÂÖ•Êï∞ÊçÆ‰∏∫Áü©Èòµ$X$ÔºåÂõûÂΩíÁ≥ªÊï∞‰∏∫ÂêëÈáè$w$ÔºåÂØπ‰∫éÁªôÂÆöÁöÑÊï∞ÊçÆ$X_1$È¢ÑÊµãÁªìÊûúÂ∞Ü‰ºöÈÄöËøá$Y_1=X^T_1w$ÂæóÂà∞„ÄÇ ÊâæÂà∞$w$ÁöÑÊñπÊ≥ïÊòØÊâæÂà∞‰ΩøËØØÂ∑ÆÊúÄÂ∞èÁöÑ$w$ÔºåËØØÂ∑ÆÊåáÈ¢ÑÊµãÂÄºÂíåÁúüÂÆûÂÄº‰πãÈó¥ÁöÑÂ∑ÆÂÄºÔºå‰ΩøÁî®ËØ•Â∑ÆÂÄºÁÆÄÂçïÁöÑÁ¥ØÂä†Â∞Ü‰ΩøÊ≠£Â∑ÆÂÄºÂíåË¥üÂ∑ÆÂÄºÁõ∏‰∫íÊäµÊ∂àÔºåÊâÄ‰ª•ÈááÁî®Âπ≥ÊñπËØØÂ∑Æ„ÄÇ Âπ≥ÊñπËØØÂ∑ÆÂèØ‰ª•ÂÜô‰ΩúÔºö $$\sum_{i=1}^m(y_i-x_i^Tw)^2$$ Áî®Áü©ÈòµË°®Á§∫ÂèØ‰ª•ÂÜô‰Ωú: $$(y-Xw)^T(y-Xw)$$ ÂØπ$w$Ê±ÇÂØºÔºåÂæóÂà∞$X^T(Y-Xw)$Ôºå‰ª§ÂÖ∂Á≠â‰∫é0ÔºåËß£Âá∫ $$w=(X^TX)^{-1}X^Ty$$ $(X^TX)^{-1}$Ë°®Á§∫Áü©ÈòµÁöÑÈÄÜÔºåÁü©ÈòµÁöÑÈÄÜÂèØËÉΩÂπ∂‰∏çÂ≠òÂú®ÔºåÂõ†Ê≠§Ë¶ÅÂú®‰ª£Á†Å‰∏≠‰ΩúÂá∫Âà§Êñ≠„ÄÇ ‰∏äËø∞ÊñπÊ≥ï‰πüÁß∞‰ΩúOLS‚ÄúÊôÆÈÄöÊúÄÂ∞è‰∫å‰πòÊ≥ï‚ÄùÔºàordinary least squaresÔºâ 123456789101112131415161718192021222324from numpy import *def loadDataSet(fileName): #general function to parse tab -delimited floats numFeat = len(open(fileName).readline().split('\t')) - 1 #get number of fields dataMat = []; labelMat = [] fr = open(fileName) for line in fr.readlines(): lineArr =[] curLine = line.strip().split('\t') for i in range(numFeat): lineArr.append(float(curLine[i])) dataMat.append(lineArr) labelMat.append(float(curLine[-1])) return dataMat,labelMatdef standRegres(xArr, yArr): xMat = mat(xArr) yMat = mat(yArr).T xTx = xMat.T*xMat if linalg.det(xTx) == 0.0: print("This matrix is singular, cannot do inverse") return ws = xTx.I * (xMat.T*yMat) return ws 12xArr, yArr = loadDataSet('MLiA_SourceCode/Ch08/ex0.txt')xArr[0:2] [[1.0, 0.067732], [1.0, 0.42781]] 12ws = standRegres(xArr, yArr)ws matrix([[3.00774324], [1.69532264]]) 123xMat = mat(xArr)yMat = mat(yArr)yHat = xMat*ws 123456789import matplotlib.pyplot as pltfig = plt.figure()ax = fig.add_subplot(111)ax.scatter(xMat[:,1].flatten().A[0], yMat.T[:,0].flatten().A[0], 10)xCopy = xMat.copy()xCopy.sort(0)yHat=xCopy*wsax.plot(xCopy[:,1], yHat)plt.show() Âá†‰πé‰ªªÊÑèÊï∞ÊçÆÈÉΩÂèØ‰ª•Áî®‰∏äËø∞Ê≥ïÊîæÂª∫Á´ãÊ®°ÂûãÔºåÊúâ‰∏ÄÁßçÊñπÊ≥ïÂèØ‰ª•ËÆ°ÁÆóÈ¢ÑÊµãÂÄºyHatÂ∫èÂàóÂíåÁúüÂÆûÂÄºyÂ∫èÂàóÁöÑÁõ∏ÂÖ≥Á≥ªÊï∞Êù•Èâ¥Âà´ÊãüÂêàÊïàÊûú„ÄÇ Âú®python‰∏≠ÂèØ‰ª•Áî®numpyÂ∫ìÁöÑcorrcoef(yEstimate, yActual)Êù•ËÆ°ÁÆóÁõ∏ÂÖ≥ÊÄß„ÄÇ 12yHat = xMat*wscorrcoef(yHat.T, yMat) array([[1. , 0.98647356], [0.98647356, 1. ]]) ‰∏äÈù¢ÁöÑÁü©ÈòµÂåÖÂê´ÊâÄÊúâ‰∏§‰∏§ÁªÑÂêàÁöÑÁõ∏ÂÖ≥Á≥ªÊï∞ÔºåÂØπËßíÁ∫ø‰∏∫1.0ÊòØÂõ†‰∏∫yMatÂíåËá™Â∑±ÂåπÈÖçÊòØÂÆåÁæéÁöÑÔºåyHatÂíåyMatÁöÑÁõ∏ÂÖ≥Á≥ªÊï∞‰∏∫0.98„ÄÇ Â±ÄÈÉ®Âä†ÊùÉÁ∫øÊÄßÂõûÂΩíÁ∫øÊÄßÂõûÂΩíÊúâÂèØËÉΩÂá∫Áé∞Ê¨†ÊãüÂêàÔºåÂõ†‰∏∫Ê±ÇÁöÑÂÖ∑ÊúâÊúÄÂ∞èÂùáÊñπËØØÂ∑ÆÁöÑÊó†ÂÅè‰º∞ËÆ°„ÄÇÂèØ‰ª•ÂºïÂÖ•‰∏Ä‰∫õÂÅèÂ∑ÆÔºå‰ªéËÄåÈôç‰ΩéÈ¢ÑÊµãÁöÑÂùáÊñπËØØÂ∑Æ„ÄÇÂÖ∂‰∏≠‰∏Ä‰∏™ÊñπÊ≥ïÊòØÂ±ÄÈÉ®Âä†ÊùÉÁ∫øÊÄßÂõûÂΩíÔºàlocally weighted linear regressionÔºå LWLRÔºâÔºåÂú®ËØ•ÁÆóÊ≥ï‰∏≠ÔºåÊàë‰ª¨ÁªôÂæÖÈ¢ÑÊµãÁÇπÈôÑËøëÁöÑÊØè‰∏™ÁÇπËµã‰∫à‰∏ÄÂÆöÁöÑÊùÉÈáçÔºõÁÑ∂ÂêéÂú®Ëøô‰∏™Â≠êÈõÜ‰∏äÂü∫‰∫éÊúÄÂ∞èÂùáÊñπÂ∑ÆÊù•ËøõË°åÊôÆÈÄöÁöÑÂõûÂΩí„ÄÇ‰∏éKNN‰∏ÄÊ†∑ÔºåËøôÁßçÁÆóÊ≥ïÊØèÊ¨°È¢ÑÊµãÈúÄË¶Å‰∫ãÂÖàÈÄâÂèñÂá∫ÂØπÂ∫îÁöÑÊï∞ÊçÆÂ≠êÈõÜÔºåËØ•ÁÆóÊ≥ïËß£Âá∫ÁöÑÂõûÂΩíÁ≥ªÊï∞wÁöÑÂΩ¢ÂºèÂ¶Ç‰∏ã $$w=(X^TWX)^{-1}X^TW_y$$ ÂÖ∂‰∏≠wÊòØ‰∏Ä‰∏™Áü©ÈòµÔºåÁî®Êù•ÁªôÊØè‰∏™Êï∞ÊçÆÁÇπËµã‰∫àÊùÉÈáç„ÄÇ LWLR‰ΩøÁî®‚ÄúÊ†∏‚ÄùÔºà‰∏éÊîØÊåÅÂêëÈáèÊú∫Á±ª‰ººÔºâÊù•ÂØπÈôÑËøëÁöÑÁÇπËµã‰∫àÊõ¥È´òÁöÑÊùÉÈáç„ÄÇÊúÄÂ∏∏Áî®ÁöÑÊòØÈ´òÊñØÊ†∏ÔºåÂõ†‰∏∫È´òÊñØÊ†∏Á¨¶ÂêàÊ≠£ÊÄÅÂàÜÂ∏ÉÔºåÈ´òÊñØÊ†∏ÂØπÂ∫îÁöÑÊùÉÈáçÂ¶Ç‰∏ãÔºö $$w(i,i)=exp(\frac{|x^{i}-x|}{-2k^2})$$ ËøôÊ†∑Â∞±ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âè™Âê´ÂØπËßíÂÖÉÁ¥†ÁöÑÊùÉÈáçÁü©ÈòµwÔºåÂπ∂‰∏îÁÇπx‰∏éx(i)Ë∂äËøëÔºåw(i,i)Â∞Ü‰ºöË∂äÂ§ß„ÄÇ‰∏äËø∞ÂÖ¨ÂºèÂåÖÂê´‰∫Ü‰∏Ä‰∏™ÈúÄË¶ÅÁî®Êà∑ÊåáÂÆöÁöÑÂèÇÊï∞kÔºåÂÆÉÂÜ≥ÂÆö‰∫ÜÂØπÈôÑËøëÁöÑÁÇπËµã‰∫àÂ§öÂ§ßÁöÑÊùÉÈáçÔºåËøôÊòØ‰ΩøÁî®LWLRÊó∂ÂîØ‰∏ÄË¶ÅËÄÉËôëÁöÑÂèÇÊï∞„ÄÇ‰∏ãÂõæÂèØ‰ª•ÁúãÂà∞ÂèÇÊï∞k‰∏éÊùÉÈáçÁöÑÂÖ≥Á≥ª ÊØè‰∏™ÁÇπÁöÑÊùÉÈáçÂõæÔºàÂÅáÂÆöÊàë‰ª¨Ê≠£È¢ÑÊµãÁöÑÁÇπÊòØ=0.5ÔºâÔºåÊúÄ‰∏äÈù¢ÁöÑÂõæÊòØÂéüÂßãÊï∞ÊçÆÈõÜÔºåÁ¨¨‰∫å‰∏™ÂõæÊòæÁ§∫‰∫ÜÂΩìk=0.5Êó∂ÔºåÂ§ßÈÉ®ÂàÜÁöÑÊï∞ÊçÆÈÉΩÁî®‰∫éËÆ≠ÁªÉÂõûÂΩíÊ®°ÂûãÔºåÊúÄ‰∏ãÈù¢ÁöÑÂõæÊòæÁ§∫ÁöÑÊòØÂΩìk=0.01Êó∂Ôºå‰ªÖÊúâÂæàÂ∞ëÁöÑÂ±ÄÈÉ®ÁÇπË¢´Áî®‰∫éËÆ≠ÁªÉÂõûÂΩíÊ®°Âûã„ÄÇ 1234567891011121314151617181920212223def lwlr(testPoint, xArr, yArr, k=1.0): xMat = mat(xArr) yMat = mat(yArr).T m = shape(xMat)[0] # ÂàõÂª∫ÂØπËßíÁü©Èòµ weights = mat(eye((m))) for j in range(m): diffMat = testPoint - xMat[j, :] # ÊùÉÈáçÂ§ßÂ∞è‰ª•ÊåáÊï∞Á∫ßË°∞Âáè weights[j, j] = exp(diffMat*diffMat.T/(-2.0*k**2)) xTx = xMat.T * (weights * xMat) if linalg.det(xTx) == 0.0: print('This matrix is singular, cannot do inverse') return ws = xTx.I * (xMat.T * (weights * yMat)) return testPoint * wsdef lwlrTest(testArr, xArr, yArr, k=1.0): m = shape(testArr)[0] yHat = zeros(m) for i in range(m): yHat[i] = lwlr(testArr[i], xArr, yArr, k) return yHat lwlr()ÁöÑ‰ΩúÁî®ÊòØÔºåÁªôÂÆöxÁ©∫Èó¥‰∏≠ÁöÑ‰ªªÊÑè‰∏ÄÁÇπÔºåËÆ°ÁÆóÂá∫ÂØπÂ∫îÁöÑÈ¢ÑÊµãÂÄºyHat„ÄÇÊùÉÈáçÁü©ÈòµÊòØ‰∏Ä‰∏™ÊñπÈòµÔºåÈò∂Êï∞Á≠â‰∫éÊ†∑Êú¨ÁÇπ‰∏™Êï∞„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåËØ•Áü©Èòµ‰∏∫ÊØè‰∏™Ê†∑Êú¨ÂàùÂßãÂåñ‰∫Ü‰∏Ä‰∏™ÊùÉÈáç„ÄÇÊé•ÁùÄÈÅçÂéÜÊï∞ÊçÆÈõÜÔºåËÆ°ÁÆóÊØè‰∏™Ê†∑Êú¨ÁÇπÂØπÂ∫îÁöÑÊùÉÈáçÔºåÈöèÁùÄÊ†∑Êú¨ÁÇπ‰∏éÂæÖÈ¢ÑÊµãÁÇπË∑ùÁ¶ªÁöÑÈÄíÂ¢ûÔºåÊùÉÈáçÂ∞Ü‰ª•ÊåáÊï∞Á∫ßË°∞Âáè„ÄÇËæìÂÖ•ÂèÇÊï∞KÊéßÂà∂Ë°∞ÂáèÈÄüÂ∫¶„ÄÇ ÊµãËØïÁÆóÊ≥ïÔºåÂØπÂçïÁÇπËøõË°å‰º∞ËÆ°Ôºö 1xArr[:2], yArr[:2] ([[1.0, 0.067732], [1.0, 0.42781]], [3.176513, 3.816464]) 1lwlr(xArr[0], xArr, yArr, 1.0) matrix([[3.12204471]]) 1lwlr(xArr[0], xArr, yArr, 0.001) matrix([[3.20175729]]) ÂØπÊâÄÊúâÊï∞ÊçÆÁÇπ‰º∞ËÆ°ÔºåÂπ∂ÁªòÂõæÔºö 123yHat1 = lwlrTest(xArr, xArr, yArr, k=1.0)yHat2 = lwlrTest(xArr, xArr, yArr, k=0.01)yHat3 = lwlrTest(xArr, xArr, yArr, k=0.003) 123456789def plotLwlr(xArr, yHat): xMat = mat(xArr) srtInd = xMat[:, 1].argsort(0) xSort = xMat[srtInd][:, 0, :] fig = plt.figure() ax = fig.add_subplot(111) ax.plot(xSort[:, 1], yHat[srtInd]) ax.scatter(xMat[:, 1].flatten().A[0], mat(yArr).T.flatten().A[0], 2, c='red') plt.show() 123plotLwlr(xArr, yHat1)plotLwlr(xArr, yHat2)plotLwlr(xArr, yHat3) ÂΩìk=1.0Êó∂ÔºåÊùÉÈáçÂæàÂ§ßÔºåÂ¶ÇÂêåÂ∞ÜÊâÄÊúâÊï∞ÊçÆËßÜ‰∏∫Á≠âÊùÉÈáçÔºåÂæóÂà∞ÁöÑÊúÄ‰Ω≥ÊãüÂêàÁõ¥Á∫øÂíåÊ†áÂáÜÂõûÂΩí‰∏ÄËá¥ ÂΩìk=0.01Êó∂ÔºåÂæóÂà∞‰∫ÜÈùûÂ∏∏Â•ΩÁöÑÊïàÊûúÔºåÊäì‰Ωè‰∫ÜÊï∞ÊçÆÁöÑÊΩúÂú®Ê®°Âºè ÂΩìk=0.003Êó∂ÔºåÊãüÂêàÁöÑÁõ¥Á∫ø‰∏éÊï∞ÊçÆÁÇπËøá‰∫éË¥¥ËøëÔºåËøáÊãüÂêà Â±ÄÈÉ®Âä†ÊùÉÁ∫øÊÄßÂõûÂΩí‰πüÂ≠òÂú®‰∏Ä‰∏™ÈóÆÈ¢òÔºåÂç≥Â¢ûÂä†‰∫ÜËÆ°ÁÆóÈáèÔºåÂõ†‰∏∫ÂÆÉÂØπÊØè‰∏™ÁÇπÂÅöÈ¢ÑÊµãÊó∂ÈÉΩÂøÖÈ°ª‰ΩøÁî®Êï¥‰∏™Êï∞ÊçÆÈõÜ„ÄÇ ÂÆû‰æãÔºöÈ¢ÑÊµãÈ≤çÈ±ºÁöÑÂπ¥ÈæÑÈ≤çÈ±ºÂπ¥ÈæÑÂèØ‰ª•‰ªéÈ≤çÈ±ºÂ£≥ÁöÑÂ±ÇÊï∞Êù•Êé®ÁÆóÂæóÂà∞„ÄÇ 12def rssError(yArr, yHatArr): return ((yArr-yHatArr)**2).sum() 1234abX, abY = loadDataSet('MLiA_SourceCode/Ch08/abalone.txt')yHat01 = lwlrTest(abX[: 99], abX[: 99], abY[: 99], 0.1)yHat1 = lwlrTest(abX[: 99], abX[: 99], abY[: 99], 1)yHat10 = lwlrTest(abX[: 99], abX[: 99], abY[: 99], 10) ÂàÜÊûêËØØÂ∑ÆÂ§ßÂ∞è 1rssError(abY[: 99], yHat01.T) 56.78868743048742 1rssError(abY[: 99], yHat1.T) 429.8905618704059 1rssError(abY[: 99], yHat10.T) 549.1181708828803 ÂèØ‰ª•ÁúãÂá∫Ôºå‰ΩøÁî®ËæÉÂ∞èÁöÑÊ†∏ÔºåÂèØ‰ª•ÂæóÂà∞ËæÉ‰ΩéÁöÑËØØÂ∑ÆÔºå‰ΩÜÂØπÊñ∞ÁöÑÊï∞ÊçÆ‰∏ç‰∏ÄÂÆöËÉΩËææÂà∞ÂæàÂ•ΩÁöÑÈ¢ÑÊµãÊïàÊûú„ÄÇ 123yHat01 = lwlrTest(abX[100: 199], abX[: 99], abY[: 99], 0.1)yHat1 = lwlrTest(abX[100: 199], abX[: 99], abY[: 99], 1)yHat10 = lwlrTest(abX[100: 199], abX[: 99], abY[: 99], 10) 1rssError(abY[100: 199], yHat01.T) 57913.51550155909 1rssError(abY[100: 199], yHat1.T) 573.5261441894984 1rssError(abY[100: 199], yHat10.T) 517.5711905381573 ‰ªé‰∏äÈù¢ÁöÑÁªìÊûúÂèØ‰ª•ÁúãÂá∫ÔºåÊ†∏ÁöÑÂ§ßÂ∞è‰∏∫10ÁöÑÊó∂ÂÄôÊµãËØïËØØÂ∑ÆÊúÄÂ∞èÔºå‰ΩÜÂú®ËÆ≠ÁªÉÈõÜ‰∏äËØØÂ∑ÆÂç¥ÊúÄÂ§ßÔºåÊé•‰∏ãÊù•ÂíåÁÆÄÂçïÁöÑÁ∫øÊÄßÂõûÂΩíÊØîËæÉÔºö 1ws = standRegres(abX[0: 99], abY[0: 99]) 1yHat = mat(abX[100: 199])*ws 1rssError(abY[100: 199], yHat.T.A) 518.6363153245542 ÁÆÄÂçïÁöÑÁ∫øÊÄßÂõûÂΩíÂíåÂ±ÄÈÉ®Âä†ÊùÉÁ∫øÊÄßÂõûÂΩíÁöÑÁªìÊûúÁ±ª‰ºº„ÄÇ Áº©ÂáèÁ≥ªÊï∞Êù•‚ÄúÁêÜËß£‚ÄùÊï∞ÊçÆÂ¶ÇÊûúÊï∞ÊçÆÁöÑÁâπÂæÅÊØîÊ†∑Êú¨ÁÇπËøòÂ§öÔºàm&gt;nÔºâÔºåËØ¥ÊòéËæìÂÖ•Áü©ÈòµX‰∏çÊòØÊª°Áß©Áü©ÈòµÔºåÊ±ÇÈÄÜÊó∂‰ºöÂá∫ÈîôÔºå‰πüÂ∞±ÊòØÂú®ËÆ°ÁÆó$(X^TX)^{-1}$ÁöÑÊó∂ÂÄô‰ºöÂá∫Èîô„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÁªüËÆ°Â≠¶ÂºïÂÖ•‰∫ÜÂ≤≠ÂõûÂΩíÔºàridge regressionÔºâ„ÄÇ Â≤≠ÂõûÂΩíÁÆÄÂçïÊù•ËØ¥ÔºåÂ≤≠ÂõûÂΩíÂ∞±ÊòØÂú®Áü©Èòµ$(X^TX)$‰∏äÂä†‰∏Ä‰∏™$\lambda I$‰ªéËÄå‰ΩøÁü©ÈòµÈùûÂ•áÂºÇÔºåËøõËÄåÂØπ$(X^TX)+\lambda I$Ê±ÇÈÄÜ„ÄÇÂÖ∂‰∏≠$I$ÊòØ‰∏Ä‰∏™mxmÁöÑÂçï‰ΩçÁü©ÈòµÔºåÂØπËßíÁ∫ø‰∏äÁöÑÂÖÉÁ¥†ÂÖ®‰∏∫1ÔºåÂÖ∂ÂÆÉÂÖÉÁ¥†ÂÖ®‰∏∫0ÔºåÂ≤≠ÂõûÂΩíÂÖ¨Âºè‰∏∫Ôºö $$w = (X^TX + \lambda I)^{-1}X^Ty$$ Â≤≠ÂõûÂΩíÊúÄÂÖàÁî®‰∫éÂ§ÑÁêÜÁâπÂæÅÊï∞Â§ö‰∫éÊ†∑Êú¨Êï∞ÁöÑÊÉÖÂÜµÔºåÁé∞Âú®‰πüÁî®‰∫éÂú®‰º∞ËÆ°‰∏≠Âä†ÂÖ•ÂÅèÂ∑Æ„ÄÇËøôÈáåÈÄöËøáÂºïÂÖ•ŒªÊù•ÈôêÂà∂ÊâÄÊúâw‰πãÂíåÔºåÈÄöËøáÂºïÂÖ•ËØ•ÊÉ©ÁΩöÈ°πÔºåËÉΩÂ§üÂáèÂ∞ë‰∏çÈáçË¶ÅÁöÑÂèÇÊï∞ÔºåËøô‰∏™ÊäÄÊúØÂú®ÁªüËÆ°Â≠¶‰∏≠‰πüÂè´‰ΩúÁº©ÂáèÔºàshrinkageÔºâ„ÄÇ Â≤≠ÂõûÂΩí‰∏≠ÁöÑÂ≤≠ÊòØ‰ªÄ‰πàÔºü Â≤≠ÂõûÂΩí‰ΩøÁî®‰∫ÜÂçï‰ΩçÁü©Èòµ‰πò‰ª•ÂêëÈáèŒªÔºåÊàë‰ª¨ËßÇÂØüÂÖ∂‰∏≠ÁöÑÂçï‰ΩçÁü©ÈòµIÔºåÂèØ‰ª•ÁúãÂà∞IË¥ØÁ©øÊï¥‰∏™ÂØπËßíÁ∫øÔºåÂÖ∂‰ΩôÂÖÉÁ¥†ÂÖ®ÊòØ0„ÄÇÂΩ¢Ë±°Âú∞ÔºåÂú®0ÊûÑÊàêÁöÑÂπ≥Èù¢‰∏äÊúâ‰∏ÄÊù°1ÁªÑÊàêÁöÑ‚ÄúÂ≤≠‚ÄùÔºåËøôÂ∞±ÊòØÂ≤≠ÂõûÂΩí‰∏≠Â≤≠ÁöÑÁî±Êù•„ÄÇ 12345678910111213141516171819202122232425def ridgeRegres(xMat, yMat, lam=0.2): xTx = xMat.T*xMat denom = xTx + eye(shape(xMat)[1]) * lam if linalg.det(denom) == 0: print("This matrix is singular, cannot do invers") return ws = denom.I * (xMat.T * yMat) return wsdef ridgeTest(xArr, yArr): xMat = mat(xArr) yMat = mat(yArr).T # Êï∞ÊçÆÂΩí‰∏ÄÂåñ yMean = mean(yMat, 0) yMat = yMat - yMean xMeans = mean(xMat, 0) xVar = var(xMat, 0) xMat = (xMat - xMeans)/xVar numTestPts = 30 wMat = zeros((numTestPts, shape(xMat)[1])) for i in range(numTestPts): ws = ridgeRegres(xMat, yMat, exp(i-10)) wMat[i, :] = ws.T return wMat ridgeRegres()Áî®‰∫éËÆ°ÁÆóÂõûÂΩíÁ≥ªÊï∞ÔºåËÄåridgeTest()Áî®‰∫éÂú®‰∏ÄÁªÑŒª‰∏äÊµãËØïÁªìÊûú„ÄÇ‰∏∫‰∫Ü‰ΩøÁî®Â≤≠ÂõûÂΩíÂíåÁº©ÂáèÊäÄÊúØÔºåÈ¶ñÂÖàÈúÄË¶ÅÂØπÁâπÂæÅÂÅöÊ†áÂáÜÂåñÂ§ÑÁêÜ„ÄÇ 1ridgeWeights = ridgeTest(abX, abY) 12345plt.rcParams['axes.unicode_minus']=False # Áî®Êù•Ê≠£Â∏∏ÊòæÁ§∫Ë¥üÂè∑fig = plt.figure()ax = fig.add_subplot(111)ax.plot(ridgeWeights)plt.show() ‰∏äÂõæÁªòÂà∂‰∫ÜÂõûÂΩíÁ≥ªÊï∞log(Œª)ÁöÑÂÖ≥Á≥ª„ÄÇÂú®ÊúÄÂ∑¶ËæπÔºåÂç≥ŒªÊúÄÂ∞èÊó∂ÔºåÂèØ‰ª•ÂæóÂà∞ÊâÄÊúâÁ≥ªÊï∞ÁöÑÂéüÂßãÂÄºÔºõËÄåÂú®Âè≥ËæπÔºåÁ≥ªÊï∞ÂÖ®ÈÉ®Áº©ÂáèÊàê0ÔºõÂú®‰∏≠Èó¥ÁöÑÊüêÂÄºÂ∞ÜÂèØ‰ª•ÂèñÂæóÊúÄÂ•ΩÁöÑÈ¢ÑÊµãÊïàÊûú„ÄÇ‰∏∫‰∫ÜÂÆöÈáèÁöÑÊâæÂà∞ÊúÄ‰Ω≥ÂèÇÊï∞ÂÄºÔºåËøòÈúÄË¶ÅËøõË°å‰∫§ÂèâÈ™åËØÅ„ÄÇ ËøòÊúâ‰∏Ä‰∫õÂÖ∂ÂÆÉÁöÑÁº©ÂáèÊñπÊ≥ïÔºå‰æãÂ¶ÇlassoÔºåLARÔºåPCAÂõûÂΩí‰ª•ÂèäÂ≠êÈõÜÈÄâÊã©Á≠âÔºå‰∏éÂ≤≠ÂõûÂΩí‰∏ÄÊ†∑ÔºåËøô‰∫õÊñπÊ≥ï‰∏ç‰ªÖÂèØ‰ª•ÊèêÈ´òÈ¢ÑÊµãÁ≤æÁ°ÆÁéáÔºåËÄå‰∏îÂèØ‰ª•Ëß£ÈáäÂõûÂΩíÁ≥ªÊï∞„ÄÇ ÂêëÂâçÈÄêÊ≠•ÂõûÂΩíÂêëÂâçÈÄêÊ≠•ÁÆóÊ≥ïÂÆÉÂ±û‰∫é‰∏ÄÁßçË¥™ÂøÉÁÆóÊ≥ïÔºåÂç≥ÊØè‰∏ÄÊ≠•ÈÉΩÂ∞ΩÂèØËÉΩÂáèÂ∞èËØØÂ∑ÆÔºå‰∏ÄÂºÄÂßãÔºåÊùÉÈáçÈÉΩËÆæ‰∏∫1ÔºåÁÑ∂ÂêéÊØè‰∏ÄÊ≠•ÊâÄÂÅöÁöÑÂÜ≥Á≠ñÊòØÂØπÊüê‰∏™ÊùÉÈáçÂ¢ûÂä†ÊàñÂáèÂ∞ë‰∏Ä‰∏™ÂæàÂ∞èÁöÑÂÄº„ÄÇ ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö Êï∞ÊçÆÊ†áÂáÜÂåñÔºå‰ΩøÂÖ∂ÂàÜÂ∏ÉÊª°Ë∂≥0ÂùáÂÄºÂíåÂçï‰ΩçÊñπÂ∑Æ Âú®ÊØèËΩÆËø≠‰ª£ËøáÁ®ã‰∏≠Ôºö ËÆæÁΩÆÂΩìÂâçÊúÄÂ∞èËØØÂ∑ÆlowestError‰∏∫Ê≠£Êó†Á©∑ ÂØπÊØè‰∏™ÁâπÂæÅÔºö Â¢ûÂ§ßÊàñÂáèÂ∞èÔºö ÊîπÂèò‰∏Ä‰∏™Á≥ªÊï∞ÂæóÂà∞‰∏Ä‰∏™Êñ∞ÁöÑW ËÆ°ÁÆóÊñ∞W‰∏ãÁöÑËØØÂ∑Æ Â¶ÇÊûúËØØÂ∑ÆErrorÂ∞è‰∫éÂΩìÂâçÊúÄÂ∞èËØØÂ∑ÆlowestErrorÔºöËÆæÁΩÆWbestÁ≠â‰∫éÂΩìÂâçÁöÑW Â∞ÜWËÆæÁΩÆ‰∏∫ÊúÄÊñ∞ÁöÑWbest 1234567891011121314151617181920212223242526272829303132333435def regularize(xMat):#regularize by columns inMat = xMat.copy() inMeans = mean(inMat,0) #calc mean then subtract it off inVar = var(inMat,0) #calc variance of Xi then divide by it inMat = (inMat - inMeans)/inVar return inMatdef stageWise(xArr, yArr, eps=0.01, numIt=100): xMat = mat(xArr) yMat = mat(yArr).T yMean = mean(yMat, 0) yMat = yMat - yMean xMat = regularize(xMat) m, n = shape(xMat) returnMat = zeros((numIt, n)) ws = zeros((n, 1)) wsTest = ws.copy() wsMax = ws.copy() for i in range(numIt): #print(ws.T) lowestError = inf for j in range(n): for sign in [-1, 1]: wsTest = ws.copy() wsTest[j] += eps*sign yTest = xMat*wsTest rssE = rssError(yMat.A, yTest.A) if rssE &lt; lowestError: lowestError = rssE wsMax = wsTest ws = wsMax.copy() returnMat[i, :] = ws.T return returnMat 1stageWise(abX, abY, 0.01, 200) array([[ 0. , 0. , 0. , ..., 0. , 0. , 0. ], [ 0. , 0. , 0. , ..., 0. , 0. , 0. ], [ 0. , 0. , 0. , ..., 0. , 0. , 0. ], ..., [ 0.05, 0. , 0.09, ..., -0.64, 0. , 0.36], [ 0.04, 0. , 0.09, ..., -0.64, 0. , 0.36], [ 0.05, 0. , 0.09, ..., -0.64, 0. , 0.36]]) ‰∏äËø∞ÁªìÊûú‰∏≠w1Âíåw6ÈÉΩÊòØ0ÔºåËøôË°®Á§∫‰ªñ‰ª¨‰∏çÂØπÁõÆÊ†áÂÄºÈÄ†Êàê‰ªª‰ΩïÂΩ±ÂìçÔºå‰πüÂ∞±ÊòØËØ¥Ëøô‰∫õÁâπÂæÅÂèØËÉΩÊòØ‰∏çÈúÄË¶ÅÁöÑÔºåÂè¶Â§ñÔºåÂú®ÂèÇÊï∞epsËÆæÁΩÆ‰∏∫0.01ÁöÑÊÉÖÂÜµ‰∏ãÔºå‰∏ÄÊÆµÊó∂Èó¥ÂêéÔºåÁ≥ªÊï∞Â∞±Â∑≤ÁªèÈ•±ÂíåÔºåÂπ∂Âú®ÁâπÂÆöÂÄº‰πãÈó¥ÈúáËç°ÔºåËøôÊòØÂõ†‰∏∫Ê≠•ÈïøÂ§™Â§ßÁöÑÁºòÊïÖÔºåËøôÈáåÁúãÂà∞Á¨¨‰∏Ä‰∏™ÊùÉÈáçÂú®0.04Âíå0.05‰πãÈó¥ÈúáËç°„ÄÇ 1stageWise(abX, abY, 0.001, 5000) array([[ 0. , 0. , 0. , ..., 0. , 0. , 0. ], [ 0. , 0. , 0. , ..., 0. , 0. , 0. ], [ 0. , 0. , 0. , ..., 0. , 0. , 0. ], ..., [ 0.043, -0.011, 0.12 , ..., -0.963, -0.105, 0.187], [ 0.044, -0.011, 0.12 , ..., -0.963, -0.105, 0.187], [ 0.043, -0.011, 0.12 , ..., -0.963, -0.105, 0.187]]) Êé•ÁùÄÊääËøô‰∫õÁªìÊûú‰∏éÊúÄÂ∞è‰∫å‰πòÊ≥ïÊØîËæÉ„ÄÇ 1234567xMat = mat(abX)yMat = mat(abY).TxMat = regularize(xMat)yM = mean(yMat, 0)yMat = yMat - yMweights = standRegres(xMat, yMat.T)weights.T matrix([[ 0.0430442 , -0.02274163, 0.13214087, 0.02075182, 2.22403814, -0.99895312, -0.11725427, 0.16622915]]) ÂèØ‰ª•ÁúãÂà∞Âú®5000Ê¨°Ëø≠‰ª£‰ª•ÂêéÔºåÈÄêÊ≠•Á∫øÊÄßÂõûÂΩíÁÆóÊ≥ï‰∏éÂ∏∏ËßÑÁöÑÊúÄÂ∞è‰∫å‰πòÊ≥ïÊïàÊûúÁ±ª‰ºº„ÄÇ‰ΩøÁî®0.005ÁöÑepsilonÂÄºÁªèËøá1000Ê¨°Ëø≠‰ª£ÂêéÁöÑÁªìÊûúÂ¶ÇÂõæ„ÄÇÂíå‰ΩøÁî®0.001Ëø≠‰ª£5000ÂõæÂÉèÁ±ª‰ºº„ÄÇ 1234fig = plt.figure()ax = fig.add_subplot(111)ax.plot(stageWise(abX, abY, 0.005, 1000))plt.show() ÈÄêÊ≠•Á∫øÊÄßÂõûÂΩíÁÆóÊ≥ïÁöÑ‰∏ªË¶Å‰ºòÁÇπÂú®‰∫éÂÆÉÂèØ‰ª•Â∏ÆÂä©‰∫∫‰ª¨ÁêÜËß£Áé∞ÊúâÁöÑÊ®°ÂûãÂπ∂ÂÅöÂá∫ÊîπËøõ„ÄÇÂΩìÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Ê®°ÂûãÂêéÔºåÂèØ‰ª•ËøêË°åËØ•ÁÆóÊ≥ïÊâæÂá∫ÈáçË¶ÅÁâπÂæÅÔºåËøôÊ†∑Â∞±ÊúâÂèØËÉΩÂÅúÊ≠¢ÂØπÈÇ£‰∫õ‰∏çÈáçË¶ÅÁöÑÁâπÂæÅÊî∂ÈõÜ„ÄÇÊúÄÂêéÔºåÂ¶ÇÊûúÁî®‰∫éÊµãËØïÔºåËØ•ÁÆóÊ≥ïÊØè100Ê¨°Ëø≠‰ª£ÂêéÂ∞±ÂèØ‰ª•ÊûÑÂª∫Âá∫‰∏Ä‰∏™Ê®°ÂûãÔºåÂèØ‰ª•‰ΩøÁî®Á±ª‰ºº‰∫é10Êäò‰∫§ÂèâÈ™åËØÅÁöÑÊñπÊ≥ïÊØîËæÉËøô‰∫õÊ®°ÂûãÔºåÊúÄÁªàÈÄâÊã©ËØØÂ∑ÆÊúÄÂ∞èÁöÑÊ®°Âûã„ÄÇ ÂΩìÂ∫îÁî®Áº©ÂáèÊñπÊ≥ïÊó∂ÔºåÊ®°Âûã‰πüÂ∞±Â¢ûÂä†‰∫ÜÂÅèÂ∑ÆÔºàbiasÔºâÔºå‰∫éÊ≠§ÂêåÊó∂ÂáèÂ∞èÊ®°ÂûãÁöÑÊñπÂ∑Æ„ÄÇ ÊùÉË°°ÊñπÂ∑Æ‰∫éÂÅèÂ∑Æ ÂÅèÂ∑ÆÊñπÂ∑ÆÊäò‰∏≠‰∏éÊµãËØïËØØÂ∑ÆÂèäËÆ≠ÁªÉËØØÂ∑ÆÁöÑÂÖ≥Á≥ªÔºå‰∏äÈù¢ÁöÑÊõ≤Á∫øÂ∞±ÊòØÊµãËØïËØØÂ∑ÆÔºåÂú®‰∏≠Èó¥ÈÉ®ÂàÜÊúÄ‰Ωé„ÄÇ‰∏∫‰∫ÜÂÅöÂá∫ÊúÄÂ•ΩÁöÑÈ¢ÑÊµãÔºåÊàë‰ª¨Â∫îËØ•Ë∞ÉÊï¥Ê®°ÂûãÂ§çÊùÇÂ∫¶Êù•ËææÂà∞ÊµãËØïËØØÂ∑ÆÁöÑÊúÄÂ∞èÂÄº„ÄÇ ÂÆû‰æãÈ¢ÑÊµã‰πêÈ´òÁé©ÂÖ∑Â•óË£ÖÁöÑ‰ª∑Ê†ºÁî®ÂõûÂΩíÊ≥ïÈ¢ÑÊµã‰πêÈ´òÂ•óË£ÖÁöÑ‰ª∑Ê†º Êî∂ÈõÜÊï∞ÊçÆÔºöÁî®Google ShoppingÁöÑAPIÊî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºö‰ªéËøîÂõûÁöÑjsonÊï∞ÊçÆ‰∏≠ÊäΩÂèñ‰ª∑Ê†º ÂàÜÊûêÊï∞ÊçÆÔºöÂèØËßÜÂåñËßÇÂØüÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÊûÑÂª∫‰∏çÂêåÁöÑÊ®°ÂûãÔºåÈááÁî®ÈÄêÊ≠•Á∫øÊÄßÂõûÂΩíÂíåÁõ¥Êé•ÁöÑÁ∫øÊÄßÂõûÂΩíÊ®°Âûã ÊµãËØïÁÆóÊ≥ïÔºö‰ΩøÁî®‰∫§ÂèâÈ™åËØÅÊù•ÊµãËØï‰∏çÂêåÁöÑÊ®°ÂûãÔºåÂàÜÊûêÂì™‰∏™ÊïàÊûúÊúÄÂ•Ω ‰ΩøÁî®ÁÆóÊ≥ïÔºöËøôÊ¨°ÁªÉ‰π†ÁöÑÁõÆÊ†áÂ∞±ÊòØÁîüÊàêÊï∞ÊçÆÊ®°Âûã Êî∂ÈõÜÊï∞ÊçÆÂõ†‰∏∫Google apiÂ∑≤ÁªèÊó†Ê≥ïËÆøÈóÆÔºåÊâÄ‰ª•‰ΩøÁî®‰ª•‰∏ãcodeÊù•Êî∂ÈõÜÊï∞ÊçÆ„ÄÇ 12345678910111213141516171819202122232425262728293031323334353637def scrapePage(inFile, outFile, yr, numPce, origPrc): from bs4 import BeautifulSoup fr = open(inFile) fw=open(outFile,'a') # a is append mode writing soup = BeautifulSoup(fr.read()) i=1 currentRow = soup.findAll('table', r="%d" % i) while(len(currentRow)!=0): title = currentRow[0].findAll('a')[1].text lwrTitle = title.lower() if (lwrTitle.find('new') &gt; -1) or (lwrTitle.find('nisb') &gt; -1): newFlag = 1.0 else: newFlag = 0.0 soldUnicde = currentRow[0].findAll('td')[3].findAll('span') if len(soldUnicde)==0: print("item #%d did not sell" % i) else: soldPrice = currentRow[0].findAll('td')[4] priceStr = soldPrice.text priceStr = priceStr.replace('$','') #strips out $ priceStr = priceStr.replace(',','') #strips out , if len(soldPrice)&gt;1: priceStr = priceStr.replace('Free shipping', '') #strips out Free Shipping print("%s\t%d\t%s" % (priceStr,newFlag,title)) fw.write("%d\t%d\t%d\t%f\t%s\n" % (yr,numPce,newFlag,origPrc,priceStr)) i += 1 currentRow = soup.findAll('table', r="%d" % i) fw.close() def setDataCollect(outFile): scrapePage('MLiA_SourceCode/Ch08/setHtml/lego8288.html', outFile, 2006, 800, 49.99) scrapePage('MLiA_SourceCode/Ch08/setHtml/lego10030.html', outFile, 2002, 3096, 269.99) scrapePage('MLiA_SourceCode/Ch08/setHtml/lego10179.html', outFile, 2007, 5195, 499.99) scrapePage('MLiA_SourceCode/Ch08/setHtml/lego10181.html', outFile, 2007, 3428, 199.99) scrapePage('MLiA_SourceCode/Ch08/setHtml/lego10189.html', outFile, 2008, 5922, 299.99) scrapePage('MLiA_SourceCode/Ch08/setHtml/lego10196.html', outFile, 2009, 3263, 249.99) 1setDataCollect('result.txt') 85.00 0 Lego Technic 8288 Crawler crane 102.50 0 Lego Technic 8288 Crawler Crane USED SET 77.00 0 Lego Technic 8288 Crawler Crane item #4 did not sell 162.50 0 RARE Lego Technic 8288 Crawler Crane 699.99 0 Lego Star Wars Imperial Star Destroyer (10030) Sealed! 602.00 0 Lego Star Wars UCS Imperial Star Destroyer #10030 515.00 0 Lego 10030 Imperial Star Destroyer 510.00 0 Lego Star Wars 10030 Ultimate Imperial Star Destroyer 375.00 0 Lego Star Wars Imperial Star Destroyer (10030) 1050.00 1 LEGO STAR DESTROYER NEW IN SEALED BOX 10030 STAR WARS 740.00 0 IMPERIAL STAR DESTROYER #10030 Lego Star Wars SEALED 759.00 1 LEGO STAR WARS 10030 UCS IMPERIAL DESTROYER NISB NEW 730.00 0 Lego 10030 Star Destroyer, MISB, Old Gray, Ships Free! 750.00 1 NEW STAR WARS LEGO SET 10030 IMPERIAL STAR DESTROYER item #11 did not sell 910.00 0 LEGO star wars Millenium Falcon #10179 MISB 1199.99 1 Lego Star Wars - 10179 Ultimate Millennium Falcon - NEW 811.88 0 Lego Star Wars - 10179 Ultimate Millennium Falcon-USED item #4 did not sell 1324.79 0 Lego Star Wars Millennium Falcon 10179 850.00 1 NEW LEGO 10179 STAR WARS UC MILLENNIUM FALCON - NISB 800.00 1 NEW LEGO 10179 STAR WARS UC MILLENNIUM FALCON - NISB 810.00 0 lego star warsUltimateCol‚Äãlectors millennium falcon10179 1075.00 1 Lego Star Wars Ultimate Millenium Falcon 10179 NEW MISB 1050.00 0 LEGO STAR WARS 10179 UCS MILLENIUM FALCON! MINT IN BOX 1199.99 1 LEGO 10179 STAR WARS MILLENNIUM FALCON UCS NEW/SEALED 1342.31 0 Lego Star Wars 10179 Collectors Millennium Falcon 1000.00 1 Star Wars - UCS Millennium Falcon - 10179 - New In Box 1780.00 0 LEGO STAR WARS 10188 10179 DEATH STAR MILLENIUM FALCON 750.00 0 STAR WARS Lego 10179 Ultimate CS MILLENNIUM FALCON! item #16 did not sell 2204.99 0 HUGE LOT OF LEGOS 10179 FALCON &amp; MORE STARWARS &amp; MORE item #18 did not sell 925.00 1 Lego #10179 BRAND NEW Star Wars UCS Millenium Falcon 860.00 0 LEGO STAR WARS UCS MILLENNIUM FALCON #10179 WITH BOX item #21 did not sell item #22 did not sell 1199.99 1 Lego Star Wars 10179 UCS Millenium Falcon - NEW! 1099.99 1 Lego Star Wars 10179 UCS Millennium Falcon NiSB HUGE! 1149.99 1 NEW LEGO 10179 STAR WARS MILLENNIUM FALCON NEW/SEALED 800.00 1 NEW LEGO 10179 STAR WARS UC MILLENNIUM FALCON - NISB 850.00 1 NEW LEGO 10179 STAR WARS UC MILLENNIUM FALCON - NISB 469.95 0 Lego Star Wars Death Star II 10143 MNIB SOLD OUT A++ 479.00 0 NIB Box Collectors Starwars Death Star II - 10143 299.99 0 Lego Star Wars Death Star II 10143 -Excellent Condition 369.00 0 Lego Star Wars Death Star ll # 10143 424.95 1 LEGO Star Wars Death Star II 10143 *Damaged Box* NEW 380.00 1 NEW Lego Star Wars Death Star II #10143 305.00 0 LEGO Star Wars Death Star II 10143 530.00 1 LEGO Taj Mahal NEW IN BOX MINT CONDITION! LAST ONE! item #2 did not sell 599.95 1 LEGO 10189 TAJ MAHAL - BRAND NEW - RARE &amp; SOLD OUT! 510.00 0 Lego~Taj Mahal~#10189~pu‚Äãt together once~EUC 423.00 0 Lego Taj Mahal 10189- Put together ONCE - perfect shape item #6 did not sell item #7 did not sell 599.99 1 Lego - Taj Mahal 10189 - NEW Sealed item #9 did not sell 589.99 1 LEGO 10189 TAJ MAHAL NEW SEALED IN BOX FAST SHIPPING 569.99 1 LEGO 10189 TAJ MAHAL NEW SEALED MINT FREE SHIPPING 529.99 1 Lego 10189 Taj Mahal ***New &amp; Sealed*** 500.00 0 LEGO TAJ MAHAL 549.95 1 LEGO 10189 TAJ MAHAL - BRAND NEW - RARE &amp; SOLD OUT! 300.00 0 Lego TAJ MAHAL 10189 100% Complete, No Box, Inst. Incl. item #16 did not sell 380.00 1 Lego - Grand Carousel 10196 - NEW Sealed 399.00 1 Lego Grand Carousel 10196 - NIB Sealed, Brand New 427.99 1 Lego 10196 Grand Carousel ***New &amp; Sealed*** 360.00 0 Grand Carousel Lego 10196 Rare Used Extra Minifigs item #5 did not sell item #6 did not sell 399.00 1 Lego City 10196 Grand Carousel New In BOX! 399.95 1 LEGO CREATOR CAROUSEL 10196 Box New *MISB* 499.99 1 Lego - Grand Carousel 10196 - NEW Sealed item #10 did not sell 399.95 0 LEGO Grand Carousel 10196 NIB item #12 did not sell 331.51 1 Lego Carousel 10196, New Unopened Bags 1lgX, lgY = loadDataSet('result.txt') ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÂª∫Á´ãÊ®°ÂûãÈ¶ñÂÖàÈúÄË¶ÅÊ∑ªÂä†ÂØπÂ∫îÂ∏∏Êï∞È°πÁöÑÁâπÂæÅX0(X0=1)Ôºå‰∏∫Ê≠§ÂàõÂª∫‰∏Ä‰∏™ÂÖ®‰∏∫1ÁöÑÁü©Èòµ„ÄÇ 1shape(lgX) (126, 4) 1lgX1 = mat(ones((126, 5))) 1lgX1[:, 1:5] = mat(lgX) 1lgX[0] [2006.0, 800.0, 0.0, 49.99] 1lgX1[0] matrix([[1.000e+00, 2.006e+03, 8.000e+02, 0.000e+00, 4.999e+01]]) 12ws = standRegres(lgX1, lgY)ws matrix([[ 5.53199701e+04], [-2.75928219e+01], [-2.68392234e-02], [-1.12208481e+01], [ 2.57604055e+00]]) Ê£ÄÊü•ÁªìÊûú 1lgX1[0]*ws matrix([[76.07418859]]) 1lgX1[-1]*ws matrix([[431.17797678]]) 1lgX1[43]*ws matrix([[516.20733111]]) 1lgY[0] 85.0 ‰∫§ÂèâÈ™åËØÅÊµãËØïÂ≤≠ÂõûÂΩí 12345678910111213141516171819202122232425262728293031323334353637383940import randomdef crossValidation(xArr, yArr, numVal=10): m = len(yArr) indexList = list(range(m)) errorMat = zeros((numVal, 30)) for i in range(numVal): trainX = [] trainY = [] testX = [] testY = [] random.shuffle(indexList) for j in range(m): if j &lt; m*0.9: trainX.append(xArr[indexList[j]]) trainY.append(yArr[indexList[j]]) else: testX.append(xArr[indexList[j]]) testY.append(yArr[indexList[j]]) wMat = ridgeTest(trainX, trainY) for k in range(30): matTestX = mat(testX) matTrainX = mat(trainX) meanTrain = mean(matTrainX, 0) varTrain = var(matTrainX, 0) matTestX = (matTestX-meanTrain)/varTrain yEst = matTestX * mat(wMat[k, :]).T + mean(trainY) errorMat[i, k] = rssError(yEst.T.A, array(testY)) meanErrors = mean(errorMat,0)#calc avg performance of the different ridge weight vectors minMean = float(min(meanErrors)) bestWeights = wMat[nonzero(meanErrors==minMean)] # ÂèØ‰ª•ÈùûÊ≠£ÂàôÂåñÂæóÂà∞Ê®°Âûã # Ê≠£ÂàôÂåñÂêéÔºåÊàë‰ª¨ÂÜô‰∫ÜXreg = (x- meanx)/var(x) # Êàë‰ª¨Áé∞Âú®ÂèØ‰ª•Áî®xËÄå‰∏çÊòØXregÊù•Ë°®Á§∫:x*w/var(x) - meanX/var(x) +mean xMat = mat(xArr) yMat = mat(yArr).T meanX = mean(xMat,0) varX = var(xMat,0) unReg = bestWeights/varX print("the best model from ridge regression is:\n", unReg) print("with constant term: ", -1*sum(multiply(meanX, unReg))+mean(yMat)) 1crossValidation(lgX, lgY, numVal=10) the best model from ridge regression is: [[-3.13000380e+01 -5.79216518e-04 -1.46976042e+01 2.33709492e+00]] with constant term: 62728.39604629546 1ridgeTest(lgX, lgY) array([[-1.42567890e+02, -1.59065167e+04, -3.32568485e+00, 4.50485291e+04], [-1.46048534e+02, -5.88035105e+03, -3.20592314e+00, 4.38513111e+04], [-1.46392961e+02, -7.53268167e+02, -2.49755326e+00, 4.21602572e+04], [-1.42882929e+02, 1.24713671e+03, -5.78336771e-01, 3.87616551e+04], [-1.34058297e+02, 1.65495690e+03, 3.46766980e+00, 3.19757189e+04], [-1.20185790e+02, 1.28302796e+03, 9.65389591e+00, 2.16984122e+04], [-1.06405098e+02, 7.16651262e+02, 1.57519175e+01, 1.15841453e+04], [-9.74799755e+01, 3.21265653e+02, 1.96506716e+01, 5.10995216e+03], [-9.29742820e+01, 1.28256118e+02, 2.14874762e+01, 2.02836160e+03], [-9.04274807e+01, 4.86739495e+01, 2.21853397e+01, 7.68474711e+02], [-8.75861154e+01, 1.80935644e+01, 2.23113328e+01, 2.85792138e+02], [-8.19045992e+01, 6.66134743e+00, 2.20039861e+01, 1.05512059e+02], [-6.99384526e+01, 2.43521001e+00, 2.11068607e+01, 3.88294842e+01], [-5.00210980e+01, 8.84809679e-01, 1.94076129e+01, 1.42672332e+01], [-2.79820303e+01, 3.21315572e-01, 1.69641166e+01, 5.24285549e+00], [-1.24628930e+01, 1.17567465e-01, 1.37731297e+01, 1.93051917e+00], [-4.77896841e+00, 4.34264276e-02, 9.63509521e+00, 7.12700367e-01], [-1.71197823e+00, 1.61100639e-02, 5.40201378e+00, 2.63366078e-01], [-6.08727885e-01, 5.96613258e-03, 2.47122138e+00, 9.72056597e-02], [-2.19489801e-01, 2.20244723e-03, 9.99173868e-01, 3.58199566e-02], [-8.00295532e-02, 8.11429705e-04, 3.81511828e-01, 1.31867450e-02], [-2.93376909e-02, 2.98679351e-04, 1.42337367e-01, 4.85246297e-03], [-1.07783727e-02, 1.09901635e-04, 5.26372259e-02, 1.78530510e-03], [-3.96318049e-03, 4.04337769e-05, 1.94015377e-02, 6.56802092e-04], [-1.45770631e-03, 1.48751929e-05, 7.14249987e-03, 2.41627386e-04], [-5.36224096e-04, 5.47233696e-06, 2.62826610e-03, 8.88902084e-05], [-1.97260935e-04, 2.01316829e-06, 9.66978104e-04, 3.27009426e-05], [-7.25675812e-05, 7.40604313e-07, 3.55743958e-04, 1.20300129e-05], [-2.66960317e-05, 2.72453248e-07, 1.30872593e-04, 4.42559557e-06], [-9.82090911e-06, 1.00229968e-07, 4.81455670e-05, 1.62808578e-06]]) ÊÄªÁªì‰∏éÂàÜÁ±ª‰∏ÄÊ†∑ÔºåÂõûÂΩí‰πüÊòØÈ¢ÑÊµãÁõÆÊ†áÂÄºÁöÑËøáÁ®ã„ÄÇÂõûÂΩí‰∏éÂàÜÁ±ªÁöÑ‰∏çÂêåÁÇπÂú®‰∫éÔºåÂâçËÄÖÈ¢ÑÊµãËøûÁª≠ÂûãÂèòÈáèËÄåÂêéËÄÖÈ¢ÑÊµãÁ¶ªÊï£ÂûãÂèòÈáè„ÄÇÂú®ÂõûÂΩíÊñπÁ®ãÈáåÔºåÊ±ÇÂæóÁâπÂæÅÂØπÂ∫îÁöÑÊúÄ‰Ω≥ÂõûÂΩíÁ≥ªÊï∞ÁöÑÊñπÊ≥ïÊòØÊúÄÂ∞èÂåñËØØÂ∑ÆÁöÑÂπ≥ÊñπÂíå„ÄÇ ÂΩìÊï∞ÊçÆÁöÑÊ†∑Êú¨ÊØîÁâπÂæÅÊï∞ËøòÂ∞ëÁöÑÊó∂ÂÄôÔºåÁü©Èòµ$X^TX$ÁöÑÈÄÜ‰∏çËÉΩÁõ¥Êé•ËÆ°ÁÆóÔºåËøôÊó∂ÂèØ‰ª•ËÄÉËôë‰ΩøÁî®Áº©ÂáèÊ≥ï„ÄÇ Áº©ÂáèÊ≥ïËøòÂèØ‰ª•ÁúãÂÅöÊòØÂØπ‰∏Ä‰∏™Ê®°ÂûãÂ¢ûÂä†ÂÅèÂ∑ÆÁöÑÂêåÊó∂ÂáèÂ∞èÊñπÂ∑Æ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>Á∫øÊÄßÂõûÂΩí</tag>
        <tag>Â≤≠ÂõûÂΩí</tag>
        <tag>ÊúÄÂ∞è‰∫å‰πòÊ≥ï</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏ÉÔºâ]]></title>
    <url>%2F2020%2F04%2F07%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Âà©Áî®AdaBoostÂÖÉÁÆóÊ≥ïÊèêÈ´òÂàÜÁ±ªÊÄßËÉΩÂú®ÂÅöÂÜ≥ÂÆöÊó∂ÔºåÂ§ßÂÆ∂ÂèØËÉΩ‰ºöÂê∏ÂèñÂ§ö‰∏™‰∏ìÂÆ∂ËÄå‰∏çÊòØ‰∏Ä‰∏™‰∫∫ÁöÑÊÑèËßÅÔºåÊú∫Âô®Â≠¶‰π†‰πüÊúâÁ±ª‰ººÁöÑÁÆóÊ≥ïÔºåËøôÂ∞±ÊòØÂÖÉÁÆóÊ≥ïÔºàmeta-algorithmÔºâ„ÄÇÂÖÉÁÆóÊ≥ïÊòØÂØπÂÖ∂‰ªñÁÆóÊ≥ïËøõË°åÁªÑÂêàÁöÑ‰∏ÄÁßçÊñπÂºè„ÄÇ Âü∫‰∫éÊï∞ÊçÆÈõÜÂ§öÈáçÊäΩÊ†∑ÁöÑÂàÜÁ±ªÂô®ÂâçÈù¢Â∑≤ÁªèÂ≠¶‰π†‰∫Ü‰∫îÁßç‰∏çÂêåÁöÑÂàÜÁ±ªÁÆóÊ≥ïÔºåÂÆÉ‰ª¨ÂêÑÊúâ‰ºòÁº∫ÁÇπÔºåÊàë‰ª¨ÂèØ‰ª•Â∞Ü‰∏çÂêåÁöÑÂàÜÁ±ªÂô®ÁªÑÂêàËµ∑Êù•ÔºåËøôÁßçÁªÑÂêàÁªìÊûúÂàôÂëóÁß∞‰∏∫ÈõÜÊàêÊñπÊ≥ïÔºàensemble methodÔºâÊàñËÄÖÂÖÉÁÆóÊ≥ïÔºàmeta-algorithmÔºâ„ÄÇÈõÜÊàêÊñπÊ≥ïÊúâÂ§öÁßçÂΩ¢ÂºèÔºö‰∏çÂêåÁÆóÊ≥ïÁöÑÈõÜÊàêÔºåÂêå‰∏ÄÁßçÁÆóÊ≥ï‰∏çÂêåËÆæÁΩÆÁöÑÈõÜÊàêÔºåÊï∞ÊçÆÈõÜ‰∏çÂêåÈÉ®ÂàÜÂàÜÈÖçÁªô‰∏çÂêåÂàÜÁ±ªÂô®‰πãÂêéÁöÑÈõÜÊàêÔºåÂêå‰∏ÄÁßçÂàÜÁ±ªÂô®Â§ö‰∏™‰∏çÂêåÂÆû‰æãÁöÑ‰∏§ÁßçËÆ°ÁÆóÊñπÊ≥ï„ÄÇ AdaBoost ‰ºòÁÇπÔºöÊ≥õÂåñÈîôËØØÁéá‰ΩéÔºåÊòìÁºñÁ†ÅÔºåÂèØ‰ª•Â∫îÁî®Âú®Â§ßÈÉ®ÂàÜÂàÜÁ±ªÂô®‰∏äÔºåÊó†ÂèÇÊï∞Ë∞ÉÊï¥ Áº∫ÁÇπÔºöÂØπÁ¶ªÁæ§ÁÇπÊïèÊÑü ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞ÂûãÊï∞ÊçÆ baggingÔºöÂü∫‰∫éÊï∞ÊçÆÈöèÊú∫ÊäΩÊ†∑ÁöÑÂàÜÁ±ªÂô®ÊûÑÂª∫ÊñπÊ≥ïËá™‰∏æÊ±áËÅöÊ≥ïÔºàbootstrap aggregatingÔºâÔºå‰πüÁß∞‰∏∫baggingÊñπÊ≥ïÔºå‰ªéÂéüÂßãÈõÜÂêàÈöèÊú∫ÈÄâÊã©‰∏Ä‰∏™Ê†∑Êú¨ÔºåÁÑ∂ÂêéÈöèÊú∫ÈÄâÊã©ÁöÑÊ†∑Êú¨Êù•‰ª£ÊõøËøô‰∏™Ê†∑Êú¨ÔºåÊÑè‰∏∫ÊúâÊîæÂõûÁöÑÂèñÊ†∑ÂæóÂà∞ÁöÑ„ÄÇ Âú®ÊúâÊîæÂõûÊäΩÊ†∑ÂæóÂà∞S‰∏™Êï∞ÊçÆÈõÜÂêéÔºåÂ∞ÜÊüê‰∏™Â≠¶‰π†ÁÆóÊ≥ïÂàÜÂà´‰ΩúÁî®Âú®ÊØè‰∏™Êï∞ÊçÆÈõÜ‰∏äÔºåÂ∞±ÂæóÂà∞‰∫ÜS‰∏™ÂàÜÁ±ªÂô®ÔºåÂØπÊñ∞Êï∞ÊçÆËøõË°åÂàÜÁ±ªÊó∂ÔºåÁî®Ëøô‰∏™S‰∏™ÂàÜÁ±ªÂô®ËøõË°åÊäïÁ•®Ë°®ÂÜ≥ÁöÑÊñπÊ≥ïÂÜ≥ÂÆöÂàÜÁ±ªÁªìÊûú„ÄÇ ÂÖ∂‰ªñbaggingÁöÑÊñπÊ≥ïÔºöÈöèÊú∫Ê£ÆÊûóÔºàrandom forestÔºâ boostingboostingÊòØ‰∏ÄÁßçÁ±ª‰ººbaggingÁöÑÊñπÊ≥ï„ÄÇbaggingÁöÑÂàÜÁ±ªÂô®Êó∂ÈÄöËøá‰∏≤Ë°åËÆ≠ÁªÉËÄåËé∑ÂæóÁöÑÔºåÊØè‰∏™Êñ∞ÂàÜÁ±ªÂô®ÈÉΩÊ†πÊçÆÂ∑≤ËÆ≠ÁªÉÂ§ÑÁöÑÂàÜÁ±ªÂô®ÁöÑÊÄßËÉΩÊù•ËøõË°åËÆ≠ÁªÉ„ÄÇboostingÊòØÈÄöËøáÈõÜ‰∏≠ÂÖ≥Ê≥®Ë¢´Â∑≤ÊúâÂàÜÁ±ªÂô®ÈîôÂàÜÁöÑÈÇ£‰∫õÊï∞ÊçÆÊù•Ëé∑ÂæóÊñ∞ÁöÑÂàÜÁ±ªÂô®„ÄÇ Áî±‰∫éboostingÂàÜÁ±ªÁªìÊûúÊòØÂü∫‰∫éÊâÄÊúâÂàÜÁ±ªÂô®ÁöÑÂä†ÊùÉÊ±ÇÂíåÁªìÊûúÁöÑÔºåÂõ†Ê≠§boosting‰∏ébagging‰∏ç‰∏ÄÊ†∑„ÄÇbagging‰∏≠ÁöÑÂàÜÁ±ªÊùÉÈáçÊòØÁõ∏Á≠âÁöÑÔºåboosting‰∏≠ÁöÑÂàÜÁ±ªÂô®ÊùÉÈáçÂπ∂‰∏çÁõ∏Á≠âÔºåÊØè‰∏™ÊùÉÈáç‰ª£Ë°®ÁöÑÊòØÂÖ∂ÂØπÂ∫îÂàÜÁ±ªÂô®Âú®‰∏ä‰∏ÄËΩÆËø≠‰ª£‰∏≠ÁöÑÊàêÂäüÂ∫¶„ÄÇ AdaBoostÁöÑ‰∏ÄËà¨ÊµÅÁ®ã Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºö‰æùËµñ‰∫éÊâÄÊúâ‰ΩøÁî®ÁöÑÂº±ÂàÜÁ±ªÂô®Á±ªÂûãÔºåÊú¨Á´†‰ΩøÁî®ÁöÑÊòØÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÔºåËøôÁßçÂàÜÁ±ªÂô®ÂèØ‰ª•Â§ÑÁêÜ‰ªª‰ΩïÊï∞ÊçÆÁ±ªÂûã„ÄÇ‰Ωú‰∏∫Âº±ÂàÜÁ±ªÂô®ÔºåÁÆÄÂçïÁöÑÂàÜÁ±ªÂô®ÊïàÊûúÊõ¥Â•Ω„ÄÇ ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöAdaBoostÁöÑÂ§ßÈÉ®ÂàÜÊó∂Èó¥ÈÉΩÂú®ËÆ≠ÁªÉ‰∏äÔºåÂàÜÁ±ªÂô®Â∞ÜÂ§öÊ¨°Âú®Âêå‰∏ÄÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÂº±ÂàÜÁ±ªÂô® ÊµãËØïÁÆóÊ≥ïÔºöËÆ°ÁÆóÂàÜÁ±ªÁöÑÈîôËØØÁéá ‰ΩøÁî®ÁÆóÊ≥ïÔºöÂêåSVM‰∏ÄÊ†∑ÔºåAdaBoostÈ¢ÑÊµã‰∏§‰∏™Á±ªÂà´‰∏≠ÁöÑ‰∏Ä‰∏™ÔºåÂ¶ÇÊûúË¶ÅÂ∫îÁî®Âú®Â§öÂàÜÁ±ªÈóÆÈ¢òÔºåË¶ÅËøõË°å‰øÆÊîπ„ÄÇ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÂü∫‰∫éÈîôËØØÊèêÂçáÂàÜÁ±ªÂô®ÁöÑÊÄßËÉΩAdaBoostÊòØadaptive boostingÔºàËá™ÈÄÇÂ∫îboostingÔºâÁöÑÁº©ÂÜôÔºåÂÖ∂ËøêË°åËøáÁ®ãÂ¶Ç‰∏ãÔºöËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÁöÑÊØè‰∏™Ê†∑Êú¨ÔºåÂπ∂Ëµã‰∫àÂÖ∂‰∏≠‰∏Ä‰∏™ÊùÉÈáçÔºåËøô‰∫õÊùÉÈáçÊûÑÊàêÂêëÈáèD„ÄÇ‰∏ÄÂºÄÂßãÔºåËøô‰∫õÊùÉÈáçÈÉΩÂàùÂßãÂåñÊàêÁõ∏Á≠âÂÄºÔºåÈ¶ñÂÖàÂú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÂá∫‰∏Ä‰∏™Âº±ÂàÜÁ±ªÂô®Âπ∂ËÆ°ÁÆóËØ•ÂàÜÁ±ªÂô®ÁöÑÈîôËØØÁéáÔºåÁÑ∂ÂêéÂú®Âêå‰∏ÄÊï∞ÊçÆÈõÜ‰∏äÂÜçÊ¨°ËÆ≠ÁªÉÂº±ÂàÜÁ±ªÂô®„ÄÇÂú®ÂàÜÁ±ªÂô®ÁöÑÁ¨¨‰∫åÊ¨°ËÆ≠ÁªÉ‰∏≠ÔºåÂ∞ÜÈáçÊñ∞Ë∞ÉÊï¥ÊØè‰∏™Ê†∑Êú¨ÁöÑÊùÉÈáçÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÊ¨°ÂàÜÂØπÁöÑÊ†∑Êú¨ÊùÉÈáçÂ∞Ü‰ºöÈôç‰ΩéÔºåËÄåÁ¨¨‰∏ÄÊ¨°ÂàÜÈîôÁöÑÊ†∑Êú¨ÊùÉÈáçÂ∞Ü‰ºöÊèêÈ´ò„ÄÇ‰∏∫‰∫Ü‰ªéÊâÄÊúâÂº±ÂàÜÁ±ªÂô®‰∏≠ÂæóÂà∞ÊúÄÁªàÁöÑÂàÜÁ±ªÁªìÊûúAdaBoost‰∏∫ÊØè‰∏™ÂàÜÁ±ªÂô®ÈÉΩÂàÜÈÖç‰∏Ä‰∏™ÊùÉÈáçÂÄºalphaÔºåËøô‰∫õalphaÂÄºÊòØÂü∫‰∫éÊØè‰∏™Âº±ÂàÜÁ±ªÂô®ÁöÑÈîôËØØÁéáËøõË°åËÆ°ÁÆóÁöÑ„ÄÇÂÖ∂‰∏≠ÈîôËØØÁéáŒµÁöÑÂÆö‰πâ‰∏∫Ôºö $$\epsilon=\frac{Êú™Ê≠£Á°ÆÂàÜÁ±ªÁöÑÊ†∑Êú¨Êï∞ÁõÆ}{ÊâÄÊúâÊ†∑Êú¨Êï∞ÁõÆ}$$ alphaÁöÑËÆ°ÁÆóÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö $$\alpha=\frac{1}{2}ln(\frac{1-\epsilon}{\epsilon})$$ ËÆ°ÁÆóÊµÅÁ®ãÂõæÂ¶Ç‰∏ãÔºö Â∑¶ËæπÊòØÊï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠Áõ¥ÊñπÂõæÁöÑ‰∏çÂêåÂÆΩÂ∫¶Ë°®Á§∫Ê†∑Êú¨ÁöÑÊùÉÈáç„ÄÇÂú®ÁªèËøá‰∏Ä‰∏™ÂàÜÁ±ªÂô®ÂêéÔºåÂä†ÊùÉÁöÑÈ¢ÑÊµãÁªìÊûú‰ºöÈÄöËøá‰∏âËßíÂΩ¢ÁöÑalphaËøõË°åÂä†ÊùÉ„ÄÇÊØè‰∏™‰∏âËßíÂΩ¢‰∏≠ËæìÂá∫ÁöÑÂä†ÊùÉÁªìÊûúÂú®ÂúÜÂΩ¢‰∏≠Ê±ÇÂíåÔºåÂæóÂà∞ËæìÂá∫ÁªìÊûú„ÄÇ ËÆ°ÁÆóÂá∫alphaÂÄºÂêéÔºåÂèØ‰ª•ÂØπÊùÉÈáçÂêëÈáèDËøõË°åÊõ¥Êñ∞„ÄÇ Â¶ÇÊûúÊ†∑Êú¨Ë¢´Ê≠£Á°ÆÂàÜÁ±ªÔºåÊùÉÈáçÈôç‰Ωé Â¶ÇÊûúÊ†∑Êú¨Ë¢´ÈîôÂàÜÔºåÊùÉÈáçÂ¢ûÂä† Âú®ËÆ°ÁÆóÂá∫D‰πãÂêéÔºåAdaBoostÂèàÂºÄÂßãËøõË°å‰∏ã‰∏ÄËΩÆËø≠‰ª£„ÄÇAdaBoostÁÆóÊ≥ï‰ºö‰∏çÊñ≠ÁöÑÈáçÂ§çËÆ≠ÁªÉÂíåË∞ÉÊï¥ÊùÉÈáçÔºåÁõ¥Âà∞ËÆ≠ÁªÉÈîôËØØÁéá‰∏∫0ÊàñËÄÖËææÂà∞ÊåáÂÆöÊ¨°Êï∞„ÄÇ Âü∫‰∫éÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÊûÑÂª∫Âº±ÂàÜÁ±ªÂô®ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÔºàdecision stumpÔºå‰πüÁß∞ÂÜ≥Á≠ñÊ†ëÊ°©ÔºâÊòØ‰∏ÄÁßçÁÆÄÂçïÁöÑÂÜ≥Á≠ñÊ†ë„ÄÇÂÖàÊûÑÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊï∞ÊçÆÈõÜ„ÄÇ 123456789from numpy import *def loadSimpData(): datMat = matrix([[1., 2.1], [2., 1.1], [1.3, 1.], [1., 1.], [2., 1.]]) classLabels = [1.0, 1.0, -1.0, -1.0, 1.0] return datMat, classLabels 123456789101112131415161718192021222324252627import matplotlibimport matplotlib.pyplot as pltfrom matplotlib.patches import Circleplt.rcParams['axes.unicode_minus']=False # Áî®Êù•Ê≠£Â∏∏ÊòæÁ§∫Ë¥üÂè∑def plotSupportVectors(): xcord0 = [] ycord0 = [] xcord1 = [] ycord1 = [] datMat, classLabels = loadSimpData() for i in range(len(classLabels)): if (classLabels[i] == -1): xcord0.append(datMat[i, 0]) ycord0.append(datMat[i, 1]) else: xcord1.append(datMat[i, 0]) ycord1.append(datMat[i, 1]) fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(xcord0, ycord0, marker='s', s=90) ax.scatter(xcord1, ycord1, marker='o', s=50, c='red') plt.title('ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÊµãËØïÊï∞ÊçÆ') plt.show() 1plotSupportVectors() Â¶ÇÊûúÊÉ≥Ë¶ÅÈÄâÊã©‰∏Ä‰∏™‰∏éÂùêÊ†áËΩ¥Âπ≥Ë°åÁöÑÁ∫øÊù•ÊääÂúÜÁÇπÂíåÊñπÂΩ¢ÂàÜÂºÄÊòØ‰∏çÂèØËÉΩÁöÑÔºåËøôÂ∞±ÊòØÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÈöæ‰ª•Â§ÑÁêÜÁöÑ‰∏Ä‰∏™ËëóÂêçÈóÆÈ¢ò„ÄÇÈÄöËøá‰ΩøÁî®Â§öÊ£µÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÊàë‰ª¨Â∞±ÂèØ‰ª•ÊûÑÂª∫Âá∫‰∏Ä‰∏™ËÉΩÂ§üÊ≠£Á°ÆÂ§ÑÁêÜËØ•Êï∞ÊçÆÈõÜÁöÑÂàÜÁ±ªÂô®„ÄÇ 1datMat, classLabels = loadSimpData() Êé•‰∏ãÊù•ÊûÑÂª∫ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ë Á¨¨‰∏Ä‰∏™ÂáΩÊï∞Áî®Êù•ÊµãËØïÊòØÂê¶ÊúâÊüê‰∏™ÂÄºÂ∞è‰∫éÊàñËÄÖÂ§ß‰∫éÊàë‰ª¨Ê≠£Âú®ÊµãËØïÁöÑÈòàÂÄº„ÄÇ Á¨¨‰∫å‰∏™ÂáΩÊï∞ÊòØÂú®‰∏Ä‰∏™Âä†ÊùÉÊï∞ÊçÆÈõÜ‰∏≠Âæ™ÁéØÔºåÂπ∂ÊâæÂà∞ÂÖ∑Êúâ‰ΩéÈîôËØØÁéáÁöÑÂçïÂ±ÇÂÜ≥Á≠ñÊ†ë ‰º™‰ª£Á†ÅÔºö Â∞ÜÊúÄÂ∞èÈîôËØØÁéáminErrorËÆæÂ§á+‚àû ÂØπÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏Ä‰∏™ÁâπÂæÅÔºàÁ¨¨‰∏ÄÂ±ÇÂæ™ÁéØÔºâÔºö ÂØπÊØè‰∏™Ê≠•ÈïøÔºàÁ¨¨‰∫åÂ±ÇÂæ™ÁéØÔºâÔºö ÂØπÊØè‰∏™‰∏çÁ≠âÂè∑ÔºàÁ¨¨‰∏âÂ±ÇÂæ™ÁéØÔºâÔºö Âª∫Á´ã‰∏ÄÊ£µÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÂπ∂Âà©Áî®Âä†ÊùÉÊï∞ÊçÆÈõÜÂØπÂÆÉÊµãËØï Â¶ÇÊûúÈîôËØØÁéá‰Ωé‰∫éminErrorÔºåÂàôÂ∞ÜÂΩìÂâçÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëËÆæ‰∏∫ÊúÄ‰Ω≥ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ë ËøîÂõûÊúÄ‰Ω≥ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ë 12345678910111213141516171819202122232425262728293031323334353637def stumpClassify(dataMatrix, dimen, threshVal, threshIneq): retArray = ones((shape(dataMatrix)[0], 1)) if threshIneq == 'lt': retArray[dataMatrix[:, dimen] &lt;= threshVal] = -1.0 else: retArray[dataMatrix[:, dimen] &gt; threshVal] = -1.0 return retArraydef buildStump(dataArr, classLabels, D): dataMatrix = mat(dataArr) labelMat = mat(classLabels).T m, n = shape(dataMatrix) numSteps = 10.0 bestStump = &#123;&#125; bestClasEst = mat(zeros((m, 1))) minError = inf for i in range(n): rangeMin = dataMatrix[:, i].min() rangeMax = dataMatrix[:, i].max() stepSize = (rangeMax-rangeMin)/numSteps for j in range(-1, int(numSteps)+1): for inequal in ['lt', 'gt']: threshVal = (rangeMin + float(j) * stepSize) predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal) errArr = mat(ones((m, 1))) errArr[predictedVals == labelMat] = 0 weightedError = D.T*errArr #print("split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f" % (i, threshVal, inequal, weightedError)) if weightedError &lt; minError: minError = weightedError bestClasEst = predictedVals.copy() bestStump['dim'] = i bestStump['thresh'] = threshVal bestStump['ineq'] = inequal return bestStump, minError, bestClasEst 12D = mat(ones((5, 1))/5)buildStump(datMat, classLabels, D) ({&apos;dim&apos;: 0, &apos;thresh&apos;: 1.3, &apos;ineq&apos;: &apos;lt&apos;}, matrix([[0.2]]), array([[-1.], [ 1.], [-1.], [-1.], [ 1.]])) Á¨¨‰∏Ä‰∏™ÂáΩÊï∞stumpClassify()ÊòØÈÄöËøáÈòàÂÄºÊØîËæÉÂØπÊï∞ÊçÆËøõË°åÂàÜÁ±ªÁöÑ„ÄÇÊâÄÊúâÂú®ÈòàÂÄº‰∏ÄËæπÁöÑÊï∞ÊçÆ‰ºöÂàÜÂà∞Á±ªÂà´-1ÔºåËÄåÂú®Âè¶‰∏ÄËæπÁöÑÊï∞ÊçÆÂàÜÂà∞Á±ªÂà´+1„ÄÇ Á¨¨‰∫å‰∏™ÂáΩÊï∞buildStump()Â∞Ü‰ºöÈÅçÂéÜstumpClassify()ÂáΩÊï∞ÊâÄÊúâÁöÑÂèØËÉΩÊÄßÔºåÂπ∂ÊâæÂà∞Êï∞ÊçÆÈõÜ‰∏äÊúÄ‰Ω≥ÁöÑÂçïÂ±ÇÂÜ≥Á≠ñÊ†ë„ÄÇËøôÈáåÁöÑÊúÄ‰Ω≥ÊòØÂü∫‰∫éÊï∞ÊçÆÊùÉÈáçÂêëÈáèDÊù•ÂÆö‰πâÁöÑ„ÄÇbestStumpÁöÑÂ≠óÂÖ∏Áî®‰∫éÂÇ®Â≠òÁªôÂÆöÊùÉÈáçÂêëÈáèDÊó∂ÊâÄÂæóÂà∞ÁöÑÊúÄ‰Ω≥ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇÂèòÈáènumStepsÁî®‰∫éÂú®ÁâπÂæÅÁöÑÊâÄÊúâÂèØËÉΩÂÄº‰∏äËøõË°åÈÅçÂéÜ„ÄÇËÄåÂèòÈáèminErrorÂàôÂú®ÂºÄÂßãÂàùÂßãÂåñ‰∏∫Êó†Á©∑Â§ßÔºå‰πãÂêéÂØªÊâæÂèØËÉΩÁöÑÊúÄÂ∞èÈîôËØØÁéá„ÄÇ Ëøô‰∏™ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÁöÑÊ†∏ÂøÉÊÄùÊÉ≥Â∞±ÊòØÊâæÂà∞‰∏Ä‰∏™Êï∞ÔºåÈÄöËøáÊØîËæÉËøô‰∏™Êï∞ÔºåÊâæÂà∞ÊãüÂêàÊ≠£Á°ÆÁéáÊúÄÂ§ßÁöÑ„ÄÇ ÁªìÊûúdim=0Ôºå‰ª£Ë°®Áî®Á¨¨‰∏ÄÂàóÊØîËæÉÔºåthresh=1.3Ôºåineq=ltÔºå‰ª£Ë°®Â∞è‰∫éÁ≠â‰∫é1.3ÁöÑÁªìÊûú Á¨¨‰∏ÄÂàóÔºö 1datMat[:,0] matrix([[1. ], [2. ], [1.3], [1. ], [2. ]]) Ëøô‰∏ÄÂàóÂ§ß‰∫é1.3ÁöÑ‰∏∫1ÔºåÂ∞è‰∫éÁ≠â‰∫é1.3ÁöÑ‰∏∫-1 1datMat[:,0] &lt;= 1.3 matrix([[ True], [False], [ True], [ True], [False]]) ÊâÄ‰ª•È¢ÑÊµãÁªìÊûú‰∏∫Ôºö[-1,1-1,-1,1] Ê≠£Á°ÆÁéá‰∏∫4/5ÔºåÊâÄ‰ª•ÈîôËØØÁéá‰∏∫0.2„ÄÇ ËøôÂ∞±ÊòØ‰∏Ä‰∏™ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÔºåÂè™ËÄÉËôë‰∏ÄÂàóÊï∞ÁöÑÂΩ±ÂìçÔºåËÄåÈùûÂÖ®Â±Ä„ÄÇ ÂÆåÊï¥AdaBoostÊàë‰ª¨Âà©Áî®‰∏äÈù¢ÁöÑÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÊù•ÂÆûÁé∞ÂÆåÊï¥ÁöÑAdaboostÔºå‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö ÂØπÊØèÊ¨°Ëø≠‰ª£Ôºö Âà©Áî®buildStump()ÂáΩÊï∞ÊâæÂà∞ÊúÄ‰Ω≥ÁöÑÂçïÂ±ÇÂÜ≥Á≠ñÊ†ë Â∞ÜÊúÄ‰Ω≥ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÂä†ÂÖ•Âà∞ÂçïÂ±ÇÂÜ≥Á≠ñÊ†ëÊï∞ÁªÑ ËÆ°ÁÆóalpha ËÆ°ÁÆóÊñ∞ÁöÑÊùÉÈáçÂêëÈáèD Êõ¥Êñ∞Á¥ØËÆ°Á±ªÂà´‰º∞ËÆ°ÂÄº Â¶ÇÊûúÈîôËØØÁéáÁ≠â‰∫é0.0ÂàôÈÄÄÂá∫Âæ™ÁéØ 123456789101112131415161718192021222324def adaBoostTrainDS(dataArr, classLabels, numIt=40): weakClassArr = [] m = shape(dataArr)[0] D = mat(ones((m,1))/m) aggClassEst = mat(zeros((m, 1))) for i in range(numIt): bestStump, error, classEst = buildStump(dataArr, classLabels, D) #print("D:",D.T) alpha = float(0.5*log((1.0-error)/max(error, 1e-16))) bestStump['alpha'] = alpha weakClassArr.append(bestStump) #print("classEst: ", classEst.T) expon = multiply(-1*alpha*mat(classLabels).T, classEst) # Ê∑∑Ê∑ÜÁü©Èòµ D = multiply(D, exp(expon)) D = D/D.sum() aggClassEst += alpha*classEst #print("aggClassEst: ", aggClassEst.T) aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m, 1))) #print("predictedVals: ", sign(aggClassEst).T) errorRate = aggErrors.sum()/m #print("total error: ", errorRate, "\n") if errorRate == 0.0: break return weakClassArr, aggClassEst 1adaBoostTrainDS(datMat, classLabels, 9) D: [[0.2 0.2 0.2 0.2 0.2]] classEst: [[-1. 1. -1. -1. 1.]] aggClassEst: [[-0.69314718 0.69314718 -0.69314718 -0.69314718 0.69314718]] predictedVals: [[-1. 1. -1. -1. 1.]] total error: 0.2 D: [[0.5 0.125 0.125 0.125 0.125]] classEst: [[ 1. 1. -1. -1. -1.]] aggClassEst: [[ 0.27980789 1.66610226 -1.66610226 -1.66610226 -0.27980789]] predictedVals: [[ 1. 1. -1. -1. -1.]] total error: 0.2 D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5 ]] classEst: [[1. 1. 1. 1. 1.]] aggClassEst: [[ 1.17568763 2.56198199 -0.77022252 -0.77022252 0.61607184]] predictedVals: [[ 1. 1. -1. -1. 1.]] total error: 0.0 [{&apos;dim&apos;: 0, &apos;thresh&apos;: 1.3, &apos;ineq&apos;: &apos;lt&apos;, &apos;alpha&apos;: 0.6931471805599453}, {&apos;dim&apos;: 1, &apos;thresh&apos;: 1.0, &apos;ineq&apos;: &apos;lt&apos;, &apos;alpha&apos;: 0.9729550745276565}, {&apos;dim&apos;: 0, &apos;thresh&apos;: 0.9, &apos;ineq&apos;: &apos;lt&apos;, &apos;alpha&apos;: 0.8958797346140273}] ÁªìÊûúÂåÖÂê´‰∏â‰∏™Â≠óÂÖ∏ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫ÜÂàÜÁ±ªÊâÄÈúÄË¶ÅÁöÑÊâÄÊúâ‰ø°ÊÅØ„ÄÇ ÊµãËØïÁÆóÊ≥ïÔºöÂü∫‰∫éAdaBoostÁöÑÂàÜÁ±ª123456789def adaClassify(datToClass, classifierArr): dataMatrix = mat(datToClass) m = shape(dataMatrix)[0] aggClassEst = mat(zeros((m, 1))) for i in range(len(classifierArr)): classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'], classifierArr[i]['thresh'], classifierArr[i]['ineq']) aggClassEst += classifierArr[i]['alpha']*classEst #print(aggClassEst.T) return sign(aggClassEst) 12classifierArr = adaBoostTrainDS(datMat, classLabels, 30)adaClassify([0, 0], classifierArr) D: [[0.2 0.2 0.2 0.2 0.2]] classEst: [[-1. 1. -1. -1. 1.]] aggClassEst: [[-0.69314718 0.69314718 -0.69314718 -0.69314718 0.69314718]] predictedVals: [[-1. 1. -1. -1. 1.]] total error: 0.2 D: [[0.5 0.125 0.125 0.125 0.125]] classEst: [[ 1. 1. -1. -1. -1.]] aggClassEst: [[ 0.27980789 1.66610226 -1.66610226 -1.66610226 -0.27980789]] predictedVals: [[ 1. 1. -1. -1. -1.]] total error: 0.2 D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5 ]] classEst: [[1. 1. 1. 1. 1.]] aggClassEst: [[ 1.17568763 2.56198199 -0.77022252 -0.77022252 0.61607184]] predictedVals: [[ 1. 1. -1. -1. 1.]] total error: 0.0 [[-0.69314718]] [[-1.66610226]] [[-2.56198199]] matrix([[-1.]]) 1adaClassify([[5, 5], [0, 0]], classifierArr) [[ 0.69314718 -0.69314718]] [[ 1.66610226 -1.66610226]] [[ 2.56198199 -2.56198199]] matrix([[ 1.], [-1.]]) ÂÆû‰æãÔºöÂú®‰∏Ä‰∏™Â§çÊùÇÊï∞ÊçÆÈõÜ‰∏äÂ∫îÁî®AdaBoost Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÁ°Æ‰øùÁ±ªÂà´Ê†áÁ≠æÊòØ+1Âíå-1ËÄåÈùû0Âíå1 ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÂú®Êï∞ÊçÆ‰∏äÔºåÂà©Áî®adaBoostTrainDS()ÂáΩÊï∞ËÆ≠ÁªÉÂá∫‰∏ÄÁ≥ªÂàóÂàÜÁ±ªÂô® ÊµãËØïÁÆóÊ≥ïÔºöÁî®AdaBoostÂíåLogisticÂõûÂΩíÂØπÊØî ‰ΩøÁî®ÁÆóÊ≥ïÔºöËßÇÂØüËØ•‰æãÂ≠ê‰∏äÁöÑÈîôËØØÁéá 123456789101112def loadDataSet(fileName): numFeat = len(open(fileName).readline().split('\t')) dataMat = []; labelMat = [] fr = open(fileName) for line in fr.readlines(): lineArr =[] curLine = line.strip().split('\t') for i in range(numFeat-1): lineArr.append(float(curLine[i])) dataMat.append(lineArr) labelMat.append(float(curLine[-1])) return dataMat,labelMat 12dataArr, labelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch07/horseColicTraining2.txt')classifierArray = adaBoostTrainDS(dataArr, labelArr, 10) 12testArr, testlabelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch07/horseColicTest2.txt')prediction10 = adaClassify(testArr, classifierArray) 12errArr=mat(ones((67, 1)))errArr[prediction10 != mat(testlabelArr).T].sum() 16.0 ÂàÜÁ±ªÈîôËØØ‰∏∫16‰∏™ÔºåÈîôËØØÁéá23%ÔºåÊòéÊòæ‰ºò‰∫éÈÄªËæëÂõûÂΩíÁöÑ33%„ÄÇ 1234567891011classifierNum = [1, 10 , 50, 100, 500, 1000, 10000]trainerrArr=mat(ones((299, 1)))testerrArr=mat(ones((67, 1)))print("ÂàÜÁ±ªÂô®Êï∞ÁõÆ\tËÆ≠ÁªÉÈîôËØØÁéá\tÊµãËØïÈîôËØØÁéá")for n in classifierNum: classifierArray = adaBoostTrainDS(dataArr, labelArr, n) trainPrediction = adaClassify(dataArr, classifierArray) testPrediction = adaClassify(testArr, classifierArray) trainErrRate = trainerrArr[trainPrediction != mat(labelArr).T].sum()/299 testErrRate = testerrArr[testPrediction != mat(testlabelArr).T].sum()/67 print("%d\t\t%.2f\t\t%.2f" % (n, trainErrRate, testErrRate)) ÂàÜÁ±ªÂô®Êï∞ÁõÆ ËÆ≠ÁªÉÈîôËØØÁéá ÊµãËØïÈîôËØØÁéá 1 0.28 0.27 10 0.23 0.24 50 0.19 0.21 100 0.19 0.22 500 0.16 0.25 1000 0.14 0.31 10000 0.11 0.33 ËßÇÂØü‰∏äË°®ÂèëÁé∞ÔºåÈöèÁùÄÂàÜÁ±ªÂô®ÁöÑÂ¢ûÂä†ËÆ≠ÁªÉÈîôËØØÁéáÂú®ÂáèÂ∞èÔºåÊµãËØïÈîôËØØÁéáÂú®ËææÂà∞‰∏Ä‰∏™ÊúÄÂ∞èÂÄºÂêéÂèàÂºÄÂßã‰∏äÂçáÔºåËøôÁßçÁé∞Ë±°Áß∞‰∏∫ËøáÊãüÂêàÔºàoverfittingÔºâ„ÄÇ AdaBoostÂíåSVMÊúâÂæàÂ§öÁõ∏‰ºº‰πãÂ§ÑÔºåÊàë‰ª¨ÂèØ‰ª•ÊääÂº±ÂàÜÁ±ªÂô®ÊÉ≥Ë±°ÊàêSVMÁöÑ‰∏Ä‰∏™Ê†∏ÂáΩÊï∞Ôºå‰πüÂèØ‰ª•ÊåâÁÖßÊúÄÂ§ßÂåñÊüê‰∏™ÊúÄÂ∞èÈó¥ÈöîÁöÑÊñπÂºèÈáçÂÜôAdaBoostÁÆóÊ≥ï„ÄÇËÄåÂÆÉ‰ª¨ÁöÑ‰∏çÂêå‰πãÂ§ÑÂú®‰∫éÂÖ∂ÊâÄÂÆö‰πâÁöÑÈó¥ÈöîËÆ°ÁÆóÊñπÂºèÊúâÊâÄ‰∏çÂêåÔºåÂõ†Ê≠§ÂØºËá¥ÁªìÊûú‰πü‰∏çÂêå„ÄÇÁâπÂà´ÊòØÂú®È´òÁ∫¨Â∫¶Á©∫Èó¥‰∏ãÔºåËøô‰∏§ËÄÖ‰πãÈó¥ÁöÑÂ∑ÆÂºÇÂ∞±Êõ¥Âä†ÊòéÊòæ„ÄÇ ÈùûÂùáË°°ÈóÆÈ¢òÂàÜÁ±ª‰πãÂâçÊàë‰ª¨ÂÅáËÆæÁ±ªÂà´ÁöÑÂàÜÁ±ª‰ª£‰ª∑ÊòØ‰∏ÄÊ†∑ÁöÑÔºåËøôÊ†∑Â∞±‰ºöÂá∫Áé∞‰∏ÄÁ≥ªÂàóÈóÆÈ¢òÔºå‰æãÂ¶ÇÔºöÊàë‰ª¨È¢ÑÊµãÈ©¨‰ºöÊ≠ªÔºå‰∫∫‰ª¨Â∞±ÂèØËÉΩÁªôÈ©¨ÂÆûÊñΩÂÆâ‰πêÊ≠ªËÄå‰∏çÊòØÈÄöËøáÊ≤ªÁñóÊù•ÈÅøÂÖçÊ≠ª‰∫°ÔºåÊàë‰ª¨ÁöÑÈ¢ÑÊµã‰πüËÆ∏ÊòØÈîôËØØÁöÑÔºåÈ©¨Êú¨Êù•ÂèØ‰ª•ÁªßÁª≠Ê¥ªÁùÄÔºåÊØïÁ´üÊàë‰ª¨ÁöÑÂàÜÁ±ªÂô®Âè™Êúâ80%ÁöÑÁ≤æÁ°ÆÁéá„ÄÇÂ¶ÇÊûúËøáÊª§ÂûÉÂúæÈÇÆ‰ª∂ÔºåÂêàÊ≥ïÁöÑÈÇÆ‰ª∂‰πüË¢´ËÆ§‰∏∫ÊòØÂûÉÂúæÈÇÆ‰ª∂Âë¢ÔºåÁôåÁóáÊ£ÄÊµãÊÉÖÊÑøËØØÂà§‰πü‰∏çËÉΩÊºèÂà§„ÄÇ Âú®Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ã‰∏çÂêåÁ±ªÂà´ÁöÑÂàÜÁ±ª‰ª£‰ª∑Âπ∂‰∏çÁõ∏Á≠â„ÄÇÊé•‰∏ãÊù•ËÆ®ËÆ∫‰∏ÄÁßçÊñ∞ÁöÑÂàÜÁ±ªÂô®Â∫¶ÈáèÊñπÊ≥ï„ÄÇ ÂÖ∂‰ªñÂàÜÁ±ªÊÄßËÉΩÂ∫¶ÈáèÊåáÊ†áÔºöÊ≠£Á°ÆÁéá„ÄÅÂè¨ÂõûÁéá„ÄÅÂèäROCÊõ≤Á∫øÈîôËØØÁéáÊåáÁöÑÊòØÂú®ÊâÄÊúâÊµãËØïÊ†∑‰æã‰∏≠ÈîôÂàÜÁöÑÊ†∑‰æãÊØî‰æãÔºåËøôÊ†∑ÁöÑÂ∫¶ÈáèÈîôËØØÊé©Áõñ‰∫ÜÊ†∑‰æãÂ¶Ç‰ΩïË¢´ÂàÜÈîôÁöÑ‰∫ãÂÆû„ÄÇ Âú®Êú∫Âô®Â≠¶‰π†‰∏≠Êúâ‰∏Ä‰∏™ÊôÆÈÅçÈÄÇÁî®ÁöÑÁß∞‰∏∫Ê∑∑Ê∑ÜÁü©ÈòµÔºàconfusion matrixÔºâÁöÑÂ∑•ÂÖ∑ÔºåÂÆÉÂèØ‰ª•Â∏ÆÂä©‰∫∫‰ª¨Êõ¥Â•ΩÁöÑ‰∫ÜËß£ÂàÜÁ±ª‰∏≠ÁöÑÈîôËØØÔºåÊúâËøôÊ†∑‰∏Ä‰∏™ÂÖ≥‰∫éÂú®ÊàøÂ≠êÂë®Âõ¥ÂèØËÉΩÂèëÁé∞ÁöÑÂä®Áâ©Á±ªÂûãÁöÑÈ¢ÑÊµã„ÄÇ . È¢Ñ Êµã Áªì Êûú Áúü Áãó Áå´ Èº† ÂÆû Áãó 24 2 5 Áªì Áå´ 2 27 0 Êûú Èº† 4 2 30 Âà©Áî®Ê∑∑Ê∑ÜÁü©ÈòµÂ∞±ÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂàÜÁ±ª‰∏≠ÁöÑÈîôËØØ‰∫Ü„ÄÇÂ¶ÇÊûúÁü©ÈòµÈùûÂØπËßíÂÖÉÁ¥†Âùá‰∏∫0ÔºåÂ∞±‰ºöÂæóÂà∞‰∏Ä‰∏™ÂÆåÁæéÁöÑÂàÜÁ±ªÂô®„ÄÇ Êé•‰∏ãÊù•ËÄÉËôëÂè¶Â§ñ‰∏Ä‰∏™Ê∑∑Ê∑ÜÁü©Èòµ„ÄÇ . È¢ÑÊµãÁªìÊûú Áúü +1 -1 ÂÆû +1 ÁúüÊ≠£‰æãÔºàTPÔºâ ‰º™Âèç‰æãÔºàFNÔºâ Áªì -1 ‰º™ËØÅ‰æãÔºàFPÔºâ ÁúüÂèç‰æãÔºàTNÔºâ Êûú Ê≠£Á°ÆÁéáÔºàprecisionÔºâ = TP/(TP+FP) Âè¨ÂõûÁéáÔºàRecallÔºâ = TP/(TP+FN) Êàë‰ª¨ÂèØ‰ª•ÊûÑÈÄ†‰∏Ä‰∏™È´òÊ≠£Á°ÆÁéáÊàñÊêûÂè¨ÂõûÁéáÁöÑÂàÜÁ±ªÂô®Ôºå‰ΩÜÊòØÂ•ãÁî∑‰øùËØÅ‰∏§ËÄÖÈÉΩÊàêÁ´ã„ÄÇ Âè¶‰∏ÄÁßçÂ∫¶ÈáèÂàÜÁ±ª‰∏≠ÁöÑÈùûÂùáË°°ÊÄßÁöÑÂ∑•ÂÖ∑ÊòØROCÊõ≤Á∫øÔºàROC curveÔºâ,ROC‰ª£Ë°®Êé•Êî∂ËÄÖÊìç‰ΩúÁâπÂæÅÔºàreceiver operating characteristicÔºâÔºå‰ªñÊúÄÊó©Âú®‰∫åÊàòÊúüÈó¥Áî±ÁîµÂô®Â∑•Á®ãÂ∏àÊûÑÂª∫Èõ∑ËææÁ≥ªÁªüÊó∂‰ΩøÁî®Ëøá„ÄÇ 1234567891011121314151617181920212223242526272829def plotROC(predStrengths, classLabels): import matplotlib.pyplot as plt cur = (1.0,1.0) # cursor ySum = 0.0 # variable to calculate AUC numPosClas = sum(array(classLabels)==1.0) yStep = 1/float(numPosClas); xStep = 1/float(len(classLabels)-numPosClas) sortedIndicies = predStrengths.argsort() # get sorted index, it's reverse fig = plt.figure() fig.clf() ax = plt.subplot(111) # loop through all the values, drawing a line segment at each point for index in sortedIndicies.tolist()[0]: if classLabels[index] == 1.0: delX = 0 delY = yStep else: delX = xStep delY = 0 ySum += cur[1] # draw line from cur to (cur[0]-delX,cur[1]-delY) ax.plot([cur[0],cur[0]-delX],[cur[1],cur[1]-delY], c='b') cur = (cur[0]-delX,cur[1]-delY) ax.plot([0,1],[0,1],'b--') plt.xlabel('False positive rate') plt.ylabel('True positive rate') plt.title('ROC curve for AdaBoost horse colic detection system') ax.axis([0,1,0,1]) plt.show() print("the Area Under the Curve is: ",ySum*xStep) 123dataArr, labelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch07/horseColicTraining2.txt')classifierArray, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 10)plotROC(aggClassEst.T, labelArr) the Area Under the Curve is: 0.8582969635063604 ‰∏äÂõæÁªôÂá∫‰∏§Êù°Á∫øÔºå‰∏ÄÊù°ÂÆûÁ∫ø‰∏ÄÊù°ËôöÁ∫øÔºåÂõæ‰∏≠ÁöÑÊ®™ËΩ¥ÊòØ‰º™ËØÅ‰æãÁöÑÊØî‰æãÔºàFP/(FP+TN)ÔºâÔºåÁ∫µËΩ¥ÊòØÁúüÊ≠£‰æãÁöÑÊØî‰æãÔºàTP/(TP+FN)Ôºâ„ÄÇROCÊõ≤Á∫øÁªôÂá∫ÁöÑÊòØÂΩìÈòàÂÄºÂèòÂåñÊó∂ÂÅáÈò≥ÁéáÂíåÁúüÈò≥ÁéáÁöÑÂèòÂåñÊÉÖÂÜµ„ÄÇ ROCÊõ≤Á∫ø‰∏ç‰ΩÜÂèØ‰ª•Áî®‰∫éÊØîËæÉÂàÜÁ±ªÂô®ÔºåËøòÂèØ‰ª•Âü∫‰∫éÊàêÊú¨ÊïàÁõäÔºàcost versus benefitÔºâÂàÜÊûêÊù•ÂÅöÂá∫ÂÜ≥Á≠ñ„ÄÇÁî±‰∫éÂú®‰∏çÂêåÁöÑÈòàÂÄº‰∏ãÔºå‰∏çÂêåÁöÑÂàÜÁ±ªÂô®ÁöÑË°®Áé∞ÊÉÖÂÜµÂèØËÉΩÂêÑ‰∏çÁõ∏ÂêåÔºåÂõ†Ê≠§‰∏ÄÊüêÁßçÊñπÂºèÂ∞ÜÂÆÉ‰ª¨ÁªÑÂêàËµ∑Êù•Ëé∑ÂèñÊõ¥ÊúâÊÑè‰πâ„ÄÇ Âú®ÁêÜÊÉ≥ÊÉÖÂÜµ‰∏ãÔºåÊúÄ‰Ω≥ÁöÑÂàÜÁ±ªÂô®Â∫îËØ•Â∞ΩÂèØËÉΩÂ§Ñ‰∫éÂ∑¶‰∏äËßíÔºåËøôÊÑèÂë≥ÁùÄÂàÜÁ±ªÂô®Âú®ÂÅáÈò≥ÁéáÂæà‰ΩéÁöÑÂêåÊó∂Ëé∑Âæó‰∫ÜÂæàÈ´òÁöÑÁúüÈò≥Áéá„ÄÇ‰æãÂ¶ÇËøáÊª§‰∫ÜÊâÄÊúâÁöÑÂûÉÂúæÈÇÆ‰ª∂ÔºåÊ≤°ÊúâÂ∞ÜÂêàÊ≥ïÈÇÆ‰ª∂ËØØËØÜÂà´‰∏∫ÂûÉÂúæÈÇÆ‰ª∂„ÄÇ ROCÊõ≤Á∫ø‰∏ã‰∏ãÁöÑÈù¢ÁßØÔºàAre unser the curveÔºåAUCÔºâAUCÁªôÂá∫ÁöÑÊó∂ÂàÜÁ±ªÂô®ÁöÑÂπ≥ÂùáÊÄßËÉΩÂÄºÔºå‰∏Ä‰∏™ÂÆåÁæéÁöÑÂàÜÁ±ªÂô®AUC‰∏∫1ÔºåÈöèÊú∫ÁåúÊµãÁöÑAUC‰∏∫0.5„ÄÇ Âü∫‰∫é‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂàÜÁ±ªÂô®ÂÜ≥Á≠ñÊéßÂà∂Â§ÑÁêÜÈùûÂùáË°°ÈóÆÈ¢òÁöÑÊï∞ÊçÆÊäΩÊ†∑ÊñπÊ≥ïÊ¨†ÊäΩÊ†∑ÔºàundersamplingÔºâÂà†Èô§Ê†∑‰æã ËøáÊäΩÊ†∑ÔºàoversamplingÔºâÂ§çÂà∂Ê†∑‰æã ÊÄªÁªìÈõÜÊàêÊñπÊ≥ïÈÄöËøáÁªÑÂêàÂ§ö‰∏™ÂàÜÁ±ªÂô®ÁöÑÂàÜÁ±ªÁªìÊûúÔºåËé∑Âæó‰∫ÜÊØîÁÆÄÂçïÁöÑÂàÜÁ±ªÂô®Êõ¥Â•ΩÁöÑÂàÜÁ±ªÁªìÊûú„ÄÇ Â§ö‰∏™ÂàÜÁ±ªÂô®ÁªÑÂêàÂèØËÉΩ‰ºöËøõ‰∏ÄÊ≠•Âá∏ÊòæÂá∫ÂçïÂàÜÁ±ªÂô®ÁöÑ‰∏çË∂≥ÔºåÊØîÂ¶ÇËøáÊãüÂêàÈóÆÈ¢ò„ÄÇÂ¶ÇÊûúÂàÜÁ±ªÂô®‰πãÈó¥Â∑ÆÂà´ÊòæËëóÔºåÈÇ£‰πàÂ§ö‰∏™ÂàÜÁ±ªÂô®ÁªÑÂêàÂ∞±ÂèØËÉΩ‰ºöÁºìËß£Ëøô‰∏ÄÈóÆÈ¢ò„ÄÇ Âú®bagging‰∏≠ÔºåÊòØÈÄöËøáÈöèÊú∫ÊäΩÊ†∑ÁöÑÊõøÊç¢ÊñπÂºèÂæóÂà∞‰∏éÂéüÂßãÊï∞ÊçÆÈõÜËßÑÊ®°‰∏ÄÊ†∑ÁöÑÊï∞ÊçÆÈõÜÔºåËÄåboostingÂú®Êï∞ÊçÆÈõÜ‰∏äÈ°∫Â∫èÂ∫îÁî®‰∫ÜÂ§ö‰∏™‰∏çÂêåÁöÑÂàÜÁ±ªÂô®„ÄÇ ÈùûÂùáË°°ÂàÜÁ±ªÈóÆÈ¢òÊòØÊåáÂú®ÂàÜÁ±ªÂô®ËÆ≠ÁªÉÊó∂Ê≠£‰æãÊï∞ÁõÆÂíåÂèç‰æãÊï∞ÁõÆ‰∏çÁõ∏Á≠âÔºàÁõ∏Â∑ÆÂæàÂ§ßÔºâ„ÄÇËØ•ÈóÆÈ¢òÂú®ÈîôÂàÜÊ≠£‰æãÂíåÂèç‰æãÁöÑ‰ª£‰ª∑‰∏çÂêåÊó∂‰πüÂ≠òÂú®]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>AdaBoost</tag>
        <tag>bagging</tag>
        <tag>boosting</tag>
        <tag>ROC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂÖ≠Ôºâ]]></title>
    <url>%2F2020%2F04%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Ëøô‰∏ÄÁ´†ÁöÑÂÜÖÂÆπÈùûÂ∏∏Â§öÔºåÂú®Á•ûÁªèÁΩëÁªúÂ§ßÁÅ´ÂâçÔºåSVMÊòØÊúÄ‰ºòÁßÄÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÂ∞ΩÁÆ°Áé∞Âú®Â∑≤ÁªèÂæàÂ∞ëÁî®‰∫ÜÔºå‰ΩÜ‰Ωú‰∏∫‰∏ÄÊú¨‰∏ÉÂπ¥ÂâçÁöÑ‰π¶ËøòÊòØÂæàËØ¶ÁªÜÁöÑËÆ≤Ëß£‰∫ÜÔºåÊâÄ‰ª•ËøôÈáåÁÆÄÂçïÁöÑËÆ∞ÂΩï‰∏ã„ÄÇ Âü∫‰∫éÊúÄÂ§ßÈó¥ÈöîÂàÜÈöîÊï∞ÊçÆÊîØÊåÅÂêëÈáèÊú∫ ‰ºòÁÇπÔºöÊ≥õÂåñÈîôËØØÁéá‰ΩéÔºåËÆ°ÁÆóÂºÄÈîÄ‰∏çÂ§ßÔºåÁªìÊûúÊòìÁêÜËß£ Áº∫ÁÇπÔºöÂØπÂèÇÊï∞Ë∞ÉËäÇÂíåÊ†∏ÂáΩÊï∞ÈÄâÊã©ÊïèÊÑüÔºåÂéüÂßãÂàÜÁ±ªÂô®‰∏çÂä†‰øÆÊîπ‰ªÖÈÄÇÁî®‰∫éÂ§ÑÁêÜ‰∫åÂàÜÁ±ªÈóÆÈ¢ò ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞ÂûãÊï∞ÊçÆ ËßÇÂØü‰∏äÂõæÂõæÂèëÁé∞Êàë‰ª¨‰∏çËÉΩÁîªÂá∫‰∏ÄÊù°Á∫øÊàñËÄÖÂúÜÊääÂúÜÂΩ¢ÂíåÊñπÂΩ¢ÁöÑÊï∞ÊçÆÂàÜÂâ≤ÂºÄÔºåËÄå‰∏ãÂõæÂèØ‰ª•ÁîªÂá∫‰∏ÄÊù°Áõ¥Á∫øÂ∞Ü‰∏§ÁªÑÊï∞ÊçÆÂàÜÂºÄ„ÄÇÊâÄ‰ª•‰∏ãÂõæÁöÑÊï∞ÊçÆÁß∞‰∏∫Á∫øÊÄßÂèØÂàÜÔºàlinearly separableÔºâ„ÄÇ Â∞ÜÊï∞ÊçÆÈõÜÂàÜÂºÄÁöÑÁõ¥Á∫øÁß∞‰∏∫ÂàÜÂâ≤Ë∂ÖÂπ≥Èù¢Ôºàseparating hyperplaneÔºâ„ÄÇ‰∏äÈù¢ÁªôÂá∫ÁöÑ‰æãÂ≠êÊï∞ÊçÆÈÉΩÂú®‰∫åÁª¥Âπ≥Èù¢‰∏äÔºåÊâÄ‰ª•ÂàÜÂâ≤Ë∂ÖÂπ≥Èù¢ÊòØ‰∏ÄÊù°Áõ¥Á∫øÔºåÂ¶ÇÊûúÊâÄÁªôÁöÑÊï∞ÊçÆÊòØ‰∏âÁª¥ÁöÑÔºåÈÇ£‰πàÂàÜÂâ≤Êï∞ÊçÆÁöÑÂ∞±ÊòØ‰∏Ä‰∏™Âπ≥Èù¢„ÄÇÂ¶ÇÊûúÊï∞ÊçÆÈõÜÊòØ‰∏Ä‰∏™1024Áª¥ÁöÑÔºåÈÇ£Â∞±ÈúÄË¶Å‰∏Ä‰∏™1023Áª¥ÁöÑÂØπË±°ÂØπÊï∞ÊçÆÂàÜÂâ≤„ÄÇÂ¶ÇÊûú‰∏Ä‰∏™Êï∞ÊçÆÈõÜÊòØNÁª¥ÁöÑÔºåÈúÄË¶Å‰∏Ä‰∏™N-1Áª¥ÁöÑË∂ÖÂπ≥Èù¢ÂàÜÂâ≤„ÄÇ ÊîØÊåÅÂêëÈáèÔºàsupport vectorÔºâÂ∞±ÊòØÁ¶ªÂàÜÂâ≤Ë∂ÖÂπ≥Èù¢ÊúÄËøëÁöÑÈÇ£‰∫õÁÇπ„ÄÇ ÂØªÊâæÊúÄÂ§ßÈó¥ÈöîHow can we measure the line that best separates the data? To start with, look at figure 6.3. Our separating hyperplane has the form wTx+b. If we want to find the distance from A to the separating plane, we must measure normal or perpendicular to the line. This is given by |wTA+b|/||w||. The constant b is just an offset like w0 in logistic regression. All this w and b stuff describes the separating line, or hyperplane, for our data. Now, let‚Äôs talk about the classifier. ÂàÜÁ±ªÂô®Ê±ÇËß£ÁöÑ‰ºòÂåñÈóÆÈ¢òSVMÂ∫îÁî®ÁöÑ‰∏ÄËà¨Ê°ÜÊû∂SVMÁöÑ‰∏ÄËà¨ÊµÅÁ®ã Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÈúÄË¶ÅÊï∞ÂÄºÂûãÊï∞ÊçÆ ÂàÜÊûêÊï∞ÊçÆÔºöÊúâÂä©‰∫éÂèØËßÜÂåñÂàÜÂâ≤Ë∂ÖÂπ≥Èù¢ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöSVMÂ§ßÂ§ßÈÉ®ÂàÜÊó∂Èó¥ÈÉΩÊ∫êËá™ËÆ≠ÁªÉÔºåËØ•ËøáÁ®ã‰∏ªË¶ÅÂÆûÁé∞‰∏§‰∏™ÂèÇÊï∞ÁöÑË∞É‰ºò ÊµãËØïÁÆóÊ≥ïÔºöÂçÅÂàÜÁÆÄÂçïÁöÑËÆ°ÁÆóËøáÁ®ãÂ∞±ÂèØ‰ª•ÂÆûÁé∞ ÈÄÇÁî®ÁÆóÊ≥ïÔºöÂá†‰πéÊâÄÊúâÂàÜÁ±ªÈóÆÈ¢òÈÉΩÂèØ‰ª•ÈÄÇÁî®SVMÔºåÂÄºÂæó‰∏ÄÊèêÁöÑÊòØÔºåSVMÊú¨Ë∫´ÊòØ‰∏Ä‰∏™‰∫åÂàÜÁ±ªÂàÜÁ±ªÂô®ÔºåÂØπÂ§öÂàÜÁ±ªÈóÆÈ¢òSVMÈúÄË¶ÅÂØπ‰ª£Á†Å‰øÆÊîπ SMOÈ´òÊïà‰ºòÂåñÁÆóÊ≥ïSMOË°®Á§∫Â∫èÂàóÊúÄÂ∞è‰ºòÂåñÔºàSequential Minimal OptimizationÔºâ SMOÁÆóÊ≥ïÁöÑÁõÆÊ†áÊòØÊ±ÇÂá∫‰∏ÄÁ≥ªÂàóalphaÂíåbÔºå‰∏ÄÊó¶Ê±ÇÂá∫‰∫ÜËøô‰∫õalphaÔºåÂ∞±ÂæàÂÆπÊòìËÆ°ÁÆóÂ§ÑÊùÉÈáçÂêëÈáèwÂπ∂ÂæóÂà∞ÂàÜÂâ≤Ë∂ÖÂπ≥Èù¢„ÄÇ SMOÁÆóÊ≥ïÁöÑÂ∑•‰ΩúÂéüÁêÜÊòØÔºöÊØèÊ¨°Âæ™ÁéØ‰∏≠ÈÄâÊã©‰∏§‰∏™alphaËøõË°å‰ºòÂåñÂ§ÑÁêÜ„ÄÇ‰∏ÄÊó¶ÊâæÂà∞‰∏ÄÂØπÂêàÈÄÇÁöÑalphaÔºåÈÇ£‰πàÂ∞±Â¢ûÂ§ßÂÖ∂‰∏≠‰∏Ä‰∏™ÂêåÊó∂ÂáèÂ∞èÂè¶‰∏Ä‰∏™„ÄÇËøôÈáåÊâÄË∞ìÁöÑÂêàÈÄÇ‰ª¨Â∞±ÊòØÊåá‰∏§‰∏™alphaÂøÖÈ°ªË¶ÅÁ¨¶Âêà‰∏§‰∏™Êù°‰ª∂Ôºå‰∏ÄÔºå‰∏§‰∏™alphaÂøÖÈ°ªË¶ÅÂú®Èó¥ÈöîËæπÁïå‰πãÂ§ñÔºå‰∫åÔºå‰∏§‰∏™alphaËøòÊ≤°ÊúâËøõË°åËøáÂå∫Èó¥ÂåñÂ§ÑÁêÜÊàñËÄÖ‰∏çÂú®ËæπÁïå‰∏ä„ÄÇ Â∫îÁî®ÁÆÄÂåñÁâàSMOÁÆóÊ≥ïÂ§ÑÁêÜÂ∞èËßÑÊ®°Êï∞ÊçÆÈõÜ$$\Sigma\alpha*label^{i} = 0$$ 1234567891011121314151617181920212223def loadDataSet(fileName): dataMat = [] labelMat = [] fr = open(fileName) for line in fr.readlines(): lineArr = line.strip().split('\t') dataMat.append([float(lineArr[0]), float(lineArr[1])]) labelMat.append(float(lineArr[2])) fr.close() return dataMat, labelMatdef selectJrand(i, m): j = i while (j == i): j = int(random.uniform(0, m)) return jdef clipAlpha(aj, H, L): if aj &gt; H: aj = H if L &gt; aj: aj = L return aj 12dataArr, labelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch06/testSet.txt')labelArr[:10] [-1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0] selectJrand()Êúâ‰∏§‰∏™ÂèÇÊï∞ÔºåiÊòØÁ¨¨‰∏Ä‰∏™alphaÁöÑ‰∏ãË°®ÔºåmÊòØÊâÄÊúâalphaÁöÑÊï∞ÁõÆÔºåÂè™Ë¶ÅÂáΩÊï∞ÂÄº‰∏çÁ≠â‰∫éËæìÂÖ•ÂÄºiÔºåÂáΩÊï∞Â∞±‰ºöÈöèÊú∫ÈÄâÊã© clipAlpha()ÁöÑ‰ΩúÁî®ÊòØË∞ÉÊï¥alphaÁöÑÂÄºÂú®HÂíåL‰πãÈó¥„ÄÇ SMO‰º™‰ª£Á†ÅÂ§ßËá¥Â¶Ç‰∏ãÔºö ÂàõÂª∫‰∏Ä‰∏™alphaÂêëÈáèÂπ∂Â∞ÜÂÖ∂ÂàùÂßãÂåñ‰∏∫0ÂêëÈáè ÂΩìËø≠‰ª£Ê¨°Êï∞Â∞è‰∫éÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞Êó∂ÔºàÂ§ñÂæ™ÁéØÔºâ ÂØπÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏™Êï∞ÊçÆÂêëÈáèÔºàÂÜÖÂæ™ÁéØÔºâÔºö Â¶ÇÊûúÁªôÊï∞ÊçÆÂêëÈáèÂèØ‰ª•Ë¢´‰ºòÂåñÔºö ÈöèÊú∫ÈÄâÊã©Âè¶Â§ñ‰∏Ä‰∏™Êï∞ÊçÆÂêëÈáè Â¶ÇÊûú‰ºòÂåñËøô‰∏§‰∏™ÂêëÈáè Â¶ÇÊûú‰∏§‰∏™ÂêëÈáèÈÉΩ‰∏çËÉΩË¢´‰ºòÂåñÔºåÈÄÄÂá∫ÂÜÖÂæ™ÁéØ Â¶ÇÊûúÊâÄÊúâÂêëÈáèÈÉΩÊ≤°Ë¢´‰ºòÂåñÔºåÂ¢ûÂä†Ëø≠‰ª£Êï∞ÁõÆÔºåÁªßÁª≠‰∏ã‰∏ÄÊ¨°Âæ™ÁéØ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from numpy import *def smoSimple(dataMatIn, classLabels, C, toler, maxIter): dataMatrix = mat(dataMatIn) labelMat = mat(classLabels).transpose() b = 0 m,n = shape(dataMatrix) alphas = mat(zeros((m,1))) iter = 0 while (iter &lt; maxIter): alphaPairsChanged = 0 for i in range(m): fXi = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b Ei = fXi - float(labelMat[i]) #if checks if an example violates KKT conditions if ((labelMat[i]*Ei &lt; -toler) and (alphas[i] &lt; C)) or ((labelMat[i]*Ei &gt; toler) and (alphas[i] &gt; 0)): j = selectJrand(i,m) fXj = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b Ej = fXj - float(labelMat[j]) alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy(); if (labelMat[i] != labelMat[j]): L = max(0, alphas[j] - alphas[i]) H = min(C, C + alphas[j] - alphas[i]) else: L = max(0, alphas[j] + alphas[i] - C) H = min(C, alphas[j] + alphas[i]) if L==H: print("L==H") continue eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T if eta &gt;= 0: print("eta&gt;=0") continue alphas[j] -= labelMat[j]*(Ei - Ej)/eta alphas[j] = clipAlpha(alphas[j],H,L) if (abs(alphas[j] - alphaJold) &lt; 0.00001): print("j not moving enough") continue alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j]) # update i by the same amount as j # the update is in the oppostie direction b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T if (0 &lt; alphas[i]) and (C &gt; alphas[i]): b = b1 elif (0 &lt; alphas[j]) and (C &gt; alphas[j]): b = b2 else: b = (b1 + b2)/2.0 alphaPairsChanged += 1 print("iter: %d i:%d, pairs changed %d" % (iter,i,alphaPairsChanged)) if (alphaPairsChanged == 0): iter += 1 else: iter = 0 print("iteration number: %d" % iter) return b,alphas 1b, alphas = smoSimple(dataArr, labelArr, 0.6, 0.001, 40) L==H L==H iter: 0 i:2, pairs changed 1 iter: 0 i:3, pairs changed 2 L==H ... ... iteration number: 39 j not moving enough j not moving enough j not moving enough iteration number: 40 1b matrix([[-3.79661253]]) 1alphas[alphas&gt;0] matrix([[0.12629181, 0.24169497, 0.36797683]]) 1shape(alphas[alphas&gt;0]) (1, 3) 12345supportVectors = []for i in range(100): if alphas[i] &gt; 0.0: supportVectors.append(dataArr[i]) print(dataArr[i], labelArr[i]) [4.658191, 3.507396] -1.0 [3.457096, -0.082216] -1.0 [6.080573, 0.418886] 1.0 123456789101112131415161718192021222324252627282930313233343536373839404142import matplotlibimport matplotlib.pyplot as pltfrom matplotlib.patches import Circleplt.rcParams['axes.unicode_minus']=False # Áî®Êù•Ê≠£Â∏∏ÊòæÁ§∫Ë¥üÂè∑def plotSupportVectors(supportVectors): xcord0 = [] ycord0 = [] xcord1 = [] ycord1 = [] markers =[] colors =[] fr = open('MLiA_SourceCode/machinelearninginaction/Ch06/testSet.txt') for line in fr.readlines(): lineSplit = line.strip().split('\t') xPt = float(lineSplit[0]) yPt = float(lineSplit[1]) label = int(lineSplit[2]) if (label == -1): xcord0.append(xPt) ycord0.append(yPt) else: xcord1.append(xPt) ycord1.append(yPt) fr.close() fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(xcord0,ycord0, marker='s', s=90) ax.scatter(xcord1,ycord1, marker='o', s=50, c='red') plt.title('Support Vectors Circled') for vector in supportVectors: circle = Circle(vector, 0.5, facecolor='none', edgecolor=(0,0.8,0.8), linewidth=2, alpha=0.5) ax.add_patch(circle) #plt.plot([2.3,8.5], [-6,6]) #seperating hyperplane b = -3.75567; w0=0.8065; w1=-0.2761 x = arange(-2.0, 12.0, 0.1) y = (-w0*x - b)/w1 ax.plot(x,y) ax.axis([-2,12,-8,6]) plt.show() ÂúàÂá∫ÊîØÊåÅÂêëÈáè 1plotSupportVectors(supportVectors) Âà©Áî®ÂÆåÊï¥ÁöÑSMOÁÆóÊ≥ïÂä†ÈÄü‰ºòÂåñ123456789101112131415161718192021222324252627282930313233343536class optStruct: def __init__(self,dataMatIn, classLabels, C, toler, kTup): # Initialize the structure with the parameters self.X = dataMatIn self.labelMat = classLabels self.C = C self.tol = toler self.m = shape(dataMatIn)[0] self.alphas = mat(zeros((self.m,1))) self.b = 0 self.eCache = mat(zeros((self.m,2))) #first column is valid flag def calcEk(oS, k): fXk = float(multiply(oS.alphas, oS.labelMat).T*(oS.X*oS.X[k, :].T)) + oS.b Ek = fXk - float(oS.labelMat[k]) return Ek def selectJ(i, oS, Ei): #this is the second choice -heurstic, and calcs Ej maxK = -1; maxDeltaE = 0; Ej = 0 oS.eCache[i] = [1,Ei] #set valid #choose the alpha that gives the maximum delta E validEcacheList = nonzero(oS.eCache[:,0].A)[0] if (len(validEcacheList)) &gt; 1: for k in validEcacheList: #loop through valid Ecache values and find the one that maximizes delta E if k == i: continue #don't calc for i, waste of time Ek = calcEk(oS, k) deltaE = abs(Ei - Ek) if (deltaE &gt; maxDeltaE): maxK = k; maxDeltaE = deltaE; Ej = Ek return maxK, Ej else: #in this case (first time around) we don't have any valid eCache values j = selectJrand(i, oS.m) Ej = calcEk(oS, j) return j, Ejdef updateEk(oS, k):#after any alpha has changed update the new value in the cache Ek = calcEk(oS, k) oS.eCache[k] = [1,Ek] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def innerL(i, oS, istraces=True): Ei = calcEk(oS, i) if ((oS.labelMat[i]*Ei &lt; -oS.tol) and (oS.alphas[i] &lt; oS.C)) or ((oS.labelMat[i]*Ei &gt; oS.tol) and (oS.alphas[i] &gt; 0)): j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy(); if (oS.labelMat[i] != oS.labelMat[j]): L = max(0, oS.alphas[j] - oS.alphas[i]) H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i]) else: L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C) H = min(oS.C, oS.alphas[j] + oS.alphas[i]) if L==H: if istraces: print("L==H") return 0 eta = 2.0 * oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - oS.X[j,:]*oS.X[j,:].T if eta &gt;= 0: if istraces: print("eta&gt;=0") return 0 oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta oS.alphas[j] = clipAlpha(oS.alphas[j],H,L) updateEk(oS, j) # added this for the Ecache if (abs(oS.alphas[j] - alphaJold) &lt; 0.00001): if istraces: print("j not moving enough") return 0 oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j updateEk(oS, i) #added this for the Ecache #the update is in the oppostie direction b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j] - alphaJold)*oS.X[i,:]*oS.X[j,:].T b2 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j] - alphaJold)*oS.X[j,:]*oS.X[j,:].T if (0 &lt; oS.alphas[i]) and (oS.C &gt; oS.alphas[i]): oS.b = b1 elif (0 &lt; oS.alphas[j]) and (oS.C &gt; oS.alphas[j]): oS.b = b2 else: oS.b = (b1 + b2)/2.0 return 1 else: return 0 12345678910111213141516171819202122232425def smoP(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0), istraces=True): #full Platt SMO oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup) iter = 0 entireSet = True; alphaPairsChanged = 0 while (iter &lt; maxIter) and ((alphaPairsChanged &gt; 0) or (entireSet)): alphaPairsChanged = 0 if entireSet: # go over all for i in range(oS.m): alphaPairsChanged += innerL(i, oS) if istraces: print("fullSet, iter: %d i:%d, pairs changed %d" % (iter,i,alphaPairsChanged)) iter += 1 else: # go over non-bound (railed) alphas nonBoundIs = nonzero((oS.alphas.A &gt; 0) * (oS.alphas.A &lt; C))[0] for i in nonBoundIs: alphaPairsChanged += innerL(i, oS, istraces) if istraces: print("non-bound, iter: %d i:%d, pairs changed %d" % (iter,i,alphaPairsChanged)) iter += 1 if entireSet: entireSet = False #toggle entire set loop elif (alphaPairsChanged == 0): entireSet = True print("iteration number: %d" % iter) return oS.b, oS.alphas 12dataArr, labelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch06/testSet.txt')b, alphas = smoP(dataArr, labelArr, 0.6, 0.001, 40) fullSet, iter: 0 i:0, pairs changed 1 fullSet, iter: 0 i:1, pairs changed 1 fullSet, iter: 0 i:2, pairs changed 2 j not moving enough ... ... fullSet, iter: 2 i:97, pairs changed 0 fullSet, iter: 2 i:98, pairs changed 0 fullSet, iter: 2 i:99, pairs changed 0 iteration number: 3 12345supportVectors = []for i in range(100): if alphas[i] &gt; 0.0: supportVectors.append(dataArr[i]) print(dataArr[i], labelArr[i]) [3.542485, 1.977398] -1.0 [7.55151, -1.58003] 1.0 [8.127113, 1.274372] 1.0 [7.108772, -0.986906] 1.0 [6.080573, 0.418886] 1.0 [3.107511, 0.758367] -1.0 1plotSupportVectors(supportVectors) Â¶Ç‰ΩïÁî®‰∏äÈù¢ÂæóÂà∞ÁöÑalphaÂÄºÊù•ËøõË°åÂàÜÁ±ªÔºüÈ¶ñÂÖàÂøÖÈ°ªÂü∫‰∫éalphaÂÄºÂæóÂà∞Ë∂ÖÂπ≥Èù¢ÔºåËÆ°ÁÆów„ÄÇ 12345678def calcWs(alphas, dataArr, classLabels): X = mat(dataArr) labelMat = mat(classLabels).transpose() m, n = shape(X) w = zeros((n ,1)) for i in range(m): w += multiply(alphas[i]*labelMat[i], X[i,:].T) return w 12ws = calcWs(alphas, dataArr, labelArr)ws array([[ 0.65139219], [-0.18666913]]) 12datMat = mat(dataArr)datMat[0]*mat(ws)+b matrix([[-0.94421679]]) Â¶ÇÊûúËØ•ÂÄºÂ§ß‰∫é0ÈÇ£‰πàÂÖ∂Â±û‰∫é1Á±ªÔºåÂ∞è‰∫é0ÂàôÂ±û‰∫é-1Á±ª„ÄÇÂØπ‰∫édataMat[0]ÁÇπÂ∫îËØ•Êó∂Á±ªÂà´-1ÔºåÈ™åËØÅÊ£ÄÊü•Ôºö 1labelArr[0] -1.0 ÂÜô‰∏™ÂáΩÊï∞ÂÖ®ÈÉ®Ê£ÄÊü•‰∏ÄÈÅçÁúãÁúã 1234567891011def checkResult(alphas, b, dataArr, labelArr): ws = calcWs(alphas, dataArr, labelArr) datMat = mat(dataArr) n = len(datMat) errorCount = 0.0 for i in range(n): result = datMat[i]*mat(ws)+b result = 1.0 if float(result) &gt; 0 else -1.0 if result != labelArr[i]: errorCount += 1.0 print("the error tate of this test is %f" % float(errorCount/n)) 1checkResult(alphas, b, dataArr, labelArr) the error tate of this test is 0.000000 ÊµãËØïÁªìÊûúÂÖ®ÈÉ®ÈÉΩÂàÜÁ±ªÊ≠£Á°Æ Âú®Â§çÊùÇÁöÑÊï∞ÊçÆ‰∏äÂ∫îÁî®Ê†∏ÂáΩÊï∞Âà©Áî®Ê†∏ÂáΩÊï∞Â∞ÜÊï∞ÊçÆÊò†Â∞ÑÂà∞È´òÁª¥Á©∫Èó¥ÂæÑÂêëÂü∫Ê†∏ÂáΩÊï∞1%run MLiA_SourceCode/machinelearninginaction/Ch06/plotRBF.py 123456789101112131415161718192021222324252627def kernelTrans(X, A, kTup): #calc the kernel or transform data to a higher dimensional space m,n = shape(X) K = mat(zeros((m,1))) if kTup[0]=='lin': K = X * A.T #linear kernel elif kTup[0]=='rbf': for j in range(m): deltaRow = X[j,:] - A K[j] = deltaRow*deltaRow.T K = exp(K/(-1*kTup[1]**2)) #divide in NumPy is element-wise not matrix like Matlab else: raise NameError('Houston We Have a Problem -- \ That Kernel is not recognized') return Kclass optStruct: def __init__(self,dataMatIn, classLabels, C, toler, kTup): # Initialize the structure with the parameters self.X = dataMatIn self.labelMat = classLabels self.C = C self.tol = toler self.m = shape(dataMatIn)[0] self.alphas = mat(zeros((self.m,1))) self.b = 0 self.eCache = mat(zeros((self.m,2))) #first column is valid flag self.K = mat(zeros((self.m,self.m))) for i in range(self.m): self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def innerL(i, oS, istraces=False): Ei = calcEk(oS, i) if ((oS.labelMat[i]*Ei &lt; -oS.tol) and (oS.alphas[i] &lt; oS.C)) or ((oS.labelMat[i]*Ei &gt; oS.tol) and (oS.alphas[i] &gt; 0)): j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy(); if (oS.labelMat[i] != oS.labelMat[j]): L = max(0, oS.alphas[j] - oS.alphas[i]) H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i]) else: L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C) H = min(oS.C, oS.alphas[j] + oS.alphas[i]) if L==H: if istraces: print("L==H") return 0 eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #changed for kernel if eta &gt;= 0: if istraces: print("eta&gt;=0") return 0 oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta oS.alphas[j] = clipAlpha(oS.alphas[j],H,L) updateEk(oS, j) # added this for the Ecache if (abs(oS.alphas[j] - alphaJold) &lt; 0.00001): if istraces: print("j not moving enough") return 0 oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j updateEk(oS, i) #added this for the Ecache #the update is in the oppostie direction b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j] b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j] if (0 &lt; oS.alphas[i]) and (oS.C &gt; oS.alphas[i]): oS.b = b1 elif (0 &lt; oS.alphas[j]) and (oS.C &gt; oS.alphas[j]): oS.b = b2 else: oS.b = (b1 + b2)/2.0 return 1 else: return 0 1234def calcEk(oS, k): fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b) Ek = fXk - float(oS.labelMat[k]) return Ek 123456789101112131415161718192021222324def testRbf(k1=1.3): dataArr,labelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch06/testSetRBF.txt') b,alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', k1)) #C=200 important datMat=mat(dataArr); labelMat = mat(labelArr).transpose() svInd=nonzero(alphas.A&gt;0)[0] sVs=datMat[svInd] #get matrix of only support vectors labelSV = labelMat[svInd]; print("there are %d Support Vectors" % shape(sVs)[0]) m,n = shape(datMat) errorCount = 0 for i in range(m): kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1)) predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b if sign(predict)!=sign(labelArr[i]): errorCount += 1 print("the training error rate is: %f" % (float(errorCount)/m)) dataArr,labelArr = loadDataSet('MLiA_SourceCode/machinelearninginaction/Ch06/testSetRBF2.txt') errorCount = 0 datMat=mat(dataArr); labelMat = mat(labelArr).transpose() m,n = shape(datMat) for i in range(m): kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1)) predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b if sign(predict)!=sign(labelArr[i]): errorCount += 1 print("the test error rate is: %f" % (float(errorCount)/m)) Âú®ÊµãËØï‰∏≠‰ΩøÁî®Ê†∏ÂáΩÊï∞Áî®Âä†ÂÖ•‰∫ÜÊ†∏ÂáΩÊï∞ÁöÑÁÆóÊ≥ïÂÜçÊ¨°ËÆ≠ÁªÉ 1testRbf() fullSet, iter: 0 i:0, pairs changed 1 fullSet, iter: 0 i:1, pairs changed 1 ... ... fullSet, iter: 6 i:99, pairs changed 0 iteration number: 7 there are 29 Support Vectors the training error rate is: 0.070000 the test error rate is: 0.050000 1testRbf(0.1) fullSet, iter: 0 i:0, pairs changed 1 fullSet, iter: 0 i:1, pairs changed 2 ... ... iteration number: 7 there are 89 Support Vectors the training error rate is: 0.000000 the test error rate is: 0.070000 ÂΩìk1=0.1Êó∂ÂÄôÔºåÊîØÊåÅÂêëÈáè‰∏∫89‰∏™Ôºåk1=1.3ÁöÑÊó∂ÂÄôÊó∂29‰∏™ÔºåÂΩìÂáèÂ∞èœÉÔºåËÆ≠ÁªÉÈîôËØØÁéáÂ∞±‰ºöÈôç‰ΩéÔºå‰ΩÜÊµãËØïÈîôËØØÁéáÂ∞±‰ºö‰∏äÂçá„ÄÇ ÊîØÊåÅÂêëÈáèÁöÑÊï∞ÁõÆÂ≠òÂú®‰∏Ä‰∏™ÊúÄ‰ºòÂÄº„ÄÇSVMÁöÑ‰ºòÁÇπÂú®‰∫éÂÆÉËÉΩÂØπÊï∞ÊçÆËøõË°åÈ´òÊïàÂàÜÁ±ª„ÄÇÂ¶ÇÊûúÊîØÊåÅÂêëÈáèÂ§™Â∞ëÔºåÂ∞±ÂèØËÉΩ‰ºöÂæóÂà∞‰∏Ä‰∏™ÂæàÂ∑ÆÁöÑÂÜ≥Á≠ñËæπÁïåÔºõÂ¶ÇÊûúÊîØÊåÅÂêëÈáèÂ§™Â§öÔºå‰πüÂ∞±Áõ∏ÂΩì‰∫éÊØèÊ¨°ÈÉΩÂà©Áî®Êï¥‰∏™Êï∞ÊçÆÈõÜËøõË°åÂàÜÁ±ªÔºåËøôÁßçÂàÜÁ±ªÊ≥ïÂèëÁß∞‰∏∫KËøëÈÇª„ÄÇ ÂÆû‰æãÔºöÊâãÂÜôËØÜÂà´ÈóÆÈ¢òÂõûÈ°æÂü∫‰∫éSVMÁöÑÊï∞Â≠óËØÜÂà´ Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÂü∫‰∫é‰∫åÂÄºÂõæÂÉèÊûÑÈÄ†ÂêëÈáè ÂàÜÊûêÊï∞ÊçÆÔºöÂØπÂõæÂÉèÂêëÈáèËøõË°åÁõÆÊµã ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÈááÁî®‰∏§Áßç‰∏çÂêåÁöÑÊ†∏ÂáΩÊï∞ÔºåÂπ∂ÂØπÂæÑÂêëÔºàradial directionÔºâÂü∫Ê†∏ÂáΩÊï∞ÈááÁî®‰∏çÂêåÁöÑËÆæÁΩÆÊù•ËøêË°åSMOÁÆóÊ≥ï ÊµãËØïÁÆóÊ≥ïÔºöÁºñÂÜô‰∏Ä‰∏™ÂáΩÊï∞Êù•ÊµãËØï‰∏çÂêåÁöÑÊ†∏ÂáΩÊï∞Âπ∂ËÆ°ÁÆóÈîôËØØÁéá ‰ΩøÁî®ÁÆóÊ≥ï È¶ñÂÖàÊääÁ¨¨‰∫åÁ´†ÁöÑimg2vector()ÂáΩÊï∞Â§çÂà∂ËøáÊù•„ÄÇ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def img2vector(filename): returnVect = zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVectdef loadImages(dirName): from os import listdir hwLabels = [] trainingFileList = listdir(dirName) # load the training set m = len(trainingFileList) trainingMat = zeros((m,1024)) for i in range(m): fileNameStr = trainingFileList[i] fileStr = fileNameStr.split('.')[0] # take off .txt classNumStr = int(fileStr.split('_')[0]) if classNumStr == 9: hwLabels.append(-1) else: hwLabels.append(1) trainingMat[i,:] = img2vector('%s/%s' % (dirName, fileNameStr)) return trainingMat, hwLabelsdef testDigits(kTup=('rbf', 10), istrances=False): dataArr,labelArr = loadImages('MLiA_SourceCode/machinelearninginaction/Ch06/digits/trainingDigits') b,alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, kTup, istrances) datMat=mat(dataArr) labelMat = mat(labelArr).transpose() svInd=nonzero(alphas.A&gt;0)[0] sVs=datMat[svInd] labelSV = labelMat[svInd]; print("there are %d Support Vectors" % shape(sVs)[0]) supportVectors = shape(sVs)[0] m,n = shape(datMat) errorCount = 0 for i in range(m): kernelEval = kernelTrans(sVs,datMat[i,:],kTup) predict = kernelEval.T * multiply(labelSV,alphas[svInd]) + b if sign(predict) != sign(labelArr[i]): errorCount += 1 trainErrorRate = float(errorCount)/m print("the training error rate is: %f" % (float(errorCount)/m)) dataArr,labelArr = loadImages('MLiA_SourceCode/machinelearninginaction/Ch06/digits/testDigits') errorCount = 0 datMat=mat(dataArr) labelMat = mat(labelArr).transpose() m,n = shape(datMat) for i in range(m): kernelEval = kernelTrans(sVs,datMat[i,:],kTup) predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b if sign(predict) != sign(labelArr[i]): errorCount += 1 print("the test error rate is: %f" % (float(errorCount)/m)) testErrorTate = float(errorCount)/m return trainErrorRate, testErrorTate, supportVectors Â∞ùËØï‰∏çÂêåÁöÑÂèÇÊï∞ÂíåÁ∫øÊÄßÊ†∏ÂáΩÊï∞Êù•Â≠¶‰π†Ôºö 123456789101112131415parameters = [['rbf', 0.1], ['rbf', 5], ['rbf', 10], ['rbf', 50], ['rbf', 100], ['lin', 0]]trainErrorRate = []testErrorTate = []supportVectors = []for i, j in parameters: result = testDigits(kTup=(i, j)) trainErrorRate.append(result[0]) testErrorTate.append(result[1]) supportVectors.append(result[2]) iteration number: 1 iteration number: 2 iteration number: 3 ... ... iteration number: 9 there are 39 Support Vectors the training error rate is: 0.000000 the test error rate is: 0.021505 123print("ÂÜÖÊ†∏,ËÆæÁΩÆ\tËÆ≠ÁªÉÈîôËØØÁéá\tÊµãËØïÈîôËØØÁéá\tÊîØÊåÅÂêëÈáèÊï∞")for i in range(len(parameters)): print("%s,%.1f \t%.4f \t\t%.4f \t\t%d" %(parameters[i][0], parameters[i][1], trainErrorRate[i], testErrorTate[i], supportVectors[i])) ÂÜÖÊ†∏,ËÆæÁΩÆ ËÆ≠ÁªÉÈîôËØØÁéá ÊµãËØïÈîôËØØÁéá ÊîØÊåÅÂêëÈáèÊï∞ rbf,0.1 0.0000 0.5215 402 rbf,5.0 0.0000 0.0323 402 rbf,10.0 0.0000 0.0054 132 rbf,50.0 0.0149 0.0269 31 rbf,100.0 0.0050 0.0108 34 lin,0.0 0.0000 0.0215 39 ËßÇÂØüÂèëÁé∞ÔºåÊúÄÂ∞èÁöÑËÆ≠ÁªÉÈîôËØØÁéáÂπ∂‰∏çÂØπÂ∫îÊúÄÂ∞èÁöÑÊîØÊåÅÂêëÈáèÊï∞ÔºåÁ∫øÊÄßÊ†∏ÂáΩÊï∞ÁöÑÊïàÊûúÂπ∂‰∏çÊòØÁâπÂà´Á≥üÁ≥ï„ÄÇÂèØ‰ª•Áâ∫Áâ≤Á∫øÊÄßÊ†∏ÂáΩÊï∞ÁöÑÈîôËØØÁéáÊù•Êç¢ÂèñÂàÜÁ±ªÈÄüÂ∫¶ÁöÑÊèêÈ´ò„ÄÇ ÊÄªÁªìÊîØÊåÅÂêëÈáèÊú∫Êó∂‰∏ÄÁßçÂàÜÁ±ªÂô®Ôºå‰πãÊâÄ‰ª•Áß∞‰∏∫‚ÄúÊú∫‚ÄùÊó∂Âõ†‰∏∫ÂÆÉ‰ºö‰∫ßÁîü‰∏Ä‰∏™‰∫åÂÄºÂÜ≥Á≠ñÁªìÊûúÔºåÂç≥ÂÆÉÊòØ‰∏ÄÁßçÂÜ≥Á≠ñ‚ÄúÊú∫‚ÄùÔºåÊîØÊåÅÂêëÈáèÊú∫ÁöÑÊ≥õÂåñÈîôËØØÁéáËæÉ‰ΩéÔºå‰πüÂ∞±ÊòØËØ¥ÂÆÉÂÖ∑ÊúâËâØÂ•ΩÁöÑÂ≠¶‰π†ËÉΩÂäõÔºåÂπ∂‰∏îÂ≠¶Âà∞ÁöÑÁªìÊûúÂÖ∑ÊúâÂæàÂ•ΩÁöÑÊé®ÂπøÊÄß„ÄÇ Ê†∏ÂáΩÊï∞‰ªé‰∏Ä‰∏™‰ΩéÁ∫¨Á©∫Èó¥Êò†Â∞ÑÂà∞‰∏Ä‰∏™È´òÁ∫¨Á©∫Èó¥ÔºåÂèØ‰ª•Â∞Ü‰∏Ä‰∏™‰ΩéÁª¥Á©∫Èó¥‰∏≠ÁöÑÈùûÁ∫øÊÄßÈóÆÈ¢òËΩ¨Êç¢‰∏∫È´òÁ∫¨Â∫¶Á©∫Èó¥‰∏ãÁöÑÁ∫øÊÄßÈóÆÈ¢òÊù•Ê±ÇËß£„ÄÇ ÊîØÊåÅÂêëÈáèÊú∫ÊòØ‰∏Ä‰∏™‰∫åÂàÜÁ±ªÂô®„ÄÇÂΩìËß£ÂÜ≥Â§öÂàÜÁ±ªÈóÆÈ¢òÊó∂ÔºåÂàôÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÊñπÊ≥ïÂØπÂÖ∂ËøõË°åÊâ©Â±ïÔºåSVMÁöÑÊïàÊûú‰πüÂØπ‰ºòÂåñÂèÇÊï∞ÂíåÊâÄÁî®Ê†∏ÂáΩÊï∞‰∏≠ÁöÑÂèÇÊï∞ÊïèÊÑü„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>SMO</tag>
        <tag>ÊîØÊåÅÂêëÈáèÊú∫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∫îÔºâ]]></title>
    <url>%2F2020%2F04%2F01%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[LogisticÂõûÂΩíÊòØ‰∏Ä‰∏™ÊúÄ‰ºòÂåñÁÆóÊ≥ïÔºåÊØîÂ¶ÇÂ¶Ç‰ΩïÂú®ÊúÄÁü≠Êó∂Èó¥‰ªéAÁÇπÂà∞ËææBÁÇπÔºü ÂõûÂΩíÔºöÂÅáËÆæÊàë‰ª¨Êúâ‰∏Ä‰∫õÊï∞ÊçÆÁÇπÔºåÊàë‰ª¨Áî®‰∏ÄÊù°Áõ¥Á∫øÂØπËøô‰∫õÁÇπËøõË°åÊãüÂêàÔºàËØ•Á∫øÁß∞‰∏∫ÊúÄ‰Ω≥ÊãüÂêàÁõ¥Á∫øÔºâÔºåËøô‰∏™ÊãüÂêàËøáÁ®ãÂ∞±Âè´ÂÅöÂõûÂΩí„ÄÇ Ê†πÊçÆÁé∞ÊúâÁöÑÊï∞ÊçÆÂØπÂàÜÁ±ªËæπÁïåÁ∫øÂª∫Á´ãÂõûÂΩíÂÖ¨ÂºèÔºå‰æùÊ¨°ËøõË°åÂàÜÁ±ª„ÄÇËøôÈáåÁöÑ‚ÄúÂõûÂΩí‚Äù‰∏ÄÊ¨°Ê∫ê‰∫éÊúÄ‰Ω≥ÊãüÂêàÔºåË°®Á§∫Ë¶ÅÊâæÂà∞ÊúÄ‰Ω≥ÊãüÂêàÂèÇÊï∞ÈõÜ„ÄÇ LogisticÂõûÂΩíÁöÑ‰∏ÄËà¨ËøáÁ®ãÔºö Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÁî±‰∫éÈúÄË¶ÅËøõË°åË∑ùÁ¶ªËÆ°ÁÆóÔºåÂõ†Ê≠§Êï∞ÊçÆÁ±ªÂûãÂøÖÈ°ª‰∏∫Êï∞ÂÄºÂûãÔºåÂè¶Â§ñÁªìÊûÑÂåñÊï∞ÊçÆÊ†ºÂºèÊúÄ‰Ω≥ ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÂ§ßÈÉ®ÂàÜÊó∂Èó¥Â∞ÜÁî®‰∫éËÆ≠ÁªÉÔºåËÆ≠ÁªÉÁöÑÁõÆÁöÑÊòØ‰∏∫‰∫ÜÊâæÂà∞ÊúÄ‰Ω≥ÁöÑÂàÜÁ±ªÂõûÂΩíÁ≥ªÊï∞ ÊµãËØïÁÆóÊ≥ï ‰ΩøÁî®ÁÆóÊ≥ïÔºöÈ¶ñÂÖàÔºåÈúÄË¶ÅËæìÂÖ•‰∏Ä‰∫õÊï∞ÊçÆÔºåÂπ∂Â∞ÜÂÖ∂ËΩ¨Êç¢ÊàêÂØπÂ∫îÁöÑÁªìÊûÑÂåñÊï∞ÂÄºÔºõÊé•ÁùÄÔºåÂü∫‰∫éËÆ≠ÁªÉÂ•ΩÁöÑÂõûÂΩíÁ≥ªÊï∞Â∞±ÂèØ‰ª•ÂØπËøô‰∫õÊï∞ÂÄºËøõË°åÁÆÄÂçïÁöÑÂõûÂΩíËÆ°ÁÆóÔºåÂà§ÂÆöÂÆÉ‰ª¨Â±û‰∫éÂì™‰∏™Á±ªÂà´ÔºõÂú®Ëøô‰πãÂêéÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•Âú®ËæìÂá∫ÁöÑÁ±ªÂà´‰∏äÂÅö‰∏Ä‰∫õÂÖ∂‰ªñÂàÜÊûêÂ∑•‰Ωú Âü∫‰∫éLogisticÂõûÂΩíÂíåSigmoidÂáΩÊï∞ÁöÑÂàÜÁ±ªlogisticÂõûÂΩí ‰ºòÁÇπÔºöËÆ°ÁÆó‰ª£‰ª∑‰∏çÈ´òÔºåÊòì‰∫éÁêÜËß£ÂíåÂÆûÁé∞ Áº∫ÁÇπÔºöÂÆπÊòìÊ¨†ÊãüÂêàÔºåÂàÜÁ±ªÁ≤æÂ∫¶ÂèØËÉΩ‰∏çÈ´ò ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞ÂûãÊï∞ÊçÆ È¶ñÂÖàÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™Èò∂Ë∑ÉÂáΩÊï∞Ôºàstep functionÔºâÔºåSigmoidÂáΩÊï∞ÔºåÂÆÉÁöÑÂÄºÂüüÂú®0-1‰πãÈó¥Ôºö $$\sigma(z)=\frac{1}{1+e^{-z}}$$ ‰∏ãÂõæÁªôÂá∫‰∫ÜsigmoidÂáΩÊï∞Âú®‰∏çÂêåÂùêÊ†áÂ∞∫Â∫¶‰∏ãÁöÑ‰∏§Êù°Êõ≤Á∫øÂõæ„ÄÇ ‰∏∫‰∫ÜÂÆûÁé∞logisticÂõûÂΩíÂàÜÁ±ªÂô®ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®ÊØè‰∏™ÁâπÂæÅ‰∏äÈÉΩ‰πò‰ª•‰∏Ä‰∏™ÂõûÂΩíÁ≥ªÊï∞ÔºåÁÑ∂ÂêéÊääÊâÄÊúâÁöÑÁªìÊûúÂÄºÁõ∏Âä†ÔºåÂ∞ÜËøô‰∏™ÊÄªÂíåÂ∏¶ÂÖ•sigmoidÂáΩÊï∞‰∏≠ÔºåËøõËÄåÂæóÂà∞‰∏Ä‰∏™ËåÉÂõ¥Âú®0~1‰πãÈó¥ÁöÑÊï∞ÂÄºÔºå‰ªª‰ΩïÂ§ß‰∫é0.5ÁöÑÊï∞ÊçÆË¢´ÂàÜÂÖ•1Á±ªÔºåÂ∞è‰∫é0.5ÁöÑÂç≥Ë¢´ÂΩí‰∏∫0Á±ªÔºåÊâÄ‰ª•logisticÂõûÂΩí‰πüÂèØ‰ª•Ë¢´ÁúãÊàê‰∏ÄÁßçÊ¶ÇÁéá‰º∞ËÆ°„ÄÇ ‰∏§ÁßçÂùêÊ†áÂ∞∫Â∫¶‰∏ãÁöÑsigmoidÂáΩÊï∞ÂõæÔºå‰∏äÂõæÁöÑÊ®™ÂùêÊ†á‰∏∫-5~5ÔºåËøôÊó∂Êõ≤Á∫øÂèòÂåñËæÉ‰∏∫Âπ≥Êªë. Âü∫‰∫éÊúÄ‰ºòÂåñÊñπÊ≥ïÁöÑÊúÄ‰Ω≥ÂõûÂΩíÁ≥ªÊï∞Á°ÆÂÆösigmoidÂáΩÊï∞ÁöÑËæìÂÖ•ËÆ∞‰∏∫zÔºåÁî±‰∏ãÈù¢ÁöÑÂÖ¨ÂºèÂæóÂá∫Ôºö $$z=w_0x_0+w_1x_1+w_2x_2+‚Ä¶+w_nx_n$$ Â¶ÇÊûúÈááÁî®ÂêëÈáèÂÜôÊ≥ïÔºå‰∏äËø∞ÂÖ¨ÂºèÂèØ‰ª•ÂÜôÊàê$Z=W^TX$ÔºåÂÆÉË°®Á§∫Â∞ÜËøô‰∏§‰∏™Êï∞ÂÄºÂêëÈáèÂØπÂ∫îÂÖÉÁ¥†Áõ∏‰πòÁÑ∂ÂêéÂÖ®ÈÉ®Âä†Ëµ∑Êù•ÂæóÂà∞zÁöÑÂÄº„ÄÇÂÖ∂‰∏≠ÁöÑÂêëÈáèxÊòØÂàÜÁ±ªÂô®ËæìÂÖ•ÁöÑÊï∞ÊçÆÔºåÂêëÈáèwÊòØÊàë‰ª¨ÈúÄË¶ÅÊ±ÇÂæóÁöÑÊúÄ‰Ω≥Á≥ªÊï∞ÔºàweightÔºâ„ÄÇ Ê¢ØÂ∫¶‰∏äÂçáÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÁöÑÊÄùÊÉ≥ÊòØÔºöË¶ÅÊâæÂà∞ÊüêÂáΩÊï∞ÁöÑÊúÄÂ§ßÂÄºÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØÊ≤øÁùÄËØ•ÂáΩÊï∞ÁöÑÊ¢ØÂ∫¶ÊñπÂêëÊé¢ÂØª„ÄÇÂ¶ÇÊûúÊ¢ØÂ∫¶ËÆ∞‰∏∫$\nabla$ÔºåÂàôÂáΩÊï∞$f(x,y)$ÁöÑÊ¢ØÂ∫¶Áî±‰∏ãÂºèË°®Á§∫ Ëøô‰∏™Ê¢ØÂ∫¶ÊÑèÂë≥ÁùÄË¶ÅÊ≤øxÁöÑÊñπÂêëÁßªÂä® ÔºåÊ≤øyÁöÑÊñπÂêëÁßªÂä® ÔºåÂÖ∂‰∏≠$f(x,y)$ÂøÖÈ°ªË¶ÅÂú®ÂæÖËÆ°ÁÆóÁöÑÁÇπ‰∏äÁî±ÂÆö‰πâÂπ∂‰∏îÂèØÂæÆ„ÄÇ Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÂà∞ËææÊØè‰∏™ÁÇπÂêéÈÉΩ‰ºöÈáçÊñ∞‰º∞ËÆ°ÁßªÂä®ÊñπÂêë„ÄÇ‰ªéP0ÂºÄÂßãÔºåËÆ°ÁÆóÂÆåËØ•ÁÇπÁöÑÊ¢ØÂ∫¶ÔºåÂáΩÊï∞Â∞±Ê†πÊçÆÊ¢ØÂ∫¶ÁßªÂä®Âà∞‰∏ã‰∏ÄÁÇπP1ÔºåÂú®P1ÁÇπÔºåÊ¢ØÂ∫¶ÂÜçÊ¨°Ë¢´ÈáçÊñ∞ËÆ°ÁÆóÔºåÂπ∂‰∏îÊ≤øÊñ∞ÁöÑÊ¢ØÂ∫¶ÊñπÂêëÁßªÂä®Âà∞P2„ÄÇÂ¶ÇÊ≠§Âæ™ÁéØËø≠‰ª£ÔºåÁõ¥Âà∞Êª°Ë∂≥ÂÅúÊ≠¢Êù°‰ª∂„ÄÇËø≠‰ª£ÁöÑËøáÁ®ã‰∏≠ÔºåÊ¢ØÂ∫¶ÁÆóÂ≠êÊÄªËÉΩ‰øùËØÅÊàë‰ª¨ÈÄâÂèñÂà∞ÊúÄ‰Ω≥ÁöÑÁßªÂä®ÊñπÂêë„ÄÇ Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÊ≤øÊ¢ØÂ∫¶ÊñπÂêëÁßªÂä®‰∫Ü‰∏ÄÊ≠•ÔºåÂèØ‰ª•ÁúãÂà∞ÔºåÊ¢ØÂ∫¶ÁÆóÂ≠êÊÄªÊòØÊåáÂêëÂáΩÊï∞Â¢ûÈïøÊúÄÂø´ÁöÑÊñπÂêëÔºåËøôÈáåÊâÄËØ¥ÁöÑÊòØÁßªÂä®ÊñπÂêëÔºåËÄåÊú™ÊèêÂà∞ÁßªÂä®ÈáèÁöÑÂ§ßÂ∞èÔºåËØ•ÈáèÂÄºÁß∞‰∏∫Ê≠•ÈïøÔºåËÆ∞‰Ωú$\alpha$ÔºåÁî®ÂêëÈáèË°®Á§∫ÁöÑËØùÔºåÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÁöÑËø≠‰ª£ÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö $$w := w+\alpha\nabla_wf(W)$$ ËØ•ÂÖ¨ÂºèÂ∞Ü‰∏ÄÁõ¥Ë¢´Ëø≠‰ª£ÊâßË°åÔºåÁõ¥Âà∞ËææÂà∞Êüê‰∏™ÂÅúÊ≠¢Êù°‰ª∂‰∏∫Ê≠¢„ÄÇ 12Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÁªèÂ∏∏Âê¨Âà∞ÁöÑÂ∫îËØ•ÊòØÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÔºå‰ªñ‰∏éËøôÈáåÁöÑÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÊòØ‰∏ÄÊ†∑ÁöÑÔºåÂè™ÊòØÂÖ¨Âºè‰∏≠ÁöÑÂä†Ê≥ïÈúÄË¶ÅÂèòÊàêÂáèÊ≥ïÔºåÂõ†Ê≠§ÂØπÂ∫îÂÖ¨ÂºèÂèØ‰ª•ÂÜôÊàê $$w := w-\alpha\nabla_wf(W)$$1Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÁî®Êù•Ê±ÇÂáΩÊï∞ÁöÑÊúÄÂ§ßÂÄºÔºåËÄåÊ¢ØÂ∫¶‰∏ãÈôçÁî®Êù•Ê±ÇÂáΩÊï∞ÁöÑÊúÄÂ∞èÂÄº Êé•‰∏ãÊù•Êàë‰ª¨Â∞ÜÂØπ‰∏ãÈù¢ÁöÑÊï∞ÊçÆÈõÜ‰ΩøÁî®Ê¢ØÂ∫¶‰∏äÂçáÁöÑÁÆóÊ≥ïÊù•ËøõË°åÂàÜÁ±ªÔºåÊ±ÇÂá∫ÊúÄ‰Ω≥ÂõûÂΩíÁ≥ªÊï∞„ÄÇ ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰ΩøÁî®Ê¢ØÂ∫¶‰∏äÂçáÊâæÂà∞ÊúÄ‰Ω≥ÂèÇÊï∞‰∏äÂõæÊúâ100‰∏™Ê†∑Êú¨ÁÇπÔºåÊØè‰∏™ÁÇπÂåÖÂê´‰∏§‰∏™Êï∞ÂÄºÂûãÁâπÂæÅX1ÂíåX2„ÄÇÂú®Ê≠§Êï∞ÊçÆÈõÜ‰∏äÔºåÊàë‰ª¨Â∞ÜÈÄöËøá‰ΩøÁî®Ê¢ØÂ∫¶‰∏äÂçáÊ≥ïÊâæÂà∞ÊúÄ‰Ω≥ÂõûÂΩíÁ≥ªÊï∞Ôºå‰πüÂ∞±ÊòØÊãüÂêàÂá∫logisticÂõûÂΩíÊ®°ÂûãÁöÑÊúÄ‰Ω≥ÂèÇÊï∞„ÄÇ ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö ÊØè‰∏™ÂõûÂΩíÁ≥ªÊï∞ÂàùÂßãÂåñ‰∏∫1 ÈáçÂ§çRÊ¨°Ôºö ËÆ°ÁÆóÊï¥‰∏™Êï∞ÊçÆÈõÜÁöÑÊ¢ØÂ∫¶ ‰ΩøÁî®alpha √ó gradientÊõ¥Êñ∞ÂõûÂΩíÁ≥ªÊï∞ÁöÑÂêëÈáè ËøîÂõûÂõûÂΩíÁ≥ªÊï∞ logisticÂõûÂΩíÊ¢ØÂ∫¶‰∏äÂçá‰ºòÂåñÁÆóÊ≥ï 123456789def loadDataSet(): dataMat = [] labelMat = [] fr = open('MLiA_SourceCode/machinelearninginaction/Ch05/testSet.txt') for line in fr.readlines(): lineArr = line.strip().split() dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])]) labelMat.append(int(lineArr[2])) return dataMat, labelMat 1dataArr, labelMat = loadDataSet() loadDataSet()ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÊâìÂºÄtestSet.txtÊñá‰ª∂ÔºåÈÄêË°åËØªÂèñÔºåÊØèË°åÁöÑÂâç‰∏§‰∏™ÂÄºÊòØX1ÂíåX2ÔºåÁ¨¨‰∏â‰∏™ÂÄºÊòØÂØπÂ∫îÁöÑÁ±ªÂà´Ê†áÁ≠æÔºå‰∏∫‰∫ÜÊñπ‰æøËÆ°ÁÆóÂ∞ÜX0ËÆæÁΩÆ‰∏∫1.0 ‰∏ãÈù¢ÊòØsigmoidÂáΩÊï∞: 12def sigmoid(inX): return 1.0/(1+exp(-inX)) 1234567891011121314151617from tqdm import trangefrom numpy import *def gradAscent(dataMat, classLabels): # ËΩ¨Êç¢‰∏∫numpyÁü©ÈòµÁöÑÊï∞ÊçÆÁ±ªÂûã dataMatrix = mat(dataMat) labelMat = mat(classLabels).transpose() # ËΩ¨ÁΩÆ m, n = shape(dataMatrix) alpha = 0.001 # Ê≠•Èïø maxCycles = 500 # Ëø≠‰ª£Ê¨°Êï∞ weights = ones((n, 1)) for k in trange(maxCycles): h = sigmoid(dataMatrix * weights) error = (labelMat-h) weights = weights + alpha * dataMatrix.transpose() * error return weights gradAscent()ÂáΩÊï∞Áî®Êù•ÂÆåÊàêÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÁöÑÂÆûÁé∞„ÄÇ 12weights = gradAscent(dataArr, labelMat)weights 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00&lt;00:00, 15757.40it/s] matrix([[ 4.12414349], [ 0.48007329], [-0.6168482 ]]) ÂàÜÊûêÊï∞ÊçÆÔºöÁîªÂá∫ÂÜ≥Á≠ñËæπÁïå‰∏äÈù¢Â∑≤ÁªèËß£Âá∫‰∏ÄÁªÑÂõûÂΩíÁ≥ªÊï∞ÔºåÊé•‰∏ãÊù•ÁîªÂá∫ÂàÜÂâ≤Á∫ø„ÄÇ 123456789101112131415161718192021222324252627282930import matplotlib.pyplot as pltplt.rcParams['axes.unicode_minus']=False #Áî®Êù•Ê≠£Â∏∏ÊòæÁ§∫Ë¥üÂè∑def plotBestFit(weights): dataMat, labelMat = loadDataSet() dataArr = array(dataMat) n = shape(dataArr)[0] xcord1 = [] ycord1 = [] xcord2 = [] ycord2 = [] for i in range(n): if int(labelMat[i]) == 1: xcord1.append(dataArr[i, 1]) ycord1.append(dataArr[i, 2]) else: xcord2.append(dataArr[i, 1]) ycord2.append(dataArr[i, 2]) fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(xcord1, ycord1, s=30, c='red', marker='s') ax.scatter(xcord2, ycord2, s=30, c='green') x = arange(-3.0, 3.0, 0.1) y = (-weights[0]-weights[1]*x)/weights[2] ax.plot(x, y.T) # yËΩ¨ÁΩÆÊòØ‰∏∫‰∫ÜxyÁü©ÈòµÁªìÊûÑÁõ∏Âêåx.shape(60,) y.T.shape(60, 1) plt.xlabel('X1') plt.ylabel('X2') plt.show() Êàë‰ª¨ËÆæÂÆö$0=w_0x_0+w_1x_1+w_2x_2$ÔºåÁÑ∂ÂêéÁî®Ëß£Âá∫X1ÂíåX2ÁöÑÂÖ≥Á≥ªÂºèÔºàÂÖ∂‰∏≠X0=1ÔºâÔºåÁîªÂá∫Á∫øÊÆµ 1plotBestFit(weights) Ëøô‰∏™ÂàÜÁ±ªÁªìÊûúÁõ∏ÂΩì‰∏çÈîôÔºåÁúãÂõæÂèØÁü•Âè™ÂàÜÈîô‰∫Ü‰∏§‰∏™ÁÇπ„ÄÇ ËÆ≠ÁªÉÁÆóÊ≥ïÔºöÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÊØèÊ¨°Ëø≠‰ª£ÈÉΩÈúÄË¶ÅÈÅçÂéÜÊï¥‰∏™Êï∞ÊçÆÈõÜÔºåÂ¶ÇÊûúÊúâÂçÅ‰∫øÊ†∑Êú¨Âíå‰∏äÂçÉ‰∏áÁâπÂæÅÔºåÈÇ£‰πàÊîπÊñπÊ≥ïÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶Â∞±Â§™È´ò‰∫ÜÔºå‰∏ÄÁßçÊîπËøõÊñπÊ≥ïÊòØ‰∏ÄÊ¨°‰ªÖÁî®‰∏Ä‰∏™Ê†∑Êú¨Êù•Êõ¥Êñ∞ÂõûÂΩíÁ≥ªÊï∞ÔºåËØ•ÊñπÊ≥ïÁß∞‰∏∫ÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ï„ÄÇÁî±‰∫éÂèØ‰ª•Âú®Êñ∞Ê†∑Êú¨Âà∞Êù•Êó∂ÂØπÂàÜÁ±ªÂô®ËøõË°åÂ¢ûÈáèÂºèÊõ¥Êñ∞ÔºåÂõ†ËÄåÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÊòØ‰∏Ä‰∏™Âú®Á∫øÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇ‰∏éÂú®Á∫øÂ≠¶‰π†Áõ∏ÂØπÂ∫îÔºå‰∏ÄÊ¨°Â§ÑÁêÜÊâÄÊúâÊï∞ÊçÆË¢´Áß∞‰ΩúÊòØ‚ÄúÊâπÂ§ÑÁêÜ‚Äù„ÄÇ ÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÂèØ‰ª•ÂÜôÊàêÂ¶Ç‰∏ãÁöÑ‰º™‰ª£Á†ÅÔºö ÊâÄÊúâÂõûÂΩíÁ≥ªÊï∞ÂàùÂßãÂåñ‰∏∫1 ÂØπÊï∞ÊçÆÈõÜ‰∏≠ÊØè‰∏™Ê†∑Êú¨ ËÆ°ÁÆóËØ•Ê†∑Êú¨ÁöÑÊ¢ØÂ∫¶ ‰ΩøÁî®alpha√ógradientÊõ¥Êñ∞ÂõûÂΩíÁ≥ªÊï∞ ÁÑ∂‰ºöÂõûÂΩíÁ≥ªÊï∞ 123456789def stocGradAscent0(dataMatrix, classLabels): m, n = shape(dataMatrix) alpha = 0.01 weights = ones(n) for i in range(m): h = sigmoid(sum(dataMatrix[i]*weights)) error = classLabels[i] - h weights = weights + alpha * error * dataMatrix[i] return weights ÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÂíåÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ï‰ª£Á†ÅÂæàÁõ∏‰ººÔºåÊúâ‰∏§ÁÇπÂå∫Âà´ÔºåÁ¨¨‰∏ÄÔºåÂêéËÄÖÁöÑÂèòÈáèhÂíåerrorÈÉΩÊòØÂêëÈáèÔºåÂâçËÄÖÂÖ®ÊòØÊï∞ÂÄºÔºõÁ¨¨‰∫åÔºåÂâçËÄÖÊ≤°ÊúâÁü©ÈòµËΩ¨ÁΩÆËøáÁ®ãÔºåÊâÄÊúâÂèòÈáèÁöÑÊï∞ÊçÆÁ±ªÂûãÈÉΩÊòØnumpyÊï∞ÁªÑ„ÄÇ 12weights = stocGradAscent0(array(dataArr), labelMat)plotBestFit(weights) ËßÇÂØü‰∏äÂõæÂèëÁé∞Êúâ‰∫õÊ¨†ÊãüÂêàÔºåÊ¢ØÂ∫¶‰∏äÂçáÁöÑÁÆóÊ≥ïËø≠‰ª£‰∫Ü500Ê¨°ÔºåËÄåËøô‰∏™ÁªìÊûúÂè™Ëø≠‰ª£‰∫Ü200Ê¨°ÔºåÊâÄ‰ª•ËøòÁÆó‰∏çÈîô‰∫Ü„ÄÇ ‰∏ãÂõæÂ±ïÁ§∫‰∫ÜÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÂú®‰∫åÁôæÊ¨°Ëø≠‰ª£ËøáÁ®ã‰∏≠ÂõûÂΩíÁ≥ªÊï∞ÁöÑÂèòÊç¢ÊÉÖÂÜµ„ÄÇ 1%run MLiA_SourceCode/machinelearninginaction/Ch05/plotSDerror.py Âíå‰π¶‰∏äÁîªÁöÑ‰∏ç‰∏ÄÊ†∑ÔºåÁï•Ëøá„ÄÇ ÊîπËøõÁöÑÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ï123456789101112131415def stocGradAscent1(dataMatrix, classLabels, numIter=150): m, n = shape(dataMatrix) weights = ones(n) for j in range(numIter): dataIndex = list(range(m)) for i in range(m): # 1.alphaÊØèÊ¨°Ëø≠‰ª£ÈúÄË¶ÅË∞ÉÊï¥ alpha = 4 / (1.0 + j + i) + 0.0001 # 2.ÈöèÊú∫ÈÄâÂèñÊõ¥Êñ∞ randIndex = int(random.uniform(0, len(dataIndex))) h = sigmoid(sum(dataMatrix[randIndex]*weights)) error = classLabels[randIndex] - h weights = weights + alpha * error * dataMatrix[randIndex] del(dataIndex[randIndex]) return weights ‰∏äÈù¢ÁöÑÁ®ãÂ∫èÊîπËøõÊúâ‰∏§Â§ÑÔºå1Â§ÑÊîπËøõ‰ºöÁºìËß£Êï∞ÊçÆÊ≥¢Âä®ÊàñÈ´òÈ¢ëÊ≥¢Âä®ÔºåËôΩÁÑ∂alpha‰ºöÈöèËø≠‰ª£Ê¨°Êï∞‰∏çÊñ≠ÂáèÂ∞èÔºå‰ΩÜÊ∞∏Ëøú‰∏ç‰ºöÂáèÂ∞èÂà∞0ÔºåËøôÊ†∑ÂÅöÁöÑÂéüÂõ†ÊòØ‰øùËØÅÂ§öÊ¨°Ëø≠‰ª£ÂêéÔºåÊñ∞Êï∞ÊçÆ‰ªªÁÑ∂ÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÂΩ±Âìç„ÄÇ 2Â§ÑÊîπËøõÈÄöËøáÈöèÊú∫ÈÄâÂèñÊ†∑Êú¨Êù•Êõ¥Êñ∞ÂõûÂΩíÁ≥ªÊï∞ÔºåËøôÁßçÊñπÊ≥ïÂ∞ÜÂáèÂ∞èÂë®ÊúüÊ≥¢Âä®„ÄÇ ÊîπËøõÁÆóÊ≥ïËøòÂ¢ûÂä†‰∫ÜËø≠‰ª£Ê¨°Êï∞‰Ωú‰∏∫Á¨¨‰∏â‰∏™ÂèÇÊï∞„ÄÇ 1%run MLiA_SourceCode/machinelearninginaction/Ch05/plotSDerror.py ‰ΩøÁî®ÈöèÊú∫Ê†∑Êú¨ÈÄâÊã©ÂíåalphaÂä®ÊÄÅÂáèÂ∞ëÊú∫Âà∂ÁöÑÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïstocGradAscent1()ÊâÄÁîüÊàêÁöÑÁ≥ªÊï∞Êî∂ÊïõÁ§∫ÊÑèÂõæ„ÄÇËØ•ÊñπÊ≥ïÊØîÈááÁî®Âõ∫ÂÆöalphaÁöÑÊñπÊ≥ïÊî∂ÊïõÈÄüÂ∫¶Êõ¥Âø´„ÄÇ 12weights = stocGradAscent1(array(dataArr), labelMat)plotBestFit(weights) Á®ãÂ∫èÊâßË°åÁªìÊûú‰∏égradAscent()Â∑Æ‰∏çÂ§öÔºå‰ΩÜÊòØËÆ°ÁÆóÈáèÊõ¥Â∞ë„ÄÇ ÂÆû‰æãÔºö‰ªéÁñùÊ∞îÁóÖÁóáÈ¢ÑÊµãÈ©¨ÁöÑÊ≠ª‰∫°Áéá‰ΩøÁî®logisticÂõûÂΩíÈ¢ÑÊµãÊÇ£ÊúâÁñùÁóÖÁöÑÈ©¨ÁöÑÂ≠òÊ¥ªÈóÆÈ¢ò„ÄÇÊèê‰æõÁöÑÊï∞ÊçÆÊúâ368‰∏™Ê†∑Êú¨28‰∏™ÁâπÂæÅ„ÄÇ Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆÔºöÁî®pythonËß£ÊûêÊñáÊú¨Âπ∂Â°´ÂÖÖÁº∫Â§±ÂÄº ÂàÜÊûêÊï∞ÊçÆÔºöÂèØËßÜÂåñËßÇÂØüÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰ΩøÁî®‰ºòÂåñÁÆóÊ≥ïÔºåÊâæÂà∞ÊúÄ‰Ω≥Á≥ªÊï∞ ÊµãËØïÁÆóÊ≥ïÔºö‰∏∫‰∫ÜÈáèÂåñÂõûÂΩíÊïàÊûúÔºåÈúÄË¶ÅËßÇÂØüÈîôËØØÁéá„ÄÇÊ†πÊçÆÈîôËØØÁéáÂÜ≥ÂÆöÊòØÂê¶ÂõûÈÄÄÂà∞ËÆ≠ÁªÉÈò∂ÊÆµÔºåÈÄöËøáÊîπÂèòËø≠‰ª£ÁöÑÊ¨°Êï∞ÂíåÊ≠•ÈïøÁ≠âÂèÇÊï∞Êù•ÂæóÂà∞Êõ¥Â•ΩÁöÑÂõûÂΩíÁ≥ªÊï∞ ‰ΩøÁî®ÁÆóÊ≥ïÔºöÂÆûÁé∞ÁÆÄÂçïÁöÑÂëΩ‰ª§Á®ãÂ∫èÊù•Êî∂ÈõÜÈ©¨ÁöÑÁóÖÁóáÂπ∂ËæìÂá∫È¢ÑÊµãÁªìÊûú ÂáÜÂ§áÊï∞ÊçÆÔºöÂ§ÑÁêÜÊï∞ÊçÆ‰∏≠ÁöÑÁº∫Â§±ÂÄºÂΩìÊï∞ÊçÆÁº∫Â§±Êó∂ÔºåÂèØ‰ª•Áî®‰ª•‰∏ãÊñπÊ≥ïÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºö ‰ΩøÁî®ÂèØÁî®ÁâπÂæÅÁöÑÂùáÂÄºÊù•Â°´Ë°•Áº∫Â§±ÂÄº ‰ΩøÁî®ÁâπÊÆäÂÄºÊù•Â°´Ë°•Áº∫Â§±ÂÄºÔºåÂ¶Ç-1 ÂøΩÁï•ÊúâÁº∫Â§±ÂÄºÁöÑÊ†∑Êú¨ ‰ΩøÁî®Áõ∏‰ººÊ†∑Êú¨ÁöÑÂùáÂÄºÊù•Â°´Ë°•Áº∫Â§±ÂÄº ‰ΩøÁî®Âè¶Â§ñÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÈ¢ÑÊµãÁº∫Â§±ÂÄº Áé∞Âú®‰∏∫‰∫ÜÂèØ‰ª•‰ΩøÁî®ÁÆóÊ≥ïÔºåÊàë‰ª¨Ë¶ÅÂÅö‰∏§‰ª∂‰∫ã Á¨¨‰∏ÄÔºåÈÄâÊã©ÂÆûÊï∞0Êù•ÊõøÊç¢ÊâÄÊúâÁöÑÁº∫Â§±ÂÄºÔºå‰øÆÊîπÂõûÂΩíÁ≥ªÊï∞ÁöÑÊõ¥Êñ∞ÂÖ¨Âºè weights = weights + alpha √ó error √ó dataMatrix[randIndex] ËøôÊ†∑ÂÅöÊòØ‰∏∫‰∫ÜÂΩìrandIndexÂØπÂ∫îÁöÑÁâπÂæÅÂÄº‰∏∫0Êó∂ÔºåweightsÂ∞Ü‰∏ç‰ºöÊõ¥Êñ∞ Á¨¨‰∫åÔºåÂ¶ÇÊûúÂú®ÊµãËØïÊï∞ÊçÆÈõÜ‰∏≠ÂèëÁé∞‰∏ÄÊù°Êï∞ÊçÆÁöÑÁ±ªÂà´Ê†áÁ≠æÂ∑≤ÁªèÁº∫Â§±ÔºåÁÆÄÂçïÁöÑÂÅöÊ≥ïÊòØÂ∞ÜËØ•Êù°Êï∞ÊçÆ‰∏¢ÂºÉ„ÄÇ ÊµãËØïÁÆóÊ≥ïÔºöÁî®logisticÂõûÂΩíËøõË°åÂàÜÁ±ª123456789101112131415161718192021222324252627282930313233343536373839def classifyVector(inX, weights): prob = sigmoid(sum(inX*weights)) if prob &gt; 0.5: return 1.0 return 0.0def colicTest(): frTrain = open('MLiA_SourceCode/machinelearninginaction/Ch05/horseColicTraining.txt') frTest = open('MLiA_SourceCode/machinelearninginaction/Ch05/horseColicTest.txt') trainingSet = [] trainingLabels = [] for line in frTrain.readlines(): currLine = line.strip().split('\t') lineArr = [] for i in range(21): lineArr.append(float(currLine[i])) trainingSet.append(lineArr) trainingLabels.append(float(currLine[21])) trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, 500) errorCount = 0 numTestVec = 0.0 for line in frTest.readlines(): numTestVec += 1.0 currLine = line.strip().split('\t') lineArr = [] for i in range(21): lineArr.append(float(currLine[i])) if int(classifyVector(array(lineArr), trainWeights)) != int(currLine[21]): errorCount += 1 errorRate = (float(errorCount)/numTestVec) print("the error tate of this test is %f" % errorRate) return errorRatedef multiTest(): numTests = 10 errorSum = 0.0 for k in range(numTests): errorSum += colicTest() print("after %d iterations the average error rate is: %f" % (numTests, errorSum/float(numTests))) 1multiTest() the error tate of this test is 0.268657 the error tate of this test is 0.373134 the error tate of this test is 0.343284 the error tate of this test is 0.328358 the error tate of this test is 0.313433 the error tate of this test is 0.298507 the error tate of this test is 0.417910 the error tate of this test is 0.328358 the error tate of this test is 0.283582 the error tate of this test is 0.373134 after 10 iterations the average error rate is: 0.332836 ÂçÅÊ¨°Ëø≠‰ª£ÂêéÁöÑÂπ≥ÂùáÈîôËØØÁéá‰∏∫33%ÔºåËøòÁÆó‰∏çÈîô ÊÄªÁªìLogisticÂõûÂΩíÁöÑÁõÆÁöÑÊòØÂØªÊâæ‰∏Ä‰∏™ÈùûÁ∫øÊÄßÂáΩÊï∞sigmoidÁöÑÊúÄ‰Ω≥ÊãüÂêàÂèÇÊï∞ÔºåÊ±ÇËß£ËøáÁ®ãÂèØ‰ª•Áî±ÊúÄ‰ºòÂåñÁÆóÊ≥ïÂÆåÊàê„ÄÇÂú®ÊúÄ‰ºòÂåñÁÆóÊ≥ï‰∏≠ÔºåÊúÄÂ∏∏Áî®ÁöÑÂ∞±ÊòØÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÔºåËÄåÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÂèàÂèØ‰ª•ÁÆÄÂåñ‰∏∫ÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçá„ÄÇ ÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ï‰∏éÊ¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÁöÑÊïàÊûúÁõ∏ÂΩìÔºå‰ΩÜÂç†Áî®Êõ¥Â∞ëÁöÑËÆ°ÁÆóËµÑÊ∫êÔºåÂπ∂‰∏îÔºåÈöèÊú∫Ê¢ØÂ∫¶‰∏äÂçáÁÆóÊ≥ïÊòØ‰∏Ä‰∏™Âú®Á∫øÁÆóÊ≥ïÔºåÂÆÉÂèØ‰ª•Âú®Êñ∞Êï∞ÊçÆÂà∞Êù•Êó∂Â∞±Êõ¥Êñ∞ÂèÇÊï∞ÔºåËÄå‰∏çÈúÄË¶ÅÈáçÊñ∞ËØªÂèñÊï¥‰∏™Êï∞ÊçÆÈõÜ Â¶Ç‰ΩïÂ§ÑÁêÜÁº∫Â§±ÂÄºÔºåÂèñÂÜ≥‰∫éÂÆûÈôÖ‰∏≠ÁöÑÈúÄÊ±Ç„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>ÈÄªËæëÂõûÂΩí</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàÂõõÔºâ]]></title>
    <url>%2F2020%2F03%2F21%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Ââç‰∏§Á´†ÁöÑÂàÜÁ±ªÂô®Âè™ËÉΩÁªôÂá∫ÂàÜÁ±ªÁªìÊûúÔºåËÄå‰∏çËÉΩÁªôÂá∫Ê¶ÇÁéáÔºåËøô‰∏ÄÁ´†Â∞ÜÂ≠¶‰π†‰∏Ä‰∏™ÊúÄÁÆÄÂçïÁöÑÊ¶ÇÁéáÂàÜÁ±ªÂô®ÔºåÊú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®„ÄÇ‰πãÊâÄ‰ª•Áß∞‰∏∫Êú¥Á¥†ÔºåÊòØÂõ†‰∏∫Êï¥‰∏™ÂΩ¢ÂºèÂåñËøáÁ®ãÂè™ÂÅöÊúÄÂéüÂßãÔºåÊúÄÁÆÄÂçïÁöÑÂÅáËÆæ„ÄÇ Âü∫‰∫éË¥ùÂè∂ÊñØÂÜ≥Á≠ñÁêÜËÆ∫ÁöÑÂàÜÁ±ªÊñπÊ≥ïÊú¥Á¥†Ë¥ùÂè∂ÊñØ ‰ºòÁÇπÔºöÂú®Êï∞ÊçÆËæÉÂ∞ëÁöÑÊÉÖÂÜµ‰∏ã‰ªçÁÑ∂ÊúâÊïàÔºåÂèØ‰ª•Â§ÑÁêÜÂ§öÂàÜÁ±ªÈóÆÈ¢ò Áº∫ÁÇπÔºöÂØπËæìÂÖ•Êï∞ÊçÆÁöÑÂáÜÂ§áÊñπÂºèËæÉ‰∏∫ÊïèÊÑü ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊ†áÁß∞ÂûãÊï∞ÊçÆ Êú¥Á¥†Ë¥ùÂè∂ÊñØÊòØË¥ùÂè∂ÊñØÁêÜËÆ∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂÅáËÆæÊàë‰ª¨Êúâ‰∏Ä‰∏™Êï∞ÊçÆÈõÜÔºåÂÆÉÁî±‰∏§Á±ªÁªÑÊàê Êàë‰ª¨Áé∞Âú®Áî®p1(x,y)ÔºåË°®Á§∫Êï∞ÊçÆÁÇπ(x,y)Â±û‰∫éÁ±ªÂà´1ÔºàÂõæ‰∏≠ÂúÜÁÇπË°®Á§∫ÁöÑÁ±ªÂà´ÔºâÁöÑÊ¶ÇÁéáÔºåÁî®p2(x,y)Ë°®Á§∫Êï∞ÊçÆÁÇπ(x,y)Â±û‰∫éÁ±ªÂà´2ÔºàÂõæ‰∏≠Áî®‰∏âËßíÂΩ¢Ë°®Á§∫ÁöÑÁ±ªÂà´ÔºâÁöÑÊ¶ÇÁéáÔºåÈÇ£‰πàÂØπ‰∫é‰∏Ä‰∏™Êñ∞Êï∞ÊçÆÁÇπ(x,y)Êï∞ÊçÆÁÇπÔºåÂèØ‰ª•Áî®‰∏ãÈù¢ÁöÑËßÑÂàôÊù•Âà§Êñ≠ÂÆÉÁöÑÁ±ªÂà´Ôºö Â¶ÇÊûúp1(x,y) &gt; p2(x,y)ÔºåÈÇ£‰πàÁ±ªÂà´‰∏∫1 Â¶ÇÊûúp2(x,y) &gt; p1(x,y)ÔºåÈÇ£‰πàÁ±ªÂà´‰∏∫2 ‰πüÂ∞±ÊòØËØ¥Êàë‰ª¨‰ºöÈÄâÊã©È´òÊ¶ÇÁéáÂØπÂ∫îÁöÑÁ±ªÂà´ÔºåËøôÂ∞±ÊòØË¥ùÂè∂ÊñØÂÜ≥Á≠ñÁêÜËÆ∫ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÔºåÂç≥ÈÄâÊã©ÂÖ∑ÊúâÊúÄÈ´òÊ¶ÇÁéáÁöÑÂÜ≥Á≠ñ„ÄÇ Êù°‰ª∂Ê¶ÇÁéá$$p(c|x)=\frac{p(x|c)p(c)}{p(x)}$$ ËØª‰ΩúcÂú®xÂèëÁîüÁöÑÊù°‰ª∂‰∏ãÂèëÁîüÁöÑÊ¶ÇÁéá ‰ΩøÁî®Êù°‰ª∂Ê¶ÇÁéáÊ†πÊçÆ‰∏äÈù¢ÊâÄËØ¥Êàë‰ª¨ÂèØ‰ª•Áü•ÈÅì $$p(c_i|x)=\frac{p(x|c_i)p(c_i)}{p(x)}$$ Â¶ÇÊûúP(c1|x,y) &gt; P(c2|x,y)ÔºåÈÇ£‰πàÁ±ªÂà´‰∏∫C1 Â¶ÇÊûúP(c1|x,y) &lt; P(c2|x,y)ÔºåÈÇ£‰πàÁ±ªÂà´‰∏∫C2 ‰ΩøÁî®Ë¥ùÂè∂ÊñØÂáÜÂàôÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÂ∑≤Áü•ÁöÑ‰∏â‰∏™Ê¶ÇÁéáÂÄºÊù•ËÆ°ÁÆóÊú™Áü•ÁöÑÊ¶ÇÁéáÂÄº„ÄÇ Ê≥®ÈáäÔºöP(c1|x,y)ËØª‰ΩúÔºöc1Âú®xÂèëÁîüÁöÑÊù°‰ª∂‰∏ãÂèëÁîüÁöÑÊ¶ÇÁéá‰∏éyÁöÑËÅîÂêàÊ¶ÇÁéá„ÄÇËÅîÂêàÊ¶ÇÁéáË°®Á§∫‰∏§‰∏™‰∫ã‰ª∂ÂÖ±ÂêåÂèëÁîüÁöÑÊ¶ÇÁéá„ÄÇA‰∏éBÁöÑËÅîÂêàÊ¶ÇÁéáË°®Á§∫‰∏∫ P(AB) ÊàñËÄÖP(A,B),ÊàñËÄÖP(A‚à©B) ‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØËøõË°åÊñáÊ°£ÂàÜÁ±ªÊú¥Á¥†Ë¥ùÂè∂ÊñØÊòØÈÄÇÁî®‰∫éÊñáÊ°£ÂàÜÁ±ªÁöÑÂ∏∏Áî®ÁÆóÊ≥ïÔºåÊàë‰ª¨ÂèØ‰ª•ËßÇÂØüÊñáÊ°£‰∏≠Âá∫Áé∞ÁöÑËØçÔºåÂπ∂ÊääÊØè‰∏™ËØçÂá∫Áé∞ÊàñËÄÖ‰∏çÂá∫Áé∞‰Ωú‰∏∫‰∏Ä‰∏™ÁâπÂæÅÔºåËøôÊ†∑ÂæóÂà∞ÁöÑÁâπÂæÅÊï∞ÁõÆÂ∞±‰ºöË∑üËØçÊ±áË°®‰∏≠ÁöÑËØçÁõÆ‰∏ÄÊ†∑Â§ö„ÄÇ Êú¥Á¥†Ë¥ùÂè∂ÊñØÁöÑ‰∏ÄËà¨ËøáÁ®ã Êî∂ÈõÜÊï∞ÊçÆÔºöÂèØ‰ª•‰ΩøÁî®‰ªª‰ΩïÊñπÊ≥ïÔºåÊú¨Á´†‰ΩøÁî®ÁöÑÊòØRSSÊ∫ê ÂáÜÂ§áÊï∞ÊçÆÔºöÈúÄË¶ÅÊï∞ÂÄºÂûãÊàñËÄÖÂ∏ÉÂ∞îÂûãÊï∞ÊçÆ ÂàÜÊûêÊï∞ÊçÆÔºöÊúâÂ§ßÈáèÁâπÂæÅÊó∂ÔºåÁªòÂà∂ÁâπÂæÅ‰ΩúÁî®‰∏çÂ§ßÔºåÊ≠§Êó∂‰ΩøÁî®Áõ¥ÊñπÂõæÊïàÊûúÊõ¥Â•Ω ËÆ≠ÁªÉÁÆóÊ≥ïÔºöËÆ°ÁÆó‰∏çÂêåÁöÑÁã¨Á´ãÁâπÂæÅÁöÑÊù°‰ª∂Ê¶ÇÁéá ÊµãËØïÁÆóÊ≥ïÔºöËÆ°ÁÆóÈîôËØØÁéá ‰ΩøÁî®ÁÆóÊ≥ïÔºö‰∏Ä‰∏™Â∏∏ËßÅÁöÑÊú¥Á¥†Ë¥ùÂè∂ÊñØÂ∫îÁî®ÊòØÊñáÊ°£ÂàÜÁ±ª„ÄÇÂèØ‰ª•Âú®‰ªªÊÑèÂàÜÁ±ªÂú∫ÊôØ‰∏≠‰ΩøÁî®„ÄÇ ÂÅáËÆæËØçÊ±áË°®Êúâ1000‰∏™ÂçïËØçÔºåÊÉ≥Ë¶ÅÂæóÂà∞Â•ΩÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºåÂ∞±ÈúÄË¶ÅË∂≥Â§üÁöÑÊ†∑Êú¨ÔºåÂÅáÂÆöÊ†∑Êú¨Êï∞‰∏∫N„ÄÇÁî±ÁªüËÆ°Â≠¶Áü•ÔºåÂ¶ÇÊûúÊØè‰∏™ÁâπÂæÅÈúÄË¶ÅN‰∏™Ê†∑Êú¨ÔºåÈÇ£‰πàÂØπ‰∫é10‰∏™ÁâπÂæÅÂ∞ÜÈúÄË¶Å$N^{10}$‰∏™Ê†∑Êú¨ÔºåÂØπ‰∫éÂåÖÂê´1000‰∏™ÁâπÂæÅÁöÑËØçÊ±áË°®Â∞ÜÈúÄË¶Å$N^{1000}$‰∏™Ê†∑Êú¨„ÄÇÊâÄÈúÄË¶ÅÁöÑÊ†∑Êú¨Êï∞‰ºöÈöèÁùÄÁâπÂæÅÊï∞ÁõÆÂ¢ûÂ§ßËÄåËøÖÈÄüÂ¢ûÈïø„ÄÇ Â¶ÇÊûúÁâπÂæÅ‰πãÈó¥Áõ∏‰∫íÁã¨Á´ãÔºåÈÇ£‰πàÊ†∑Êú¨Êï∞ÂèØ‰ª•‰ªé$N^{1000}$ÂáèÂ∞ëÂà∞1000√óN‰∏™„ÄÇÊâÄË∞ìÁöÑÁã¨Á´ãÔºàindependenceÔºâÊåáÁöÑÊòØÁªüËÆ°ÊÑè‰πâ‰∏äÁöÑÁã¨Á´ãÔºåÂç≥‰∏Ä‰∏™ÁâπÂæÅÊàñÂçïËØçÂá∫Áé∞ÁöÑÂèØËÉΩÊÄß‰∏éÂÆÉÂíåÂÖ∂‰ªñÂçïËØçÁõ∏ÈÇªÊ≤°ÊúâÂÖ≥Á≥ª„ÄÇÂè¶‰∏Ä‰∏™Ë¶ÅÊ±ÇÊòØÊòØËØ¥ÊØè‰∏™ÁâπÂæÅÁöÑÈáçË¶ÅÁ®ãÂ∫¶ÊòØÁõ∏ÂêåÁöÑ„ÄÇÂΩìÁÑ∂ËøôÂú®Áé∞ÂÆû‰∏≠ÊòØ‰∏çÂèØËÉΩÁöÑ„ÄÇ ‰ΩøÁî®PythonËøõË°åÊñáÊú¨ÂàÜÁ±ªÂ¶Ç‰Ωï‰ªéÊñáÊú¨‰∏≠Ëé∑ÂèñÁâπÂæÅÔºåÊàë‰ª¨Ë¶ÅÊûÑÂª∫‰∏Ä‰∏™ÊñáÊú¨ËØçÊù°ÔºàtokenÔºâÔºåÂÆÉÊòØ‰∏Ä‰∫õÂçïËØçÁöÑÁªÑÂêàÔºåÁÑ∂ÂêéÂ∞Ü‰∏Ä‰∏™ÊñáÊú¨ÊÆµË°®Á§∫‰∏∫‰∏Ä‰∏™ÂêëÈáèËØçÊù°ÔºåÂÖ∂‰∏≠ÂÄº‰∏∫1Ë°®Á§∫ÂçïËØçÂá∫Áé∞Âú®ÊñáÊú¨‰∏≠Ôºå0Ë°®Á§∫ÂçïËØçÊú™Âá∫Áé∞Âú®ÊñáÊú¨‰∏≠„ÄÇ ÂáÜÂ§áÊï∞ÊçÆÔºö‰ªéÊñáÊú¨‰∏≠ÊûÑÂª∫ËØçÂêëÈáè12345678910111213141516171819202122232425262728from numpy import *def loadDataSet(): postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] classVec = [0,1,0,1,0,1] #1 is abusive, 0 not return postingList,classVecdef createVocabList(dataSet): # ÂàõÂª∫‰∏Ä‰∏™Á©∫ÈõÜ vocabSet = set([]) for document in dataSet: # ÂàõÂª∫‰∏§‰∏™ÈõÜÂêàÁöÑÂπ∂ÈõÜ vocabSet = vocabSet | set(document) return list(vocabSet)def setOfWords2Vec(vocabList, inputSet): # ÂàõÂª∫‰∏Ä‰∏™ÊâÄÊúâÂÖÉÁ¥†ÈÉΩ‰∏∫0ÁöÑÂêëÈáè returnVec = [0]*len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] = 1 else: print("the word: %s is not in my Vocabulary!" % word) return returnVec Á¨¨‰∏Ä‰∏™ÂáΩÊï∞createVocabList()ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂÆûÈ™åÊ†∑Êú¨„ÄÇËØ•ÂáΩÊï∞ËøîÂõûÂá†‰∏™ÂàáÂàÜÂ•ΩÁöÑÊñáÊú¨ËØçÊù°ÔºåÂ∑≤ÁªèÂéªÈô§Ê†áÁÇπÁ¨¶Âè∑ÔºåÁ¨¨‰∫å‰∏™ËøîÂõûÂÄºÊòØ‰∏Ä‰∏™Á±ªÂà´Ê†áÁ≠æÁöÑÈõÜÂêàÔºåÊúâ‰∏§Á±ªÔºå‰æÆËæ±ÊÄßÂíåÈùû‰æÆËæ±ÊÄß„ÄÇ createVocabList()ÂáΩÊï∞ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ÊñáÊ°£ÊâÄÊúâÂçïËØçÁöÑÂàóË°®ÔºåÂàóË°®‰∏≠Ê≤°ÊúâÈáçÂ§çÂÄº„ÄÇ setOfWords2Vec()ËæìÂÖ•ÂèÇÊï∞ÊòØËØçÊ±áË°®ÔºåÂíåÊüê‰∏™ÊñáÊ°£ÔºåËæìÂá∫ÊòØËøô‰∏™ÊñáÊ°£ÁöÑÂêëÈáè„ÄÇ 123listOPosts, listClasses = loadDataSet()myVocabList = createVocabList(listOPosts)myVocabList [&apos;posting&apos;, &apos;to&apos;, &apos;please&apos;, &apos;help&apos;, &apos;him&apos;, &apos;worthless&apos;, &apos;mr&apos;, &apos;love&apos;, &apos;is&apos;, &apos;stop&apos;, &apos;has&apos;, &apos;stupid&apos;, &apos;flea&apos;, &apos;I&apos;, &apos;quit&apos;, &apos;problems&apos;, &apos;steak&apos;, &apos;cute&apos;, &apos;garbage&apos;, &apos;food&apos;, &apos;park&apos;, &apos;dog&apos;, &apos;dalmation&apos;, &apos;licks&apos;, &apos;buying&apos;, &apos;ate&apos;, &apos;not&apos;, &apos;maybe&apos;, &apos;take&apos;, &apos;so&apos;, &apos;how&apos;, &apos;my&apos;] 1setOfWords2Vec(myVocabList, listOPosts[0]) [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 1setOfWords2Vec(myVocabList, listOPosts[3]) [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰ªéËØçÂêëÈáèËÆ°ÁÆóÊ¶ÇÁéáÊàë‰ª¨‰ΩøÁî®ÂâçÈù¢ÁöÑË¥ùÂè∂ÊñØÂÖ¨ÂºèÔºåÂ∞Üx,yÊõøÊç¢‰Ωçw,wË°®Á§∫‰∏Ä‰∏™ÂêëÈáèÔºåÂÆÉÁî±Â§ö‰∏™Êï∞ÂÄºÁªÑÊàêÔºö $$p(c_i|w)=\frac{p(w|c_i)p(c_i)}{p(w)}$$ ËÆ°ÁÆóÊñπÊ≥ïÔºö $p(c_i)=Á±ªÂà´i‰∏≠ÁöÑÂçïËØçÊï∞\divÊÄªÁöÑÂçïËØçÊï∞$ $p(w|c_i)=p(w_0,w_1,w_2‚Ä¶w_N|c_i)=p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)‚Ä¶p(w_N|c_i)$ ‰º™‰ª£Á†ÅÔºö ËÆ°ÁÆóÊØè‰∏™Á±ªÂà´‰∏≠ÁöÑÂçïËØçÊï∞ ÂØπÊØèÁØáËÆ≠ÁªÉÊñáÊ°£Ôºö ÂØπÊØè‰∏™Á±ªÂà´Ôºö Â¶ÇÊûúËØçÊù°Âá∫Áé∞Âú®ÊñáÊ°£‰∏≠-&gt;Â¢ûÂä†ËØ•ËØçÊù°ÁöÑËÆ°Êï∞ÂÄº Â¢ûÂä†ÊâÄÊúâËØçÊù°ÁöÑËÆ°Êï∞ÂÄº ÂØπÊØè‰∏™Á±ªÂà´Ôºö ÂØπÊØè‰∏™ËØçÊù°Ôºö Â∞ÜËØ•ËØçÊù°ÁöÑÊï∞ÁõÆÈô§‰ª•ÊÄªËØçÊù°Êï∞ÁõÆÂæóÂà∞Êù°‰ª∂Ê¶ÇÁéá ËøîÂõûÊØè‰∏™Á±ªÂà´ÁöÑÊù°‰ª∂Ê¶ÇÁéá 123456789101112131415161718192021def trainNB0(trainMatrix, trainCategory): # ÂàùÂßãÂåñÊ¶ÇÁéá numTrainDocs = len(trainMatrix) numWords = len(trainMatrix[0]) pAbusive = sum(trainCategory)/float(numTrainDocs) p0Num = zeros(numWords) p1Num = zeros(numWords) p0Denom = 0.0 p1Denom = 0.0 for i in range(numTrainDocs): if trainCategory[i] == 1: # ÂêëÈáèÁõ∏Âä† p1Num += trainMatrix[i] p1Denom += sum(trainMatrix[i]) else: p0Num += trainMatrix[i] p0Denom += sum(trainMatrix[i]) # ÂØπÊØè‰∏™ÂÖÉÁ¥†ÂÅöÈô§Ê≥ï p1vect = p1Num/p1Denom p0vect = p0Num/p0Denom return p0vect, p1vect, pAbusive ‰ª£Á†Å‰∏≠ÁöÑËæìÂÖ•‰∏∫ÊñáÊ°£Áü©ÈòµtrainMatrixÔºåÂíåÊØèÁØáÊñáÊ°£Á±ªÂà´Ê†áÁ≠æÊâÄÊûÑÊàêÁöÑÂêëÈáètrainCategory„ÄÇÈ¶ñÂÖàËÆ°ÁÆó‰æÆËæ±ÊÄßÊñáÊ°£Ôºàclass=1ÔºâÁöÑÊ¶ÇÁéáÔºåÂç≥P(1).Âõ†‰∏∫ËøôÊòØ‰∏™‰∫åÂàÜÁ±ªÈóÆÈ¢òÔºåÊâÄÊúâÂèØ‰ª•ÈÄöËøáËÆ°ÁÆóp(0)=1-p(1) 123trainMat = []for postinDoc in listOPosts: trainMat.append(setOfWords2Vec(myVocabList, postinDoc)) 1p0V, p1V, pAb = trainNB0(trainMat, listClasses) 1p0V array([0. , 0.04166667, 0.04166667, 0.04166667, 0.08333333, 0. , 0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667, 0. , 0.04166667, 0.04166667, 0. , 0.04166667, 0.04166667, 0.04166667, 0. , 0. , 0. , 0.04166667, 0.04166667, 0.04166667, 0. , 0.04166667, 0. , 0. , 0. , 0.04166667, 0.04166667, 0.125 ]) 1p1V array([0.05263158, 0.05263158, 0. , 0. , 0.05263158, 0.10526316, 0. , 0. , 0. , 0.05263158, 0. , 0.15789474, 0. , 0. , 0.05263158, 0. , 0. , 0. , 0.05263158, 0.05263158, 0.05263158, 0.10526316, 0. , 0. , 0.05263158, 0. , 0.05263158, 0.05263158, 0.05263158, 0. , 0. , 0. ]) 1pAb 0.5 ÊµãËØïÁÆóÊ≥ïÔºöÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰øÆÊîπÂàÜÁ±ªÂô®Âú®ËÆ°ÁÆóÂ§ö‰∏™Ê¶ÇÁéáÁöÑ‰πòÁßØ‰∏ÄËé∑ÂæóÂàÜÊ°£Â±û‰∫éÊüê‰∏™Á±ªÂà´ÁöÑÊ¶ÇÁéáÔºåÂç≥ËÆ°ÁÆó$p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)$Êó∂ÂÄôÔºåÂ¶ÇÊûúÂÖ∂‰∏≠‰∏Ä‰∏™Ê¶ÇÁéáÁöÑÂÄº‰∏∫0ÔºåÈÇ£‰πàÊúÄÂêéÁöÑ‰πòÁßØ‰πü‰∏∫0Ôºå‰∏∫‰∫ÜÈôç‰ΩéËøôÁßçÂΩ±ÂìçÔºåÊàë‰ª¨Â∞ÜÊâÄÊúâËØçÂá∫Áé∞ÁöÑÊ¨°Êï∞ÂàùÂßãÂåñ‰∏∫1ÔºåÂ∞ÜÂàÜÊØçÂàùÂßãÂåñ‰∏∫2„ÄÇ Âè¶‰∏Ä‰∏™ÈÅáÂà∞ÁöÑÈóÆÈ¢òÊòØ‰∏ãÊ∫¢ÔºåÊòØÁî±‰∫éÂ§™Â§öÁöÑÂæàÂ∞èÁöÑÊï∞Áõ∏‰πòÈÄ†ÊàêÁöÑÔºåÂèØ‰ª•Ê±ÇÂØπÊï∞ÈÅøÂÖç‰∏ãÊ∫¢„ÄÇ ËßÇÂØü‰∏äÂõæÂèëÁé∞Ôºåf(x)Âíåln(f(x))ÁöÑÊõ≤Á∫øË∂ãÂäøÊòØÁõ∏ÂêåÁöÑ 1234567891011121314151617181920212223def trainNB0(trainMatrix, trainCategory): # ÂàùÂßãÂåñÊ¶ÇÁéá numTrainDocs = len(trainMatrix) numWords = len(trainMatrix[0]) pAbusive = sum(trainCategory)/float(numTrainDocs) # ÂàùÂßãÂåñ‰∏∫ 1 p0Num = ones(numWords) p1Num = ones(numWords) # ÂàÜÊØçÊîπ‰∏∫ 2 p0Denom = 2.0 p1Denom = 2.0 for i in range(numTrainDocs): if trainCategory[i] == 1: # ÂêëÈáèÁõ∏Âä† p1Num += trainMatrix[i] p1Denom += sum(trainMatrix[i]) else: p0Num += trainMatrix[i] p0Denom += sum(trainMatrix[i]) # ÂØπÊØè‰∏™ÂÖÉÁ¥†ÂÅöÈô§Ê≥ïÔºåÂπ∂Ê±ÇÂØπÊï∞ p1vect = log(p1Num/p1Denom) p0vect = log(p0Num/p0Denom) return p0vect, p1vect, pAbusive Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂáΩÊï∞Ôºö 123456789101112131415161718192021def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1): p1 = sum(vec2Classify * p1Vec) + log(pClass1) p0 = sum(vec2Classify * p0Vec) + log(1.0-pClass1) if p1 &gt; p0: return 1 else: return 0def testingNB(): listOposts, listClasses = loadDataSet() myVocabList = createVocabList(listOPosts) trainMat = [] for postinDoc in listOposts: trainMat.append(setOfWords2Vec(myVocabList, postinDoc)) p0V, p1V, pAb = trainNB0(array(trainMat), array(listClasses)) testEntry = ['love', 'my', 'dalmation'] thisDoc = array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, 'classif as ', classifyNB(thisDoc, p0V, p1V, pAb)) testEntry = ['stupid', 'garbage'] thisDoc = array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, 'classif as ', classifyNB(thisDoc, p0V, p1V, pAb)) 1testingNB() [&apos;love&apos;, &apos;my&apos;, &apos;dalmation&apos;] classif as 0 [&apos;stupid&apos;, &apos;garbage&apos;] classif as 1 ÊµãËØïÁªìÊûúÔºåÁ¨¨‰∏ÄÂè•ËØùÊòØÈùû‰æÆËæ±ÊÄßÁöÑÔºåÁ¨¨‰∫åÂè•ÊòØ‰æÆËæ±ÊÄßÁöÑÔºåÂàÜÁ±ªÊ≠£Á°Æ ÂáÜÂ§áÊï∞ÊçÆÔºöÊñáÊ°£ËØçË¢ãÊ®°ÂûãÊØè‰∏™ËØçÁöÑÂá∫Áé∞Ê¨°Êï∞‰Ωú‰∏∫‰∏Ä‰∏™ÁâπÂæÅÔºåËøô‰∏™ÂèØ‰ª•Ë¢´ÊèèËø∞‰∏∫ËØçÈõÜÊ®°ÂûãÔºàset of word modelÔºâÔºåÂ¶ÇÊûú‰∏Ä‰∏™ËØçÂú®ÊñáÊ°£‰∏≠ÁöÑÂá∫Áé∞‰∏çÊ≠¢‰∏ÄÊ¨°ÔºåËøôÁßçÊñπÊ≥ïË¢´Áß∞‰∏∫ËØçË¢ãÊ®°ÂûãÔºàbag of words modelÔºâÔºå‰øÆÊîπsetOfWords2Vec()ÂáΩÊï∞‰∏∫bagOfWords2Vec() 123456def bagOfWords2Vec(vocabList, inputSet): returnVec = [0]*len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] += 1 return returnVec Áé∞Âú®ÂàÜÁ±ªÂô®Â∑≤ÁªèÊûÑÂª∫Â•Ω‰∫ÜÔºå‰∏ãÈù¢Âà©Áî®ËØ•ÂàÜÁ±ªÂô®ËøáÊª§ÂûÉÂúæÈÇÆ‰ª∂„ÄÇ ÂÆû‰æãÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØËøáÊª§ÂûÉÂúæÈÇÆ‰ª∂ Êî∂ÈõÜÊï∞ÊçÆÔºöÊèê‰æõÁöÑÊñáÊú¨Êñá‰ª∂ ÂáÜÂ§áÊï∞ÔºöÂ∞ÜÊñáÊú¨Êñá‰ª∂Ëß£ÊûêÊàêËØçÊù°ÂêëÈáè ÂàÜÊûêÊï∞ÊçÆÔºöÊ£ÄÊü•ËØçÊù°Á°Æ‰øùËß£ÊûêÁöÑÊ≠£Á°ÆÊÄß ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰ΩøÁî®Êàë‰ª¨‰πãÂâçÂª∫Á´ãÁöÑtrainBN()ÂáΩÊï∞ ÊµãËØïÁÆóÊ≥ïÔºö‰ΩøÁî®classifyNB()ÔºåÂπ∂‰∏îÊûÑÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÊµãËØïÂáΩÊï∞Êù•ËÆ°ÁÆóÊñáÊ°£ÈõÜÁöÑÈîôËØØ ‰ΩøÁî®ÁÆóÊ≥ïÔºöÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÁ®ãÂ∫èËøáÁ®ãÂØπ‰∏ÄÁªÑÊñáÊ°£ËøõË°åÂàÜÁ±ªÔºåÂ∞ÜÈîôÂàÜÁöÑÊñáÊ°£ËæìÂá∫Âà∞Â±èÂπï‰∏ä ÂáÜÂ§áÊï∞ÊçÆÔºöÂàáÂàÜÊñáÊú¨‰ΩøÁî®pythonÁöÑstring.split()ÊñπÊ≥ïÂàáÂàÜ ‰ΩøÁî®re.compile(‚Äò\W*‚Äô)ÂéªÈô§Ê†áÁÇπÂíåÊï∞Â≠ó„ÄÇ ÂéªÈô§Á©∫Â≠óÁ¨¶‰∏≤ ‰ΩøÁî®.lower()ËΩ¨Êç¢‰∏∫Â∞èÂÜô 12345import reregEx = re.compile('\W')emailText = open('MLiA_SourceCode/machinelearninginaction/Ch04/email/ham/6.txt').read()listOfTokens = regEx.split(emailText)listOfTokens = [tok.lower() for tok in listOfTokens if len(tok) &gt; 0 and re.search('[^0-9]', tok)] ÊµãËØïÁÆóÊ≥ïÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØËøõË°å‰∫§ÂèâÈ™åËØÅ1234567891011121314151617181920212223242526272829303132333435363738def textParse(bigString): listOfTokens = re.split(r'\W', bigString) return [tok.lower() for tok in listOfTokens if len(tok) &gt; 2 and re.search('[^0-9]', tok)]def spamTest(): docList = [] classList = [] fullText = [] for i in range(1, 26): wordList = textParse(open('MLiA_SourceCode/machinelearninginaction/Ch04/email/spam/%d.txt' % i).read()) docList.append(wordList) fullText.extend(wordList) classList.append(1) wordList = textParse(open('MLiA_SourceCode/machinelearninginaction/Ch04/email/ham/%d.txt' % i).read()) docList.append(wordList) fullText.extend(wordList) classList.append(0) vocabList = createVocabList(docList) trainingSet = list(range(50)) testSet = [] for i in range(10): randIndex = int(random.uniform(0, len(trainingSet))) testSet.append(trainingSet[randIndex]) del(trainingSet[randIndex]) trainMat = [] trainClasses = [] for docIndex in trainingSet: trainMat.append(setOfWords2Vec(vocabList, docList[docIndex])) trainClasses.append(classList[docIndex]) p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses)) errorCount = 0 for docIndex in testSet: wordVector = setOfWords2Vec(vocabList, docList[docIndex]) if classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]: errorCount += 1 print("classification error",docList[docIndex]) print('the error rate is ', float(errorCount)/len(testSet)) return float(errorCount)/len(testSet) 1spamTest() the error rate is 0.0 0.0 1spamTest() classification error [&apos;this&apos;, &apos;mail&apos;, &apos;was&apos;, &apos;sent&apos;, &apos;from&apos;, &apos;notification&apos;, &apos;only&apos;, &apos;address&apos;, &apos;that&apos;, &apos;cannot&apos;, &apos;accept&apos;, &apos;incoming&apos;, &apos;mail&apos;, &apos;please&apos;, &apos;not&apos;, &apos;reply&apos;, &apos;this&apos;, &apos;message&apos;, &apos;thank&apos;, &apos;you&apos;, &apos;for&apos;, &apos;your&apos;, &apos;online&apos;, &apos;reservation&apos;, &apos;the&apos;, &apos;store&apos;, &apos;you&apos;, &apos;selected&apos;, &apos;has&apos;, &apos;located&apos;, &apos;the&apos;, &apos;item&apos;, &apos;you&apos;, &apos;requested&apos;, &apos;and&apos;, &apos;has&apos;, &apos;placed&apos;, &apos;hold&apos;, &apos;your&apos;, &apos;name&apos;, &apos;please&apos;, &apos;note&apos;, &apos;that&apos;, &apos;all&apos;, &apos;items&apos;, &apos;are&apos;, &apos;held&apos;, &apos;for&apos;, &apos;day&apos;, &apos;please&apos;, &apos;note&apos;, &apos;store&apos;, &apos;prices&apos;, &apos;may&apos;, &apos;differ&apos;, &apos;from&apos;, &apos;those&apos;, &apos;online&apos;, &apos;you&apos;, &apos;have&apos;, &apos;questions&apos;, &apos;need&apos;, &apos;assistance&apos;, &apos;with&apos;, &apos;your&apos;, &apos;reservation&apos;, &apos;please&apos;, &apos;contact&apos;, &apos;the&apos;, &apos;store&apos;, &apos;the&apos;, &apos;phone&apos;, &apos;number&apos;, &apos;listed&apos;, &apos;below&apos;, &apos;you&apos;, &apos;can&apos;, &apos;also&apos;, &apos;access&apos;, &apos;store&apos;, &apos;information&apos;, &apos;such&apos;, &apos;store&apos;, &apos;hours&apos;, &apos;and&apos;, &apos;location&apos;, &apos;the&apos;, &apos;web&apos;, &apos;http&apos;, &apos;www&apos;, &apos;borders&apos;, &apos;com&apos;, &apos;online&apos;, &apos;store&apos;, &apos;storedetailview_98&apos;] the error rate is 0.1 0.1 ÊØè‰∏ÄÊ¨°ÂæóÂà∞ÁöÑÈîôËØØÁéáÈÉΩ‰∏çÂêåÔºåË¶ÅÊÉ≥Êõ¥Â•ΩÁöÑËØÑ‰º∞ÈîôËØØÁéáÔºåÂèØ‰ª•ÈáçÂ§çÂ§öÊ¨°ÔºåÂçÅÊ¨°ËÆ°ÁÆóÊ±ÇÂπ≥ÂùáÈîôËØØÁéá‰∏∫6% 1234errorRate = 0for i in range(10): errorRate += spamTest()errorRate/10 the error rate is 0.2 the error rate is 0.1 the error rate is 0.0 the error rate is 0.0 the error rate is 0.1 the error rate is 0.1 the error rate is 0.1 the error rate is 0.0 the error rate is 0.1 the error rate is 0.0 0.06999999999999999 ÂÆû‰æãÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®‰ªé‰∏™‰∫∫ÂπøÂëä‰∏≠Ëé∑ÂèñÂå∫ÂüüÂÄæÂêë‰∏ãÈù¢Â∞Ü‰ΩøÁî®Êù•Ëá™‰∏çÂêåÂüéÂ∏ÇÁöÑÂπøÂëäËÆ≠ÁªÉ‰∏Ä‰∏™ÂàÜÁ±ªÂô®ÔºåÁÑ∂ÂêéËßÇÂØüÂàÜÁ±ªÁöÑÊïàÊûúÔºåÊàë‰ª¨ÁöÑÁõÆÁöÑ‰∏çÊòØ‰ΩøÁî®ËØ•ÂàÜÁ±ªÂô®ËøõË°åÂàÜÁ±ªÔºåËÄåÊòØÈÄöËøáËßÇÂØüÂçïËØçÂíåÊù°‰ª∂Ê¶ÇÁéáÂÄºÊù•ÂèëÁé∞‰∏éÁâπÂÆöÂüéÂ∏ÇÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÔºå Êî∂ÈõÜÊï∞ÊçÆÔºöÂØºÂÖ•RSSÊ∫êÂà©Áî®python‰∏ãËΩΩRSSÁöÑÊñáÊú¨„ÄÇ È¶ñÂÖàÈúÄË¶ÅÂÆâË£Öfeedparser,https://github.com/kurtmckee/feedparser 1%pip install feedparser 1import feedparser Êé•‰∏ãÊù•‰ΩúËÄÖ‰ΩøÁî®‰∫ÜRSSÊ∫êhttp://newyork.craigslist.org/stp/index.rss Â∑≤Áªè‰∏çËÉΩËÆøÈóÆ‰∫Ü‰π¶‰∏≠‰ΩúËÄÖÁöÑÊÑèÊÄùÊòØ‰ª•Êù•Ëá™Ê∫ê http://newyork.craigslist.org/stp/index.rss ‰∏≠ÁöÑÊñáÁ´†‰Ωú‰∏∫ÂàÜÁ±ª‰∏∫1ÁöÑÊñáÁ´†Ôºå‰ª•Êù•Ëá™Ê∫ê http://sfbay.craigslist.org/stp/index.rss ‰∏≠ÁöÑÊñáÁ´†‰Ωú‰∏∫ÂàÜÁ±ª‰∏∫0ÁöÑÊñáÁ´† ‰∏∫‰∫ÜËÉΩÂ§üË∑ëÈÄöÁ§∫‰æã‰ª£Á†ÅÔºåÂèØ‰ª•Êâæ‰∏§ÂèØÁî®ÁöÑRSSÊ∫ê‰Ωú‰∏∫Êõø‰ª£„ÄÇ ÊàëÁî®ÁöÑÊòØËøô‰∏§‰∏™Ê∫êÔºö NASA Image of the DayÔºöhttp://www.nasa.gov/rss/dyn/image_of_the_day.rss Yahoo Sports - NBA - Houston Rockets NewsÔºöhttp://sports.yahoo.com/nba/teams/hou/rss.xml ‰πüÂ∞±ÊòØËØ¥ÔºåÂ¶ÇÊûúÁÆóÊ≥ïËøêË°åÊ≠£Á°ÆÁöÑËØùÔºåÊâÄÊúâÊù•Ëá™‰∫é nasa ÁöÑÊñáÁ´†Â∞Ü‰ºöË¢´ÂàÜÁ±ª‰∏∫1ÔºåÊâÄÊúâÊù•Ëá™‰∫éyahoo sportsÁöÑ‰ºëÊñØÈ°øÁÅ´ÁÆ≠ÈòüÊñ∞ÈóªÂ∞Ü‰ºöÂàÜÁ±ª‰∏∫0 1ny=feedparser.parse('https://www.nasa.gov/rss/dyn/image_of_the_day.rss') 1len(ny['entries']) 60 123456789101112131415161718192021222324252627282930313233343536373839404142434445def calcMostFreq(vocabList,fullText): import operator freqDict = &#123;&#125; for token in vocabList: freqDict[token]=fullText.count(token) sortedFreq = sorted(freqDict.items(), key=operator.itemgetter(1), reverse=True) return sortedFreq[:30]def localWords(feed1,feed0): import feedparser docList=[] classList = [] fullText =[] minLen = min(len(feed1['entries']),len(feed0['entries'])) for i in range(minLen): wordList = textParse(feed1['entries'][i]['summary']) docList.append(wordList) fullText.extend(wordList) classList.append(1) #NY is class 1 wordList = textParse(feed0['entries'][i]['summary']) docList.append(wordList) fullText.extend(wordList) classList.append(0) vocabList = createVocabList(docList)#create vocabulary top30Words = calcMostFreq(vocabList,fullText) #remove top 30 words for pairW in top30Words: if pairW[0] in vocabList: vocabList.remove(pairW[0]) trainingSet = list(range(2*minLen)) testSet=[] #create test set for i in range(20): randIndex = int(random.uniform(0,len(trainingSet))) testSet.append(trainingSet[randIndex]) del(trainingSet[randIndex]) trainMat=[]; trainClasses = [] for docIndex in trainingSet:#train the classifier (get probs) trainNB0 trainMat.append(bagOfWords2Vec(vocabList, docList[docIndex])) trainClasses.append(classList[docIndex]) p0V,p1V,pSpam = trainNB0(array(trainMat),array(trainClasses)) errorCount = 0 for docIndex in testSet: #classify the remaining items wordVector = bagOfWords2Vec(vocabList, docList[docIndex]) if classifyNB(array(wordVector),p0V,p1V,pSpam) != classList[docIndex]: errorCount += 1 print('the error rate is: ',float(errorCount)/len(testSet)) return vocabList,p0V,p1V calcMostFreq()ÂáΩÊï∞ÁöÑÂäüËÉΩÊòØÈÅçÂéÜËØçÊ±áË°®‰∏≠ÁöÑÊØè‰∏™ËØçÂπ∂ÁªüËÆ°ÂÆÉÂú®ÊñáÊú¨‰∏≠Âá∫Áé∞ÁöÑÊ¨°Êï∞ÔºåÁÑ∂ÂêéÊ†πÊçÆÂá∫Áé∞Ê¨°Êï∞‰ªéÈ´òÂà∞‰ΩéÂØπËØçÂÖ∏ËøõË°åÊéíÂ∫èÔºåËøîÂõûÊéíÂ∫èÊúÄÈ´òÁöÑ30‰∏™ÂçïËØç„ÄÇ 12ny=feedparser.parse('http://www.nasa.gov/rss/dyn/image_of_the_day.rss')sf=feedparser.parse('http://sports.yahoo.com/nba/teams/hou/rss.xml') 1vocabList, pSF, pNY=localWords(ny, sf) the error rate is: 0.5 1vocabList, pSF, pNY=localWords(ny, sf) the error rate is: 0.35 ÂàÜÊûêÊï∞ÊçÆÔºöÊòæÁ§∫Âú∞ÂüüÁõ∏ÂÖ≥ÁöÑÁî®ËØçÂÖàÂØπpSFÂíåpNYËøõË°åÊéíÂ∫èÔºåÁÑ∂ÂêéÊåâÁÖßÈ°∫Â∫èÂ∞ÜËØçÊâìÂç∞Âá∫Êù•„ÄÇ 123456789101112131415def getTopWords(ny,sf): import operator vocabList,p0V,p1V=localWords(ny,sf) topNY=[]; topSF=[] for i in range(len(p0V)): if p0V[i] &gt; -6.0 : topSF.append((vocabList[i],p0V[i])) if p1V[i] &gt; -6.0 : topNY.append((vocabList[i],p1V[i])) sortedSF = sorted(topSF, key=lambda pair: pair[1], reverse=True) print("SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**") for item in sortedSF: print(item[0]) sortedNY = sorted(topNY, key=lambda pair: pair[1], reverse=True) print("NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**") for item in sortedNY: print(item[0]) 1getTopWords(ny,sf) the error rate is: 0.2 SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF** westbrook but fund michael los also amid NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY** arms station program agency spacecraft milky ÊÄªÁªìÂØπ‰∫éÂàÜÁ±ªËÄåË®ÄÔºå‰ΩøÁî®Ê¶ÇÁéáÊúâÊó∂Ë¶ÅÊØî‰ΩøÁî®Á°¨ËßÑÂàôÊõ¥‰∏∫ÊúâÊïà„ÄÇË¥ùÂè∂ÊñØÊ¶ÇÁéáÂç≥Ë¥ùÂè∂ÊñØÂáÜÂàôÊèê‰æõ‰∫Ü‰∏ÄÁßçÂà©Áî®‰∏ÄÁõ¥ÂÄºÊù•‰º∞ËÆ°Êú™Áü•Ê¶ÇÁéáÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇ ÂèØ‰ª•ÈÄöËøáÁâπÂæÅ‰πãÈó¥ÁöÑÊù°‰ª∂Áã¨Á´ãÊÄßÂÅáËÆæÔºåÈôç‰ΩéÂØπÊï∞ÊçÆÈáèÁöÑÈúÄÊ±Ç„ÄÇÁã¨Á´ãÊÄßÂÅáËÆæÊòØÊåá‰∏Ä‰∏™ËØçÂá∫Áé∞ÁöÑÊ¶ÇÁéá‰∏ç‰æùËµñ‰∏éÊñáÊ°£‰∏≠ÁöÑÂÖ∂‰ªñËØç„ÄÇ ÁºñÁ®ãË¥ùÂè∂ÊñØÊó∂ÈúÄË¶ÅËÄÉËôëÂæàÂ§öÂÆûÈôÖÂõ†Á¥†„ÄÇ‰∏ãÊ∫¢Âá∫Â∞±ÊòØÂÖ∂‰∏≠‰πã‰∏ÄÔºåÂèØ‰ª•ÈÄöËøáÂØπÊ¶ÇÁéáÂèñÂØπÊï∞Êù•Ëß£ÂÜ≥„ÄÇËøòÊúâÂÖ∂‰ªñÊñπÊ≥ïÊîπËøõÔºåÊØîÂ¶ÇÁßªÈô§ÂÅúÁî®ËØç„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>Êú¥Á¥†Ë¥ùÂè∂ÊñØ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏âÔºâ]]></title>
    <url>%2F2020%2F03%2F06%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÂÜ≥Á≠ñÊ†ëÁöÑÁÆÄ‰ªã‰Ω†ÊòØÂê¶Áé©Ëøá‰∫åÂçÅ‰∏™ÈóÆÈ¢òÁöÑÊ∏∏ÊàèÔºåÂ∞±ÊòØ‰Ω†Âú®ËÑëÊµ∑‰∏≠ÊÉ≥Êüê‰∏™‰∫ãÁâ©ÔºåÂêë‰Ω†ÊèêÈóÆ‰∫åÂçÅ‰∏™ÈóÆÈ¢òÊé®ÊµãÂá∫‰Ω†ÊÉ≥ÁöÑ‰∏úË•ø„ÄÇËøô‰∏™Ê∏∏ÊàèÁöÑÂéüÁêÜÂíåÂÜ≥Á≠ñÊ†ëÁ±ª‰ººÔºå‰∏ãÈù¢ÊòØ‰∏Ä‰∏™Âà§Êñ≠ÂûÉÂúæÈÇÆ‰ª∂ÁöÑÂÜ≥Á≠ñÊ†ë„ÄÇ ÂÜ≥Á≠ñÊ†ëÁöÑÊûÑÈÄ†ÂÜ≥Á≠ñÊ†ë ‰ºòÁÇπÔºöËÆ°ÁÆóÂ§çÊùÇÂ∫¶‰∏çÈ´òÔºåËæìÂá∫ÁöÑÁªìÊûúÊòì‰∫éÁêÜËß£ÔºåÂØπ‰∏≠Èó¥ÂÄºÁöÑÁº∫Â§±‰∏çÊïèÊÑüÔºåÂèØ‰ª•Â§ÑÁêÜ‰∏çÁõ∏ÂÖ≥ÁâπÂæÅÁöÑÊï∞ÊçÆ Áº∫ÁÇπÔºöÂèØËÉΩ‰ºö‰∫ßÁîüËøáÂ∫¶ÂåπÈÖçÁöÑÈóÆÈ¢ò ÈÄÇÁî®Êï∞ÊçÆÁ±ªÂûãÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞Âûã Âú®ÊûÑÈÄ†ÂÜ≥Á≠ñÊ†ëÊó∂ÔºåÈ¶ñÂÖàË¶ÅÁ°ÆÂÆöÂì™‰∫õÁâπÂæÅÂú®ÂàíÂàÜÊï∞ÊçÆÂàÜÁ±ªÊó∂Ëµ∑Âà∞ÂÜ≥ÂÆöÊÄßÁöÑ‰ΩúÁî®Ôºå‰∏∫‰∫ÜÂàíÂàÜÂá∫ÊúÄÂ•ΩÁöÑÁªìÊûúÔºåÊàë‰ª¨ÂøÖÈ°ªËØÑ‰º∞ÊØè‰∏™ÁâπÂæÅÔºåÂàõÂª∫ÂàÜÊîØÁöÑ‰º™‰ª£Á†ÅcreateBranch()ÂáΩÊï∞Â¶Ç‰∏ã 12345678if so returen Á±ªÊ†áÁ≠æelse ÂØªÊâæÂàíÂàÜÊï∞ÊçÆÈõÜÁöÑÊúÄÂ•ΩÁâπÂæÅ ÂàíÂàÜÊï∞ÊçÆÈõÜ ÂàõÂª∫ÂàÜÊîØËäÇÁÇπ for ÊØè‰∏™ÂàíÂàÜÁöÑÂ≠êÈõÜ Ë∞ÉÁî®ÂáΩÊï∞createBranchÂπ∂Â¢ûÂä†ËøîÂõûÁªìÊûúÂà∞ÂàÜÊîØËäÇÁÇπ‰∏≠ return ÂàÜÊîØËäÇÁÇπ ‰∏äÈù¢ÁöÑ‰º™‰ª£Á†ÅcreateBranch()ÊòØ‰∏Ä‰∏™ÈÄíÂΩíÂáΩÊï∞ÔºåÂú®ÂÄíÊï∞Á¨¨‰∫åË°åÁõ¥Êé•Ë∞ÉÁî®Ëá™Â∑±„ÄÇ ÂÜ≥Á≠ñÊ†ëÁöÑ‰∏ÄËà¨ÊµÅÁ®ãÔºö Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áÊï∞ÊçÆ ÂàÜÊûêÊï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ï ÊµãËØïÁÆóÊ≥ï ‰ΩøÁî®ÁÆóÊ≥ï ‰ø°ÊÅØÂ¢ûÁõäÂàíÂàÜÊï∞ÊçÆÈõÜÁöÑÂ§ßÂéüÂàôÊòØÔºöÂ∞ÜÊó†Â∫èÁöÑÊï∞ÊçÆÂèòÂæóÊõ¥Âä†ÊúâÂ∫èÔºåÂ¶Ç‰ΩïËÉΩÁü•ÈÅìÊï∞ÊçÆÊòØÂêëÊúâÂ∫èÁöÑÊñπÂêëÂàíÂàÜÂë¢ÔºüÊñπÊ≥ïÊúâÂæàÂ§öÔºåËøôÈáåÁöÑÊñπÊ≥ï‰∏∫È¶ôÊµìÁÜµÔºàÂÖ∂ÂÆÉÊñπÊ≥ïËøòÊúâÂü∫Â∞ºÁ≥ªÊï∞Ôºâ„ÄÇ ÁÜµÁöÑÂÆö‰πâ‰∏∫‰ø°ÊÅØÁöÑÊúüÊúõÂÄºÔºåÂ¶ÇÊûúÂæÖÂàÜÁ±ªÁöÑ‰∫ãÁâ©ÂèØËÉΩÂàíÂàÜÂú®Â§ö‰∏™ÂàÜÁ±ª‰πã‰∏≠ÔºåÂàôÁ¨¶Âè∑$x_i$ÁöÑ‰ø°ÊÅØÂÆö‰πâ‰∏∫ $$l(x_i)=-\log_2p(x_i)$$ ÂÖ∂‰∏≠$p(x_i)$ÊòØÈÄâÊã©ÂàÜÁ±ªÁöÑÊ¶ÇÁéá ‰∏∫‰∫ÜËÆ°ÁÆóÁÜµÔºåÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÊâÄÊúâÁ±ªÂà´ÊâÄÊúâÂèØËÉΩÂÄºÂåÖÂê´ÁöÑ‰ø°ÊÅØÊúüÊúõÂÄºÔºåÈÄöËøá‰∏ãÈù¢ÂÖ¨ÂºèÂæóÂà∞Ôºö $$H = -\sum_{i=1}^n p(x_i)\log_2p(x_i)$$ ÂÖ∂‰∏≠nÊòØÂàÜÁ±ªÁöÑÊï∞ÁõÆÔºå‰∏ãÈù¢Áî®pythonËÆ°ÁÆó‰ø°ÊÅØÁÜµ 1234567891011121314151617from math import logdef calcShannonEnt(dataSet): numEntries = len(dataSet) labelCounts = &#123;&#125; # ‰∏∫ÊâÄÊúâÂèØËÉΩÂàÜÁöÑÁ±ªÂàõÂª∫Â≠óÂÖ∏ÔºåÂ¶ÇÊûúÁ±ªÂà´Â∑≤ÁªèËÆ∞ÂΩïÔºåÂàôËÆ∞ÂΩïÂΩìÂâçÁ±ªÂà´Âá∫Áé∞ÁöÑÊ¨°Êï∞ for featVec in dataSet: currentLabel = featVec[-1] if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0 labelCounts[currentLabel] += 1 shannonEnt = 0.0 # ËÆ°ÁÆóÊØè‰∏™Á±ªÂà´ÁöÑÂá∫Áé∞ÁöÑÊ¶ÇÁéáÔºåÁÑ∂ÂêéÂ•óÂÖ•ÂÖ¨ÂºèÊ±ÇÂá∫ÁÜµ for key in labelCounts: prob = float(labelCounts[key]) / numEntries shannonEnt -= prob * log(prob, 2) return shannonEnt ‰∏ãÈù¢ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Êï∞ÊçÆÈõÜÊµãËØï‰∏Ä‰∏ã 123456789def createDataSet(): dataSet = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no'], ] labels = ['no surfacing', 'flippers'] return dataSet, labels 1myDat, labels = createDataSet() 1myDat [[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]] 1calcShannonEnt(myDat) 0.9709505944546686 ÁÜµË∂äÈ´òÔºåÂàôÊ∑∑ÂêàÁöÑÊï∞ÊçÆ‰πüË∂äÂ§öÔºåÊàë‰ª¨ÂèØ‰ª•Âú®Êï∞ÊçÆÈõÜ‰∏≠Ê∑ªÂä†Êõ¥Â§öÁöÑÂàÜÁ±ªÔºåËßÇÂØüÁÜµÊòØÂ¶Ç‰ΩïÂèòÂåñÁöÑÔºåÊ∑ªÂä†‰∏Ä‰∏™maybeÁöÑÁ±ªÂà´ 12myDat[0][-1]='maybe'myDat [[1, 1, &apos;maybe&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]] 1calcShannonEnt(myDat) 1.3709505944546687 ÂàíÂàÜÊï∞ÊçÆÈõÜÂæóÂà∞ÁÜµÂêéÊàë‰ª¨Â∞±ÂèØ‰ª•ÊåâÁÖßËé∑ÂèñÊúÄÂ§ß‰ø°ÊÅØÂ¢ûÁõäÁöÑÊñπÊ≥ïÂàíÂàÜÊï∞ÊçÆÈõÜ 12345678def splitDataSet(dataSet, axis, value): retDataSet = [] for featVec in dataSet: if featVec[axis] == value: reducedFeatVec = featVec[:axis] reducedFeatVec.extend(featVec[axis+1:]) retDataSet.append(reducedFeatVec) return retDataSet splitDatSet()Êúâ‰∏â‰∏™ÂèÇÊï∞ÔºöÂæÖÂàíÂàÜÁöÑÊï∞ÊçÆÈõÜÔºåÂàíÂàÜÊï∞ÊçÆÈõÜÁöÑÁâπÂæÅÂàóÔºåÈúÄË¶ÅËøîÂõûÁöÑÁâπÂæÅÂÄº 12345# Ê≥®ÊÑèappendÂíåextendÁöÑ‰∏çÂêåa = [1, 2, 3]b = [4, 5, 6]a.append(b)a [1, 2, 3, [4, 5, 6]] 123a = [1, 2, 3]a.extend(b)a [1, 2, 3, 4, 5, 6] Áî®ÂâçÈù¢ÁÆÄÂçïÁöÑÊï∞ÊçÆÈõÜÊµãËØï‰∏Ä‰∏ã 12myDat, labels = createDataSet()myDat [[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]] 1splitDataSet(myDat, 1, 1) [[1, &apos;yes&apos;], [1, &apos;yes&apos;], [0, &apos;no&apos;], [0, &apos;no&apos;]] 1splitDataSet(myDat, 0, 0) [[1, &apos;no&apos;], [1, &apos;no&apos;]] Êé•‰∏ãÊù•ÈÅçÂéÜÊï¥‰∏™Êï∞ÊçÆÈõÜÔºåÂæ™ÁéØËÆ°ÁÆóÈ¶ôÂÜúÁÜµsplitDataSet()ÂáΩÊï∞ÔºåÊâæÂà∞ÊúÄÂ•ΩÁöÑÁâπÂæÅÂàíÂàÜÊñπÂºè„ÄÇ 123456789101112131415161718def chooseBestFeatureToSplit(dataSet): numFeatures = len(dataSet[0]) - 1 baseEntropy = calcShannonEnt(dataSet) bestInfoGain = 0.0 bestFeature = -1 for i in range(numFeatures): featList = [example[i] for example in dataSet] uniqueVals = set(featList) newEntropy = 0.0 for value in uniqueVals: subDataSet = splitDataSet(dataSet, i, value) prob = len(subDataSet)/float(len(dataSet)) newEntropy += prob * calcShannonEnt(subDataSet) infoGain = baseEntropy - newEntropy if (infoGain &gt; bestInfoGain): bestInfoGain = infoGain bestFeature = i return bestFeature 1chooseBestFeatureToSplit(myDat) 0 1myDat [[1, 1, &apos;yes&apos;], [1, 1, &apos;yes&apos;], [1, 0, &apos;no&apos;], [0, 1, &apos;no&apos;], [0, 1, &apos;no&apos;]] ‰ª£Á†ÅËøêË°åÂëäËØâÊàë‰ª¨Á¨¨0‰∏™ÁâπÂæÅÂàíÂàÜÊúÄÂ•Ω ÈÄíÂΩíÊûÑÂª∫ÂÜ≥Á≠ñÊ†ëÁõÆÂâçÊàë‰ª¨Â∑≤ÁªèÊûÑÂª∫Â•ΩÊâÄÊúâÂÜ≥Á≠ñÊ†ëÁÆóÊ≥ïÊâÄÈúÄÁöÑÂ≠êÂäüËÉΩÊ®°ÂùóÔºåÂÖ∂Â∑•‰ΩúÂéüÁêÜÂ¶Ç‰∏ãÔºöÂæóÂà∞ÂéüÂßãÊï∞ÊçÆÈõÜÔºåÁÑ∂ÂêéÂü∫‰∫éÊúÄÂ•ΩÁöÑÂ±ûÊÄßÂàíÂàÜÊï∞ÊçÆÈõÜÔºåÁî±‰∫éÁâπÂæÅÂÄºÂèØËÉΩÂ§ö‰∫é‰∏§‰∏™ÔºåÂõ†Ê≠§ÂèØËÉΩÂ≠òÂú®Â§ß‰∫é‰∏§‰∏™ÂàÜÊîØÁöÑÊï∞ÊçÆÈõÜÂàíÂàÜ„ÄÇÁ¨¨‰∏ÄÊ¨°ÂàíÂàÜÂêéÔºåÊï∞ÊçÆÂ∞ÜË¢´Âêë‰∏ã‰º†ÈÄíÂà∞Ê†ëÂàÜÊîØÁöÑ‰∏ã‰∏ÄËäÇÁÇπÔºåÂú®Ëøô‰∏™ËäÇÁÇπ‰∏äÔºåÊàë‰ª¨ÂèØ‰ª•ÂÜçÊ¨°ÂàíÂàÜÊï∞ÊçÆÔºåÂõ†Ê≠§Êàë‰ª¨ÂèØ‰ª•ÈááÁî®ÈÄíÂΩíÁöÑÂéüÂàôÂ§ÑÁêÜÊï∞ÊçÆÈõÜ„ÄÇ ÈÄíÂΩíÁªìÊùüÁöÑÊù°‰ª∂ÊòØÔºöÁ®ãÂ∫èÈÅçÂéÜÂÆåÊâÄÊúâÁöÑÂàíÂàÜÊï∞ÊçÆÈõÜÁöÑÂ±ûÊÄßÔºåÊàñËÄÖÊØè‰∏™ÂàÜÊîØ‰∏ãÁöÑÊâÄÊúâÂÆû‰æãÈÉΩÂÖ∑ÊúâÁõ∏ÂêåÁöÑÂàÜÁ±ª„ÄÇÂ¶ÇÊûúÊâÄÊúâÂÆûÂàóÂÖ∑ÊúâÁõ∏ÂêåÁöÑÂàÜÁ±ªÔºåÂàôÂæóÂà∞‰∏Ä‰∏™Âè∂Â≠êËäÇÁÇπÊàñËÄÖÁªàÊ≠¢Âùó„ÄÇ 12345678def majorityCnt(classList): classCount=&#123;&#125; for vote in classList: if vote not in classCount.keys(): classCount[vote] = 0 classCount[vote] += 1 sortedClassCount = sorted(classCount,iteritems(), key=operator.itemgetter(1), reverse=True) return sortedClassCount[0][0] ‰∏äÈù¢‰ª£Á†ÅÁöÑ‰ΩúÁî®Â∏ÇÔºåÂΩìÈÅçÂéÜÂÆåÊâÄÊúâÁöÑÁâπÂæÅÊó∂ÔºåÊàë‰ª¨Áî®ÊäïÁ•®Ë°®ÂÜ≥ÁöÑÊñπÊ≥ïÔºåËøîÂõûÂá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÁ±ªÂà´ 12345678910111213141516def createTree(dataSet, labels): classList = [example[-1] for example in dataSet] if classList.count(classList[0]) == len(classList): return classList[0] if len(dataSet[0]) == 1: return majorityCnt(classList) bestFeat = chooseBestFeatureToSplit(dataSet) bestFeatLabel = labels[bestFeat] myTree = &#123;bestFeatLabel:&#123;&#125;&#125; del(labels[bestFeat]) featValues = [example[bestFeat] for example in dataSet] uniqueVals = set(featValues) for value in uniqueVals: subLabels = labels[:] myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels) return myTree 123myDat, labels = createDataSet()myTree = createTree(myDat, labels)myTree {&apos;no surfacing&apos;: {0: &apos;no&apos;, 1: {&apos;flippers&apos;: {0: &apos;no&apos;, 1: &apos;yes&apos;}}}} ÁªòÂà∂Ê†ëÂΩ¢Âõæ‰∏∫‰∫ÜÊõ¥Ê∏ÖÊô∞ÁöÑÁúãÂá∫Êàë‰ª¨ÂàõÂª∫ÁöÑÊ†ëÔºåÂèØ‰ª•Áî®matplotlibÁªòÂõæ ‰ΩøÁî®ÊñáÊú¨Ê≥®Ëß£ÁªòÂà∂Ê†ëËäÇÁÇπ1234567891011121314151617181920import matplotlib.pyplot as plt# ÂÆö‰πâÊñáÊú¨Ê°ÜÂíåÁÆ≠Â§¥Ê†ºÂºèdecisionNode = dict(boxstyle="sawtooth", fc="0.8")leafNode = dict(boxstyle="round4", fc="0.8")arrow_args = dict(arrowstyle="&lt;-")# ÁªòÂà∂Â∏¶ÁÆ≠Â§¥ÁöÑÊ≥®Ëß£def plotNode(nodeTxt, centerPt, parentPt, nodeType): createPlot.ax1.annotate(nodeTxt, xy=parentPt, xycoords='axes fraction', xytext=centerPt, textcoords='axes fraction', va='center', ha='center', bbox=nodeType, arrowprops=arrow_args)def createPlot(): fig = plt.figure(1, facecolor='white') fig.clf() createPlot.ax1 = plt.subplot(111, frameon=False) plotNode('ÂÜ≥Á≠ñËäÇÁÇπ', (0.5, 0.1), (0.1, 0.5), decisionNode) plotNode('Âè∂ËäÇÁÇπ', (0.8, 0.1), (0.3, 0.8), leafNode) plt.show() 1createPlot() ÊûÑÈÄ†Ê≥®Ëß£Ê†ëÁªòÂà∂‰∏ÄÈ¢óÂÆåÊï¥ÁöÑÊ†ëÈúÄË¶Å‰∏Ä‰∫õÊäÄÂ∑ßÔºåÊàë‰ª¨ÂøÖÈ°ªÊúâx,yÂùêÊ†áÔºåÁü•ÈÅìÂ§öÂ∞ë‰∏™Âè∂ËäÇÁÇπÔºåÁ°ÆÂÆöxËΩ¥ÁöÑÈïøÂ∫¶ÔºåÊ†ëÁöÑÊ∑±Â∫¶ÔºåÁ°ÆÂÆöyËΩ¥ÁöÑÈ´òÂ∫¶ÔºåËøôÈáåÁºñÂÜô‰∏§‰∏™ÂáΩÊï∞getNumLeafs()ÂíågetTreeDepth()ÔºåÊù•Ëé∑ÂèñÂè∂ËäÇÁÇπÊï∞ÂíåÊ†ëÁöÑÊ∑±Â∫¶„ÄÇ 12345678910111213141516171819202122def getNumLeafs(myTree): numLeafs = 0 firstStr = list(myTree.keys())[0] secondDict = myTree[firstStr] for key in list(secondDict.keys()): if type(secondDict[key]).__name__=='dict': numLeafs += getNumLeafs(secondDict[key]) else: numLeafs += 1 return numLeafsdef getTreeDepth(myTree): maxDepth = 0 firstStr = list(myTree.keys())[0] secondDict = myTree[firstStr] for key in list(secondDict.keys()): if type(secondDict[key]).__name__=='dict': thisDepth = 1 + getTreeDepth(secondDict[key]) else: thisDepth = 1 if thisDepth &gt; maxDepth: maxDepth = thisDepth return maxDepth 12345def retrieveTree(i): listOfTrees =[&#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: 'no', 1: 'yes'&#125;&#125;&#125;&#125;, &#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: &#123;'head': &#123;0: 'no', 1: 'yes'&#125;&#125;, 1: 'no'&#125;&#125;&#125;&#125; ] return listOfTrees[i] 1retrieveTree(1) {&apos;no surfacing&apos;: {0: &apos;no&apos;, 1: {&apos;flippers&apos;: {0: {&apos;head&apos;: {0: &apos;no&apos;, 1: &apos;yes&apos;}}, 1: &apos;no&apos;}}}} 1myTree = retrieveTree(0) 1getNumLeafs(myTree) 3 1getTreeDepth(myTree) 2 Êé•‰∏ãÊù•Êàë‰ª¨ÁîªÂá∫ËøôÈ¢óÊ†ë 12345678910111213141516171819202122232425262728293031323334def plotMidText(cntrPt, parentPt, txtString): xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0] yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1] createPlot.ax1.text(xMid, yMid, txtString)def plotTree(myTree, parentPt, nodeTxt): numLeafs = getNumLeafs(myTree) depth = getTreeDepth(myTree) firstStr = list(myTree.keys())[0] cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff) plotMidText(cntrPt, parentPt, nodeTxt) plotNode(firstStr, cntrPt, parentPt, decisionNode) secondDict = myTree[firstStr] plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD for key in list(secondDict.keys()): if type(secondDict[key]).__name__ == 'dict': plotTree(secondDict[key], cntrPt, str(key)) else: plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode) plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key)) plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalDdef createPlot(inTree): fig = plt.figure(1, facecolor='white') fig.clf() axprops = dict(xticks=[], yticks=[]) createPlot.ax1 = plt.subplot(111, frameon=False, **axprops) plotTree.totalW = float(getNumLeafs(inTree)) plotTree.totalD = float(getTreeDepth(inTree)) plotTree.xOff = -0.5/plotTree.totalW plotTree.yOff = 1.0 plotTree(inTree, (0.5, 1.0), '') plt.show() 1myTree = retrieveTree(0) 1createPlot(myTree) Ê∑ªÂä†‰∏ÄÁªÑÊï∞ÊçÆÂÜçÁªòÂà∂ 1myTree['no surfacing'][3]='maybe' 1createPlot(myTree) ÊµãËØïÂíåÂ≠òÂÇ®ÂàÜÁ±ªÂô®ÊµãËØïÁÆóÊ≥ïÔºö‰ΩøÁî®ÂÜ≥Á≠ñÊ†ëÊâßË°åÂàÜÁ±ª‰æùÈù†ËÆ≠ÁªÉÊï∞ÊçÆÊûÑÈÄ†‰∫ÜÂÜ≥Á≠ñÊ†ë‰πãÂêéÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÂÆÉÁî®‰∫éÂÆûÈôÖÊï∞ÊçÆÁöÑÂàÜÁ±ªÔºåÂú®ÊâßË°åÊï∞ÊçÆÂàÜÁ±ªÊó∂ÔºåÈúÄË¶Å‰ΩøÁî®ÂÜ≥Á≠ñÊ†ë‰ª•ÂèäÁî®‰∫éÊûÑÈÄ†ÂÜ≥Á≠ñÊ†ëÁöÑÊ†áÁ≠æÂêëÈáè„ÄÇÁÑ∂ÂêéÁ®ãÂ∫èÊØîËæÉÊµãËØïÊï∞ÊçÆ‰∏éÂÜ≥Á≠ñÊ†ë‰∏äÁöÑÊï∞ÂÄºÔºåÈÄíÂΩíÊâßË°åËØ•ËøáÁ®ãÔºåÁõ¥Âà∞Âè∂Â≠êËäÇÁÇπÔºõÊúÄÂêéÂ∞ÜÊµãËØïÊï∞ÊçÆÂÆö‰πâ‰∏∫Âè∂Â≠êËäÇÁÇπÊâÄÂ±ûÁöÑÁ±ªÂûã„ÄÇ 1234567891011def classify(inputTree, featLabels, testVec): firstStr = list(inputTree.keys())[0] secondDict = inputTree[firstStr] featIndex = featLabels.index(firstStr) for key in list(secondDict.keys()): if testVec[featIndex] == key: if type(secondDict[key]).__name__ == 'dict': classLables = classify(secondDict[key], featLabels, testVec) else: classLables = secondDict[key] return classLables 12myDat, labels = createDataSet()labels [&apos;no surfacing&apos;, &apos;flippers&apos;] myTree = retrieveTree(0)myTree 1classify(myTree, labels, [1, 0]) &apos;no&apos; 1classify(myTree, labels, [1, 1]) &apos;yes&apos; ‰ΩøÁî®ÁÆóÊ≥ïÔºöÂÜ≥Á≠ñÊ†ëÁöÑÂ≠òÂÇ®ÂÜ≥Á≠ñÊ†ëÁöÑÊûÑÈÄ†ÊòØÂæàËÄóÊó∂ÁöÑ‰ªªÂä°Ôºå‰ΩÜÂ¶ÇÊûú‰ΩøÁî®ÂàõÂª∫Â•ΩÁöÑÂÜ≥Á≠ñÊ†ëÂàôÂèØ‰ª•ÂæàÂø´ÁöÑËß£ÂÜ≥ÂàÜÁ±ªÈóÆÈ¢òÔºåËøôÈáåÈúÄË¶Å‰ΩøÁî®pickleÊ®°ÂùóÊääÂÜ≥Á≠ñÊ†ë‰øùÂ≠òÂà∞Êú¨Âú∞„ÄÇ 12345678910def storeTree(inputTree, filename): import pickle fw = open(filename, 'wb') pickle.dump(inputTree, fw) fw.close()def grabTree(filename): import pickle fr = open(filename, 'rb') return pickle.load(fr) 12storeTree(myTree, 'classifierStorage.txt')grabTree('classifierStorage.txt') {&apos;no surfacing&apos;: {0: &apos;no&apos;, 1: {&apos;flippers&apos;: {0: &apos;no&apos;, 1: &apos;yes&apos;}}, 3: &apos;maybe&apos;}} ÈÄöËøá‰∏äËø∞ÁöÑ‰ª£Á†ÅÔºåÊàë‰ª¨Â∞ÜÂàÜÁ±ªÂô®ÂÇ®Â≠òÂú®Êú¨Âú∞ÔºåÂàô‰∏çÁî®ÊØè‰∏ÄÊ¨°ÂàÜÁ±ªÈÉΩÈáçÊñ∞Â≠¶‰π†‰∏ÄÈÅç ÂÆû‰æãÔºö‰ΩøÁî®ÂÜ≥Á≠ñÊ†ëÈ¢ÑÊµãÈöêÂΩ¢ÁúºÈïúÁöÑÁ±ªÂûãÊ†πÊçÆÈöêÂΩ¢ÁúºÈïúÁöÑÊùêË¥®Á≠â‰ø°ÊÅØÈ¢ÑÊµãÊÇ£ËÄÖÈúÄË¶ÅÁöÑÁúºÈïúÁ±ªÂûãÔºåÊµÅÁ®ãÂ¶Ç‰∏ã Êî∂ÈõÜÊï∞ÊçÆÔºöÊèê‰æõÁöÑÊñáÊú¨Êñá‰ª∂ ÂáÜÂ§áÊï∞ÊçÆÔºöËß£ÊûêtabÈîÆÂàÜÂâ≤ÁöÑÊï∞ÊçÆË°å ÂàÜÊûêÊï∞ÊçÆÔºöÂø´ÈÄüÊ£ÄÊü•Êï∞ÊçÆÊ≠£Á°ÆÊÄßÔºå‰ΩøÁî®createPlot()ÂáΩÊï∞ÁªòÂà∂Ê†ëÂΩ¢Âõæ ËÆ≠ÁªÉÁÆóÊ≥ïÔºö‰ΩøÁî®creatTree()ÂáΩÊï∞ ÊµãËØïÁÆóÊ≥ïÔºöÁºñÂÜôÊµãËØïÂáΩÊï∞È™åËØÅÂÜ≥Á≠ñÊ†ëÁöÑÊ≠£Á°ÆÁéá ‰ΩøÁî®ÁÆóÊ≥ïÔºöÂÇ®Â≠òÊ†ëÁöÑÊï∞ÊçÆÁªìÊûÑÔºå‰ª•‰æø‰∏ãÊ¨°‰ΩøÁî® 12345fr = open('./MLiA_SourceCode/machinelearninginaction/Ch03/lenses.txt')lenses = [inst.strip().split('\t') for inst in fr.readlines()]lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']lensesTree = createTree(lenses, lensesLabels)lensesTree {&apos;tearRate&apos;: {&apos;reduced&apos;: &apos;no lenses&apos;, &apos;normal&apos;: {&apos;astigmatic&apos;: {&apos;yes&apos;: {&apos;prescript&apos;: {&apos;myope&apos;: &apos;hard&apos;, &apos;hyper&apos;: {&apos;age&apos;: {&apos;pre&apos;: &apos;no lenses&apos;, &apos;young&apos;: &apos;hard&apos;, &apos;presbyopic&apos;: &apos;no lenses&apos;}}}}, &apos;no&apos;: {&apos;age&apos;: {&apos;pre&apos;: &apos;soft&apos;, &apos;young&apos;: &apos;soft&apos;, &apos;presbyopic&apos;: {&apos;prescript&apos;: {&apos;myope&apos;: &apos;no lenses&apos;, &apos;hyper&apos;: &apos;soft&apos;}}}}}}}} 1createPlot(lensesTree) ÈÄöËøáËßÇÂØüÊ†ëÊàë‰ª¨Áü•ÈÅìÔºåÂåªÁîüÊúÄÂ§öÂè™ÈúÄË¶ÅÈóÆÂõõ‰∏™ÈóÆÈ¢òÂ∞±ËÉΩÁ°ÆÂÆöÊÇ£ËÄÖÈúÄË¶Å‰Ω©Êà¥ÁöÑÁúºÈïú„ÄÇ ËôΩÁÑ∂ÂÜ≥Á≠ñÊ†ëÈùûÂ∏∏Â•ΩÁöÑÂåπÈÖç‰∫ÜÂÆûÈ™åÊï∞ÊçÆÔºå‰ΩÜÂåπÈÖçÁöÑÈÄâÈ°πÂ§™Â§ö‰∫ÜÔºåÊàë‰ª¨Â∞ÜËøôÁßçÈóÆÈ¢òÁß∞‰∏∫ËøáÂ∫¶ÂåπÈÖçÔºàoverfittingÔºâÔºå‰∏∫‰∫ÜÂáèÂ∞ëËøáÂ∫¶ÂåπÈÖçÈóÆÈ¢òÔºåÊàë‰ª¨ÂèØ‰ª•Ë£ÅÂâ™ÂÜ≥Á≠ñÊ†ëÔºåÂéªÊéâ‰∏Ä‰∫õ‰∏çÂøÖË¶ÅÁöÑÂè∂Â≠êËäÇÁÇπ„ÄÇ ÊÄªÁªìÊú¨Á´†‰ΩøÁî®ÁöÑÁÆóÊ≥ïÁß∞‰∏∫ID3ÔºåÂÆÉÊó†Ê≥ïÂ§ÑÁêÜÊï∞ÂÄºÂûãÊï∞ÊçÆÔºåÂ¶ÇÊûúÁâπÂæÅÂ§™Â§öÔºå‰πü‰ºöÈù¢‰∏¥ÂÖ∂ÂÆÉÈóÆÈ¢ò„ÄÇ ÂÜ≥Á≠ñÊ†ëÂàÜÁ±ªÂô®Â∞±ÂÉèÂ∏¶ÊúâÁªàÊ≠¢ÂùóÁöÑÊµÅÁ®ãÂõæÔºåÁªàÊ≠¢ÂùóË°®Á§∫ÂàÜÁ±ªÁªìÊûú„ÄÇÂºÄÂßãÂ§ÑÁêÜÊï∞ÊçÆÈõÜÊó∂ÔºåÊàë‰ª¨È¶ñÂÖàÈúÄË¶ÅÊµãÈáèÈõÜÂêà‰∏≠Êï∞ÊçÆÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºå‰πüÂ∞±ÊòØÁÜµÔºåÁÑ∂ÂêéÂØªÊâæÊúÄ‰ºòÊñπÊ°àÂàíÂàÜÊï∞ÊçÆÈõÜÔºåÁü•ÈÅìÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊâÄÊúâÊï∞ÊçÆÂ±û‰∫éÂêå‰∏ÄÂàÜÁ±ª„ÄÇID3ÂèØ‰ª•ÂàíÂàÜÊ†áÁß∞ÂûãÊï∞ÊçÆÈõÜ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>ÂÜ≥Á≠ñÊ†ë</tag>
        <tag>ID3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonËôöÊãüÁéØÂ¢ÉÁöÑÊê≠Âª∫]]></title>
    <url>%2F2020%2F02%2F19%2FPython%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Êàë‰ΩøÁî®ÁöÑUbuntu18Â∑≤ÁªèËá™Â∏¶‰∫Üpyhon3.6ÔºåÁé∞Âú®ÊàëÊÉ≥Áî®pipÂÆâË£Ö‰∏Ä‰∫õÂÖ∂ÂÆÉÁöÑÂ∫îÁî®ÁöÑÁâàÊú¨ÂíåÁé∞ÊúâÁöÑÊúâÂÜ≤Á™ÅÔºå‰∏∫‰∫ÜÈò≤Ê≠¢ÂÜ≤Á™ÅÔºåÊàëÈúÄË¶ÅÂè¶‰∏Ä‰∏™pythonÁéØÂ¢É„ÄÇ pythonÁöÑÂÆâË£ÖËøôÈáåÂõ†‰∏∫ÊòØÂú®LinuxÁ≥ªÁªü‰∏äÔºåÊâÄ‰ª•‰ΩøÁî®Ê∫êÁ†ÅÂÆâË£Ö„ÄÇPythonSource‰∏ãËΩΩptyhon3.8ÁöÑÊ∫êÁ†Å Ëß£ÂéãÂêéËøõÂÖ•Python-3.8.1Êñá‰ª∂Â§πÔºåÊâßË°åÂëΩ‰ª§1234567891011121314$ ./configurechecking build system type... x86_64-pc-linux-gnuchecking host system type... x86_64-pc-linux-gnuchecking for python3.8... nochecking for python3... python3checking for --enable-universalsdk... nochecking for --with-universal-archs... nochecking MACHDEP... "linux"checking for gcc... nochecking for cc... nochecking for cl.exe... noconfigure: error: in `/home/void/Python-3.8.1':configure: error: no acceptable C compiler found in $PATHSee `config.log' for more details Âá∫Èîô‰∫ÜÔºåÊàë‰ª¨Á´üÁÑ∂Ê≤°ÊúâgccÔºåccÂíåcl‰πüÊ≤°Êúâ„ÄÇ ÂÆâË£Ö‰æùËµñÂÆâË£ÖpythonÂâçÂÖàÂÆâË£ÖÈúÄË¶ÅÁöÑ‰æùËµñËΩØ‰ª∂ÔºåÂ¶ÇÊûúÂ∑≤ÁªèÂÆâË£ÖÂàô‰∏çÈúÄË¶ÅÂÜçÂÆâË£Ö Â¶ÇÊûúÊòØÊñ∞ÂÆâË£ÖÁöÑÁ≥ªÁªüÂÖàÊõ¥Êñ∞‰∏ãaptÔºö 1$ sudo apt-get update ÂÖàÂÆâË£ÖgccÔºö 1234567$ sudo apt install gcc............$ gcc --versiongcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0 ÂÆâË£Ög++ 1234567$ sudo apt install g++............$ g++ --versiong++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0 Ëøûmake‰πüÊ≤°ÊúâÔºåÂÆâË£Ömake 1234567$ sudo apt install make............$ make -vGNU Make 4.1 ÂÆâË£ÖÂÖ∂ÂÆÉ‰æùËµñÔºö1sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python-openssl ÊûÑÂª∫Python12345678910111213141516$ ./configure............creating Modules/Setup.localcreating Makefile$ make............Python build finished successfully!$ sudo make altinstall ............Installing collected packages: setuptools, pipSuccessfully installed pip-19.2.3 setuptools-41.2.0 If you want a release build with all stable optimizations active (PGO, etc),please run ./configure ‚Äìenable-optimizations Ë≠¶Âëä make install ÂèØ‰ª•Ë¶ÜÁõñÊàñ‰º™Ë£Ö python3 ‰∫åËøõÂà∂Êñá‰ª∂„ÄÇÂõ†Ê≠§ÔºåÂª∫ËÆÆ‰ΩøÁî® make altinstall ËÄå‰∏çÊòØ make install ÔºåÂõ†‰∏∫ÂêéËÄÖÂè™ÂÆâË£Ö‰∫Ü exec_prefix/bin/pythonversion „ÄÇ Ê£ÄÊü•ÂÆâË£ÖÊòØÂê¶ÊàêÂäü 1234$ python3.8 --versionPython 3.8.1$ pip3.8 --versionpip 19.2.3 from /usr/local/lib/python3.8/site-packages/pip (python 3.8) È°∫‰æøÊõ¥Êñ∞‰∏ãpip1$ sudo pip3.8 install --upgrade pip ÂÆâË£ÖËôöÊãüÁéØÂ¢ÉvirtualenvÊòØÁî®Êù•ÂàõÂª∫‰∏Ä‰∏™ÂçïÁã¨ÁöÑPythonËøêË°åÁéØÂ¢ÉÁöÑÂ∑•ÂÖ∑„ÄÇ 1$ sudo pip3.8 install virtualenv ÂÆâË£ÖvirtualenvÂ•ΩÂêéÂ∞±ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™ÂçïÁã¨pythonÁéØÂ¢É‰∫Ü12345ÂÖàÂàõÂª∫‰∏Ä‰∏™Â≠òÊîæpythonÁéØÂ¢ÉÁöÑÊñá‰ª∂Â§π$ mkdir pyvenv$ cd pyenvÂàõÂª∫ÁéØÂ¢É$ sudo virtualenv env Êñ∞Âª∫‰∏Ä‰∏™Âêç‰∏∫envÁöÑËôöÊãüÁéØÂ¢ÉÔºåÂπ∂Âú®ÂΩìÂâçÁõÆÂΩï‰∏ãÊñ∞Âª∫ÂêåÂêçÊñá‰ª∂Â§π ËôöÊãüÁéØÂ¢ÉÁöÑ‰ΩøÁî®‰ΩøÁî®sourceÂëΩ‰ª§ÊâßË°åËôöÊãüÁéØÂ¢ÉÁõÆÂΩï‰∏≠bin/activateÊñá‰ª∂ÔºåÂ∞ÜÊøÄÊ¥ªËôöÊãüÁéØÂ¢ÉÔºåÂëΩ‰ª§Ë°åÂâçÂá∫Áé∞ÔºàÁéØÂ¢ÉÂêçÔºâË°®Á§∫Â∑≤Âú®ËôöÊãüÁéØÂ¢É‰∏≠ ÊøÄÊ¥ªÂπ∂‰ΩøÁî®ËôöÊãüÁéØÂ¢É12$ source env/bin/activate(env) []$ deactive ÈÄÄÂá∫ÁéØÂ¢ÉÊâßË°åÂëΩ‰ª§deactivateÈÄÄÂá∫ËôöÊãüÁéØÂ¢É]]></content>
      <categories>
        <category>virtualenv</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∏ÄÔºâ]]></title>
    <url>%2F2020%2F02%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Ê≠§blogÊòØÊú∫Âô®Â≠¶‰π†ÂÆûÊàòËøôÊú¨‰π¶ÁöÑËØª‰π¶Á¨îËÆ∞ Êú∫Âô®Â≠¶‰π†Âü∫Á°ÄÁî®ËÆ°ÁÆóÊú∫Êù•ÂΩ∞ÊòæÊï∞ÊçÆËÉåÂêéÁúüÊ≠£ÁöÑÊÑè‰πâÔºåËøôÊâçÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÁúüÊ≠£Âê´‰πâ„ÄÇ Âú®ÂàÜÁ±ªÁÆóÊ≥ï‰∏≠ÁõÆÊ†áÂèòÈáèÁöÑÁ±ªÂûãÈÄöÂ∏∏ÊòØÊ†áÁß∞ÂûãÁöÑÔºåËÄåÂú®ÂõûÂΩíÁÆóÊ≥ï‰∏≠ÈÄöÂ∏∏ÊòØËøûÁª≠ÂûãÁöÑ„ÄÇ ËÆ≠ÁªÉÊ†∑Êú¨ÂøÖÈ°ªÁü•ÈÅìÁõÆÊ†áÂèòÈáèÁöÑÂÄºÔºå‰ª•‰æøÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂèØ‰ª•ÂèëÁé∞ÁâπÂæÅÂíåÁõÆÊ†áÂèòÈáè‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ ÁâπÂæÅÊàñËÄÖÂ±ûÊÄßÈÄöÂ∏∏ÊòØËÆ≠ÁªÉÊ†∑Êú¨ÈõÜÁöÑÂàóÔºåÂÆÉ‰ª¨ÊòØÁã¨Á´ãÊµãÈáèÁöÑÁªìÊûúÔºåÂ§ö‰∏™ÁâπÂæÅËÅîÁ≥ªÂú®‰∏ÄËµ∑ÂÖ±ÂêåÁªÑÊàê‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑Êú¨„ÄÇ ÁõëÁù£Â≠¶‰π†Ôºö k-ÈÇªËøëÁÆóÊ≥ï Á∫øÊÄßÂõûÂΩí Êú¥Á¥†Ë¥ùÂè∂ÊñØÁÆóÊ≥ï Â±ÄÈÉ®Âä†ÊùÉÁ∫øÊÄßÂõûÂΩí ÊîØÊåÅÂêëÈáèÊú∫ RidgeÂõûÂΩí ÂÜ≥Á≠ñÊ†ë LassoÊúÄÂ∞èÂõûÂΩíÁ≥ªÊï∞ Êó†ÁõëÁù£Â≠¶‰π†Ôºö K-ÂùáÂÄº ÊúÄÂ§ßÊúüÊúõÁÆóÊ≥ï DBSCAN ParzenÁ™óËÆæËÆ° Â¶Ç‰ΩïÈÄâÊã©ÂêàÈÄÇÁöÑÁÆóÊ≥ïÂ¶ÇÊûúË¶ÅÈ¢ÑÊµãÁõÆÊ†áÂèòÈáèÁöÑÂÄºÔºåÈÄâÊã©ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåÂê¶ÂàôÊó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï„ÄÇ Á°ÆÂÆöÁõÆÊ†áÂèòÈáèÁ±ªÂûãÔºö Á¶ªÊï£ÂûãÔºöTrue/FalseÔºå1/2/3ÔºåA/B/CÁ≠âÔºåÈÄâÊã©ÂàÜÁ±ªÁÆóÊ≥ï ËøûÁª≠ÂûãÔºö0.0 ~ 100Ôºå -99 ~ 99Ôºå +‚àû ~ -‚àûÁ≠âÔºåÈÄâÊã©ÂõûÂΩíÁÆóÊ≥ï ‰∏ÄËà¨Êù•ËØ¥ÂèëÁé∞ÊúÄÂ•ΩÁöÑÁÆóÊ≥ïÁöÑÂÖ≥ÈîÆÊòØÂèçÂ§çËØïÈîôËø≠‰ª£„ÄÇ ÂºÄÂèëÊú∫Âô®Â≠¶‰π†Â∫îÁî®Á®ãÂ∫èÁöÑÊ≠•È™§ Êî∂ÈõÜÊï∞ÊçÆ ÂáÜÂ§áËæìÂÖ•Êï∞ÊçÆ ÂàÜÊûêËæìÂÖ•Êï∞ÊçÆ ËÆ≠ÁªÉÁÆóÊ≥ï ÊµãËØïÁÆóÊ≥ï ‰ΩøÁî®ÁÆóÊ≥ï]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºà‰∫åÔºâ]]></title>
    <url>%2F2020%2F02%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[k-ÈÇªËøëÁÆóÊ≥ïÊ¶ÇËø∞k-ÈÇªËøëÁÆóÊ≥ïÈááÁî®ÊµãÈáè‰∏çÂêåÁâπÂæÅ‰πãÈó¥ÁöÑË∑ùÁ¶ªÊñπÊ≥ïËøõË°åÂàÜÁ±ª„ÄÇ ‰ºòÁÇπÔºöÁ≤æÂ∫¶È´òÔºåÂØπÂºÇÂ∏∏ÂÄº‰∏çÊïèÊÑüÔºåÊó†Êï∞ÊçÆËæìÂÖ•ÂÅáÂÆö Áº∫ÁÇπÔºöËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´òÔºåÁ©∫Èó¥Â§çÊùÇÂ∫¶È´ò ÈÄÇÁî®Êï∞ÊçÆËåÉÂõ¥ÔºöÊï∞ÂÄºÂûãÂíåÊ†áÁß∞Âûã ÂáÜÂ§á‰ΩøÁî®PythonÂØºÂÖ•Êï∞ÊçÆÈ¶ñÂÖàÂÜô‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ®ãÂ∫èÊù•ÁêÜËß£pythonÊòØÂ¶Ç‰ΩïËß£ÊûêÂíåÂä†ËΩΩÊï∞ÊçÆÁöÑ 1234567from numpy import *import operatordef createDataSet(): group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]]) labels = ['A', 'A', 'B', 'B'] return group, labels 1group, labels = createDataSet() 1group array([[1. , 1.1], [1. , 1. ], [0. , 0. ], [0. , 0.1]]) 1labels [&apos;A&apos;, &apos;A&apos;, &apos;B&apos;, &apos;B&apos;] ÂÆûÊñΩKNNÂàÜÁ±ªÁÆóÊ≥ïÂØπÊú™Áü•Á±ªÂà´Â±ûÊÄßÁöÑÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏™ÁÇπ‰æùÊ¨°ÊâßË°å‰ª•‰∏ãÊìç‰ΩúÔºö ËÆ°ÁÆóÂ∑≤Áü•Á±ªÂà´Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÁÇπ‰∏éÂΩìÂâçÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ª ÊåâÁÖßË∑ùÁ¶ªÈÄíÂ¢ûÊ¨°Â∫èÊéíÂ∫è ÈÄâÂèñ‰∏éÂΩìÂâçË∑ùÁ¶ªÊúÄÂ∞èÁöÑk‰∏™ÁÇπ Á°ÆÂÆöÂâçk‰∏™ÁÇπÊâÄÂú®Á±ªÂà´ÁöÑÂá∫Áé∞È¢ëÁéá ËøîÂõûÂâçk‰∏™ÁÇπÂá∫Áé∞È¢ëÁéáÊúÄÈ´òÁöÑÁ±ªÂà´ÂΩì‰ΩúÂΩìÂâçÁÇπÁöÑÈ¢ÑÊµãÂàÜÁ±ª ËÆ°ÁÆóË∑ùÁ¶ªÁöÑÊñπÊ≥ï‰ΩøÁî®Ê¨ßÊ∞èË∑ùÁ¶ªËÆ°ÁÆóÂÖ¨Âºè: $$d=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$$ ÂÖ∑‰ΩìÁ®ãÂ∫èÂ¶Ç‰∏ãÔºö 12345678910111213def classify0(inX, dataSet, labels, k): dataSetSize = dataSet.shape[0] diffMat = tile(inX, (dataSetSize, 1)) - dataSet sqDiffMat = diffMat**2 sqDistances = sqDiffMat.sum(axis=1) distances = sqDistances ** 0.5 sortedDistIndicies = distances.argsort() classCount = &#123;&#125; for i in range(k): voteIlabe1 = labels[sortedDistIndicies[i]] classCount[voteIlabe1] = classCount.get(voteIlabe1, 0) + 1 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) return sortedClassCount[0][0] classify0 ÊúâÂõõ‰∏™ÂèÇÊï∞ inXÔºöÈúÄË¶ÅÂàÜÁ±ªÁöÑÂêëÈáè dataSetÔºöËÆ≠ÁªÉÈõÜÁöÑÁâπÂæÅ labelsÔºöËÆ≠ÁªÉÈõÜÁöÑÊ†áÁ≠æ kÔºöÊúÄËøëÈÇªÂ±ÖÁöÑÊï∞ÁõÆ ÊµãËØï‰∏ãÊàë‰ª¨ÂÜôÁöÑÁÆóÊ≥ïÊòØÂê¶Ê≠£Á°ÆÔºåÊàë‰ª¨‰º†ÂÖ•Ôºà0Ôºå0ÔºâÁöÑÁÇπÔºåÊ≠£Á°ÆÁöÑÂàÜÁ±ªÁÇπÂ∫îËØ•ÊòØBÁÇπ 1classify0([0,0], group, labels, 3) &apos;B&apos; ‰ΩøÁî®k-ÈÇªËøëÁÆóÊ≥ïÊîπËøõÁ∫¶‰ºöÁΩëÁ´ôÁöÑÈÖçÂØπÁªìÊûúÁ∫¶‰ºöÁΩëÁ´ôÈÄöËøá‰∏â‰∏™ÁâπÂæÅÊääÊ†∑Êú¨ÂàÜ‰∏∫3Á±ª ÊØèÂπ¥È£ûË°åÈáåÁ®ã Áé©Ê∏∏ÊàèÊ∂àËÄóÁöÑÊó∂Èó¥ÁôæÂàÜÊØî ÊØèÂë®Ê∂àËÄóÁöÑÂÜ∞Ê∑áÊ∑ãÂÖ¨ÂçáÊï∞ Ê†∑Êú¨ÂàÜÁ±ª (largeDoses,smallDoses,didntLike) ÂáÜÂ§áÊï∞ÊçÆÔºö‰ªéÊñáÊú¨Êñá‰ª∂‰∏≠Ëß£ÊûêÊï∞ÊçÆÂÖ±Êúâ1000Ë°åÊï∞ÊçÆÂ≠òÊîæÂú®datingTestSet2.txt‰∏≠ÔºåË°å‰πãÈó¥Áî®\nÂàÜÂâ≤ÔºåÂàó‰πãÈó¥\tÂàÜÂâ≤ÔºåÁé∞Âú®ÈúÄË¶ÅÊääËøô‰∏™Êñá‰ª∂ÈáåÁöÑÊï∞ÊçÆËΩ¨Êç¢‰∏∫‰∏Ä‰∏™ÂêëÈáè 123456789101112131415def file2matrix(filename): fr = open(filename, 'r') arrayOLines = fr.readlines() numberOfLines = len(arrayOLines) returnMat = zeros((numberOfLines, 3)) classLabelVector = [] index = 0 for line in arrayOLines: line = line.strip() listFromLine = line.split('\t') returnMat[index, :] = listFromLine[0: 3] classLabelVector.append(int(listFromLine[-1])) index += 1 fr.close() return returnMat, classLabelVector 1datingDataMat, datingLabels = file2matrix('./MLiA_SourceCode/machinelearninginaction/Ch02/datingTestSet2.txt') 1datingDataMat array([[4.0920000e+04, 8.3269760e+00, 9.5395200e-01], [1.4488000e+04, 7.1534690e+00, 1.6739040e+00], [2.6052000e+04, 1.4418710e+00, 8.0512400e-01], ..., [2.6575000e+04, 1.0650102e+01, 8.6662700e-01], [4.8111000e+04, 9.1345280e+00, 7.2804500e-01], [4.3757000e+04, 7.8826010e+00, 1.3324460e+00]]) 1datingLabels[:20] [3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3] ÂàÜÊûêÊï∞ÊçÆÔºö‰ΩøÁî®matplotlibÁªòÂà∂Êï£ÁÇπÂõæÊï∞ÊçÆ‰ΩøÁî®Á¨¨‰∫åÂàóÂíåÁ¨¨‰∏âÂàóÁöÑÂÄºÂàÜÂà´ÊòØ xËΩ¥ÔºöÁé©Ê∏∏ÊàèÊ∂àËÄóÁöÑÊó∂Èó¥ÁôæÂàÜÊØî yËΩ¥ÔºöÊØèÂë®Ê∂àË¥πÁöÑÂÜ∞Ê∑áÊ∑ãÂÖ¨ÂçáÊï∞ 1234567import matplotlibimport matplotlib.pyplot as pltfig = plt.figure()ax = fig.add_subplot(111)ax.scatter(datingDataMat[:, 1], datingDataMat[:, 2])plt.show() ‰ªé‰∏äÂõæÂæàÈöæÁúãÂà∞ÊúâÁî®ÁöÑ‰ø°ÊÅØÔºåÊàë‰ª¨ÈÄöËøáÈ¢úËâ≤Ê†áËÆ∞‰∏çÂêåÁöÑÊ†∑Êú¨ 1234fig = plt.figure()ax = fig.add_subplot(111)ax.scatter(datingDataMat[:, 1], datingDataMat[:, 2], 15.0*array(datingLabels), 15.0*array(datingLabels))plt.show() Âà©Áî®È¢úËâ≤ÂíåÂ∞∫ÂØ∏Êàë‰ª¨Âü∫Êú¨ÂèØ‰ª•ÁúãÂá∫‰∏âÁßçÊ†∑Êú¨ÁöÑÂå∫ÂüüËΩÆÂªì„ÄÇ ÂáÜÂ§áÊï∞ÊçÆÔºöÂΩí‰∏ÄÂåñÊï∞ÂÄºÊàë‰ª¨ÂèëÁé∞È£ûË°åÈáåÁ®ãÁöÑÊï∞ÂÄºËøúËøúÂ§ß‰∫éÂè¶‰∏§‰∏™Êï∞ÂÄºÔºåËøôÊ†∑Êàë‰ª¨ËÆ°ÁÆóÁöÑÁªìÊûú‰ºöË¢´È£ûË°åÈáåÁ®ã‰∏•ÈáçÂΩ±ÂìçÔºåÊàë‰ª¨ËÆ§‰∏∫‰∏â‰∏™ÁâπÂæÅÊòØÂêåÁ≠âÈáçË¶ÅÁöÑÔºåÊâÄ‰ª•‰Ωú‰∏∫‰∏â‰∏™Á≠âÊùÉÈáçÁöÑÁâπÂæÅÔºåÈ£ûË°åÈáåÁ®ã‰∏çÂ∫îËØ•‰∏•ÈáçÂΩ±ÂìçÁªìÊûú„ÄÇ Âú®Â§ÑÁêÜËøôÁßç‰∏çÂêåÂèñÂÄºËåÉÂõ¥ÁöÑÁâπÂæÅÊó∂ÔºåÊàë‰ª¨ÈúÄË¶ÅÂÖàÂΩí‰∏ÄÂåñÊï∞ÂÄºÔºåÂ∞ÜÊï∞ÂÄºËåÉÂõ¥Â§ÑÁêÜÂà∞0Âà∞1Êàñ-1Âà∞1‰πãÈó¥ÔºåÈÄöÂ∏∏‰ΩøÁî®ÁöÑÂÖ¨ÂºèÊòØ $$newValue = (oldValue-min) / max-min)$$ Á®ãÂ∫èÂ¶Ç‰∏ãÔºö 123456789def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m, 1)) normDataSet = normDataSet/tile(ranges, (m, 1)) return normDataSet, ranges, minVals 1normMat, ranges, minVals = autoNorm(datingDataMat) 1normMat array([[0.44832535, 0.39805139, 0.56233353], [0.15873259, 0.34195467, 0.98724416], [0.28542943, 0.06892523, 0.47449629], ..., [0.29115949, 0.50910294, 0.51079493], [0.52711097, 0.43665451, 0.4290048 ], [0.47940793, 0.3768091 , 0.78571804]]) 1ranges array([9.1273000e+04, 2.0919349e+01, 1.6943610e+00]) 1minVals array([0. , 0. , 0.001156]) ÊµãËØïÁÆóÊ≥ïÔºöÊûÑÂª∫ÂÆåÊï¥Á®ãÂ∫èÈ™åËØÅÂàÜÁ±ªÂô®ÈÄâÊã©90%ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜÔºå10%‰Ωú‰∏∫ÊµãËØïÈõÜÔºåËÆ∞ÂΩïÊØè‰∏ÄÊ¨°ÈîôËØØÁöÑÂàÜÁ±ªÔºåÊúÄÂêéÁî®È¢ÑÊµãÈîôËØØÁöÑÊÄªÊï∞Èô§‰ª•ÊµãËØïÈõÜÊï∞ÊçÆÁöÑÊÄªÊï∞Â∞±ËÆ°ÁÆóÂá∫‰∫ÜÈîôËØØÁéá„ÄÇ 1234567891011121314def datingClassTest(): hoRatio = 0.10 datingDataMat, datingLabels = file2matrix('./MLiA_SourceCode/machinelearninginaction/Ch02/datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify0(normMat[i, :], normMat[numTestVecs:m, :],\ datingLabels[numTestVecs:m], 3) #print("the classifier came back with: %d, the real answer is: %d"% (classifierResult, datingLabels[i])) if classifierResult != datingLabels[i]: errorCount += 1.0 print("the total error rate is: %f"%(errorCount/float(numTestVecs))) 1datingClassTest() the total error rate is: 0.050000 ËøôÈáåËÆ°ÁÆóÂá∫ÁöÑÈîôËØØÁéá‰∏∫5%Ôºå‰π¶‰∏≠ÂÜôÁöÑ‰∏∫2.4%ÔºåÊãÖÂøÉÁÆóÈîôÁî®source codeË∑ë‰∫Ü‰∏ÄÈÅçÈîôËØØÁéá‰∏∫6.6% ‰ΩøÁî®ÁÆóÊ≥ïÔºöÊûÑÂª∫ÂÆåÊï¥ÁöÑÂèØÁî®Á≥ªÁªüÊâãÂÜôËØÜÂà´Á≥ªÁªüÁé∞Âú®ÂºÄÂßãÁ¨¨‰∫å‰∏™Á§∫‰æãÔºåËØÜÂà´ÊâãÂÜôÊï∞Â≠óÔºåÊï∞ÊçÆÂ∑≤ÁªèË¢´ÂõæÂΩ¢ËΩØ‰ª∂Â§ÑÁêÜ‰∏∫ÊñáÊú¨Ê†ºÂºèÔºåÂÖàÊâìÂºÄÂá†‰∏™ËßÇÂØü‰∏Ä‰∏ã 12345def readTrainingDigits(filename): fr = open(filename, 'r') data = fr.read() print(data) fr.close() 123readTrainingDigits('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/trainingDigits/0_0.txt')readTrainingDigits('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/trainingDigits/1_0.txt')readTrainingDigits('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/trainingDigits/2_0.txt') 00000000000001111000000000000000 00000000000011111110000000000000 00000000001111111111000000000000 00000001111111111111100000000000 00000001111111011111100000000000 00000011111110000011110000000000 00000011111110000000111000000000 00000011111110000000111100000000 00000011111110000000011100000000 00000011111110000000011100000000 00000011111100000000011110000000 00000011111100000000001110000000 00000011111100000000001110000000 00000001111110000000000111000000 00000001111110000000000111000000 00000001111110000000000111000000 00000001111110000000000111000000 00000011111110000000001111000000 00000011110110000000001111000000 00000011110000000000011110000000 00000001111000000000001111000000 00000001111000000000011111000000 00000001111000000000111110000000 00000001111000000001111100000000 00000000111000000111111000000000 00000000111100011111110000000000 00000000111111111111110000000000 00000000011111111111110000000000 00000000011111111111100000000000 00000000001111111110000000000000 00000000000111110000000000000000 00000000000011000000000000000000 00000000000000001111000000000000 00000000000000011111111000000000 00000000000000011111111100000000 00000000000000011111111110000000 00000000000000011111111110000000 00000000000000111111111100000000 00000000000000111111111100000000 00000000000001111111111100000000 00000000000000111111111100000000 00000000000000111111111100000000 00000000000000111111111000000000 00000000000001111111111000000000 00000000000011111111111000000000 00000000000111111111110000000000 00000000001111111111111000000000 00000001111111111111111000000000 00000011111111111111110000000000 00000111111111111111110000000000 00000111111111111111110000000000 00000001111111111111110000000000 00000001111111011111110000000000 00000000111100011111110000000000 00000000000000011111110000000000 00000000000000011111100000000000 00000000000000111111110000000000 00000000000000011111110000000000 00000000000000011111110000000000 00000000000000011111111000000000 00000000000000011111111000000000 00000000000000011111111000000000 00000000000000000111111110000000 00000000000000000111111100000000 00000000001111111000000000000000 00000000011111111100000000000000 00000000011111111110000000000000 00000000011111111111100000000000 00000000111111111111100000000000 00000001111111111111110000000000 00000011111110001111110000000000 00000001111110000111111000000000 00000001111110000111111000000000 00000001111110000111111000000000 00000001111100000111111000000000 00000001111110000011111100000000 00000001111111000011111100000000 00000000111111000011111000000000 00000000111110000111111000000000 00000000001110000011111100000000 00000000000000000011111000000000 00000000000000000111110000000000 00000000000000000111111000000000 00000000000000001111110000000000 00000000000000011111110000000000 00000000000000111111100000000000 00000000000000011111110000000000 00000000000000111111100000000000 00000000000001111111000000000000 00000000000011111110000000000000 00000000001111111111111111111000 00000000011111111111111111111100 00000000111111111111111111111100 00000000011111111111111111111100 00000000001111111111111111111100 00000000000111111111111111110000 ËøôÊòØ‰∏Ä‰∏™32√ó32ÁöÑÊï∞Â≠óÁü©ÈòµÂπ∂‰∏îÂèØ‰ª•ÂæàÊòéÊòæÁöÑÁúãÂá∫Êï∞Â≠óÁöÑËΩÆÂªì„ÄÇ ÂáÜÂ§áÊï∞ÊçÆÔºöÂ∞ÜÂõæÂÉèËΩ¨Êç¢‰∏∫ÊµãËØïÂêëÈáèÂ¶Ç‰∏äÊâÄÁ§∫ÔºåÊØè‰∏Ä‰∏™Êñá‰ª∂ÈÉΩÊòØ‰∏Ä‰∏™32√ó32ÊûÑÊàêÁöÑÊï∞Â≠óÁü©ÈòµÔºå‰∏∫‰∫Ü‰ΩøÁî®ÂâçÈù¢ÂÜôÁöÑÂàÜÁ±ªÂô®ÔºåÊàë‰ª¨ÂøÖÈ°ªÂ∞ÜÂõæÂÉèÊ†ºÂºèÂåñÂ§ÑÁêÜ‰∏∫‰∏Ä‰∏™1√ó1024ÁöÑÂêëÈáè 12345678def img2vector(filename): returnVect = zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 12testVector = img2vector('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/testDigits/0_13.txt')testVector[0, 0:31] array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) 1testVector[0, 32:63] array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) ÊµãËØïÁÆóÊ≥ïÔºö‰ΩøÁî®k-ËøëÈÇªÁÆóÊ≥ïËØÜÂà´ÊâãÂÜôÊï∞Â≠ó123456789101112131415161718192021222324252627import osfrom tqdm import trangedef handwritingClassTest(): hwLabels = [] trainingFileList = os.listdir('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/trainingDigits') #load the training set m = len(trainingFileList) trainingMat = zeros((m,1024)) for i in range(m): fileNameStr = trainingFileList[i] fileStr = fileNameStr.split('.')[0] #take off .txt classNumStr = int(fileStr.split('_')[0]) hwLabels.append(classNumStr) trainingMat[i,:] = img2vector('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/trainingDigits/%s' % fileNameStr) testFileList = os.listdir('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/testDigits') #iterate through the test set errorCount = 0.0 mTest = len(testFileList) for i in trange(mTest): fileNameStr = testFileList[i] fileStr = fileNameStr.split('.')[0] #take off .txt classNumStr = int(fileStr.split('_')[0]) vectorUnderTest = img2vector('./MLiA_SourceCode/machinelearninginaction/Ch02/digits/testDigits/%s' % fileNameStr) classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3) #print ("the classifier came back with: %d, the real answer is: %d" % (classifierResult, classNumStr)) if (classifierResult != classNumStr): errorCount += 1.0 print ("\nthe total number of errors is: %d" % errorCount) print ("\nthe total error rate is: %f" % (errorCount/float(mTest))) 1handwritingClassTest() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 946/946 [00:30&lt;00:00, 31.30it/s] the total number of errors is: 10 the total error rate is: 0.010571 ÈîôËØØÁéáÂè™Êúâ1%Ôºå ÊÄªÁªìk-ËøëÈÇªÁÆóÊ≥ïÊòØÂàÜÁ±ªÊï∞ÊçÆÊúÄÁÆÄÂçïÊúâÊïàÁöÑÁÆóÊ≥ïÔºå‰ΩøÁî®ÁÆóÊ≥ïÊó∂Êàë‰ª¨ÂøÖÈ°ªÊúâÊé•ËøëÂÆûÈôÖÊï∞ÊçÆÁöÑËÆ≠ÁªÉÊ†∑Êú¨ÔºåÂøÖÈ°ª‰øùÂ≠òÂÖ®ÈÉ®Êï∞ÊçÆÈõÜÔºåÂ¶ÇÊûúËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂæàÂ§ßÔºåÂøÖÈ°ª‰ΩøÁî®Â§ßÈáèÁöÑÂ≠òÂÇ®Á©∫Èó¥ÔºåÊ≠§Â§ñÔºåÁî±‰∫éÂøÖÈ°ªÂØπÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏™Êï∞ÊçÆËÆ°ÁÆóË∑ùÁ¶ªÂÄºÔºåÂÆûÈôÖ‰ΩøÁî®‰ºöÈùûÂ∏∏ËÄóÊó∂,ÂÆÉÁöÑÂè¶‰∏Ä‰∏™Áº∫Èô∑ÊòØÊó†Ê≥ïÁªôÂá∫‰ªª‰ΩïÊï∞ÊçÆÁöÑÂü∫Êú¨ÁªìÊûÑ‰ø°ÊÅØÔºåÂõ†Ê≠§Êàë‰ª¨Êó†Ê≥ïÁü•ÊôìÂπ≥ÂùáÂÆû‰æãÊ†∑Êú¨ÂíåÂÖ∏ÂûãÂÆû‰æãÊ†∑Êú¨ÂÖ∑‰ΩìÊúâ‰ªÄ‰πàÁâπÂæÅ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†ÂÆûÊàò</category>
      </categories>
      <tags>
        <tag>k-ÈÇªËøëÁÆóÊ≥ï</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django]]></title>
    <url>%2F2020%2F02%2F05%2FDjango%2F</url>
    <content type="text"><![CDATA[Python‰∏ãÊúâËÆ∏Â§öÊ¨æ‰∏çÂêåÁöÑ Web Ê°ÜÊû∂„ÄÇDjangoÊòØÈáçÈáèÁ∫ßÈÄâÊâã‰∏≠ÊúÄÊúâ‰ª£Ë°®ÊÄßÁöÑ‰∏Ä‰Ωç„ÄÇËÆ∏Â§öÊàêÂäüÁöÑÁΩëÁ´ôÂíåAPPÈÉΩÂü∫‰∫éDjango„ÄÇ DjangoÊòØ‰∏Ä‰∏™ÂºÄÊîæÊ∫ê‰ª£Á†ÅÁöÑWebÂ∫îÁî®Ê°ÜÊû∂ÔºåÁî±PythonÂÜôÊàê„ÄÇ DjangoÈááÁî®‰∫ÜMVCÁöÑËΩØ‰ª∂ËÆæËÆ°Ê®°ÂºèÔºåÂç≥Ê®°ÂûãMÔºåËßÜÂõæVÂíåÊéßÂà∂Âô®C„ÄÇ DjangoÁöÑÂÆâË£Ö12345pip install Django&gt;&gt;&gt; import django&gt;&gt;&gt; django.VERSION(2, 1, 7, 'final', 0) ÂàõÂª∫Â∑•Á®ãÂÆâË£ÖÂÆådjangoÂêéÊàë‰ª¨‰ºöÊúâ‰∏Ä‰∏™ django-adminÁöÑÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåÊàë‰ª¨‰ΩøÁî®Ê≠§Â∑•ÂÖ∑Êù•ÂàõÂª∫Â∑•Á®ã„ÄÇ 12345678910django-admin startproject projectname$ cd projectname/$ tree.|-- projectname| |-- __init__.py| |-- settings.py| |-- urls.py| `-- wsgi.py`-- manage.py ÁõÆÂΩïËØ¥ÊòéÔºö projectname: È°πÁõÆÁöÑÂÆπÂô®„ÄÇ manage.py: ‰∏Ä‰∏™ÂÆûÁî®ÁöÑÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑ÔºåÂèØËÆ©‰Ω†‰ª•ÂêÑÁßçÊñπÂºè‰∏éËØ• Django È°πÁõÆËøõË°å‰∫§‰∫í„ÄÇ __init__.py: ‰∏Ä‰∏™Á©∫Êñá‰ª∂ÔºåÂëäËØâ Python ËØ•ÁõÆÂΩïÊòØ‰∏Ä‰∏™ Python ÂåÖ„ÄÇ settings.py: ËØ• Django È°πÁõÆÁöÑËÆæÁΩÆ/ÈÖçÁΩÆ„ÄÇ urls.py: ËØ• Django È°πÁõÆÁöÑ URL Â£∞Êòé; ‰∏Ä‰ªΩÁî± Django È©±Âä®ÁöÑÁΩëÁ´ô&quot;ÁõÆÂΩï&quot;„ÄÇ wsgi.py: ‰∏Ä‰∏™ WSGI ÂÖºÂÆπÁöÑ Web ÊúçÂä°Âô®ÁöÑÂÖ•Âè£Ôºå‰ª•‰æøËøêË°å‰Ω†ÁöÑÈ°πÁõÆ„ÄÇ Êé•‰∏ãÊù•Êàë‰ª¨ËøõÂÖ• projectname ÁõÆÂΩïËæìÂÖ•‰ª•‰∏ãÂëΩ‰ª§ÔºåÂêØÂä®ÊúçÂä°Âô®Ôºö python manage.py runserver 0.0.0.0:8000 0.0.0.0 ËÆ©ÂÖ∂ÂÆÉÁîµËÑëÂèØËøûÊé•Âà∞ÂºÄÂèëÊúçÂä°Âô®Ôºå8000 ‰∏∫Á´ØÂè£Âè∑„ÄÇÂ¶ÇÊûú‰∏çËØ¥ÊòéÔºåÈÇ£‰πàÁ´ØÂè£Âè∑ÈªòËÆ§‰∏∫ 8000„ÄÇ Âú®ÊµèËßàÂô®ËæìÂÖ•‰Ω†ÊúçÂä°Âô®ÁöÑ ipÔºàËøôÈáåÊàë‰ª¨ËæìÂÖ•Êú¨Êú∫ IP Âú∞ÂùÄÔºö 127.0.0.1:8000Ôºâ ÂèäÁ´ØÂè£Âè∑ÔºåÂ¶ÇÊûúÊ≠£Â∏∏ÂêØÂä®Ôºå‰ºöÊâìÂºÄdjangoÈªòËÆ§È°µÈù¢„ÄÇ ÂàõÂª∫ APPpython manage.py startapp Â∫îÁî®Âêç Êñ∞Âª∫‰∏Ä‰∏™Â∫îÁî®Êñá‰ª∂appnameÔºåÂÆÉÁöÑÈáåÈù¢‰πüÂàõÂª∫‰∫Ü‰∏Ä‰∫õpyÊñá‰ª∂ÂíåÂåÖÔºö 1234567891011python manage.py startapp appname.|-- appname| |-- __init__.py| |-- admin.py| |-- apps.py| |-- migrations| |-- models.py| |-- test.py| |-- views.py| |-- urls.py ‰∏ãÈù¢‰ªãÁªçËøô‰∫õÊñá‰ª∂ÈÉΩÊòØ‰ªÄ‰πàÔºö admin.pyÔºöÁÆ°ÁêÜÁ´ôÁÇπÊ®°ÂûãÁöÑÂ£∞ÊòéÊñá‰ª∂ÔºåÈªòËÆ§‰∏∫Á©∫„ÄÇ apps.pyÔºöÂ∫îÁî®‰ø°ÊÅØÂÆö‰πâÊñá‰ª∂„ÄÇÂú®ÂÖ∂‰∏≠ÁîüÊàê‰∫ÜÁ±ªAppconfigÔºåÁ±ªÁî®‰∫éÂÆö‰πâÂ∫îÁî®ÂêçÁ≠âMetaÊï∞ÊçÆ„ÄÇ migrations: Áî®‰∫éÂú®‰πãÂêéÂÆö‰πâÂºïÁî®ËøÅÁßªÂäüËÉΩ„ÄÇ models.py: Ê∑ªÂä†Ê®°ÂûãÂ±ÇÊï∞ÊçÆÁ±ªÁöÑÊñá‰ª∂„ÄÇ test.pyÔºöÊµãËØï‰ª£Á†ÅÊñá‰ª∂„ÄÇ views.pyÔºöÂÆö‰πâURLÂìçÂ∫îÂáΩÊï∞„ÄÇ urls.pyÔºöÈúÄË¶ÅËá™Â∑±ÂàõÂª∫Ôºå‰Ωú‰∏∫Â≠êË∑ØÁî±„ÄÇ ÂàõÂª∫Â•ΩappÂêéÂú®settings.py‰∏≠ÁöÑINSTALLED_APPSÊ∑ªÂä†appname 123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'appname',] ÁΩëÈ°µÂíåÈùôÊÄÅÊñá‰ª∂Âú®appname‰∏≠Êñ∞Âª∫‰∏Ä‰∏™templatesÊñá‰ª∂Â§πÂ≠òÊîæhtml Êñ∞Âª∫staticÊñá‰ª∂Â§πÂ≠òÊîæjsÔºåimageÔºåcssÁ≠â Âπ∂‰∏îÂú®settings.py‰∏≠Ê∑ªÂä†ÈùôÊÄÅÊñá‰ª∂ÁõÆÂΩï1234STATIC_URL = '/static/'STATICFILES_DIRS = [ os.path.join(BASE_DIR, "static"),] Ê≥®ÊÑèÔºöÊØè‰∏Ä‰∏™app‰∏≠ÁöÑstaticËÆøÈóÆË∑ØÂæÑÈÉΩÊòØÁõ∏ÂêåÁöÑ„ÄÇ Âú®html‰∏≠ÁöÑ‰ΩøÁî®Ôºö 12345678È¶ñÂÖàÂàõÂª∫‰∫Ü‰∏Ä‰∏™cssÊñá‰ª∂appname/static/js/style.cssÂ¶Ç‰Ωï‰ΩøÁî®Ôºåappname/templates/index.htmlÈáåÊ∑ªÂä†‰∏ãÈù¢‰ª£Á†ÅÔºö&#123;% load staticfiles %&#125; &lt;link rel="stylesheet" type="text/css" href="&#123;% static 'js/style.css' %&#125;" /&gt; Ê∑ªÂä†ËÑöÊú¨ÁõÆÂΩïÊàë‰ª¨Êúâ‰∏Ä‰∫õËÑöÊú¨ÂÜôÂú®Âè¶‰∏Ä‰∏™Êñá‰ª∂Â§πÔºåÊàë‰ª¨Â∏åÊúõÂºïÂÖ•ÂÆÉ‰ª¨ÔºåÂú®settings.py‰∏≠Ê∑ªÂä†12import syssys.path.insert(0, os.path.join(BASE_DIR, '/home/Scripts')) Êï∞ÊçÆÂ∫ìÁõ∏ÂÖ≥ÈÉ®ÁΩ≤ÈùôÊÄÅÊñá‰ª∂Êî∂ÈõÜÈùôÊÄÅÊñá‰ª∂python manage.py collectstatic Ëøô‰∏ÄÂè•ËØùÂ∞±‰ºöÊää‰ª•ÂâçÊîæÂú®app‰∏ãstatic‰∏≠ÁöÑÈùôÊÄÅÊñá‰ª∂ÂÖ®ÈÉ®Êã∑Ë¥ùÂà∞ settings.py ‰∏≠ËÆæÁΩÆÁöÑ STATIC_ROOT Êñá‰ª∂Â§π‰∏≠ Áî®UWSGIÈÉ®ÁΩ≤uWSGIÊòØ‰∏Ä‰∏™WebÊúçÂä°Âô®ÔºåÂÆÉÂÆûÁé∞‰∫ÜWSGIÂçèËÆÆ„ÄÅuwsgi„ÄÅhttpÁ≠âÂçèËÆÆ„ÄÇNginx‰∏≠HttpUwsgiModuleÁöÑ‰ΩúÁî®ÊòØ‰∏éuWSGIÊúçÂä°Âô®ËøõË°å‰∫§Êç¢„ÄÇ Ë¶ÅÊ≥®ÊÑè WSGI / uwsgi / uWSGI Ëøô‰∏â‰∏™Ê¶ÇÂøµÁöÑÂå∫ÂàÜ„ÄÇ WSGIÊòØ‰∏ÄÁßçÈÄö‰ø°ÂçèËÆÆ„ÄÇ uwsgiÊòØ‰∏ÄÁßçÁ∫øË∑ØÂçèËÆÆËÄå‰∏çÊòØÈÄö‰ø°ÂçèËÆÆÔºåÂú®Ê≠§Â∏∏Áî®‰∫éÂú®uWSGIÊúçÂä°Âô®‰∏éÂÖ∂‰ªñÁΩëÁªúÊúçÂä°Âô®ÁöÑÊï∞ÊçÆÈÄö‰ø°„ÄÇ ËÄåuWSGIÊòØÂÆûÁé∞‰∫ÜuwsgiÂíåWSGI‰∏§ÁßçÂçèËÆÆÁöÑWebÊúçÂä°Âô®„ÄÇ uwsgiÂçèËÆÆÊòØ‰∏Ä‰∏™uWSGIÊúçÂä°Âô®Ëá™ÊúâÁöÑÂçèËÆÆÔºåÂÆÉÁî®‰∫éÂÆö‰πâ‰º†Ëæì‰ø°ÊÅØÁöÑÁ±ªÂûãÔºàtype of informationÔºâÔºåÊØè‰∏Ä‰∏™uwsgi packetÂâç4byte‰∏∫‰º†Ëæì‰ø°ÊÅØÁ±ªÂûãÊèèËø∞ÔºåÂÆÉ‰∏éWSGIÁõ∏ÊØîÊòØ‰∏§Ê†∑‰∏úË•ø„ÄÇ uwsgiÂÆâË£ÖÂëΩ‰ª§ 1sudo pip install uwsgi --upgrade uwsgi.iniÈÖçÁΩÆÊñá‰ª∂ÁºñÂÜô 123456789101112131415[uwsgi]http-socket = 0.0.0.0:80 # IPÂú∞ÂùÄ‰∏éÁ´ØÂè£Âè∑chdir = /home/user/myProject/ # DjangoÂ∑•Á®ãÁöÑÁõÆÂΩïvirtualenv = /home/user/pyvenv/env3.7 # pythonËôöÊãüÁéØÂ¢ÉÁõÆÂΩïwsgi-file = myProject/wsgi.py # wsgi.pyÁöÑ‰ΩçÁΩÆÔºåÊé•Âú®chdirÂêéÈù¢static-map = /static=/home/user/myProject/static # ÈùôÊÄÅÊñá‰ª∂ÁöÑ‰ΩçÁΩÆenable-threads = true # ÂÖÅËÆ∏Âú®djangoÂàõÂª∫Á∫øÁ®ãauto-procname = true # Ëá™Âä®ÁªôËøõÁ®ãËµ∑ÂêçÂ≠ódaemonize = /home/user/log/uwsgi.log # logÂú∞ÂùÄpidfile = /home/user/myProject/uwsgi.pid # ‰øùÂ≠ò‰∏ªËøõÁ®ãpidÁöÑÊñá‰ª∂disable-logging = true # logÂè™ËÆ∞ÂΩïÈîôËØØ‰ø°ÊÅØbuffer-size = 51200 # ÂÖÅËÆ∏‰º†ËæìÁöÑÂ≠óËäÇÊï∞processes = 4 # ËøõÁ®ãÊï∞threads = 2 # Á∫øÁ®ãÊï∞vacuum = true # ÂÖÅËÆ∏‰∏ªËøõÁ®ã ÂÖ≥Èó≠Âè™ËÉΩÂÖ≥Èó≠pidfileÈáåËÆ∞ÂΩïÁöÑpidÂè∑Ôºå‰∏çËÉΩkillÂÖ∂ÂÆÉ‰∏â‰∏™ËøõÁ®ã 123uwsgi --ini uwsgi.ini # ÂêØÂä®uwsgi --reload uwsgi.pid # ÈáçÂêØuwsgi --stop uwsgi.pid # ÂÖ≥Èó≠ ÈÉ®ÁΩ≤Âà∞ÊúçÂä°Âô®Áî® apache2 Êàñ nginx Á§∫‰æã‰ª£Á†Å apache2ÈÖçÁΩÆÊñá‰ª∂12345Alias /static/ /path/to/collected_static/ &lt;Directory /path/to/collected_static&gt; Require all granted&lt;/Directory&gt; nginx Á§∫‰æã‰ª£Á†ÅÔºö1234567location /media &#123; alias /path/to/project/media;&#125; location /static &#123; alias /path/to/project/collected_static;&#125;]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Aerial Cactus Identification]]></title>
    <url>%2F2020%2F01%2F10%2FAerialCactusIdentification%2F</url>
    <content type="text"><![CDATA[‰ªô‰∫∫ÊéåËØÜÂà´To assess the impact of climate change on Earth‚Äôs flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the VIGIA project, which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery. https://www.kaggle.com/c/aerial-cactus-identification 1234567891011121314# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to load in import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the "../input/" directory.# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directoryimport osprint(os.listdir("../input"))# Any results you write to the current directory are saved as output. [&apos;aerial-cactus-identification&apos;] 123from tqdm import tqdm, tqdm_notebookimport cv2import seaborn as sns 12345678from keras import layersfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2Dfrom keras.models import Model, load_modelfrom keras.utils import layer_utilsfrom keras.utils.data_utils import get_filefrom keras.applications.imagenet_utils import preprocess_inputfrom keras.initializers import glorot_uniformfrom keras import optimizers imge È¢ÑÂ§ÑÁêÜÂä†ËΩΩÊï∞ÊçÆÈõÜÈ¶ñÂÖàËß£ÂéãÂõæÁâáÊï∞ÊçÆ 1234567import zipfileDataset = "aerial-cactus-identification"with zipfile.ZipFile("../input/"+Dataset+"/train.zip","r") as z: z.extractall(".")with zipfile.ZipFile("../input/"+Dataset+"/test.zip","r") as z: z.extractall(".") 1print(os.listdir("./")) [&apos;train&apos;, &apos;test&apos;, &apos;__notebook_source__.ipynb&apos;] 123train_path = './train/'test_path = "./test/"train_csv = pd.read_csv('../input/aerial-cactus-identification/train.csv') ÊääÂõæÁâáËΩ¨Êç¢‰∏∫Áü©Èòµ12345678labels = []images = []image_name = train_csv['id'].valuesfor img_id in tqdm_notebook(image_name): imdata = cv2.imread(train_path + img_id) images.append(imdata) has_cactus = train_csv[train_csv['id'] == img_id]['has_cactus'].values labels.append(has_cactus) HBox(children=(IntProgress(value=0, max=17500), HTML(value=&apos;&apos;))) 1labels[0:10] [array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([1]), array([1])] ÁîªÂá∫ÂõæÁâáËßÇÂØü‰∏Ä‰∏ãÔºåÁ¨¨1Ôºå2‰∏™ÂõæÁâáÊúâ‰ªô‰∫∫ÊéåÔºåÁ¨¨7‰∏™ÂõæÁâáÊ≤°Êúâ„ÄÇ 12345import matplotlib.pyplot as pltfig, ax = plt.subplots(1, 3)ax[0].imshow(images[0])ax[1].imshow(images[1])ax[2].imshow(images[6]) Êï∞ÂÄºÂΩí‰∏ÄÂåñ 1234images = np.asarray(images)images = images.astype('float32')images /= 255labels = np.asarray(labels) 1images.shape, labels.shape ((17500, 32, 32, 3), (17500, 1)) ÁîªÂá∫ÊúâÊó†‰ªô‰∫∫ÊéåÂõæÁâáÊù°ÂΩ¢Âõæ 1sns.countplot(np.squeeze(labels)) ÊûÑÂª∫Ê®°Âûã1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# GRADED FUNCTION: identity_blockdef identity_block(X, f, filters, stage, block): """ Implementation of the identity block as defined in Figure 3 Arguments: X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev) f -- integer, specifying the shape of the middle CONV's window for the main path filters -- python list of integers, defining the number of filters in the CONV layers of the main path stage -- integer, used to name the layers, depending on their position in the network block -- string/character, used to name the layers, depending on their position in the network Returns: X -- output of the identity block, tensor of shape (n_H, n_W, n_C) """ # defining name basis conv_name_base = 'res' + str(stage) + block + '_branch' bn_name_base = 'bn' + str(stage) + block + '_branch' # Retrieve Filters F1, F2, F3 = filters # Save the input value. You'll need this later to add back to the main path. X_shortcut = X # First component of main path X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X) X = Activation('relu')(X) ### START CODE HERE ### # Second component of main path (‚âà3 lines) X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = "same", name = conv_name_base + "2b", kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + "2b")(X) X = Activation("relu")(X) # Third component of main path (‚âà2 lines) X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = "valid", name = conv_name_base + "2c", kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + "2c")(X) # Final step: Add shortcut value to main path, and pass it through a RELU activation (‚âà2 lines) X = Add()([X, X_shortcut]) X = Activation("relu")(X) ### END CODE HERE ### return X 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# GRADED FUNCTION: convolutional_blockdef convolutional_block(X, f, filters, stage, block, s = 2): """ Implementation of the convolutional block as defined in Figure 4 Arguments: X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev) f -- integer, specifying the shape of the middle CONV's window for the main path filters -- python list of integers, defining the number of filters in the CONV layers of the main path stage -- integer, used to name the layers, depending on their position in the network block -- string/character, used to name the layers, depending on their position in the network s -- Integer, specifying the stride to be used Returns: X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C) """ # defining name basis conv_name_base = 'res' + str(stage) + block + '_branch' bn_name_base = 'bn' + str(stage) + block + '_branch' # Retrieve Filters F1, F2, F3 = filters # Save the input value X_shortcut = X ##### MAIN PATH ##### # First component of main path X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X) X = Activation('relu')(X) ### START CODE HERE ### # Second component of main path (‚âà3 lines) X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + "2b", kernel_initializer = glorot_uniform(seed=0), padding = "same")(X) X = BatchNormalization(axis = 3, name = bn_name_base + "2b")(X) X = Activation("relu")(X) # Third component of main path (‚âà2 lines) X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + "2c", kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + "2c")(X) ##### SHORTCUT PATH #### (‚âà2 lines) X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), name = conv_name_base + "1", kernel_initializer = glorot_uniform(seed=0))(X_shortcut) X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + "1")(X_shortcut) # Final step: Add shortcut value to main path, and pass it through a RELU activation (‚âà2 lines) X = Add()([X, X_shortcut]) X = Activation("relu")(X) ### END CODE HERE ### return X 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# GRADED FUNCTION: ResNet50def ResNet50(input_shape = (32, 32, 3), classes = 1): """ Implementation of the popular ResNet50 the following architecture: CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; CONVBLOCK -&gt; IDBLOCK*3 -&gt; CONVBLOCK -&gt; IDBLOCK*5 -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; AVGPOOL -&gt; TOPLAYER Arguments: input_shape -- shape of the images of the dataset classes -- integer, number of classes Returns: model -- a Model() instance in Keras """ # Define the input as a tensor with shape input_shape X_input = Input(input_shape) # Zero-Padding X = ZeroPadding2D((3, 3))(X_input) # Stage 1 X = Conv2D(32, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = 'bn_conv1')(X) X = Activation('relu')(X) X = MaxPooling2D((3, 3), strides=(2, 2))(X) # Stage 2 X = convolutional_block(X, f = 3, filters = [32, 32, 256], stage = 2, block='a', s = 1) X = identity_block(X, 3, [32, 32, 256], stage=2, block='b') ### START CODE HERE ### # Stage 3 (‚âà4 lines) X = convolutional_block(X, f = 3, filters = [64, 64, 512], stage = 3, block = "a", s = 2) X = identity_block(X, f = 3, filters = [64, 64, 512], stage = 3, block = "b") # Stage 4 (‚âà6 lines) X = convolutional_block(X, f = 3, filters = [128, 128, 1024], stage = 4, block = "a", s = 2) X = identity_block(X, f = 3, filters = [128, 128, 1024], stage = 4, block = "b") # Stage 5 (‚âà3 lines) X = convolutional_block(X, f = 3, filters = [256, 256, 2048], stage = 5, block = "a", s = 2) # AVGPOOL (‚âà1 line). Use "X = AveragePooling2D(...)(X)" #X = AveragePooling2D((2, 2), name = "ave_pool")(X) ### END CODE HERE ### # output layer X = Flatten()(X) X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X) # Create model model = Model(inputs = X_input, outputs = X, name='ResNet50') return model 1model = ResNet50() 1model.summary() _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 30, 30, 32) 896 _________________________________________________________________ conv2d_2 (Conv2D) (None, 28, 28, 32) 9248 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 12, 12, 64) 18496 _________________________________________________________________ conv2d_4 (Conv2D) (None, 10, 10, 64) 36928 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ flatten_2 (Flatten) (None, 1600) 0 _________________________________________________________________ dense_1 (Dense) (None, 512) 819712 _________________________________________________________________ dense_2 (Dense) (None, 1) 513 ================================================================= Total params: 885,793 Trainable params: 885,793 Non-trainable params: 0 _________________________________________________________________ ÂºÄÂßãÈ¢ÑÊµã123model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc']) 12345hist = model.fit(images, labels, validation_split=0.2, batch_size=100, epochs = 20, ) Train on 14000 samples, validate on 3500 samples Epoch 1/20 14000/14000 [==============================] - 4s 316us/step - loss: 0.3205 - acc: 0.8562 - val_loss: 0.2419 - val_acc: 0.9023 Epoch 2/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.1864 - acc: 0.9275 - val_loss: 0.1531 - val_acc: 0.9431 Epoch 3/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.1672 - acc: 0.9336 - val_loss: 0.1459 - val_acc: 0.9429 Epoch 4/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.1520 - acc: 0.9414 - val_loss: 0.1198 - val_acc: 0.9563 Epoch 5/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.1383 - acc: 0.9474 - val_loss: 0.1515 - val_acc: 0.9437 Epoch 6/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.1271 - acc: 0.9528 - val_loss: 0.1026 - val_acc: 0.9649 Epoch 7/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.1176 - acc: 0.9560 - val_loss: 0.1102 - val_acc: 0.9611 Epoch 8/20 14000/14000 [==============================] - 1s 76us/step - loss: 0.1113 - acc: 0.9574 - val_loss: 0.0971 - val_acc: 0.9663 Epoch 9/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.1046 - acc: 0.9626 - val_loss: 0.0826 - val_acc: 0.9729 Epoch 10/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.1002 - acc: 0.9626 - val_loss: 0.0854 - val_acc: 0.9700 Epoch 11/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.0928 - acc: 0.9646 - val_loss: 0.0860 - val_acc: 0.9700 Epoch 12/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.0869 - acc: 0.9683 - val_loss: 0.2181 - val_acc: 0.9163 Epoch 13/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.0829 - acc: 0.9694 - val_loss: 0.0929 - val_acc: 0.9663 Epoch 14/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.0793 - acc: 0.9705 - val_loss: 0.0618 - val_acc: 0.9814 Epoch 15/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.0737 - acc: 0.9731 - val_loss: 0.0687 - val_acc: 0.9777 Epoch 16/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.0718 - acc: 0.9738 - val_loss: 0.0578 - val_acc: 0.9823 Epoch 17/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.0671 - acc: 0.9750 - val_loss: 0.0616 - val_acc: 0.9786 Epoch 18/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.0620 - acc: 0.9784 - val_loss: 0.1049 - val_acc: 0.9626 Epoch 19/20 14000/14000 [==============================] - 1s 75us/step - loss: 0.0612 - acc: 0.9771 - val_loss: 0.0627 - val_acc: 0.9791 Epoch 20/20 14000/14000 [==============================] - 1s 74us/step - loss: 0.0592 - acc: 0.9780 - val_loss: 0.0547 - val_acc: 0.9834 1hist.history.keys() dict_keys([&apos;val_loss&apos;, &apos;val_acc&apos;, &apos;loss&apos;, &apos;acc&apos;]) 1234567891011121314151617import matplotlib.pyplot as plt# summarize history for accuracyplt.plot(hist.history['acc'])plt.plot(hist.history['val_acc'])plt.title('model accuracy')plt.ylabel('accuracy')plt.xlabel('epoch')plt.legend(['train', 'test'], loc='upper left')plt.show()# summarize history for lossplt.plot(hist.history['loss'])plt.plot(hist.history['val_loss'])plt.title('model loss')plt.ylabel('loss')plt.xlabel('epoch')plt.legend(['train', 'test'], loc='upper left')plt.show() È¢ÑÊµã12345678test = []test_id = []for img_id in tqdm_notebook(os.listdir(test_path)): test.append(cv2.imread(test_path + img_id)) test_id.append(img_id)test = np.asarray(test)test = test.astype('float32')test /= 255 1test_predictions = model.predict(test) 12345678sub_df = pd.DataFrame(test_predictions, columns=['has_cactus'])sub_df['has_cactus'] = sub_df['has_cactus'].apply(lambda x: 1 if x &gt; 0.75 else 0)sub_df['id'] = ''cols = sub_df.columns.tolist()cols = cols[-1:] + cols[:-1]sub_df=sub_df[cols]for i, img in enumerate(test_id): sub_df.set_value(i,'id',img) 1sns.countplot(sub_df['has_cactus']) 1sub_df.to_csv('submission.csv',index=False) ÂæóÂàÜPublic Score 0.9583 ÁÆÄÂçïÁöÑÊ®°Âûã1234567891011121314151617#modelfrom keras import modelsmodel = models.Sequential() model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) model.add(layers.Conv2D(32, (3, 3), activation='relu'))model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Flatten()) model.add(layers.Dense(512, activation='relu')) model.add(layers.Dense(1, activation='sigmoid'))]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>Kaggle</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂüÉÂèäÂàÜÊï∞]]></title>
    <url>%2F2019%2F12%2F23%2F%E5%9F%83%E5%8F%8A%E5%88%86%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Âú®ÁúãÁßëÊôÆËßÜÈ¢ëÁöÑÊó∂ÂÄôÂ≠¶Âà∞‰∫ÜÂüÉÂèäÂàÜÊï∞ÂíåË¥™Â©™ÁÆóÊ≥ïÔºåËøôÈáåÁî®codeÂÆûÁé∞‰∏Ä‰∏ã„ÄÇ ÂüÉÂèäÂàÜÊï∞Âè§ÂüÉ‰∫∫‰ΩøÁî®ÁöÑÊòØË±°ÂΩ¢ÊñáÂ≠óÔºå‰ªñ‰ª¨Áî®ËøôÊ†∑ÁöÑÁ¨¶Âè∑Ë°®Á§∫ÂàÜÊï∞ ‰ªñ‰ª¨Âú®ÂúàÂúà‰∏ãÈù¢ÁîªÂá†‰∏™Á´ñÁ∫ø‰ª£Ë°®Âá†ÂàÜ‰πã‰∏ÄÔºåËøòÊúâÂá†‰∏™ËßÑÂÆöÂ•ΩÁöÑÂàÜÊï∞ÊúâÁâπÊÆäÁöÑÁ¨¶Âè∑ÔºåÂàÜÊï∞ÊúâÊó†Êï∞Â§ö‰∏™Ôºå‰∏çÂèØËÉΩÁªôÊâÄÊúâÂàÜÊï∞ÈÉΩÁîª‰∏äÁ¨¶Âè∑ÔºåÊâÄ‰ª•Âè§ÂüÉÂèä‰∫∫Êää‰ªªÊÑèÂàÜÊï∞ÈÉΩË°®Á§∫‰∏∫‰∏çÂêåÁöÑÂçï‰ΩçÂàÜÊï∞ÁöÑÂíåÔºåÂ∞±ÊòØÂàÜÂ≠ê‰∏∫1ÔºåÂàÜÊØç‰∏∫ÂêÑ‰∏çÁõ∏ÂêåÁöÑÊ≠£Êï¥Êï∞„ÄÇ‰ªª‰ΩïÊ≠£ÊúâÁêÜÊï∞ÈÉΩËÉΩË°®ËææÊàêËøô‰∏Ä‰∏™ÂΩ¢Âºè„ÄÇ ‰æãÂ¶ÇÔºö $1=\frac12+\frac13+\frac16$ 1ËøòÂèØ‰ª•Ë°®Á§∫‰∏∫Ôºö $1=\frac12+\frac13+\frac19+\frac1{18}$ Êé•‰∏ã‰ΩøÁî®Ë¥™Â©™ÁÆóÊ≥ïÊù•ÁîüÊàê‰ªªÊÑè‰∏Ä‰∏™Ê≠£ÊúâÁêÜÊï∞ÁöÑÂüÉÂèäÂàÜÊï∞ÂΩ¢Âºè„ÄÇ Ë¥™Â©™ÁÆóÊ≥ïË¥™Â©™ÁÆóÊ≥ïÔºöÂ∞Ü‰∏ÄÈ°πÂàÜÊï∞ÂàÜËß£ÊàêËã•Âπ≤È°πÂçïÂàÜÂ≠êÂàÜÊï∞ÂêéÁöÑÈ°πÊï∞ÊúÄÂ∞ëÔºåÁß∞‰∏∫Á¨¨‰∏ÄÁßçÂ•ΩÁÆóÊ≥ïÔºõÊúÄÂ§ßÁöÑÂàÜÊØçÊï∞ÂÄºÊúÄÂ∞èÔºåÁß∞‰∏∫Á¨¨‰∫åÁßçÂ•ΩÁÆóÊ≥ï„ÄÇ ‰æãÂ¶ÇÔºö ${\displaystyle {\frac {2}{7}}={\frac {1}{4}}+{\frac {1}{28}}}$„ÄÇÂÖ±2È°πÔºåÊòØÁ¨¨‰∏ÄÁßçÂ•ΩÁÆóÊ≥ïÔºåÊØî${\displaystyle {\frac {2}{7}}={\frac {1}{5}}+{\frac {1}{20}}+{\frac {1}{28}}}$ÁöÑÈ°πÊï∞Ë¶ÅÂ∞ë„ÄÇ Âèà‰æãÂ¶ÇÔºå${\displaystyle {\frac {5}{121}}={\frac {1}{33}}+{\frac {1}{121}}+{\frac {1}{363}}}ÊØî {\displaystyle {\frac {5}{121}}={\frac {1}{25}}+{\frac {1}{759}}+{\frac {1}{208725}}}$ ÁöÑÊúÄÂ§ßÂàÜÊØçË¶ÅÂ∞èÔºåÊâÄ‰ª•ÊòØÁ¨¨‰∫åÁßçÂ•ΩÁÆóÊ≥ï„ÄÇ ÊâæÂá∫‰ªÖÂ∞è‰∫é${\displaystyle r={\frac {a}{b}}}$ÁöÑÊúÄÂ§ßÂçï‰ΩçÂàÜÊï∞„ÄÇËøô‰∏™ÂàÜÊï∞ÁöÑÂàÜÊØçÁöÑËÆ°ÁÆóÊñπÊ≥ïÊòØÔºöÂç≥Áî®${\displaystyle b}$Èô§‰ª•${\displaystyle a}$ÔºåËàçÂéª‰ΩôÊï∞ÔºåÂÜçÂä†1„ÄÇÔºàÂ¶ÇÊûúÊ≤°Êúâ‰ΩôÊï∞ÔºåÂàô${\displaystyle r}$Â∑≤ÊòØÂçï‰ΩçÂàÜÊï∞„ÄÇÔºâÊää${\displaystyle r}$ÂáèÂéªÂçï‰ΩçÂàÜÊï∞Ôºå‰ª•Ëøô‰∏™Êñ∞ÁöÑ„ÄÅÊõ¥Â∞èÁöÑ${\displaystyle r}$ÈáçÂ§çÊ≠•È™§1„ÄÇ ‰æãÂ≠êÔºöÊää${\displaystyle {\frac {19}{20}}}$ËΩ¨ÊàêÂçï‰ΩçÂàÜÊï∞„ÄÇ ${\displaystyle \lfloor 20\div 19\rfloor =1}$ÔºåÊâÄ‰ª•Á¨¨1‰∏™Âçï‰ΩçÂàÜÊï∞ÊòØ${\frac {1}{2}}$Ôºõ ${\displaystyle {\frac {19}{20}}-{\frac {1}{2}}={\frac {9}{20}}}$Ôºõ ${\displaystyle \lfloor 20\div 9\rfloor =2}$ÔºåÊâÄ‰ª•Á¨¨2‰∏™Âçï‰ΩçÂàÜÊï∞ÊòØ${\displaystyle {\frac {1}{3}}}$Ôºõ ${\displaystyle {\frac {9}{20}}-{\frac {1}{3}}={\frac {7}{60}}}$Ôºõ ${\displaystyle \lfloor 60\div 7\rfloor =8}$ÔºåÊâÄ‰ª•Á¨¨3‰∏™Âçï‰ΩçÂàÜÊï∞ÊòØ${\displaystyle {\frac {1}{9}}}$Ôºõ ${\displaystyle {\frac {7}{60}}-{\frac {1}{9}}={\frac {1}{180}}}$Â∑≤ÊòØÂçï‰ΩçÂàÜÊï∞„ÄÇ ÊâÄ‰ª•ÁªìÊûúÊòØÔºö${\displaystyle {\frac {19}{20}}={\frac {1}{2}}+{\frac {1}{3}}+{\frac {1}{9}}+{\frac {1}{180}}}$„ÄÇ ‰ª£Á†ÅÂÆûÁé∞123456789101112131415161718192021222324252627282930313233343536# ÂØªÊâæÊúÄÂ§ßÂÖ¨Á∫¶Êï∞def _gcd(a, b): # Supports non-integers for backward compatibility. while b: a, b = b, a%b return a# Á∫¶ÂàÜdef ReduceFraction(numerator, denominator): if type(numerator) is int is type(denominator): g = _gcd(numerator, denominator) if denominator &lt; 0: g = -g else: g = _gcd(numerator, denominator) numerator //= g denominator //= g return (numerator, denominator)# ÂàÜÊï∞ÂáèÊ≥ïdef SubFraction(a, b): an, ad = a bn, bd = b numerator = an*bd - ad*bn denominator = ad * bd return ReduceFraction(numerator, denominator)# ÂüÉÂèäÂàÜÊï∞ÁîüÊàêÂô®ËøîÂõûÂàÜÊØçÁöÑlistdef EgpytFraction(numerator=0, denominator=None, ret=[]): a = (denominator // numerator) + 1 ret.append(a) t = SubFraction((numerator, denominator), (1, a)) if t[0] == 1: ret.append(t[1]) return ret return EgpytFraction(t[0], t[1], ret=ret) EgpytFraction(5, 121, ret) [25, 757, 763309, 873960180913, 1527612795642093418846225] ÊÄªÁªìÂüÉÂèäÂàÜÊï∞ÁöÑË°®Á§∫‰∏çÊòØÂîØ‰∏ÄÁöÑÔºå‰ΩÜÂ∫îËØ•Êúâ‰∏Ä‰∏™È°πÊï∞ÊúÄÂ∞ëÁöÑË°®ËææÂºèÔºåÊàë‰ª¨ÊääËøô‰∏™Âè´ÂÅöÊúÄ‰ºòÁöÑÔºå‰ΩÜÁõÆÂâçËøòÊ≤°Êúâ‰∏Ä‰∏™ÁÆóÊ≥ïÂèØ‰ª•Ê±ÇÂá∫ÊúÄ‰ºòÁöÑÂüÉÂèäÂàÜÊï∞„ÄÇ]]></content>
      <categories>
        <category>ÁÆóÊ≥ïÁªÉ‰π†</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python ËøõÂ∫¶Êù° tqdm]]></title>
    <url>%2F2019%2F07%2F26%2FPython%20%E8%BF%9B%E5%BA%A6%E6%9D%A1%20tqdm%2F</url>
    <content type="text"><![CDATA[tqdmÊòØPython‰∏≠‰∏ìÈó®Áî®‰∫éËøõÂ∫¶Êù°ÁæéÂåñÁöÑÊ®°ÂùóÔºåÈÄöËøáÂú®ÈùûwhileÁöÑÂæ™ÁéØ‰ΩìÂÜÖÂµåÂÖ•tqdmÔºåÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™ËÉΩÊõ¥Â•ΩÂ±ïÁé∞Á®ãÂ∫èËøêË°åËøáÁ®ãÁöÑÊèêÁ§∫ËøõÂ∫¶Êù°ÔºåÊú¨ÊñáÂ∞±Â∞ÜÈíàÂØπtqdmÁöÑÂü∫Êú¨Áî®Ê≥ïËøõË°å‰ªãÁªç„ÄÇ Âü∫Êú¨Áî®Ê≥ïtqdm()ÁöÑ‰ΩøÁî®ÈùûÂ∏∏ÁÆÄÂçïÔºåÂè™Ë¶Å‰º†ÂÖ•‰∏Ä‰∏™Ëø≠‰ª£Âô®Â∞±ÂèØ‰ª•‰∫ÜÔºå‰æãÂ¶Çrange()„ÄÇ 12345from tqdm import tqdmimport timefor c in tqdm(['a', 'b', 'c', 'd', 'e']): time.sleep(1) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05&lt;00:00, 1.00s/it] 12for it in tqdm(range(10)): time.sleep(1) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:10&lt;00:00, 1.00s/it] tqdm ËøòÊèê‰æõ‰∫Ütqdm(range())ÁöÑÁÆÄÂçïÁâàÊú¨Ôºåtrange() 1234from tqdm import trangefor i in trange(10): time.sleep(1) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:10&lt;00:00, 1.00s/it] tqdm‰∏∫jupyterÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊïàÊûúÊõ¥Â•ΩÁöÑËøõÂ∫¶Êù°ÔºåÂú®jupyterÈáåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÊïàÊûúÊõ¥Â•Ω„ÄÇ 1234from tqdm import tqdm_notebookfor i in tqdm_notebook(range(100),desc='demoÔºö'): time.sleep(1) okÔºåÁªìÊùü„ÄÇ]]></content>
      <tags>
        <tag>pythonÂ∫ì</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂæÆÂçöÁà¨Ëô´]]></title>
    <url>%2F2019%2F07%2F25%2F%E7%AE%80%E5%8D%95%E7%9A%84%E5%BE%AE%E5%8D%9A%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[ÂáÜÂ§áÂÜôËÆ∫Êñá‰∫ÜÔºåÈúÄË¶ÅÁà¨Âèñ‰∫õ‰∫íËÅîÁΩëÁöÑÊï∞ÊçÆËøõË°åÂàÜÊûê‰∏ãÔºåPyhtonÁà¨Ëô´ÊòØ‰∏Ä‰∏™ÊØîËæÉÁÆÄÂçïÁöÑÊñπÊ≥ïÔºåËôΩÁÑ∂ÊúâËÆ∏Â§öÁöÑÁà¨Ëô´Ê°ÜÊû∂‰ΩÜÊòØÊàëÂπ∂‰∏çÈúÄË¶ÅÂ§™Â§çÊùÇÁöÑÁà¨Ëô´ÔºåÊâÄ‰ª•ÂÜ≥ÂÆö‰ªéÈõ∂ÂºÄÂßãÂÜô‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁà¨Ëô´Áà¨‰∏Ä‰∏ãÂæÆÂçöÂíåËØÑËÆ∫„ÄÇ ÂáÜÂ§áÂ∑•ÂÖ∑Áà¨Ëô´Â∞±ÊòØ‰∏Ä‰∏™ÂàÜÊûêHTTPËØ∑Ê±ÇÁöÑÂ∑•‰ΩúÔºåÈ¶ñÂÖàÈúÄË¶Å‰∏Ä‰∫õÊäìÂèñhttpÁöÑÂ∑•ÂÖ∑ÔºåÊé®Ëçê‰ΩøÁî® FiddlerÔºåÁÆÄÂçïÂÖçË¥π„ÄÇ ËøòÈúÄË¶ÅÊµèËßàÂô® GoogleChrome ÂàÜÊûêÂæÆÂçöÁΩëÁ´ôÂæÆÂçöÊúâ‰∏â‰∏™ÂÖ•Âè£ÔºåÂàÜÂà´ÊòØ weibo.com weibo.cn m.weibo.cn Á¨¨‰∏Ä‰∏™ÊòØPCÁΩëÈ°µÁâàÔºåÂêé‰∏§‰∏™ÊòØÊâãÊú∫ÁâàÔºåÊâãÊú∫ÁâàÁΩëÁ´ôÁªìÊûÑÁõ∏ÂØπÁÆÄÂçïÁà¨ÂèñÂÆπÊòìÔºåÊâÄ‰ª•ÈÄâÊã©m.weibo.cn‰∏∫Áà¨ÂèñÂØπË±°„ÄÇ ÊâìÂºÄÊµèËßàÂô®ÂºÄÂèëËÄÖÊ®°ÂºèÔºåËßÇÂØüNetworkÔºåÂú®ÁÉ≠Èó®È¢ëÈÅìÂà∑Êñ∞ÔºåÂèëÁé∞‰∏Ä‰∏™API https://m.weibo.cn/api/container/getIndex?containerid=102803&amp;openApp=0 Ëøô‰∏™Âú∞ÂùÄÁöÑresponseÂ∞±ÊòØÁÉ≠Èó®ÂæÆÂçöÁöÑÊï∞ÊçÆÔºåÊé•‰∏ãÊù•ÂØªÊâæÁøªÈ°µÁöÑÊñπÊ≥ïÔºåÂêë‰∏ãÂà∑Êñ∞ËßÇÂØüÂèëÁé∞‰∏Ä‰∏™Âú∞ÂùÄÂú®ÂèòÂåñ„ÄÇ https://m.weibo.cn/api/container/getIndex?containerid=102803&amp;openApp=0&amp;since_id=1 since_idËøô‰∏™ÂèÇÊï∞ÊòØÊéßÂà∂ÁøªÈ°µÁöÑ„ÄÇ Áî®ÂêåÊ†∑ÁöÑÊñπÊ≥ïËßÇÂØüËØÑËÆ∫È°µÈù¢ https://m.weibo.cn/detail/{ÂæÆÂçöÁºñÂè∑} Ëøô‰∏™Âú∞ÂùÄÂ∞±ÊòØÂÖ∑‰ΩìÂæÆÂçöÁöÑËØ¶ÁªÜÔºå https://m.weibo.cn/comments/hotflow?id={mblogid}&amp;mid={mblogid}&amp;max_id={max_id}&amp;max_id_type=0 mblogidÊòØÂæÆÂçöÁöÑÁºñÂè∑Ôºåmax_idÊéßÂà∂ÁøªÈ°µÔºåÂâç‰∏Ä‰∏™request‰ºöÂëäËØâËøô‰∏™idÁöÑÊï∞ÔºåÂ¶ÇÊûúÊòØ0ÂàôË°®Á§∫ÊúÄÂêé‰∏ÄÈ°µ„ÄÇ ÂæÆÂçöÈ°µÈù¢ÂàÜÊûêÂÆåÊØïÔºåÊé•‰∏ãÊù•ÁºñÂÜô‰ª£Á†ÅÊ®°‰ªøÊµèËßàÂô®ÂèëHttpËØ∑Ê±ÇÂ∞±OK‰∫Ü„ÄÇ ÁºñÂÜô‰ª£Á†ÅÈ¶ñÂÖàÊàë‰ª¨ÈúÄË¶ÅÁî®Âà∞urllibËøô‰∏™Â∫ìÊù•ÂèëÈÄÅËØ∑Ê±Ç„ÄÇËøòÈúÄË¶ÅjsonÂåñ‰∏Ä‰∏ãÊï∞ÊçÆ„ÄÇ 1234567891011121314# -*- coding: utf-8 -*-# env python3.7import jsonimport timeimport randomfrom urllib import requestfrom urllib import parse# ÁÉ≠Èó®ÂæÆÂçöÁöÑurlHotWeiBoUrl = 'https://m.weibo.cn/api/container/getIndex?containerid=102803&amp;since_id=&#123;sinceid&#125;'# ÂæÆÂçöËØÑËÆ∫ÁöÑUrlWeiBoCommentsUrl = 'https://m.weibo.cn/comments/hotflow?id=&#123;mblogid&#125;&amp;mid=&#123;mblogid&#125;&amp;max_id=&#123;max_id&#125;&amp;max_id_type=0' È¶ñÂÖàËÆøÈóÆÁÉ≠Èó®ÂæÆÂçöÈ°µÈù¢ÔºåËß£ÊûêÂΩìÂâçÈ°µÈù¢ÁöÑÁÉ≠Èó®ÂæÆÂçöÁöÑresponseÔºåÊèêÂèñÂá∫ÊØè‰∏™ÂæÆÂçöÁöÑÂÜÖÂÆπÂíåÂú∞ÂùÄ„ÄÇ 12345678910111213141516def GetHotWeiBoData(url): scheme_url = [] body_text = [] req = request.Request(url) req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25') with request.urlopen(req) as f: print('Status:', f.status, f.reason) if f.status == 200: data = f.read().decode('utf-8') data = json.loads(data) for i in data['data']['cards']: scheme_url.append(i['scheme']) body_text.append(i['mblog']['text']) return body_text, scheme_url return None, None Ëé∑ÂèñËØÑËÆ∫Âíå‰∏ã‰∏ÄÈ°µËØÑËÆ∫ 12345678910111213141516def GetCommentsData(comments_url): text = [] req = request.Request(comments_url) req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25') print(comments_url) with request.urlopen(req) as f: if f.status == 200: data = f.read().decode('utf-8') data = json.loads(data) if "data" in data: data = data["data"] for i in data["data"]: text.append(i["text"]) next_id = data['max_id'] return text, next_id return None, None Âæ™ÁéØÊâßË°å‰∏äÈù¢‰∏§‰∏™ÂáΩÊï∞ÔºåÂ∞±ÂèØ‰ª•‰∫Ü 12345678910111213141516171819202122232425262728def GetCommentsUrl(url, max_id=0): parsed_tuple = parse.urlparse(url) mblogid = parsed_tuple.path[8:] comments_url = WeiBoCommentsUrl.format(mblogid=mblogid, max_id=max_id) return comments_url, mblogiddef GetWeiBo(sinceid): data = &#123;&#125; url = HotWeiBoUrl.format(sinceid=0) body_text, scheme_url = GetHotWeiBoData(url) for i in range(len(scheme_url)): url = scheme_url[i] body = body_text[i] comments_url, mblogid = GetCommentsUrl(url) comments, next_id = GetCommentsData(comments_url) if comments: data[mblogid] = &#123;&#125; data[mblogid]['comments'] = [] data[mblogid]['comments'].extend(comments) data[mblogid]['body'] = body # while next_id != 0: # comments_url, mblogid = GetCommentsUrl(url, next_id) # comments, next_id = GetCommentsData(comments_url) # data[mblogid]['comments'].extend(comments) return data ÊääÊï∞ÊçÆ‰øùÂ≠òËµ∑Êù• 12345def SaveData(data): data = json.dumps(data, ensure_ascii=False) + "\n" WeiBoData.write(data) # ÂÖ≥Èó≠ÊâìÂºÄÁöÑÊñá‰ª∂ # fo.close() ËÆ©Áà¨Ëô´ÂºÄÂßãÂ∑•‰ΩúÔºå‰∏∫Èò≤Ê≠¢Ë¢´Á¶ÅÔºåÊääÁà¨ÂèñÈ¢ëÁéáË∞É‰ΩéÁÇπ„ÄÇ 1234567# ÊâìÂºÄ‰∏Ä‰∏™Êñá‰ª∂ a Â∑≤ËøΩÂä†ÁöÑÊñπÂºèÊâìÂºÄÔºåÁºñÁ†ÅÊñπÂºè‰∏∫ utf-8WeiBoData = open("./WeiBoData.txt", "a", encoding="utf-8")while True: data = GetWeiBo(0) SaveData(data) time.sleep(random.randint(280, 320)) Â¶ÇÊûúÊÉ≥Ë¶ÅÁà¨ÂèñÂ§öÈ°µËØÑËÆ∫ÔºåÈúÄË¶ÅÁôªÈôÜÊìç‰ΩúÔºåËÆæÁΩÆ cookie„ÄÇ]]></content>
      <categories>
        <category>Áà¨Ëô´</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÊñáÊú¨Áõ∏‰ººÂ∫¶]]></title>
    <url>%2F2019%2F07%2F18%2F%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[Â¶Ç‰ΩïÂØπÊØî‰∏§‰∏™ÊñáÊú¨ÁöÑÁõ∏‰ººÂ∫¶ÔºåËøôÈáåËÆ∞ÂΩïÂá†‰∏™ÁÆÄÂçïËÆ°ÁÆóÊñáÊú¨Ë∑ùÁ¶ªÁöÑÊñπÊ≥ï„ÄÇ ËßÑÂÆöÔºåÁªìÊûú‰∏∫0-1ÁöÑÊµÆÁÇπÊï∞Ôºå0‰∏∫ÂÆåÂÖ®‰∏çÁõ∏ÂÖ≥Ôºå1‰∏∫ÂÆåÂÖ®Ê≠£Áõ∏ÂÖ≥ ÂàÜËØç‰ΩøÁî® jieba.cut Á≠âÂ∑•ÂÖ∑ÂØπÊñáÊú¨ËøõË°åÂàÜËØçÂ§ÑÁêÜÔºåËé∑ÂæóÂà∞‰∏§‰∏™Â≠óÁ¨¶‰∏≤Â∫èÂàó„ÄÇ 123import jiebaseq1 = [i for i in jieba.cut(text1, cut_all=True) if i != '']seq2 = [i for i in jieba.cut(text2, cut_all=True) if i != ''] ÂÖ±ÊúâËØçÊØîÁéáÊØîËæÉÁÆÄÂçïÁöÑÁÆóÊ≥ïÂ∞±ÊòØÁúã‰∏§Âè•ËØù‰∏≠Áõ∏ÂêåÁöÑÊ±âÂ≠óÊï∞ÔºåÂ¶ÇÊûúÊúâËæÉÂ§öÁöÑÁõ∏ÂêåÊ±âÂ≠óÔºåÂàôËÆ§‰∏∫ÂÆÉ‰ª¨ÊòØÊØîËæÉÁõ∏‰ººÁöÑ„ÄÇ 123def similartiy_rate(seq1, seq2): set1, set2 = set(seq1), set(seq2) return len(set1 &amp; set2) / len(set2) ÁºñËæëË∑ùÁ¶ªÁºñËæëË∑ùÁ¶ªÔºàEdit DistanceÔºâÔºåÂèàÁß∞LevenshteinË∑ùÁ¶ªÔºåÊòØÊåá‰∏§‰∏™Â≠ó‰∏≤‰πãÈó¥ÔºåÁî±‰∏Ä‰∏™ËΩ¨ÊàêÂè¶‰∏Ä‰∏™ÊâÄÈúÄÁöÑÊúÄÂ∞ëÁºñËæëÊìç‰ΩúÊ¨°Êï∞„ÄÇÁºñËæëÊìç‰ΩúÂåÖÊã¨Â∞Ü‰∏Ä‰∏™Â≠óÁ¨¶ÊõøÊç¢ÊàêÂè¶‰∏Ä‰∏™Â≠óÁ¨¶ÔºåÊèíÂÖ•‰∏Ä‰∏™Â≠óÁ¨¶ÔºåÂà†Èô§‰∏Ä‰∏™Â≠óÁ¨¶„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÁºñËæëË∑ùÁ¶ªË∂äÂ∞èÔºå‰∏§‰∏™‰∏≤ÁöÑÁõ∏‰ººÂ∫¶Ë∂äÂ§ß„ÄÇÁî±‰øÑÁΩóÊñØÁßëÂ≠¶ÂÆ∂Vladimir Levenshtein Âú®1965Âπ¥ÊèêÂá∫Ëøô‰∏™Ê¶ÇÂøµ„ÄÇ ‰æãÂ¶ÇÂ∞ÜabcdefËΩ¨Êç¢‰∏∫abcdgh,ÈúÄË¶ÅÊîπÂèò‰∏§‰∏™Â≠óÁ¨¶(ef-&gt;gh)ÔºåÊâÄ‰ª•ÁºñËæëË∑ùÁ¶ªÂ∞±ÊòØ2 ÁÑ∂ÂêéÊãøÁºñËæëË∑ùÁ¶ªÂéªÈô§‰ª•‰∏§ËÄÖ‰πãÈó¥ÁöÑÊúÄÂ§ßÈïøÂ∫¶Ôºå2/6‚âà0.333ÔºåÊÑèÂë≥ÁùÄÂè™Ë¶ÅÂèòÂä®Ëøô‰πàÂ§öÂ∞±ÂèØ‰ª•‰ªéAÂèòÊàêBÔºåÊâÄ‰ª•‰∏çÁî®ÂèòÂä®ÁöÑÂ≠óÁ¨¶‰æø‰ª£Ë°®‰∫ÜÁõ∏‰ººÂ∫¶Ôºå1-0.333Ôºù0.667„ÄÇ ÂèÇÊï∞ methodÔºö 1:Â∫èÂàóÈó¥ÂØπÈΩêÊúÄÁü≠ÈïøÂ∫¶ÁöÑÂ∫èÂàó 2:Â∫èÂàóÈó¥ÂØπÈΩêÊúÄÈïøÈïøÂ∫¶ÁöÑÂ∫èÂàó 1234567891011121314151617181920212223242526272829303132333435363738394041424344from array import arraydef levenshtein(seq1, seq2, method=1): if seq1 == seq2: return 0.0 len1, len2 = len(seq1), len(seq2) if len1 == 0 or len2 == 0: return 1.0 if len1 &lt; len2: # minimize the arrays size len1, len2 = len2, len1 seq1, seq2 = seq2, seq1 if method == 1: return 1 - levenshtein(seq1, seq2) / float(len1) if method != 2: raise ValueError("expected either 1 or 2 for `method` parameter") column = array('L', range(len2 + 1)) length = array('L', range(len2 + 1)) for x in range(1, len1 + 1): column[0] = length[0] = x last = llast = x - 1 for y in range(1, len2 + 1): # dist old = column[y] ic = column[y - 1] + 1 dc = column[y] + 1 rc = last + (seq1[x - 1] != seq2[y - 1]) column[y] = min(ic, dc, rc) last = old # length lold = length[y] lic = length[y - 1] + 1 if ic == column[y] else 0 ldc = length[y] + 1 if dc == column[y] else 0 lrc = llast + 1 if rc == column[y] else 0 length[y] = max(ldc, lic, lrc) llast = lold return 1 - column[y] / float(length[y]) ‰ΩôÂº¶Áõ∏‰ººÂ∫¶‰ΩôÂº¶Áõ∏‰ººÂ∫¶Â∫¶ÊòØÂ∏∏Áî®ÁöÑËÆ°ÁÆóË∑ùÁ¶ªÁöÑÂÖ¨ÂºèÔºåÈÄöÂ∏∏Áî®Êù•ÊØîËæÉÊñáÊú¨ÁöÑÁõ∏‰ººÊÄß È¶ñÂÖàÁúã‰∏Ä‰∏ãÂÖ¨Âºè Âü∫Êú¨Ê≠•È™§Ôºö 1.ÈÄöËøá‰∏≠ÊñáÂàÜËØçÔºåÊääÂÆåÊï¥ÁöÑÂè•Â≠êÊ†πÊçÆÂàÜËØçÁÆóÊ≥ïÂàÜ‰∏∫Áã¨Á´ãÁöÑËØçÈõÜÂêà 2.Ê±ÇÂá∫‰∏§‰∏™ËØçÈõÜÂêàÁöÑÂπ∂ÈõÜ(ËØçÂåÖ) 3.ËÆ°ÁÆóÂêÑËá™ËØçÈõÜÁöÑËØçÈ¢ëÂπ∂ÊääËØçÈ¢ëÂêëÈáèÂåñ 4.Â∏¶ÂÖ•ÂêëÈáèËÆ°ÁÆóÊ®°ÂûãÂ∞±ÂèØ‰ª•Ê±ÇÂá∫ÊñáÊú¨Áõ∏‰ººÂ∫¶ 5.Â•óÁî®‰ΩôÂº¶ÂáΩÊï∞ËÆ°Èáè‰∏§‰∏™Âè•Â≠êÁöÑÁõ∏‰ººÂ∫¶„ÄÇ 1234567891011121314151617181920212223242526272829303132333435# ÁªüËÆ°ÊØè‰∏™ÂÖÉÁ¥†Âá∫Áé∞ÁöÑÊ¨°Êï∞def all_list(arr): result = &#123;&#125; for i in set(arr): result[i] = arr.count(i) - 1 return result# ËØçÈ¢ëÁºñÁ†Ådef word_frequency(word_list1, word_list2): word_list = word_list1 + word_list2 dict = all_list(word_list) word_vector1 = map(lambda x: dict[x], word_list1) word_vector2 = map(lambda x: dict[x], word_list2) return list(word_vector1), list(word_vector2)# ËÆ°ÁÆó‰ΩôÂº¶def calculate_cosine(a, b): sum_list = map(lambda x, y: x*y, a, b) p = reduce(lambda x, y: x+y, sum_list) q1 = map(lambda x: x*x, a) q1_sum = reduce(lambda x, y: x+y, q1) q2 = map(lambda x: x*x, b) q2_sum = reduce(lambda x, y: x+y, q2) q = math.sqrt(q1_sum) * math.sqrt(q2_sum) if q != 0: return p/q return 0# ‰ΩôÂº¶Áõ∏‰ººÂ∫¶def cosine_similartiy(seq1, seq2): p1, p2 = word_frequency(seq1, seq2) return calculate_cosine(p1, p2) Ê±âÊòéË∑ùÁ¶ªÊ±âÊòéË∑ùÁ¶ªÊòØ‰ΩøÁî®Âú®Êï∞ÊçÆ‰º†ËæìÂ∑ÆÈîôÊéßÂà∂ÁºñÁ†ÅÈáåÁöÑÔºåÂÆÉË°®Á§∫‰∏§‰∏™ÔºàÁõ∏ÂêåÈïøÂ∫¶ÔºâÂ≠óÂØπÂ∫î‰Ωç‰∏çÂêåÁöÑÊï∞ÈáèÔºåÊàë‰ª¨‰ª•d(x,y)Ë°®Á§∫‰∏§‰∏™Â≠óx,y‰πãÈó¥ÁöÑÊ±âÊòéË∑ùÁ¶ª„ÄÇÂØπ‰∏§‰∏™Â≠óÁ¨¶‰∏≤ËøõË°åÂºÇÊàñËøêÁÆóÔºåÂπ∂ÁªüËÆ°ÁªìÊûú‰∏∫1ÁöÑ‰∏™Êï∞ÔºåÈÇ£‰πàËøô‰∏™Êï∞Â∞±ÊòØÊ±âÊòéË∑ùÁ¶ª„ÄÇ 123456789# Ê±âÊòéË∑ùÁ¶ªdef hamming(seq1, seq2): L = len(seq1) if L != len(seq2): seq2.extend([0] * (len(seq1) - len(seq2))) if L == 0: return 0 # equal dist = sum(c1 != c2 for c1, c2 in zip(seq1, seq2)) return 1 - dist / float(L) JaccardÁ≥ªÊï∞ÂÆö‰πâ ÁªôÂÆö‰∏§‰∏™ÈõÜÂêàA,BÔºåJaccard Á≥ªÊï∞ÂÆö‰πâ‰∏∫A‰∏éB‰∫§ÈõÜÁöÑÂ§ßÂ∞è‰∏éA‰∏éBÂπ∂ÈõÜÁöÑÂ§ßÂ∞èÁöÑÊØîÂÄºÔºåÂÆö‰πâÂ¶Ç‰∏ãÔºö ÂΩìÈõÜÂêàAÔºåBÈÉΩ‰∏∫Á©∫Êó∂ÔºåJ(A,B)ÂÆö‰πâ‰∏∫1„ÄÇ‰∏éJaccard Á≥ªÊï∞Áõ∏ÂÖ≥ÁöÑÊåáÊ†áÂè´ÂÅöJaccard Ë∑ùÁ¶ªÔºåÁî®‰∫éÊèèËø∞ÈõÜÂêà‰πãÈó¥ÁöÑ‰∏çÁõ∏‰ººÂ∫¶„ÄÇJaccard Ë∑ùÁ¶ªË∂äÂ§ßÔºåÊ†∑Êú¨Áõ∏‰ººÂ∫¶Ë∂ä‰Ωé„ÄÇÂÖ¨ÂºèÂÆö‰πâÂ¶Ç‰∏ãÔºö ÂÖ∂‰∏≠ÂØπÂèÇÂ∑ÆÔºàsymmetric differenceÔºâ ÊÄßË¥® 1234# Êù∞Âç°Âæ∑Á≥ªÊï∞def jaccard(seq1, seq2): set1, set2 = set(seq1), set(seq2) return len(set1 &amp; set2) / float(len(set1 | set2)) DiceÁ≥ªÊï∞Dice Á≥ªÊï∞ÂèØ‰ª•ËÆ°ÁÆó‰∏§‰∏™Â≠óÁ¨¶‰∏≤ÁöÑÁõ∏‰ººÂ∫¶ÔºöDiceÔºàs1,s2Ôºâ=2*comm(s1,s2)/(leng(s1)+leng(s2))„ÄÇÂÖ∂‰∏≠Ôºåcomm (s1,s2)ÊòØs1„ÄÅs2 ‰∏≠Áõ∏ÂêåÂ≠óÁ¨¶ÁöÑ‰∏™Êï∞leng(s1)Ôºåleng(s2)ÊòØÂ≠óÁ¨¶‰∏≤s1„ÄÅs2 ÁöÑÈïøÂ∫¶„ÄÇ Dice Á≥ªÊï∞ÊòØ‰∏ÄÁßçÈõÜÂêàÁõ∏‰ººÂ∫¶Â∫¶ÈáèÂáΩÊï∞Ôºå‰∏éÁõ∏‰ººÂ∫¶ÊåáÊï∞Áõ∏ÂêåÔºå‰πüË¢´Áß∞‰∏∫Á≥ªÊï∞ÔºåÂΩ¢Âºè‰∏ä‰πüÂíåÊù∞Âç°Âæ∑Á≥ªÊï∞Ê≤°ÊúâÂ§öÂ§ßÂå∫Âà´Ôºå‰ΩÜËøòÊòØÊúâ‰∫õ‰∏çÂêåÁöÑÊÄßË¥®„ÄÇ 1234# DiceÁ≥ªÊï∞def sorensen(seq1, seq2): set1, set2 = set(seq1), set(seq2) return 2 * len(set1 &amp; set2) / float(len(set1) + len(set2)) ÊÄªÁªìÁÆÄÂçïÁöÑÂá†‰∏™ËÆ°ÁÆóÊñáÊú¨Áõ∏‰ººÂ∫¶ÁöÑÊñπÊ≥ïÂ∞±ÊòØËøô‰∫õ‰∫ÜÔºåÂ∏∏Áî®ÁöÑ‰∏∫‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÔºåÁ®çÂ§çÊùÇÁöÑÂèØ‰ª•Â∞ùËØïÂ§ö‰∏™ÁÆóÊ≥ïÁöÑÂè†Âä†Ôºå‰æãÂ¶ÇËøòÊúâÊ¨ßÂá†ÈáåÂæóË∑ùÁ¶ªÔºåÊõºÂìàÈ°øË∑ùÁ¶ªÔºåSimHashÁ≠âÊñπÊ≥ïÂèØ‰ª•ËÆ°ÁÆóÊñáÊú¨‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÇ7]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰ª£Á†ÅÂÆûÁé∞</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CodeForces978C Letters]]></title>
    <url>%2F2019%2F06%2F10%2FCodeForces978C%20Letters%2F</url>
    <content type="text"><![CDATA[There are dormitories in Berland State University, they are numbered with integers from to . Each dormitory consists of rooms, there are rooms in -th dormitory. The rooms in -th dormitory are numbered from to . A postman delivers letters. Sometimes there is no specific dormitory and room number in it on an envelope. Instead of it only a room number among all rooms of all dormitories is written on an envelope. In this case, assume that all the rooms are numbered from to and the rooms of the first dormitory go first, the rooms of the second dormitory go after them and so on. For example, in case , and an envelope can have any integer from to written on it. If the number is written on an envelope, it means that the letter should be delivered to the room number of the second dormitory. For each of letters by the room number among all dormitories, determine the particular dormitory and the room number in a dormitory where this letter should be delivered. InputThe first line contains two integers and ‚Äî the number of dormitories and the number of letters. The second line contains a sequence , where equals to the number of rooms in the -th dormitory. The third line contains a sequence , where equals to the room number (among all rooms of all dormitories) for the -th letter. All are given in increasing order. OutputPrint lines. For each letter print two integers and ‚Äî the dormitory number and the room number in this dormitory to deliver the letter. 1234567891011121314151617181920212223242526272829ExamplesInput3 610 15 121 9 12 23 26 37Output1 11 92 22 133 13 12Input2 35 100000000005 6 9999999999Output1 52 12 9999999994NoteIn the first example letters should be delivered in the following order:the first letter in room of the first dormitorythe second letter in room of the first dormitorythe third letter in room of the second dormitorythe fourth letter in room of the second dormitorythe fifth letter in room of the third dormitorythe sixth letter in room of the third dormitory Ëß£ÊûêÔºö È¢òÊÑè: Êü•ËØ¢m‰∏™Êï∞ÂàÜÂà´Âú®‰∏Ä‰∏™Êúân‰∏™ÂÖÉÁ¥†ÁöÑÈÄíÂ¢ûÂ∫èÂàó‰∏≠ÁöÑÁõ∏ÂØπ‰ΩçÁΩÆ„ÄÇ ‰∏§ÁßçËß£Ê≥ïÔºö Êö¥ÂäõËß£Ê≥ï‰∏∫‰∏§Â±ÇÂµåÂ•óÂæ™ÁéØÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫O(m√ón)Ôºõ ‰∫åÂàÜÊ≥ïÊü•ÊâæÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫O(m√ólog2n) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;stdio.h&gt;#define MAXN 2048 //ÂÆö‰πâ‰∏Ä‰∏™Êï∞ÁªÑÁöÑÂ§ßÂ∞è// Êö¥ÂäõÊ±ÇËß£int letters(int* a, int* b, int n, int m)&#123; int i, j, t, sum=0; for(j = 0; j &lt; m; j++) &#123; sum = 0; for(i = 0; i &lt; n; i++) &#123; sum += a[i]; if(b[j] &lt;= sum) &#123; t = sum - a[i]; printf("%d %d\n", i+1, b[j] - t); break; &#125; &#125; &#125; return 0;&#125;// ‰∫åÂàÜÊ≥ïint binary_letters(int* a, int* b, int n, int m)&#123; int sum[MAXN] = &#123;0&#125;; int i, j, r, l, mid; sum[0] = a[0]; // ÊûÑÂª∫aiÂ∫èÂàó for(i = 1; i &lt; n; i++) sum[i] = sum[i-1] + a[i]; for(j = 0; j &lt; m; j++) &#123; if(b[j] &gt; sum[i-1]) &#123; printf("%d index out of bounds.\n", b[j]); continue; &#125; for(r = n - 1, l = 0; r - l &gt; 1; ) &#123; mid = (r + l) / 2; if(b[j] &gt; sum[mid]) l = mid; else r = mid; &#125; if(b[j] &gt; sum[l]) printf("%d %d\n", l+2, b[j]-sum[l]); else printf("%d %d\n", l+1, b[j]); &#125; return 0;&#125;int main()&#123; int a[] = &#123;10, 15, 12, 12, 12&#125;; int b[] = &#123;1, 9, 12, 23, 26, 37, 50, 62&#125;; int n = sizeof(a) / sizeof(int); int m = sizeof(b) / sizeof(int); letters(a, b, n, m); printf("================\n"); binary_letters(a, b, n, m); return 0;&#125; out put 123456789101112131415161 11 92 22 133 13 125 1================1 11 92 22 133 13 125 162 index out of bounds.]]></content>
      <categories>
        <category>ÁÆóÊ≥ïÁªÉ‰π†</category>
      </categories>
      <tags>
        <tag>ÁÆóÊ≥ï</tag>
        <tag>c</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Titanic Machine Learning from Disaster]]></title>
    <url>%2F2019%2F05%2F28%2FTitanic_Machine_Learning_from_Disaster.2%2F</url>
    <content type="text"><![CDATA[Kaggle Competition ÁöÑÁªÉ‰π† Ê≥∞Âù¶Â∞ºÂÖãÂè∑Ôºö‰ªéÁÅæÈöæ‰∏≠Â≠¶‰π†Êú∫Âô® 12345678910111213141516171819202122# Êï∞ÊçÆÂàÜÊûêÂ∫ìimport pandas as pdimport numpy as npimport random# Êï∞ÊçÆÂèØËßÜÂåñimport seaborn as snsimport matplotlib.pyplot as plt# Êú∫Âô®Â≠¶‰π†Â∫ìfrom sklearn.preprocessing import OneHotEncoderfrom sklearn.linear_model import LogisticRegressionfrom sklearn.svm import SVC, LinearSVCfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.naive_bayes import GaussianNBfrom sklearn.linear_model import Perceptronfrom sklearn.linear_model import SGDClassifierfrom sklearn.tree import DecisionTreeClassifierpd.options.display.max_rows = 10 # ÊúÄÂ§ßÊòæÁ§∫Ë°åÊï∞pd.options.display.float_format = '&#123;:.5f&#125;'.format # Á≤æÁ°ÆÂ∫¶ ‰øùÁïô‰∏Ä‰ΩçÂ∞èÊï∞ Âä†ËΩΩÊï∞ÊçÆÈ¶ñÂÖàÂä†ËΩΩÊµèËßàÊï∞ÊçÆ 12train_df = pd.read_csv('/train.csv')test_df = pd.read_csv('/test.csv') 1train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.00000 1 0 A/5 21171 7.25000 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.00000 1 0 PC 17599 71.28330 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.00000 0 0 STON/O2. 3101282 7.92500 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.00000 1 0 113803 53.10000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.00000 0 0 373450 8.05000 NaN S 1test_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 892 3 Kelly, Mr. James male 34.50000 0 0 330911 7.82920 NaN Q 1 893 3 Wilkes, Mrs. James (Ellen Needs) female 47.00000 1 0 363272 7.00000 NaN S 2 894 2 Myles, Mr. Thomas Francis male 62.00000 0 0 240276 9.68750 NaN Q 3 895 3 Wirz, Mr. Albert male 27.00000 0 0 315154 8.66250 NaN S 4 896 3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female 22.00000 1 1 3101298 12.28750 NaN S 1train_df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.00000 891.00000 891.00000 714.00000 891.00000 891.00000 891.00000 mean 446.00000 0.38384 2.30864 29.69912 0.52301 0.38159 32.20421 std 257.35384 0.48659 0.83607 14.52650 1.10274 0.80606 49.69343 min 1.00000 0.00000 1.00000 0.42000 0.00000 0.00000 0.00000 25% 223.50000 0.00000 2.00000 20.12500 0.00000 0.00000 7.91040 50% 446.00000 0.00000 3.00000 28.00000 0.00000 0.00000 14.45420 75% 668.50000 1.00000 3.00000 38.00000 1.00000 0.00000 31.00000 max 891.00000 1.00000 3.00000 80.00000 8.00000 6.00000 512.32920 1test_df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Pclass Age SibSp Parch Fare count 418.00000 418.00000 332.00000 418.00000 418.00000 417.00000 mean 1100.50000 2.26555 30.27259 0.44737 0.39234 35.62719 std 120.81046 0.84184 14.18121 0.89676 0.98143 55.90758 min 892.00000 1.00000 0.17000 0.00000 0.00000 0.00000 25% 996.25000 1.00000 21.00000 0.00000 0.00000 7.89580 50% 1100.50000 3.00000 27.00000 0.00000 0.00000 14.45420 75% 1204.75000 3.00000 39.00000 1.00000 0.00000 31.50000 max 1309.00000 3.00000 76.00000 8.00000 9.00000 512.32920 ËÆ≠ÁªÉÈõÜÊúâ PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked ÂÖ±ÂçÅ‰∫åÂàóÊï∞ÊçÆÔºåÊµãËØïÈõÜ‰∏≠Ê≤°ÊúâÁöÑSurvivedÂ∞±ÊòØÊàë‰ª¨Ë¶ÅÈ¢ÑÊµãÁöÑÂÄº„ÄÇ Ê£ÄÊü•Êï∞ÊçÆÊ£ÄÊü•Êï∞ÊçÆÁ±ªÂûãÂíåÁº∫Â§±ÊÉÖÂÜµ„ÄÇ 123train_df.info()print('_'*40)test_df.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 714 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.6+ KB ________________________________________ &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 418 entries, 0 to 417 Data columns (total 11 columns): PassengerId 418 non-null int64 Pclass 418 non-null int64 Name 418 non-null object Sex 418 non-null object Age 332 non-null float64 SibSp 418 non-null int64 Parch 418 non-null int64 Ticket 418 non-null object Fare 417 non-null float64 Cabin 91 non-null object Embarked 418 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 36.0+ KB ËßÇÂØüÂèëÁé∞ÔºåAge Cabin Embarked Â≠òÂú®Áº∫Â§±ÔºåÂπ∂‰∏îÊï∞ÊçÆÁ±ªÂûãÊó¢ÊúâÊï∞Â≠ó‰πüÊúâÂ≠óÁ¨¶‰∏≤„ÄÇÊµãËØïÈõÜ‰∏≠ Fare Áº∫Â§±‰∫Ü‰∏Ä‰∏™„ÄÇ ËßÇÂØüÁâπÂæÅÁöÑÂàÜÂ∏ÉName ÊòØÂîØ‰∏ÄÁöÑÂÖ± 891 Sex Êúâ‰∏§ÁßçÔºåmale Âç† 64.7%Ôºàtop=male, freq/count=64.7%Ôºâ Ticket ‰∏çÂêåÁöÑÁßçÁ±ªÊØîËæÉÂ§ö Cabin ÊúâËÆ∏Â§ö‰πòÂÆ¢Âú®Âêå‰∏Ä‰∏™ cabin Embarked Êúâ‰∏âÁßçÂ§ßÂ§öÊï∞ÊòØ S 1train_df.describe(include=["O"]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Name Sex Ticket Cabin Embarked count 891 891 891 204 889 unique 891 2 681 147 3 top Renouf, Mr. Peter Henry male 1601 C23 C25 C27 S freq 1 577 7 4 644 Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÂú®ËÆ≠ÁªÉÈõÜ‰∏≠Â≠òÂú®ÁùÄÁº∫Â§±ÂÄºÂíåÈîôËØØÂÄºÔºåÊâÄ‰ª•Ë¶ÅÁ≠õÈÄâÂá∫Êúâ‰ª∑ÂÄºÁöÑÁâπÂæÅÔºåÂ°´ÂÖÖÁº∫Â§±ÁöÑÊï∞ÊçÆ„ÄÇ Âà†Èô§È¶ñÂÖàÂà†Èô§Ê≤°Êúâ‰ª∑ÂÄºÊàñ‰ª∑ÂÄºÊØîËæÉ‰ΩéÁöÑÁâπÂæÅ„ÄÇ Ê†πÊçÆÊàë‰ª¨ÁöÑÂÅáËÆæÂíåÂÜ≥ÂÆöÔºåÊàë‰ª¨ÂÖàÊîæÂºÉ Cabin Âíå Ticket „ÄÇ Êàë‰ª¨ÂØπËÆ≠ÁªÉÂíåÊµãËØïÊï∞ÊçÆÈõÜÊâßË°åÁõ∏ÂêåÁöÑÊìç‰Ωú‰ª•‰øùÊåÅÂÖ∂‰∏ÄËá¥„ÄÇ 1234567print("Before", train_df.shape, test_df.shape)train_df = train_df.drop(["Ticket", "Cabin"], axis=1)test_df = test_df.drop(["Ticket", "Cabin"], axis=1)combine = [train_df, test_df]"After", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape Before (891, 12) (418, 11) (&apos;After&apos;, (891, 10), (418, 9), (891, 10), (418, 9)) NameÈ¶ñÂÖàËßÇÂØüÂà∞ Name ÈÉΩÊòØÂîØ‰∏ÄÁöÑÂπ∂‰∏îÂú® Name ‰∏≠Èó¥Â≠òÂú®Áß∞Ë∞ìÔºåÊèêÂèñÂá∫ÂêçÂ≠ó‰∏≠Èó¥ÁöÑÁß∞Ë∞ì„ÄÇ 1234for dataset in combine: dataset["Title"] = dataset.Name.str.extract(' ([A-Za-z]+)\.', expand=False) pd.crosstab(train_df["Title"], train_df["Sex"]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex female male Title Capt 0 1 Col 0 2 Countess 1 0 Don 0 1 Dr 1 6 ... ... ... Mr 0 517 Mrs 125 0 Ms 1 0 Rev 0 6 Sir 0 1 17 rows √ó 2 columns ÊääÁß∞ÂëºÊõøÊç¢‰∏∫Êõ¥‰∏∫Â∏∏ËßÅÁöÑÔºå‰∏çÂ∏∏ËßÅÁöÑÂÆö‰πâ‰∏∫ Rare 123456789for dataset in combine: dataset["Title"] = dataset["Title"].replace(["Lady", "Countess", "Capt", "Col", \ "Don", "Dr", "Major", "Rev", "Sir", \ "Jonkheer", "Dona"], "Rare") dataset["Title"] = dataset["Title"].replace("Mlle", "Miss") dataset["Title"] = dataset["Title"].replace("Ms", "Miss") dataset["Title"] = dataset["Title"].replace("Mme", "Mrs")train_df[["Title", "Survived"]].groupby(["Title"], as_index=False).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Title Survived 0 Master 0.57500 1 Miss 0.70270 2 Mr 0.15667 3 Mrs 0.79365 4 Rare 0.34783 Êää Titles ËΩ¨Êç¢‰∏∫Êï∞Â≠ó 123456title_mapping = &#123;"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5&#125;for dataset in combine: dataset["Title"] = dataset["Title"].map(title_mapping) dataset["Title"] = dataset["Title"].fillna(0) # Áº∫Â§±ÂÄºË°•0train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Fare Embarked Title 0 1 0 3 Braund, Mr. Owen Harris male 22.00000 1 0 7.25000 S 1 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.00000 1 0 71.28330 C 3 2 3 1 3 Heikkinen, Miss. Laina female 26.00000 0 0 7.92500 S 2 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.00000 1 0 53.10000 S 3 4 5 0 3 Allen, Mr. William Henry male 35.00000 0 0 8.05000 S 1 Áé∞Âú®ÂèØ‰ª•Âà†Èô§ Name Âíå PassengerId‰∫Ü 1234train_df = train_df.drop(["Name", "PassengerId"], axis=1)test_df = test_df.drop(["Name"], axis=1)combine = [train_df, test_df]train_df.shape, test_df.shape ((891, 9), (418, 9)) SexÂ∞ÜÂåÖÂê´Â≠óÁ¨¶‰∏≤ÁöÑÁâπÂæÅËΩ¨Êç¢‰∏∫Êï∞ÂÄº„ÄÇËøôÊòØÂ§ßÂ§öÊï∞Ê®°ÂûãÁÆóÊ≥ïÊâÄÂøÖÈúÄÁöÑ„ÄÇËøôÊ†∑ÂÅö‰πüÂ∞ÜÊúâÂä©‰∫éÊàë‰ª¨ÂÆûÁé∞ÂäüËÉΩÂÆåÊàêÁõÆÊ†á„ÄÇ ËÆ©Êàë‰ª¨È¶ñÂÖàÂ∞Ü Sex ÁâπÂæÅËΩ¨Êç¢‰∏∫‰∏Ä‰∏™Êñ∞ÁöÑ featureÔºåÂÖ∂‰∏≠ female = 1Ôºåmale = 0„ÄÇ 1234for dataset in combine: dataset["Sex"] = dataset["Sex"].map(&#123;"female": 1, "male": 0&#125;).astype(int)train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Fare Embarked Title 0 0 3 0 22.00000 1 0 7.25000 S 1 1 1 1 1 38.00000 1 0 71.28330 C 3 2 1 3 1 26.00000 0 0 7.92500 S 2 3 1 1 1 35.00000 1 0 53.10000 S 3 4 0 3 0 35.00000 0 0 8.05000 S 1 AgeÁé∞Âú®Â§ÑÁêÜÁº∫Â∞ëÂÄºÊàñÁ©∫ÂÄºÁöÑÈóÆÈ¢ò„ÄÇÊàë‰ª¨È¶ñÂÖàÂ§ÑÁêÜ Age „ÄÇ ÂèØ‰ª•ËÄÉËôë‰∏âÁßçÊñπÊ≥ïÊù•ÂÆåÊàêÁâπÂæÅÁöÑÂ°´ÂÖÖ„ÄÇ ‰∏ÄÁßçÁÆÄÂçïÁöÑÊñπÊ≥ïÊòØÂú®ÂùáÂÄºÁöÑÊ†áÂáÜÂ∑Æ‰πãÈó¥ÁîüÊàêÈöèÊú∫Êï∞„ÄÇ ‰ΩøÁî®ÂÖ∂‰ªñÁõ∏ÂÖ≥ÁâπÂæÅÁåúÊµãÁº∫Â§±ÂÄº„ÄÇÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨Ê≥®ÊÑèÂà∞ AgeÔºåGender Âíå Pclass ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇÁî®ÁåúÂπ¥ÈæÑÂÄº‰∏≠‰ΩçÂÄºË∑®Ë∂äÂ•ó Pclass ÂíåÊÄßÂà´ÁâπÂæÅÁªÑÂêàÂπ¥ÈæÑ„ÄÇÂõ†Ê≠§ÔºåPclass ÁöÑ‰∏≠‰ΩçÊï∞Âπ¥ÈæÑ = 1‰∏îÊÄßÂà´ = 0ÔºåPclass = 1 ‰∏îÊÄßÂà´ = 1Ôºå‰æùÊ≠§Á±ªÊé®‚Ä¶‚Ä¶ ÁªìÂêàÊñπÊ≥ï1Âíå2Âõ†Ê≠§Ôºå‰∏çÊòØÂü∫‰∫é‰∏≠‰ΩçÊï∞Êù•ÁåúÊµãÂπ¥ÈæÑÂÄºÔºåËÄåÊòØÊ†πÊçÆPclassÂíåGenderÁªÑÂêàÁöÑÈõÜÂêà‰ΩøÁî®ÂùáÂÄºÂíåÊ†áÂáÜÂ∑Æ‰πãÈó¥ÁöÑÈöèÊú∫Êï∞„ÄÇ ÊñπÊ≥ï1Âíå3Â∞ÜÈöèÊú∫Âô™Â£∞ÂºïÂÖ•Êàë‰ª¨ÁöÑÊ®°Âûã„ÄÇÂ§öÊ¨°ÊâßË°åÁöÑÁªìÊûúÂèØËÉΩ‰ºöÊúâÊâÄ‰∏çÂêå„ÄÇÊàë‰ª¨ÈÄâÊã©ÊñπÊ≥ï2„ÄÇ 123grid = sns.FacetGrid(train_df, row="Pclass", col="Sex", size=2.2, aspect=1.6)grid.map(plt.hist, "Age", alpha=0.5, bins=20)grid.add_legend() /usr/local/lib/python3.6/dist-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) &lt;seaborn.axisgrid.FacetGrid at 0x7f3b28420a90&gt; È¶ñÂÖàÂáÜÂ§á‰∏Ä‰∏™Á©∫Êï∞ÁªÑÔºåÁåúÊµã Age Âíå Pclass √ó Geender ÊúâÂÖ≥Á≥ª 12guess_ages = np.zeros((2, 3))guess_ages array([[0., 0., 0.], [0., 0., 0.]]) Áé∞Âú®Êàë‰ª¨Ëø≠‰ª£ Sex(0,1) Âíå Pclass(1,2,3) Êù•ÁåúÊµãËøôÂÖ≠ÁßçÁªÑÂêàÁöÑ Age„ÄÇ 1234567891011121314for dataset in combine: for i in range(0, 2): for j in range(0, 3): guess_df = dataset[(dataset["Sex"] == i) &amp; (dataset["Pclass"] == j+1)]["Age"].dropna() age_guess = guess_df.median() guess_ages[i, j] = int(age_guess/0.5 + 0.5) * 0.5 for i in range(0, 2): for j in range(0, 3): dataset.loc[(dataset.Age.isnull()) &amp; (dataset.Sex == i) &amp; (dataset.Pclass == j+1), "Age"] = guess_ages[i, j] dataset["Age"] = dataset["Age"].astype(int) train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Fare Embarked Title 0 0 3 0 22 1 0 7.25000 S 1 1 1 1 1 38 1 0 71.28330 C 3 2 1 3 1 26 0 0 7.92500 S 2 3 1 1 1 35 1 0 53.10000 S 3 4 0 3 0 35 0 0 8.05000 S 1 ËÆ©Êàë‰ª¨ÂàõÂª∫ AgeBandÔºåÂπ∂Á°ÆÂÆö‰∏éÂ≠òÊ¥ªÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇ 123# ÊääAgeÂàÜ‰∏∫5ÁÆ±train_df["AgeBand"] = pd.cut(train_df["Age"], 5)train_df[["AgeBand", "Survived"]].groupby(["AgeBand"], as_index=False).mean().sort_values(by="AgeBand", ascending=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } AgeBand Survived 0 (-0.08, 16.0] 0.55000 1 (16.0, 32.0] 0.33737 2 (32.0, 48.0] 0.41204 3 (48.0, 64.0] 0.43478 4 (64.0, 80.0] 0.09091 Áî®Ëøô‰∏™È¢ëÁéáÊù•Êää Age ÂàÜ‰∏∫‰∫îÁÆ±Êù•Êõø‰ª£Âéü Age„ÄÇ 12345678for dataset in combine: dataset.loc[dataset["Age"] &lt;= 16, "Age"] = 0 dataset.loc[(dataset["Age"] &gt; 16) &amp; (dataset["Age"] &lt;= 32), "Age"] = 1 dataset.loc[(dataset["Age"] &gt; 32) &amp; (dataset["Age"] &lt;= 48), "Age"] = 2 dataset.loc[(dataset["Age"] &gt; 48) &amp; (dataset["Age"] &lt;= 64), "Age"] = 3 dataset.loc[dataset["Age"] &gt; 64, "Age"] = 4train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Fare Embarked Title AgeBand 0 0 3 0 1 1 0 7.25000 S 1 (16.0, 32.0] 1 1 1 1 2 1 0 71.28330 C 3 (32.0, 48.0] 2 1 3 1 1 0 0 7.92500 S 2 (16.0, 32.0] 3 1 1 1 2 1 0 53.10000 S 3 (32.0, 48.0] 4 0 3 0 2 0 0 8.05000 S 1 (32.0, 48.0] ÁßªÈô§ AgeBand feature 123train_df = train_df.drop(["AgeBand"], axis=1)combine = [train_df, test_df]train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Fare Embarked Title 0 0 3 0 1 1 0 7.25000 S 1 1 1 1 1 2 1 0 71.28330 C 3 2 1 3 1 1 0 0 7.92500 S 2 3 1 1 1 2 1 0 53.10000 S 3 4 0 3 0 2 0 0 8.05000 S 1 EmbarkedEmbarked ÁâπÂæÅÂèñÂÄº‰∏∫ S„ÄÅQ„ÄÅC„ÄÇÊàë‰ª¨ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÊúâ‰∏§‰∏™Áº∫Â§±ÁöÑÂÄº„ÄÇÁî®ÊúÄÂ∏∏ËßÅÁöÑ Embarked Êù•Â°´ÂÖÖÔºà‰ºóÊï∞Â°´ÂÖÖÔºâ„ÄÇ 12freq_port = train_df.Embarked.dropna().mode()[0] # ËøîÂõûÂá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÂÄºÔºà‰ºóÊï∞Ôºâfreq_port &apos;S&apos; 1234for dataset in combine: dataset["Embarked"] = dataset["Embarked"].fillna(freq_port) train_df[["Embarked", "Survived"]].groupby(["Embarked"], as_index=False).mean().sort_values(by="Survived", ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Embarked Survived 0 C 0.55357 1 Q 0.38961 2 S 0.33901 Áé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•Êää Embarked ËΩ¨Êç¢‰∏∫‰∏Ä‰∏™Êñ∞ÁöÑÊï∞Â≠óÂ∫èÂàó„ÄÇ 1234for dataset in combine: dataset["Embarked"] = dataset["Embarked"].map( &#123;"S": 0, "C": 1, "Q": 2&#125; ).astype(int)train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Fare Embarked Title 0 0 3 0 1 1 0 7.25000 0 1 1 1 1 1 2 1 0 71.28330 1 3 2 1 3 1 1 0 0 7.92500 0 2 3 1 1 1 2 1 0 53.10000 0 3 4 0 3 0 2 0 0 8.05000 0 1 FareÁé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® df.fillna Â°´ÂÖÖ test dataset ‰∏≠ Fare ÁöÑÂçï‰∏™Áº∫Â§±ÂÄºÔºå‰ΩøÁî® median Ôºà‰∏≠‰ΩçÊï∞ÔºâÊù•Â°´ÂÖÖ„ÄÇÊàë‰ª¨Âè™ÈúÄË¶Å‰∏ÄË°å‰ª£Á†ÅÂ∞±ÂèØ‰ª•ÂÅöÂà∞Ëøô‰∏ÄÁÇπ„ÄÇ Ê≥®ÊÑèÔºåÊàë‰ª¨Âπ∂Ê≤°ÊúâÂàõÂª∫‰∏Ä‰∏™‰∏≠Èó¥ÁöÑÊñ∞ÁâπÊÄßÔºå‰πüÊ≤°ÊúâÂØπÁõ∏ÂÖ≥ÊÄßËøõË°å‰ªª‰ΩïËøõ‰∏ÄÊ≠•ÁöÑÂàÜÊûêÊù•ÁåúÊµãÁº∫Â§±ÁöÑÁâπÊÄßÔºåÂõ†‰∏∫Êàë‰ª¨Âè™ÊòØÊõøÊç¢‰∫Ü‰∏Ä‰∏™ÂÄº„ÄÇ‰ª•ËææÂà∞‰∫ÜÊ®°ÂûãÁÆóÊ≥ïÂØπÈùûÁ©∫ÂÄºËøêÁÆóÁöÑË¶ÅÊ±Ç„ÄÇ 12test_df["Fare"].fillna(test_df["Fare"].dropna().median(), inplace=True)test_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Pclass Sex Age SibSp Parch Fare Embarked Title 0 892 3 0 2 0 0 7.82920 2 1 1 893 3 1 2 1 0 7.00000 0 3 2 894 2 0 3 0 0 9.68750 2 1 3 895 3 0 1 0 0 8.66250 0 1 4 896 3 1 1 1 1 12.28750 0 3 ÂàõÂª∫‰∏Ä‰∏™ FareBand 12train_df["FareBand"] = pd.qcut(train_df["Fare"], 4)train_df[["FareBand", "Survived"]].groupby(["FareBand"], as_index=False).mean().sort_values(by="FareBand", ascending=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } FareBand Survived 0 (-0.001, 7.91] 0.19731 1 (7.91, 14.454] 0.30357 2 (14.454, 31.0] 0.45495 3 (31.0, 512.329] 0.58108 Âü∫‰∫é FareBand Â∞Ü Fare ËΩ¨Êç¢‰∏∫Â∫èÂàóÂÄº„ÄÇ 12345678910for dataset in combine: dataset.loc[dataset["Fare"] &lt;= 7.91, "Fare"] = 0 dataset.loc[(dataset["Fare"] &gt; 7.91) &amp; (dataset["Fare"] &lt;= 14.454), "Fare"] = 1 dataset.loc[(dataset["Fare"] &gt; 14.454) &amp; (dataset["Fare"] &lt;= 31), "Fare"] = 2 dataset.loc[dataset["Fare"] &gt; 31, "Fare"] = 3 dataset["Fare"] = dataset["Fare"].astype(int)train_df = train_df.drop(["FareBand"], axis=1)combine = [train_df, test_df]train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass Sex Age SibSp Parch Fare Embarked Title 0 0 3 0 1 1 0 0 0 1 1 1 1 1 2 1 0 3 1 3 2 1 3 1 1 0 0 1 0 2 3 1 1 1 2 1 0 3 0 3 4 0 3 0 2 0 0 1 0 1 Ê®°ÂûãÈ¢ÑÊµã1234X_train = train_df.drop("Survived", axis=1)Y_train = train_df["Survived"]X_test = test_df.drop("PassengerId", axis=1).copy()X_train.shape, Y_train.shape, X_test.shape ((891, 8), (891,), (418, 8)) 12X_train.describe()X_test .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Pclass Sex Age SibSp Parch Fare Embarked Title 0 3 0 2 0 0 0 2 1 1 3 1 2 1 0 0 0 3 2 2 0 3 0 0 1 2 1 3 3 0 1 0 0 1 0 1 4 3 1 1 1 1 1 0 3 ... ... ... ... ... ... ... ... ... 413 3 0 1 0 0 1 0 1 414 1 1 2 0 0 3 1 5 415 3 0 2 0 0 0 0 1 416 3 0 1 0 0 1 0 1 417 3 0 1 1 1 2 1 4 418 rows √ó 8 columns Áé∞Âú®ÔºåÊàë‰ª¨ÂáÜÂ§áËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÂπ∂È¢ÑÊµã„ÄÇÊúâ60Â§öÁßçÈ¢ÑÊµãÂª∫Ê®°ÁÆóÊ≥ïÂèØ‰æõÈÄâÊã©„ÄÇÊàë‰ª¨ÂøÖÈ°ª‰∫ÜËß£ÈóÆÈ¢òÁöÑÁ±ªÂûãÂíåËß£ÂÜ≥ÊñπÊ°àÁöÑÈúÄÊ±ÇÔºå‰ª•‰æøÂ∞ÜËåÉÂõ¥Áº©Â∞èÂà∞Êàë‰ª¨ÂèØ‰ª•ËØÑ‰º∞ÁöÑÂá†‰∏™ÈÄâÂÆöÁöÑÊ®°Âûã„ÄÇ Êàë‰ª¨ÁöÑÈóÆÈ¢òÊòØ‰∏Ä‰∏™ÂàÜÁ±ªÂíåÂõûÂΩíÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÊÉ≥Ë¶ÅÁ°ÆÂÆöËæìÂá∫(Survived or not)‰∏éÂÖ∂‰ªñÂèòÈáèÊàñÁâπÊÄß(Gender, Age, Port‚Ä¶‚Ä¶)‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇËøôÊòØ‰∏Ä‰∏™ÁõëÁù£Â≠¶‰π†„ÄÇÊúâ‰∫ÜËøô‰∏§‰∏™Ê†áÂáÜ ‚Äî‚Äî ÁõëÁù£Â≠¶‰π†Âä†‰∏äÂàÜÁ±ªÂíåÂõûÂΩíÔºåÊàë‰ª¨ÂèØ‰ª•ÊääÊ®°ÂûãÁöÑÈÄâÊã©ËåÉÂõ¥Áº©Â∞èÂà∞Âá†‰∏™„ÄÇ Ëøô‰∫õÂåÖÊã¨: ÈÄªËæëÂõûÂΩí KNNÊàñkËøëÈÇª ÊîØÊåÅÂêëÈáèÊú∫ Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô® ÂÜ≥Á≠ñÊ†ë ÈöèÊú∫Ê£ÆÊûó ÊÑüÁü•Âô® ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôç RVM Áõ∏ÂÖ≥ÂêëÈáèÊú∫ 1234567# ÈÄªËæëÂõûÂΩílogreg = LogisticRegression()logreg.fit(X_train, Y_train)Y_pred = logreg.predict(X_test)acc_log = round(logreg.score(X_train, Y_train) * 100, 2)acc_log /usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning. FutureWarning) 81.37 Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®ÈÄªËæëÂõûÂΩíÊù•È™åËØÅÂíåÊ£ÄÊü•Êàë‰ª¨ÁöÑÈ¢ÑÊµã„ÄÇÂèØ‰ª•ÈÄöËøáËÆ°ÁÆóÂÜ≥Á≠ñÂáΩÊï∞‰∏≠ÁâπÂæÅÁöÑÁ≥ªÊï∞Êù•ÂÆûÁé∞„ÄÇ Ê≠£Á≥ªÊï∞Â¢ûÂä†‰∫ÜÂìçÂ∫îÁöÑ log-odds (‰ªéËÄåÂ¢ûÂä†‰∫ÜÊ¶ÇÁéá)ÔºåË¥üÁ≥ªÊï∞ÂáèÂ∞ë‰∫ÜÂìçÂ∫îÁöÑ log-odds (‰ªéËÄåÂáèÂ∞ë‰∫ÜÊ¶ÇÁéá)„ÄÇÊÄßÂà´ÊòØÊ≠£Á≥ªÊï∞ÊúÄÈ´òÁöÑÔºåËØ¥ÊòéÈöèÁùÄÊÄßÂà´ÂÄºÁöÑÂ¢ûÂä†(Áî∑ÊÄß: 0 Â•≥ÊÄß:1)ÔºåÂ≠òÊ¥ªÁöÑÊ¶ÇÁéáÂ¢ûÂä†ÊúÄÂ§ö„ÄÇÁõ∏ÂèçÔºåÈöèÁùÄ Pclass ÁöÑÂ¢ûÂä†ÔºåÁîüÂ≠òÊ¶ÇÁéá‰∏ãÈôç„ÄÇËøôÊ†∑ÔºåAge ÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑ‰∫∫Â∑•ÁâπÂæÅÔºåÂõ†‰∏∫ÂÆÉ‰∏éÂ≠òÊ¥ªÊúâÁ¨¨‰∫åÈ´òÁöÑË¥üÁõ∏ÂÖ≥„ÄÇTitle ‰πüÊòØÁ¨¨‰∫åÈ´òÁöÑÊ≠£Áõ∏ÂÖ≥„ÄÇ 12345coeff_df = pd.DataFrame(train_df.columns.delete(0))coeff_df.columns = ['Feature']coeff_df["Correlation"] = pd.Series(logreg.coef_[0])coeff_df.sort_values(by='Correlation', ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Feature Correlation 1 Sex 2.19360 7 Title 0.49431 5 Fare 0.31180 6 Embarked 0.24051 4 Parch -0.25322 3 SibSp -0.50649 2 Age -0.65716 0 Pclass -0.91037 ÂÖ∂Ê¨°ÔºåÊàë‰ª¨‰ΩøÁî®ÊîØÊåÅÂêëÈáèÊú∫Âª∫Ê®°ÔºåËøôÊòØÁõëÁù£Â≠¶‰π†ÁöÑÁÆóÊ≥ïÔºåÁî®‰∫éÊï∞ÊçÆÂàÜÁ±ªÂíåÂõûÂΩíÂàÜÊûê„ÄÇÁªôÂÆö‰∏ÄÁªÑËÆ≠ÁªÉÊ†∑Êú¨ÔºåÊØè‰∏™Ê†∑Êú¨ÈÉΩË¢´Ê†áËÆ∞‰∏∫Â±û‰∫é‰∏§‰∏™Á±ªÂà´‰∏≠ÁöÑ‰∏Ä‰∏™ÊàñÂè¶‰∏Ä‰∏™Á±ªÂà´ÔºåSVMËÆ≠ÁªÉÁÆóÊ≥ïÂª∫Á´ã‰∏Ä‰∏™Ê®°ÂûãÔºåÂ∞ÜÊñ∞ÁöÑÊµãËØïÊ†∑Êú¨ÂàÜÈÖçÁªôÂÖ∂‰∏≠‰∏Ä‰∏™Á±ªÂà´ÊàñÂè¶‰∏Ä‰∏™Á±ªÂà´Ôºå‰ΩøÂÖ∂Êàê‰∏∫‰∏Ä‰∏™ÈùûÊ¶ÇÁéá‰∫åÂÖÉÁ∫øÊÄßÂàÜÁ±ªÂô®„ÄÇ ËØ•Ê®°ÂûãÁîüÊàêÁöÑËØÑÂàÜÈ´ò‰∫éÈÄªËæëÂõûÂΩíÊ®°Âûã„ÄÇ 1234567# Support Vector Machinessvm = SVC()svm.fit(X_train, Y_train)Y_pred = svm.predict(X_test)acc_svm = round(svm.score(X_train, Y_train) * 100, 2)acc_svm /usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from &apos;auto&apos; to &apos;scale&apos; in version 0.22 to account better for unscaled features. Set gamma explicitly to &apos;auto&apos; or &apos;scale&apos; to avoid this warning. &quot;avoid this warning.&quot;, FutureWarning) 83.73 Âú®Ê®°ÂºèËØÜÂà´‰∏≠ÔºåkËøëÈÇªÁÆóÊ≥ï(ÁÆÄÁß∞k-NN)ÊòØ‰∏ÄÁßçÁî®‰∫éÂàÜÁ±ªÂíåÂõûÂΩíÁöÑÈùûÂèÇÊï∞ÁÆóÊ≥ï„ÄÇ‰∏Ä‰∏™Ê†∑Êú¨Áî±ÂÆÉÁöÑÈÇªÂ±ÖÁöÑÂ§öÊï∞ÊäïÁ•®Êù•ÂàÜÁ±ªÔºåËøô‰∏™Ê†∑Êú¨Ë¢´ÂàÜÈÖçÂà∞ÂÆÉÁöÑk‰∏™ÊúÄËøëÈÇªÂ±Ö‰∏≠ÊúÄÂ∏∏ËßÅÁöÑÁ±ª(kÊòØ‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºåÈÄöÂ∏∏ÂæàÂ∞è)„ÄÇÂ¶ÇÊûú k = 1ÔºåÈÇ£‰πàÂØπË±°Â∞±Ë¢´ÁÆÄÂçïÂú∞ÂàÜÈÖçÁªôÈÇ£‰∏™ÊúÄËøëÈÇªÂ±ÖÁöÑÁ±ª„ÄÇ KNNÂæóÂàÜ‰ºò‰∫élogisticÂõûÂΩíÔºå‰ΩÜ‰Ωé‰∫éSVM„ÄÇ 1234567# KNNknn = KNeighborsClassifier(n_neighbors = 3)knn.fit(X_train, Y_train)Y_pred = knn.predict(X_test)acc_knn = round(knn.score(X_train, Y_train) * 100, 2)acc_knn 84.4 Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÊú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®ÊòØ‰∏ÄÁªÑÂü∫‰∫éË¥ùÂè∂ÊñØÂÆöÁêÜÁöÑÁÆÄÂçïÊ¶ÇÁéáÂàÜÁ±ªÂô®ÔºåÁâπÂæÅ‰πãÈó¥ÂÖ∑ÊúâÂº∫(Êú¥Á¥†)Áã¨Á´ãÊÄßÂÅáËÆæ„ÄÇÊú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®ÊòØÈ´òÂ∫¶ÂèØ‰º∏Áº©ÁöÑÔºåÂú®‰∏Ä‰∏™Â≠¶‰π†ÈóÆÈ¢ò‰∏≠ÈúÄË¶Å‰∏Ä‰∫õÂèÇÊï∞Âú®ÂèòÈáè(ÁâπÂæÅ)ÁöÑÊï∞Èáè‰∏äÊòØÁ∫øÊÄßÁöÑ„ÄÇ Ê®°ÂûãÁîüÊàêÁöÑÁΩÆ‰ø°Â∫¶ËØÑÂàÜÊòØÁõÆÂâçËØÑ‰ª∑Ê®°Âûã‰∏≠ÊúÄ‰ΩéÁöÑ„ÄÇ 1234567# Gaussian Naive Bayesgaussian = GaussianNB()gaussian.fit(X_train, Y_train)Y_pred = gaussian.predict(X_test)acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)acc_gaussian 80.13 ÊÑüÁü•Âô®ÊòØ‰∏ÄÁßç‰∫åËøõÂà∂ÂàÜÁ±ªÂô®ÁöÑÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï(ÂáΩÊï∞ÔºåÂÆÉÂèØ‰ª•ÂÜ≥ÂÆö‰∏Ä‰∏™ËæìÂÖ•ÊòØÂê¶Â±û‰∫éÊüê‰∏™ÁâπÂÆöÁöÑÁ±ªÔºåÁî±‰∏Ä‰∏™Êï∞Â≠óÂêëÈáèË°®Á§∫)„ÄÇÂÆÉÊòØ‰∏ÄÁßçÁ∫øÊÄßÂàÜÁ±ªÂô®ÔºåÂç≥Âü∫‰∫é‰∏ÄÁªÑÊùÉÂÄº‰∏éÁâπÂæÅÂêëÈáèÁõ∏ÁªìÂêàÁöÑÁ∫øÊÄßÈ¢ÑÊµãÂáΩÊï∞ËøõË°åÈ¢ÑÊµãÁöÑÂàÜÁ±ªÁÆóÊ≥ï„ÄÇËØ•ÁÆóÊ≥ïÂÖÅËÆ∏Âú®Á∫øÂ≠¶‰π†ÔºåÊØèÊ¨°Â§ÑÁêÜËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑ‰∏Ä‰∏™ÂÖÉÁ¥†„ÄÇ 1234567# Perceptronperceptron = Perceptron()perceptron.fit(X_train, Y_train)Y_pred = perceptron.predict(X_test)acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)acc_perceptron 80.58 1234567# Linear SVClinear_svc = LinearSVC()linear_svc.fit(X_train, Y_train)Y_pred = linear_svc.predict(X_test)acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)acc_linear_svc /usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. &quot;the number of iterations.&quot;, ConvergenceWarning) 81.14 1234567# Stochastic Gradient Descentsgd = SGDClassifier()sgd.fit(X_train, Y_train)Y_pred = sgd.predict(X_test)acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)acc_sgd 80.92 ‰ΩøÁî®ÂÜ≥Á≠ñÊ†ë‰Ωú‰∏∫È¢ÑÊµãÊ®°ÂûãÔºåÊòØ‰∏ÄÁßçÂçÅÂàÜÂ∏∏Áî®ÁöÑÂàÜÁ±ªÊñπÊ≥ï„ÄÇ‰ªñÊòØ‰∏ÄÁßçÁõëÁÆ°Â≠¶‰π†ÔºåÊâÄË∞ìÁõëÁÆ°Â≠¶‰π†Â∞±ÊòØÁªôÂÆö‰∏ÄÂ†ÜÊ†∑Êú¨ÔºåÊØè‰∏™Ê†∑Êú¨ÈÉΩÊúâ‰∏ÄÁªÑÂ±ûÊÄßÂíå‰∏Ä‰∏™Á±ªÂà´ÔºåËøô‰∫õÁ±ªÂà´ÊòØ‰∫ãÂÖàÁ°ÆÂÆöÁöÑÔºåÈÇ£‰πàÈÄöËøáÂ≠¶‰π†ÂæóÂà∞‰∏Ä‰∏™ÂàÜÁ±ªÂô®ÔºåËøô‰∏™ÂàÜÁ±ªÂô®ËÉΩÂ§üÂØπÊñ∞Âá∫Áé∞ÁöÑÂØπË±°ÁªôÂá∫Ê≠£Á°ÆÁöÑÂàÜÁ±ª„ÄÇ ÁõÆÂâçÊ®°Âûã‰∏≠ÊúÄÈ´òÁöÑËØÑÂàÜ„ÄÇ 1234567# Decision Treedecision_tree = DecisionTreeClassifier()decision_tree.fit(X_train, Y_train)Y_pred = decision_tree.predict(X_test)acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)acc_decision_tree 89.0 ‰∏ã‰∏Ä‰∏™Ê®°ÂûãÈöèÊú∫Ê£ÆÊûóÊòØÊúÄÂèóÊ¨¢ËøéÁöÑ‰πã‰∏Ä„ÄÇ‰∏Ä‰∏™ÂåÖÂê´Â§ö‰∏™ÂÜ≥Á≠ñÊ†ëÁöÑÂàÜÁ±ªÂô®Ôºå Âπ∂‰∏îÂÖ∂ËæìÂá∫ÁöÑÁ±ªÂà´ÊòØÁî±‰∏™Âà´Ê†ëËæìÂá∫ÁöÑÁ±ªÂà´ÁöÑ‰ºóÊï∞ËÄåÂÆö„ÄÇ Ê®°ÂûãÁõÆÂâçËØÑÂàÜ‰∏≠ÊúÄÈ´òÁöÑ„ÄÇÊàë‰ª¨ÂÜ≥ÂÆö‰ΩøÁî®Ëøô‰∏™Ê®°ÂûãÁöÑËæìÂá∫(Y_pred)Êèê‰∫§ÁªìÊûú„ÄÇ 12345678# Random Forestrandom_forest = RandomForestClassifier(n_estimators=100)random_forest.fit(X_train, Y_train)Y_pred = random_forest.predict(X_test)random_forest.score(X_train, Y_train)acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)acc_random_forest 89.0 Ê®°ÂûãËØÑ‰ª∑Áé∞Âú®Êàë‰ª¨ÂèØ‰ª•ÂØπÊâÄÊúâÊ®°ÂûãÁöÑËØÑ‰º∞ËøõË°åÊéíÂ∫èÔºå‰ª•ÈÄâÊã©ÊúÄÈÄÇÂêàÊàë‰ª¨ÈóÆÈ¢òÁöÑÊ®°Âûã„ÄÇÂú®ÂÜ≥Á≠ñÊ†ëÂíåÈöèÊú∫Ê£ÆÊûóÂæóÂàÜÁõ∏ÂêåÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÈÄâÊã©ÈöèÊú∫Ê£ÆÊûóÊù•Á∫†Ê≠£ÂÜ≥Á≠ñÊ†ëÂØπËÆ≠ÁªÉÈõÜËøáÂ∫¶ÊãüÂêàÁöÑ‰π†ÊÉØ„ÄÇ 12345678models = pd.DataFrame(&#123; "Model": ["Support Vector Machines", "KNN", "Logistic Regression", "Random Forest", "Naive Bayes", "Percep tron", "Stochastic Gradient Decent", "Linear SVC", "Decision Tree"], "Score": [acc_svm, acc_knn, acc_log, acc_random_forest, acc_gaussian, acc_perceptron, acc_sgd, acc_linear_svc, acc_decision_tree] &#125;)models.sort_values(by="Score", ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Model Score 3 Random Forest 89.00000 8 Decision Tree 89.00000 1 KNN 84.40000 0 Support Vector Machines 83.73000 2 Logistic Regression 81.37000 7 Linear SVC 81.14000 6 Stochastic Gradient Decent 80.92000 5 Percep tron 80.58000 4 Naive Bayes 80.13000 1234567# ‰øùÂ≠òÁªìÊûúsubmission = pd.DataFrame(&#123; "PassengerId": test_df["PassengerId"], "Survived": Y_pred &#125;)submission.to_csv("/submission.csv", index=False)]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[House Prices Advanced Regression Techniques V2]]></title>
    <url>%2F2019%2F05%2F28%2FHouse_Prices_Advanced_Regression_Techniques_V2%2F</url>
    <content type="text"><![CDATA[Kaggle Competition ÁöÑÁªÉ‰π† Êàø‰ª∑È¢ÑÊµã 12# ÂÆâË£Ö vecstack!pip install vecstack 1234567891011121314151617181920212223242526272829# Êï∞ÊçÆÂàÜÊûêÂ∫ìimport pandas as pdimport numpy as npimport random# Êï∞ÊçÆÂèØËßÜÂåñimport seaborn as snsimport matplotlib.pyplot as pltplt.style.use('ggplot')# Êú∫Âô®Â≠¶‰π†Â∫ìfrom sklearn.preprocessing import OneHotEncoderfrom sklearn.linear_model import LogisticRegressionfrom sklearn.svm import SVC, LinearSVCfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressorfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.naive_bayes import GaussianNBfrom sklearn.linear_model import Perceptronfrom sklearn.linear_model import SGDClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.metrics import r2_score, mean_squared_errorfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold, train_test_split# Ensemble Modelsfrom xgboost import XGBRegressorfrom lightgbm import LGBMRegressor# Package for stacking modelsfrom vecstack import stacking ÂØºÂÖ•Êï∞ÊçÆ1234train = pd.read_csv('/train.csv', index_col='Id')test = pd.read_csv('/test.csv', index_col='Id')train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF Heating HeatingQC CentralAir Electrical 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice Id 1 60 RL 65.0 8450 Pave NaN Reg Lvl AllPub Inside Gtl CollgCr Norm Norm 1Fam 2Story 7 5 2003 2003 Gable CompShg VinylSd VinylSd BrkFace 196.0 Gd TA PConc Gd TA No GLQ 706 Unf 0 150 856 GasA Ex Y SBrkr 856 854 0 1710 1 0 2 1 3 1 Gd 8 Typ 0 NaN Attchd 2003.0 RFn 2 548 TA TA Y 0 61 0 0 0 0 NaN NaN NaN 0 2 2008 WD Normal 208500 2 20 RL 80.0 9600 Pave NaN Reg Lvl AllPub FR2 Gtl Veenker Feedr Norm 1Fam 1Story 6 8 1976 1976 Gable CompShg MetalSd MetalSd None 0.0 TA TA CBlock Gd TA Gd ALQ 978 Unf 0 284 1262 GasA Ex Y SBrkr 1262 0 0 1262 0 1 2 0 3 1 TA 6 Typ 1 TA Attchd 1976.0 RFn 2 460 TA TA Y 298 0 0 0 0 0 NaN NaN NaN 0 5 2007 WD Normal 181500 3 60 RL 68.0 11250 Pave NaN IR1 Lvl AllPub Inside Gtl CollgCr Norm Norm 1Fam 2Story 7 5 2001 2002 Gable CompShg VinylSd VinylSd BrkFace 162.0 Gd TA PConc Gd TA Mn GLQ 486 Unf 0 434 920 GasA Ex Y SBrkr 920 866 0 1786 1 0 2 1 3 1 Gd 6 Typ 1 TA Attchd 2001.0 RFn 2 608 TA TA Y 0 42 0 0 0 0 NaN NaN NaN 0 9 2008 WD Normal 223500 4 70 RL 60.0 9550 Pave NaN IR1 Lvl AllPub Corner Gtl Crawfor Norm Norm 1Fam 2Story 7 5 1915 1970 Gable CompShg Wd Sdng Wd Shng None 0.0 TA TA BrkTil TA Gd No ALQ 216 Unf 0 540 756 GasA Gd Y SBrkr 961 756 0 1717 1 0 1 0 3 1 Gd 7 Typ 1 Gd Detchd 1998.0 Unf 3 642 TA TA Y 0 35 272 0 0 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 5 60 RL 84.0 14260 Pave NaN IR1 Lvl AllPub FR2 Gtl NoRidge Norm Norm 1Fam 2Story 8 5 2000 2000 Gable CompShg VinylSd VinylSd BrkFace 350.0 Gd TA PConc Gd TA Av GLQ 655 Unf 0 490 1145 GasA Ex Y SBrkr 1145 1053 0 2198 1 0 2 1 4 1 Gd 9 Typ 1 TA Attchd 2000.0 RFn 3 836 TA TA Y 192 84 0 0 0 0 NaN NaN NaN 0 12 2008 WD Normal 250000 ÊµèËßàÊï∞ÊçÆ1train.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; Int64Index: 1460 entries, 1 to 1460 Data columns (total 80 columns): MSSubClass 1460 non-null int64 MSZoning 1460 non-null object LotFrontage 1201 non-null float64 LotArea 1460 non-null int64 Street 1460 non-null object Alley 91 non-null object LotShape 1460 non-null object LandContour 1460 non-null object Utilities 1460 non-null object LotConfig 1460 non-null object LandSlope 1460 non-null object Neighborhood 1460 non-null object Condition1 1460 non-null object Condition2 1460 non-null object BldgType 1460 non-null object HouseStyle 1460 non-null object OverallQual 1460 non-null int64 OverallCond 1460 non-null int64 YearBuilt 1460 non-null int64 YearRemodAdd 1460 non-null int64 RoofStyle 1460 non-null object RoofMatl 1460 non-null object Exterior1st 1460 non-null object Exterior2nd 1460 non-null object MasVnrType 1452 non-null object MasVnrArea 1452 non-null float64 ExterQual 1460 non-null object ExterCond 1460 non-null object Foundation 1460 non-null object BsmtQual 1423 non-null object BsmtCond 1423 non-null object BsmtExposure 1422 non-null object BsmtFinType1 1423 non-null object BsmtFinSF1 1460 non-null int64 BsmtFinType2 1422 non-null object BsmtFinSF2 1460 non-null int64 BsmtUnfSF 1460 non-null int64 TotalBsmtSF 1460 non-null int64 Heating 1460 non-null object HeatingQC 1460 non-null object CentralAir 1460 non-null object Electrical 1459 non-null object 1stFlrSF 1460 non-null int64 2ndFlrSF 1460 non-null int64 LowQualFinSF 1460 non-null int64 GrLivArea 1460 non-null int64 BsmtFullBath 1460 non-null int64 BsmtHalfBath 1460 non-null int64 FullBath 1460 non-null int64 HalfBath 1460 non-null int64 BedroomAbvGr 1460 non-null int64 KitchenAbvGr 1460 non-null int64 KitchenQual 1460 non-null object TotRmsAbvGrd 1460 non-null int64 Functional 1460 non-null object Fireplaces 1460 non-null int64 FireplaceQu 770 non-null object GarageType 1379 non-null object GarageYrBlt 1379 non-null float64 GarageFinish 1379 non-null object GarageCars 1460 non-null int64 GarageArea 1460 non-null int64 GarageQual 1379 non-null object GarageCond 1379 non-null object PavedDrive 1460 non-null object WoodDeckSF 1460 non-null int64 OpenPorchSF 1460 non-null int64 EnclosedPorch 1460 non-null int64 3SsnPorch 1460 non-null int64 ScreenPorch 1460 non-null int64 PoolArea 1460 non-null int64 PoolQC 7 non-null object Fence 281 non-null object MiscFeature 54 non-null object MiscVal 1460 non-null int64 MoSold 1460 non-null int64 YrSold 1460 non-null int64 SaleType 1460 non-null object SaleCondition 1460 non-null object SalePrice 1460 non-null int64 dtypes: float64(3), int64(34), object(43) memory usage: 923.9+ KB 1train.describe(include="O") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinType2 Heating HeatingQC CentralAir Electrical KitchenQual Functional FireplaceQu GarageType GarageFinish GarageQual GarageCond PavedDrive PoolQC Fence MiscFeature SaleType SaleCondition count 1460 1460 91 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1452 1460 1460 1460 1423 1423 1422 1423 1422 1460 1460 1460 1459 1460 1460 770 1379 1379 1379 1379 1460 7 281 54 1460 1460 unique 5 2 2 4 4 2 5 3 25 9 8 5 8 6 8 15 16 4 4 5 6 4 4 4 6 6 6 5 2 5 4 7 5 6 3 5 5 3 3 4 4 9 6 top RL Pave Grvl Reg Lvl AllPub Inside Gtl NAmes Norm Norm 1Fam 1Story Gable CompShg VinylSd VinylSd None TA TA PConc TA TA No Unf Unf GasA Ex Y SBrkr TA Typ Gd Attchd Unf TA TA Y Gd MnPrv Shed WD Normal freq 1151 1454 50 925 1311 1459 1052 1382 225 1260 1445 1220 726 1141 1434 515 504 864 906 1282 647 649 1311 953 430 1256 1428 741 1365 1334 735 1360 380 870 605 1311 1326 1340 3 157 49 1267 1198 Ê£ÄÊü•Áº∫Â§±Êï∞ÊçÆ123train_missing = train.isnull().sum()train_missing = train_missing[train_missing &gt; 0]train_missing LotFrontage 259 Alley 1369 MasVnrType 8 MasVnrArea 8 BsmtQual 37 BsmtCond 37 BsmtExposure 38 BsmtFinType1 37 BsmtFinType2 38 Electrical 1 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageQual 81 GarageCond 81 PoolQC 1453 Fence 1179 MiscFeature 1406 dtype: int64 123test_missing = test.isnull().sum()test_missing = test_missing[test_missing &gt; 0]test_missing MSZoning 4 LotFrontage 227 Alley 1352 Utilities 2 Exterior1st 1 Exterior2nd 1 MasVnrType 16 MasVnrArea 15 BsmtQual 44 BsmtCond 45 BsmtExposure 44 BsmtFinType1 42 BsmtFinSF1 1 BsmtFinType2 42 BsmtFinSF2 1 BsmtUnfSF 1 TotalBsmtSF 1 BsmtFullBath 2 BsmtHalfBath 2 KitchenQual 1 Functional 2 FireplaceQu 730 GarageType 76 GarageYrBlt 78 GarageFinish 78 GarageCars 1 GarageArea 1 GarageQual 78 GarageCond 78 PoolQC 1456 Fence 1169 MiscFeature 1408 SaleType 1 dtype: int64 1234567891011121314151617# ÂèØËßÜÂåñÁº∫Â§±Êï∞ÊçÆdef plot_missing(df): # ÂØªÊâæÁº∫Â§±ÁöÑÂàó missing = df.isnull().sum() missing = missing[missing &gt; 0] missing.sort_values(inplace=True) # ÁîªÂá∫Áº∫Â§±ÂÄºÁöÑÊü±Áä∂Âõæ„ÄÇ missing.plot.bar(figsize=(10,8)) plt.xlabel('Columns with missing values') plt.ylabel('Count') # ÊêúÁ¥¢Áº∫Â§±ÂÄº import missingno as msno msno.matrix(df=df, figsize=(10,8)) # Êü•ÁúãÁõ∏ÂÖ≥ÊÄß #msno.heatmap(df=df,figsize=(10,8)) 1plot_missing(train) 1plot_missing(test) ÂàÜÊûêÊ¶ÇË¶Å‰ª•‰∏ãÊòØÁº∫Â§±ÊØîËæÉÂ§öÁöÑfeature Feature Train miss Test miss Dispos LotFrontage 259 227 Â°´‰∏™‰∏≠‰ΩçÊï∞Âêß Alley 1369 1352 Âà†Èô§ FireplaceQu 690 730 fireplaceQU Âíå fireplaces ÊúâÂÖ≥ Áº∫Â§±È°πË≤å‰ººÈÉΩÊòØÊ≤°ÊúâfireplaceÁöÑ PoolQC 1453 1456 Âà†Èô§ Fence 1179 1169 Âà†Èô§ MiscFeature 1406 1408 Âà†Èô§ Â§ÑÁêÜÁº∫Â§±ÂÄº123# Âà†Èô§Áº∫Â§±ËøáÂ§öÁöÑfeaturetrain = train.drop(['Alley', 'PoolQC', 'MiscFeature', 'Fence'], axis=1)test = test.drop(['Alley', 'PoolQC', 'MiscFeature', 'Fence'], axis=1) 123# FireplaceQu Áº∫Â§±ÁöÑÈÉΩËÆ§‰∏∫ÊòØÊ≤°ÊúâÁöÑtrain['FireplaceQu'] = train['FireplaceQu'].fillna('NA')test['FireplaceQu'] = test['FireplaceQu'].fillna('NA') 12345678910111213# Â°´ÂÖÖÂÖ∂‰ªñÁº∫Â§±ÂÄºdef fill_missing_values(df): # Êü•ÊâæÁº∫Â§±ÂÄº missing = df.isnull().sum() missing = missing[missing &gt; 0] for column in missing.index: # Á±ªÂûã‰∏∫ object ÁöÑÂ°´‰ºóÊï∞ if df[column].dtype == 'object': df[column].fillna(df[column].value_counts().index[0], inplace=True) # ÂÖ∂‰ªñÁ±ªÂûãÂ°´‰∏≠‰ΩçÊï∞ else: df[column].fillna(df[column].median(), inplace=True) 12fill_missing_values(train)train.isnull().sum().max() 0 12fill_missing_values(test)test.isnull().sum().max() 0 Â•ΩÁöÑÔºåÂ∑≤ÁªèÊ≤°ÊúâÁº∫Â§±Êï∞ÊçÆ‰∫Ü„ÄÇ Êï¥ÁêÜ description Êñá‰ª∂Êï∞ÊçÆÊèèËø∞Êñá‰ª∂ËÆ∞ÂΩï‰∫ÜÊâÄÊúâÁâπÂæÅÊâÄ‰ª£Ë°®ÁöÑÂê´‰πâÔºåÂÖ∂‰∏≠ËÆ∏Â§öÁâπÂæÅÊòØÂ≠óÁ¨¶‰∏≤ÔºåÁé∞Âú®Êàë‰ª¨Ë¶ÅÊï¥ÁêÜ‰∏∫‰∏™Â≠óÂÖ∏Ôºå‰æø‰∫éÊàë‰ª¨Êü•ËØ¢„ÄÇ 123456description_dict = &#123;&#125;with open('/data_description.txt','r') as description: description_data = description.read() description.close() description_data = description_data.split('\n') 123456789for i in description_data: if ':' in i: key = i.split(':')[0] description_dict[key] = [] elif i.split() and ' ' in i: value = i.split()[0] description_dict[key].append(value)print(description_dict) {&apos;MSSubClass&apos;: [&apos;20&apos;, &apos;30&apos;, &apos;40&apos;, &apos;45&apos;, &apos;50&apos;, &apos;60&apos;, &apos;70&apos;, &apos;75&apos;, &apos;80&apos;, &apos;85&apos;, &apos;90&apos;, &apos;120&apos;, &apos;150&apos;, &apos;160&apos;, &apos;180&apos;, &apos;190&apos;], &apos;MSZoning&apos;: [&apos;A&apos;, &apos;C&apos;, &apos;FV&apos;, &apos;I&apos;, &apos;RH&apos;, &apos;RL&apos;, &apos;RP&apos;, &apos;RM&apos;], &apos;LotFrontage&apos;: [], &apos;LotArea&apos;: [], &apos;Street&apos;: [&apos;Grvl&apos;, &apos;Pave&apos;], &apos;Alley&apos;: [&apos;Grvl&apos;, &apos;Pave&apos;, &apos;NA&apos;], &apos;LotShape&apos;: [&apos;Reg&apos;, &apos;IR1&apos;, &apos;IR2&apos;, &apos;IR3&apos;], &apos;LandContour&apos;: [&apos;Lvl&apos;, &apos;Bnk&apos;, &apos;HLS&apos;, &apos;Low&apos;], &apos;Utilities&apos;: [&apos;AllPub&apos;, &apos;NoSewr&apos;, &apos;NoSeWa&apos;, &apos;ELO&apos;], &apos;LotConfig&apos;: [&apos;Inside&apos;, &apos;Corner&apos;, &apos;CulDSac&apos;, &apos;FR2&apos;, &apos;FR3&apos;], &apos;LandSlope&apos;: [&apos;Gtl&apos;, &apos;Mod&apos;, &apos;Sev&apos;], &apos;Neighborhood&apos;: [&apos;Blmngtn&apos;, &apos;Blueste&apos;, &apos;BrDale&apos;, &apos;BrkSide&apos;, &apos;ClearCr&apos;, &apos;CollgCr&apos;, &apos;Crawfor&apos;, &apos;Edwards&apos;, &apos;Gilbert&apos;, &apos;IDOTRR&apos;, &apos;MeadowV&apos;, &apos;Mitchel&apos;, &apos;Names&apos;, &apos;NoRidge&apos;, &apos;NPkVill&apos;, &apos;NridgHt&apos;, &apos;NWAmes&apos;, &apos;OldTown&apos;, &apos;SWISU&apos;, &apos;Sawyer&apos;, &apos;SawyerW&apos;, &apos;Somerst&apos;, &apos;StoneBr&apos;, &apos;Timber&apos;, &apos;Veenker&apos;], &apos;Condition1&apos;: [&apos;Artery&apos;, &apos;Feedr&apos;, &apos;Norm&apos;, &apos;RRNn&apos;, &apos;RRAn&apos;, &apos;PosN&apos;, &apos;PosA&apos;, &apos;RRNe&apos;, &apos;RRAe&apos;], &apos;Condition2&apos;: [&apos;Artery&apos;, &apos;Feedr&apos;, &apos;Norm&apos;, &apos;RRNn&apos;, &apos;RRAn&apos;, &apos;PosN&apos;, &apos;PosA&apos;, &apos;RRNe&apos;, &apos;RRAe&apos;], &apos;BldgType&apos;: [&apos;1Fam&apos;, &apos;2FmCon&apos;, &apos;Duplx&apos;, &apos;TwnhsE&apos;, &apos;TwnhsI&apos;], &apos;HouseStyle&apos;: [&apos;1Story&apos;], &apos; 1.5Fin\tOne and one-half story&apos;: [], &apos; 1.5Unf\tOne and one-half story&apos;: [&apos;2Story&apos;], &apos; 2.5Fin\tTwo and one-half story&apos;: [], &apos; 2.5Unf\tTwo and one-half story&apos;: [&apos;SFoyer&apos;, &apos;SLvl&apos;], &apos;OverallQual&apos;: [&apos;10&apos;, &apos;9&apos;, &apos;8&apos;, &apos;7&apos;, &apos;6&apos;, &apos;5&apos;, &apos;4&apos;, &apos;3&apos;, &apos;2&apos;, &apos;1&apos;], &apos;OverallCond&apos;: [&apos;10&apos;, &apos;9&apos;, &apos;8&apos;, &apos;7&apos;, &apos;6&apos;, &apos;5&apos;, &apos;4&apos;, &apos;3&apos;, &apos;2&apos;, &apos;1&apos;], &apos;YearBuilt&apos;: [], &apos;YearRemodAdd&apos;: [], &apos;RoofStyle&apos;: [&apos;Flat&apos;, &apos;Gable&apos;, &apos;Gambrel&apos;, &apos;Hip&apos;, &apos;Mansard&apos;, &apos;Shed&apos;], &apos;RoofMatl&apos;: [&apos;ClyTile&apos;, &apos;CompShg&apos;, &apos;Membran&apos;, &apos;Metal&apos;, &apos;Roll&apos;, &apos;Tar&amp;Grv&apos;, &apos;WdShake&apos;, &apos;WdShngl&apos;], &apos;Exterior1st&apos;: [&apos;AsbShng&apos;, &apos;AsphShn&apos;, &apos;BrkComm&apos;, &apos;BrkFace&apos;, &apos;CBlock&apos;, &apos;CemntBd&apos;, &apos;HdBoard&apos;, &apos;ImStucc&apos;, &apos;MetalSd&apos;, &apos;Other&apos;, &apos;Plywood&apos;, &apos;PreCast&apos;, &apos;Stone&apos;, &apos;Stucco&apos;, &apos;VinylSd&apos;, &apos;Wd&apos;, &apos;WdShing&apos;], &apos;Exterior2nd&apos;: [&apos;AsbShng&apos;, &apos;AsphShn&apos;, &apos;BrkComm&apos;, &apos;BrkFace&apos;, &apos;CBlock&apos;, &apos;CemntBd&apos;, &apos;HdBoard&apos;, &apos;ImStucc&apos;, &apos;MetalSd&apos;, &apos;Other&apos;, &apos;Plywood&apos;, &apos;PreCast&apos;, &apos;Stone&apos;, &apos;Stucco&apos;, &apos;VinylSd&apos;, &apos;Wd&apos;, &apos;WdShing&apos;], &apos;MasVnrType&apos;: [&apos;BrkCmn&apos;, &apos;BrkFace&apos;, &apos;CBlock&apos;, &apos;None&apos;, &apos;Stone&apos;], &apos;MasVnrArea&apos;: [], &apos;ExterQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;ExterCond&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;Foundation&apos;: [&apos;BrkTil&apos;, &apos;CBlock&apos;, &apos;PConc&apos;, &apos;Slab&apos;, &apos;Stone&apos;, &apos;Wood&apos;], &apos;BsmtQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;BsmtCond&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;BsmtExposure&apos;: [&apos;Gd&apos;, &apos;Av&apos;, &apos;Mn&apos;, &apos;No&apos;, &apos;NA&apos;], &apos;BsmtFinType1&apos;: [&apos;GLQ&apos;, &apos;ALQ&apos;, &apos;BLQ&apos;, &apos;Rec&apos;, &apos;LwQ&apos;, &apos;Unf&apos;, &apos;NA&apos;], &apos;BsmtFinSF1&apos;: [], &apos;BsmtFinType2&apos;: [&apos;GLQ&apos;, &apos;ALQ&apos;, &apos;BLQ&apos;, &apos;Rec&apos;, &apos;LwQ&apos;, &apos;Unf&apos;, &apos;NA&apos;], &apos;BsmtFinSF2&apos;: [], &apos;BsmtUnfSF&apos;: [], &apos;TotalBsmtSF&apos;: [], &apos;Heating&apos;: [&apos;Floor&apos;, &apos;GasA&apos;, &apos;GasW&apos;, &apos;Grav&apos;, &apos;OthW&apos;, &apos;Wall&apos;], &apos;HeatingQC&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;CentralAir&apos;: [&apos;N&apos;, &apos;Y&apos;], &apos;Electrical&apos;: [&apos;SBrkr&apos;, &apos;FuseA&apos;, &apos;FuseF&apos;, &apos;FuseP&apos;, &apos;Mix&apos;], &apos;1stFlrSF&apos;: [], &apos;2ndFlrSF&apos;: [], &apos;LowQualFinSF&apos;: [], &apos;GrLivArea&apos;: [], &apos;BsmtFullBath&apos;: [], &apos;BsmtHalfBath&apos;: [], &apos;FullBath&apos;: [], &apos;HalfBath&apos;: [], &apos;Bedroom&apos;: [], &apos;Kitchen&apos;: [], &apos;KitchenQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;TotRmsAbvGrd&apos;: [], &apos;Functional&apos;: [&apos;Typ&apos;, &apos;Min1&apos;, &apos;Min2&apos;, &apos;Mod&apos;, &apos;Maj1&apos;, &apos;Maj2&apos;, &apos;Sev&apos;, &apos;Sal&apos;], &apos;Fireplaces&apos;: [], &apos;FireplaceQu&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;GarageType&apos;: [&apos;2Types&apos;, &apos;Attchd&apos;, &apos;Basment&apos;, &apos;BuiltIn&apos;, &apos;CarPort&apos;, &apos;Detchd&apos;, &apos;NA&apos;], &apos;GarageYrBlt&apos;: [], &apos;GarageFinish&apos;: [&apos;Fin&apos;, &apos;RFn&apos;, &apos;Unf&apos;, &apos;NA&apos;], &apos;GarageCars&apos;: [], &apos;GarageArea&apos;: [], &apos;GarageQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;GarageCond&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;PavedDrive&apos;: [&apos;Y&apos;, &apos;P&apos;, &apos;N&apos;], &apos;WoodDeckSF&apos;: [], &apos;OpenPorchSF&apos;: [], &apos;EnclosedPorch&apos;: [], &apos;3SsnPorch&apos;: [], &apos;ScreenPorch&apos;: [], &apos;PoolArea&apos;: [], &apos;PoolQC&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;NA&apos;], &apos;Fence&apos;: [&apos;GdPrv&apos;, &apos;MnPrv&apos;, &apos;GdWo&apos;, &apos;MnWw&apos;, &apos;NA&apos;], &apos;MiscFeature&apos;: [&apos;Elev&apos;, &apos;Gar2&apos;, &apos;Othr&apos;, &apos;Shed&apos;, &apos;TenC&apos;, &apos;NA&apos;], &apos;MiscVal&apos;: [], &apos;MoSold&apos;: [], &apos;YrSold&apos;: [], &apos;SaleType&apos;: [&apos;WD&apos;, &apos;CWD&apos;, &apos;VWD&apos;, &apos;New&apos;, &apos;COD&apos;, &apos;Con&apos;, &apos;ConLw&apos;, &apos;ConLI&apos;, &apos;ConLD&apos;, &apos;Oth&apos;], &apos;SaleCondition&apos;: [&apos;Normal&apos;, &apos;Abnorml&apos;, &apos;AdjLand&apos;, &apos;Alloca&apos;, &apos;Family&apos;, &apos;Partial&apos;]} Â≠óÁ¨¶‰∏≤Á±ªÂûãÁöÑ feature ÈáçÁºñÁ†Å1234567# Ëøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÂæóÂà∞Êï∞ÊçÆÈõÜ‰∏≠ÈùûÊï∞Â≠óÁöÑfeature columndef get_object_column(df): object_column = [] for column in df.columns: if df[column].dtype == 'object': object_column.append(column) return object_column 1#object_column = get_object_column(train) 12345678# Ëøô‰∏™ÂáΩÊï∞ÁöÑ‰ΩúÁî®ÊòØÊää description_dict ‰∏≠ÁöÑ value ËΩ¨Êç¢‰∏∫ÂØπÂ∫îÊï∞Â≠óÁöÑÂ≠óÂÖ∏def generate_map(map_list, end_index=1): d = &#123;&#125; j = len(map_list) - end_index for i in map_list: d[i] = j j -= 1 return d 123456def preprocess_order_feature(df): for i in get_object_column(df): order_map = generate_map(description_dict[i], 0) df[i] = df[i].map(order_map) df[i] = df[i].fillna(0) return df 12train = preprocess_order_feature(train)test = preprocess_order_feature(test) ËßÇÂØüÊï∞ÊçÆ1train.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } MSSubClass MSZoning LotFrontage LotArea Street LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF Heating HeatingQC CentralAir Electrical 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold SaleType SaleCondition SalePrice count 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.00000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 mean 56.897260 2.825342 69.863699 10516.828082 1.004110 3.591781 3.814384 3.998630 4.583562 2.937671 10.747945 6.969178 6.993151 4.334247 0.497260 6.099315 5.575342 1971.267808 1984.865753 4.589726 6.924658 5.958904 5.271918 2.552740 103.117123 3.39589 3.083562 4.603425 4.565068 4.010959 2.656164 4.571233 443.639726 2.273288 46.549315 567.240411 1057.429452 4.963699 4.145205 1.065068 4.889726 1162.626712 346.992466 5.844521 1515.463699 0.425342 0.057534 1.565068 0.382877 2.866438 1.046575 3.511644 6.517808 7.841781 0.613014 2.825342 4.791781 1978.589041 2.771233 1.767123 472.980137 3.976712 3.975342 2.856164 94.244521 46.660274 21.954110 3.409589 15.060959 2.758904 43.489041 6.321918 2007.815753 9.509589 5.417808 180921.195890 std 42.300571 1.020174 22.027677 9981.264932 0.063996 0.582296 0.606509 0.052342 0.773448 0.276232 7.565716 0.878349 0.248272 1.555218 0.500164 1.382997 1.112799 30.202904 20.645407 0.834998 0.599127 4.426038 4.263353 1.046204 180.731373 0.57428 0.351054 0.722394 0.678071 0.284178 1.039123 2.070649 456.098091 0.869859 161.319273 441.866955 438.705324 0.295124 0.959501 0.246731 0.394658 386.587738 436.528436 48.623081 525.480383 0.518911 0.238753 0.550916 0.502885 0.815778 0.220338 0.663760 1.625393 0.667698 0.644666 1.810877 1.759864 23.997022 0.811835 0.747315 213.804841 0.241665 0.232860 0.496592 125.338794 66.256028 61.119149 29.317331 55.757415 40.177307 496.123024 2.703626 1.328095 1.368616 1.475209 79442.502883 min 20.000000 0.000000 21.000000 1300.000000 1.000000 1.000000 1.000000 2.000000 1.000000 1.000000 0.000000 1.000000 1.000000 0.000000 0.000000 1.000000 1.000000 1872.000000 1950.000000 1.000000 1.000000 0.000000 0.000000 1.000000 0.000000 2.00000 1.000000 1.000000 3.000000 2.000000 2.000000 2.000000 0.000000 2.000000 0.000000 0.000000 0.000000 1.000000 1.000000 1.000000 1.000000 334.000000 0.000000 0.000000 334.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 2.000000 2.000000 2.000000 0.000000 1.000000 2.000000 1900.000000 2.000000 0.000000 0.000000 2.000000 2.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 2006.000000 1.000000 1.000000 34900.000000 25% 20.000000 3.000000 60.000000 7553.500000 1.000000 3.000000 4.000000 4.000000 4.000000 3.000000 4.000000 7.000000 7.000000 5.000000 0.000000 5.000000 5.000000 1954.000000 1967.000000 5.000000 7.000000 3.000000 3.000000 2.000000 0.000000 3.00000 3.000000 4.000000 4.000000 4.000000 2.000000 2.000000 0.000000 2.000000 0.000000 223.000000 795.750000 5.000000 3.000000 1.000000 5.000000 882.000000 0.000000 0.000000 1129.500000 0.000000 0.000000 1.000000 0.000000 2.000000 1.000000 3.000000 5.000000 8.000000 0.000000 1.000000 2.000000 1962.000000 2.000000 1.000000 334.500000 4.000000 4.000000 3.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 5.000000 2007.000000 10.000000 6.000000 129975.000000 50% 50.000000 3.000000 69.000000 9478.500000 1.000000 4.000000 4.000000 4.000000 5.000000 3.000000 10.000000 7.000000 7.000000 5.000000 0.000000 6.000000 5.000000 1973.000000 1994.000000 5.000000 7.000000 3.000000 3.000000 2.000000 0.000000 3.00000 3.000000 5.000000 5.000000 4.000000 2.000000 5.000000 383.500000 2.000000 0.000000 477.500000 991.500000 5.000000 5.000000 1.000000 5.000000 1087.000000 0.000000 0.000000 1464.000000 0.000000 0.000000 2.000000 0.000000 3.000000 1.000000 3.000000 6.000000 8.000000 1.000000 3.000000 6.000000 1980.000000 3.000000 2.000000 480.000000 4.000000 4.000000 3.000000 0.000000 25.000000 0.000000 0.000000 0.000000 0.000000 0.000000 6.000000 2008.000000 10.000000 6.000000 163000.000000 75% 70.000000 3.000000 79.000000 11601.500000 1.000000 4.000000 4.000000 4.000000 5.000000 3.000000 18.000000 7.000000 7.000000 5.000000 1.000000 7.000000 6.000000 2000.000000 2004.000000 5.000000 7.000000 9.000000 9.000000 4.000000 164.250000 4.00000 3.000000 5.000000 5.000000 4.000000 3.000000 7.000000 712.250000 2.000000 0.000000 808.000000 1298.250000 5.000000 5.000000 1.000000 5.000000 1391.250000 728.000000 0.000000 1776.750000 1.000000 0.000000 2.000000 1.000000 3.000000 1.000000 4.000000 7.000000 8.000000 1.000000 5.000000 6.000000 2001.000000 3.000000 2.000000 576.000000 4.000000 4.000000 3.000000 168.000000 68.000000 0.000000 0.000000 0.000000 0.000000 0.000000 8.000000 2009.000000 10.000000 6.000000 214000.000000 max 190.000000 6.000000 313.000000 215245.000000 2.000000 4.000000 4.000000 4.000000 5.000000 3.000000 25.000000 9.000000 9.000000 5.000000 1.000000 10.000000 9.000000 2010.000000 2010.000000 6.000000 8.000000 17.000000 17.000000 5.000000 1600.000000 5.00000 5.000000 6.000000 6.000000 5.000000 5.000000 7.000000 5644.000000 7.000000 1474.000000 2336.000000 6110.000000 6.000000 5.000000 2.000000 5.000000 4692.000000 2065.000000 572.000000 5642.000000 3.000000 2.000000 3.000000 2.000000 8.000000 3.000000 5.000000 14.000000 8.000000 3.000000 6.000000 7.000000 2010.000000 4.000000 4.000000 1418.000000 6.000000 6.000000 3.000000 857.000000 547.000000 552.000000 508.000000 480.000000 738.000000 15500.000000 12.000000 2010.000000 10.000000 6.000000 755000.000000 ËßÇÂØü feature ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß123456corr_mat = train[["SalePrice","MSSubClass","MSZoning","LotFrontage","LotArea", "BldgType", "OverallQual", "OverallCond","YearBuilt", "BedroomAbvGr", "PoolArea", "GarageArea", "SaleType", "MoSold"]].corr()# corr_mat = train.corr()f, ax = plt.subplots(figsize=(16, 8))sns.heatmap(corr_mat, vmax=1 , square=True) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6c086fa20&gt; ËßÇÂØüÁÉ≠ÂäõÂõæÔºåÈ¢úËâ≤Ë∂äÊµÖÁõ∏ÂÖ≥ÊÄßË∂äÂ§ß„ÄÇÂÖ≥‰∫éÁÉ≠ÂäõÂõæ-&gt; this video. ËßÇÂØüÂπ¥ÈôêÂíåÂîÆ‰ª∑ÁöÑËßÑÂæã12f, ax = plt.subplots(figsize=(16, 8))sns.lineplot(x='YearBuilt', y='SalePrice', data=train) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6a5211320&gt; Âú®‰∫åÂçÅ‰∏ñÁ∫™ÁöÑÊó∂ÂÄô‰ª∑Ê†ºÂ¢ûÈïøËøÖÈÄü„ÄÇ ÁªºÂêàË¥®ÈáèÂíåÂîÆ‰ª∑ÊúâÊòéÊòæÁöÑÁõ∏ÂÖ≥ÊÄß12f, ax = plt.subplots(figsize=(12, 8))sns.lineplot(x='OverallQual', y='SalePrice', color='green',data=train) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6a3e6d8d0&gt; Êàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÔºåÈöèÁùÄÊàøÂ±ãÊï¥‰ΩìË¥®ÈáèÁöÑÊèêÈ´òÔºåÈîÄÂîÆ‰ª∑Ê†ºÂø´ÈÄü‰∏äÊ∂®ÔºåËøôÊòØÈùûÂ∏∏ÂêàÁêÜÁöÑ„ÄÇ ËßÇÂØüÂîÆ‰ª∑12f, ax = plt.subplots(figsize=(10, 6))sns.distplot(train['SalePrice']) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb6a25cdba8&gt; Â§ßÈÉ®ÂàÜÁöÑÊàøÂ±ãÂîÆ‰ª∑Âú® 100000 Âà∞ 200000 ‰πãÈó¥„ÄÇ ÊûÑÂª∫È¢ÑÊµãÊ®°Âûã1234X = train.drop('SalePrice', axis=1)y = np.ravel(np.array(train[['SalePrice']]))print(y.shape)y (1460,) array([208500, 181500, 223500, ..., 266500, 142125, 147500]) 12# Use train_test_split from sci-kit learn to segment our data into train and a local testsetX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) ÂÆö‰πâËØÑ‰º∞ÂáΩÊï∞ËØÑ‰º∞ÂáΩÊï∞Âü∫‰∫éÈ¢ÑÊµãÂÄºÁöÑÂØπÊï∞‰∏éËßÇÂØüÂà∞ÁöÑÈîÄÂîÆ‰ª∑Ê†ºÁöÑÂØπÊï∞‰πãÈó¥ÁöÑÂùáÊñπÊ†πËØØÂ∑Æ(RMSE)„ÄÇ 12def rmse(y, y_pred): return np.sqrt(mean_squared_error(np.log(y), np.log(y_pred))) ÈöèÊú∫Ê£ÆÊûó12345678910random_forest = RandomForestRegressor(n_estimators=1200, max_depth=15, min_samples_split=5, min_samples_leaf=5, max_features=None, random_state=42, oob_score=True)kf = KFold(n_splits=5)y_pred = cross_val_score(random_forest, X, y, cv=kf)y_pred.mean() 0.8500001566166802 1random_forest.fit(X, y) RandomForestRegressor(bootstrap=True, criterion=&apos;mse&apos;, max_depth=15, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=5, min_samples_split=5, min_weight_fraction_leaf=0.0, n_estimators=1200, n_jobs=None, oob_score=True, random_state=42, verbose=0, warm_start=False) 1rf_pred = random_forest.predict(test) 1rf_pred array([126945.71699684, 153924.56961003, 182182.80294353, ..., 156066.28489667, 117296.65091637, 224995.13115853]) XG Boost12345678910111213141516xg_boost = XGBRegressor(learning_rate=0.01, n_estimators=6000, max_depth=4, min_child_weight=1, gamma=0.6, subsample=0.7, colsample_bytree=0.2, objective='reg:linear', nthread=-1, scale_pos_weight=1, seed=27, reg_alpha=0.00006)kf = KFold(n_splits=5)y_pred = cross_val_score(xg_boost, X, y, cv=kf)y_pred.mean() [03:11:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [03:11:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [03:11:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [03:12:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [03:12:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. 0.8959027545454475 1xg_boost.fit(X, y) [03:12:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. XGBRegressor(base_score=0.5, booster=&apos;gbtree&apos;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.2, gamma=0.6, importance_type=&apos;gain&apos;, learning_rate=0.01, max_delta_step=0, max_depth=4, min_child_weight=1, missing=None, n_estimators=6000, n_jobs=1, nthread=-1, objective=&apos;reg:linear&apos;, random_state=0, reg_alpha=6e-05, reg_lambda=1, scale_pos_weight=1, seed=27, silent=None, subsample=0.7, verbosity=1) 12xgb_pred = xg_boost.predict(test)xgb_pred array([127263.77 , 163056.02 , 193208.25 , ..., 173218.75 , 115712.914, 211616.88 ], dtype=float32) Gradient Boost Regressor(GBM)12345678910111213g_boost = GradientBoostingRegressor(n_estimators=6000, learning_rate=0.01, max_depth=5, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='ls', random_state=42 )kf = KFold(n_splits=5)y_pred = cross_val_score(g_boost, X, y, cv=kf)y_pred.mean() 0.8905525972502479 1g_boost.fit(X, y) GradientBoostingRegressor(alpha=0.9, criterion=&apos;friedman_mse&apos;, init=None, learning_rate=0.01, loss=&apos;ls&apos;, max_depth=5, max_features=&apos;sqrt&apos;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=15, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=6000, n_iter_no_change=None, presort=&apos;auto&apos;, random_state=42, subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0, warm_start=False) 12gbm_pred = g_boost.predict(test)gbm_pred array([125909.87154943, 163184.8652622 , 187872.72372976, ..., 176429.22616544, 119620.23912638, 211953.00041747]) Light GBM1234567891011121314lightgbm = LGBMRegressor(objective='regression', num_leaves=6, learning_rate=0.01, n_estimators=6400, verbose=-1, bagging_fraction=0.8, bagging_freq=4, bagging_seed=6, feature_fraction=0.2, feature_fraction_seed=7 )kf = KFold(n_splits=5)y_pred = cross_val_score(lightgbm, X, y, cv=kf)y_pred.mean() 0.8881867437856128 1lightgbm.fit(X,y) LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, bagging_seed=6, boosting_type=&apos;gbdt&apos;, class_weight=None, colsample_bytree=1.0, feature_fraction=0.2, feature_fraction_seed=7, importance_type=&apos;split&apos;, learning_rate=0.01, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=6400, n_jobs=-1, num_leaves=6, objective=&apos;regression&apos;, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0, verbose=-1) 12lgb_pred = lightgbm.predict(test)lgb_pred array([124759.4703253 , 161206.70919126, 187680.444818 , ..., 168310.83365532, 123698.90457326, 206480.92047866]) Logistic Regression1234logreg = LogisticRegression()kf = KFold(n_splits=5)y_pred = cross_val_score(logreg, X, y, cv=kf)y_pred.mean() 1logreg.fit(X, y) /usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning. FutureWarning) /usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning. &quot;this warning.&quot;, FutureWarning) /usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. &quot;the number of iterations.&quot;, ConvergenceWarning) LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&apos;warn&apos;, n_jobs=None, penalty=&apos;l2&apos;, random_state=None, solver=&apos;warn&apos;, tol=0.0001, verbose=0, warm_start=False) 1round(logreg.score(X, y) * 100, 2) 88.9 12log_pred = logreg.predict(test)log_pred array([135500, 128950, 175000, ..., 133900, 190000, 187500]) Ê®°ÂûãÁöÑÂè†Âä†Âè†Âä†(‰πüÁß∞‰∏∫ÂÖÉÈõÜÊàê)ÊòØ‰∏ÄÁßçÊ®°ÂûãÈõÜÊàêÊäÄÊúØÔºåÁî®‰∫éÁªÑÂêàÊù•Ëá™Â§ö‰∏™È¢ÑÊµãÊ®°ÂûãÁöÑ‰ø°ÊÅØÔºåÁîüÊàêÊÄßËÉΩÊõ¥Â•ΩÁöÑÊñ∞Ê®°Âûã„ÄÇÂú®Ëøô‰∏™È°πÁõÆ‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®Âêç‰∏∫vecstackÁöÑpythonÂåÖÔºåÂÆÉÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨ÂØπÂâçÈù¢ÂØºÂÖ•ÁöÑÊ®°ÂûãËøõË°åÂ†ÜÊ†à„ÄÇÂÆÉÂÆûÈôÖ‰∏äÈùûÂ∏∏ÂÆπÊòì‰ΩøÁî®ÔºåÂèØ‰ª•Êü•ÁúãÊñáÊ°£‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ„ÄÇvecstack 1models = [g_boost, xg_boost, lightgbm, random_forest] 12345678910Strain, S_test = stacking(models, X_train, y_train, X_test, regression=True, mode='oof_pred_bag', metric=rmse, n_folds=5, random_state=25, verbose=2) task: [regression] metric: [rmse] mode: [oof_pred_bag] n_models: [4] model 0: [GradientBoostingRegressor] fold 0: [0.12653004] fold 1: [0.13818165] fold 2: [0.10747644] fold 3: [0.14980732] fold 4: [0.11127270] ---- MEAN: [0.12665363] + [0.01595833] FULL: [0.12764756] model 1: [XGBRegressor] [03:23:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. fold 0: [0.11631560] [03:24:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. fold 1: [0.14701253] [03:24:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. fold 2: [0.10450330] [03:24:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. fold 3: [0.14328067] [03:24:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. fold 4: [0.10632026] ---- MEAN: [0.12348647] + [0.01817552] FULL: [0.12481458] model 2: [LGBMRegressor] fold 0: [0.12668239] fold 1: [0.14251415] fold 2: [0.11409004] fold 3: [0.15394461] fold 4: [0.11576550] ---- MEAN: [0.13059934] + [0.01545902] FULL: [0.13150292] model 3: [RandomForestRegressor] fold 0: [0.13803357] fold 1: [0.16746496] fold 2: [0.13370269] fold 3: [0.17907099] fold 4: [0.13625091] ---- MEAN: [0.15090463] + [0.01867560] FULL: [0.15204350] 1Strain, S_test (array([[145154.57609501, 140247.640625 , 144708.92814448, 136304.80002144], [441586.84575012, 453786.875 , 476049.8262998 , 433615.5690085 ], [205559.38156983, 199459.953125 , 204548.62741617, 189012.87710637], ..., [229773.83814053, 245324.03125 , 222988.34529258, 233726.54189435], [ 78529.68615301, 81706.46875 , 74919.86211206, 94651.91862458], [126564.42955093, 118016.921875 , 131591.97464745, 134449.34870648]]), array([[156946.11019358, 162235.903125 , 156274.58204718, 174271.19166786], [168719.74644755, 171368.26875 , 172660.15892698, 168988.4858204 ], [165875.73697659, 167827.703125 , 166511.09786993, 144720.7621456 ], ..., [235105.18179731, 240780.803125 , 236012.18528746, 224310.44197611], [311340.99357469, 306275.29375 , 305036.50098821, 319953.95931372], [100400.26285948, 97430.8671875 , 97576.05463032, 109458.70614352]])) 12345678910# Initialize 2nd level modelxgb_lev2 = XGBRegressor(learning_rate=0.1, n_estimators=500, max_depth=3, n_jobs=-1, random_state=17 )# Fit the 2nd level model on the output of level 1xgb_lev2.fit(Strain, y_train) [03:25:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. XGBRegressor(base_score=0.5, booster=&apos;gbtree&apos;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, importance_type=&apos;gain&apos;, learning_rate=0.1, max_delta_step=0, max_depth=3, min_child_weight=1, missing=None, n_estimators=500, n_jobs=-1, nthread=None, objective=&apos;reg:linear&apos;, random_state=17, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=None, subsample=1, verbosity=1) 123# Make predictions on the localized test setstacked_pred = xgb_lev2.predict(S_test)print("RMSE of Stacked Model: &#123;&#125;".format(rmse(y_test,stacked_pred))) RMSE of Stacked Model: 0.12290530277450722 12345y1_pred_L1 = models[0].predict(test)y2_pred_L1 = models[1].predict(test)y3_pred_L1 = models[2].predict(test)y4_pred_L1 = models[3].predict(test)S_test_L1 = np.c_[y1_pred_L1, y2_pred_L1, y3_pred_L1, y4_pred_L1] 1test_stacked_pred = xgb_lev2.predict(S_test_L1) 12345# Save the predictions in form of a dataframesubmission = pd.DataFrame()submission['Id'] = np.array(test.index)submission['SalePrice'] = test_stacked_pred 1submission.to_csv('/submissionV2.csv', index=False) Ê∑∑ÂêàËæÉÂ•ΩÂæóÂàÜÁöÑ submissionÂõ†‰∏∫‰∏çÁü•ÈÅìÊúÄÁªàÁöÑÊµãËØïÈõÜÂêàÁöÑÊ≠£ÁúüÊï∞ÊçÆÊòØ‰ªÄ‰πàÔºåÂè™ËÉΩ‰∏ÄÈÅç‰∏ÄÈÅçÊèê‰∫§ÂéªËíôÔºåÁúãÂà∞Âà´‰∫∫ÁöÑÊñπÊ≥ïÊòØÊ∑∑Âêà‰ªñ‰∫∫ËæÉÂ•ΩÁöÑÊèê‰∫§ÂéªÈ™åËØÅÔºåÂ∞ùËØï‰∏ãÁúãÁúã„ÄÇ 123submission_v1 = pd.read_csv('/House_price_submission_v44.csv')submission_v2 = pd.read_csv('/submissionV19.csv')submission_v3 = pd.read_csv('/blended_submission.csv') 123456final_blend = 0.5*submission_v1.SalePrice.values + 0.2*submission_v2.SalePrice.values + 0.3*submission_v3.SalePrice.valuesblended_submission = pd.DataFrame()blended_submission['Id'] = submission_v1.Id.valuesblended_submission['SalePrice'] = final_blend 12blended_submission.to_csv('/submissionV20.csv', index=False)blended_submission ÂëÉÔºåÂ∞±ËøôÊ†∑ÂêßÔºåÊúÄÁªàÂíåÂâçÂçÅÂêçÂ∑Æ‰∏çÂà∞0.004„ÄÇ Áî® Tensorfolw ËØïËØï123456import mathimport tensorflow as tffrom tensorflow.python.data import Datasetfrom sklearn.model_selection import train_test_splitfrom sklearn import metricstf.logging.set_verbosity(tf.logging.ERROR) 1234correlation_dataframe = train.copy()saleprice_corr = correlation_dataframe.corr()['SalePrice']saleprice_corr = saleprice_corr[saleprice_corr &gt; 0]corr_feature = saleprice_corr.index 1corr_feature Index([&apos;MSZoning&apos;, &apos;LotFrontage&apos;, &apos;LotArea&apos;, &apos;Utilities&apos;, &apos;BldgType&apos;, &apos;OverallQual&apos;, &apos;YearBuilt&apos;, &apos;YearRemodAdd&apos;, &apos;MasVnrType&apos;, &apos;MasVnrArea&apos;, &apos;ExterQual&apos;, &apos;ExterCond&apos;, &apos;BsmtQual&apos;, &apos;BsmtCond&apos;, &apos;BsmtExposure&apos;, &apos;BsmtFinType1&apos;, &apos;BsmtFinSF1&apos;, &apos;BsmtUnfSF&apos;, &apos;TotalBsmtSF&apos;, &apos;Heating&apos;, &apos;HeatingQC&apos;, &apos;Electrical&apos;, &apos;1stFlrSF&apos;, &apos;2ndFlrSF&apos;, &apos;GrLivArea&apos;, &apos;BsmtFullBath&apos;, &apos;FullBath&apos;, &apos;HalfBath&apos;, &apos;BedroomAbvGr&apos;, &apos;KitchenQual&apos;, &apos;TotRmsAbvGrd&apos;, &apos;Functional&apos;, &apos;Fireplaces&apos;, &apos;FireplaceQu&apos;, &apos;GarageType&apos;, &apos;GarageYrBlt&apos;, &apos;GarageFinish&apos;, &apos;GarageCars&apos;, &apos;GarageArea&apos;, &apos;GarageQual&apos;, &apos;GarageCond&apos;, &apos;PavedDrive&apos;, &apos;WoodDeckSF&apos;, &apos;OpenPorchSF&apos;, &apos;3SsnPorch&apos;, &apos;ScreenPorch&apos;, &apos;PoolArea&apos;, &apos;MoSold&apos;, &apos;SalePrice&apos;], dtype=&apos;object&apos;) 12345def preprocess_feature(df, corr_feature): newdf = pd.DataFrame() for feature in corr_feature: newdf[feature] = df[feature] return newdf 12X = preprocess_feature(train, corr_feature).drop('SalePrice', axis=1)y = np.ravel(np.array(train[['SalePrice']])) 1X.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } MSZoning LotFrontage LotArea Utilities BldgType OverallQual YearBuilt YearRemodAdd MasVnrType MasVnrArea ExterQual ExterCond BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtUnfSF TotalBsmtSF Heating HeatingQC Electrical 1stFlrSF 2ndFlrSF GrLivArea BsmtFullBath FullBath HalfBath BedroomAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF 3SsnPorch ScreenPorch PoolArea MoSold count 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.00000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 1460.000000 mean 2.825342 69.863699 10516.828082 3.998630 4.334247 6.099315 1971.267808 1984.865753 2.552740 103.117123 3.39589 3.083562 4.565068 4.010959 2.656164 4.571233 443.639726 567.240411 1057.429452 4.963699 4.145205 4.889726 1162.626712 346.992466 1515.463699 0.425342 1.565068 0.382877 2.866438 3.511644 6.517808 7.841781 0.613014 2.825342 4.791781 1978.589041 2.771233 1.767123 472.980137 3.976712 3.975342 2.856164 94.244521 46.660274 3.409589 15.060959 2.758904 6.321918 std 1.020174 22.027677 9981.264932 0.052342 1.555218 1.382997 30.202904 20.645407 1.046204 180.731373 0.57428 0.351054 0.678071 0.284178 1.039123 2.070649 456.098091 441.866955 438.705324 0.295124 0.959501 0.394658 386.587738 436.528436 525.480383 0.518911 0.550916 0.502885 0.815778 0.663760 1.625393 0.667698 0.644666 1.810877 1.759864 23.997022 0.811835 0.747315 213.804841 0.241665 0.232860 0.496592 125.338794 66.256028 29.317331 55.757415 40.177307 2.703626 min 0.000000 21.000000 1300.000000 2.000000 0.000000 1.000000 1872.000000 1950.000000 1.000000 0.000000 2.00000 1.000000 3.000000 2.000000 2.000000 2.000000 0.000000 0.000000 0.000000 1.000000 1.000000 1.000000 334.000000 0.000000 334.000000 0.000000 0.000000 0.000000 0.000000 2.000000 2.000000 2.000000 0.000000 1.000000 2.000000 1900.000000 2.000000 0.000000 0.000000 2.000000 2.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 25% 3.000000 60.000000 7553.500000 4.000000 5.000000 5.000000 1954.000000 1967.000000 2.000000 0.000000 3.00000 3.000000 4.000000 4.000000 2.000000 2.000000 0.000000 223.000000 795.750000 5.000000 3.000000 5.000000 882.000000 0.000000 1129.500000 0.000000 1.000000 0.000000 2.000000 3.000000 5.000000 8.000000 0.000000 1.000000 2.000000 1962.000000 2.000000 1.000000 334.500000 4.000000 4.000000 3.000000 0.000000 0.000000 0.000000 0.000000 0.000000 5.000000 50% 3.000000 69.000000 9478.500000 4.000000 5.000000 6.000000 1973.000000 1994.000000 2.000000 0.000000 3.00000 3.000000 5.000000 4.000000 2.000000 5.000000 383.500000 477.500000 991.500000 5.000000 5.000000 5.000000 1087.000000 0.000000 1464.000000 0.000000 2.000000 0.000000 3.000000 3.000000 6.000000 8.000000 1.000000 3.000000 6.000000 1980.000000 3.000000 2.000000 480.000000 4.000000 4.000000 3.000000 0.000000 25.000000 0.000000 0.000000 0.000000 6.000000 75% 3.000000 79.000000 11601.500000 4.000000 5.000000 7.000000 2000.000000 2004.000000 4.000000 164.250000 4.00000 3.000000 5.000000 4.000000 3.000000 7.000000 712.250000 808.000000 1298.250000 5.000000 5.000000 5.000000 1391.250000 728.000000 1776.750000 1.000000 2.000000 1.000000 3.000000 4.000000 7.000000 8.000000 1.000000 5.000000 6.000000 2001.000000 3.000000 2.000000 576.000000 4.000000 4.000000 3.000000 168.000000 68.000000 0.000000 0.000000 0.000000 8.000000 max 6.000000 313.000000 215245.000000 4.000000 5.000000 10.000000 2010.000000 2010.000000 5.000000 1600.000000 5.00000 5.000000 6.000000 5.000000 5.000000 7.000000 5644.000000 2336.000000 6110.000000 6.000000 5.000000 5.000000 4692.000000 2065.000000 5642.000000 3.000000 3.000000 2.000000 8.000000 5.000000 14.000000 8.000000 3.000000 6.000000 7.000000 2010.000000 4.000000 4.000000 1418.000000 6.000000 6.000000 3.000000 857.000000 547.000000 508.000000 480.000000 738.000000 12.000000 1234567891011def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): features = &#123;key: np.array(value) for key, value in dict(features).items()&#125; ds = Dataset.from_tensor_slices((features, targets)) ds = ds.batch(batch_size).repeat(num_epochs) if shuffle: ds = ds.shuffle(10000) features, labels = ds.make_one_shot_iterator().get_next() return features, labels 123456789def construct_feature_columns(input_features): """ÊûÑÈÄ†TensorFlowÁâπÂæÅÂàó ÂèÇÊï∞: input_features:Ë¶Å‰ΩøÁî®ÁöÑÊï∞Â≠óËæìÂÖ•ÁâπÊÄßÁöÑÂêçÁß∞„ÄÇ ËøîÂõû: ‰∏Ä‰∏™ feature columns ÈõÜÂêà """ return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features]) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798def train_model( learning_rate, strps, batch_size, training_examples, training_targets, validation_examples, validation_targets): """ËÆ≠ÁªÉÂ§öÂÖÉÁâπÂæÅÁöÑÁ∫øÊÄßÂõûÂΩíÊ®°Âûã Èô§ËÆ≠ÁªÉÂ§ñÔºåÊ≠§ÂäüËÉΩËøòÊâìÂç∞ËÆ≠ÁªÉËøõÂ∫¶‰ø°ÊÅØÔºå ‰ª•ÂèäÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªËÄåÂ§±ÂéªÁöÑËÆ≠ÁªÉÂíåÈ™åËØÅ„ÄÇ ÂèÇÊï∞: learning_rate:‰∏Ä‰∏™floatÔºåË°®Á§∫Â≠¶‰π†Áéá steps:‰∏Ä‰∏™ÈùûÈõ∂ÁöÑintÔºåËÆ≠ÁªÉÊ≠•È™§ÁöÑÊÄªÊï∞„ÄÇËÆ≠ÁªÉÊ≠•È™§ Áî±‰ΩøÁî®Âçï‰∏™ÊâπÂ§ÑÁêÜÁöÑÂêëÂâçÂíåÂêëÂêé‰º†ÈÄíÁªÑÊàê„ÄÇ batch_size:‰∏Ä‰∏™ÈùûÈõ∂ÁöÑint training_example: DataFrame ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™Âàó ' california_housing_dataframe '‰Ωú‰∏∫ËÆ≠ÁªÉÁöÑËæìÂÖ•feature training_targets:‰∏Ä‰∏™' DataFrame 'ÔºåÂÆÉÂè™ÂåÖÂê´‰∏ÄÂàó ' california_housing_dataframe '‰Ωú‰∏∫ËÆ≠ÁªÉÁöÑÁõÆÊ†á„ÄÇ validation_example: ' DataFrame 'ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™Âàó ' california_housing_dataframe '‰Ωú‰∏∫È™åËØÅÁöÑËæìÂÖ•feature validation_targets: ' DataFrame 'Ôºå‰ªÖÂåÖÂê´Êù•Ëá™ÂÖ∂‰∏≠ÁöÑ‰∏ÄÂàó ' california_housing_dataframe '‰Ωú‰∏∫È™åËØÅÁöÑÁõÆÊ†á„ÄÇ ËøîÂõû: Âú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÁöÑ‚ÄúÁ∫øÊÄßÂõûÂΩíÂô®‚ÄùÂØπË±° """ periods = 10 steps_per_period = strps / periods # ÂàõÂª∫‰∏Ä‰∏™Á∫øÊÄßÂõûÂΩíÂØπË±° my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_regressor = tf.estimator.LinearRegressor( feature_columns=construct_feature_columns(training_examples), optimizer=my_optimizer ) # ÂàõÂª∫ËæìÂÖ•ÂáΩÊï∞ training_input_fn = lambda: my_input_fn( training_examples, training_targets, batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn( training_examples, training_targets, num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn( validation_examples, validation_targets, num_epochs=1, shuffle=False) #ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩÜË¶ÅÂú®Âæ™ÁéØ‰∏≠ËøõË°åÔºåËøôÊ†∑Êàë‰ª¨ÊâçËÉΩÂÆöÊúüËØÑ‰º∞ #ÊçüÂ§±ÊåáÊ†á print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_regressor.train( input_fn=training_input_fn, steps=steps_per_period, ) # Take a break and compute predictions. training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # Compute training and validation loss. training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() return linear_regressor 12345678linear_regressor = train_model( learning_rate=0.5, strps=200, batch_size=5, training_examples=X_train, training_targets=y_train, validation_examples=X_test, validation_targets=y_test) Training model... RMSE (on training data): period 00 : 115236.06 period 01 : 135729.29 period 02 : 94007.13 period 03 : 94940.56 period 04 : 78776.40 period 05 : 73407.86 period 06 : 79100.02 period 07 : 76995.32 period 08 : 94657.55 period 09 : 55721.83 Model training finished. 12345678linear_regressor2 = train_model( learning_rate=0.25, strps=500, batch_size=5, training_examples=X_train, training_targets=y_train, validation_examples=X_test, validation_targets=y_test) Training model... RMSE (on training data): period 00 : 126663.18 period 01 : 89900.76 period 02 : 67300.53 period 03 : 73597.13 period 04 : 59429.95 period 05 : 60645.34 period 06 : 57056.42 period 07 : 55974.51 period 08 : 59490.64 period 09 : 59963.44 Model training finished. 123456789predict_test_input_fn = lambda: my_input_fn( test, test, num_epochs=1, shuffle=False)test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)test_predictions = np.array([item['predictions'][0] for item in test_predictions])test_predictions array([152403.8 , 178793.02, 186845.23, ..., 203018.39, 142496.02, 197809.12], dtype=float32) Â∞±ÂÖàËøôÊ†∑Âêß„ÄÇ]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[House Prices Advanced Regression Techniques]]></title>
    <url>%2F2019%2F05%2F28%2FHouse_Prices_Advanced_Regression_Techniques%2F</url>
    <content type="text"><![CDATA[Kaggle Competition ÁöÑÁªÉ‰π† Êàø‰ª∑È¢ÑÊµã 12345678910111213141516171819202122# Êï∞ÊçÆÂàÜÊûêÂ∫ìimport pandas as pdimport numpy as npimport random# Êï∞ÊçÆÂèØËßÜÂåñimport seaborn as snsimport matplotlib.pyplot as plt# Êú∫Âô®Â≠¶‰π†Â∫ìfrom sklearn.preprocessing import OneHotEncoderfrom sklearn.linear_model import LogisticRegressionfrom sklearn.svm import SVC, LinearSVCfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.naive_bayes import GaussianNBfrom sklearn.linear_model import Perceptronfrom sklearn.linear_model import SGDClassifierfrom sklearn.tree import DecisionTreeClassifierpd.options.display.max_rows = 10 # ÊúÄÂ§ßÊòæÁ§∫Ë°åÊï∞pd.options.display.float_format = '&#123;:.5f&#125;'.format # Á≤æÁ°ÆÂ∫¶ ‰øùÁïô‰∏Ä‰ΩçÂ∞èÊï∞ 123train_df = pd.read_csv('/train.csv')test_df = pd.read_csv('/test.csv')train_df.shape, test_df.shape ((1460, 81), (1459, 80)) 1train_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF Heating ... CentralAir Electrical 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice 0 1 60 RL 65.00000 8450 Pave NaN Reg Lvl AllPub Inside Gtl CollgCr Norm Norm 1Fam 2Story 7 5 2003 2003 Gable CompShg VinylSd VinylSd BrkFace 196.00000 Gd TA PConc Gd TA No GLQ 706 Unf 0 150 856 GasA ... Y SBrkr 856 854 0 1710 1 0 2 1 3 1 Gd 8 Typ 0 NaN Attchd 2003.00000 RFn 2 548 TA TA Y 0 61 0 0 0 0 NaN NaN NaN 0 2 2008 WD Normal 208500 1 2 20 RL 80.00000 9600 Pave NaN Reg Lvl AllPub FR2 Gtl Veenker Feedr Norm 1Fam 1Story 6 8 1976 1976 Gable CompShg MetalSd MetalSd None 0.00000 TA TA CBlock Gd TA Gd ALQ 978 Unf 0 284 1262 GasA ... Y SBrkr 1262 0 0 1262 0 1 2 0 3 1 TA 6 Typ 1 TA Attchd 1976.00000 RFn 2 460 TA TA Y 298 0 0 0 0 0 NaN NaN NaN 0 5 2007 WD Normal 181500 2 3 60 RL 68.00000 11250 Pave NaN IR1 Lvl AllPub Inside Gtl CollgCr Norm Norm 1Fam 2Story 7 5 2001 2002 Gable CompShg VinylSd VinylSd BrkFace 162.00000 Gd TA PConc Gd TA Mn GLQ 486 Unf 0 434 920 GasA ... Y SBrkr 920 866 0 1786 1 0 2 1 3 1 Gd 6 Typ 1 TA Attchd 2001.00000 RFn 2 608 TA TA Y 0 42 0 0 0 0 NaN NaN NaN 0 9 2008 WD Normal 223500 3 4 70 RL 60.00000 9550 Pave NaN IR1 Lvl AllPub Corner Gtl Crawfor Norm Norm 1Fam 2Story 7 5 1915 1970 Gable CompShg Wd Sdng Wd Shng None 0.00000 TA TA BrkTil TA Gd No ALQ 216 Unf 0 540 756 GasA ... Y SBrkr 961 756 0 1717 1 0 1 0 3 1 Gd 7 Typ 1 Gd Detchd 1998.00000 Unf 3 642 TA TA Y 0 35 272 0 0 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 4 5 60 RL 84.00000 14260 Pave NaN IR1 Lvl AllPub FR2 Gtl NoRidge Norm Norm 1Fam 2Story 8 5 2000 2000 Gable CompShg VinylSd VinylSd BrkFace 350.00000 Gd TA PConc Gd TA Av GLQ 655 Unf 0 490 1145 GasA ... Y SBrkr 1145 1053 0 2198 1 0 2 1 4 1 Gd 9 Typ 1 TA Attchd 2000.00000 RFn 3 836 TA TA Y 192 84 0 0 0 0 NaN NaN NaN 0 12 2008 WD Normal 250000 5 rows √ó 81 columns 1# test_df.head() 1train_df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass LotFrontage LotArea OverallQual OverallCond YearBuilt YearRemodAdd MasVnrArea BsmtFinSF1 BsmtFinSF2 BsmtUnfSF TotalBsmtSF 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr TotRmsAbvGrd Fireplaces GarageYrBlt GarageCars GarageArea WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold SalePrice count 1460.00000 1460.00000 1201.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1452.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1379.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 mean 730.50000 56.89726 70.04996 10516.82808 6.09932 5.57534 1971.26781 1984.86575 103.68526 443.63973 46.54932 567.24041 1057.42945 1162.62671 346.99247 5.84452 1515.46370 0.42534 0.05753 1.56507 0.38288 2.86644 1.04658 6.51781 0.61301 1978.50616 1.76712 472.98014 94.24452 46.66027 21.95411 3.40959 15.06096 2.75890 43.48904 6.32192 2007.81575 180921.19589 std 421.61001 42.30057 24.28475 9981.26493 1.38300 1.11280 30.20290 20.64541 181.06621 456.09809 161.31927 441.86696 438.70532 386.58774 436.52844 48.62308 525.48038 0.51891 0.23875 0.55092 0.50289 0.81578 0.22034 1.62539 0.64467 24.68972 0.74732 213.80484 125.33879 66.25603 61.11915 29.31733 55.75742 40.17731 496.12302 2.70363 1.32810 79442.50288 min 1.00000 20.00000 21.00000 1300.00000 1.00000 1.00000 1872.00000 1950.00000 0.00000 0.00000 0.00000 0.00000 0.00000 334.00000 0.00000 0.00000 334.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 2.00000 0.00000 1900.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 2006.00000 34900.00000 25% 365.75000 20.00000 59.00000 7553.50000 5.00000 5.00000 1954.00000 1967.00000 0.00000 0.00000 0.00000 223.00000 795.75000 882.00000 0.00000 0.00000 1129.50000 0.00000 0.00000 1.00000 0.00000 2.00000 1.00000 5.00000 0.00000 1961.00000 1.00000 334.50000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 5.00000 2007.00000 129975.00000 50% 730.50000 50.00000 69.00000 9478.50000 6.00000 5.00000 1973.00000 1994.00000 0.00000 383.50000 0.00000 477.50000 991.50000 1087.00000 0.00000 0.00000 1464.00000 0.00000 0.00000 2.00000 0.00000 3.00000 1.00000 6.00000 1.00000 1980.00000 2.00000 480.00000 0.00000 25.00000 0.00000 0.00000 0.00000 0.00000 0.00000 6.00000 2008.00000 163000.00000 75% 1095.25000 70.00000 80.00000 11601.50000 7.00000 6.00000 2000.00000 2004.00000 166.00000 712.25000 0.00000 808.00000 1298.25000 1391.25000 728.00000 0.00000 1776.75000 1.00000 0.00000 2.00000 1.00000 3.00000 1.00000 7.00000 1.00000 2002.00000 2.00000 576.00000 168.00000 68.00000 0.00000 0.00000 0.00000 0.00000 0.00000 8.00000 2009.00000 214000.00000 max 1460.00000 190.00000 313.00000 215245.00000 10.00000 9.00000 2010.00000 2010.00000 1600.00000 5644.00000 1474.00000 2336.00000 6110.00000 4692.00000 2065.00000 572.00000 5642.00000 3.00000 2.00000 3.00000 2.00000 8.00000 3.00000 14.00000 3.00000 2010.00000 4.00000 1418.00000 857.00000 547.00000 552.00000 508.00000 480.00000 738.00000 15500.00000 12.00000 2010.00000 755000.00000 1# test_df.describe() 123train_df.info()print('_' * 50)test_df.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 1460 entries, 0 to 1459 Data columns (total 81 columns): Id 1460 non-null int64 MSSubClass 1460 non-null int64 MSZoning 1460 non-null object LotFrontage 1201 non-null float64 LotArea 1460 non-null int64 Street 1460 non-null object Alley 91 non-null object LotShape 1460 non-null object LandContour 1460 non-null object Utilities 1460 non-null object LotConfig 1460 non-null object LandSlope 1460 non-null object Neighborhood 1460 non-null object Condition1 1460 non-null object Condition2 1460 non-null object BldgType 1460 non-null object HouseStyle 1460 non-null object OverallQual 1460 non-null int64 OverallCond 1460 non-null int64 YearBuilt 1460 non-null int64 YearRemodAdd 1460 non-null int64 RoofStyle 1460 non-null object RoofMatl 1460 non-null object Exterior1st 1460 non-null object Exterior2nd 1460 non-null object MasVnrType 1452 non-null object MasVnrArea 1452 non-null float64 ExterQual 1460 non-null object ExterCond 1460 non-null object Foundation 1460 non-null object BsmtQual 1423 non-null object BsmtCond 1423 non-null object BsmtExposure 1422 non-null object BsmtFinType1 1423 non-null object BsmtFinSF1 1460 non-null int64 BsmtFinType2 1422 non-null object BsmtFinSF2 1460 non-null int64 BsmtUnfSF 1460 non-null int64 TotalBsmtSF 1460 non-null int64 Heating 1460 non-null object HeatingQC 1460 non-null object CentralAir 1460 non-null object Electrical 1459 non-null object 1stFlrSF 1460 non-null int64 2ndFlrSF 1460 non-null int64 LowQualFinSF 1460 non-null int64 GrLivArea 1460 non-null int64 BsmtFullBath 1460 non-null int64 BsmtHalfBath 1460 non-null int64 FullBath 1460 non-null int64 HalfBath 1460 non-null int64 BedroomAbvGr 1460 non-null int64 KitchenAbvGr 1460 non-null int64 KitchenQual 1460 non-null object TotRmsAbvGrd 1460 non-null int64 Functional 1460 non-null object Fireplaces 1460 non-null int64 FireplaceQu 770 non-null object GarageType 1379 non-null object GarageYrBlt 1379 non-null float64 GarageFinish 1379 non-null object GarageCars 1460 non-null int64 GarageArea 1460 non-null int64 GarageQual 1379 non-null object GarageCond 1379 non-null object PavedDrive 1460 non-null object WoodDeckSF 1460 non-null int64 OpenPorchSF 1460 non-null int64 EnclosedPorch 1460 non-null int64 3SsnPorch 1460 non-null int64 ScreenPorch 1460 non-null int64 PoolArea 1460 non-null int64 PoolQC 7 non-null object Fence 281 non-null object MiscFeature 54 non-null object MiscVal 1460 non-null int64 MoSold 1460 non-null int64 YrSold 1460 non-null int64 SaleType 1460 non-null object SaleCondition 1460 non-null object SalePrice 1460 non-null int64 dtypes: float64(3), int64(35), object(43) memory usage: 924.0+ KB __________________________________________________ &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 1459 entries, 0 to 1458 Data columns (total 80 columns): Id 1459 non-null int64 MSSubClass 1459 non-null int64 MSZoning 1455 non-null object LotFrontage 1232 non-null float64 LotArea 1459 non-null int64 Street 1459 non-null object Alley 107 non-null object LotShape 1459 non-null object LandContour 1459 non-null object Utilities 1457 non-null object LotConfig 1459 non-null object LandSlope 1459 non-null object Neighborhood 1459 non-null object Condition1 1459 non-null object Condition2 1459 non-null object BldgType 1459 non-null object HouseStyle 1459 non-null object OverallQual 1459 non-null int64 OverallCond 1459 non-null int64 YearBuilt 1459 non-null int64 YearRemodAdd 1459 non-null int64 RoofStyle 1459 non-null object RoofMatl 1459 non-null object Exterior1st 1458 non-null object Exterior2nd 1458 non-null object MasVnrType 1443 non-null object MasVnrArea 1444 non-null float64 ExterQual 1459 non-null object ExterCond 1459 non-null object Foundation 1459 non-null object BsmtQual 1415 non-null object BsmtCond 1414 non-null object BsmtExposure 1415 non-null object BsmtFinType1 1417 non-null object BsmtFinSF1 1458 non-null float64 BsmtFinType2 1417 non-null object BsmtFinSF2 1458 non-null float64 BsmtUnfSF 1458 non-null float64 TotalBsmtSF 1458 non-null float64 Heating 1459 non-null object HeatingQC 1459 non-null object CentralAir 1459 non-null object Electrical 1459 non-null object 1stFlrSF 1459 non-null int64 2ndFlrSF 1459 non-null int64 LowQualFinSF 1459 non-null int64 GrLivArea 1459 non-null int64 BsmtFullBath 1457 non-null float64 BsmtHalfBath 1457 non-null float64 FullBath 1459 non-null int64 HalfBath 1459 non-null int64 BedroomAbvGr 1459 non-null int64 KitchenAbvGr 1459 non-null int64 KitchenQual 1458 non-null object TotRmsAbvGrd 1459 non-null int64 Functional 1457 non-null object Fireplaces 1459 non-null int64 FireplaceQu 729 non-null object GarageType 1383 non-null object GarageYrBlt 1381 non-null float64 GarageFinish 1381 non-null object GarageCars 1458 non-null float64 GarageArea 1458 non-null float64 GarageQual 1381 non-null object GarageCond 1381 non-null object PavedDrive 1459 non-null object WoodDeckSF 1459 non-null int64 OpenPorchSF 1459 non-null int64 EnclosedPorch 1459 non-null int64 3SsnPorch 1459 non-null int64 ScreenPorch 1459 non-null int64 PoolArea 1459 non-null int64 PoolQC 3 non-null object Fence 290 non-null object MiscFeature 51 non-null object MiscVal 1459 non-null int64 MoSold 1459 non-null int64 YrSold 1459 non-null int64 SaleType 1458 non-null object SaleCondition 1459 non-null object dtypes: float64(11), int64(26), object(43) memory usage: 912.0+ KB 1train_df.describe(include="O") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinType2 Heating HeatingQC CentralAir Electrical KitchenQual Functional FireplaceQu GarageType GarageFinish GarageQual GarageCond PavedDrive PoolQC Fence MiscFeature SaleType SaleCondition count 1460 1460 91 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1452 1460 1460 1460 1423 1423 1422 1423 1422 1460 1460 1460 1459 1460 1460 770 1379 1379 1379 1379 1460 7 281 54 1460 1460 unique 5 2 2 4 4 2 5 3 25 9 8 5 8 6 8 15 16 4 4 5 6 4 4 4 6 6 6 5 2 5 4 7 5 6 3 5 5 3 3 4 4 9 6 top RL Pave Grvl Reg Lvl AllPub Inside Gtl NAmes Norm Norm 1Fam 1Story Gable CompShg VinylSd VinylSd None TA TA PConc TA TA No Unf Unf GasA Ex Y SBrkr TA Typ Gd Attchd Unf TA TA Y Gd MnPrv Shed WD Normal freq 1151 1454 50 925 1311 1459 1052 1382 225 1260 1445 1220 726 1141 1434 515 504 864 906 1282 647 649 1311 953 430 1256 1428 741 1365 1334 735 1360 380 870 605 1311 1326 1340 3 157 49 1267 1198 12 ÂàÜÊûêÊ¶ÇË¶Å Feature Status Dispose Alley Áº∫Â§±ÊØîËæÉÂ§ö Âà†Èô§ PoolQC Âè™Êúâ‰∏ÉÂÆ∂ÊúâÊ∏∏Ê≥≥Ê±†Âπ∂‰∏îÂíå PoolArea Áõ∏ÂÖ≥ ÂÖà‰∏çÂ°´ÂÖÖ Âà†Èô§ Fence Ê†èÊùÜË¥®ÈáèÂè™Êúâ20%ÁöÑÊúâ Áº∫Â§±ÁöÑÂ°´ÂÖÖ‰∏∫Ê≤°Êúâ MiscFeature ÂÖ∂‰ªñÈ°πÁõÆ‰πüÂè™ÊúâÂ•ΩÂ∞ëÁöÑÊàøÂ≠êÊúâ ÂÖà‰∏çÂ°´ÂÖÖ Âà†Èô§ FireplaceQu Êúâ‰∏ÄÂçäÂÆ∂Ê≤°ÊúâÂ£ÅÁÇâ Â°´ 0 Garagetype Á©∫‰ª£Ë°®Ê≤°Êúâ Â°´ 0 Garagefinish Á©∫‰ª£Ë°®Ê≤°Êúâ Â°´ 0 Garagequal Á©∫‰ª£Ë°®Ê≤°Êúâ Â°´ 0 Garagecond Á©∫‰ª£Ë°®Ê≤°Êúâ Â°´ 0 LotFrontage ÂíåÁâ©‰∏öÁõ∏ËøûÁöÑË°óÈÅìÊúâ1/3Áº∫Â§± Ê≤°ÊÉ≥Âà∞Â§™Â•ΩÁöÑÂ°´ÂÖÖÊñπÊ≥ï Âà†Èô§ Êï¥ÁêÜ description Êñá‰ª∂Êï∞ÊçÆÊèèËø∞Êñá‰ª∂ËÆ∞ÂΩï‰∫ÜÊâÄÊúâÁâπÂæÅÊâÄ‰ª£Ë°®ÁöÑÂê´‰πâÔºåÂÖ∂‰∏≠ËÆ∏Â§öÁâπÂæÅÊòØÂ≠óÁ¨¶‰∏≤ÔºåÁé∞Âú®Êàë‰ª¨Ë¶ÅÊï¥ÁêÜ‰∏∫‰∏™Â≠óÂÖ∏Ôºå‰æø‰∫éÊàë‰ª¨Êü•ËØ¢„ÄÇ 123456description_dict = &#123;&#125;with open('/data_description.txt','r') as description: description_data = description.read() description.close() description_data = description_data.split('\n') 123456789for i in description_data: if ':' in i: key = i.split(':')[0] description_dict[key] = [] elif i.split() and ' ' in i: value = i.split()[0] description_dict[key].append(value)print(description_dict) {&apos;MSSubClass&apos;: [&apos;20&apos;, &apos;30&apos;, &apos;40&apos;, &apos;45&apos;, &apos;50&apos;, &apos;60&apos;, &apos;70&apos;, &apos;75&apos;, &apos;80&apos;, &apos;85&apos;, &apos;90&apos;, &apos;120&apos;, &apos;150&apos;, &apos;160&apos;, &apos;180&apos;, &apos;190&apos;], &apos;MSZoning&apos;: [&apos;A&apos;, &apos;C&apos;, &apos;FV&apos;, &apos;I&apos;, &apos;RH&apos;, &apos;RL&apos;, &apos;RP&apos;, &apos;RM&apos;], &apos;LotFrontage&apos;: [], &apos;LotArea&apos;: [], &apos;Street&apos;: [&apos;Grvl&apos;, &apos;Pave&apos;], &apos;Alley&apos;: [&apos;Grvl&apos;, &apos;Pave&apos;, &apos;NA&apos;], &apos;LotShape&apos;: [&apos;Reg&apos;, &apos;IR1&apos;, &apos;IR2&apos;, &apos;IR3&apos;], &apos;LandContour&apos;: [&apos;Lvl&apos;, &apos;Bnk&apos;, &apos;HLS&apos;, &apos;Low&apos;], &apos;Utilities&apos;: [&apos;AllPub&apos;, &apos;NoSewr&apos;, &apos;NoSeWa&apos;, &apos;ELO&apos;], &apos;LotConfig&apos;: [&apos;Inside&apos;, &apos;Corner&apos;, &apos;CulDSac&apos;, &apos;FR2&apos;, &apos;FR3&apos;], &apos;LandSlope&apos;: [&apos;Gtl&apos;, &apos;Mod&apos;, &apos;Sev&apos;], &apos;Neighborhood&apos;: [&apos;Blmngtn&apos;, &apos;Blueste&apos;, &apos;BrDale&apos;, &apos;BrkSide&apos;, &apos;ClearCr&apos;, &apos;CollgCr&apos;, &apos;Crawfor&apos;, &apos;Edwards&apos;, &apos;Gilbert&apos;, &apos;IDOTRR&apos;, &apos;MeadowV&apos;, &apos;Mitchel&apos;, &apos;Names&apos;, &apos;NoRidge&apos;, &apos;NPkVill&apos;, &apos;NridgHt&apos;, &apos;NWAmes&apos;, &apos;OldTown&apos;, &apos;SWISU&apos;, &apos;Sawyer&apos;, &apos;SawyerW&apos;, &apos;Somerst&apos;, &apos;StoneBr&apos;, &apos;Timber&apos;, &apos;Veenker&apos;], &apos;Condition1&apos;: [&apos;Artery&apos;, &apos;Feedr&apos;, &apos;Norm&apos;, &apos;RRNn&apos;, &apos;RRAn&apos;, &apos;PosN&apos;, &apos;PosA&apos;, &apos;RRNe&apos;, &apos;RRAe&apos;], &apos;Condition2&apos;: [&apos;Artery&apos;, &apos;Feedr&apos;, &apos;Norm&apos;, &apos;RRNn&apos;, &apos;RRAn&apos;, &apos;PosN&apos;, &apos;PosA&apos;, &apos;RRNe&apos;, &apos;RRAe&apos;], &apos;BldgType&apos;: [&apos;1Fam&apos;, &apos;2FmCon&apos;, &apos;Duplx&apos;, &apos;TwnhsE&apos;, &apos;TwnhsI&apos;], &apos;HouseStyle&apos;: [&apos;1Story&apos;], &apos; 1.5Fin\tOne and one-half story&apos;: [], &apos; 1.5Unf\tOne and one-half story&apos;: [&apos;2Story&apos;], &apos; 2.5Fin\tTwo and one-half story&apos;: [], &apos; 2.5Unf\tTwo and one-half story&apos;: [&apos;SFoyer&apos;, &apos;SLvl&apos;], &apos;OverallQual&apos;: [&apos;10&apos;, &apos;9&apos;, &apos;8&apos;, &apos;7&apos;, &apos;6&apos;, &apos;5&apos;, &apos;4&apos;, &apos;3&apos;, &apos;2&apos;, &apos;1&apos;], &apos;OverallCond&apos;: [&apos;10&apos;, &apos;9&apos;, &apos;8&apos;, &apos;7&apos;, &apos;6&apos;, &apos;5&apos;, &apos;4&apos;, &apos;3&apos;, &apos;2&apos;, &apos;1&apos;], &apos;YearBuilt&apos;: [], &apos;YearRemodAdd&apos;: [], &apos;RoofStyle&apos;: [&apos;Flat&apos;, &apos;Gable&apos;, &apos;Gambrel&apos;, &apos;Hip&apos;, &apos;Mansard&apos;, &apos;Shed&apos;], &apos;RoofMatl&apos;: [&apos;ClyTile&apos;, &apos;CompShg&apos;, &apos;Membran&apos;, &apos;Metal&apos;, &apos;Roll&apos;, &apos;Tar&amp;Grv&apos;, &apos;WdShake&apos;, &apos;WdShngl&apos;], &apos;Exterior1st&apos;: [&apos;AsbShng&apos;, &apos;AsphShn&apos;, &apos;BrkComm&apos;, &apos;BrkFace&apos;, &apos;CBlock&apos;, &apos;CemntBd&apos;, &apos;HdBoard&apos;, &apos;ImStucc&apos;, &apos;MetalSd&apos;, &apos;Other&apos;, &apos;Plywood&apos;, &apos;PreCast&apos;, &apos;Stone&apos;, &apos;Stucco&apos;, &apos;VinylSd&apos;, &apos;Wd&apos;, &apos;WdShing&apos;], &apos;Exterior2nd&apos;: [&apos;AsbShng&apos;, &apos;AsphShn&apos;, &apos;BrkComm&apos;, &apos;BrkFace&apos;, &apos;CBlock&apos;, &apos;CemntBd&apos;, &apos;HdBoard&apos;, &apos;ImStucc&apos;, &apos;MetalSd&apos;, &apos;Other&apos;, &apos;Plywood&apos;, &apos;PreCast&apos;, &apos;Stone&apos;, &apos;Stucco&apos;, &apos;VinylSd&apos;, &apos;Wd&apos;, &apos;WdShing&apos;], &apos;MasVnrType&apos;: [&apos;BrkCmn&apos;, &apos;BrkFace&apos;, &apos;CBlock&apos;, &apos;None&apos;, &apos;Stone&apos;], &apos;MasVnrArea&apos;: [], &apos;ExterQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;ExterCond&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;Foundation&apos;: [&apos;BrkTil&apos;, &apos;CBlock&apos;, &apos;PConc&apos;, &apos;Slab&apos;, &apos;Stone&apos;, &apos;Wood&apos;], &apos;BsmtQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;BsmtCond&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;BsmtExposure&apos;: [&apos;Gd&apos;, &apos;Av&apos;, &apos;Mn&apos;, &apos;No&apos;, &apos;NA&apos;], &apos;BsmtFinType1&apos;: [&apos;GLQ&apos;, &apos;ALQ&apos;, &apos;BLQ&apos;, &apos;Rec&apos;, &apos;LwQ&apos;, &apos;Unf&apos;, &apos;NA&apos;], &apos;BsmtFinSF1&apos;: [], &apos;BsmtFinType2&apos;: [&apos;GLQ&apos;, &apos;ALQ&apos;, &apos;BLQ&apos;, &apos;Rec&apos;, &apos;LwQ&apos;, &apos;Unf&apos;, &apos;NA&apos;], &apos;BsmtFinSF2&apos;: [], &apos;BsmtUnfSF&apos;: [], &apos;TotalBsmtSF&apos;: [], &apos;Heating&apos;: [&apos;Floor&apos;, &apos;GasA&apos;, &apos;GasW&apos;, &apos;Grav&apos;, &apos;OthW&apos;, &apos;Wall&apos;], &apos;HeatingQC&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;CentralAir&apos;: [&apos;N&apos;, &apos;Y&apos;], &apos;Electrical&apos;: [&apos;SBrkr&apos;, &apos;FuseA&apos;, &apos;FuseF&apos;, &apos;FuseP&apos;, &apos;Mix&apos;], &apos;1stFlrSF&apos;: [], &apos;2ndFlrSF&apos;: [], &apos;LowQualFinSF&apos;: [], &apos;GrLivArea&apos;: [], &apos;BsmtFullBath&apos;: [], &apos;BsmtHalfBath&apos;: [], &apos;FullBath&apos;: [], &apos;HalfBath&apos;: [], &apos;Bedroom&apos;: [], &apos;Kitchen&apos;: [], &apos;KitchenQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;], &apos;TotRmsAbvGrd&apos;: [], &apos;Functional&apos;: [&apos;Typ&apos;, &apos;Min1&apos;, &apos;Min2&apos;, &apos;Mod&apos;, &apos;Maj1&apos;, &apos;Maj2&apos;, &apos;Sev&apos;, &apos;Sal&apos;], &apos;Fireplaces&apos;: [], &apos;FireplaceQu&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;GarageType&apos;: [&apos;2Types&apos;, &apos;Attchd&apos;, &apos;Basment&apos;, &apos;BuiltIn&apos;, &apos;CarPort&apos;, &apos;Detchd&apos;, &apos;NA&apos;], &apos;GarageYrBlt&apos;: [], &apos;GarageFinish&apos;: [&apos;Fin&apos;, &apos;RFn&apos;, &apos;Unf&apos;, &apos;NA&apos;], &apos;GarageCars&apos;: [], &apos;GarageArea&apos;: [], &apos;GarageQual&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;GarageCond&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;], &apos;PavedDrive&apos;: [&apos;Y&apos;, &apos;P&apos;, &apos;N&apos;], &apos;WoodDeckSF&apos;: [], &apos;OpenPorchSF&apos;: [], &apos;EnclosedPorch&apos;: [], &apos;3SsnPorch&apos;: [], &apos;ScreenPorch&apos;: [], &apos;PoolArea&apos;: [], &apos;PoolQC&apos;: [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;NA&apos;], &apos;Fence&apos;: [&apos;GdPrv&apos;, &apos;MnPrv&apos;, &apos;GdWo&apos;, &apos;MnWw&apos;, &apos;NA&apos;], &apos;MiscFeature&apos;: [&apos;Elev&apos;, &apos;Gar2&apos;, &apos;Othr&apos;, &apos;Shed&apos;, &apos;TenC&apos;, &apos;NA&apos;], &apos;MiscVal&apos;: [], &apos;MoSold&apos;: [], &apos;YrSold&apos;: [], &apos;SaleType&apos;: [&apos;WD&apos;, &apos;CWD&apos;, &apos;VWD&apos;, &apos;New&apos;, &apos;COD&apos;, &apos;Con&apos;, &apos;ConLw&apos;, &apos;ConLI&apos;, &apos;ConLD&apos;, &apos;Oth&apos;], &apos;SaleCondition&apos;: [&apos;Normal&apos;, &apos;Abnorml&apos;, &apos;AdjLand&apos;, &apos;Alloca&apos;, &apos;Family&apos;, &apos;Partial&apos;]} 1description_dict['FireplaceQu'] [&apos;Ex&apos;, &apos;Gd&apos;, &apos;TA&apos;, &apos;Fa&apos;, &apos;Po&apos;, &apos;NA&apos;] È¢ÑÂ§ÑÁêÜÈ¶ñÂÖàÂÖàÂà†Èô§‰∏Ä‰∫õÁ°ÆÂÆûËæÉÂ§öÂíå‰∏çÂ§™Â•ΩÂ°´ÂÖÖÁöÑfeature„ÄÇ 123# Âà†Èô§train_df = train_df.drop(['Alley', 'PoolQC', 'MiscFeature', 'LotFrontage'], axis=1)test_df = test_df.drop(['Alley', 'PoolQC', 'MiscFeature', 'LotFrontage'], axis=1) Â§ÑÁêÜ GarageYrBlt: Year garage was builtËΩ¶Â∫ìÁöÑÂπ¥‰ª£ÔºåÊ≤°ÊúâÂ°´ÂÖÖ 0ÔºåÊîπ‰∏∫ 1900 Âπ¥ÂºÄÂßã„ÄÇ 1234567def preprocess_garage_year(dataset): dataset = dataset.fillna(1900) dataset -= 1900 return dataset train_df['GarageYrBlt'] = preprocess_garage_year(train_df['GarageYrBlt'])test_df['GarageYrBlt'] = preprocess_garage_year(test_df['GarageYrBlt']) Â§ÑÁêÜ ElectricalElectrical: Electrical system SBrkr Standard Circuit Breakers &amp; Romex FuseA Fuse Box over 60 AMP and all Romex wiring (Average) FuseF 60 AMP Fuse Box and mostly Romex wiring (Fair) FuseP 60 AMP Fuse Box and mostly knob &amp; tube wiring (poor) Mix Mixed 12freq_port = train_df.Electrical.dropna().mode()[0] # ËøîÂõûÂá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÂÄºÔºà‰ºóÊï∞Ôºâfreq_port &apos;SBrkr&apos; 123456def preprocess_garage_year(dataset): dataset = dataset.fillna(freq_port) return dataset train_df['Electrical'] = preprocess_garage_year(train_df['Electrical'])test_df['Electrical'] = preprocess_garage_year(test_df['Electrical']) Â§ÑÁêÜ MasVnrArea: Masonry veneer area in square feetÁ†ñÁü≥È•∞Èù¢Èù¢ÁßØ:Á†ñÁü≥È•∞Èù¢Èù¢ÁßØ(Âπ≥ÊñπËã±Â∞∫) Áº∫Â§±ÁöÑ‰∏çÊòØÂ§™Â§öÔºà148ÔºâÔºåmean 103Ôºå‰ºóÊï∞Ôºà75%‰ª•‰∏äÔºâ‰∏∫ 0ÔºåËøòÊ≤°ÊÉ≥Âà∞Â§™Â•ΩÁöÑÂ°´ÂÖÖÔºåÂÖàÂ°´‰∏™0ËØïËØïÂêß„ÄÇ 1train_df.MasVnrArea.describe() count 1452.00000 mean 103.68526 std 181.06621 min 0.00000 25% 0.00000 50% 0.00000 75% 166.00000 max 1600.00000 Name: MasVnrArea, dtype: float64 123456def preprocess_masvararea(dataset): dataset = dataset.fillna(0) return dataset train_df['MasVnrArea'] = preprocess_masvararea(train_df['MasVnrArea'])test_df['MasVnrArea'] = preprocess_masvararea(test_df['MasVnrArea']) Â§ÑÁêÜ MasVnrTypeMasVnrType: Masonry veneer type BrkCmn Brick Common BrkFace Brick Face CBlock Cinder Block None None Stone Stone Ëøô‰∏™ÂÄºÂæàÂ•áÊÄ™Ôºå‰∏çÂ§™ÊòéÁôΩËøôÊòØ‰ªÄ‰πàÔºåÊòØÊ≤°ÊúâÂ•ΩÂë¢ËøòÊòØ Stone Â•ΩÂë¢Ôºü 1train_df.MasVnrType.dropna().mode()[0] # ËøîÂõûÂá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÂÄºÔºà‰ºóÊï∞Ôºâ &apos;None&apos; Â§ßÂ§öÊï∞ÈÉΩÊ≤°ÊúâÔºåÈÇ£Â∞±ÊääÁº∫Â§±ÂÄºÂ°´‰∏∫Ê≤°ÊúâÂêß„ÄÇ 123456def preprocess_masvnrtype(dataset): dataset = dataset.fillna('None') return dataset train_df['MasVnrType'] = preprocess_masvnrtype(train_df['MasVnrType'])test_df['MasVnrType'] = preprocess_masvnrtype(test_df['MasVnrType']) Â§ÑÁêÜÂÖ∂‰ªñÁº∫Â§± featureÈúÄË¶ÅÂ°´ÂÖÖÁº∫Â§±ÂÄºÂíåÈáçÁºñÁ†Å„ÄÇ Ê†πÊçÆ data description Êää Â≠óÁ¨¶‰∏≤Á±ªÂûãÁöÑ feature ÈáçÁºñÁ†Å„ÄÇ ÊûÑÈÄ† feature ÂØπÂ∫îÁöÑ map ËßÇÂØüÂèëÁé∞‰ª•‰∏ãËøô‰∫õÁº∫Â§±Êàë‰ª¨ÂèØ‰ª•Â°´ÂÖÖÔºåÈ°∫‰æøÈáçÁºñÁ†Å„ÄÇ 1234567891011missing_value = ['Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',] 1234567def generate_map(map_list, end_index=1): d = &#123;&#125; j = len(map_list) - end_index for i in map_list: d[i] = j j -= 1 return d 12345missing_map_dict = &#123;&#125;for feature in missing_value: missing_map_dict[feature] = generate_map(description_dict[feature])missing_map_dict {&apos;BsmtCond&apos;: {&apos;Ex&apos;: 5, &apos;Fa&apos;: 2, &apos;Gd&apos;: 4, &apos;NA&apos;: 0, &apos;Po&apos;: 1, &apos;TA&apos;: 3}, &apos;BsmtExposure&apos;: {&apos;Av&apos;: 3, &apos;Gd&apos;: 4, &apos;Mn&apos;: 2, &apos;NA&apos;: 0, &apos;No&apos;: 1}, &apos;BsmtFinType1&apos;: {&apos;ALQ&apos;: 5, &apos;BLQ&apos;: 4, &apos;GLQ&apos;: 6, &apos;LwQ&apos;: 2, &apos;NA&apos;: 0, &apos;Rec&apos;: 3, &apos;Unf&apos;: 1}, &apos;BsmtFinType2&apos;: {&apos;ALQ&apos;: 5, &apos;BLQ&apos;: 4, &apos;GLQ&apos;: 6, &apos;LwQ&apos;: 2, &apos;NA&apos;: 0, &apos;Rec&apos;: 3, &apos;Unf&apos;: 1}, &apos;BsmtQual&apos;: {&apos;Ex&apos;: 5, &apos;Fa&apos;: 2, &apos;Gd&apos;: 4, &apos;NA&apos;: 0, &apos;Po&apos;: 1, &apos;TA&apos;: 3}, &apos;Fence&apos;: {&apos;GdPrv&apos;: 4, &apos;GdWo&apos;: 2, &apos;MnPrv&apos;: 3, &apos;MnWw&apos;: 1, &apos;NA&apos;: 0}, &apos;FireplaceQu&apos;: {&apos;Ex&apos;: 5, &apos;Fa&apos;: 2, &apos;Gd&apos;: 4, &apos;NA&apos;: 0, &apos;Po&apos;: 1, &apos;TA&apos;: 3}, &apos;GarageCond&apos;: {&apos;Ex&apos;: 5, &apos;Fa&apos;: 2, &apos;Gd&apos;: 4, &apos;NA&apos;: 0, &apos;Po&apos;: 1, &apos;TA&apos;: 3}, &apos;GarageFinish&apos;: {&apos;Fin&apos;: 3, &apos;NA&apos;: 0, &apos;RFn&apos;: 2, &apos;Unf&apos;: 1}, &apos;GarageQual&apos;: {&apos;Ex&apos;: 5, &apos;Fa&apos;: 2, &apos;Gd&apos;: 4, &apos;NA&apos;: 0, &apos;Po&apos;: 1, &apos;TA&apos;: 3}, &apos;GarageType&apos;: {&apos;2Types&apos;: 6, &apos;Attchd&apos;: 5, &apos;Basment&apos;: 4, &apos;BuiltIn&apos;: 3, &apos;CarPort&apos;: 2, &apos;Detchd&apos;: 1, &apos;NA&apos;: 0}} 12345# È¢ÑÂ§ÑÁêÜ feature Êää str ËΩ¨Êç¢‰∏∫Â∫èÂàó def preprocess_feature_strtoint(feature_df, feature_mapping, default=0): feature_df = feature_df.map(feature_mapping) feature_df = feature_df.fillna(default) return feature_df 1234def preprocess_feature(dataset): for feature in missing_value: dataset[feature] = preprocess_feature_strtoint(dataset[feature], missing_map_dict[feature]) return dataset 12train_df = preprocess_feature(train_df)test_df = preprocess_feature(test_df) Ê£ÄÊü•ËÆ≠ÁªÉÈõÜÁº∫Â§±ÂÄºÔºåÂ∑≤ÁªèÊ≤°Êúâ‰∫Ü„ÄÇ 1train_df[train_df.isnull().values==True] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass MSZoning LotArea Street LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF Heating HeatingQC CentralAir Electrical 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea Fence MiscVal MoSold YrSold SaleType SaleCondition SalePrice Â°´ÂÖÖÊµãËØïÈõÜÊµãËØïÈõÜËøòÊúâËÆ∏Â§öÁº∫Â§±ÔºåÂÖàÂÜ≥ÂÆöÁî®‰ºóÊï∞Â°´ÂÖÖ„ÄÇ 1test_df[test_df.isnull().values==True] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass MSZoning LotArea Street LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF Heating HeatingQC CentralAir Electrical 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea Fence MiscVal MoSold YrSold SaleType SaleCondition 95 1556 50 RL 10632 Pave IR1 Lvl AllPub Inside Gtl ClearCr Norm Norm 1Fam 1.5Fin 5 3 1917 1950 Gable CompShg Wd Sdng Wd Sdng None 0.00000 TA TA BrkTil 4.00000 2.00000 1.00000 1.00000 0.00000 1.00000 0.00000 689.00000 689.00000 GasA Gd N SBrkr 725 499 0 1224 0.00000 0.00000 1 1 3 1 NaN 6 Mod 0 0.00000 1.00000 17.00000 1.00000 1.00000 180.00000 2.00000 2.00000 N 0 0 248 0 0 0 0.00000 0 1 2010 COD Normal 455 1916 30 NaN 21780 Grvl Reg Lvl NaN Inside Gtl IDOTRR Norm Norm 1Fam 1Story 2 4 1910 1950 Gable CompShg Wd Sdng Wd Sdng None 0.00000 Fa Fa CBlock 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 GasA TA N FuseA 810 0 0 810 0.00000 0.00000 1 0 1 1 TA 4 Min1 0 0.00000 1.00000 75.00000 1.00000 1.00000 280.00000 3.00000 3.00000 N 119 24 0 0 0 0 0.00000 0 3 2009 ConLD Normal 455 1916 30 NaN 21780 Grvl Reg Lvl NaN Inside Gtl IDOTRR Norm Norm 1Fam 1Story 2 4 1910 1950 Gable CompShg Wd Sdng Wd Sdng None 0.00000 Fa Fa CBlock 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 GasA TA N FuseA 810 0 0 810 0.00000 0.00000 1 0 1 1 TA 4 Min1 0 0.00000 1.00000 75.00000 1.00000 1.00000 280.00000 3.00000 3.00000 N 119 24 0 0 0 0 0.00000 0 3 2009 ConLD Normal 485 1946 20 RL 31220 Pave IR1 Bnk NaN FR2 Gtl Gilbert Feedr Norm 1Fam 1Story 6 2 1952 1952 Hip CompShg BrkFace BrkFace None 0.00000 TA TA CBlock 3.00000 3.00000 1.00000 1.00000 0.00000 1.00000 0.00000 1632.00000 1632.00000 GasA TA Y FuseA 1474 0 0 1474 0.00000 0.00000 1 0 3 1 TA 7 Min2 2 4.00000 5.00000 52.00000 1.00000 2.00000 495.00000 3.00000 3.00000 Y 0 0 144 0 0 0 0.00000 750 5 2008 WD Normal 660 2121 20 RM 5940 Pave IR1 Lvl AllPub FR3 Gtl BrkSide Feedr Norm 1Fam 1Story 4 7 1946 1950 Gable CompShg MetalSd CBlock None 0.00000 TA TA PConc 0.00000 0.00000 0.00000 0.00000 nan 0.00000 nan nan nan GasA TA Y FuseA 896 0 0 896 nan nan 1 0 2 1 TA 4 Typ 0 0.00000 1.00000 46.00000 1.00000 1.00000 280.00000 3.00000 3.00000 Y 0 0 0 0 0 0 3.00000 0 4 2008 ConLD Abnorml ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1013 2474 50 RM 10320 Pave Reg Lvl AllPub Corner Gtl IDOTRR Artery Norm 1Fam 1.5Fin 4 1 1910 1950 Gable CompShg Wd Sdng Wd Sdng None 0.00000 Fa Fa CBlock 3.00000 2.00000 1.00000 1.00000 0.00000 1.00000 0.00000 771.00000 771.00000 GasA Fa Y SBrkr 866 504 114 1484 0.00000 0.00000 2 0 3 1 TA 6 NaN 0 0.00000 1.00000 10.00000 1.00000 1.00000 264.00000 3.00000 2.00000 N 14 211 0 0 84 0 0.00000 0 9 2007 COD Abnorml 1029 2490 20 RL 13770 Pave Reg Lvl AllPub Corner Gtl Sawyer Feedr Norm 1Fam 1Story 5 6 1958 1998 Gable CompShg Plywood Plywood BrkFace 340.00000 TA TA CBlock 3.00000 3.00000 2.00000 3.00000 190.00000 4.00000 873.00000 95.00000 1158.00000 GasA TA Y SBrkr 1176 0 0 1176 1.00000 0.00000 1 0 3 1 TA 6 Typ 2 4.00000 5.00000 58.00000 1.00000 1.00000 303.00000 3.00000 3.00000 Y 0 0 0 0 0 0 0.00000 0 10 2007 NaN Normal 1116 2577 70 RM 9060 Pave Reg Lvl AllPub Inside Gtl IDOTRR Norm Norm 1Fam 2Story 5 6 1923 1999 Gable CompShg Wd Sdng Plywood None 0.00000 TA TA BrkTil 4.00000 3.00000 1.00000 5.00000 548.00000 1.00000 0.00000 311.00000 859.00000 GasA Ex Y SBrkr 942 886 0 1828 0.00000 0.00000 2 0 3 1 Gd 6 Typ 0 0.00000 1.00000 0.00000 0.00000 nan nan 0.00000 0.00000 Y 174 0 212 0 0 0 3.00000 0 3 2007 WD Alloca 1116 2577 70 RM 9060 Pave Reg Lvl AllPub Inside Gtl IDOTRR Norm Norm 1Fam 2Story 5 6 1923 1999 Gable CompShg Wd Sdng Plywood None 0.00000 TA TA BrkTil 4.00000 3.00000 1.00000 5.00000 548.00000 1.00000 0.00000 311.00000 859.00000 GasA Ex Y SBrkr 942 886 0 1828 0.00000 0.00000 2 0 3 1 Gd 6 Typ 0 0.00000 1.00000 0.00000 0.00000 nan nan 0.00000 0.00000 Y 174 0 212 0 0 0 3.00000 0 3 2007 WD Alloca 1444 2905 20 NaN 31250 Pave Reg Lvl AllPub Inside Gtl Mitchel Artery Norm 1Fam 1Story 1 3 1951 1951 Gable CompShg CBlock VinylSd None 0.00000 TA Fa CBlock 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 GasA TA Y FuseA 1600 0 0 1600 0.00000 0.00000 1 1 3 1 TA 6 Mod 0 0.00000 5.00000 51.00000 1.00000 1.00000 270.00000 2.00000 3.00000 N 0 0 135 0 0 0 0.00000 0 5 2006 WD Normal 22 rows √ó 76 columns 123for i in test_df.columns.values.tolist(): freq_port = test_df[i].dropna().mode()[0] # ËøîÂõûÂá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÂÄºÔºà‰ºóÊï∞) test_df[i] = test_df[i].fillna(freq_port) Â≠óÁ¨¶‰∏≤Á±ªÂûã feature ÈáçÁºñÁ†ÅÂ§ÑÁêÜÂÆåÁº∫Â§±ÂÄºÂêéËßÇÂØü‰∏ãËøòÊúâÈÇ£‰∫õfeatureÊòØÂ≠óÁ¨¶‰∏≤ÂΩ¢ÂºèÁöÑ„ÄÇ 1train_df.describe(include="O") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } MSZoning Street LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType ExterQual ExterCond Foundation Heating HeatingQC CentralAir Electrical KitchenQual Functional PavedDrive SaleType SaleCondition count 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 1460 unique 5 2 4 4 2 5 3 25 9 8 5 8 6 8 15 16 4 4 5 6 6 5 2 5 4 7 3 9 6 top RL Pave Reg Lvl AllPub Inside Gtl NAmes Norm Norm 1Fam 1Story Gable CompShg VinylSd VinylSd None TA TA PConc GasA Ex Y SBrkr TA Typ Y WD Normal freq 1151 1454 925 1311 1459 1052 1382 225 1260 1445 1220 726 1141 1434 515 504 872 906 1282 647 1428 741 1365 1335 735 1360 1340 1267 1198 ÁõÆÂâçËøòÊúâ‰ª•‰∏ãÁöÑ feature ÈúÄË¶ÅÁºñÁ†Å [‚ÄòMSZoning‚Äô, ‚ÄòStreet‚Äô, ‚ÄòLotShape‚Äô, ‚ÄòLandContour‚Äô, ‚ÄòUtilities‚Äô, ‚ÄòLotConfig‚Äô, ‚ÄòLandSlope‚Äô, ‚ÄòNeighborhood‚Äô, ‚ÄòCondition1‚Äô, ‚ÄòCondition2‚Äô, ‚ÄòBldgType‚Äô, ‚ÄòHouseStyle‚Äô, ‚ÄòRoofStyle‚Äô, ‚ÄòRoofMatl‚Äô, ‚ÄòExterior1st‚Äô, ‚ÄòExterior2nd‚Äô, ‚ÄòMasVnrType‚Äô, ‚ÄòExterQual‚Äô, ‚ÄòExterCond‚Äô, ‚ÄòFoundation‚Äô, ‚ÄòHeating‚Äô, ‚ÄòHeatingQC‚Äô, ‚ÄòCentralAir‚Äô, ‚ÄòElectrical‚Äô, ‚ÄòKitchenQual‚Äô, ‚ÄòFunctional‚Äô, ‚ÄòPavedDrive‚Äô, ‚ÄòSaleType‚Äô, ‚ÄòSaleCondition‚Äô] 123feature = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']for i in feature: print(set(train_df[i])) {&apos;RL&apos;, &apos;FV&apos;, &apos;C (all)&apos;, &apos;RM&apos;, &apos;RH&apos;} {&apos;Grvl&apos;, &apos;Pave&apos;} {&apos;IR2&apos;, &apos;Reg&apos;, &apos;IR3&apos;, &apos;IR1&apos;} {&apos;Lvl&apos;, &apos;Low&apos;, &apos;HLS&apos;, &apos;Bnk&apos;} {&apos;AllPub&apos;, &apos;NoSeWa&apos;} {&apos;CulDSac&apos;, &apos;FR2&apos;, &apos;Corner&apos;, &apos;FR3&apos;, &apos;Inside&apos;} {&apos;Gtl&apos;, &apos;Mod&apos;, &apos;Sev&apos;} {&apos;BrDale&apos;, &apos;NoRidge&apos;, &apos;Blmngtn&apos;, &apos;Sawyer&apos;, &apos;NPkVill&apos;, &apos;NridgHt&apos;, &apos;SawyerW&apos;, &apos;Mitchel&apos;, &apos;OldTown&apos;, &apos;NWAmes&apos;, &apos;NAmes&apos;, &apos;Somerst&apos;, &apos;Veenker&apos;, &apos;SWISU&apos;, &apos;CollgCr&apos;, &apos;BrkSide&apos;, &apos;ClearCr&apos;, &apos;IDOTRR&apos;, &apos;Crawfor&apos;, &apos;StoneBr&apos;, &apos;Timber&apos;, &apos;Gilbert&apos;, &apos;Blueste&apos;, &apos;MeadowV&apos;, &apos;Edwards&apos;} {&apos;Artery&apos;, &apos;PosN&apos;, &apos;PosA&apos;, &apos;Norm&apos;, &apos;RRNn&apos;, &apos;RRAe&apos;, &apos;RRNe&apos;, &apos;Feedr&apos;, &apos;RRAn&apos;} {&apos;Artery&apos;, &apos;PosN&apos;, &apos;PosA&apos;, &apos;Norm&apos;, &apos;RRNn&apos;, &apos;RRAe&apos;, &apos;Feedr&apos;, &apos;RRAn&apos;} {&apos;2fmCon&apos;, &apos;Duplex&apos;, &apos;Twnhs&apos;, &apos;TwnhsE&apos;, &apos;1Fam&apos;} {&apos;SFoyer&apos;, &apos;1.5Fin&apos;, &apos;2Story&apos;, &apos;1.5Unf&apos;, &apos;2.5Fin&apos;, &apos;2.5Unf&apos;, &apos;1Story&apos;, &apos;SLvl&apos;} {&apos;Mansard&apos;, &apos;Shed&apos;, &apos;Gable&apos;, &apos;Flat&apos;, &apos;Gambrel&apos;, &apos;Hip&apos;} {&apos;Roll&apos;, &apos;Metal&apos;, &apos;ClyTile&apos;, &apos;WdShngl&apos;, &apos;CompShg&apos;, &apos;Tar&amp;Grv&apos;, &apos;Membran&apos;, &apos;WdShake&apos;} {&apos;BrkFace&apos;, &apos;Plywood&apos;, &apos;MetalSd&apos;, &apos;Stucco&apos;, &apos;WdShing&apos;, &apos;CBlock&apos;, &apos;AsphShn&apos;, &apos;Stone&apos;, &apos;ImStucc&apos;, &apos;CemntBd&apos;, &apos;Wd Sdng&apos;, &apos;VinylSd&apos;, &apos;BrkComm&apos;, &apos;AsbShng&apos;, &apos;HdBoard&apos;} {&apos;BrkFace&apos;, &apos;Plywood&apos;, &apos;Wd Shng&apos;, &apos;MetalSd&apos;, &apos;CmentBd&apos;, &apos;Stucco&apos;, &apos;Other&apos;, &apos;CBlock&apos;, &apos;AsphShn&apos;, &apos;ImStucc&apos;, &apos;Stone&apos;, &apos;Wd Sdng&apos;, &apos;VinylSd&apos;, &apos;AsbShng&apos;, &apos;Brk Cmn&apos;, &apos;HdBoard&apos;} {&apos;BrkFace&apos;, &apos;None&apos;, &apos;BrkCmn&apos;, &apos;Stone&apos;} {&apos;Ex&apos;, &apos;Gd&apos;, &apos;Fa&apos;, &apos;TA&apos;} {&apos;Fa&apos;, &apos;Gd&apos;, &apos;Po&apos;, &apos;TA&apos;, &apos;Ex&apos;} {&apos;BrkTil&apos;, &apos;PConc&apos;, &apos;CBlock&apos;, &apos;Stone&apos;, &apos;Slab&apos;, &apos;Wood&apos;} {&apos;GasA&apos;, &apos;GasW&apos;, &apos;Wall&apos;, &apos;Floor&apos;, &apos;Grav&apos;, &apos;OthW&apos;} {&apos;Fa&apos;, &apos;Gd&apos;, &apos;Po&apos;, &apos;TA&apos;, &apos;Ex&apos;} {&apos;Y&apos;, &apos;N&apos;} {&apos;SBrkr&apos;, &apos;Mix&apos;, &apos;FuseA&apos;, &apos;FuseP&apos;, &apos;FuseF&apos;} {&apos;Ex&apos;, &apos;Gd&apos;, &apos;Fa&apos;, &apos;TA&apos;} {&apos;Mod&apos;, &apos;Min1&apos;, &apos;Maj1&apos;, &apos;Min2&apos;, &apos;Maj2&apos;, &apos;Typ&apos;, &apos;Sev&apos;} {&apos;Y&apos;, &apos;N&apos;, &apos;P&apos;} {&apos;Con&apos;, &apos;ConLD&apos;, &apos;ConLw&apos;, &apos;CWD&apos;, &apos;WD&apos;, &apos;New&apos;, &apos;ConLI&apos;, &apos;Oth&apos;, &apos;COD&apos;} {&apos;Abnorml&apos;, &apos;Alloca&apos;, &apos;Normal&apos;, &apos;AdjLand&apos;, &apos;Partial&apos;, &apos;Family&apos;} ËßÇÂØüÂà∞Ëøô‰∫õ feature Âç≥Êúâ‰ºòÂä£Á≠âÁ∫ßÂàíÂàÜÁöÑÔºå‰πüÊúâÊ≤°ÊúâÁ≠âÁ∫ßÁöÑÔºåÊó¢ÁÑ∂Â¶ÇÊ≠§ÔºåÊääÊúâÁ≠âÁ∫ßÂå∫ÂàÜÁöÑÁºñÁ†Å‰∏∫Â∫èÂàóÔºåÊ≤°ÊúâÁ≠âÁ∫ßÁöÑ‰ΩøÁî®Áã¨ÁÉ≠Á†Å„ÄÇ ÊúâÁ≠âÁ∫ßÁöÑÔºö MSZoning ExterQual ExterCond HeatingQC KitchenQual ÂÖ∂‰ΩôÁöÑ‰ΩøÁî®onehotÁºñÁ†Å„ÄÇ 1234567order_feature_set =&#123;'MSZoning','ExterQual','ExterCond','HeatingQC','KitchenQual',&#125;onehot_feature_set = set(feature) - order_feature_set Order ÁºñÁ†Å123456def preprocess_order_feature(dataset): for i in order_feature_set: order_map = generate_map(description_dict[i], 0) dataset[i] = dataset[i].map(order_map) dataset[i] = dataset[i].fillna(0) return dataset 12train_df = preprocess_order_feature(train_df)test_df = preprocess_order_feature(test_df) 1train_df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass MSZoning LotArea OverallQual OverallCond YearBuilt YearRemodAdd MasVnrArea ExterQual ExterCond BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF HeatingQC 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea Fence MiscVal MoSold YrSold SalePrice count 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 mean 730.50000 56.89726 2.82534 10516.82808 6.09932 5.57534 1971.26781 1984.86575 103.11712 3.39589 3.08356 3.48904 2.93493 1.63014 3.54589 443.63973 1.24726 46.54932 567.24041 1057.42945 4.14521 1162.62671 346.99247 5.84452 1515.46370 0.42534 0.05753 1.56507 0.38288 2.86644 1.04658 3.51164 6.51781 0.61301 1.82534 3.51438 74.15068 1.71575 1.76712 472.98014 2.81027 2.80890 94.24452 46.66027 21.95411 3.40959 15.06096 2.75890 0.56575 43.48904 6.32192 2007.81575 180921.19589 std 421.61001 42.30057 1.02017 9981.26493 1.38300 1.11280 30.20290 20.64541 180.73137 0.57428 0.35105 0.87648 0.55216 1.06739 2.10778 456.09809 0.89233 161.31927 441.86696 438.70532 0.95950 386.58774 436.52844 48.62308 525.48038 0.51891 0.23875 0.55092 0.50289 0.81578 0.22034 0.66376 1.62539 0.64467 1.81088 1.93321 29.98205 0.89283 0.74732 213.80484 0.72290 0.71969 125.33879 66.25603 61.11915 29.31733 55.75742 40.17731 1.20448 496.12302 2.70363 1.32810 79442.50288 min 1.00000 20.00000 0.00000 1300.00000 1.00000 1.00000 1872.00000 1950.00000 0.00000 2.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 334.00000 0.00000 0.00000 334.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 2.00000 2.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 2006.00000 34900.00000 25% 365.75000 20.00000 3.00000 7553.50000 5.00000 5.00000 1954.00000 1967.00000 0.00000 3.00000 3.00000 3.00000 3.00000 1.00000 1.00000 0.00000 1.00000 0.00000 223.00000 795.75000 3.00000 882.00000 0.00000 0.00000 1129.50000 0.00000 0.00000 1.00000 0.00000 2.00000 1.00000 3.00000 5.00000 0.00000 0.00000 1.00000 58.00000 1.00000 1.00000 334.50000 3.00000 3.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 5.00000 2007.00000 129975.00000 50% 730.50000 50.00000 3.00000 9478.50000 6.00000 5.00000 1973.00000 1994.00000 0.00000 3.00000 3.00000 4.00000 3.00000 1.00000 4.00000 383.50000 1.00000 0.00000 477.50000 991.50000 5.00000 1087.00000 0.00000 0.00000 1464.00000 0.00000 0.00000 2.00000 0.00000 3.00000 1.00000 3.00000 6.00000 1.00000 2.00000 5.00000 77.00000 2.00000 2.00000 480.00000 3.00000 3.00000 0.00000 25.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 6.00000 2008.00000 163000.00000 75% 1095.25000 70.00000 3.00000 11601.50000 7.00000 6.00000 2000.00000 2004.00000 164.25000 4.00000 3.00000 4.00000 3.00000 2.00000 6.00000 712.25000 1.00000 0.00000 808.00000 1298.25000 5.00000 1391.25000 728.00000 0.00000 1776.75000 1.00000 0.00000 2.00000 1.00000 3.00000 1.00000 4.00000 7.00000 1.00000 4.00000 5.00000 101.00000 2.00000 2.00000 576.00000 3.00000 3.00000 168.00000 68.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 8.00000 2009.00000 214000.00000 max 1460.00000 190.00000 6.00000 215245.00000 10.00000 9.00000 2010.00000 2010.00000 1600.00000 5.00000 5.00000 5.00000 4.00000 4.00000 6.00000 5644.00000 6.00000 1474.00000 2336.00000 6110.00000 5.00000 4692.00000 2065.00000 572.00000 5642.00000 3.00000 2.00000 3.00000 2.00000 8.00000 3.00000 5.00000 14.00000 3.00000 5.00000 6.00000 110.00000 3.00000 4.00000 1418.00000 5.00000 5.00000 857.00000 547.00000 552.00000 508.00000 480.00000 738.00000 4.00000 15500.00000 12.00000 2010.00000 755000.00000 One hot ÁºñÁ†Å1train_df.shape, test_df.shape ((1460, 77), (1459, 76)) 1234567def preprocess_onehot_feature(dataset): dataset_len = len(dataset) result = pd.DataFrame() for i in onehot_feature_set: tmp_pd = pd.get_dummies(dataset[i], prefix=i, dtype=float) result = pd.concat([result, tmp_pd], axis=1) return result 12train_onehot_df = preprocess_onehot_feature(train_df)test_onehot_df = preprocess_onehot_feature(test_df) 123print(train_onehot_df.shape, test_onehot_df.shape)test_missing = set(train_onehot_df.columns.values.tolist()) - set(test_onehot_df.columns.values.tolist())test_missing (1460, 168) (1459, 153) {&apos;Condition2_RRAe&apos;, &apos;Condition2_RRAn&apos;, &apos;Condition2_RRNn&apos;, &apos;Electrical_Mix&apos;, &apos;Exterior1st_ImStucc&apos;, &apos;Exterior1st_Stone&apos;, &apos;Exterior2nd_Other&apos;, &apos;Heating_Floor&apos;, &apos;Heating_OthW&apos;, &apos;HouseStyle_2.5Fin&apos;, &apos;RoofMatl_ClyTile&apos;, &apos;RoofMatl_Membran&apos;, &apos;RoofMatl_Metal&apos;, &apos;RoofMatl_Roll&apos;, &apos;Utilities_NoSeWa&apos;} ÂèàÈÅáÂà∞‰∏™ÂùëÔºåÊµãËØïÈõÜÊØîËÆ≠ÁªÉÈõÜÁöÑÊÉÖÂÜµÂ∞ë„ÄÇ 123456# ÁîüÊàê‰∏Ä‰∏™Áº∫Â§±ÁöÑ dagafarmtest_missing_zeros = pd.Series(np.zeros(1459))test_missing_fd = pd.DataFrame(&#123;k: test_missing_zeros for k in test_missing&#125; )# ÊääÁº∫Â§±ÁöÑÂ°´ËøõÂéªtest_onehot_df = pd.concat([test_onehot_df, test_missing_fd], axis=1) 1print(train_onehot_df.shape, test_onehot_df.shape) (1460, 168) (1459, 168) Êää Êñ∞ one hot ÁºñÁ†ÅÁöÑ feature Ê∑ªÂä†Âà∞ ÂéüÈõÜÂêà‰∏≠ÔºåÂπ∂Âà†Èô§ÂéüÊù•ÁöÑ feature 1234567# Êääone hotÁöÑfeatureÊ∑ªÂä†Âà∞ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜtrain_df = pd.concat([train_df, train_onehot_df], axis=1)test_df = pd.concat([test_df, test_onehot_df], axis=1)# ÂêåÊ≠•Âà†Èô§ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ‰∏≠ÁöÑÂéüfeaturetrain_df = train_df.drop(onehot_feature_set, axis=1)test_df = test_df.drop(onehot_feature_set, axis=1) 1train_df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass MSZoning LotArea OverallQual OverallCond YearBuilt YearRemodAdd MasVnrArea ExterQual ExterCond BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF HeatingQC 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea ... Exterior1st_BrkFace Exterior1st_CBlock Exterior1st_CemntBd Exterior1st_HdBoard Exterior1st_ImStucc Exterior1st_MetalSd Exterior1st_Plywood Exterior1st_Stone Exterior1st_Stucco Exterior1st_VinylSd Exterior1st_Wd Sdng Exterior1st_WdShing RoofMatl_ClyTile RoofMatl_CompShg RoofMatl_Membran RoofMatl_Metal RoofMatl_Roll RoofMatl_Tar&amp;Grv RoofMatl_WdShake RoofMatl_WdShngl Electrical_FuseA Electrical_FuseF Electrical_FuseP Electrical_Mix Electrical_SBrkr SaleCondition_Abnorml SaleCondition_AdjLand SaleCondition_Alloca SaleCondition_Family SaleCondition_Normal SaleCondition_Partial Condition1_Artery Condition1_Feedr Condition1_Norm Condition1_PosA Condition1_PosN Condition1_RRAe Condition1_RRAn Condition1_RRNe Condition1_RRNn count 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 ... 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 1460.00000 mean 730.50000 56.89726 2.82534 10516.82808 6.09932 5.57534 1971.26781 1984.86575 103.11712 3.39589 3.08356 3.48904 2.93493 1.63014 3.54589 443.63973 1.24726 46.54932 567.24041 1057.42945 4.14521 1162.62671 346.99247 5.84452 1515.46370 0.42534 0.05753 1.56507 0.38288 2.86644 1.04658 3.51164 6.51781 0.61301 1.82534 3.51438 74.15068 1.71575 1.76712 472.98014 ... 0.03425 0.00068 0.04178 0.15205 0.00068 0.15068 0.07397 0.00137 0.01712 0.35274 0.14110 0.01781 0.00068 0.98219 0.00068 0.00068 0.00068 0.00753 0.00342 0.00411 0.06438 0.01849 0.00205 0.00068 0.91438 0.06918 0.00274 0.00822 0.01370 0.82055 0.08562 0.03288 0.05548 0.86301 0.00548 0.01301 0.00753 0.01781 0.00137 0.00342 std 421.61001 42.30057 1.02017 9981.26493 1.38300 1.11280 30.20290 20.64541 180.73137 0.57428 0.35105 0.87648 0.55216 1.06739 2.10778 456.09809 0.89233 161.31927 441.86696 438.70532 0.95950 386.58774 436.52844 48.62308 525.48038 0.51891 0.23875 0.55092 0.50289 0.81578 0.22034 0.66376 1.62539 0.64467 1.81088 1.93321 29.98205 0.89283 0.74732 213.80484 ... 0.18192 0.02617 0.20016 0.35920 0.02617 0.35786 0.26182 0.03700 0.12978 0.47799 0.34824 0.13230 0.02617 0.13230 0.02617 0.02617 0.02617 0.08650 0.05844 0.06400 0.24552 0.13477 0.04530 0.02617 0.27989 0.25384 0.05229 0.09032 0.11628 0.38386 0.27989 0.17837 0.22899 0.34395 0.07385 0.11337 0.08650 0.13230 0.03700 0.05844 min 1.00000 20.00000 0.00000 1300.00000 1.00000 1.00000 1872.00000 1950.00000 0.00000 2.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 334.00000 0.00000 0.00000 334.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 2.00000 2.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 25% 365.75000 20.00000 3.00000 7553.50000 5.00000 5.00000 1954.00000 1967.00000 0.00000 3.00000 3.00000 3.00000 3.00000 1.00000 1.00000 0.00000 1.00000 0.00000 223.00000 795.75000 3.00000 882.00000 0.00000 0.00000 1129.50000 0.00000 0.00000 1.00000 0.00000 2.00000 1.00000 3.00000 5.00000 0.00000 0.00000 1.00000 58.00000 1.00000 1.00000 334.50000 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 50% 730.50000 50.00000 3.00000 9478.50000 6.00000 5.00000 1973.00000 1994.00000 0.00000 3.00000 3.00000 4.00000 3.00000 1.00000 4.00000 383.50000 1.00000 0.00000 477.50000 991.50000 5.00000 1087.00000 0.00000 0.00000 1464.00000 0.00000 0.00000 2.00000 0.00000 3.00000 1.00000 3.00000 6.00000 1.00000 2.00000 5.00000 77.00000 2.00000 2.00000 480.00000 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 75% 1095.25000 70.00000 3.00000 11601.50000 7.00000 6.00000 2000.00000 2004.00000 164.25000 4.00000 3.00000 4.00000 3.00000 2.00000 6.00000 712.25000 1.00000 0.00000 808.00000 1298.25000 5.00000 1391.25000 728.00000 0.00000 1776.75000 1.00000 0.00000 2.00000 1.00000 3.00000 1.00000 4.00000 7.00000 1.00000 4.00000 5.00000 101.00000 2.00000 2.00000 576.00000 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 max 1460.00000 190.00000 6.00000 215245.00000 10.00000 9.00000 2010.00000 2010.00000 1600.00000 5.00000 5.00000 5.00000 4.00000 4.00000 6.00000 5644.00000 6.00000 1474.00000 2336.00000 6110.00000 5.00000 4692.00000 2065.00000 572.00000 5642.00000 3.00000 2.00000 3.00000 2.00000 8.00000 3.00000 5.00000 14.00000 3.00000 5.00000 6.00000 110.00000 3.00000 4.00000 1418.00000 ... 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 8 rows √ó 221 columns 1train_df.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 1460 entries, 0 to 1459 Columns: 221 entries, Id to Condition1_RRNn dtypes: float64(182), int64(39) memory usage: 2.5 MB Áªà‰∫éÂ§ÑÁêÜÂÆå‰∫ÜÔºåÂ∑≤ÁªèÊ≤°Êúâ object Á±ªÂûãÁöÑÊï∞ÊçÆ‰∫Ü„ÄÇÊé•‰∏ãÊù•Â∞±ËÉΩÂª∫Ê®°‰∫Ü„ÄÇ Ê®°ÂûãÈ¢ÑÊµã12345train_df.sample(frac=1)X_train = train_df.drop(['SalePrice', 'Id'], axis=1)Y_train = train_df['SalePrice']X_test = test_df.drop('Id', axis=1).copy()X_train.shape, Y_train.shape, X_test.shape ((1460, 219), (1460,), (1459, 219)) ÂÖàÁî®ÈÄªËæëÂõûÂΩíÁúãÁúã 1X_train .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id MSSubClass MSZoning LotArea OverallQual OverallCond YearBuilt YearRemodAdd MasVnrArea ExterQual ExterCond BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF HeatingQC 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea ... Exterior1st_BrkFace Exterior1st_CBlock Exterior1st_CemntBd Exterior1st_HdBoard Exterior1st_ImStucc Exterior1st_MetalSd Exterior1st_Plywood Exterior1st_Stone Exterior1st_Stucco Exterior1st_VinylSd Exterior1st_Wd Sdng Exterior1st_WdShing RoofMatl_ClyTile RoofMatl_CompShg RoofMatl_Membran RoofMatl_Metal RoofMatl_Roll RoofMatl_Tar&amp;Grv RoofMatl_WdShake RoofMatl_WdShngl Electrical_FuseA Electrical_FuseF Electrical_FuseP Electrical_Mix Electrical_SBrkr SaleCondition_Abnorml SaleCondition_AdjLand SaleCondition_Alloca SaleCondition_Family SaleCondition_Normal SaleCondition_Partial Condition1_Artery Condition1_Feedr Condition1_Norm Condition1_PosA Condition1_PosN Condition1_RRAe Condition1_RRAn Condition1_RRNe Condition1_RRNn 0 1 60 3.00000 8450 7 5 2003 2003 196.00000 4 3 4.00000 3.00000 1.00000 6.00000 706 1.00000 0 150 856 5 856 854 0 1710 1 0 2 1 3 1 4 8 0 0.00000 5.00000 103.00000 2.00000 2 548 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1 2 20 3.00000 9600 6 8 1976 1976 0.00000 3 3 4.00000 3.00000 4.00000 5.00000 978 1.00000 0 284 1262 5 1262 0 0 1262 0 1 2 0 3 1 3 6 1 3.00000 5.00000 76.00000 2.00000 2 460 ... 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 2 3 60 3.00000 11250 7 5 2001 2002 162.00000 4 3 4.00000 3.00000 2.00000 6.00000 486 1.00000 0 434 920 5 920 866 0 1786 1 0 2 1 3 1 4 6 1 3.00000 5.00000 101.00000 2.00000 2 608 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 3 4 70 3.00000 9550 7 5 1915 1970 0.00000 3 3 3.00000 4.00000 1.00000 5.00000 216 1.00000 0 540 756 4 961 756 0 1717 1 0 1 0 3 1 4 7 1 4.00000 1.00000 98.00000 1.00000 3 642 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 4 5 60 3.00000 14260 8 5 2000 2000 350.00000 4 3 4.00000 3.00000 3.00000 6.00000 655 1.00000 0 490 1145 5 1145 1053 0 2198 1 0 2 1 4 1 4 9 1 3.00000 5.00000 100.00000 2.00000 3 836 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1455 1456 60 3.00000 7917 6 5 1999 2000 0.00000 3 3 4.00000 3.00000 1.00000 1.00000 0 1.00000 0 953 953 5 953 694 0 1647 0 0 2 1 3 1 3 7 1 3.00000 5.00000 99.00000 2.00000 2 460 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1456 1457 20 3.00000 13175 6 6 1978 1988 119.00000 3 3 4.00000 3.00000 1.00000 5.00000 790 3.00000 163 589 1542 3 2073 0 0 2073 1 0 2 0 3 1 3 7 2 3.00000 5.00000 78.00000 1.00000 2 500 ... 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1457 1458 70 3.00000 9042 7 9 1941 2006 0.00000 5 4 3.00000 4.00000 1.00000 6.00000 275 1.00000 0 877 1152 5 1188 1152 0 2340 0 0 2 0 4 1 4 9 2 4.00000 5.00000 41.00000 2.00000 1 252 ... 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1458 1459 20 3.00000 9717 5 6 1950 1996 0.00000 3 3 3.00000 3.00000 2.00000 6.00000 49 3.00000 1029 0 1078 4 1078 0 0 1078 1 0 1 0 2 1 4 5 0 0.00000 5.00000 50.00000 1.00000 1 240 ... 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1459 1460 20 3.00000 9937 5 6 1965 1965 0.00000 4 3 3.00000 3.00000 1.00000 4.00000 830 2.00000 290 136 1256 4 1256 0 0 1256 1 0 1 1 3 1 3 6 0 0.00000 5.00000 65.00000 3.00000 1 276 ... 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1460 rows √ó 220 columns 1234567# ÈÄªËæëÂõûÂΩílogreg = LogisticRegression()logreg.fit(X_train, Y_train)Y_pred = logreg.predict(X_test)acc_log = round(logreg.score(X_train, Y_train) * 100, 2)acc_log /usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning. FutureWarning) /usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning. &quot;this warning.&quot;, FutureWarning) /usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. &quot;the number of iterations.&quot;, ConvergenceWarning) 90.55 12345678# Random Forestrandom_forest = RandomForestClassifier(n_estimators=100)random_forest.fit(X_train, Y_train)Y_pred = random_forest.predict(X_test)random_forest.score(X_train, Y_train)acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)acc_random_forest 100.0 12345678910X = X_train.loc[: 1000]Y = Y_train.loc[: 1000]X_t = X_train.loc[1000: ]Y_t = Y_train.loc[1000: ]logreg = RandomForestClassifier(n_estimators=100)logreg.fit(X, Y)pred = logreg.predict(X_t) 12345plt.figure(figsize=(30, 5))x = np.array(range(len(pred)))plt.scatter(x, pred)plt.scatter(x, Y_t)plt.show() 1234plt.figure(figsize=(30, 5))plt.plot(pred - Y_t)plt.show()np.var(pred - Y_t) 2231563230.032489 1np.array([range(len(pred))]*10).T array([[ 0, 0, 0, ..., 0, 0, 0], [ 1, 1, 1, ..., 1, 1, 1], [ 2, 2, 2, ..., 2, 2, 2], ..., [457, 457, 457, ..., 457, 457, 457], [458, 458, 458, ..., 458, 458, 458], [459, 459, 459, ..., 459, 459, 459]]) 1234567# Support Vector Machinessvm = SVC()svm.fit(X_train, Y_train)Y_pred = svm.predict(X_test)acc_svm = round(svm.score(X_train, Y_train) * 100, 2)acc_svm /usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from &apos;auto&apos; to &apos;scale&apos; in version 0.22 to account better for unscaled features. Set gamma explicitly to &apos;auto&apos; or &apos;scale&apos; to avoid this warning. &quot;avoid this warning.&quot;, FutureWarning) 99.52 1234567# ‰øùÂ≠òÁªìÊûúsubmission = pd.DataFrame(&#123; "Id": test_df["Id"], "SalePrice": Y_pred &#125;)submission.to_csv("/submission.csv", index=False)]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Á≠ñÁï•]]></title>
    <url>%2F2019%2F04%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[ÂΩìÊàë‰ª¨ÁöÑÁ≥ªÁªüËææÂà∞‰∫Ü90%ÁöÑÂáÜÁ°ÆÁéáÊó∂ÔºåËßâÂæóËøòÊòØ‰∏çÂ§üÂ•ΩÔºåÊàë‰ª¨ÊúâÂæàÂ§öÊÉ≥Ê≥ïÂéªÊîπÂñÑÊàë‰ª¨ÁöÑÁ≥ªÁªüÔºåÊØîÂ¶ÇÔºåÂéªÊî∂ÈõÜÊõ¥Â§öÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÊî∂ÈõÜÊõ¥Â§ö‰∏çÂêåÂßøÂäøÂõæÁâá‰∏∞ÂØåÊ†∑Êú¨ÁöÑÂ§öÊ†∑ÊÄßÔºåÊàñËÄÖÊõ¥Â§öÁöÑÂèç‰æãÈõÜ„ÄÇÊàñËÄÖÂÜçÁî®Ê¢ØÂ∫¶‰∏ãÈôçËÆ≠ÁªÉÁÆóÊ≥ïÔºåËÆ≠ÁªÉ‰πÖ‰∏ÄÁÇπ„ÄÇÊàñËÄÖÂ∞ùËØïÁî®‰∏Ä‰∏™ÂÆåÂÖ®‰∏çÂêåÁöÑ‰ºòÂåñÁÆóÊ≥ïÔºåÊØîÂ¶ÇAdam‰ºòÂåñÁÆóÊ≥ï„ÄÇÊàñËÄÖÂ∞ùËØï‰ΩøÁî®ËßÑÊ®°Êõ¥Â§ßÊàñËÄÖÊõ¥Â∞èÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇÊàñËÄÖËØïËØïdropoutÊàñËÄÖL2Ê≠£ÂàôÂåñ„ÄÇÊàñËÄÖÊÉ≥Ë¶Å‰øÆÊîπÁΩëÁªúÁöÑÊû∂ÊûÑÔºåÊØîÂ¶Ç‰øÆÊîπÊøÄÊ¥ªÂáΩÊï∞ÔºåÊîπÂèòÈöêËóèÂçïÂÖÉÁöÑÊï∞ÁõÆ‰πãÁ±ªÁöÑÊñπÊ≥ï„ÄÇ Â¶Ç‰ΩïÈÄâÊã©Êõ¥Â•ΩÁöÑÊñπÊ≥ïËÄå‰∏çÊòØÊµ™Ë¥πÊó∂Èó¥ÔºåËøôÈáåËÆ∞ÂΩï‰∏ã‰∏Ä‰∫õÁ≠ñÁï•„ÄÇ Âçï‰∏ÄËØÑ‰º∞ÊåáÊ†ápercisionÔºöÊü•ÂáÜÁéá Ë¢´‰Ω†ÁöÑÂàÜÁ±ªÂô®‰∏≠Ê†áËÆ∞‰∏∫ÁúüÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊúâÂ§öÂ∞ëÁúüÁöÑ‰∏∫Áúü recallÔºöÊü•ÂÖ®Áéá ÂØπ‰∫éÊâÄÊúâ‰∏∫ÁúüÁöÑ‰æãÂ≠êÔºåÊúâÂ§öÂ∞ëË¢´ËØÜÂà´Âá∫Êù• Êü•ÂáÜÁéáÂíåÊü•ÂÖ®Áéá‰πãÈó¥ÂæÄÂæÄÈúÄË¶ÅÊäòË°∑Ôºå‰∏§‰∏™ÊåáÊ†áÈÉΩË¶ÅÈ°æÂèäÂà∞ÔºåÁî®F1ÂàÜÊï∞ÂèØ‰ª•Êõ¥Â•ΩÁöÑË°°ÈáèÁ≥ªÁªüÁöÑ‰ºòÂä£ $F_1 = \frac{2}{\frac{1}{P} + \frac{1}{R}}$ Âú®Êï∞Â≠¶‰∏≠ÔºåËøô‰∏™ÂáΩÊï∞Âè´ÂÅöÊü•ÂáÜÁéáPÂíåÊü•ÂÖ®ÁéáRÁöÑË∞ÉÂíåÂπ≥ÂùáÊï∞ Êª°Ë∂≥Âíå‰ºòÂåñÊåáÊ†áÈô§‰∫ÜF1ÂàÜÊï∞ÊàñËÄÖÂÖ∂ÂÆÉË°°ÈáèÂáÜÁ°ÆÂ∫¶ÁöÑÊåáÊ†áÂ§ñÔºåÊàë‰ª¨ËøòË¶ÅËÄÉËôëËøêË°åÊó∂Èó¥ÔºåÂ∞±ÊòØÈúÄË¶ÅÂ§öÈïøÊó∂Èó¥Êù•ÂàÜÁ±ª‰∏ÄÂº†Âõæ„ÄÇAÂàÜÁ±ªÂô®ÈúÄË¶Å80ÊØ´ÁßíÔºåBÈúÄË¶Å95ÊØ´ÁßíÔºåCÈúÄË¶Å1500ÊØ´ÁßíÔºåÂ∞±ÊòØËØ¥ÈúÄË¶Å1.5ÁßíÊù•ÂàÜÁ±ªÂõæÂÉè„ÄÇ Â¶Ç‰ΩïÈÄâÂèñ‰∏äÂõæ‰∏≠ÁöÑÂàÜÁ±ªÂô®ÔºåÂèØ‰ª•ËøôÊ†∑Âà§Êñ≠‰∏Ä‰∏ã‰ª£‰ª∑ cost = accuracy - 0.5 √ó running time Ëøô‰∏™ÊñπÊ≥ïÂèØËÉΩÂ§™ËøáÂàªÊÑèÔºåÂΩìÁÑ∂Âú®ÂÖ∑‰ΩìÊÉÖÂÜµÂÖ∑‰ΩìËÄÉËôë„ÄÇ ËÆ≠ÁªÉ/ÂºÄÂèë/ÊµãËØïÈõÜÂêàËÆæÁ´ãËÆ≠ÁªÉÈõÜÔºåÂºÄÂèëÈõÜÂíåÊµãËØïÈõÜÁöÑÊñπÂºèÂ§ßÂ§ßÂΩ±Âìç‰∫ÜÂª∫Á´ãÊú∫Âô®Â≠¶‰π†Â∫îÁî®ÊñπÈù¢ÂèñÂæóËøõÂ±ïÁöÑÈÄüÂ∫¶„ÄÇÊâÄ‰ª•ÔºåÊàë‰ª¨Â∏åÊúõÊúÄÁªàÂ∫îÁî®ÁöÑÁõÆÊ†áÊï∞ÊçÆÊòØÂíåËÆ≠ÁªÉÈõÜÂêàÊù•Ëá™Âêå‰∏ÄÂ§Ñ„ÄÇÊØîÂ¶ÇÔºåÊàë‰ª¨ÊÉ≥Ë¶ÅÂÅöÊâãÊú∫ÊëÑÂÉèÂ§¥ËØÜÂà´Áå´ÔºåËÆ≠ÁªÉÈõÜÊúÄÂ•ΩÊù•Ëá™ÊâãÊú∫ÊãçÊëÑÁöÑÂõæÁâáËÄå‰∏çÊòØÂú®ÁΩë‰∏äÁà¨ÂèñÁöÑÂæàÊ∏ÖÊô∞ÁöÑÂõæÁâáÊàñËÄÖÂç°ÈÄöÁå´‰πãÁ±ª„ÄÇ ÂºÄÂèëÈõÜÂíåÊµãËØïÈõÜÁöÑÂ§ßÂ∞èÂ¶ÇÊûú‰Ω†ÊÄªÂÖ±Êúâ100‰∏™Ê†∑Êú¨ÔºåËøôÊ†∑70/30ÊàñËÄÖ60/20/20ÂàÜÁöÑÁªèÈ™åÊ≥ïÂàôÊòØÁõ∏ÂΩìÂêàÁêÜÁöÑ„ÄÇÂ¶ÇÊûú‰Ω†ÊúâÂá†ÂçÉ‰∏™Ê†∑Êú¨ÊàñËÄÖÊúâ‰∏Ä‰∏á‰∏™Ê†∑Êú¨ÔºåËøô‰∫õÂÅöÊ≥ï‰πüËøòÊòØÂêàÁêÜÁöÑ„ÄÇ ‰ΩÜÂú®Áé∞‰ª£Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨Êõ¥‰π†ÊÉØÊìç‰ΩúËßÑÊ®°Â§ßÂæóÂ§öÁöÑÊï∞ÊçÆÈõÜÔºåÊØîÂ¶ÇËØ¥‰Ω†Êúâ1Áôæ‰∏á‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÔºåËøôÊ†∑ÂàÜÂèØËÉΩÊõ¥ÂêàÁêÜÔºå98%‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜÔºå1%ÂºÄÂèëÈõÜÔºå1%ÊµãËØïÈõÜ„ÄÇ ÈîôËØØÁéáÊåáÊ†á $Error = \frac{1}{\sum_{}^{}w^{(i)}}\sum_{i = 1}^{m_{{dev}}}{w^{(i)}I\{ y_{{pred}}^{(i)} \neq y^{(i)}\}}$ ÂèØÈÅøÂÖçÂÅèÂ∑ÆÊàë‰ª¨‰ΩøÁî®Áå´ÂàÜÁ±ªÂô®Êù•ÂÅö‰æãÂ≠êÔºåÊØîÂ¶Ç‰∫∫Á±ªÂÖ∑ÊúâËøë‰πéÂÆåÁæéÁöÑÂáÜÁ°ÆÂ∫¶ÔºåÊâÄ‰ª•‰∫∫Á±ªÊ∞¥Âπ≥ÁöÑÈîôËØØÊòØ1%„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂ¶ÇÊûúÊàë‰ª¨ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïËææÂà∞8%ÁöÑËÆ≠ÁªÉÈîôËØØÁéáÂíå10%ÁöÑÂºÄÂèëÈîôËØØÁéáÔºå‰Ω†ÁöÑÁÆóÊ≥ïÂú®ËÆ≠ÁªÉÈõÜ‰∏äÁöÑË°®Áé∞Âíå‰∫∫Á±ªÊ∞¥Âπ≥ÁöÑË°®Áé∞ÊúâÂæàÂ§ßÂ∑ÆË∑ùÁöÑËØùÔºåËØ¥Êòé‰Ω†ÁöÑÁÆóÊ≥ïÂØπËÆ≠ÁªÉÈõÜÁöÑÊãüÂêàÂπ∂‰∏çÂ•Ω„ÄÇÊâÄ‰ª•‰ªéÂáèÂ∞ëÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÁöÑÂ∑•ÂÖ∑Ëøô‰∏™ËßíÂ∫¶ÁúãÔºåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàë‰ºöÊääÈáçÁÇπÊîæÂú®ÂáèÂ∞ëÂÅèÂ∑Æ‰∏ä„ÄÇÈúÄË¶ÅÂÅöÁöÑÊòØÔºåÊØîÂ¶ÇËØ¥ËÆ≠ÁªÉÊõ¥Â§ßÁöÑÁ•ûÁªèÁΩëÁªúÔºåÊàñËÄÖË∑ë‰πÖ‰∏ÄÁÇπÊ¢ØÂ∫¶‰∏ãÈôçÔºåÂ∞±ËØïËØïËÉΩ‰∏çËÉΩÂú®ËÆ≠ÁªÉÈõÜ‰∏äÂÅöÂæóÊõ¥Â•Ω„ÄÇ ËøõË°åËØØÂ∑ÆÂàÜÊûêËøõË°åÈîôËØØÂàÜÊûêÔºåÂ∫îËØ•Êâæ‰∏ÄÁªÑÈîôËØØÊ†∑Êú¨ÔºåÂèØËÉΩÂú®‰Ω†ÁöÑÂºÄÂèëÈõÜÈáåÊàñËÄÖÊµãËØïÈõÜÈáåÔºåËßÇÂØüÈîôËØØÊ†áËÆ∞ÁöÑÊ†∑Êú¨ÔºåÁúãÁúãÂÅáÈò≥ÊÄßÔºàfalse positivesÔºâÂíåÂÅáÈò¥ÊÄßÔºàfalse negativesÔºâÔºåÁªüËÆ°Â±û‰∫é‰∏çÂêåÈîôËØØÁ±ªÂûãÁöÑÈîôËØØÊï∞Èáè„ÄÇÂú®Ëøô‰∏™ËøáÁ®ã‰∏≠ÔºåÂèØËÉΩ‰ºöÂæóÂà∞ÂêØÂèëÔºåÂΩíÁ∫≥Âá∫Êñ∞ÁöÑÈîôËØØÁ±ªÂûã„ÄÇÂ¶ÇÊûúËøá‰∫Ü‰∏ÄÈÅçÈîôËØØÊ†∑Êú¨ÔºåÁÑ∂ÂêéËØ¥ÔºåÂ§©ÔºåÊúâËøô‰πàÂ§öInstagramÊª§ÈïúÊàñSnapchatÊª§ÈïúÔºåËøô‰∫õÊª§ÈïúÂπ≤Êâ∞‰∫ÜÊàëÁöÑÂàÜÁ±ªÂô®Ôºå‰Ω†Â∞±ÂèØ‰ª•Âú®ÈÄî‰∏≠Êñ∞Âª∫‰∏Ä‰∏™ÈîôËØØÁ±ªÂûã„ÄÇÊÄª‰πãÔºåÈÄöËøáÁªüËÆ°‰∏çÂêåÈîôËØØÊ†áËÆ∞Á±ªÂûãÂç†ÊÄªÊï∞ÁöÑÁôæÂàÜÊØîÔºåÂèØ‰ª•Â∏ÆÂèëÁé∞Âì™‰∫õÈóÆÈ¢òÈúÄË¶Å‰ºòÂÖàËß£ÂÜ≥ÔºåÊàñËÄÖÊûÑÊÄùÊñ∞‰ºòÂåñÊñπÂêëÁöÑÁÅµÊÑü„ÄÇ Ê£ÄÊü•ÊòØÂê¶ÊúâÈîôËØØÁöÑÊ†áËÆ∞ÔºåÂΩìÊàë‰ª¨ÁöÑÊï∞ÊçÆÈáèËæÉÂ∞ëÊó∂ÔºåÂ∫îËØ•Ê£ÄÊü•‰∏ãÊòØÂê¶ÊúâÈîôËØØÁöÑÊ†áËÆ∞„ÄÇ ËøÅÁßªÂ≠¶‰π†ËøÅÁßªÂ≠¶‰π†ÊúÄÊúâÁî®ÁöÑÂú∫ÂêàÊòØÔºåÂ¶ÇÊûú‰Ω†Â∞ùËØï‰ºòÂåñ‰ªªÂä°BÁöÑÊÄßËÉΩÔºåÈÄöÂ∏∏Ëøô‰∏™‰ªªÂä°Êï∞ÊçÆÁõ∏ÂØπËæÉÂ∞ëÔºå‰æãÂ¶ÇÔºåÂú®ÊîæÂ∞ÑÁßë‰∏≠‰Ω†Áü•ÈÅìÂæàÈöæÊî∂ÈõÜÂæàÂ§öXÂ∞ÑÁ∫øÊâ´ÊèèÂõæÊù•Êê≠Âª∫‰∏Ä‰∏™ÊÄßËÉΩËâØÂ•ΩÁöÑÊîæÂ∞ÑÁßëËØäÊñ≠Á≥ªÁªüÔºåÊâÄ‰ª•Âú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºå‰Ω†ÂèØËÉΩ‰ºöÊâæ‰∏Ä‰∏™Áõ∏ÂÖ≥‰ΩÜ‰∏çÂêåÁöÑ‰ªªÂä°ÔºåÂ¶ÇÂõæÂÉèËØÜÂà´ÔºåÂÖ∂‰∏≠‰Ω†ÂèØËÉΩÁî®1Áôæ‰∏áÂº†ÂõæÁâáËÆ≠ÁªÉËøá‰∫ÜÔºåÂπ∂‰ªé‰∏≠Â≠¶Âà∞ÂæàÂ§ö‰ΩéÂ±ÇÊ¨°ÁâπÂæÅÔºåÊâÄ‰ª•ÈÇ£‰πüËÆ∏ËÉΩÂ∏ÆÂä©ÁΩëÁªúÂú®‰ªªÂä°BÂú®ÊîæÂ∞ÑÁßë‰ªªÂä°‰∏äÂÅöÂæóÊõ¥Â•ΩÔºåÂ∞ΩÁÆ°‰ªªÂä°BÊ≤°ÊúâËøô‰πàÂ§öÊï∞ÊçÆ„ÄÇËøÅÁßªÂ≠¶‰π†‰ªÄ‰πàÊó∂ÂÄôÊòØÊúâÊÑè‰πâÁöÑÔºüÂÆÉÁ°ÆÂÆûÂèØ‰ª•ÊòæËëóÊèêÈ´ò‰Ω†ÁöÑÂ≠¶‰π†‰ªªÂä°ÁöÑÊÄßËÉΩÔºå‰ΩÜ‰ªªÂä°AÂÆûÈôÖ‰∏äÊï∞ÊçÆÈáèÊØî‰ªªÂä°BË¶ÅÂ∞ëÔºåËøôÁßçÊÉÖÂÜµ‰∏ãÂ¢ûÁõäÂèØËÉΩ‰∏çÂ§ö„ÄÇ Â§ö‰ªªÂä°Â≠¶‰π†Âú®Â§ö‰ªªÂä°Â≠¶‰π†‰∏≠ÔºåÊòØÂêåÊó∂ÂºÄÂßãÂ≠¶‰π†ÁöÑÔºåËØïÂõæËÆ©Âçï‰∏™Á•ûÁªèÁΩëÁªúÂêåÊó∂ÂÅöÂá†‰ª∂‰∫ãÊÉÖÔºåÁÑ∂ÂêéÂ∏åÊúõËøôÈáåÊØè‰∏™‰ªªÂä°ÈÉΩËÉΩÂ∏ÆÂà∞ÂÖ∂‰ªñÊâÄÊúâ‰ªªÂä°„ÄÇ Â§ö‰ªªÂä°Â≠¶‰π†ËÉΩËÆ©‰Ω†ËÆ≠ÁªÉ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊù•ÊâßË°åËÆ∏Â§ö‰ªªÂä°ÔºåËøôÂèØ‰ª•Áªô‰Ω†Êõ¥È´òÁöÑÊÄßËÉΩÔºåÊØîÂçïÁã¨ÂÆåÊàêÂêÑ‰∏™‰ªªÂä°Êõ¥È´òÁöÑÊÄßËÉΩ„ÄÇ‰ΩÜË¶ÅÊ≥®ÊÑèÔºåÂÆûÈôÖ‰∏äËøÅÁßªÂ≠¶‰π†ÊØîÂ§ö‰ªªÂä°Â≠¶‰π†‰ΩøÁî®È¢ëÁéáÊõ¥È´ò„ÄÇÊàëÁúãÂà∞ÂæàÂ§ö‰ªªÂä°ÈÉΩÊòØÔºåÂ¶ÇÊûú‰Ω†ÊÉ≥Ëß£ÂÜ≥‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÔºå‰ΩÜ‰Ω†ÁöÑÊï∞ÊçÆÈõÜÁõ∏ÂØπËæÉÂ∞èÔºåÈÇ£‰πàËøÅÁßªÂ≠¶‰π†ÁúüÁöÑËÉΩÂ∏ÆÂà∞‰Ω†ÔºåÂ∞±ÊòØÂ¶ÇÊûú‰Ω†ÊâæÂà∞‰∏Ä‰∏™Áõ∏ÂÖ≥ÈóÆÈ¢òÔºåÂÖ∂‰∏≠Êï∞ÊçÆÈáèË¶ÅÂ§ßÂæóÂ§öÔºå‰Ω†Â∞±ËÉΩ‰ª•ÂÆÉ‰∏∫Âü∫Á°ÄËÆ≠ÁªÉ‰Ω†ÁöÑÁ•ûÁªèÁΩëÁªúÔºåÁÑ∂ÂêéËøÅÁßªÂà∞Ëøô‰∏™Êï∞ÊçÆÈáèÂæàÂ∞ëÁöÑ‰ªªÂä°‰∏äÊù•„ÄÇ Á´ØÂà∞Á´ØÁöÑÊ∑±Â∫¶Â≠¶‰π†ÁÆÄËÄåË®Ä‰πãÔºå‰ª•ÂâçÊúâ‰∏Ä‰∫õÊï∞ÊçÆÂ§ÑÁêÜÁ≥ªÁªüÊàñËÄÖÂ≠¶‰π†Á≥ªÁªüÔºåÂÆÉ‰ª¨ÈúÄË¶ÅÂ§ö‰∏™Èò∂ÊÆµÁöÑÂ§ÑÁêÜ„ÄÇÈÇ£‰πàÁ´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†Â∞±ÊòØÂøΩÁï•ÊâÄÊúâËøô‰∫õ‰∏çÂêåÁöÑÈò∂ÊÆµÔºåÁî®Âçï‰∏™Á•ûÁªèÁΩëÁªú‰ª£ÊõøÂÆÉ„ÄÇ Êàë‰ª¨Êù•Áúã‰∏Ä‰∫õ‰æãÂ≠êÔºå‰ª•ËØ≠Èü≥ËØÜÂà´‰∏∫‰æãÔºå‰Ω†ÁöÑÁõÆÊ†áÊòØËæìÂÖ•ÔºåÊØîÂ¶ÇËØ¥‰∏ÄÊÆµÈü≥È¢ëÔºåÁÑ∂ÂêéÊääÂÆÉÊò†Â∞ÑÂà∞‰∏Ä‰∏™ËæìÂá∫ÔºåÂ∞±ÊòØËøôÊÆµÈü≥È¢ëÁöÑÂê¨ÂÜôÊñáÊú¨„ÄÇÊâÄ‰ª•‰º†Áªü‰∏äÔºåËØ≠Èü≥ËØÜÂà´ÈúÄË¶ÅÂæàÂ§öÈò∂ÊÆµÁöÑÂ§ÑÁêÜ„ÄÇÈ¶ñÂÖà‰Ω†‰ºöÊèêÂèñ‰∏Ä‰∫õÁâπÂæÅÔºå‰∏Ä‰∫õÊâãÂ∑•ËÆæËÆ°ÁöÑÈü≥È¢ëÁâπÂæÅÔºå‰πüËÆ∏‰Ω†Âê¨ËøáMFCCÔºåËøôÁßçÁÆóÊ≥ïÊòØÁî®Êù•‰ªéÈü≥È¢ë‰∏≠ÊèêÂèñ‰∏ÄÁªÑÁâπÂÆöÁöÑ‰∫∫Â∑•ËÆæËÆ°ÁöÑÁâπÂæÅ„ÄÇÂú®ÊèêÂèñÂá∫‰∏Ä‰∫õ‰ΩéÂ±ÇÊ¨°ÁâπÂæÅ‰πãÂêéÔºå‰Ω†ÂèØ‰ª•Â∫îÁî®Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂú®Èü≥È¢ëÁâáÊÆµ‰∏≠ÊâæÂà∞Èü≥‰ΩçÔºåÊâÄ‰ª•Èü≥‰ΩçÊòØÂ£∞Èü≥ÁöÑÂü∫Êú¨Âçï‰ΩçÔºåÊØîÂ¶ÇËØ¥‚ÄúCat‚ÄùËøô‰∏™ËØçÊòØ‰∏â‰∏™Èü≥ËäÇÊûÑÊàêÁöÑÔºåCu-„ÄÅAh-ÂíåTu-ÔºåÁÆóÊ≥ïÂ∞±ÊääËøô‰∏â‰∏™Èü≥‰ΩçÊèêÂèñÂá∫Êù•ÔºåÁÑ∂Âêé‰Ω†Â∞ÜÈü≥‰Ωç‰∏≤Âú®‰∏ÄËµ∑ÊûÑÊàêÁã¨Á´ãÁöÑËØçÔºåÁÑ∂Âêé‰Ω†Â∞ÜËØç‰∏≤Ëµ∑Êù•ÊûÑÊàêÈü≥È¢ëÁâáÊÆµÁöÑÂê¨ÂÜôÊñáÊú¨„ÄÇ ÊâÄ‰ª•ÂíåËøôÁßçÊúâÂæàÂ§öÈò∂ÊÆµÁöÑÊµÅÊ∞¥Á∫øÁõ∏ÊØîÔºåÁ´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†ÂÅöÁöÑÊòØÔºå‰Ω†ËÆ≠ÁªÉ‰∏Ä‰∏™Â∑®Â§ßÁöÑÁ•ûÁªèÁΩëÁªúÔºåËæìÂÖ•Â∞±ÊòØ‰∏ÄÊÆµÈü≥È¢ëÔºåËæìÂá∫Áõ¥Êé•ÊòØÂê¨ÂÜôÊñáÊú¨„ÄÇAIÁöÑÂÖ∂‰∏≠‰∏Ä‰∏™ÊúâË∂£ÁöÑÁ§æ‰ºöÂ≠¶ÊïàÂ∫îÊòØÔºåÈöèÁùÄÁ´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†Á≥ªÁªüË°®Áé∞ÂºÄÂßãÊõ¥Â•ΩÔºåÊúâ‰∏Ä‰∫õËä±‰∫ÜÂ§ßÈáèÊó∂Èó¥ÊàñËÄÖÊï¥‰∏™‰∫ã‰∏öÁîüÊ∂ØËÆæËÆ°Âá∫ÊµÅÊ∞¥Á∫øÂêÑ‰∏™Ê≠•È™§ÁöÑÁ†îÁ©∂ÂëòÔºåËøòÊúâÂÖ∂‰ªñÈ¢ÜÂüüÁöÑÁ†îÁ©∂ÂëòÔºå‰∏çÂè™ÊòØËØ≠Ë®ÄËØÜÂà´È¢ÜÂüüÁöÑÔºå‰πüËÆ∏ÊòØËÆ°ÁÆóÊú∫ËßÜËßâÔºåËøòÊúâÂÖ∂‰ªñÈ¢ÜÂüüÔºå‰ªñ‰ª¨Ëä±‰∫ÜÂ§ßÈáèÁöÑÊó∂Èó¥ÔºåÂÜô‰∫ÜÂæàÂ§öËÆ∫ÊñáÔºåÊúâ‰∫õÁîöËá≥Êï¥‰∏™ËÅå‰∏öÁîüÊ∂ØÁöÑ‰∏ÄÂ§ßÈÉ®ÂàÜÈÉΩÊäïÂÖ•Âà∞ÂºÄÂèëËøô‰∏™ÊµÅÊ∞¥Á∫øÁöÑÂäüËÉΩÊàñËÄÖÂÖ∂‰ªñÊûÑ‰ª∂‰∏äÂéª‰∫Ü„ÄÇËÄåÁ´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†Â∞±Âè™ÈúÄË¶ÅÊääËÆ≠ÁªÉÈõÜÊãøËøáÊù•ÔºåÁõ¥Êé•Â≠¶Âà∞‰∫ÜÂíå‰πãÈó¥ÁöÑÂáΩÊï∞Êò†Â∞ÑÔºåÁõ¥Êé•ÁªïËøá‰∫ÜÂÖ∂‰∏≠ÂæàÂ§öÊ≠•È™§„ÄÇÂØπ‰∏Ä‰∫õÂ≠¶ÁßëÈáåÁöÑ‰∫∫Êù•ËØ¥ÔºåËøôÁÇπÁõ∏ÂΩìÈöæ‰ª•Êé•ÂèóÔºå‰ªñ‰ª¨Êó†Ê≥ïÊé•ÂèóËøôÊ†∑ÊûÑÂª∫AIÁ≥ªÁªüÔºåÂõ†‰∏∫Êúâ‰∫õÊÉÖÂÜµÔºåÁ´ØÂà∞Á´ØÊñπÊ≥ïÂÆåÂÖ®Âèñ‰ª£‰∫ÜÊóßÁ≥ªÁªüÔºåÊüê‰∫õÊäïÂÖ•‰∫ÜÂ§öÂπ¥Á†îÁ©∂ÁöÑ‰∏≠Èó¥ÁªÑ‰ª∂‰πüËÆ∏Â∑≤ÁªèËøáÊó∂‰∫Ü„ÄÇ ‰∫ãÂÆûËØÅÊòéÔºåÁ´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊåëÊàò‰πã‰∏ÄÊòØÔºå‰Ω†ÂèØËÉΩÈúÄË¶ÅÂ§ßÈáèÊï∞ÊçÆÊâçËÉΩËÆ©Á≥ªÁªüË°®Áé∞ËâØÂ•ΩÔºåÊØîÂ¶ÇÔºå‰Ω†Âè™Êúâ3000Â∞èÊó∂Êï∞ÊçÆÂéªËÆ≠ÁªÉ‰Ω†ÁöÑËØ≠Èü≥ËØÜÂà´Á≥ªÁªüÔºåÈÇ£‰πà‰º†ÁªüÁöÑÊµÅÊ∞¥Á∫øÊïàÊûúÁúüÁöÑÂæàÂ•Ω„ÄÇ‰ΩÜÂΩì‰Ω†Êã•ÊúâÈùûÂ∏∏Â§ßÁöÑÊï∞ÊçÆÈõÜÊó∂ÔºåÊØîÂ¶Ç10,000Â∞èÊó∂Êï∞ÊçÆÊàñËÄÖ100,000Â∞èÊó∂Êï∞ÊçÆÔºåËøôÊ†∑Á´ØÂà∞Á´ØÊñπÊ≥ïÁ™ÅÁÑ∂ÂºÄÂßãÂæàÂéâÂÆ≥‰∫Ü„ÄÇÊâÄ‰ª•ÂΩì‰Ω†ÁöÑÊï∞ÊçÆÈõÜËæÉÂ∞èÁöÑÊó∂ÂÄôÔºå‰º†ÁªüÊµÅÊ∞¥Á∫øÊñπÊ≥ïÂÖ∂ÂÆûÊïàÊûú‰πü‰∏çÈîôÔºåÈÄöÂ∏∏ÂÅöÂæóÊõ¥Â•Ω„ÄÇ‰Ω†ÈúÄË¶ÅÂ§ßÊï∞ÊçÆÈõÜÊâçËÉΩËÆ©Á´ØÂà∞Á´ØÊñπÊ≥ïÁúüÊ≠£ÂèëÂá∫ËÄÄÁúºÂÖâËäí„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÊï∞ÊçÆÈáèÈÄÇ‰∏≠ÔºåÈÇ£‰πà‰πüÂèØ‰ª•Áî®‰∏≠Èó¥‰ª∂ÊñπÊ≥ïÔºå‰Ω†ÂèØËÉΩËæìÂÖ•ËøòÊòØÈü≥È¢ëÔºåÁÑ∂ÂêéÁªïËøáÁâπÂæÅÊèêÂèñÔºåÁõ¥Êé•Â∞ùËØï‰ªéÁ•ûÁªèÁΩëÁªúËæìÂá∫Èü≥‰ΩçÔºåÁÑ∂Âêé‰πüÂèØ‰ª•Âú®ÂÖ∂‰ªñÈò∂ÊÆµÁî®ÔºåÊâÄ‰ª•ËøôÊòØÂæÄÁ´ØÂà∞Á´ØÂ≠¶‰π†ËøàÂá∫ÁöÑ‰∏ÄÂ∞èÊ≠•Ôºå‰ΩÜËøòÊ≤°ÊúâÂà∞ÈÇ£Èáå„ÄÇ Âè¶‰∏Ä‰∏™‰æãÂ≠êÔºåÊØîÂ¶ÇËØ¥‰Ω†Â∏åÊúõËßÇÂØü‰∏Ä‰∏™Â≠©Â≠êÊâãÈÉ®ÁöÑXÂÖâÁÖßÁâáÔºåÂπ∂‰º∞ËÆ°‰∏Ä‰∏™Â≠©Â≠êÁöÑÂπ¥ÈæÑ„ÄÇ Â§ÑÁêÜËøô‰∏™‰æãÂ≠êÁöÑ‰∏Ä‰∏™ÈùûÁ´ØÂà∞Á´ØÊñπÊ≥ïÔºåÂ∞±ÊòØÁÖß‰∏ÄÂº†ÂõæÔºåÁÑ∂ÂêéÂàÜÂâ≤Âá∫ÊØè‰∏ÄÂùóÈ™®Â§¥ÔºåÊâÄ‰ª•Â∞±ÊòØÂàÜËæ®Âá∫ÈÇ£ÊÆµÈ™®Â§¥Â∫îËØ•Âú®Âì™ÈáåÔºåÈÇ£ÊÆµÈ™®Â§¥Âú®Âì™ÈáåÔºåÈÇ£ÊÆµÈ™®Â§¥Âú®Âì™ÈáåÔºåÁ≠âÁ≠â„ÄÇÁÑ∂ÂêéÔºåÁü•ÈÅì‰∏çÂêåÈ™®È™ºÁöÑÈïøÂ∫¶Ôºå‰Ω†ÂèØ‰ª•ÂéªÊü•Ë°®ÔºåÊü•Âà∞ÂÑøÁ´•Êâã‰∏≠È™®Â§¥ÁöÑÂπ≥ÂùáÈïøÂ∫¶ÔºåÁÑ∂ÂêéÁî®ÂÆÉÊù•‰º∞ËÆ°Â≠©Â≠êÁöÑÂπ¥ÈæÑÔºåÊâÄ‰ª•ËøôÁßçÊñπÊ≥ïÂÆûÈôÖ‰∏äÂæàÂ•Ω„ÄÇ Áõ∏ÊØî‰πã‰∏ãÔºåÂ¶ÇÊûú‰Ω†Áõ¥Êé•‰ªéÂõæÂÉèÂéªÂà§Êñ≠Â≠©Â≠êÁöÑÂπ¥ÈæÑÔºåÈÇ£‰πà‰Ω†ÈúÄË¶ÅÂ§ßÈáèÁöÑÊï∞ÊçÆÂéªÁõ¥Êé•ËÆ≠ÁªÉ„ÄÇÊçÆÊàëÊâÄÁü•ÔºåËøôÁßçÂÅöÊ≥ï‰ªäÂ§©ËøòÊòØ‰∏çË°åÁöÑÔºåÂõ†‰∏∫Ê≤°ÊúâË∂≥Â§üÁöÑÊï∞ÊçÆÊù•Áî®Á´ØÂà∞Á´ØÁöÑÊñπÂºèÊù•ËÆ≠ÁªÉËøô‰∏™‰ªªÂä°„ÄÇ ‰Ω†ÂèØ‰ª•ÊÉ≥Ë±°‰∏Ä‰∏ãÂ¶Ç‰ΩïÂ∞ÜËøô‰∏™ÈóÆÈ¢òÂàÜËß£Êàê‰∏§‰∏™Ê≠•È™§ÔºåÁ¨¨‰∏ÄÊ≠•ÊòØ‰∏Ä‰∏™ÊØîËæÉÁÆÄÂçïÁöÑÈóÆÈ¢òÔºå‰πüËÆ∏‰Ω†‰∏çÈúÄË¶ÅÈÇ£‰πàÂ§öÊï∞ÊçÆÔºå‰πüËÆ∏‰Ω†‰∏çÈúÄË¶ÅËÆ∏Â§öXÂ∞ÑÁ∫øÂõæÂÉèÊù•ÂàáÂàÜÈ™®È™º„ÄÇËÄå‰ªªÂä°‰∫åÔºåÊî∂ÈõÜÂÑøÁ´•ÊâãÈÉ®ÁöÑÈ™®Â§¥ÈïøÂ∫¶ÁöÑÁªüËÆ°Êï∞ÊçÆÔºå‰Ω†‰∏çÈúÄË¶ÅÂ§™Â§öÊï∞ÊçÆ‰πüËÉΩÂÅöÂá∫Áõ∏ÂΩìÂáÜÁ°ÆÁöÑ‰º∞ËÆ°ÔºåÊâÄ‰ª•Ëøô‰∏™Â§öÊ≠•ÊñπÊ≥ïÁúãËµ∑Êù•ÂæàÊúâÂ∏åÊúõÔºå‰πüËÆ∏ÊØîÁ´ØÂØπÁ´ØÊñπÊ≥ïÊõ¥ÊúâÂ∏åÊúõÔºåËá≥Â∞ëÁõ¥Âà∞‰Ω†ËÉΩËé∑ÂæóÊõ¥Â§öÁ´ØÂà∞Á´ØÂ≠¶‰π†ÁöÑÊï∞ÊçÆ‰πãÂâç„ÄÇ ÊâÄ‰ª•Á´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†Á≥ªÁªüÊòØÂèØË°åÁöÑÔºåÂÆÉË°®Áé∞ÂèØ‰ª•ÂæàÂ•ΩÔºå‰πüÂèØ‰ª•ÁÆÄÂåñÁ≥ªÁªüÊû∂ÊûÑÔºåËÆ©‰Ω†‰∏çÈúÄË¶ÅÊê≠Âª∫ÈÇ£‰πàÂ§öÊâãÂ∑•ËÆæËÆ°ÁöÑÂçïÁã¨ÁªÑ‰ª∂„ÄÇ ÊòØÂê¶Ë¶Å‰ΩøÁî®Á´ØÂà∞Á´ØÁöÑÊ∑±Â∫¶Â≠¶‰π†Â∫îÁî®Á´ØÂà∞Á´ØÂ≠¶‰π†ÁöÑ‰∏Ä‰∫õÂ•ΩÂ§ÑÔºåÈ¶ñÂÖàÁ´ØÂà∞Á´ØÂ≠¶‰π†ÁúüÁöÑÂè™ÊòØËÆ©Êï∞ÊçÆËØ¥ËØù„ÄÇÊâÄ‰ª•Â¶ÇÊûú‰Ω†ÊúâË∂≥Â§üÂ§öÁöÑÊï∞ÊçÆÔºåÈÇ£‰πà‰∏çÁÆ°‰ªéxÂà∞yÊúÄÈÄÇÂêàÁöÑÂáΩÊï∞Êò†Â∞ÑÊòØ‰ªÄ‰πàÔºåÂ¶ÇÊûú‰Ω†ËÆ≠ÁªÉ‰∏Ä‰∏™Ë∂≥Â§üÂ§ßÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂ∏åÊúõËøô‰∏™Á•ûÁªèÁΩëÁªúËÉΩËá™Â∑±ÊêûÊ∏ÖÊ•öÔºåËÄå‰ΩøÁî®Á∫ØÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºåÁõ¥Êé•‰ªéÂà∞ËæìÂÖ•ÂéªËÆ≠ÁªÉÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂèØËÉΩÊõ¥ËÉΩÂ§üÊçïËé∑Êï∞ÊçÆ‰∏≠ÁöÑ‰ªª‰ΩïÁªüËÆ°‰ø°ÊÅØÔºåËÄå‰∏çÊòØË¢´Ëø´ÂºïÂÖ•‰∫∫Á±ªÁöÑÊàêËßÅ„ÄÇ ‰æãÂ¶ÇÔºåÂú®ËØ≠Èü≥ËØÜÂà´È¢ÜÂüüÔºåÊó©ÊúüÁöÑËØÜÂà´Á≥ªÁªüÊúâËøô‰∏™Èü≥‰ΩçÊ¶ÇÂøµÔºåÂ∞±ÊòØÂü∫Êú¨ÁöÑÂ£∞Èü≥ÂçïÂÖÉÔºåÂ¶ÇcatÂçïËØçÁöÑ‚Äúcat‚ÄùÁöÑCu-„ÄÅAh-ÂíåTu-ÔºåÊàëËßâÂæóËøô‰∏™Èü≥‰ΩçÊòØ‰∫∫Á±ªËØ≠Ë®ÄÂ≠¶ÂÆ∂ÁîüÈÄ†Âá∫Êù•ÁöÑÔºåÊàëÂÆûÈôÖ‰∏äËÆ§‰∏∫Èü≥‰ΩçÂÖ∂ÂÆûÊòØËØ≠Èü≥Â≠¶ÂÆ∂ÁöÑÂπªÊÉ≥ÔºåÁî®Èü≥‰ΩçÊèèËø∞ËØ≠Ë®Ä‰πüËøòÁÆóÂêàÁêÜ„ÄÇ‰ΩÜÊòØ‰∏çË¶ÅÂº∫Ëø´‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ï‰ª•Èü≥‰Ωç‰∏∫Âçï‰ΩçÊÄùËÄÉÔºåËøôÁÇπÊúâÊó∂Ê≤°ÈÇ£‰πàÊòéÊòæ„ÄÇÂ¶ÇÊûú‰Ω†ËÆ©‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂ≠¶‰π†ÂÆÉÊÉ≥Â≠¶‰π†ÁöÑ‰ªªÊÑèË°®Á§∫ÊñπÂºèÔºåËÄå‰∏çÊòØÂº∫Ëø´‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ï‰ΩøÁî®Èü≥‰Ωç‰Ωú‰∏∫Ë°®Á§∫ÊñπÂºèÔºåÈÇ£‰πàÂÖ∂Êï¥‰ΩìË°®Áé∞ÂèØËÉΩ‰ºöÊõ¥Â•Ω„ÄÇ Á´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†ÁöÑÁ¨¨‰∫å‰∏™Â•ΩÂ§ÑÂ∞±ÊòØËøôÊ†∑ÔºåÊâÄÈúÄÊâãÂ∑•ËÆæËÆ°ÁöÑÁªÑ‰ª∂Êõ¥Â∞ëÔºåÊâÄ‰ª•Ëøô‰πüËÆ∏ËÉΩÂ§üÁÆÄÂåñ‰Ω†ÁöÑËÆæËÆ°Â∑•‰ΩúÊµÅÁ®ãÔºå‰Ω†‰∏çÈúÄË¶ÅËä±Â§™Â§öÊó∂Èó¥ÂéªÊâãÂ∑•ËÆæËÆ°ÂäüËÉΩÔºåÊâãÂ∑•ËÆæËÆ°Ëøô‰∫õ‰∏≠Èó¥Ë°®Á§∫ÊñπÂºè„ÄÇ ËøôÈáåÊúâ‰∏Ä‰∫õÁº∫ÁÇπÔºåÈ¶ñÂÖàÔºåÂÆÉÂèØËÉΩÈúÄË¶ÅÂ§ßÈáèÁöÑÊï∞ÊçÆ„ÄÇË¶ÅÁõ¥Êé•Â≠¶Âà∞Ëøô‰∏™Âà∞ÁöÑÊò†Â∞Ñ„ÄÇ Âè¶‰∏Ä‰∏™Áº∫ÁÇπÊòØÔºåÂÆÉÊéíÈô§‰∫ÜÂèØËÉΩÊúâÁî®ÁöÑÊâãÂ∑•ËÆæËÆ°ÁªÑ‰ª∂„ÄÇÂ¶ÇÊûú‰Ω†Ê≤°ÊúâÂæàÂ§öÊï∞ÊçÆÔºå‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂ∞±Ê≤°ÂäûÊ≥ï‰ªéÂæàÂ∞èÁöÑËÆ≠ÁªÉÈõÜÊï∞ÊçÆ‰∏≠Ëé∑ÂæóÊ¥ûÂØüÂäõ„ÄÇÂΩì‰Ω†ÊúâÂ§ßÈáèÊï∞ÊçÆÊó∂ÔºåÊâãÂ∑•ËÆæËÆ°ÁöÑ‰∏úË•øÂ∞±‰∏çÂ§™ÈáçË¶Å‰∫ÜÔºå‰ΩÜÊòØÂΩì‰Ω†Ê≤°ÊúâÂ§™Â§öÁöÑÊï∞ÊçÆÊó∂ÔºåÊûÑÈÄ†‰∏Ä‰∏™Á≤æÂøÉËÆæËÆ°ÁöÑÁ≥ªÁªüÔºåÂÆûÈôÖ‰∏äÂèØ‰ª•Â∞Ü‰∫∫Á±ªÂØπËøô‰∏™ÈóÆÈ¢òÁöÑÂæàÂ§öËÆ§ËØÜÁõ¥Êé•Ê≥®ÂÖ•Âà∞ÈóÆÈ¢òÈáåÔºåËøõÂÖ•ÁÆóÊ≥ïÈáåÂ∫îËØ•Êå∫ÊúâÂ∏ÆÂä©ÁöÑ„ÄÇ ÊâÄ‰ª•Á´ØÂà∞Á´ØÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂºäÁ´Ø‰πã‰∏ÄÊòØÂÆÉÊääÂèØËÉΩÊúâÁî®ÁöÑ‰∫∫Â∑•ËÆæËÆ°ÁöÑÁªÑ‰ª∂ÊéíÈô§Âú®Â§ñ‰∫ÜÔºåÁ≤æÂøÉËÆæËÆ°ÁöÑ‰∫∫Â∑•ÁªÑ‰ª∂ÂèØËÉΩÈùûÂ∏∏ÊúâÁî®Ôºå‰ΩÜÂÆÉ‰ª¨‰πüÊúâÂèØËÉΩÁúüÁöÑ‰º§ÂÆ≥Âà∞‰Ω†ÁöÑÁÆóÊ≥ïË°®Áé∞„ÄÇ‰æãÂ¶ÇÔºåÂº∫Âà∂‰Ω†ÁöÑÁÆóÊ≥ï‰ª•Èü≥‰Ωç‰∏∫Âçï‰ΩçÊÄùËÄÉÔºå‰πüËÆ∏ËÆ©ÁÆóÊ≥ïËá™Â∑±ÊâæÂà∞Êõ¥Â•ΩÁöÑË°®Á§∫ÊñπÊ≥ïÊõ¥Â•Ω„ÄÇÊâÄ‰ª•ËøôÊòØ‰∏ÄÊääÂèåÂàÉÂâëÔºåÂèØËÉΩÊúâÂùèÂ§ÑÔºåÂèØËÉΩÊúâÂ•ΩÂ§ÑÔºå‰ΩÜÂæÄÂæÄÂ•ΩÂ§ÑÊõ¥Â§öÔºåÊâãÂ∑•ËÆæËÆ°ÁöÑÁªÑ‰ª∂ÂæÄÂæÄÂú®ËÆ≠ÁªÉÈõÜÊõ¥Â∞èÁöÑÊó∂ÂÄôÂ∏ÆÂä©Êõ¥Â§ß„ÄÇ]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Ê∑±Â∫¶Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ê∑±Â∫¶Â≠¶‰π†ÁöÑÂèÇÊï∞Ë∞ÉËØï]]></title>
    <url>%2F2019%2F04%2F04%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[Âú®ÊûÑÂª∫Á•ûÁªèÁΩëÁªúÊ®°ÂûãÊó∂ÔºåÊúâËÆ∏Â§öÁöÑÂèÇÊï∞ÈúÄË¶ÅÂéªË∞ÉËØïÔºåÊØîÂ¶Çlearning rate ÔºàÂ≠¶‰π†ÁéáÔºâ„ÄÅiterations(Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂæ™ÁéØÁöÑÊï∞Èáè)„ÄÅLÔºàÈöêËóèÂ±ÇÊï∞ÁõÆÔºâ„ÄÅÔºàÈöêËóèÂ±ÇÂçïÂÖÉÊï∞ÁõÆÔºâ„ÄÅchoice of activation functionÔºàÊøÄÊ¥ªÂáΩÊï∞ÁöÑÈÄâÊã©ÔºâÈô§‰∫ÜËøô‰∫õÂü∫Êú¨ÁöÑËøòÊúâ‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÂèÇÊï∞ÔºåÂ¶Çmomentum„ÄÅmini batch size„ÄÅregularization parametersÁ≠âÁ≠â„ÄÇ Âú®ËøôÈáåËÆ∞ÂΩï‰∏ãÂ∏∏Áî®ÁöÑÂá†‰∏™ÂèÇÊï∞ÁöÑÈÄâÊã©„ÄÇ ÈöêËóèÂçïÂÖÉ hidden unitsËøôÊòØÈ¶ñÂÖàË¶ÅËÄÉËôëÁöÑÈóÆÈ¢òÔºåÊàë‰ª¨Ë¶ÅÊûÑÂª∫Â§öÂ∞ë‰∏™ÈöêËóèÂçïÂÖÉÊâç‰ºöÊõ¥ÈÄÇÂêàÔºü È¶ñÂÖàË¶ÅÊòéÁôΩ‰∏ÄÁÇπÔºåhidden units‰∏çÊòØË∂äÂ§öË∂äÂ•ΩÔºåÂÖ∑‰ΩìÂ§öÂ∞ëË¶ÅÈÄöËøáÂÖ∑‰ΩìÁöÑÊÉÖÂÜµÂ∞ùËØïÔºåËôΩÁÑ∂ÊúâËÆ∏Â§öÁöÑËÆ∫ÊñáÂÜô‰∫ÜÂêÑÁßçÊï∞Â≠¶ÂÖ¨ÂºèÊù•È™åËØÅÊ†∑Êú¨ÈõÜÂêà‰∏éÁ•ûÁªèÂÖÉÁöÑÂÖ≥Á≥ªÔºå‰ΩÜÊòØÊàëËßâÂæóËøòÊòØÂú®ÂÖ∑‰ΩìÊÉÖÂÜµ‰∏ãÔºåÊ†πÊçÆÁõ¥ËßâÊù•ËÆæÁΩÆ‰∏Ä‰∏™ÔºåÁÑ∂ÂêéÂÜçÂà†ÂáèÊâæÂà∞ÊúÄ‰ºò„ÄÇ ÈÄöÂ∏∏ÁöÑÂª∫ËÆÆÊòØËÆæÁΩÆÂ∞è‰∫éËæìÂÖ•ÁöÑ75%Ôºå‰ΩÜÂÖ∑‰ΩìÁöÑÊÉÖÂÜµÂÖ∑‰ΩìËÄÉËôëÔºå‰æãÂ¶ÇÊàëÂú®ÂÅöÊï∞Â≠óËØÜÂà´Êó∂ÔºåÊàë‰ª¨Êúâ0-9ÂçÅ‰∏™Êï∞Â≠óÔºåËÆæÁΩÆÂçÅ‰∏™ÈöêËóèÂçïÂÖÉË¶ÅÂ•Ω‰∫éËÆæÁΩÆÂ§ß‰∫éÂçÅÂíåÂ∞è‰∫éÂçÅ„ÄÇ Â≠¶‰π†ÈÄüÁéá learning rateËøôÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑÂèÇÊï∞ÔºåÂõ†‰∏∫Â≠¶‰π†ÈÄüÁéáÁöÑÈÄâÊã©ÂØπÊ¢ØÂ∫¶‰∏ãÈôçÁöÑÂΩ±ÂìçÊúÄÂ§ßÔºåÂÆÉÂèØËÉΩ‰ºöÂú®0Âà∞1‰πãÈó¥Ôºå ÊâÄ‰ª•Âú®Python‰∏≠Ôºå‰Ω†ÂèØ‰ª•ËøôÊ†∑ÂÅöÔºå‰Ωø pythonr = -4*np.random.rand()a = 10**r Âõ†‰∏∫$r \in \lbrack - 4,0\rbrack$ÊâÄ‰ª•$a \in \lbrack 10^{-4}, 10^{0}\rbrack$ÔºåËøôÊ†∑Êàë‰ª¨Â∞±ÂèØ‰ª•Âú®0.0001Âíå1‰πãÈó¥ÈöèÊú∫ÂèñÂá∫‰∏Ä‰∏™ÂÄº„ÄÇ batch sizeÂú®Ê†∑Êú¨ÈùûÂ∏∏Â§öÁöÑÊÉÖÂÜµ‰∏ã‰ºö‰ΩøÁî®mini batchÊ¢ØÂ∫¶‰∏ãÈôçÔºåÊàë‰ª¨ÊØèÊ¨°Ëø≠‰ª£ÈÄâÊã©Â§öÂ∞ësizeÊù•ËÆ°ÁÆóÂë¢Ôºü È¶ñÂÖàÔºåÂ¶ÇÊûúËÆ≠ÁªÉÈõÜËæÉÂ∞èÔºåÂ∞è‰∫é2000‰∏™Ê†∑Êú¨ÔºåÁõ¥Êé•‰ΩøÁî®batchÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºå‰πüÂ∞±ÊòØsize=mÔºàÊ†∑Êú¨ÊÄªÊï∞ÔºâÔºåÊ†∑Êú¨ÈõÜËæÉÂ∞èÂ∞±Ê≤°ÂøÖË¶Å‰ΩøÁî®mini-batchÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºåÊàë‰ª¨ÂèØ‰ª•Âø´ÈÄüÂ§ÑÁêÜÊï¥‰∏™ËÆ≠ÁªÉÈõÜÔºåÊâÄ‰ª•‰ΩøÁî®batchÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ï‰πüÂæàÂ•Ω„ÄÇ Ê†∑Êú¨Êï∞ÁõÆËæÉÂ§ßÁöÑËØùÔºå‰∏ÄËà¨ÁöÑmini batchÂ§ßÂ∞è‰∏∫64Âà∞512ÔºåËÄÉËôëÂà∞ÁîµËÑëÂÜÖÂ≠òËÆæÁΩÆÂíå‰ΩøÁî®ÁöÑÊñπÂºèÔºåÂ¶ÇÊûúmini batchÂ§ßÂ∞èÊòØ2ÁöÑÊ¨°ÊñπÔºå‰ª£Á†Å‰ºöËøêË°åÂú∞Âø´‰∏Ä‰∫õÔºå64Â∞±ÊòØ2ÁöÑ6Ê¨°ÊñπÔºå‰ª•Ê≠§Á±ªÊé®Ôºå128ÊòØ2ÁöÑ7Ê¨°ÊñπÔºå256ÊòØ2ÁöÑ8Ê¨°ÊñπÔºå512ÊòØ2ÁöÑ9Ê¨°Êñπ„ÄÇ ÊúÄÂêéÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÂú®mini batch‰∏≠ÔºåË¶ÅÁ°Æ‰øùÂíåË¶ÅÁ¨¶ÂêàCPU/GPUÂÜÖÂ≠òÔºåÂèñÂÜ≥‰∫éÊàë‰ª¨ÁöÑÂ∫îÁî®ÊñπÂêë‰ª•ÂèäËÆ≠ÁªÉÈõÜÁöÑÂ§ßÂ∞è„ÄÇÂ¶ÇÊûúÂ§ÑÁêÜÁöÑmini batchÂíåCPU/GPUÂÜÖÂ≠ò‰∏çÁõ∏Á¨¶Ôºå‰∏çÁÆ°Áî®‰ªÄ‰πàÊñπÊ≥ïÂ§ÑÁêÜÊï∞ÊçÆÔºåÁÆóÊ≥ïÁöÑË°®Áé∞‰ºöÊÄ•ËΩ¨Áõ¥‰∏ãÂèòÂæóÊÉ®‰∏çÂøçÁùπÔºåÊàë‰ª¨ÈúÄË¶ÅÂÅö‰∏Ä‰∫õÂ∞ùËØïÔºåÊâçËÉΩÊâæÂà∞ËÉΩÂ§üÊúÄÊúâÊïàÂú∞ÂáèÂ∞ëÊàêÊú¨ÂáΩÊï∞ÁöÑÈÇ£‰∏™Ôºå‰∏ÄËà¨‰ºöÂ∞ùËØïÂá†‰∏™‰∏çÂêåÁöÑÂÄºÔºåÂá†‰∏™‰∏çÂêåÁöÑ2Ê¨°ÊñπÔºåÁÑ∂ÂêéÁúãËÉΩÂê¶ÊâæÂà∞‰∏Ä‰∏™ËÆ©Ê¢ØÂ∫¶‰∏ãÈôç‰ºòÂåñÁÆóÊ≥ïÊúÄÈ´òÊïàÁöÑÂ§ßÂ∞è„ÄÇ Ê≠£ÂàôÂåñÂèÇÊï∞Ê≠£ÂàôËØùÂèØ‰ª•Èò≤Ê≠¢ËøáÊãüÂêàÔºåÈô§‰∫Ü‰πãÂâçÂú®ÈÄªËæëÂõûÂΩí‰∏≠‰ΩøÁî®ÁöÑÁöÑL2Ê≠£ÂàôÂåñÔºåËøòÂèØ‰ª•‰ΩøÁî®ÈöèÊú∫Â§±Ê¥ªÔºàdropoutÔºâÊ≠£ÂàôÂåñÔºåÂÆûÊñΩdropoutÔºåÂú®ËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÂæàÊàêÂäü„ÄÇËÆ°ÁÆóËßÜËßâ‰∏≠ÁöÑËæìÂÖ•ÈáèÈùûÂ∏∏Â§ßÔºåËæìÂÖ•Â§™Â§öÂÉèÁ¥†Ôºå‰ª•Ëá≥‰∫éÊ≤°ÊúâË∂≥Â§üÁöÑÊï∞ÊçÆÔºåÊâÄ‰ª•dropoutÂú®ËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠Â∫îÁî®ÂæóÊØîËæÉÈ¢ëÁπÅÔºåÊúâ‰∫õËÆ°ÁÆóÊú∫ËßÜËßâÁ†îÁ©∂‰∫∫ÂëòÈùûÂ∏∏ÂñúÊ¨¢Áî®ÂÆÉÔºåÂá†‰πéÊàê‰∫ÜÈªòËÆ§ÁöÑÈÄâÊã©Ôºå‰ΩÜË¶ÅÁâ¢ËÆ∞‰∏ÄÁÇπÔºådropoutÊòØ‰∏ÄÁßçÊ≠£ÂàôÂåñÊñπÊ≥ïÔºåÂÆÉÊúâÂä©‰∫éÈ¢ÑÈò≤ËøáÊãüÂêàÔºåÂõ†Ê≠§Èô§ÈùûÁÆóÊ≥ïËøáÊãüÂêàÔºå‰∏çÁÑ∂ÊàëÊòØ‰∏ç‰ºö‰ΩøÁî®dropoutÁöÑÔºåÊâÄ‰ª•ÂÆÉÂú®ÂÖ∂ÂÆÉÈ¢ÜÂüüÂ∫îÁî®ÂæóÊØîËæÉÂ∞ëÔºå‰∏ªË¶ÅÂ≠òÂú®‰∫éËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÔºåÂõ†‰∏∫Êàë‰ª¨ÈÄöÂ∏∏Ê≤°ÊúâË∂≥Â§üÁöÑÊï∞ÊçÆÔºåÊâÄ‰ª•‰∏ÄÁõ¥Â≠òÂú®ËøáÊãüÂêàÔºåËøôÂ∞±ÊòØÊúâ‰∫õËÆ°ÁÆóÊú∫ËßÜËßâÁ†îÁ©∂‰∫∫ÂëòÂ¶ÇÊ≠§ÈíüÊÉÖ‰∫édropoutÂáΩÊï∞ÁöÑÂéüÂõ†„ÄÇ dropout‰∏ÄÂ§ßÁº∫ÁÇπÂ∞±ÊòØ‰ª£‰ª∑ÂáΩÊï∞‰∏çÂÜçË¢´ÊòéÁ°ÆÂÆö‰πâÔºåÊØèÊ¨°Ëø≠‰ª£ÔºåÈÉΩ‰ºöÈöèÊú∫ÁßªÈô§‰∏Ä‰∫õËäÇÁÇπÔºåÂ¶ÇÊûúÂÜç‰∏âÊ£ÄÊü•Ê¢ØÂ∫¶‰∏ãÈôçÁöÑÊÄßËÉΩÔºåÂÆûÈôÖ‰∏äÊòØÂæàÈöæËøõË°åÂ§çÊü•ÁöÑ„ÄÇ Êâ©ÂÖÖÊàë‰ª¨ÁöÑÊï∞ÊçÆÂèØ‰ª•Èò≤Ê≠¢ËøáÊãüÂêàÔºå‰ΩÜÊâ©Â¢ûÊï∞ÊçÆ‰ª£‰ª∑ÂæàÈ´òÔºåËÄå‰∏îÊúâÊó∂ÂÄôÊàë‰ª¨Êó†Ê≥ïÊâ©Â¢ûÊï∞ÊçÆÔºå‰ΩÜÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÊ∑ªÂä†ËøôÁ±ªÂõæÁâáÊù•Â¢ûÂä†ËÆ≠ÁªÉÈõÜ„ÄÇ‰æãÂ¶ÇÔºåÊ∞¥Âπ≥ÁøªËΩ¨ÂõæÁâáÔºåÊâ≠Êõ≤ÂõæÁâáÔºåÈöèÊÑèË£ÅÂâ™ÂõæÁâáÔºåÂπ∂ÊääÂÆÉÊ∑ªÂä†Âà∞ËÆ≠ÁªÉÈõÜ„ÄÇÊâÄ‰ª•Áé∞Âú®ËÆ≠ÁªÉÈõÜ‰∏≠ÊúâÂéüÂõæÔºåËøòÊúâÂèòÊç¢ÂêéÁöÑËøôÂº†ÂõæÁâáÔºåËøôËôΩÁÑ∂‰∏çÂ¶ÇÊàë‰ª¨È¢ùÂ§ñÊî∂ÈõÜ‰∏ÄÁªÑÊñ∞ÂõæÁâáÈÇ£‰πàÂ•ΩÔºå‰ΩÜËøôÊ†∑ÂÅöËäÇÁúÅ‰∫ÜËé∑ÂèñÊõ¥Â§öÂõæÁâáÁöÑËä±Ë¥π„ÄÇ ËøòÊúâÂè¶Â§ñ‰∏ÄÁßçÂ∏∏Áî®ÁöÑÊñπÊ≥ïÂè´‰Ωúearly stoppingÔºåËøêË°åÊ¢ØÂ∫¶‰∏ãÈôçÊó∂ÔºåÊàë‰ª¨ÂèØ‰ª•ÁªòÂà∂ËÆ≠ÁªÉËØØÂ∑ÆÔºåÊàñÂè™ÁªòÂà∂‰ª£‰ª∑ÂáΩÊï∞ÁöÑ‰ºòÂåñËøáÁ®ãÔºåËøòÂèØ‰ª•ÁªòÂà∂È™åËØÅÈõÜËØØÂ∑ÆÔºåÂÆÉÂèØ‰ª•ÊòØÈ™åËØÅÈõÜ‰∏äÁöÑÂàÜÁ±ªËØØÂ∑ÆÔºåÊàñÈ™åËØÅÈõÜ‰∏äÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåÈÄªËæëÊçüÂ§±ÂíåÂØπÊï∞ÊçüÂ§±Á≠âÔºå‰Ω†‰ºöÂèëÁé∞ÔºåÈ™åËØÅÈõÜËØØÂ∑ÆÈÄöÂ∏∏‰ºöÂÖàÂëà‰∏ãÈôçË∂ãÂäøÔºåÁÑ∂ÂêéÂú®Êüê‰∏™ËäÇÁÇπÂ§ÑÂºÄÂßã‰∏äÂçáÔºåÊàë‰ª¨Âú®Ê≠§ÂÅúÊ≠¢ËÆ≠ÁªÉÂêßÔºåËøôÂπ∂‰∏çÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂª∫ËÆÆ„ÄÇ optimizer‰ºòÂåñÂô®ÁöÑÂÖ∑‰ΩìÈÄâÊã©Â∞±ÊØîËæÉÂ§çÊùÇ‰∫ÜÔºåÊúâËÆ∏Â§öÁöÑËÆ∫ÊñáÔºåÂÖ∑‰ΩìÂèØ‰ª•ÁúãÁúãËøôÁØáËÆ∫ÊñáÔºöAn overview of gradient descent optimization algorithms Áúã‰∏§Âº†Âä®ÂõæÁõ¥ËßÇ‰∏äÊÑüÂèó‰∏ãÁÆóÊ≥ïÁöÑ‰ºòÂåñËøáÁ®ã„ÄÇÁ¨¨‰∏ÄÂº†Âõæ‰∏∫‰∏çÂêåÁÆóÊ≥ïÂú®ÊçüÂ§±Âπ≥Èù¢Á≠âÈ´òÁ∫ø‰∏äÈöèÊó∂Èó¥ÁöÑÂèòÂåñÊÉÖÂÜµÔºåÁ¨¨‰∫åÂº†Âõæ‰∏∫‰∏çÂêåÁÆóÊ≥ïÂú®ÈûçÁÇπÂ§ÑÁöÑË°å‰∏∫ÊØîËæÉ„ÄÇ optimization on loss surface contours optimization on saddle point tensorflow Êèê‰æõ‰∫ÜÂ§ö‰∏™‰ºòÂåñÂô®ÁöÑapiÔºå‰ΩøÁî®Ëµ∑Êù•ÈùûÂ∏∏ÁÆÄÂçï„ÄÇ tf.train.Optimizer]]></content>
      <categories>
        <category>Ê∑±Â∫¶Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Ê∑±Â∫¶Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÊøÄÊ¥ªÂáΩÊï∞ÔºàActivation functionsÔºâ]]></title>
    <url>%2F2019%2F03%2F27%2F%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%88Activation%20functions%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Âú®‰ΩøÁî®Á•ûÁªèÁΩëÁªúÊó∂ÔºåÈúÄË¶ÅÂÜ≥ÂÆö‰ΩøÁî®Âì™ÁßçÊøÄÊ¥ªÂáΩÊï∞‰ΩúÁî®Âú®ÈöêËóèÂ±Ç‰∏äÔºåÂì™ÁßçÁî®Âú®ËæìÂá∫ËäÇÁÇπ‰∏ä„ÄÇÊôÆÈÄöÁöÑÊøÄÊ¥ªÂáΩÊï∞Êúâsigmoid, tanh, ReluÂíåReluÁöÑ‰ºòÂåñÁâàLeaky Relu„ÄÇ ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞‰∏∫‰ªÄ‰πàÁ•ûÁªèÁΩëÁªúÈúÄË¶ÅÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞Ôºü‰∫ãÂÆûËØÅÊòéÔºöË¶ÅËÆ©‰Ω†ÁöÑÁ•ûÁªèÁΩëÁªúËÉΩÂ§üËÆ°ÁÆóÂá∫ÊúâË∂£ÁöÑÂáΩÊï∞Ôºå‰Ω†ÂøÖÈ°ª‰ΩøÁî®ÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÔºåÂ¶ÇÊûúÊòØÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÊàñËÄÖÂè´ÊÅíÁ≠âÊøÄÂä±ÂáΩÊï∞ÔºåÈÇ£‰πàÁ•ûÁªèÁΩëÁªúÂè™ÊòØÊääËæìÂÖ•Á∫øÊÄßÁªÑÂêàÂÜçËæìÂá∫„ÄÇ ‰∫ãÂÆûËØÅÊòéÔºåÂ¶ÇÊûú‰Ω†‰ΩøÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÊàñËÄÖÊ≤°Êúâ‰ΩøÁî®‰∏Ä‰∏™ÊøÄÊ¥ªÂáΩÊï∞ÔºåÈÇ£‰πàÊó†ËÆ∫‰Ω†ÁöÑÁ•ûÁªèÁΩëÁªúÊúâÂ§öÂ∞ëÂ±Ç‰∏ÄÁõ¥Âú®ÂÅöÁöÑÂè™ÊòØËÆ°ÁÆóÁ∫øÊÄßÂáΩÊï∞ÔºåÊâÄ‰ª•‰∏çÂ¶ÇÁõ¥Êé•ÂéªÊéâÂÖ®ÈÉ®ÈöêËóèÂ±Ç„ÄÇ‰∫ãÂÆûËØÅÊòéÂ¶ÇÊûú‰Ω†Âú®ÈöêËóèÂ±ÇÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÔºåÂú®ËæìÂá∫Â±ÇÁî®sigmoidÂáΩÊï∞ÔºåÈÇ£‰πàËøô‰∏™Ê®°ÂûãÁöÑÂ§çÊùÇÂ∫¶ÂíåÊ≤°Êúâ‰ªª‰ΩïÈöêËóèÂ±ÇÁöÑÊ†áÂáÜLogisticÂõûÂΩíÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇ Âè™Êúâ‰∏Ä‰∏™Âú∞ÊñπÂèØ‰ª•‰ΩøÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÔºåÂ∞±ÊòØ‰Ω†Âú®ÂÅöÊú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÂõûÂΩíÈóÆÈ¢ò„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåÊØîÂ¶Ç‰Ω†ÊÉ≥È¢ÑÊµãÊàøÂú∞‰∫ß‰ª∑Ê†ºÔºåÁõÆÊ†áÁªìÊûúÂ∞±‰∏çÊòØ‰∫åÂàÜÁ±ª‰ªªÂä°0Êàñ1ÔºåËÄåÊòØ‰∏Ä‰∏™ÂÆûÊï∞Ôºå‰ªé0Âà∞Ê≠£Êó†Á©∑„ÄÇÂ¶ÇÊûúÁõÆÊ†áÊòØ‰∏™ÂÆûÊï∞ÔºåÈÇ£‰πàÂú®ËæìÂá∫Â±ÇÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞‰πüËÆ∏ÂèØË°åÔºå‰Ω†ÁöÑËæìÂá∫‰πüÊòØ‰∏Ä‰∏™ÂÆûÊï∞Ôºå‰ªéË¥üÊó†Á©∑Âà∞Ê≠£Êó†Á©∑„ÄÇ ÊÄªËÄåË®Ä‰πãÔºå‰∏çËÉΩÂú®ÈöêËóèÂ±ÇÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÔºåÂèØ‰ª•Áî®ReLUÊàñËÄÖtanhÊàñËÄÖleaky ReLUÊàñËÄÖÂÖ∂‰ªñÁöÑÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÔºåÂîØ‰∏ÄÂèØ‰ª•Áî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÁöÑÈÄöÂ∏∏Â∞±ÊòØËæìÂá∫Â±ÇÔºõÈô§‰∫ÜËøôÁßçÊÉÖÂÜµÔºå‰ºöÂú®ÈöêÂ±ÇÁî®Á∫øÊÄßÂáΩÊï∞ÁöÑÔºåÈô§‰∫Ü‰∏Ä‰∫õÁâπÊÆäÊÉÖÂÜµÔºåÊØîÂ¶Ç‰∏éÂéãÁº©ÊúâÂÖ≥ÁöÑÔºåÈÇ£ÊñπÈù¢Âú®ËøôÈáåÂ∞Ü‰∏çÊ∑±ÂÖ•ËÆ®ËÆ∫„ÄÇÂú®Ëøô‰πãÂ§ñÔºåÂú®ÈöêÂ±Ç‰ΩøÁî®Á∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞ÈùûÂ∏∏Â∞ëËßÅ„ÄÇÂõ†‰∏∫Êàø‰ª∑ÈÉΩÊòØÈùûË¥üÊï∞ÔºåÊâÄ‰ª•Êàë‰ª¨‰πüÂèØ‰ª•Âú®ËæìÂá∫Â±Ç‰ΩøÁî®ReLUÂáΩÊï∞ËøôÊ†∑‰Ω†ÁöÑËæìÂá∫ÁªìÊûúÈÉΩÂ§ß‰∫éÁ≠â‰∫é0„ÄÇ sigmoid $a=\frac{1}{1+e^x}$ sigmoidÊøÄÊ¥ªÂáΩÊï∞ÊòØ‰πãÂâçÂú®Â≠¶‰π†ÈÄªËæëÂõûÂΩíÁöÑÊó∂ÂÄô‰ΩøÁî®ÁöÑÊøÄÊ¥ªÂáΩÊï∞Ôºå‰ΩÜÂÆÉÊòØ‰∏Ä‰∏™Âü∫Êú¨‰∏ç‰ΩøÁî®ÁöÑÊøÄÊ¥ªÂáΩÊï∞ÔºåtanhÂáΩÊï∞ÔºàËÄÖÂèåÊõ≤Ê≠£ÂàáÂáΩÊï∞ÔºâÊòØÊÄª‰Ωì‰∏äÈÉΩ‰ºò‰∫ésigmoidÂáΩÊï∞ÁöÑÊøÄÊ¥ªÂáΩÊï∞„ÄÇÊàë‰ª¨Âè™ÊúâÂú®‰∫åÂàÜÁ±ª‰ªªÂä°‰∏≠‰ºö‰ΩøÁî®ÔºåÂõ†‰∏∫Âú®‰∫åÂàÜÁ±ªÁöÑÈóÆÈ¢ò‰∏≠ÔºåÂØπ‰∫éËæìÂá∫Â±ÇÔºåÁõÆÊ†áÁöÑÂÄºÊòØ0Êàñ1ÔºåÊâÄ‰ª•ÊÉ≥ËÆ©È¢ÑÊµãÁöÑÊï∞ÂÄº‰ªã‰∫é0Âíå1‰πãÈó¥ÔºåËÄå‰∏çÊòØÂú®-1Âíå+1‰πãÈó¥„ÄÇÊâÄ‰ª•ÈúÄË¶Å‰ΩøÁî®sigmoidÊøÄÊ¥ªÂáΩÊï∞„ÄÇ ÂØºÊï∞ÂÖ∂ÂÖ∑‰ΩìÁöÑÊ±ÇÂØºÂ¶Ç‰∏ãÔºö $\frac{d}{dz}g(z) = {\frac{1}{1 + e^{-z}} (1-\frac{1}{1 + e^{-z}})}=g(z)(1-g(z))$ Ê≥®Ôºö ÂΩì$z=10$Êàñ$z=-10$ $\frac{d}{dz}g(z)\approx0$ ÂΩì$z=0$,$\frac{d}{dz}g(z)\text{=g(z)(1-g(z))=}{1}/{4}$ Âú®Á•ûÁªèÁΩëÁªú‰∏≠$a= g(z)$;$g{{(z)}^{'}}=\frac{d}{dz}g(z)=a(1-a)$ tanh $a=\frac{e^x-e^{-x}}{e^x+e^{-x}}$ ‰∫ãÂÆû‰∏äÔºåtanhÂáΩÊï∞ÊòØsigmoidÁöÑÂêë‰∏ãÂπ≥ÁßªÂíå‰º∏Áº©ÂêéÁöÑÁªìÊûú„ÄÇÂØπÂÆÉËøõË°å‰∫ÜÂèòÂΩ¢ÂêéÔºåÁ©øËøá‰∫ÜÁÇπ(0, 0)ÔºåÂπ∂‰∏îÂÄºÂüü‰ªã‰∫é+1Âíå-1‰πãÈó¥„ÄÇ ÁªìÊûúË°®ÊòéÔºåÂ¶ÇÊûúÂú®ÈöêËóèÂ±Ç‰∏ä‰ΩøÁî®tanhÂáΩÊï∞ÊïàÊûúÊÄªÊòØ‰ºò‰∫ésigmoidÂáΩÊï∞„ÄÇÂõ†‰∏∫ÂáΩÊï∞ÂÄºÂüüÂú®-1Âíå+1ÁöÑÊøÄÊ¥ªÂáΩÊï∞ÔºåÂÖ∂ÂùáÂÄºÊòØÊõ¥Êé•ËøëÈõ∂ÂùáÂÄºÁöÑ„ÄÇÂú®ËÆ≠ÁªÉ‰∏Ä‰∏™ÁÆóÊ≥ïÊ®°ÂûãÊó∂ÔºåÂ¶ÇÊûú‰ΩøÁî®tanhÂáΩÊï∞‰ª£ÊõøsigmoidÂáΩÊï∞‰∏≠ÂøÉÂåñÊï∞ÊçÆÔºå‰ΩøÂæóÊï∞ÊçÆÁöÑÂπ≥ÂùáÂÄºÊõ¥Êé•Ëøë0ËÄå‰∏çÊòØ0.5. sigmoidÂáΩÊï∞ÂíåtanhÂáΩÊï∞‰∏§ËÄÖÂÖ±ÂêåÁöÑÁº∫ÁÇπÊòØÔºåÂú®zÁâπÂà´Â§ßÊàñËÄÖÁâπÂà´Â∞èÁöÑÊÉÖÂÜµ‰∏ãÔºåÂØºÊï∞ÁöÑÊ¢ØÂ∫¶ÊàñËÄÖÂáΩÊï∞ÁöÑÊñúÁéá‰ºöÂèòÂæóÁâπÂà´Â∞èÔºåÊúÄÂêéÂ∞±‰ºöÊé•Ëøë‰∫é0ÔºåÂØºËá¥Èôç‰ΩéÊ¢ØÂ∫¶‰∏ãÈôçÁöÑÈÄüÂ∫¶„ÄÇ ÂØºÊï∞ÂÖ∂ÂÖ∑‰ΩìÁöÑÊ±ÇÂØºÂ¶Ç‰∏ãÔºö $g(z)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$ $\frac{d}{{d}z}g(z) = 1 - (tanh(z))^{2}$ Ê≥®Ôºö ÂΩì$z=10$Êàñ$z=-10$ $\frac{d}{dz}g(z)\approx0$ ÂΩì$z=0$,$\frac{d}{dz}g(z)\text{=1-(0)=}1$ Relu $a=\max\left(0,\ x\right)$ Âú®Êú∫Âô®Â≠¶‰π†Âè¶‰∏Ä‰∏™ÂæàÊµÅË°åÁöÑÂáΩÊï∞ÊòØÔºö‰øÆÊ≠£Á∫øÊÄßÂçïÂÖÉÁöÑÂáΩÊï∞ÔºàReLuÔºâ„ÄÇÂè™Ë¶ÅÊòØÊ≠£ÂÄºÁöÑÊÉÖÂÜµ‰∏ãÔºåÂØºÊï∞ÊÅíÁ≠â‰∫é1ÔºåÂΩìÊòØË¥üÂÄºÁöÑÊó∂ÂÄôÔºåÂØºÊï∞ÊÅíÁ≠â‰∫é0„ÄÇ‰ªéÂÆûÈôÖ‰∏äÊù•ËØ¥ÔºåÂΩì‰ΩøÁî®ÁöÑÂØºÊï∞Êó∂Ôºåz=0ÁöÑÂØºÊï∞ÊòØÊ≤°ÊúâÂÆö‰πâÁöÑ„ÄÇ‰ΩÜÊòØÂΩìÁºñÁ®ãÂÆûÁé∞ÁöÑÊó∂ÂÄôÔºåzÁöÑÂèñÂÄºÂàöÂ•ΩÁ≠â‰∫é0.00000001ÔºåËøô‰∏™ÂÄºÁõ∏ÂΩìÂ∞èÔºåÊâÄ‰ª•ÔºåÂú®ÂÆûË∑µ‰∏≠Ôºå‰∏çÈúÄË¶ÅÊãÖÂøÉËøô‰∏™ÂÄºÔºåÊòØÁ≠â‰∫é0ÁöÑÊó∂ÂÄôÔºåÂÅáËÆæ‰∏Ä‰∏™ÂØºÊï∞ÊòØ1ÊàñËÄÖ0ÊïàÊûúÈÉΩÂèØ‰ª•„ÄÇ ËøôÊúâ‰∏Ä‰∫õÈÄâÊã©ÊøÄÊ¥ªÂáΩÊï∞ÁöÑÁªèÈ™åÊ≥ïÂàôÔºö Â¶ÇÊûúËæìÂá∫ÊòØ0„ÄÅ1ÂÄºÔºà‰∫åÂàÜÁ±ªÈóÆÈ¢òÔºâÔºåÂàôËæìÂá∫Â±ÇÈÄâÊã©sigmoidÂáΩÊï∞ÔºåÁÑ∂ÂêéÂÖ∂ÂÆÉÁöÑÊâÄÊúâÂçïÂÖÉÈÉΩÈÄâÊã©ReluÂáΩÊï∞„ÄÇ ËøôÊòØÂæàÂ§öÊøÄÊ¥ªÂáΩÊï∞ÁöÑÈªòËÆ§ÈÄâÊã©ÔºåÂ¶ÇÊûúÂú®ÈöêËóèÂ±Ç‰∏ä‰∏çÁ°ÆÂÆö‰ΩøÁî®Âì™‰∏™ÊøÄÊ¥ªÂáΩÊï∞ÔºåÈÇ£‰πàÈÄöÂ∏∏‰ºö‰ΩøÁî®ReluÊøÄÊ¥ªÂáΩÊï∞„ÄÇÊúâÊó∂Ôºå‰πü‰ºö‰ΩøÁî®tanhÊøÄÊ¥ªÂáΩÊï∞Ôºå‰ΩÜReluÁöÑ‰∏Ä‰∏™‰ºòÁÇπÊòØÔºöÂΩìzÊòØË¥üÂÄºÁöÑÊó∂ÂÄôÔºåÂØºÊï∞Á≠â‰∫é0„ÄÇ ÂØºÊï∞ $g(z)^{'}= \begin{cases} 0& \text{if z < 0}\\ 1& \text{if z > 0}\\ undefined& \text{if z = 0} \end{cases}$ Ê≥®ÔºöÈÄöÂ∏∏Âú®z=0ÁöÑÊó∂ÂÄôÁªôÂÆöÂÖ∂ÂØºÊï∞1,0ÔºõÂΩìÁÑ∂z=0ÁöÑÊÉÖÂÜµÂæàÂ∞ë Leaky Relu $a=\max\left(0.01x,\ x\right)$ ËøôÈáå‰πüÊúâÂè¶‰∏Ä‰∏™ÁâàÊú¨ÁöÑReluË¢´Áß∞‰∏∫Leaky Relu„ÄÇÂΩìÊòØË¥üÂÄºÊó∂ÔºåËøô‰∏™ÂáΩÊï∞ÁöÑÂÄº‰∏çÊòØÁ≠â‰∫é0ÔºåËÄåÊòØËΩªÂæÆÁöÑÂÄæÊñúÔºåËøô‰∏™ÂáΩÊï∞ÈÄöÂ∏∏ÊØîReluÊøÄÊ¥ªÂáΩÊï∞ÊïàÊûúË¶ÅÂ•ΩÔºåÂ∞ΩÁÆ°Âú®ÂÆûÈôÖ‰∏≠Leaky ReLu‰ΩøÁî®ÁöÑÂπ∂‰∏çÂ§ö„ÄÇ ‰∏§ËÄÖÁöÑ‰ºòÁÇπÊòØÔºö Á¨¨‰∏ÄÔºåÂú®ÁöÑÂå∫Èó¥ÂèòÂä®ÂæàÂ§ßÁöÑÊÉÖÂÜµ‰∏ãÔºåÊøÄÊ¥ªÂáΩÊï∞ÁöÑÂØºÊï∞ÊàñËÄÖÊøÄÊ¥ªÂáΩÊï∞ÁöÑÊñúÁéáÈÉΩ‰ºöËøúÂ§ß‰∫é0ÔºåÂú®Á®ãÂ∫èÂÆûÁé∞Â∞±ÊòØ‰∏Ä‰∏™if-elseËØ≠Âè•ÔºåËÄåsigmoidÂáΩÊï∞ÈúÄË¶ÅËøõË°åÊµÆÁÇπÂõõÂàôËøêÁÆóÔºåÂú®ÂÆûË∑µ‰∏≠Ôºå‰ΩøÁî®ReLuÊøÄÊ¥ªÂáΩÊï∞Á•ûÁªèÁΩëÁªúÈÄöÂ∏∏‰ºöÊØî‰ΩøÁî®sigmoidÊàñËÄÖtanhÊøÄÊ¥ªÂáΩÊï∞Â≠¶‰π†ÁöÑÊõ¥Âø´„ÄÇ Á¨¨‰∫åÔºåsigmoidÂíåtanhÂáΩÊï∞ÁöÑÂØºÊï∞Âú®Ê≠£Ë¥üÈ•±ÂíåÂå∫ÁöÑÊ¢ØÂ∫¶ÈÉΩ‰ºöÊé•Ëøë‰∫é0ÔºåËøô‰ºöÈÄ†ÊàêÊ¢ØÂ∫¶Âº•Êï£ÔºåËÄåReluÂíåLeaky ReLuÂáΩÊï∞Â§ß‰∫é0ÈÉ®ÂàÜÈÉΩ‰∏∫Â∏∏Êï∞Ôºå‰∏ç‰ºö‰∫ßÁîüÊ¢ØÂ∫¶Âº•Êï£Áé∞Ë±°„ÄÇ(ÂêåÊó∂Â∫îËØ•Ê≥®ÊÑèÂà∞ÁöÑÊòØÔºåReluËøõÂÖ•Ë¥üÂçäÂå∫ÁöÑÊó∂ÂÄôÔºåÊ¢ØÂ∫¶‰∏∫0ÔºåÁ•ûÁªèÂÖÉÊ≠§Êó∂‰∏ç‰ºöËÆ≠ÁªÉÔºå‰∫ßÁîüÊâÄË∞ìÁöÑÁ®ÄÁñèÊÄßÔºåËÄåLeaky ReLu‰∏ç‰ºöÊúâËøôÈóÆÈ¢ò) Âú®ReLuÁöÑÊ¢ØÂ∫¶‰∏ÄÂçäÈÉΩÊòØ0Ôºå‰ΩÜÊòØÔºåÊúâË∂≥Â§üÁöÑÈöêËóèÂ±Ç‰ΩøÂæózÂÄºÂ§ß‰∫é0ÔºåÊâÄ‰ª•ÂØπÂ§ßÂ§öÊï∞ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÊù•ËØ¥Â≠¶‰π†ËøáÁ®ã‰ªçÁÑ∂ÂèØ‰ª•ÂæàÂø´„ÄÇ ÂØºÊï∞ $g(z)=\max(0.01z,z)$ $g(z)^{'}= \begin{cases} 0.01& \text{if z < 0}\\ 1& \text{if z > 0}\\ undefined& \text{if z = 0} \end{cases}$ Ê≥®ÔºöÈÄöÂ∏∏Âú®z=0ÁöÑÊó∂ÂÄôÁªôÂÆöÂÖ∂ÂØºÊï∞1,0.01ÔºõÂΩìÁÑ∂z=0ÁöÑÊÉÖÂÜµÂæàÂ∞ë„ÄÇ ÊÄªÁªìÊ¶ÇÊã¨‰∏Ä‰∏ã‰∏çÂêåÊøÄÊ¥ªÂáΩÊï∞ÁöÑËøáÁ®ãÂíåÁªìËÆ∫„ÄÇ sigmoidÊøÄÊ¥ªÂáΩÊï∞ÔºöÈô§‰∫ÜËæìÂá∫Â±ÇÊòØ‰∏Ä‰∏™‰∫åÂàÜÁ±ªÈóÆÈ¢òÂü∫Êú¨‰∏ç‰ºöÁî®ÂÆÉ„ÄÇ tanhÊøÄÊ¥ªÂáΩÊï∞ÔºötanhÊòØÈùûÂ∏∏‰ºòÁßÄÁöÑÔºåÂá†‰πéÈÄÇÂêàÊâÄÊúâÂú∫Âêà„ÄÇ ReLuÊøÄÊ¥ªÂáΩÊï∞ÔºöÊúÄÂ∏∏Áî®ÁöÑÈªòËÆ§ÂáΩÊï∞ÔºåÂ¶ÇÊûú‰∏çÁ°ÆÂÆöÁî®Âì™‰∏™ÊøÄÊ¥ªÂáΩÊï∞ÔºåÂ∞±‰ΩøÁî®ReLuÊàñËÄÖLeaky ReLu„ÄÇ$g(z)=\max(0.01z,z)$‰∏∫‰ªÄ‰πàÂ∏∏Êï∞ÊòØ0.01ÔºüÂΩìÁÑ∂ÔºåÂèØ‰ª•‰∏∫Â≠¶‰π†ÁÆóÊ≥ïÈÄâÊã©‰∏çÂêåÁöÑÂèÇÊï∞„ÄÇ Âú®ÈÄâÊã©Ëá™Â∑±Á•ûÁªèÁΩëÁªúÁöÑÊøÄÊ¥ªÂáΩÊï∞Êó∂ÔºåÊúâ‰∏ÄÂÆöÁöÑÁõ¥ËßÇÊÑüÂèóÔºåÂú®Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑÁªèÂ∏∏ÈÅáÂà∞‰∏Ä‰∏™ÈóÆÈ¢òÔºöÂú®ÁºñÂÜôÁ•ûÁªèÁΩëÁªúÁöÑÊó∂ÂÄôÔºå‰ºöÊúâÂæàÂ§öÈÄâÊã©ÔºöÈöêËóèÂ±ÇÂçïÂÖÉÁöÑ‰∏™Êï∞„ÄÅÊøÄÊ¥ªÂáΩÊï∞ÁöÑÈÄâÊã©„ÄÅÂàùÂßãÂåñÊùÉÂÄº‚Ä¶‚Ä¶Ëøô‰∫õÈÄâÊã©ÊÉ≥ÂæóÂà∞‰∏Ä‰∏™ÂØπÊØîËæÉÂ•ΩÁöÑÊåáÂØºÂéüÂàôÊòØÊå∫Âõ∞ÈöæÁöÑ„ÄÇ Èâ¥‰∫é‰ª•‰∏ä‰∏â‰∏™ÂéüÂõ†Ôºå‰ª•ÂèäÂú®Â∑•‰∏öÁïåÁöÑËßÅÈóªÔºåÊèê‰æõ‰∏ÄÁßçÁõ¥ËßÇÁöÑÊÑüÂèóÔºåÂì™‰∏ÄÁßçÂ∑•‰∏öÁïåÁî®ÁöÑÂ§öÔºåÂì™‰∏ÄÁßçÁî®ÁöÑÂ∞ë„ÄÇ‰ΩÜÊòØÔºåËá™Â∑±ÁöÑÁ•ûÁªèÁΩëÁªúÁöÑÂ∫îÁî®Ôºå‰ª•ÂèäÂÖ∂ÁâπÊÆäÊÄßÔºåÊòØÂæàÈöæÊèêÂâçÁü•ÈÅìÈÄâÊã©Âì™‰∫õÊïàÊûúÊõ¥Â•Ω„ÄÇÊâÄ‰ª•ÈÄöÂ∏∏ÁöÑÂª∫ËÆÆÊòØÔºöÂ¶ÇÊûú‰∏çÁ°ÆÂÆöÂì™‰∏Ä‰∏™ÊøÄÊ¥ªÂáΩÊï∞ÊïàÊûúÊõ¥Â•ΩÔºåÂèØ‰ª•ÊääÂÆÉ‰ª¨ÈÉΩËØïËØïÔºåÁÑ∂ÂêéÂú®È™åËØÅÈõÜÊàñËÄÖÂèëÂ±ïÈõÜ‰∏äËøõË°åËØÑ‰ª∑„ÄÇÁÑ∂ÂêéÁúãÂì™‰∏ÄÁßçË°®Áé∞ÁöÑÊõ¥Â•ΩÔºåÂ∞±Âéª‰ΩøÁî®ÂÆÉ„ÄÇ ‰∏∫Ëá™Â∑±ÁöÑÁ•ûÁªèÁΩëÁªúÁöÑÂ∫îÁî®ÊµãËØïËøô‰∫õ‰∏çÂêåÁöÑÈÄâÊã©Ôºå‰ºöÂú®‰ª•ÂêéÊ£ÄÈ™åËá™Â∑±ÁöÑÁ•ûÁªèÁΩëÁªúÊàñËÄÖËØÑ‰º∞ÁÆóÊ≥ïÁöÑÊó∂ÂÄôÔºåÁúãÂà∞‰∏çÂêåÁöÑÊïàÊûú„ÄÇÂ¶ÇÊûú‰ªÖ‰ªÖÈÅµÂÆà‰ΩøÁî®ÈªòËÆ§ÁöÑReLuÊøÄÊ¥ªÂáΩÊï∞ÔºåËÄå‰∏çË¶ÅÁî®ÂÖ∂‰ªñÁöÑÊøÄÂä±ÂáΩÊï∞ÔºåÈÇ£Â∞±ÂèØËÉΩÂú®ËøëÊúüÊàñËÄÖÂæÄÂêéÔºåÊØèÊ¨°Ëß£ÂÜ≥ÈóÆÈ¢òÁöÑÊó∂ÂÄôÈÉΩ‰ΩøÁî®Áõ∏ÂêåÁöÑÂäûÊ≥ï„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>ÊøÄÊ¥ªÂáΩÊï∞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 10]]></title>
    <url>%2F2019%2F02%2F25%2FTensorFlow_10%2F</url>
    <content type="text"><![CDATA[Á®ÄÁñèÊï∞ÊçÆÂíåÂµåÂÖ•ÁÆÄ‰ªã Â∞ÜÂΩ±ËØÑÂ≠óÁ¨¶‰∏≤Êï∞ÊçÆËΩ¨Êç¢‰∏∫Á®ÄÁñèÁâπÂæÅÁü¢Èáè ‰ΩøÁî®Á®ÄÁñèÁâπÂæÅÁü¢ÈáèÂÆûÁé∞ÊÉÖÊÑüÂàÜÊûêÁ∫øÊÄßÊ®°Âûã ÈÄöËøáÂ∞ÜÊï∞ÊçÆÊäïÂ∞ÑÂà∞‰∫åÁª¥Á©∫Èó¥ÁöÑÂµåÂÖ•Êù•ÂÆûÁé∞ÊÉÖÊÑüÂàÜÊûê DNN Ê®°Âûã Â∞ÜÂµåÂÖ•ÂèØËßÜÂåñÔºå‰ª•‰æøÊü•ÁúãÊ®°ÂûãÂ≠¶Âà∞ÁöÑËØçËØ≠‰πãÈó¥ÁöÑÂÖ≥Á≥ª Âú®Ê≠§ÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®Á®ÄÁñèÊï∞ÊçÆÔºåÂπ∂‰ΩøÁî®ÂΩ±ËØÑÊñáÊú¨Êï∞ÊçÆÔºàÊù•Ëá™ ACL 2011 IMDB Êï∞ÊçÆÈõÜÔºâËøõË°åÂµåÂÖ•„ÄÇËøô‰∫õÊï∞ÊçÆÂ∑≤Ë¢´Â§ÑÁêÜÊàê tf.Example Ê†ºÂºè„ÄÇ ËÆæÁΩÆÊàë‰ª¨ÂØºÂÖ•‰æùËµñÈ°πÂπ∂‰∏ãËΩΩËÆ≠ÁªÉÊï∞ÊçÆÂíåÊµãËØïÊï∞ÊçÆ„ÄÇtf.keras ‰∏≠ÂåÖÂê´‰∏Ä‰∏™Êñá‰ª∂‰∏ãËΩΩÂíåÁºìÂ≠òÂ∑•ÂÖ∑ÔºåÊàë‰ª¨ÂèØ‰ª•Áî®ÂÆÉÊù•Ê£ÄÁ¥¢Êï∞ÊçÆÈõÜ„ÄÇ 123456789101112131415161718from __future__ import print_functionimport collectionsimport ioimport mathimport matplotlib.pyplot as pltimport numpy as npimport pandas as pdimport tensorflow as tffrom IPython import displayfrom sklearn import metricstf.logging.set_verbosity(tf.logging.ERROR)train_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/train.tfrecord'train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)test_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/test.tfrecord'test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url) Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/train.tfrecord 41631744/41625533 [==============================] - 0s 0us/step Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/test.tfrecord 40689664/40688441 [==============================] - 0s 0us/step ÊûÑÂª∫ÊÉÖÊÑüÂàÜÊûêÊ®°Âûã Êàë‰ª¨Ê†πÊçÆËøô‰∫õÊï∞ÊçÆËÆ≠ÁªÉ‰∏Ä‰∏™ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÔºå‰ª•È¢ÑÊµãÊüêÊù°ËØÑ‰ª∑ÊÄª‰Ωì‰∏äÊòØÂ•ΩËØÑÔºàÊ†áÁ≠æ‰∏∫ 1ÔºâËøòÊòØÂ∑ÆËØÑÔºàÊ†áÁ≠æ‰∏∫ 0Ôºâ„ÄÇ ‰∏∫Ê≠§ÔºåÊàë‰ª¨‰ºö‰ΩøÁî®ËØçÊ±áË°®ÔºàÂç≥Êàë‰ª¨È¢ÑËÆ°Â∞ÜÂú®Êï∞ÊçÆ‰∏≠ÁúãÂà∞ÁöÑÊØè‰∏™ÊúØËØ≠ÁöÑÂàóË°®ÔºâÔºåÂ∞ÜÂ≠óÁ¨¶‰∏≤ÂÄº terms ËΩ¨Êç¢‰∏∫ÁâπÂæÅÁü¢Èáè„ÄÇÂú®Êú¨ÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰æßÈáç‰∫é‰∏ÄÁªÑÊúâÈôêÊúØËØ≠ÁöÑÂ∞èÂûãËØçÊ±áË°®„ÄÇÂÖ∂‰∏≠ÁöÑÂ§ßÂ§öÊï∞ÊúØËØ≠ÊòéÁ°ÆË°®Á§∫ÊòØÂ•ΩËØÑÊàñÂ∑ÆËØÑÔºå‰ΩÜÊúâ‰∫õÂè™ÊòØÂõ†‰∏∫ÊúâË∂£ËÄåË¢´Ê∑ªÂä†ËøõÊù•„ÄÇ ËØçÊ±áË°®‰∏≠ÁöÑÊØè‰∏™ÊúØËØ≠ÈÉΩ‰∏éÁâπÂæÅÁü¢Èáè‰∏≠ÁöÑ‰∏Ä‰∏™ÂùêÊ†áÁõ∏ÂØπÂ∫î„ÄÇ‰∏∫‰∫ÜÂ∞ÜÊ†∑Êú¨ÁöÑÂ≠óÁ¨¶‰∏≤ÂÄº terms ËΩ¨Êç¢‰∏∫ËøôÁßçÁü¢ÈáèÊ†ºÂºèÔºåÊàë‰ª¨Êåâ‰ª•‰∏ãÊñπÂºèÂ§ÑÁêÜÂ≠óÁ¨¶‰∏≤ÂÄºÔºöÂ¶ÇÊûúËØ•ÊúØËØ≠Ê≤°ÊúâÂá∫Áé∞Âú®Ê†∑Êú¨Â≠óÁ¨¶‰∏≤‰∏≠ÔºåÂàôÂùêÊ†áÂÄºÂ∞Ü‰∏∫ 0ÔºõÂ¶ÇÊûúÂá∫Áé∞Âú®Ê†∑Êú¨Â≠óÁ¨¶‰∏≤‰∏≠ÔºåÂàôÂÄº‰∏∫ 1„ÄÇÊú™Âá∫Áé∞Âú®ËØ•ËØçÊ±áË°®‰∏≠ÁöÑÊ†∑Êú¨‰∏≠ÁöÑÊúØËØ≠Â∞ÜË¢´ÂºÉÁî®„ÄÇ Ê≥®ÊÑèÔºöÊàë‰ª¨ÂΩìÁÑ∂ÂèØ‰ª•‰ΩøÁî®Êõ¥Â§ßÁöÑËØçÊ±áË°®ÔºåËÄå‰∏îÊúâÂàõÂª∫Ê≠§Á±ªËØçÊ±áË°®ÁöÑ‰∏ìÁî®Â∑•ÂÖ∑„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂèØ‰ª•Ê∑ªÂä†Â∞ëÈáèÁöÑ OOVÔºàÊú™Êî∂ÂΩïËØçÊ±áÔºâÂàÜÊ°∂ÔºåÊÇ®ÂèØ‰ª•Âú®ÂÖ∂‰∏≠ÂØπËØçÊ±áË°®‰∏≠Êú™ÂåÖÂê´ÁöÑÊúØËØ≠ËøõË°åÂìàÂ∏åÂ§ÑÁêÜÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂºÉÁî®Ëøô‰∫õÊúØËØ≠„ÄÇÊàë‰ª¨ËøòÂèØ‰ª•‰ΩøÁî®ÁâπÂæÅÂìàÂ∏åÊ≥ïÂØπÊØè‰∏™ÊúØËØ≠ËøõË°åÂìàÂ∏åÂ§ÑÁêÜÔºåËÄå‰∏çÊòØÂàõÂª∫ÊòæÂºèËØçÊ±áË°®„ÄÇËøôÂú®ÂÆûË∑µ‰∏≠ÂæàÊúâÊïàÔºå‰ΩÜÂç¥‰∏çÂÖ∑Â§áÂèØËß£ËØªÊÄßÔºàËøôÂØπÊú¨ÁªÉ‰π†ÈùûÂ∏∏ÂÆûÁî®Ôºâ„ÄÇÂ¶ÇÈúÄ‰∫ÜËß£Â§ÑÁêÜÊ≠§Á±ªËØçÊ±áË°®ÁöÑÂ∑•ÂÖ∑ÔºåËØ∑ÂèÇÈòÖ tf.feature_column Ê®°Âùó„ÄÇ ÊûÑÂª∫ËæìÂÖ•ÁÆ°ÈÅì È¶ñÂÖàÔºåÊàë‰ª¨Êù•ÈÖçÁΩÆËæìÂÖ•ÁÆ°ÈÅìÔºå‰ª•Â∞ÜÊï∞ÊçÆÂØºÂÖ• TensorFlow Ê®°Âûã‰∏≠„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÂáΩÊï∞Êù•Ëß£ÊûêËÆ≠ÁªÉÊï∞ÊçÆÂíåÊµãËØïÊï∞ÊçÆÔºàÊ†ºÂºè‰∏∫ TFRecordÔºâÔºåÁÑ∂ÂêéËøîÂõû‰∏Ä‰∏™Áî±ÁâπÂæÅÂíåÁõ∏Â∫îÊ†áÁ≠æÁªÑÊàêÁöÑÂ≠óÂÖ∏„ÄÇ 123456789101112131415161718192021def _parse_function(record): """Extracts features and labels. Args: record: File path to a TFRecord file Returns: A `tuple` `(labels, features)`: features: A dict of tensors representing the features labels: A tensor with the corresponding labels. """ features = &#123; "terms": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths "labels": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1 &#125; parsed_features = tf.parse_single_example(record, features) terms = parsed_features['terms'].values labels = parsed_features['labels'] return &#123;'terms':terms&#125;, labels ‰∏∫‰∫ÜÁ°ÆËÆ§ÂáΩÊï∞ÊòØÂê¶ËÉΩÊ≠£Â∏∏ËøêË°åÔºåÊàë‰ª¨‰∏∫ËÆ≠ÁªÉÊï∞ÊçÆÊûÑÂª∫‰∏Ä‰∏™ TFRecordDatasetÔºåÂπ∂‰ΩøÁî®‰∏äËø∞ÂáΩÊï∞Â∞ÜÊï∞ÊçÆÊò†Â∞ÑÂà∞ÁâπÂæÅÂíåÊ†áÁ≠æ„ÄÇ 123456# Create the Dataset object.ds = tf.data.TFRecordDataset(train_path)# Map features and labels with the parse function.ds = ds.map(_parse_function)ds &lt;DatasetV1Adapter shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)&gt; ËøêË°å‰ª•‰∏ãÂçïÂÖÉÔºå‰ª•‰ªéËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏≠Ëé∑ÂèñÁ¨¨‰∏Ä‰∏™Ê†∑Êú¨„ÄÇ 123n = ds.make_one_shot_iterator().get_next()sess = tf.Session()sess.run(n) ({&apos;terms&apos;: array([b&apos;but&apos;, b&apos;it&apos;, b&apos;does&apos;, b&apos;have&apos;, b&apos;some&apos;, b&apos;good&apos;, b&apos;action&apos;, b&apos;and&apos;, b&apos;a&apos;, b&apos;plot&apos;, b&apos;that&apos;, b&apos;is&apos;, b&apos;somewhat&apos;, b&apos;interesting&apos;, b&apos;.&apos;, b&apos;nevsky&apos;, b&apos;acts&apos;, b&apos;like&apos;, b&apos;a&apos;, b&apos;body&apos;, b&apos;builder&apos;, b&apos;and&apos;, b&apos;he&apos;, b&apos;isn&apos;, b&quot;&apos;&quot;, b&apos;t&apos;, b&apos;all&apos;, b&apos;that&apos;, b&apos;attractive&apos;, b&apos;,&apos;, b&apos;in&apos;, b&apos;fact&apos;, b&apos;,&apos;, b&apos;imo&apos;, b&apos;,&apos;, b&apos;he&apos;, b&apos;is&apos;, b&apos;ugly&apos;, b&apos;.&apos;, b&apos;(&apos;, b&apos;his&apos;, b&apos;acting&apos;, b&apos;skills&apos;, b&apos;lack&apos;, b&apos;everything&apos;, b&apos;!&apos;, b&apos;)&apos;, b&apos;sascha&apos;, b&apos;is&apos;, b&apos;played&apos;, b&apos;very&apos;, b&apos;well&apos;, b&apos;by&apos;, b&apos;joanna&apos;, b&apos;pacula&apos;, b&apos;,&apos;, b&apos;but&apos;, b&apos;she&apos;, b&apos;needed&apos;, b&apos;more&apos;, b&apos;lines&apos;, b&apos;than&apos;, b&apos;she&apos;, b&apos;was&apos;, b&apos;given&apos;, b&apos;,&apos;, b&apos;her&apos;, b&apos;character&apos;, b&apos;needed&apos;, b&apos;to&apos;, b&apos;be&apos;, b&apos;developed&apos;, b&apos;.&apos;, b&apos;there&apos;, b&apos;are&apos;, b&apos;way&apos;, b&apos;too&apos;, b&apos;many&apos;, b&apos;men&apos;, b&apos;in&apos;, b&apos;this&apos;, b&apos;story&apos;, b&apos;,&apos;, b&apos;there&apos;, b&apos;is&apos;, b&apos;zero&apos;, b&apos;romance&apos;, b&apos;,&apos;, b&apos;too&apos;, b&apos;much&apos;, b&apos;action&apos;, b&apos;,&apos;, b&apos;and&apos;, b&apos;way&apos;, b&apos;too&apos;, b&apos;dumb&apos;, b&apos;of&apos;, b&apos;an&apos;, b&apos;ending&apos;, b&apos;.&apos;, b&apos;it&apos;, b&apos;is&apos;, b&apos;very&apos;, b&apos;violent&apos;, b&apos;.&apos;, b&apos;i&apos;, b&apos;did&apos;, b&apos;however&apos;, b&apos;love&apos;, b&apos;the&apos;, b&apos;scenery&apos;, b&apos;,&apos;, b&apos;this&apos;, b&apos;movie&apos;, b&apos;takes&apos;, b&apos;you&apos;, b&apos;all&apos;, b&apos;over&apos;, b&apos;the&apos;, b&apos;world&apos;, b&apos;,&apos;, b&apos;and&apos;, b&apos;that&apos;, b&apos;is&apos;, b&apos;a&apos;, b&apos;bonus&apos;, b&apos;.&apos;, b&apos;i&apos;, b&apos;also&apos;, b&apos;liked&apos;, b&apos;how&apos;, b&apos;it&apos;, b&apos;had&apos;, b&apos;some&apos;, b&apos;stuff&apos;, b&apos;about&apos;, b&apos;the&apos;, b&apos;mafia&apos;, b&apos;in&apos;, b&apos;it&apos;, b&apos;,&apos;, b&apos;not&apos;, b&apos;too&apos;, b&apos;much&apos;, b&apos;or&apos;, b&apos;too&apos;, b&apos;little&apos;, b&apos;,&apos;, b&apos;but&apos;, b&apos;enough&apos;, b&apos;that&apos;, b&apos;it&apos;, b&apos;got&apos;, b&apos;my&apos;, b&apos;attention&apos;, b&apos;.&apos;, b&apos;the&apos;, b&apos;actors&apos;, b&apos;needed&apos;, b&apos;to&apos;, b&apos;be&apos;, b&apos;more&apos;, b&apos;handsome&apos;, b&apos;.&apos;, b&apos;.&apos;, b&apos;.&apos;, b&apos;the&apos;, b&apos;biggest&apos;, b&apos;problem&apos;, b&apos;i&apos;, b&apos;had&apos;, b&apos;was&apos;, b&apos;that&apos;, b&apos;nevsky&apos;, b&apos;was&apos;, b&apos;just&apos;, b&apos;too&apos;, b&apos;normal&apos;, b&apos;,&apos;, b&apos;not&apos;, b&apos;sexy&apos;, b&apos;enough&apos;, b&apos;.&apos;, b&apos;i&apos;, b&apos;think&apos;, b&apos;for&apos;, b&apos;most&apos;, b&apos;guys&apos;, b&apos;,&apos;, b&apos;sascha&apos;, b&apos;will&apos;, b&apos;be&apos;, b&apos;hot&apos;, b&apos;enough&apos;, b&apos;,&apos;, b&apos;but&apos;, b&apos;for&apos;, b&apos;us&apos;, b&apos;ladies&apos;, b&apos;that&apos;, b&apos;are&apos;, b&apos;fans&apos;, b&apos;of&apos;, b&apos;action&apos;, b&apos;,&apos;, b&apos;nevsky&apos;, b&apos;just&apos;, b&apos;doesn&apos;, b&quot;&apos;&quot;, b&apos;t&apos;, b&apos;cut&apos;, b&apos;it&apos;, b&apos;.&apos;, b&apos;overall&apos;, b&apos;,&apos;, b&apos;this&apos;, b&apos;movie&apos;, b&apos;was&apos;, b&apos;fine&apos;, b&apos;,&apos;, b&apos;i&apos;, b&apos;didn&apos;, b&quot;&apos;&quot;, b&apos;t&apos;, b&apos;love&apos;, b&apos;it&apos;, b&apos;nor&apos;, b&apos;did&apos;, b&apos;i&apos;, b&apos;hate&apos;, b&apos;it&apos;, b&apos;,&apos;, b&apos;just&apos;, b&apos;found&apos;, b&apos;it&apos;, b&apos;to&apos;, b&apos;be&apos;, b&apos;another&apos;, b&apos;normal&apos;, b&apos;action&apos;, b&apos;flick&apos;, b&apos;.&apos;], dtype=object)}, array([0.], dtype=float32)) Áé∞Âú®ÔºåÊàë‰ª¨ÊûÑÂª∫‰∏Ä‰∏™Ê≠£ÂºèÁöÑËæìÂÖ•ÂáΩÊï∞ÔºåÂèØ‰ª•Â∞ÜÂÖ∂‰º†ÈÄíÁªô TensorFlow Estimator ÂØπË±°ÁöÑ train() ÊñπÊ≥ï„ÄÇ 123456789101112131415161718192021# Create an input_fn that parses the tf.Examples from the given files,# and split them into features and targets.def _input_fn(input_filenames, num_epochs=None, shuffle=True): # Same code as above; create a dataset and map features and labels. ds = tf.data.TFRecordDataset(input_filenames) ds = ds.map(_parse_function) if shuffle: ds = ds.shuffle(10000) # Our feature data is variable-length, so we pad and batch # each field of the dataset structure to whatever size is necessary. ds = ds.padded_batch(25, ds.output_shapes) ds = ds.repeat(num_epochs) # Return the next batch of data. features, labels = ds.make_one_shot_iterator().get_next() return features, labels ‰ΩøÁî®ÂÖ∑ÊúâÁ®ÄÁñèËæìÂÖ•ÂíåÊòæÂºèËØçÊ±áË°®ÁöÑÁ∫øÊÄßÊ®°ÂûãÂØπ‰∫éÊàë‰ª¨ÁöÑÁ¨¨‰∏Ä‰∏™Ê®°ÂûãÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî® 50 ‰∏™‰ø°ÊÅØÊÄßÊúØËØ≠Êù•ÊûÑÂª∫ LinearClassifier Ê®°ÂûãÔºõÂßãÁªà‰ªéÁÆÄÂçïÂÖ•ÊâãÔºÅ ‰ª•‰∏ã‰ª£Á†ÅÂ∞Ü‰∏∫Êàë‰ª¨ÁöÑÊúØËØ≠ÊûÑÂª∫ÁâπÂæÅÂàó„ÄÇcategorical_column_with_vocabulary_list ÂáΩÊï∞ÂèØ‰ΩøÁî®‚ÄúÂ≠óÁ¨¶‰∏≤-ÁâπÂæÅÁü¢Èáè‚ÄùÊò†Â∞ÑÊù•ÂàõÂª∫ÁâπÂæÅÂàó„ÄÇ 12345678910111213# 50 informative terms that compose our model vocabulary. informative_terms = ("bad", "great", "best", "worst", "fun", "beautiful", "excellent", "poor", "boring", "awful", "terrible", "definitely", "perfect", "liked", "worse", "waste", "entertaining", "loved", "unfortunately", "amazing", "enjoyed", "favorite", "horrible", "brilliant", "highly", "simple", "annoying", "today", "hilarious", "enjoyable", "dull", "fantastic", "poorly", "fails", "disappointing", "disappointment", "not", "him", "her", "good", "time", "?", ".", "!", "movie", "film", "action", "comedy", "drama", "family")terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key="terms", vocabulary_list=informative_terms) Êé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞ÜÊûÑÂª∫ LinearClassifierÔºåÂú®ËÆ≠ÁªÉÈõÜ‰∏≠ËÆ≠ÁªÉËØ•Ê®°ÂûãÔºåÂπ∂Âú®ËØÑ‰º∞ÈõÜ‰∏≠ÂØπÂÖ∂ËøõË°åËØÑ‰º∞„ÄÇÈòÖËØª‰∏äËø∞‰ª£Á†ÅÂêéÔºåËøêË°åËØ•Ê®°Âûã‰ª•‰∫ÜËß£ÂÖ∂ÊïàÊûú„ÄÇ 12345678910111213141516171819202122232425262728293031my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)feature_columns = [ terms_feature_column ]classifier = tf.estimator.LinearClassifier( feature_columns=feature_columns, optimizer=my_optimizer,)classifier.train( input_fn=lambda: _input_fn([train_path]), steps=1000)evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([train_path]), steps=1000)print("Training set metrics:")for m in evaluation_metrics: print(m, evaluation_metrics[m])print("---")evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([test_path]), steps=1000)print("Test set metrics:")for m in evaluation_metrics: print(m, evaluation_metrics[m])print("---") Training set metrics: accuracy 0.78928 accuracy_baseline 0.5 auc 0.87206453 auc_precision_recall 0.8640158 average_loss 0.45088252 label/mean 0.5 loss 11.272063 precision 0.77057767 prediction/mean 0.4956976 recall 0.82384 global_step 1000 --- Test set metrics: accuracy 0.78504 accuracy_baseline 0.5 auc 0.86939275 auc_precision_recall 0.8610384 average_loss 0.4532239 label/mean 0.5 loss 11.330598 precision 0.7680963 prediction/mean 0.49426404 recall 0.81664 global_step 1000 --- ‰ΩøÁî®Ê∑±Â∫¶Á•ûÁªèÁΩëÁªú (DNN) Ê®°Âûã‰∏äËø∞Ê®°ÂûãÊòØ‰∏Ä‰∏™Á∫øÊÄßÊ®°ÂûãÔºåÊïàÊûúÈùûÂ∏∏Â•Ω„ÄÇ‰ΩÜÊòØÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® DNN Ê®°ÂûãÂÆûÁé∞Êõ¥Â•ΩÁöÑÊïàÊûúÂêóÔºü Êàë‰ª¨Â∞Ü LinearClassifier ÂàáÊç¢‰∏∫ DNNClassifier„ÄÇËøêË°å‰ª•‰∏ãÂçïÂÖÉÔºåÁúãÁúãÊÇ®ÁöÑÊ®°ÂûãÊïàÊûúÂ¶Ç‰Ωï„ÄÇ 12345678910111213141516171819202122232425262728293031##################### Here's what we changed ##################################classifier = tf.estimator.DNNClassifier( # feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], # hidden_units=[20,20], # optimizer=my_optimizer, #) ################################################################################try: classifier.train( input_fn=lambda: _input_fn([train_path]), steps=1000) evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([train_path]), steps=1) print("Training set metrics:") for m in evaluation_metrics: print(m, evaluation_metrics[m]) print("---") evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([test_path]), steps=1) print("Test set metrics:") for m in evaluation_metrics: print(m, evaluation_metrics[m]) print("---")except ValueError as err: print(err) Training set metrics: accuracy 0.92 accuracy_baseline 0.68 auc 0.9705881 auc_precision_recall 0.9885154 average_loss 0.33181748 label/mean 0.68 loss 8.295437 precision 1.0 prediction/mean 0.52073544 recall 0.88235295 global_step 1000 --- Test set metrics: accuracy 0.8 accuracy_baseline 0.56 auc 0.75974023 auc_precision_recall 0.66889143 average_loss 0.7257034 label/mean 0.56 loss 18.142586 precision 0.84615386 prediction/mean 0.4270074 recall 0.78571427 global_step 1000 --- Âú® DNN Ê®°Âûã‰∏≠‰ΩøÁî®ÂµåÂÖ•Âú®Ê≠§‰ªªÂä°‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®ÂµåÂÖ•ÂàóÊù•ÂÆûÁé∞ DNN Ê®°Âûã„ÄÇÂµåÂÖ•Âàó‰ºöÂ∞ÜÁ®ÄÁñèÊï∞ÊçÆ‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ËøîÂõû‰∏Ä‰∏™‰ΩéÁª¥Â∫¶ÂØÜÈõÜÁü¢Èáè‰Ωú‰∏∫ËæìÂá∫„ÄÇ Ê≥®ÊÑèÔºö‰ªéËÆ°ÁÆóÊñπÈù¢ËÄåË®ÄÔºåembedding_column ÈÄöÂ∏∏ÊòØÁî®‰∫éÂú®Á®ÄÁñèÊï∞ÊçÆ‰∏≠ËÆ≠ÁªÉÊ®°ÂûãÊúÄÊúâÊïàÁöÑÈÄâÈ°π„ÄÇÂú®Ê≠§ÁªÉ‰π†Êú´Â∞æÁöÑÂèØÈÄâÈÉ®ÂàÜÔºåÊàë‰ª¨Â∞ÜÊõ¥Ê∑±ÂÖ•Âú∞ËÆ®ËÆ∫‰ΩøÁî® embedding_column ‰∏é indicator_column ‰πãÈó¥ÁöÑÂÆûÁé∞Â∑ÆÂºÇÔºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®Ëøô‰∏§ËÄÖ‰πãÈó¥ÂÅöÂá∫ÊùÉË°°„ÄÇ Âú®‰∏ãÈù¢ÁöÑ‰ª£Á†Å‰∏≠ÔºåÊâßË°å‰ª•‰∏ãÊìç‰ΩúÔºö ÈÄöËøáÂ∞ÜÊï∞ÊçÆÊäïÂ∞ÑÂà∞‰∫åÁª¥Á©∫Èó¥ÁöÑ embedding_column Êù•‰∏∫Ê®°ÂûãÂÆö‰πâÁâπÂæÅÂàóÔºàÂ¶ÇÈúÄËØ¶ÁªÜ‰∫ÜËß£ embedding_column ÁöÑÂáΩÊï∞Á≠æÂêçÔºåËØ∑ÂèÇÈòÖÁõ∏ÂÖ≥ TF ÊñáÊ°£Ôºâ„ÄÇ ÂÆö‰πâÁ¨¶Âêà‰ª•‰∏ãËßÑËåÉÁöÑ DNNClassifierÔºö ÂÖ∑Êúâ‰∏§‰∏™ÈöêËóèÂ±ÇÔºåÊØè‰∏™ÂåÖÂê´ 20 ‰∏™ÂçïÂÖÉ ÈááÁî®Â≠¶‰π†ÈÄüÁéá‰∏∫ 0.1 ÁöÑ AdaGrad ‰ºòÂåñÊñπÊ≥ï gradient_clip_norm ÂÄº‰∏∫ 5.0 Ê≥®ÊÑèÔºöÂú®ÂÆûË∑µ‰∏≠ÔºåÊàë‰ª¨ÂèØËÉΩ‰ºöÂ∞ÜÊï∞ÊçÆÊäïÂ∞ÑÂà∞ 2 Áª¥‰ª•‰∏äÔºàÊØîÂ¶Ç 50 Êàñ 100ÔºâÁöÑÁ©∫Èó¥‰∏≠„ÄÇ‰ΩÜÂ∞±ÁõÆÂâçËÄåË®ÄÔºå2 Áª¥ÊòØÊØîËæÉÂÆπÊòìÂèØËßÜÂåñÁöÑÁª¥Êï∞„ÄÇ 12345678910111213141516171819202122232425262728293031323334########################## SOLUTION CODE ########################################terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)feature_columns = [ terms_embedding_column ]my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)classifier = tf.estimator.DNNClassifier( feature_columns=feature_columns, hidden_units=[20,20], optimizer=my_optimizer)#################################################################################classifier.train( input_fn=lambda: _input_fn([train_path]), steps=1000)evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([train_path]), steps=1000)print("Training set metrics:")for m in evaluation_metrics: print(m, evaluation_metrics[m])print("---")evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([test_path]), steps=1000)print("Test set metrics:")for m in evaluation_metrics: print(m, evaluation_metrics[m])print("---") Training set metrics: accuracy 0.78516 accuracy_baseline 0.5 auc 0.8685013 auc_precision_recall 0.8568284 average_loss 0.45557868 label/mean 0.5 loss 11.389467 precision 0.7566789 prediction/mean 0.52443045 recall 0.84064 global_step 1000 --- Test set metrics: accuracy 0.78168 accuracy_baseline 0.5 auc 0.8668425 auc_precision_recall 0.85428405 average_loss 0.45733798 label/mean 0.5 loss 11.433449 precision 0.7556637 prediction/mean 0.52328736 recall 0.83256 global_step 1000 --- Á°Æ‰ø°Ê®°Âûã‰∏≠Á°ÆÂÆûÂ≠òÂú®ÂµåÂÖ•‰∏äËø∞Ê®°Âûã‰ΩøÁî®‰∫Ü embedding_columnÔºåËÄå‰∏î‰ºº‰πéÂæàÊúâÊïàÔºå‰ΩÜËøôÂπ∂Ê≤°ÊúâËÆ©Êàë‰ª¨‰∫ÜËß£Âà∞ÂÜÖÈÉ®ÂèëÁîüÁöÑÊÉÖÂΩ¢„ÄÇÊàë‰ª¨Â¶Ç‰ΩïÊ£ÄÊü•ËØ•Ê®°ÂûãÁ°ÆÂÆûÂú®ÂÜÖÈÉ®‰ΩøÁî®‰∫ÜÂµåÂÖ•Ôºü È¶ñÂÖàÔºåÊàë‰ª¨Êù•ÁúãÁúãËØ•Ê®°Âûã‰∏≠ÁöÑÂº†ÈáèÔºö 1classifier.get_variable_names() [&apos;dnn/hiddenlayer_0/bias&apos;, &apos;dnn/hiddenlayer_0/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_0/kernel&apos;, &apos;dnn/hiddenlayer_0/kernel/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/bias&apos;, &apos;dnn/hiddenlayer_1/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/kernel&apos;, &apos;dnn/hiddenlayer_1/kernel/t_0/Adagrad&apos;, &apos;dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights&apos;, &apos;dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights/t_0/Adagrad&apos;, &apos;dnn/logits/bias&apos;, &apos;dnn/logits/bias/t_0/Adagrad&apos;, &apos;dnn/logits/kernel&apos;, &apos;dnn/logits/kernel/t_0/Adagrad&apos;, &apos;global_step&apos;] Â•ΩÁöÑÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ËøôÈáåÊúâ‰∏Ä‰∏™ÂµåÂÖ•Â±ÇÔºö&#39;dnn/input_from_feature_columns/input_layer/terms_embedding/...&#39;„ÄÇÔºàÈ°∫‰æøËØ¥‰∏Ä‰∏ãÔºåÊúâË∂£ÁöÑÊòØÔºåËØ•Â±ÇÂèØ‰ª•‰∏éÊ®°ÂûãÁöÑÂÖ∂‰ªñÂ±Ç‰∏ÄËµ∑ËÆ≠ÁªÉÔºåÂ∞±ÂÉèÊâÄÊúâÈöêËóèÂ±Ç‰∏ÄÊ†∑„ÄÇÔºâ ÂµåÂÖ•Â±ÇÁöÑÂΩ¢Áä∂ÊòØÂê¶Ê≠£Á°ÆÔºüËØ∑ËøêË°å‰ª•‰∏ã‰ª£Á†ÅÊù•Êü•Êòé„ÄÇ Ê≥®ÊÑèÔºöÂú®Êàë‰ª¨ÁöÑÁ§∫‰æã‰∏≠ÔºåÂµåÂÖ•ÊòØ‰∏Ä‰∏™Áü©ÈòµÔºåÂèØËÆ©Êàë‰ª¨Â∞Ü‰∏Ä‰∏™ 50 Áª¥Áü¢ÈáèÊäïÂ∞ÑÂà∞ 2 Áª¥Á©∫Èó¥„ÄÇ 12for neure in classifier.get_variable_names(): print(classifier.get_variable_value(neure).shape, ": " + neure) (20,) : dnn/hiddenlayer_0/bias (20,) : dnn/hiddenlayer_0/bias/t_0/Adagrad (2, 20) : dnn/hiddenlayer_0/kernel (2, 20) : dnn/hiddenlayer_0/kernel/t_0/Adagrad (20,) : dnn/hiddenlayer_1/bias (20,) : dnn/hiddenlayer_1/bias/t_0/Adagrad (20, 20) : dnn/hiddenlayer_1/kernel (20, 20) : dnn/hiddenlayer_1/kernel/t_0/Adagrad (50, 2) : dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights (50, 2) : dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights/t_0/Adagrad (1,) : dnn/logits/bias (1,) : dnn/logits/bias/t_0/Adagrad (20, 1) : dnn/logits/kernel (20, 1) : dnn/logits/kernel/t_0/Adagrad () : global_step Ëä±‰∫õÊó∂Èó¥Êù•ÊâãÂä®Ê£ÄÊü•ÂêÑ‰∏™Â±ÇÂèäÂÖ∂ÂΩ¢Áä∂Ôºå‰ª•Á°Æ‰øù‰∏ÄÂàáÈÉΩÊåâÁÖßÊÇ®È¢ÑÊúüÁöÑÊñπÂºè‰∫íÁõ∏ËøûÊé•„ÄÇ Ê£ÄÊü•ÂµåÂÖ•Áé∞Âú®ÔºåÊàë‰ª¨Êù•ÁúãÁúãÂÆûÈôÖÂµåÂÖ•Á©∫Èó¥ÔºåÂπ∂‰∫ÜËß£ÊúØËØ≠ÊúÄÁªàÊâÄÂú®ÁöÑ‰ΩçÁΩÆ„ÄÇËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰ΩúÔºö ËøêË°å‰ª•‰∏ã‰ª£Á†ÅÊù•Êü•ÁúãÊàë‰ª¨Âú®ËÆ≠ÁªÉÁöÑÂµåÂÖ•„ÄÇ‰∏ÄÂàáÊúÄÁªàÊòØÂê¶Â¶ÇÊÇ®ÊâÄÈ¢ÑÊúüÁöÑÈÇ£Ê†∑Ôºü ÈáçÊñ∞ËøêË°åÂú® DNN Ê®°Âûã‰∏≠‰ΩøÁî®Âµå ‰∏≠ÁöÑ‰ª£Á†ÅÊù•ÈáçÊñ∞ËÆ≠ÁªÉËØ•Ê®°ÂûãÔºåÁÑ∂ÂêéÂÜçÊ¨°ËøêË°å‰∏ãÈù¢ÁöÑÂµåÂÖ•ÂèØËßÜÂåñ„ÄÇÂì™‰∫õ‰øùÊåÅ‰∏çÂèòÔºüÂì™‰∫õÂèëÁîü‰∫ÜÂèòÂåñÔºü ÊúÄÂêéÔºå‰ªÖ‰ΩøÁî® 10 Ê≠•Êù•ÈáçÊñ∞ËÆ≠ÁªÉËØ•Ê®°ÂûãÔºàËøôÂ∞Ü‰∫ßÁîü‰∏Ä‰∏™Á≥üÁ≥ïÁöÑÊ®°ÂûãÔºâ„ÄÇÂÜçÊ¨°ËøêË°å‰∏ãÈù¢ÁöÑÂµåÂÖ•ÂèØËßÜÂåñ„ÄÇÊÇ®Áé∞Âú®ÁúãÂà∞‰∫Ü‰ªÄ‰πàÔºü‰∏∫‰ªÄ‰πàÔºü 123456789101112131415161718192021import numpy as npimport matplotlib.pyplot as pltembedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')for term_index in range(len(informative_terms)): # Create a one-hot encoding for our term. It has 0s everywhere, except for # a single 1 in the coordinate that corresponds to that term. term_vector = np.zeros(len(informative_terms)) term_vector[term_index] = 1 # We'll now project that one-hot vector into the embedding space. embedding_xy = np.matmul(term_vector, embedding_matrix) plt.text(embedding_xy[0], embedding_xy[1], informative_terms[term_index])# Do a little setup to make sure the plot displays nicely.plt.rcParams["figure.figsize"] = (15, 15)plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())plt.show() 123456789101112131415161718192021import numpy as npimport matplotlib.pyplot as pltembedding_matrix = classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')for term_index in range(len(informative_terms)): # Create a one-hot encoding for our term. It has 0s everywhere, except for # a single 1 in the coordinate that corresponds to that term. term_vector = np.zeros(len(informative_terms)) term_vector[term_index] = 1 # We'll now project that one-hot vector into the embedding space. embedding_xy = np.matmul(term_vector, embedding_matrix) plt.text(embedding_xy[0], embedding_xy[1], informative_terms[term_index])# Do a little setup to make sure the plot displays nicely.plt.rcParams["figure.figsize"] = (15, 15)plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())plt.show() ‰ªªÂä° 6ÔºöÂ∞ùËØïÊîπËøõÊ®°ÂûãÁöÑÊïàÊûúÁúãÁúãÊÇ®ËÉΩÂê¶‰ºòÂåñËØ•Ê®°Âûã‰ª•ÊîπËøõÂÖ∂ÊïàÊûú„ÄÇÊÇ®ÂèØ‰ª•Â∞ùËØï‰ª•‰∏ãÂá†ÁßçÂÅöÊ≥ïÔºö Êõ¥ÊîπË∂ÖÂèÇÊï∞Êàñ‰ΩøÁî®ÂÖ∂‰ªñ‰ºòÂåñÂ∑•ÂÖ∑ÔºåÊØîÂ¶Ç AdamÔºàÈÄöËøáÈÅµÂæ™Ëøô‰∫õÁ≠ñÁï•ÔºåÊÇ®ÁöÑÂáÜÁ°ÆÁéáÂèØËÉΩÂè™‰ºöÊèêÈ´ò‰∏Ä‰∏§‰∏™ÁôæÂàÜÁÇπÔºâ„ÄÇ Âêë informative_terms ‰∏≠Ê∑ªÂä†ÂÖ∂‰ªñÊúØËØ≠„ÄÇÊ≠§Êï∞ÊçÆÈõÜÊúâ‰∏Ä‰∏™ÂÆåÊï¥ÁöÑËØçÊ±áË°®Êñá‰ª∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´ 30716 ‰∏™ÊúØËØ≠ÔºåÊÇ®ÂèØ‰ª•Âú®‰ª•‰∏ã‰ΩçÁΩÆÊâæÂà∞ËØ•Êñá‰ª∂Ôºöhttps://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt ÊÇ®ÂèØ‰ª•‰ªéËØ•ËØçÊ±áË°®Êñá‰ª∂‰∏≠ÊåëÈÄâÂá∫ÂÖ∂‰ªñÊúØËØ≠Ôºå‰πüÂèØ‰ª•ÈÄöËøá categorical_column_with_vocabulary_file ÁâπÂæÅÂàó‰ΩøÁî®Êï¥‰∏™ËØçÊ±áË°®Êñá‰ª∂„ÄÇ 123# Download the vocabulary file.terms_url = 'https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt'terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url) Downloading data from https://download.mlcc.google.cn/mledu-datasets/sparse-data-embedding/terms.txt 253952/253538 [==============================] - 0s 0us/step 1234567891011121314151617181920212223242526272829303132333435363738394041# Create a feature column from "terms", using a full vocabulary file.informative_terms = Nonewith io.open(terms_path, 'r', encoding='utf8') as f: # Convert it to a set first to remove duplicates. informative_terms = list(set(f.read().split())) terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key="terms", vocabulary_list=informative_terms)terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=2)feature_columns = [ terms_embedding_column ]my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)classifier = tf.estimator.DNNClassifier( feature_columns=feature_columns, hidden_units=[10,10], optimizer=my_optimizer)classifier.train( input_fn=lambda: _input_fn([train_path]), steps=1000)evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([train_path]), steps=1000)print("Training set metrics:")for m in evaluation_metrics: print(m, evaluation_metrics[m])print("---")evaluation_metrics = classifier.evaluate( input_fn=lambda: _input_fn([test_path]), steps=1000)print("Test set metrics:")for m in evaluation_metrics: print(m, evaluation_metrics[m])print("---") Training set metrics: accuracy 0.82 accuracy_baseline 0.5 auc 0.89789164 auc_precision_recall 0.8937925 average_loss 0.4075714 label/mean 0.5 loss 10.189285 precision 0.83664364 prediction/mean 0.4748372 recall 0.79528 global_step 1000 --- Test set metrics: accuracy 0.8048 accuracy_baseline 0.5 auc 0.88663244 auc_precision_recall 0.8821298 average_loss 0.42734343 label/mean 0.5 loss 10.683586 precision 0.8235394 prediction/mean 0.47395515 recall 0.77584 global_step 1000 --- ÊÄªÁªìÊàë‰ª¨ÂèØËÉΩËé∑Âæó‰∫ÜÊØîÊàë‰ª¨ÂéüÊù•ÁöÑÁ∫øÊÄßÊ®°ÂûãÊõ¥Â•Ω‰∏îÂÖ∑ÊúâÂµåÂÖ•ÁöÑ DNN Ëß£ÂÜ≥ÊñπÊ°àÔºå‰ΩÜÁ∫øÊÄßÊ®°Âûã‰πüÁõ∏ÂΩì‰∏çÈîôÔºåËÄå‰∏îËÆ≠ÁªÉÈÄüÂ∫¶Âø´ÂæóÂ§ö„ÄÇÁ∫øÊÄßÊ®°ÂûãÁöÑËÆ≠ÁªÉÈÄüÂ∫¶‰πãÊâÄ‰ª•Êõ¥Âø´ÔºåÊòØÂõ†‰∏∫ÂÆÉ‰ª¨Ê≤°ÊúâÂ§™Â§öË¶ÅÊõ¥Êñ∞ÁöÑÂèÇÊï∞ÊàñË¶ÅÂèçÂêë‰º†Êí≠ÁöÑÂ±Ç„ÄÇ Âú®Êúâ‰∫õÂ∫îÁî®‰∏≠ÔºåÁ∫øÊÄßÊ®°ÂûãÁöÑÈÄüÂ∫¶ÂèØËÉΩÈùûÂ∏∏ÂÖ≥ÈîÆÔºåÊàñËÄÖ‰ªéË¥®ÈáèÁöÑËßíÂ∫¶Êù•ÁúãÔºåÁ∫øÊÄßÊ®°ÂûãÂèØËÉΩÂÆåÂÖ®Â§üÁî®„ÄÇÂú®ÂÖ∂‰ªñÈ¢ÜÂüüÔºåDNN Êèê‰æõÁöÑÈ¢ùÂ§ñÊ®°ÂûãÂ§çÊùÇÊÄßÂíåËÉΩÂäõÂèØËÉΩÊõ¥ÈáçË¶Å„ÄÇÂú®ÂÆö‰πâÊ®°ÂûãÊû∂ÊûÑÊó∂ÔºåËØ∑ËÆ∞ÂæóË¶ÅÂÖÖÂàÜÊé¢ËÆ®ÊÇ®ÁöÑÈóÆÈ¢òÔºå‰ª•‰æøÁü•ÈÅìËá™Â∑±ÊâÄÂ§ÑÁöÑÊÉÖÂΩ¢„ÄÇ ÂèØÈÄâÂÜÖÂÆπÔºöÂú® embedding_column ‰∏é indicator_column ‰πãÈó¥ËøõË°åÊùÉË°°‰ªéÊ¶ÇÂøµ‰∏äËÆ≤ÔºåÂú®ËÆ≠ÁªÉ LinearClassifier Êàñ DNNClassifier Êó∂ÔºåÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰ΩøÁî®Á®ÄÁñèÂàó„ÄÇTF Êèê‰æõ‰∫Ü‰∏§‰∏™ÈÄâÈ°πÔºöembedding_column Êàñ indicator_column„ÄÇ Âú®ËÆ≠ÁªÉ LinearClassifierÔºàÂ¶Ç‰ΩøÁî®ÂÖ∑ÊúâÁ®ÄÁñèËæìÂÖ•ÂíåÊòæÂºèËØçÊ±áË°®ÁöÑÁ∫øÊÄßÊ®°Âûã ‰∏≠ÊâÄÁ§∫ÔºâÊó∂ÔºåÁ≥ªÁªüÂú®ÂêéÂè∞‰ΩøÁî®‰∫Ü embedding_column„ÄÇÊ≠£Â¶Ç‰ΩøÁî®Ê∑±Â∫¶Á•ûÁªèÁΩëÁªú (DNN) Ê®°Âûã ‰∏≠ÊâÄÁ§∫ÔºåÂú®ËÆ≠ÁªÉ DNNClassifier Êó∂ÔºåÊÇ®ÂøÖÈ°ªÊòéÁ°ÆÈÄâÊã© embedding_column Êàñ indicator_column„ÄÇÊú¨ÈÉ®ÂàÜÈÄöËøá‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ§∫‰æãËÆ®ËÆ∫‰∫ÜËøô‰∏§ËÄÖ‰πãÈó¥ÁöÑÂå∫Âà´Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÂú®‰∫åËÄÖ‰πãÈó¥ËøõË°åÊùÉË°°„ÄÇ ÂÅáËÆæÊàë‰ª¨ÁöÑÁ®ÄÁñèÊï∞ÊçÆÂåÖÂê´ &quot;great&quot;„ÄÅ&quot;beautiful&quot; Âíå &quot;excellent&quot; ËøôÂá†‰∏™ÂÄº„ÄÇÁî±‰∫éÊàë‰ª¨Âú®Ê≠§Â§Ñ‰ΩøÁî®ÁöÑËØçÊ±áË°®Â§ßÂ∞è‰∏∫ $V = 50$ÔºåÂõ†Ê≠§Á¨¨‰∏ÄÂ±Ç‰∏≠ÁöÑÊØè‰∏™ÂçïÂÖÉÔºàÁ•ûÁªèÂÖÉÔºâÁöÑÊùÉÈáçÂ∞Ü‰∏∫ 50„ÄÇÊàë‰ª¨Áî® $s$ Ë°®Á§∫Á®ÄÁñèËæìÂÖ•‰∏≠ÁöÑÈ°πÊï∞„ÄÇÂØπ‰∫éÊ≠§Á§∫‰æãÁ®ÄÁñèÊï∞ÊçÆÔºå$s = 3$„ÄÇÂØπ‰∫éÂÖ∑Êúâ $V$ ‰∏™ÂèØËÉΩÂÄºÁöÑËæìÂÖ•Â±ÇÔºåÂ∏¶Êúâ $d$ ‰∏™ÂçïÂÖÉÁöÑÈöêËóèÂ±ÇÈúÄË¶ÅËøêË°å‰∏ÄÊ¨°‚ÄúÁü¢Èáè - Áü©Èòµ‚Äù‰πòÊ≥ïËøêÁÆóÔºö$(1 \times V) (V \times d)$„ÄÇÊ≠§ËøêÁÆó‰ºö‰∫ßÁîü $O(V d)$ ÁöÑËÆ°ÁÆóÊàêÊú¨„ÄÇËØ∑Ê≥®ÊÑèÔºåÊ≠§ÊàêÊú¨‰∏éÈöêËóèÂ±Ç‰∏≠ÁöÑÊùÉÈáçÊï∞ÊàêÊ≠£ÊØîÔºåËÄå‰∏é $s$ Êó†ÂÖ≥„ÄÇ Â¶ÇÊûúËæìÂÖ•‰ΩøÁî® indicator_column ËøõË°å‰∫ÜÁã¨ÁÉ≠ÁºñÁ†ÅÔºàÈïøÂ∫¶‰∏∫ $V$ ÁöÑÂ∏ÉÂ∞îÂûãÁü¢ÈáèÔºåÂ≠òÂú®Áî® 1 Ë°®Á§∫ÔºåÂÖ∂‰ΩôÂàô‰∏∫ 0ÔºâÔºåËøôË°®Á§∫ÂæàÂ§öÈõ∂ËøõË°å‰∫ÜÁõ∏‰πòÂíåÁõ∏Âä†ËøêÁÆó„ÄÇ ÂΩìÊàë‰ª¨ÈÄöËøá‰ΩøÁî®Â§ßÂ∞è‰∏∫ $d$ ÁöÑ embedding_column Ëé∑ÂæóÂÆåÂÖ®Áõ∏ÂêåÁöÑÁªìÊûúÊó∂ÔºåÊàë‰ª¨Â∞Ü‰ªÖÊü•ËØ¢‰∏éÁ§∫‰æãËæìÂÖ•‰∏≠Â≠òÂú®ÁöÑ 3 ‰∏™ÁâπÂæÅ &quot;great&quot;„ÄÅ&quot;beautiful&quot; Âíå &quot;excellent&quot; Áõ∏ÂØπÂ∫îÁöÑÂµåÂÖ•Âπ∂Â∞ÜËøô‰∏â‰∏™ÂµåÂÖ•Áõ∏Âä†Ôºö$(1 \times d) + (1 \times d) + (1 \times d)$„ÄÇÁî±‰∫é‰∏çÂ≠òÂú®ÁöÑÁâπÂæÅÁöÑÊùÉÈáçÂú®‚ÄúÁü¢Èáè-Áü©Èòµ‚Äù‰πòÊ≥ï‰∏≠‰∏é 0 Áõ∏‰πòÔºåÂõ†Ê≠§ÂØπÁªìÊûúÊ≤°Êúâ‰ªª‰ΩïÂΩ±ÂìçÔºõËÄåÂ≠òÂú®ÁöÑÁâπÂæÅÁöÑÊùÉÈáçÂú®‚ÄúÁü¢Èáè-Áü©Èòµ‚Äù‰πòÊ≥ï‰∏≠‰∏é 1 Áõ∏‰πò„ÄÇÂõ†Ê≠§ÔºåÂ∞ÜÈÄöËøáÂµåÂÖ•Êü•ËØ¢Ëé∑ÂæóÁöÑÊùÉÈáçÁõ∏Âä†‰ºöËé∑Âæó‰∏é‚ÄúÁü¢Èáè-Áü©Èòµ‚Äù‰πòÊ≥ïÁõ∏ÂêåÁöÑÁªìÊûú„ÄÇ ÂΩì‰ΩøÁî®ÂµåÂÖ•Êó∂ÔºåËÆ°ÁÆóÂµåÂÖ•Êü•ËØ¢ÊòØ‰∏Ä‰∏™ $O(s d)$ ËÆ°ÁÆóÔºõ‰ªéËÆ°ÁÆóÊñπÈù¢ËÄåË®ÄÔºåÂÆÉÊØîÁ®ÄÁñèÊï∞ÊçÆ‰∏≠ÁöÑ indicator_column ÁöÑ $O(V d)$ Êõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõäÔºåÂõ†‰∏∫ $s$ ËøúËøúÂ∞è‰∫é $V$„ÄÇÔºàËØ∑Ê≥®ÊÑèÔºåËøô‰∫õÂµåÂÖ•ÊòØ‰∏¥Êó∂Â≠¶‰π†ÁöÑÁªìÊûú„ÄÇÂú®‰ªª‰ΩïÊåáÂÆöÁöÑËÆ≠ÁªÉËø≠‰ª£‰∏≠ÔºåÈÉΩÊòØÂΩìÂâçÊü•ËØ¢ÁöÑÊùÉÈáç„ÄÇ Ê≠£Â¶ÇÊàë‰ª¨Âú®Âú® DNN Ê®°Âûã‰∏≠‰ΩøÁî®ÂµåÂÖ• ‰∏≠ÁúãÂà∞ÁöÑÔºåÈÄöËøáÂú®ËÆ≠ÁªÉ DNNClassifier ËøáÁ®ã‰∏≠‰ΩøÁî® embedding_columnÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂ≠¶‰π†‰∫ÜÁâπÂæÅÁöÑ‰ΩéÁª¥Â∫¶Ë°®Á§∫Ê≥ïÔºåÂÖ∂‰∏≠ÁÇπÁßØÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÈíàÂØπÁõÆÊ†á‰ªªÂä°ÁöÑÁõ∏‰ººÊÄßÊåáÊ†á„ÄÇÂú®Êú¨‰æã‰∏≠ÔºåÂΩ±ËØÑ‰∏≠‰ΩøÁî®ÁöÑÁõ∏‰ººÊúØËØ≠Ôºà‰æãÂ¶Ç &quot;great&quot; Âíå &quot;excellent&quot;ÔºâÂú®ÂµåÂÖ•Á©∫Èó¥‰∏≠ÂΩºÊ≠§‰πãÈó¥Ë∑ùÁ¶ªËæÉËøëÔºàÂç≥ÂÖ∑ÊúâËæÉÂ§ßÁöÑÁÇπÁßØÔºâÔºåËÄåÁõ∏ÂºÇÁöÑÊúØËØ≠Ôºà‰æãÂ¶Ç &quot;great&quot; Âíå &quot;bad&quot;ÔºâÂú®ÂµåÂÖ•Á©∫Èó¥‰∏≠ÂΩºÊ≠§‰πãÈó¥Ë∑ùÁ¶ªËæÉËøúÔºàÂç≥ÂÖ∑ÊúâËæÉÂ∞èÁöÑÁÇπÁßØÔºâ„ÄÇ]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 9]]></title>
    <url>%2F2019%2F02%2F21%2FTensorFlow_9%2F</url>
    <content type="text"><![CDATA[‰ΩøÁî®Á•ûÁªèÁΩëÁªúÂØπÊâãÂÜôÊï∞Â≠óËøõË°åÂàÜÁ±ª ËÆ≠ÁªÉÁ∫øÊÄßÊ®°ÂûãÂíåÁ•ûÁªèÁΩëÁªúÔºå‰ª•ÂØπ‰º†Áªü MNIST Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÊâãÂÜôÊï∞Â≠óËøõË°åÂàÜÁ±ª ÊØîËæÉÁ∫øÊÄßÂàÜÁ±ªÊ®°ÂûãÂíåÁ•ûÁªèÁΩëÁªúÂàÜÁ±ªÊ®°ÂûãÁöÑÊïàÊûú ÂèØËßÜÂåñÁ•ûÁªèÁΩëÁªúÈöêËóèÂ±ÇÁöÑÊùÉÈáç Êàë‰ª¨ÁöÑÁõÆÊ†áÊòØÂ∞ÜÊØè‰∏™ËæìÂÖ•ÂõæÁâá‰∏éÊ≠£Á°ÆÁöÑÊï∞Â≠óÁõ∏ÂØπÂ∫î„ÄÇÊàë‰ª¨‰ºöÂàõÂª∫‰∏Ä‰∏™ÂåÖÂê´Âá†‰∏™ÈöêËóèÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂπ∂Âú®È°∂ÈÉ®ÊîæÁΩÆ‰∏Ä‰∏™ÂΩí‰∏ÄÂåñÊåáÊï∞Â±ÇÔºå‰ª•ÈÄâÂá∫ÊúÄÂêàÈÄÇÁöÑÁ±ªÂà´„ÄÇ ËÆæÁΩÆ È¶ñÂÖàÔºåÊàë‰ª¨‰∏ãËΩΩÊï∞ÊçÆÈõÜ„ÄÅÂØºÂÖ• TensorFlow ÂíåÂÖ∂‰ªñÂÆûÁî®Â∑•ÂÖ∑ÔºåÂπ∂Â∞ÜÊï∞ÊçÆÂä†ËΩΩÂà∞ Pandas DataFrame„ÄÇËØ∑Ê≥®ÊÑèÔºåÊ≠§Êï∞ÊçÆÊòØÂéüÂßã MNIST ËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊ†∑Êú¨ÔºõÊàë‰ª¨ÈöèÊú∫ÈÄâÊã©‰∫Ü 20000 Ë°å„ÄÇ 12345678910111213141516171819202122232425262728293031from __future__ import print_functionimport globimport mathimport osfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdimport seaborn as snsfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10pd.options.display.float_format = '&#123;:.1f&#125;'.formatmnist_dataframe = pd.read_csv( "https://download.mlcc.google.cn/mledu-datasets/mnist_train_small.csv", sep=",", header=None)# Use just the first 10,000 records for training/validation.mnist_dataframe = mnist_dataframe.head(10000)mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))mnist_dataframe.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 ... 775 776 777 778 779 780 781 782 783 784 5456 8 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 934 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2662 8 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9385 4 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 157 8 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 5 rows √ó 785 columns Á¨¨‰∏ÄÂàó‰∏≠ÂåÖÂê´Á±ªÂà´Ê†áÁ≠æ„ÄÇÂÖ∂‰ΩôÂàó‰∏≠ÂåÖÂê´ÁâπÂæÅÂÄºÔºåÊØè‰∏™ÂÉèÁ¥†ÂØπÂ∫î‰∏Ä‰∏™ÁâπÂæÅÂÄºÔºåÊúâ 28√ó28=784 ‰∏™ÂÉèÁ¥†ÂÄºÔºåÂÖ∂‰∏≠Â§ßÈÉ®ÂàÜÂÉèÁ¥†ÂÄºÈÉΩ‰∏∫Èõ∂ÔºõÊÇ®‰πüËÆ∏ÈúÄË¶ÅËä±‰∏ÄÂàÜÈíüÊó∂Èó¥Êù•Á°ÆËÆ§ÂÆÉ‰ª¨‰∏çÂÖ®ÈÉ®‰∏∫Èõ∂„ÄÇ Ëøô‰∫õÊ†∑Êú¨ÈÉΩÊòØÂàÜËæ®ÁéáÁõ∏ÂØπËæÉ‰Ωé„ÄÅÂØπÊØîÂ∫¶Áõ∏ÂØπËæÉÈ´òÁöÑÊâãÂÜôÊï∞Â≠óÂõæÁâá„ÄÇ0-9 ËøôÂçÅ‰∏™Êï∞Â≠ó‰∏≠ÁöÑÊØè‰∏™ÂèØËÉΩÂá∫Áé∞ÁöÑÊï∞Â≠óÂùáÁî±ÂîØ‰∏ÄÁöÑÁ±ªÂà´Ê†áÁ≠æË°®Á§∫„ÄÇÂõ†Ê≠§ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ∑Êúâ 10 ‰∏™Á±ªÂà´ÁöÑÂ§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢ò„ÄÇ Áé∞Âú®ÔºåÊàë‰ª¨Ëß£Êûê‰∏Ä‰∏ãÊ†áÁ≠æÂíåÁâπÂæÅÔºåÂπ∂Êü•ÁúãÂá†‰∏™Ê†∑Êú¨„ÄÇÊ≥®ÊÑè loc ÁöÑ‰ΩøÁî®ÔºåÂÄüÂä© locÔºåÊàë‰ª¨ËÉΩÂ§üÂü∫‰∫éÂéüÊù•ÁöÑ‰ΩçÁΩÆÊäΩÂá∫ÂêÑÂàóÔºåÂõ†‰∏∫Ê≠§Êï∞ÊçÆÈõÜ‰∏≠Ê≤°ÊúâÊ†áÈ¢òË°å„ÄÇ 123456789101112131415161718192021def parse_labels_and_features(dataset): """Extracts labels and features. This is a good place to scale or transform the features if needed. Args: dataset: A Pandas `Dataframe`, containing the label on the first column and monochrome pixel values on the remaining columns, in row major order. Returns: A `tuple` `(labels, features)`: labels: A Pandas `Series`. features: A Pandas `DataFrame`. """ labels = dataset[0] # DataFrame.loc index ranges are inclusive at both ends. features = dataset.loc[:,1:784] # Scale the data to [0, 1] by dividing out the max value, 255. features = features / 255 return labels, features 12training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])training_examples.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1 2 3 4 5 6 7 8 9 10 ... 775 776 777 778 779 780 781 782 783 784 count 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 ... 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 mean 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 std 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 min 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 25% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 50% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 75% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 max 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 1.0 1.0 0.8 0.2 1.0 0.2 0.0 0.0 0.0 0.0 8 rows √ó 784 columns 12validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])validation_examples.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1 2 3 4 5 6 7 8 9 10 ... 775 776 777 778 779 780 781 782 783 784 count 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 ... 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 mean 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 std 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 min 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 25% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 50% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 75% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 max 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 1.0 0.8 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8 rows √ó 784 columns ÊòæÁ§∫‰∏Ä‰∏™ÈöèÊú∫Ê†∑Êú¨ÂèäÂÖ∂ÂØπÂ∫îÁöÑÊ†áÁ≠æ„ÄÇ 12345rand_example = np.random.choice(training_examples.index)_, ax = plt.subplots()ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))ax.set_title("Label: %i" % training_targets.loc[rand_example])ax.grid(False) ‰∏∫ MNIST ÊûÑÂª∫Á∫øÊÄßÊ®°ÂûãÈ¶ñÂÖàÔºåÊàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™Âü∫ÂáÜÊ®°ÂûãÔºå‰Ωú‰∏∫ÊØîËæÉÂØπË±°„ÄÇLinearClassifier ÂèØÊèê‰æõ‰∏ÄÁªÑ k Á±ª‰∏ÄÂØπÂ§öÂàÜÁ±ªÂô®ÔºåÊØè‰∏™Á±ªÂà´ÔºàÂÖ± k ‰∏™ÔºâÂØπÂ∫î‰∏Ä‰∏™ÂàÜÁ±ªÂô®„ÄÇ ÊÇ®‰ºöÂèëÁé∞ÔºåÈô§‰∫ÜÊä•ÂëäÂáÜÁ°ÆÁéáÂíåÁªòÂà∂ÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ÈöèÊó∂Èó¥ÂèòÂåñÊÉÖÂÜµÁöÑÊõ≤Á∫øÂõæ‰πãÂ§ñÔºåÊàë‰ª¨ËøòÂ±ïÁ§∫‰∫Ü‰∏Ä‰∏™Ê∑∑Ê∑ÜÁü©Èòµ„ÄÇÊ∑∑Ê∑ÜÁü©Èòµ‰ºöÊòæÁ§∫ÈîôËØØÂàÜÁ±ª‰∏∫ÂÖ∂‰ªñÁ±ªÂà´ÁöÑÁ±ªÂà´„ÄÇÂì™‰∫õÊï∞Â≠óÁõ∏‰∫í‰πãÈó¥ÂÆπÊòìÊ∑∑Ê∑ÜÔºü Âè¶ËØ∑Ê≥®ÊÑèÔºåÊàë‰ª¨‰ºö‰ΩøÁî® log_loss ÂáΩÊï∞Ë∑üË∏™Ê®°ÂûãÁöÑÈîôËØØ„ÄÇ‰∏çÂ∫îÂ∞ÜÊ≠§ÂáΩÊï∞‰∏éÁî®‰∫éËÆ≠ÁªÉÁöÑ LinearClassifier ÂÜÖÈÉ®ÊçüÂ§±ÂáΩÊï∞Áõ∏Ê∑∑Ê∑Ü„ÄÇ 123456789def construct_feature_columns(): """Construct the TensorFlow Feature Columns. Returns: A set of feature columns """ # There are 784 pixels in each image. return set([tf.feature_column.numeric_column('pixels', shape=784)]) Âú®Êú¨Ê¨°ÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨‰ºöÂØπËÆ≠ÁªÉÂíåÈ¢ÑÊµã‰ΩøÁî®ÂçïÁã¨ÁöÑËæìÂÖ•ÂáΩÊï∞ÔºåÂπ∂Â∞ÜËøô‰∫õÂáΩÊï∞ÂàÜÂà´ÂµåÂ•óÂú® create_training_input_fn() Âíå create_predict_input_fn() ‰∏≠ÔºåËøôÊ†∑‰∏ÄÊù•ÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•Ë∞ÉÁî®Ëøô‰∫õÂáΩÊï∞Ôºå‰ª•ËøîÂõûÁõ∏Â∫îÁöÑ _input_fnÔºåÂπ∂Â∞ÜÂÖ∂‰º†ÈÄíÂà∞ .train() Âíå .predict() Ë∞ÉÁî®„ÄÇ 12345678910111213141516171819202122232425262728293031def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True): """A custom input_fn for sending MNIST data to the estimator for training. Args: features: The training features. labels: The training labels. batch_size: Batch size to use during training. Returns: A function that returns batches of training features and labels during training. """ def _input_fn(num_epochs=None, shuffle=True): # Input pipelines are reset with each call to .train(). To ensure model # gets a good sampling of data, even when number of steps is small, we # shuffle all the data before creating the Dataset object idx = np.random.permutation(features.index) raw_features = &#123;"pixels":features.reindex(idx)&#125; raw_targets = np.array(labels[idx]) ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit ds = ds.batch(batch_size).repeat(num_epochs) if shuffle: ds = ds.shuffle(10000) # Return the next batch of data. feature_batch, label_batch = ds.make_one_shot_iterator().get_next() return feature_batch, label_batch return _input_fn 1234567891011121314151617181920212223def create_predict_input_fn(features, labels, batch_size): """A custom input_fn for sending mnist data to the estimator for predictions. Args: features: The features to base predictions on. labels: The labels of the prediction examples. Returns: A function that returns features and labels for predictions. """ def _input_fn(): raw_features = &#123;"pixels": features.values&#125; raw_targets = np.array(labels) ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit ds = ds.batch(batch_size) # Return the next batch of data. feature_batch, label_batch = ds.make_one_shot_iterator().get_next() return feature_batch, label_batch return _input_fn 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115def train_linear_classification_model( learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets): """Trains a linear classification model for the MNIST digits dataset. In addition to training, this function also prints training progress information, a plot of the training and validation loss over time, and a confusion matrix. Args: learning_rate: A `float`, the learning rate to use. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. training_examples: A `DataFrame` containing the training features. training_targets: A `DataFrame` containing the training labels. validation_examples: A `DataFrame` containing the validation features. validation_targets: A `DataFrame` containing the validation labels. Returns: The trained `LinearClassifier` object. """ periods = 10 steps_per_period = steps / periods # Create the input functions. predict_training_input_fn = create_predict_input_fn( training_examples, training_targets, batch_size) predict_validation_input_fn = create_predict_input_fn( validation_examples, validation_targets, batch_size) training_input_fn = create_training_input_fn( training_examples, training_targets, batch_size) # Create a LinearClassifier object. my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) classifier = tf.estimator.LinearClassifier( feature_columns=construct_feature_columns(), n_classes=10, optimizer=my_optimizer, config=tf.estimator.RunConfig(keep_checkpoint_max=1) ) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("LogLoss error (on validation data):") training_errors = [] validation_errors = [] for period in range (0, periods): # Train the model, starting from the prior state. classifier.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute probabilities. training_predictions = list(classifier.predict(input_fn=predict_training_input_fn)) training_probabilities = np.array([item['probabilities'] for item in training_predictions]) training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions]) training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10) validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn)) validation_probabilities = np.array([item['probabilities'] for item in validation_predictions]) validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions]) validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10) # Compute training and validation errors. training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot) validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, validation_log_loss)) # Add the loss metrics from this period to our list. training_errors.append(training_log_loss) validation_errors.append(validation_log_loss) print("Model training finished.") # Remove event files to save disk space. _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*'))) # Calculate final predictions (not probabilities, as above). final_predictions = classifier.predict(input_fn=predict_validation_input_fn) final_predictions = np.array([item['class_ids'][0] for item in final_predictions]) accuracy = metrics.accuracy_score(validation_targets, final_predictions) print("Final accuracy (on validation data): %0.2f" % accuracy) # Output a graph of loss metrics over periods. plt.ylabel("LogLoss") plt.xlabel("Periods") plt.title("LogLoss vs. Periods") plt.plot(training_errors, label="training") plt.plot(validation_errors, label="validation") plt.legend() plt.show() # Output a plot of the confusion matrix. cm = metrics.confusion_matrix(validation_targets, final_predictions) # Normalize the confusion matrix by row (i.e by the number of samples # in each class). cm_normalized = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] ax = sns.heatmap(cm_normalized, cmap="bone_r") ax.set_aspect(1) plt.title("Confusion matrix") plt.ylabel("True label") plt.xlabel("Predicted label") plt.show() return classifier 12345678_ = train_linear_classification_model( learning_rate=0.03, steps=1000, batch_size=30, training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... LogLoss error (on validation data): period 00 : 4.39 period 01 : 4.01 period 02 : 3.77 period 03 : 3.84 period 04 : 3.70 period 05 : 3.59 period 06 : 3.65 period 07 : 3.54 period 08 : 3.50 period 09 : 3.55 Model training finished. Final accuracy (on validation data): 0.90 ‰ΩøÁî®Á•ûÁªèÁΩëÁªúÊõøÊç¢Á∫øÊÄßÂàÜÁ±ªÂô®‰ΩøÁî® DNNClassifier ÊõøÊç¢‰∏äÈù¢ÁöÑ LinearClassifierÔºåÂπ∂Êü•ÊâæÂèØÂÆûÁé∞ 0.95 ÊàñÊõ¥È´òÂáÜÁ°ÆÁéáÁöÑÂèÇÊï∞ÁªÑÂêà„ÄÇ ÊÇ®ÂèØËÉΩÂ∏åÊúõÂ∞ùËØï Dropout Á≠âÂÖ∂‰ªñÊ≠£ÂàôÂåñÊñπÊ≥ï„ÄÇËøô‰∫õÈ¢ùÂ§ñÁöÑÊ≠£ÂàôÂåñÊñπÊ≥ïÂ∑≤ËÆ∞ÂΩïÂú® DNNClassifier Á±ªÁöÑÊ≥®Èáä‰∏≠„ÄÇ Èô§‰∫ÜÁ•ûÁªèÁΩëÁªú‰∏ìÁî®ÈÖçÁΩÆÔºà‰æãÂ¶ÇÈöêËóèÂçïÂÖÉÁöÑË∂ÖÂèÇÊï∞Ôºâ‰πãÂ§ñÔºå‰ª•‰∏ã‰ª£Á†Å‰∏éÂéüÂßãÁöÑ LinearClassifer ËÆ≠ÁªÉ‰ª£Á†ÅÂá†‰πéÂÆåÂÖ®Áõ∏Âêå„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126def train_nn_classification_model( learning_rate, steps, batch_size, hidden_units, training_examples, training_targets, validation_examples, validation_targets): """Trains a neural network classification model for the MNIST digits dataset. In addition to training, this function also prints training progress information, a plot of the training and validation loss over time, as well as a confusion matrix. Args: learning_rate: A `float`, the learning rate to use. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. hidden_units: A `list` of int values, specifying the number of neurons in each layer. training_examples: A `DataFrame` containing the training features. training_targets: A `DataFrame` containing the training labels. validation_examples: A `DataFrame` containing the validation features. validation_targets: A `DataFrame` containing the validation labels. Returns: The trained `DNNClassifier` object. """ periods = 10 # Caution: input pipelines are reset with each call to train. # If the number of steps is small, your model may never see most of the data. # So with multiple `.train` calls like this you may want to control the length # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, # or since it's in-memory data, shuffle all the data in the `input_fn`. steps_per_period = steps / periods # Create the input functions. predict_training_input_fn = create_predict_input_fn( training_examples, training_targets, batch_size) predict_validation_input_fn = create_predict_input_fn( validation_examples, validation_targets, batch_size) training_input_fn = create_training_input_fn( training_examples, training_targets, batch_size) # Create feature columns. feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)] # Create a DNNClassifier object. my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) classifier = tf.estimator.DNNClassifier( feature_columns=feature_columns, n_classes=10, hidden_units=hidden_units, optimizer=my_optimizer, config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1) ) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("LogLoss error (on validation data):") training_errors = [] validation_errors = [] for period in range (0, periods): # Train the model, starting from the prior state. classifier.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute probabilities. training_predictions = list(classifier.predict(input_fn=predict_training_input_fn)) training_probabilities = np.array([item['probabilities'] for item in training_predictions]) training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions]) training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10) validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn)) validation_probabilities = np.array([item['probabilities'] for item in validation_predictions]) validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions]) validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10) # Compute training and validation errors. training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot) validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, validation_log_loss)) # Add the loss metrics from this period to our list. training_errors.append(training_log_loss) validation_errors.append(validation_log_loss) print("Model training finished.") # Remove event files to save disk space. _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*'))) # Calculate final predictions (not probabilities, as above). final_predictions = classifier.predict(input_fn=predict_validation_input_fn) final_predictions = np.array([item['class_ids'][0] for item in final_predictions]) accuracy = metrics.accuracy_score(validation_targets, final_predictions) print("Final accuracy (on validation data): %0.2f" % accuracy) # Output a graph of loss metrics over periods. plt.ylabel("LogLoss") plt.xlabel("Periods") plt.title("LogLoss vs. Periods") plt.plot(training_errors, label="training") plt.plot(validation_errors, label="validation") plt.legend() plt.show() # Output a plot of the confusion matrix. cm = metrics.confusion_matrix(validation_targets, final_predictions) # Normalize the confusion matrix by row (i.e by the number of samples # in each class). cm_normalized = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] ax = sns.heatmap(cm_normalized, cmap="bone_r") ax.set_aspect(1) plt.title("Confusion matrix") plt.ylabel("True label") plt.xlabel("Predicted label") plt.show() return classifier 123456789classifier = train_nn_classification_model( learning_rate=0.05, steps=1000, batch_size=30, hidden_units=[100, 100], training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... LogLoss error (on validation data): period 00 : 4.01 period 01 : 3.45 period 02 : 3.01 period 03 : 3.19 period 04 : 2.62 period 05 : 2.29 period 06 : 2.17 period 07 : 2.11 period 08 : 2.06 period 09 : 2.00 Model training finished. Final accuracy (on validation data): 0.94 Êé•‰∏ãÊù•ÔºåÊàë‰ª¨Êù•È™åËØÅÊµãËØïÈõÜÁöÑÂáÜÁ°ÆÁéá„ÄÇ 1234567mnist_test_dataframe = pd.read_csv( "https://download.mlcc.google.cn/mledu-datasets/mnist_test.csv", sep=",", header=None)test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)test_examples.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1 2 3 4 5 6 7 8 9 10 ... 775 776 777 778 779 780 781 782 783 784 count 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 ... 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 10000.0 mean 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 std 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 min 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 25% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 50% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 75% 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 max 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 1.0 1.0 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8 rows √ó 784 columns 12345678predict_test_input_fn = create_predict_input_fn( test_examples, test_targets, batch_size=100)test_predictions = classifier.predict(input_fn=predict_test_input_fn)test_predictions = np.array([item['class_ids'][0] for item in test_predictions]) accuracy = metrics.accuracy_score(test_targets, test_predictions)print("Accuracy on test data: %0.2f" % accuracy) Accuracy on test data: 0.95 ÂèØËßÜÂåñÁ¨¨‰∏Ä‰∏™ÈöêËóèÂ±ÇÁöÑÊùÉÈáç„ÄÇÊàë‰ª¨Êù•Ëä±Âá†ÂàÜÈíüÊó∂Èó¥ÁúãÁúãÊ®°ÂûãÁöÑ weights_ Â±ûÊÄßÔºå‰ª•Ê∑±ÂÖ•Êé¢Á¥¢Êàë‰ª¨ÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂπ∂‰∫ÜËß£ÂÆÉÂ≠¶Âà∞‰∫ÜÂì™‰∫õËßÑÂæã„ÄÇ Ê®°ÂûãÁöÑËæìÂÖ•Â±ÇÊúâ 784 ‰∏™ÊùÉÈáçÔºåÂØπÂ∫î‰∫é 28√ó28 ÂÉèÁ¥†ËæìÂÖ•ÂõæÁâá„ÄÇÁ¨¨‰∏Ä‰∏™ÈöêËóèÂ±ÇÂ∞ÜÊúâ 784√óN ‰∏™ÊùÉÈáçÔºåÂÖ∂‰∏≠ N ÊåáÁöÑÊòØËØ•Â±Ç‰∏≠ÁöÑËäÇÁÇπÊï∞„ÄÇÊàë‰ª¨ÂèØ‰ª•Â∞ÜËøô‰∫õÊùÉÈáçÈáçÊñ∞ÂèòÂõû 28√ó28 ÂÉèÁ¥†ÁöÑÂõæÁâáÔºåÂÖ∑‰ΩìÊñπÊ≥ïÊòØÂ∞Ü N ‰∏™ 1√ó784 ÊùÉÈáçÊï∞ÁªÑÂèòÂΩ¢‰∏∫ N ‰∏™ 28√ó28 Â§ßÂ∞èÊï∞ÁªÑ„ÄÇ ËøêË°å‰ª•‰∏ãÂçïÂÖÉÊ†ºÔºåÁªòÂà∂ÊùÉÈáçÊõ≤Á∫øÂõæ„ÄÇËØ∑Ê≥®ÊÑèÔºåÊ≠§ÂçïÂÖÉÊ†ºË¶ÅÊ±ÇÂêç‰∏∫ ‚Äúclassifier‚Äù ÁöÑ DNNClassifier Â∑≤ÁªèËøáËÆ≠ÁªÉ„ÄÇ 12345678910111213141516print(classifier.get_variable_names())weights0 = classifier.get_variable_value("dnn/hiddenlayer_0/kernel")print("weights0 shape:", weights0.shape)num_nodes = weights0.shape[1]num_rows = int(math.ceil(num_nodes / 10.0))fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))for coef, ax in zip(weights0.T, axes.ravel()): # Weights in coef is reshaped from 1x784 to 28x28. ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink) ax.set_xticks(()) ax.set_yticks(())plt.show() [&apos;dnn/hiddenlayer_0/bias&apos;, &apos;dnn/hiddenlayer_0/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_0/kernel&apos;, &apos;dnn/hiddenlayer_0/kernel/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/bias&apos;, &apos;dnn/hiddenlayer_1/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/kernel&apos;, &apos;dnn/hiddenlayer_1/kernel/t_0/Adagrad&apos;, &apos;dnn/logits/bias&apos;, &apos;dnn/logits/bias/t_0/Adagrad&apos;, &apos;dnn/logits/kernel&apos;, &apos;dnn/logits/kernel/t_0/Adagrad&apos;, &apos;global_step&apos;] weights0 shape: (784, 100) Á•ûÁªèÁΩëÁªúÁöÑÁ¨¨‰∏Ä‰∏™ÈöêËóèÂ±ÇÂ∫îËØ•‰ºöÂØπ‰∏Ä‰∫õÁ∫ßÂà´ÁâπÂà´‰ΩéÁöÑÁâπÂæÅËøõË°åÂª∫Ê®°ÔºåÂõ†Ê≠§ÂèØËßÜÂåñÊùÉÈáçÂèØËÉΩÂè™ÊòæÁ§∫‰∏Ä‰∫õÊ®°Á≥äÁöÑÂå∫ÂüüÔºå‰πüÂèØËÉΩÂè™ÊòæÁ§∫Êï∞Â≠óÁöÑÊüêÂá†‰∏™ÈÉ®ÂàÜ„ÄÇÊ≠§Â§ñÔºåÊÇ®ÂèØËÉΩËøò‰ºöÁúãÂà∞‰∏Ä‰∫õÂü∫Êú¨‰∏äÊòØÂô™ÁÇπÔºàËøô‰∫õÂô™ÁÇπË¶Å‰πà‰∏çÊî∂ÊïõÔºåË¶Å‰πàË¢´Êõ¥È´òÁöÑÂ±ÇÂøΩÁï•ÔºâÁöÑÁ•ûÁªèÂÖÉ„ÄÇ Âú®Ëø≠‰ª£‰∏çÂêåÁöÑÊ¨°Êï∞ÂêéÂÅúÊ≠¢ËÆ≠ÁªÉÂπ∂Êü•ÁúãÊïàÊûúÔºåÂèØËÉΩ‰ºöÂèëÁé∞ÊúâË∂£ÁöÑÁªìÊûú„ÄÇ ÂàÜÂà´Áî® 10„ÄÅ100 Âíå 1000 Ê≠•ËÆ≠ÁªÉÂàÜÁ±ªÂô®„ÄÇÁÑ∂ÂêéÈáçÊñ∞ËøêË°åÊ≠§ÂèØËßÜÂåñ„ÄÇ ÊÇ®ÁúãÂà∞‰∏çÂêåÁ∫ßÂà´ÁöÑÊî∂Êïõ‰πãÈó¥ÊúâÂì™‰∫õÁõ¥ËßÇ‰∏äÁöÑÂ∑ÆÂºÇÔºü 123456789classifier = train_nn_classification_model( learning_rate=0.05, steps=10, batch_size=30, hidden_units=[100, 100], training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... LogLoss error (on validation data): period 00 : 29.18 period 01 : 28.72 period 02 : 21.72 period 03 : 27.76 period 04 : 21.00 period 05 : 22.31 period 06 : 17.28 period 07 : 15.51 period 08 : 20.03 period 09 : 13.90 Model training finished. Final accuracy (on validation data): 0.60 12345678910111213141516print(classifier.get_variable_names())weights0 = classifier.get_variable_value("dnn/hiddenlayer_0/kernel")print("weights0 shape:", weights0.shape)num_nodes = weights0.shape[1]num_rows = int(math.ceil(num_nodes / 10.0))fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))for coef, ax in zip(weights0.T, axes.ravel()): # Weights in coef is reshaped from 1x784 to 28x28. ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink) ax.set_xticks(()) ax.set_yticks(())plt.show() [&apos;dnn/hiddenlayer_0/bias&apos;, &apos;dnn/hiddenlayer_0/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_0/kernel&apos;, &apos;dnn/hiddenlayer_0/kernel/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/bias&apos;, &apos;dnn/hiddenlayer_1/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/kernel&apos;, &apos;dnn/hiddenlayer_1/kernel/t_0/Adagrad&apos;, &apos;dnn/logits/bias&apos;, &apos;dnn/logits/bias/t_0/Adagrad&apos;, &apos;dnn/logits/kernel&apos;, &apos;dnn/logits/kernel/t_0/Adagrad&apos;, &apos;global_step&apos;] weights0 shape: (784, 100) 123456789classifier = train_nn_classification_model( learning_rate=0.05, steps=100, batch_size=30, hidden_units=[100, 100], training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... LogLoss error (on validation data): period 00 : 18.72 period 01 : 10.71 period 02 : 7.58 period 03 : 8.70 period 04 : 5.79 period 05 : 5.21 period 06 : 5.40 period 07 : 6.05 period 08 : 5.75 period 09 : 3.95 Model training finished. Final accuracy (on validation data): 0.89 12345678910111213141516print(classifier.get_variable_names())weights0 = classifier.get_variable_value("dnn/hiddenlayer_0/kernel")print("weights0 shape:", weights0.shape)num_nodes = weights0.shape[1]num_rows = int(math.ceil(num_nodes / 10.0))fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))for coef, ax in zip(weights0.T, axes.ravel()): # Weights in coef is reshaped from 1x784 to 28x28. ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink) ax.set_xticks(()) ax.set_yticks(())plt.show() [&apos;dnn/hiddenlayer_0/bias&apos;, &apos;dnn/hiddenlayer_0/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_0/kernel&apos;, &apos;dnn/hiddenlayer_0/kernel/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/bias&apos;, &apos;dnn/hiddenlayer_1/bias/t_0/Adagrad&apos;, &apos;dnn/hiddenlayer_1/kernel&apos;, &apos;dnn/hiddenlayer_1/kernel/t_0/Adagrad&apos;, &apos;dnn/logits/bias&apos;, &apos;dnn/logits/bias/t_0/Adagrad&apos;, &apos;dnn/logits/kernel&apos;, &apos;dnn/logits/kernel/t_0/Adagrad&apos;, &apos;global_step&apos;] weights0 shape: (784, 100)]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 8]]></title>
    <url>%2F2019%2F02%2F20%2FTensorFlow_8%2F</url>
    <content type="text"><![CDATA[Á•ûÁªèÁΩëÁªúÁÆÄ‰ªã ‰ΩøÁî® TensorFlow DNNRegressor Á±ªÂÆö‰πâÁ•ûÁªèÁΩëÁªú (NN) ÂèäÂÖ∂ÈöêËóèÂ±Ç ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÂ≠¶‰π†Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÈùûÁ∫øÊÄßËßÑÂæãÔºåÂπ∂ÂÆûÁé∞ÊØîÁ∫øÊÄßÂõûÂΩíÊ®°ÂûãÊõ¥Â•ΩÁöÑÊïàÊûú Âú®‰πãÂâçÁöÑÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®ÂêàÊàêÁâπÂæÅÊù•Â∏ÆÂä©Ê®°ÂûãÂ≠¶‰π†ÈùûÁ∫øÊÄßËßÑÂæã„ÄÇ ‰∏ÄÁªÑÈáçË¶ÅÁöÑÈùûÁ∫øÊÄßÂÖ≥Á≥ªÊòØÁ∫¨Â∫¶ÂíåÁªèÂ∫¶ÁöÑÂÖ≥Á≥ªÔºå‰ΩÜ‰πüÂèØËÉΩÂ≠òÂú®ÂÖ∂‰ªñÈùûÁ∫øÊÄßÂÖ≥Á≥ª„ÄÇ Áé∞Âú®Êàë‰ª¨‰ªé‰πãÂâçÁªÉ‰π†‰∏≠ÁöÑÈÄªËæëÂõûÂΩí‰ªªÂä°ÂõûÂà∞Ê†áÂáÜÁöÑÔºàÁ∫øÊÄßÔºâÂõûÂΩí‰ªªÂä°„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÊàë‰ª¨Â∞ÜÁõ¥Êé•È¢ÑÊµã median_house_value„ÄÇ ËÆæÁΩÆÂä†ËΩΩÊï∞ÊçÆÂπ∂ÂàõÂª∫ÁâπÂæÅÂÆö‰πâ„ÄÇ 12345678910111213141516171819202122from __future__ import print_functionimport mathfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10pd.options.display.float_format = '&#123;:.1f&#125;'.formatcalifornia_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",")california_housing_dataframe = california_housing_dataframe.reindex( np.random.permutation(california_housing_dataframe.index)) 12345678910111213141516171819202122232425262728293031323334353637383940def preprocess_features(california_housing_dataframe): """Prepares input features from California housing data set. Args: california_housing_dataframe: A Pandas DataFrame expected to contain data from the California housing data set. Returns: A DataFrame that contains the features to be used for the model, including synthetic features. """ selected_features = california_housing_dataframe[ ["latitude", "longitude", "housing_median_age", "total_rooms", "total_bedrooms", "population", "households", "median_income"]] processed_features = selected_features.copy() # Create a synthetic feature. processed_features["rooms_per_person"] = ( california_housing_dataframe["total_rooms"] / california_housing_dataframe["population"]) return processed_featuresdef preprocess_targets(california_housing_dataframe): """Prepares target features (i.e., labels) from California housing data set. Args: california_housing_dataframe: A Pandas DataFrame expected to contain data from the California housing data set. Returns: A DataFrame that contains the target feature. """ output_targets = pd.DataFrame() # Scale the target to be in units of thousands of dollars. output_targets["median_house_value"] = ( california_housing_dataframe["median_house_value"] / 1000.0) return output_targets 123456789101112131415161718# Choose the first 12000 (out of 17000) examples for training.training_examples = preprocess_features(california_housing_dataframe.head(12000))training_targets = preprocess_targets(california_housing_dataframe.head(12000))# Choose the last 5000 (out of 17000) examples for validation.validation_examples = preprocess_features(california_housing_dataframe.tail(5000))validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))# Double-check that we've done the right thing.print("Training examples summary:")display.display(training_examples.describe())print("Validation examples summary:")display.display(validation_examples.describe())print("Training targets summary:")display.display(training_targets.describe())print("Validation targets summary:")display.display(validation_targets.describe()) Training examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 mean 35.6 -119.6 28.7 2636.9 537.9 1429.2 500.3 3.9 2.0 std 2.1 2.0 12.5 2187.4 422.5 1168.5 387.3 1.9 1.1 min 32.5 -124.3 1.0 2.0 1.0 3.0 1.0 0.5 0.0 25% 33.9 -121.8 18.0 1461.0 296.8 788.0 281.0 2.6 1.5 50% 34.2 -118.5 29.0 2116.0 431.0 1165.0 407.5 3.5 1.9 75% 37.7 -118.0 37.0 3127.0 645.0 1713.0 601.0 4.8 2.3 max 42.0 -114.3 52.0 37937.0 6445.0 35682.0 6082.0 15.0 55.2 Validation examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 mean 35.6 -119.6 28.4 2659.9 542.9 1430.4 503.5 3.9 2.0 std 2.1 2.0 12.9 2162.0 419.1 1096.8 377.9 1.9 1.3 min 32.6 -124.3 2.0 15.0 4.0 8.0 2.0 0.5 0.1 25% 33.9 -121.8 18.0 1465.8 297.0 793.0 283.0 2.6 1.5 50% 34.2 -118.5 28.0 2154.5 439.0 1173.0 413.0 3.5 1.9 75% 37.7 -118.0 37.0 3216.0 658.2 1738.0 614.0 4.7 2.3 max 41.9 -114.6 52.0 30401.0 4957.0 13251.0 4339.0 15.0 52.0 Training targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 12000.0 mean 206.6 std 115.5 min 15.0 25% 119.2 50% 180.8 75% 263.3 max 500.0 Validation targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 5000.0 mean 208.9 std 117.0 min 15.0 25% 120.2 50% 179.2 75% 268.3 max 500.0 ÊûÑÂª∫Á•ûÁªèÁΩëÁªúÁ•ûÁªèÁΩëÁªúÁî± DNNRegressor Á±ªÂÆö‰πâ„ÄÇ ‰ΩøÁî® hidden_units ÂÆö‰πâÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑ„ÄÇhidden_units ÂèÇÊï∞‰ºöÂàõÂª∫‰∏Ä‰∏™Êï¥Êï∞ÂàóË°®ÔºåÂÖ∂‰∏≠ÊØè‰∏™Êï¥Êï∞ÂØπÂ∫î‰∏Ä‰∏™ÈöêËóèÂ±ÇÔºåË°®Á§∫ÂÖ∂‰∏≠ÁöÑËäÇÁÇπÊï∞„ÄÇ‰ª•‰∏ãÈù¢ÁöÑËµãÂÄº‰∏∫‰æãÔºö hidden_units=[3,10] ‰∏äËø∞ËµãÂÄº‰∏∫Á•ûÁªèÁΩëÁªúÊåáÂÆö‰∫Ü‰∏§‰∏™ÈöêËóèÂ±ÇÔºö Á¨¨‰∏Ä‰∏™ÈöêËóèÂ±ÇÂåÖÂê´ 3 ‰∏™ËäÇÁÇπ„ÄÇ Á¨¨‰∫å‰∏™ÈöêËóèÂ±ÇÂåÖÂê´ 10 ‰∏™ËäÇÁÇπ„ÄÇ Â¶ÇÊûúÊàë‰ª¨ÊÉ≥Ë¶ÅÊ∑ªÂä†Êõ¥Â§öÂ±ÇÔºåÂèØ‰ª•ÂêëËØ•ÂàóË°®Ê∑ªÂä†Êõ¥Â§öÊï¥Êï∞„ÄÇ‰æãÂ¶ÇÔºåhidden_units=[10,20,30,40] ‰ºöÂàõÂª∫ 4 ‰∏™ÂàÜÂà´ÂåÖÂê´ 10„ÄÅ20„ÄÅ30 Âíå 40 ‰∏™ÂçïÂÖÉÁöÑÈöêËóèÂ±Ç„ÄÇ ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåÊâÄÊúâÈöêËóèÂ±ÇÈÉΩ‰ºö‰ΩøÁî® ReLu ÊøÄÊ¥ªÂáΩÊï∞Ôºå‰∏îÊòØÂÖ®ËøûÊé•Â±Ç„ÄÇ 1234567891011121314151617181920212223242526272829303132333435363738def construct_feature_columns(input_features): """Construct the TensorFlow Feature Columns. Args: input_features: The names of the numerical input features to use. Returns: A set of feature columns """ return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features])def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): """Trains a neural net regression model. Args: features: pandas DataFrame of features targets: pandas DataFrame of targets batch_size: Size of batches to be passed to the model shuffle: True or False. Whether to shuffle the data. num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely Returns: Tuple of (features, labels) for next data batch """ # Convert pandas data into a dict of np arrays. features = &#123;key:np.array(value) for key,value in dict(features).items()&#125; # Construct a dataset, and configure batching/repeating. ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit ds = ds.batch(batch_size).repeat(num_epochs) # Shuffle the data, if specified. if shuffle: ds = ds.shuffle(10000) # Return the next batch of data. features, labels = ds.make_one_shot_iterator().get_next() return features, labels 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104def train_nn_regression_model( learning_rate, steps, batch_size, hidden_units, training_examples, training_targets, validation_examples, validation_targets): """Trains a neural network regression model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: learning_rate: A `float`, the learning rate. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. hidden_units: A `list` of int values, specifying the number of neurons in each layer. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A `DNNRegressor` object trained on the training data. """ periods = 10 steps_per_period = steps / periods # Create a DNNRrgressor object. my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) dnn_regressor = tf.estimator.DNNRegressor( feature_columns=construct_feature_columns(training_examples), hidden_units=hidden_units, optimizer=my_optimizer ) # Create input functions. training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range(0, periods): # train the model, starting from the prior state. dnn_regressor.train( input_fn=training_input_fn, steps=steps_per_period ) # take abreak and compute perdictions. training_predictions = dnn_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = dnn_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # compute training an validation loss training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() print("Final RMSE (on training data): %0.2f" % training_root_mean_squared_error) print("Final RMSE (on validation data): %0.2f" % validation_root_mean_squared_error) return dnn_regressor ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÊ®°ÂûãË∞ÉÊï¥Ë∂ÖÂèÇÊï∞ÔºåÁõÆÊ†áÊòØÂ∞Ü RMSE ÈôçÂà∞ 110 ‰ª•‰∏ã„ÄÇ Êàë‰ª¨Â∑≤ÁªèÁü•ÈÅìÔºåÂú®‰ΩøÁî®‰∫ÜÂæàÂ§öÁâπÂæÅÁöÑÁ∫øÊÄßÂõûÂΩíÁªÉ‰π†‰∏≠Ôºå110 Â∑¶Âè≥ÁöÑ RMSE Â∑≤ÁªèÊòØÁõ∏ÂΩì‰∏çÈîôÁöÑÁªìÊûú„ÄÇÁé∞Âú®Êàë‰ª¨Â∞ÜÂæóÂà∞ÊØîÂÆÉÊõ¥Â•ΩÁöÑÁªìÊûú„ÄÇ ÂØπ‰∫éÁ•ûÁªèÁΩëÁªúËÄåË®ÄÔºåËøáÊãüÂêàÊòØ‰∏ÄÁßçÁúüÊ≠£ÁöÑÊΩúÂú®Âç±Èô©„ÄÇÊÇ®ÂèØ‰ª•Êü•ÁúãËÆ≠ÁªÉÊï∞ÊçÆÊçüÂ§±‰∏éÈ™åËØÅÊï∞ÊçÆÊçüÂ§±‰πãÈó¥ÁöÑÂ∑ÆÂÄºÔºå‰ª•Â∏ÆÂä©Âà§Êñ≠Ê®°ÂûãÊòØÂê¶ÊúâËøáÊãüÂêàÁöÑË∂ãÂäø„ÄÇÂ¶ÇÊûúÂ∑ÆÂÄºÂºÄÂßãÂèòÂ§ßÔºåÂàôÈÄöÂ∏∏ÂèØ‰ª•ËÇØÂÆöÂ≠òÂú®ËøáÊãüÂêà„ÄÇ ‰∏ãÈù¢ÂèÇÊï∞ÊòØÊàëÂÜôÁöÑÔºå‰πüËÆ∏ÊúâÊõ¥Â•ΩÁöÑÂèÇÊï∞‰ºöËé∑ÂæóÊõ¥‰ΩéÁöÑRMSE„ÄÇ 123456789dnn_regressor = train_nn_regression_model( learning_rate=0.002, steps=2000, batch_size=100, hidden_units=[8, 10], training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 153.67 period 01 : 136.38 period 02 : 119.26 period 03 : 106.87 period 04 : 107.80 period 05 : 106.81 period 06 : 107.47 period 07 : 109.00 period 08 : 104.58 period 09 : 106.55 Model training finished. Final RMSE (on training data): 106.55 Final RMSE (on validation data): 106.82 Áî®ÊµãËØïÊï∞ÊçÆËøõË°åËØÑ‰º∞Á°ÆËÆ§È™åËØÅÊïàÊûúÁªìÊûúÁªèÂèóÂæó‰ΩèÊµãËØïÊï∞ÊçÆÁöÑÊ£ÄÈ™å„ÄÇ Ëé∑ÂæóÊª°ÊÑèÁöÑÊ®°ÂûãÂêéÔºåÁî®ÊµãËØïÊï∞ÊçÆËØÑ‰º∞ËØ•Ê®°ÂûãÔºå‰ª•‰∏éÈ™åËØÅÊïàÊûúËøõË°åÊØîËæÉ„ÄÇ ÊµãËØïÊï∞ÊçÆÈõÜ‰Ωç‰∫éÊ≠§Â§Ñ„ÄÇ 1234567891011121314151617california_housing_test_data = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_test.csv", sep=",")test_examples = preprocess_features(california_housing_test_data)test_targets = preprocess_targets(california_housing_test_data)predict_testing_input_fn = lambda: my_input_fn(test_examples, test_targets["median_house_value"], num_epochs=1, shuffle=False)test_predictions = dnn_regressor.predict(input_fn=predict_testing_input_fn)test_predictions = np.array([item['predictions'][0] for item in test_predictions])root_mean_squared_error = math.sqrt( metrics.mean_squared_error(test_predictions, test_targets))print("Final RMSE (on test data): %0.2f" % root_mean_squared_error) Final RMSE (on test data): 105.23 ÊèêÈ´òÁ•ûÁªèÁΩëÁªúÊÄßËÉΩ ÈÄöËøáÂ∞ÜÁâπÂæÅÊ†áÂáÜÂåñÂπ∂Â∫îÁî®ÂêÑÁßç‰ºòÂåñÁÆóÊ≥ïÊù•ÊèêÈ´òÁ•ûÁªèÁΩëÁªúÁöÑÊÄßËÉΩ Ê≥®ÊÑèÔºöÊú¨ÁªÉ‰π†‰∏≠‰ªãÁªçÁöÑ‰ºòÂåñÊñπÊ≥ïÂπ∂Èùû‰∏ìÈó®ÈíàÂØπÁ•ûÁªèÁΩëÁªúÔºõËøô‰∫õÊñπÊ≥ïÂèØÊúâÊïàÊîπËøõÂ§ßÂ§öÊï∞Á±ªÂûãÁöÑÊ®°Âûã„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104def train_nn_regression_model_optimize( my_optimizer, steps, batch_size, hidden_units, training_examples, training_targets, validation_examples, validation_targets): """Trains a neural network regression model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: my_optimizer: An instance of `tf.train.Optimizer`, the optimizer to use. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. hidden_units: A `list` of int values, specifying the number of neurons in each layer. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A tuple `(estimator, training_losses, validation_losses)`: estimator: the trained `DNNRegressor` object. training_losses: a `list` containing the training loss values taken during training. validation_losses: a `list` containing the validation loss values taken during training. """ periods = 10 steps_per_period = steps / periods # Create a DNNRegressor object. my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) dnn_regressor = tf.estimator.DNNRegressor( feature_columns=construct_feature_columns(training_examples), hidden_units=hidden_units, optimizer=my_optimizer ) # Create input functions. training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range (0, periods): # Train the model, starting from the prior state. dnn_regressor.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute predictions. training_predictions = dnn_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = dnn_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # Compute training and validation loss. training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() print("Final RMSE (on training data): %0.2f" % training_root_mean_squared_error) print("Final RMSE (on validation data): %0.2f" % validation_root_mean_squared_error) return dnn_regressor, training_rmse, validation_rmse 123456789_ = train_nn_regression_model_optimize( my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0007), steps=5000, batch_size=70, hidden_units=[10, 10], training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 162.48 period 01 : 157.66 period 02 : 150.85 period 03 : 142.03 period 04 : 131.60 period 05 : 120.72 period 06 : 113.46 period 07 : 110.01 period 08 : 108.28 period 09 : 107.34 Model training finished. Final RMSE (on training data): 107.34 Final RMSE (on validation data): 108.43 Á∫øÊÄßÁº©ÊîæÂ∞ÜËæìÂÖ•Ê†áÂáÜÂåñ‰ª•‰ΩøÂÖ∂‰Ωç‰∫é (-1, 1) ËåÉÂõ¥ÂÜÖÂèØËÉΩÊòØ‰∏ÄÁßçËâØÂ•ΩÁöÑÊ†áÂáÜÂÅöÊ≥ï„ÄÇËøôÊ†∑‰∏ÄÊù•ÔºåSGD Âú®‰∏Ä‰∏™Áª¥Â∫¶‰∏≠ÈááÁî®ÂæàÂ§ßÊ≠•ÈïøÔºàÊàñËÄÖÂú®Âè¶‰∏ÄÁª¥Â∫¶‰∏≠ÈááÁî®ÂæàÂ∞èÊ≠•ÈïøÔºâÊó∂‰∏ç‰ºöÂèóÈòª„ÄÇÊï∞ÂÄº‰ºòÂåñÁöÑÁà±Â•ΩËÄÖÂèØËÉΩ‰ºöÊ≥®ÊÑèÂà∞ÔºåËøôÁßçÂÅöÊ≥ï‰∏é‰ΩøÁî®È¢ÑË∞ÉËäÇÂô® (Preconditioner) ÁöÑÊÉ≥Ê≥ïÊòØÊúâËÅîÁ≥ªÁöÑ„ÄÇ 12345def linear_scale(series): min_val = series.min() max_val = series.max() scale = (max_val - min_val) / 2.0 return series.apply(lambda x:((x - min_val) / scale) - 1.0) ‰ΩøÁî®Á∫øÊÄßÁº©ÊîæÂ∞ÜÁâπÂæÅÊ†áÂáÜÂåñÂ∞ÜËæìÂÖ•Ê†áÂáÜÂåñÂà∞ (-1, 1) Ëøô‰∏ÄËåÉÂõ¥ÂÜÖ„ÄÇËÉΩËææÂà∞‰ªÄ‰πàÁ®ãÂ∫¶ÁöÑÊïàÊûúÔºü ‰∏ÄËà¨Êù•ËØ¥ÔºåÂΩìËæìÂÖ•ÁâπÂæÅÂ§ßËá¥‰Ωç‰∫éÁõ∏ÂêåËåÉÂõ¥Êó∂ÔºåÁ•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉÊïàÊûúÊúÄÂ•Ω„ÄÇ ÂØπÊÇ®ÁöÑÊ†áÂáÜÂåñÊï∞ÊçÆËøõË°åÂÅ•ÂÖ®ÊÄßÊ£ÄÊü•„ÄÇÔºàÂ¶ÇÊûúÊÇ®Âøò‰∫ÜÂ∞ÜÊüê‰∏™ÁâπÂæÅÊ†áÂáÜÂåñÔºå‰ºöÂèëÁîü‰ªÄ‰πàÊÉÖÂÜµÔºüÔºâ Áî±‰∫éÊ†áÂáÜÂåñ‰ºö‰ΩøÁî®ÊúÄÂ∞èÂÄºÂíåÊúÄÂ§ßÂÄºÔºåÊàë‰ª¨ÂøÖÈ°ªÁ°Æ‰øùÂú®Êï¥‰∏™Êï∞ÊçÆÈõÜ‰∏≠‰∏ÄÊ¨°ÊÄßÂÆåÊàêËØ•Êìç‰Ωú„ÄÇ Êàë‰ª¨‰πãÊâÄ‰ª•ÂèØ‰ª•ËøôÊ†∑ÂÅöÔºåÊòØÂõ†‰∏∫Êàë‰ª¨ÊâÄÊúâÁöÑÊï∞ÊçÆÈÉΩÂú®‰∏Ä‰∏™ DataFrame ‰∏≠„ÄÇÂ¶ÇÊûúÊàë‰ª¨ÊúâÂ§ö‰∏™Êï∞ÊçÆÈõÜÔºåÂàôÊúÄÂ•Ω‰ªéËÆ≠ÁªÉÈõÜ‰∏≠ÂØºÂá∫Ê†áÂáÜÂåñÂèÇÊï∞ÔºåÁÑ∂Âêé‰ª•Áõ∏ÂêåÊñπÂºèÂ∞ÜÂÖ∂Â∫îÁî®‰∫éÊµãËØïÈõÜ„ÄÇ 123456789101112131415161718192021222324252627def normalize_linear_scale(examples_dataframe): """Returns a version of the input `DataFrame` that has all its features normalized linearly.""" processed_features = pd.DataFrame() processed_features["latitude"] = linear_scale(examples_dataframe["latitude"]) processed_features["longitude"] = linear_scale(examples_dataframe["longitude"]) processed_features["housing_median_age"] = linear_scale(examples_dataframe["housing_median_age"]) processed_features["total_rooms"] = linear_scale(examples_dataframe["total_rooms"]) processed_features["total_bedrooms"] = linear_scale(examples_dataframe["total_bedrooms"]) processed_features["population"] = linear_scale(examples_dataframe["population"]) processed_features["households"] = linear_scale(examples_dataframe["households"]) processed_features["median_income"] = linear_scale(examples_dataframe["median_income"]) processed_features["rooms_per_person"] = linear_scale(examples_dataframe["rooms_per_person"]) return processed_featuresnormalized_dataframe = normalize_linear_scale(preprocess_features(california_housing_dataframe))normalized_training_examples = normalized_dataframe.head(12000)normalized_validation_examples = normalized_dataframe.tail(5000)_ = train_nn_regression_model_optimize( my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.005), steps=2000, batch_size=50, hidden_units=[10, 10], training_examples=normalized_training_examples, training_targets=training_targets, validation_examples=normalized_validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 163.23 period 01 : 115.65 period 02 : 106.20 period 03 : 91.27 period 04 : 79.65 period 05 : 76.10 period 06 : 74.00 period 07 : 72.52 period 08 : 71.52 period 09 : 70.72 Model training finished. Final RMSE (on training data): 70.72 Final RMSE (on validation data): 72.52 Â∞ùËØïÂÖ∂‰ªñ‰ºòÂåñÂô® ‰ΩøÁî® AdaGrad Âíå Adam ‰ºòÂåñÂô®Âπ∂ÂØπÊØîÂÖ∂ÊïàÊûú„ÄÇ AdaGrad ‰ºòÂåñÂô®ÊòØ‰∏ÄÁßçÂ§áÈÄâÊñπÊ°à„ÄÇAdaGrad ÁöÑÊ†∏ÂøÉÊòØÁÅµÊ¥ªÂú∞‰øÆÊîπÊ®°Âûã‰∏≠ÊØè‰∏™Á≥ªÊï∞ÁöÑÂ≠¶‰π†ÁéáÔºå‰ªéËÄåÂçïË∞ÉÈôç‰ΩéÊúâÊïàÁöÑÂ≠¶‰π†Áéá„ÄÇËØ•‰ºòÂåñÂô®ÂØπ‰∫éÂá∏‰ºòÂåñÈóÆÈ¢òÈùûÂ∏∏ÊúâÊïàÔºå‰ΩÜ‰∏ç‰∏ÄÂÆöÈÄÇÂêàÈùûÂá∏‰ºòÂåñÈóÆÈ¢òÁöÑÁ•ûÁªèÁΩëÁªúËÆ≠ÁªÉ„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøáÊåáÂÆö AdagradOptimizerÔºàËÄå‰∏çÊòØ GradientDescentOptimizerÔºâÊù•‰ΩøÁî® AdaGrad„ÄÇËØ∑Ê≥®ÊÑèÔºåÂØπ‰∫é AdaGradÔºåÊÇ®ÂèØËÉΩÈúÄË¶Å‰ΩøÁî®ËæÉÂ§ßÁöÑÂ≠¶‰π†Áéá„ÄÇ ÂØπ‰∫éÈùûÂá∏‰ºòÂåñÈóÆÈ¢òÔºåAdam ÊúâÊó∂ÊØî AdaGrad Êõ¥ÊúâÊïà„ÄÇË¶Å‰ΩøÁî® AdamÔºåËØ∑Ë∞ÉÁî® tf.train.AdamOptimizer ÊñπÊ≥ï„ÄÇÊ≠§ÊñπÊ≥ïÂ∞ÜÂá†‰∏™ÂèØÈÄâË∂ÖÂèÇÊï∞‰Ωú‰∏∫ÂèÇÊï∞Ôºå‰ΩÜÊàë‰ª¨ÁöÑËß£ÂÜ≥ÊñπÊ°à‰ªÖÊåáÂÆöÂÖ∂‰∏≠‰∏Ä‰∏™ (learning_rate)„ÄÇÂú®Â∫îÁî®ËÆæÁΩÆ‰∏≠ÔºåÊÇ®Â∫îËØ•Ë∞®ÊÖéÊåáÂÆöÂíåË∞ÉÊï¥ÂèØÈÄâË∂ÖÂèÇÊï∞„ÄÇ 12345678910# È¶ñÂÖàÔºåÊàë‰ª¨Êù•Â∞ùËØï AdaGrad„ÄÇ_, adagrad_training_losses, adagrad_validation_losses = train_nn_regression_model_optimize( my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.5), steps=500, batch_size=100, hidden_units=[10, 10], training_examples=normalized_training_examples, training_targets=training_targets, validation_examples=normalized_validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 84.89 period 01 : 72.08 period 02 : 71.06 period 03 : 71.18 period 04 : 69.57 period 05 : 72.57 period 06 : 69.04 period 07 : 67.49 period 08 : 68.83 period 09 : 69.24 Model training finished. Final RMSE (on training data): 69.24 Final RMSE (on validation data): 71.91 12345678910 # Áé∞Âú®ÔºåÊàë‰ª¨Êù•Â∞ùËØï Adam„ÄÇ_, adam_training_losses, adam_validation_losses = train_nn_regression_model_optimize( my_optimizer=tf.train.AdamOptimizer(learning_rate=0.009), steps=500, batch_size=100, hidden_units=[10, 10], training_examples=normalized_training_examples, training_targets=training_targets, validation_examples=normalized_validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 171.53 period 01 : 108.88 period 02 : 100.89 period 03 : 88.85 period 04 : 76.59 period 05 : 72.77 period 06 : 70.84 period 07 : 70.29 period 08 : 69.79 period 09 : 68.84 Model training finished. Final RMSE (on training data): 68.84 Final RMSE (on validation data): 70.98 123456789# Êàë‰ª¨Âπ∂ÊéíËæìÂá∫ÊçüÂ§±ÊåáÊ†áÁöÑÂõæË°®„ÄÇplt.ylabel("RMSE")plt.xlabel("Periods")plt.title("Root Mean Squared Error vs. Periods")plt.plot(adagrad_training_losses, label='Adagrad training')plt.plot(adagrad_validation_losses, label='Adagrad validation')plt.plot(adam_training_losses, label='Adam training')plt.plot(adam_validation_losses, label='Adam validation')_ = plt.legend() Â∞ùËØïÂÖ∂‰ªñÊ†áÂáÜÂåñÊñπÊ≥ïÂ∞ùËØïÂØπÂêÑÁßçÁâπÂæÅ‰ΩøÁî®ÂÖ∂‰ªñÊ†áÂáÜÂåñÊñπÊ≥ïÔºå‰ª•Ëøõ‰∏ÄÊ≠•ÊèêÈ´òÊÄßËÉΩ„ÄÇ Â¶ÇÊûú‰ªîÁªÜÊü•ÁúãËΩ¨Êç¢ÂêéÊï∞ÊçÆÁöÑÊ±áÊÄªÁªüËÆ°‰ø°ÊÅØÔºåÊÇ®ÂèØËÉΩ‰ºöÊ≥®ÊÑèÂà∞ÔºåÂØπÊüê‰∫õÁâπÂæÅËøõË°åÁ∫øÊÄßÁº©Êîæ‰ºö‰ΩøÂÖ∂ËÅöÈõÜÂà∞Êé•Ëøë -1 ÁöÑ‰ΩçÁΩÆ„ÄÇ ‰æãÂ¶ÇÔºåÂæàÂ§öÁâπÂæÅÁöÑ‰∏≠‰ΩçÊï∞Á∫¶‰∏∫ -0.8ÔºåËÄå‰∏çÊòØ 0.0„ÄÇ 1_ = training_examples.hist(bins=20, figsize=(18, 12), xlabelsize=2) ÈÄöËøáÈÄâÊã©ÂÖ∂‰ªñÊñπÂºèÊù•ËΩ¨Êç¢Ëøô‰∫õÁâπÂæÅÔºåÊàë‰ª¨ÂèØËÉΩ‰ºöËé∑ÂæóÊõ¥Â•ΩÁöÑÊïàÊûú„ÄÇ ‰æãÂ¶ÇÔºåÂØπÊï∞Áº©ÊîæÂèØËÉΩÂØπÊüê‰∫õÁâπÂæÅÊúâÂ∏ÆÂä©„ÄÇÊàñËÄÖÔºåÊà™ÂèñÊûÅÁ´ØÂÄºÂèØËÉΩ‰ºö‰ΩøÂâ©‰ΩôÈÉ®ÂàÜÁöÑ‰ø°ÊÅØÊõ¥Âä†‰∏∞ÂØå„ÄÇ 1234567891011121314def log_normalize(series): return series.apply(lambda x:math.log(x+1.0))def clip(series, clip_to_min, clip_to_max): return series.apply(lambda x:( min(max(x, clip_to_min), clip_to_max)))def z_score_normalize(series): mean = series.mean() std_dv = series.std() return series.apply(lambda x:(x - mean) / std_dv)def binary_threshold(series, threshold): return series.apply(lambda x:(1 if x &gt; threshold else 0)) ‰∏äËø∞ÈÉ®ÂàÜÂåÖÂê´‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÊ†áÂáÜÂåñÂáΩÊï∞„ÄÇ ËØ∑Ê≥®ÊÑèÔºåÂ¶ÇÊûúÊÇ®Â∞ÜÁõÆÊ†áÊ†áÂáÜÂåñÔºåÂàôÈúÄË¶ÅÂ∞ÜÁΩëÁªúÁöÑÈ¢ÑÊµãÁªìÊûúÈùûÊ†áÂáÜÂåñÔºå‰ª•‰æøÊØîËæÉÊçüÂ§±ÂáΩÊï∞ÁöÑÂÄº„ÄÇ 12345678910111213141516171819202122232425262728293031def normalize(examples_dataframe): """Returns a version of the input `DataFrame` that has all its features normalized.""" processed_features = pd.DataFrame() processed_features["households"] = log_normalize(examples_dataframe["households"]) processed_features["median_income"] = log_normalize(examples_dataframe["median_income"]) processed_features["total_bedrooms"] = log_normalize(examples_dataframe["total_bedrooms"]) processed_features["latitude"] = linear_scale(examples_dataframe["latitude"]) processed_features["longitude"] = linear_scale(examples_dataframe["longitude"]) processed_features["housing_median_age"] = linear_scale(examples_dataframe["housing_median_age"]) processed_features["population"] = linear_scale(clip(examples_dataframe["population"], 0, 5000)) processed_features["rooms_per_person"] = linear_scale(clip(examples_dataframe["rooms_per_person"], 0, 5)) processed_features["total_rooms"] = linear_scale(clip(examples_dataframe["total_rooms"], 0, 10000)) return processed_featuresnormalized_dataframe = normalize(preprocess_features(california_housing_dataframe))normalized_training_examples = normalized_dataframe.head(12000)normalized_validation_examples = normalized_dataframe.tail(5000)_ = train_nn_regression_model_optimize( my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.15), steps=1000, batch_size=50, hidden_units=[10, 10], training_examples=normalized_training_examples, training_targets=training_targets, validation_examples=normalized_validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 89.38 period 01 : 75.15 period 02 : 72.35 period 03 : 70.70 period 04 : 70.95 period 05 : 69.13 period 06 : 68.46 period 07 : 68.42 period 08 : 68.68 period 09 : 67.93 Model training finished. Final RMSE (on training data): 67.93 Final RMSE (on validation data): 69.55 ‰ªÖ‰ΩøÁî®Á∫¨Â∫¶ÂíåÁªèÂ∫¶ÁâπÂæÅËÆ≠ÁªÉ‰ªÖ‰ΩøÁî®Á∫¨Â∫¶ÂíåÁªèÂ∫¶‰Ωú‰∏∫ÁâπÂæÅÁöÑÁ•ûÁªèÁΩëÁªúÊ®°Âûã„ÄÇ ÊàøÂú∞‰∫ßÂïÜÂñúÊ¨¢ËØ¥ÔºåÂú∞ÊÆµÊòØÊàø‰ª∑ÁöÑÂîØ‰∏ÄÈáçË¶ÅÁâπÂæÅ„ÄÇÊàë‰ª¨Êù•ÁúãÁúãËÉΩÂê¶ÈÄöËøáËÆ≠ÁªÉ‰ªÖ‰ΩøÁî®Á∫¨Â∫¶ÂíåÁªèÂ∫¶‰Ωú‰∏∫ÁâπÂæÅÁöÑÊ®°ÂûãÊù•ËØÅÂÆûËøô‰∏ÄÁÇπ„ÄÇ Âè™ÊúâÊàë‰ª¨ÁöÑÁ•ûÁªèÁΩëÁªúÊ®°ÂûãÂèØ‰ª•‰ªéÁ∫¨Â∫¶ÂíåÁªèÂ∫¶‰∏≠Â≠¶‰ºöÂ§çÊùÇÁöÑÈùûÁ∫øÊÄßËßÑÂæãÔºåÊâçËÉΩËææÂà∞Êàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÊïàÊûú„ÄÇ Ê≥®ÊÑèÔºöÊàë‰ª¨ÂèØËÉΩÈúÄË¶Å‰∏Ä‰∏™ÁΩëÁªúÁªìÊûÑÔºåÂÖ∂Â±ÇÊï∞ÊØîÊàë‰ª¨‰πãÂâçÂú®ÁªÉ‰π†‰∏≠‰ΩøÁî®ÁöÑË¶ÅÂ§ö„ÄÇ 1234567891011121314151617181920def location_location_location(examples_dataframe): """Returns a version of the input `DataFrame` that keeps only the latitude and longitude.""" processed_features = pd.DataFrame() processed_features["latitude"] = linear_scale(examples_dataframe["latitude"]) processed_features["longitude"] = linear_scale(examples_dataframe["longitude"]) return processed_featureslll_dataframe = location_location_location(preprocess_features(california_housing_dataframe))lll_training_examples = lll_dataframe.head(12000)lll_validation_examples = lll_dataframe.tail(5000)_ = train_nn_regression_model_optimize( my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.05), steps=500, batch_size=50, hidden_units=[10, 10, 5, 5, 5], training_examples=lll_training_examples, training_targets=training_targets, validation_examples=lll_validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 157.77 period 01 : 107.67 period 02 : 105.43 period 03 : 104.46 period 04 : 103.15 period 05 : 101.82 period 06 : 101.01 period 07 : 100.61 period 08 : 100.10 period 09 : 99.77 Model training finished. Final RMSE (on training data): 99.77 Final RMSE (on validation data): 100.48 ÊúÄÂ•Ω‰ΩøÁ∫¨Â∫¶ÂíåÁªèÂ∫¶‰øùÊåÅÊ†áÂáÜÂåñÁä∂ÊÄÅÔºåÂØπ‰∫éÂè™Êúâ‰∏§‰∏™ÁâπÂæÅÁöÑÊ®°ÂûãÔºåÁªìÊûúÂπ∂‰∏çÁÆóÂ§™Á≥ü„ÄÇÂΩìÁÑ∂ÔºåÂú∞‰∫ß‰ª∑ÂÄºÂú®Áü≠Ë∑ùÁ¶ªÂÜÖ‰ªçÁÑ∂ÂèØËÉΩÊúâËæÉÂ§ßÂ∑ÆÂºÇ„ÄÇ]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÊàëÁöÑÊµÅÊµ™Âú∞ÁêÉ]]></title>
    <url>%2F2019%2F02%2F10%2F%E6%88%91%E7%9A%84%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83%2F</url>
    <content type="text"><![CDATA[‰∫å„Äá‰∏Ä‰πùÂπ¥‰∫åÊúàÂçÅÂè∑ÔºåÊòüÊúüÂÖ≠ÔºåÂÜúÂéÜÊ≠£ÊúàÂàùÂÖ≠ÔºåÂÅáÊúüÁöÑÊúÄÂêé‰∏ÄÂ§©ÔºåÊòéÂ§©Â∞±Ë¶ÅÂ•îËµ¥Â∏ùÈÉΩÔºåÂºÄÂßãÊàëÁöÑÊµÅÊµ™ÁîüÊ¥ª„ÄÇ ÊµÅÊµ™Âú∞ÁêÉÊòØÊàëÁúãËøáÂ§ßÂàòÁöÑÁ¨¨‰∫åÊú¨‰π¶ÔºåËÄå‰∏îÁúãËøá‰∏§ÈÅçÔºåÁ¨¨‰∏ÄÈÅçÊòØÂ§ßÁ∫¶‰∏§Âπ¥ÂâçÂπ¥‰ªéÂåó‰∫¨ÂõûÂÆ∂ÁöÑÁÅ´ËΩ¶‰∏äÔºåÈÇ£‰∏ÄÂπ¥‰∏â‰ΩìÁÅ´‰∫ÜÔºåÈÇ£‰∏ÄÂπ¥‰πüÊòØÊàëÂú®Â∏ùÈÉΩÁöÑÁ¨¨‰∏ÄÂπ¥ÔºåÁ¨¨‰∫åÈÅçÊòØÊòØÂéªÂπ¥ÊàëÂú®‰ªéÂÆ∂Âà∞Âåó‰∫¨ÁöÑÁÅ´ËΩ¶‰∏äÔºåÁúãÁ¨¨‰∫åÈÅçÁöÑÁêÜÁî±ÊòØÊàëÂøòËÆ∞ÊàëÁúãËøá‰∫ÜÔºåËØªÂà∞‰∏ÄÂçäÊâçÊÉ≥Ëµ∑ÁúãËøá„ÄÇ‰∏∫‰ªÄ‰πàË¶ÅËØ¥ÂéüËëóÔºåÂõ†‰∏∫Áõ∏ÊØîËæÉÊµÅÊµ™Âú∞ÁêÉÁöÑÁîµÂΩ±ÔºåÊàëÊõ¥ÊÉ≥ËÅäËÅäÂéüËëó„ÄÇ ÂÖàËØ¥ËØ¥ÁîµÂΩ±ÂêßÔºåÂàö‰∏äÊò†Â∞±Ë¢´ÂêµÂæóÁÅ´ÁÉ≠Ôºå‰∏ÄÁâáÂ•ΩËØÑÔºå‰ΩÜÊàëÊòØ‰∏ÄÂêë‰∏çÁúãÂ•Ω‰∏≠ÂõΩÂΩ±ËßÜÂØπÂéüËëóÁöÑÊîπÁºñÔºåÊâÄ‰ª•ÊàëÊÄÄÁùÄÂÖ´ÂàÜÁöÑÂøÉÊÉÖÂéªÁúãÔºåÂéªÊéâÁî∑Â•≥‰∏ªÁöÑÂè∞ËØçÔºåÂä†‰∏äÊÉÖÊÄÄÁªôÂÖ≠ÂàÜÂèäÊ†ºÔºåÁúãÂÆåÁöÑÁû¨Èó¥ÂøÉÊÉÖÊòØÊãÖÂøÉ‰∏â‰ΩìÁöÑÂè∞ËØçÂà´Ëøô‰πàÁ≥üÁ≥ïÔºåÂõ†‰∏∫ÂéüËëóÊòØÂèôËø∞ÂΩ¢ÂºèÁöÑÔºåÊÉ≥ÈÄöËøáÂΩ±ËßÜ‰ΩúÂìÅË°®Áé∞ÂéüËëóÁöÑÊÄùÊÉ≥Âü∫Êú¨‰∏çÂèØËÉΩ‰∫ÜÔºåËÉΩÊääÊïÖ‰∫ãËÆ≤ÊòéÁôΩÁöÑÂØºÊºîÂ∞±ËÉΩÁªôÂçÅÂàÜ‰∫ÜÔºåËøô‰∏ÄÊ¨°ÁöÑÁîµÂΩ±ÂæàÊòéÊòæÔºåËÆ≤ÁöÑÂíåÂéüËëó‰∏≠ÁöÑÊïÖ‰∫ãÊÉÖËäÇÊ≤°‰ªÄ‰πàÂÖ≥Á≥ªÔºåÂ•ΩÂêßÔºåÂêêÊßΩ‰πüÂ∞±Ëøô‰πàÂ§ö‰∫ÜÔºåÂØπ‰∫é‰∏≠ÂõΩÁöÑÁ¨¨‰∏ÄÈÉ®Ê≠£ÁúüÊÑè‰πâ‰∏äÁöÑÁßëÂπªÂ§ßÁâáÔºåË°åÊòüÂèëÂä®Êú∫ÁöÑÁâπÊïàÁªô9ÂàÜÔºåËôΩÁÑ∂ÁúãÂ§ö‰∫ÜÁßëÂπªÂ§ßÁâáÂíåÊ∏∏ÊàèÔºå‰πüÊ≤°Âï•ÊÑüËßâÔºå‰ΩÜÊòØËøô‰∏™Ë°åÊòüÂèëÂä®Êú∫ÁöÑÁ°ÆÊòØÊàëÊÉ≥Ë±°‰∏≠ÁöÑÊ†∑Â≠êÔºåÊàëÊú¨Êù•ÊòØÂéªÁúãÂâßÊÉÖÁöÑ‰Ω†ÁªôÊàëÊîæÁâπÊïàÔºüÁîµÂΩ±ÂâßÊÉÖÊØîËæÉÁÆÄÂçïÊ≤°Âï•ÂèØËÅäÁöÑÔºåÂèØÂêêÊßΩÁöÑÂú∞ÊñπÂ§™Â§öÔºåÊáíÂæóÂÜô‰∫Ü„ÄÇ ÊúÄÂêéÂÜçËØ¥ËØ¥ÂéüËëóÂêßÔºåËøôÊòØ‰∏™‰∏≠ÁØáÂ∞èËØ¥ÔºåÂ∑≤Á¨¨‰∏ÄËßÜËßíÊàëÊù•ÂèôËø∞ÔºåÊïÖ‰∫ãÂÜÖÂÆπ‰∏çÂ§öÔºå‰πüÂ∞±ËÆ≤‰∫ÜËøôÂá†‰ª∂‰∫ã ÂπºÂπ¥Êó∂Âú∞ÁêÉÂÅúËΩ¨ÔºåËøõÂÖ•Âú∞‰∏ãÂüéÁîüÊ¥ª Âàù‰∫åÊó∂ÔºåÂú∞‰∏ãÂüéÂ≤©ÊµÜ‰æµÂÖ•ÔºåÊéíÈòüÊïëÊè¥ÔºåÂõ†‰∏∫‰∏ªËßíÂπ¥ËΩªÊâÄ‰ª•ÊéíÂâçÈù¢Ëé∑ÊïëÔºåÊØç‰∫≤ÂíåËÄÅ‰∫∫ÊéíÂêéÈù¢Ë¢´ÁÉßÊ≠ª ÈùíÂπ¥Êó∂ÂèÇÂä†Â••Ëøê‰ºöÊâæ‰∫Ü‰∏™Êó•Êú¨Â™≥Â¶áÔºåÂπ∂ÊäΩÂà∞‰∫ÜÁîüËÇ≤ÊåáÊ†á ‰∏ªËßíÁà∏Âú®ÊëßÊØÅÂ∞èË°åÊòüÁöÑË°åÂä®‰∏≠ÊÆâËÅå È´òÊΩÆÔºö‰∏ÄÈÉ®ÂàÜ‰∫∫ËÆ§‰∏∫Â§™Èò≥‰∏ç‰ºöÁàÜÁÇ∏ÔºåÂºÄÂßãËµ∑‰πâÔºåÂ™≥Â¶á‰πüÂä†ÂÖ•‰∫ÜËµ∑‰πâÂÜõÔºåÊúÄÂêéËµ∑‰πâÂÜõÊîªÂÖ•ÊÄªÈÉ®Ôºå‰∏ªËßí‰πüÂä†ÂÖ•Ëµ∑‰πâÂÜõÔºåÂéüÊîøÂ∫úÈ¢ÜÂØºË¢´Â§ÑÊ≠ªÔºåÁÑ∂ÂêéÂ§™Èò≥ÁàÜÁÇ∏‰∫ÜÔºåËØÅÊòéËµ∑‰πâÂÜõÊòØÈîôÁöÑ ÁªìÂ∞æÔºå‰∏ªËßíËÄÅÂéªÔºåÂú∞ÁêÉÁªßÁª≠ÊµÅÊµ™‰∏≠ Ëá≥‰∫éÁîµÂΩ±‰∏≠ÁöÑËøáÊú®ÊòüÔºåÂ∞±‰∏ÄÁ¨îÂ∏¶Ëøá‰∫ÜÔºåË≤å‰ººÊ≤°Âá∫Âï•‰∫ãÔºåÂéüËëóÊïÖ‰∫ãÊÉ≥ËØ¥ÁöÑÊòØÔºåÂà∞Â∫ïË∞ÅÂØπË∞ÅÈîôÔºåÊ≤°ÊúâÂäûÊ≥ïË°°ÈáèÔºå‰∏ªËßí‰∏ÄÁõ¥ÂùöÂÆàÁöÑ‰ø°Âøµ‰πüÂú®Ëµ∑‰πâÂÜõÊîªÂÖ•ÊÄªÈÉ®Êó∂Â¥©Â°å‰∫ÜÔºå‰ªñ‰πü‰∏çÂú®‰πéÂ§™Èò≥ÊòØÂê¶‰ºöÁàÜÁÇ∏‰∫ÜÔºåÈöèÁùÄËµ∑‰πâÂÜõ‰∏ÄËµ∑ÁñØÁãÇ‰∫ÜÔºåËøôÊòØ‰∏Ä‰∏™‰∫∫‰∏ÄÁõ¥ÂùöÊåÅ‰ΩÜÊòØÁúã‰∏çÂà∞Â∏åÊúõÁöÑÁªìÊûúÔºåÂú∞ÁêÉ‰∏äÁöÑ‰∫∫‰πüÈÉΩÁñØ‰∫ÜÔºåÂ∞ΩÊÉÖÁöÑÁãÇÊ¨¢ÔºåÂÖ∂ÂÆûËøôÂ§ßÊ¶ÇÊâçÊòØÊ≠£ÁúüÁöÑÊú´Êó•ÂêßÔºåÂΩìÂ§™Èò≥ÁàÜÁÇ∏ÂêéÔºåÊâÄÊúâ‰∫∫ÂèàÊàê‰∏∫‰∫ÜÂêå‰∏ÄÊ†πÁª≥‰∏äÁöÑËöÇËö±ÔºåÁªßÁª≠ÊµÅÊµ™Âú∞ÁêÉËÆ°Âàí„ÄÇ ÂØπ‰∫ÜÔºåÁñØÁãÇÂ§ñÊòü‰∫∫ÊòØÊîπÁºñÂ§ßÂàòÁöÑ„Ää‰π°ÊùëÊïôÂ∏à„ÄãÔºåÈÉùÂª∫ÁöÑ‰ΩúÂìÅËøòÊòØÊØîËæÉÂñúÂâßÁöÑÔºå‰ΩÜËøô‰∏™Ë≤å‰ººÂíåÂéüËëóÂÆåÂÖ®Ê≤°Êúâ‰ªÄ‰πàÂÖ≥Á≥ª‰∫Ü„ÄÇ„ÄÇ„ÄÇ ÊúÄÂêé. ÊúüÂæÖ„Ää‰∏â‰Ωì„Äã‰∏≠]]></content>
      <categories>
        <category>ÂΩ±ËØÑ</category>
      </categories>
      <tags>
        <tag>ÂΩ±ËØÑ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django ÈÉ®ÁΩ≤(Apache) Ë∂üËøáÁöÑÂùë]]></title>
    <url>%2F2019%2F01%2F27%2FDjango%20%E9%83%A8%E7%BD%B2(Apache)%2F</url>
    <content type="text"><![CDATA[DjangoÊòØ‰∏Ä‰∏™ÔºåÁî±PythonÂÜôÊàêÁöÑÂºÄÊîæÊ∫ê‰ª£Á†ÅÁöÑWebÂ∫îÁî®Ê°ÜÊû∂ÔºåÂú®‰ΩøÁî®apacheÈÉ®ÁΩ≤ÁöÑÊó∂ÂÄôËµ∞‰∫ÜÂ•ΩÂ§öÂùëËøôÈáåËÆ∞ÂΩï‰∏ã„ÄÇ ÂèÇËÄÉÔºö DjangoÊïôÁ®ã apacheÈÉ®ÁΩ≤ ÂâçÊèêÊù°‰ª∂ ‰∏Ä‰∏™ÊúçÂä°Âô®ÔºåÊàë‰ΩøÁî®ÁöÑÊòØÈòøÈáå‰∫ëÊúçÂä°Âô®„ÄÇ Êé®Ëçê‰ΩøÁî®ubuntuÈïúÂÉèÔºåÂõ†‰∏∫ËΩØ‰ª∂ÈõÜÊàêÂ∫¶È´òÔºàÂ∞±ÊòØÁÆÄÂçïÔºåÂÇªÁìú‰πü‰ºöÁé©Ôºâ„ÄÇ Â∑≤Áªè‰ΩøÁî®DjangoÊê≠Âª∫Â•ΩwebÊúçÂä°ÔºåÂ¶Ç‰ΩïÊê≠Âª∫ÁúãDjangoÊïôÁ®ã„ÄÇ ËøôÈáåÂè™ËÆ∞ÂΩïÈÉ®ÁΩ≤apacheÁöÑÂùë‰∫ÜÔºåÂÖ∂‰ªñ‰∏äÈù¢ÈÉΩÊúâËØ¶ÁªÜËÆ≤Ëß£ÔºåÂ∞±Áï•‰∫Ü„ÄÇ ÂÆâË£Öapache2Âíåmod_wsgi1234567sudo apt-get install apache2 # Python 2sudo apt-get install libapache2-mod-wsgi # Python 3sudo apt-get install libapache2-mod-wsgi-py3 ÁúãÁâàÊú¨ÔºÅÔºÅÔºÅÔºàÈùûÂ∏∏ÈáçË¶ÅÔºâ ÁâàÊú¨‰∏çÂêåÂú®ÈÖçÁΩÆ‰∏äÊúâÂå∫Âà´ÔºåÊé®Ëçê‰ΩøÁî®ÊØîËæÉÊñ∞ÁöÑÁâàÊú¨Ôºå‰πüÂ∞±ÊòØ2.4‰ª•‰∏äÔºåÂ¶ÇÊûúÊòØ1Ôºå‰∏ãÈù¢ÁöÑÈÖçÁΩÆÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑÔºÅÔºÅÔºÅ1234apachectl -vServer version: Apache/2.4.18 (Ubuntu)Server built: 2018-06-07T19:43:03 ÂÖàÂà´ÊÄ•ÁùÄÈÖçÁΩÆÔºåÁúãÁúãËÉΩ‰∏çËÉΩÊ≠£Â∏∏ÂêØÂä® 1sudo service apache2 restart ËøôÊó∂ÂÄôÊ≠£Â∏∏ÊÉÖÂÜµ‰ºöÂêØÂä®ÈªòËÆ§ÈÖçÁΩÆÔºå‰ΩøÁî®ÊµèËßàÂô®ËÆøÈóÆ‰Ω†ÊúçÂä°Âô®ÁöÑÂ§ñÁΩëIPÔºåÂ¶ÇÊûúÊ≠£Â∏∏‰ºöÊòæÁ§∫‰∏ãÂõæÔºö Êó†Ê≥ïËÆøÈóÆËØ∑Ê£ÄÊü•ÈòøÈáå‰∫ëÁöÑÈò≤ÁÅ´Â¢ôËÆæÁΩÆÔºåÁúãÁ´ØÂè£ÊòØÂê¶ÂÖÅËÆ∏ÈÄöËøáÔºåÊµèËßàÂô®ÈªòËÆ§ÊòØ80ÔºåËøôÈáåÈ°∫‰æøÂä†‰∏Ä‰∏™8080Ôºå‰æõ‰∏ãÈù¢ÊµãËØï„ÄÇ Apache2 Ubuntu Default Page È°µÈù¢ÂèØ‰ª•Ê≠£Â∏∏ËÆøÈóÆ‰ª£Ë°®Êàë‰ª¨ÁöÑapacheÂÆâË£ÖÊàêÂäüÔºå‰∏ãÈù¢ÂºÄÂßã‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂„ÄÇ ËÆæÁΩÆÁõÆÂΩïÂíåÊñá‰ª∂ÁöÑÊùÉÈôê‰∏ÄËà¨ÁõÆÂΩïÊùÉÈôêËÆæÁΩÆ‰∏∫ 755ÔºåÊñá‰ª∂ÊùÉÈôêËÆæÁΩÆ‰∏∫ 644 ÂÅáÂ¶ÇÈ°πÁõÆ‰ΩçÁΩÆÂú® /home/user/WebService ÔºàÂú®WebService ‰∏ãÈù¢Êúâ‰∏Ä‰∏™ manage.pyÔºåWebService ÊòØÈ°πÁõÆÂêçÁß∞Ôºâ 123cd /home/user/sudo chmod -R 644 WebServicesudo find WebService -type d | xargs chmod 755 Django ÁöÑ settings.py Ë¶ÅËÆæÁΩÆÊ∏ÖÊ•ömedia Êñá‰ª∂Â§π‰∏ÄËà¨Áî®Êù•Â≠òÊîæÁî®Êà∑‰∏ä‰º†Êñá‰ª∂Ôºåstatic ‰∏ÄËà¨Áî®Êù•ÊîæËá™Â∑±ÁΩëÁ´ôÁöÑjsÔºåcssÔºåÂõæÁâáÁ≠âÔºåÂú®settings.py‰∏≠ÁöÑÁõ∏ÂÖ≥ËÆæÁΩÆ STATIC_URL ‰∏∫ÈùôÊÄÅÊñá‰ª∂ÁöÑÁΩëÂùÄ STATIC_ROOT ‰∏∫ÈùôÊÄÅÊñá‰ª∂ÁöÑÊ†πÁõÆÂΩïÔºå MEDIA_URL ‰∏∫Áî®Êà∑‰∏ä‰º†Êñá‰ª∂Â§πÁöÑÊ†πÁõÆÂΩïÔºåMEDIA_URL‰∏∫ÂØπÂ∫îÁöÑËÆøÈóÆÁΩëÂùÄ ÈúÄË¶ÅmediaÁöÑ Ë¶ÅÁªômediaÁõÆÂΩïÂçïÁã¨ËÆæÁΩÆÂÜôÁöÑÊùÉÈôê ALLOWED_HOSTSÊòØ‰∏∫‰∫ÜÈôêÂÆöËØ∑Ê±Ç‰∏≠ÁöÑhostÂÄºÔºå‰ª•Èò≤Ê≠¢ÈªëÂÆ¢ÊûÑÈÄ†ÂåÖÊù•ÂèëÈÄÅËØ∑Ê±Ç„ÄÇÂè™ÊúâÂú®ÂàóË°®‰∏≠ÁöÑhostÊâçËÉΩËÆøÈóÆ„ÄÇ Ê≥®ÊÑèÔºöÂú®ËøôÈáåÊú¨‰∫∫Âº∫ÁÉàÂª∫ËÆÆ‰∏çË¶Å‰ΩøÁî®ÈÄöÈÖçÁ¨¶ÂéªÈÖçÁΩÆÔºåÂè¶Â§ñÂΩìDEBUGËÆæÁΩÆ‰∏∫FalseÁöÑÊó∂ÂÄôÂøÖÈ°ªÈÖçÁΩÆËøô‰∏™ÈÖçÁΩÆ„ÄÇÂê¶Âàô‰ºöÊäõÂá∫ÂºÇÂ∏∏„ÄÇ*1ALLOWED_HOSTS = ['*'] ËøôÈáåÂÖàÂÜô‰∏™*Á≠âÂÖ®ÈÉ®Ë∞ÉÈÄö‰∫ÜÂÜçÊîπ„ÄÇ„ÄÇ„ÄÇ apacheÁöÑÈÖçÁΩÆÊñá‰ª∂12cd /etc/apache2/sites-availablesudo vim mysite.conf Âú®ËøôÈáåÊàë‰ª¨Ëá™Â∑±ÂÜô‰∏™ÈÖçÁΩÆ1234567891011121314151617181920&lt;VirtualHost *:8080&gt; ServerName www.yourdomain.com ServerAdmin youremail@mail.com ErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log CustomLog $&#123;APACHE_LOG_DIR&#125;/access.log combined Alias /static/ /home/user//WebService/static/ &lt;Directory /home/user/WebService/static&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt; WSGIScriptAlias / /home/user/WebService/WebService/wsgi.py &lt;Directory /home/user/WebService/WebService&gt; &lt;Files wsgi.py&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted &lt;/Files&gt; &lt;/Directory&gt;&lt;/VirtualHost&gt; Ê†πÊçÆËá™Â∑±ÁöÑÊÉÖÂÜµÊîπÊîπÔºåË¶ÅÊ≥®ÊÑèÁõÆÂΩïË¶ÅÂØπÔºåÂπ∂‰∏î‰πüÂÜô‰∏ãÈù¢Ëøô‰∏™ÈÖçÁΩÆÔºåapacheÁâàÊú¨‰∏çÂêåÈÖçÁΩÆÊòØ‰∏çÂêåÁöÑÔºÅÔºÅÔºÅ Options Indexes FollowSymLinks AllowOverride None Require all granted Âõ†‰∏∫Êàë‰ª¨ÂàöÈÖçÁΩÆÈáåÂÜôÁöÑÊòØ8080ÁöÑÁ´ØÂè£ÔºåÊâÄ‰ª•Ë¶ÅÊääÂÆÉÂä†Âà∞ÁõëÂê¨ÂàóË°®Èáå12345678sudo vim /etc/apache2/ports.confListen 80Âä†‰∏ÄÂè•Listen 80Listen 8080 wsgi.pyÊñá‰ª∂‰øÆÊîπ‰øÆÊîπËøô‰∏™Êñá‰ª∂ÁöÑÁõÆÁöÑÂ∞±ÊòØÊääapache2Âíå‰Ω†ÁöÑÁΩëÁ´ôprojectËÅîÁ≥ªËµ∑Êù• 1234567891011import osfrom os.path import join,dirname,abspath # +from django.core.wsgi import get_wsgi_applicationPROJECT_DIR = dirname(dirname(abspath(__file__))) # +import sys # +sys.path.insert(0,PROJECT_DIR) # +os.environ.setdefault("DJANGO_SETTINGS_MODULE", "WebService.settings")from django.core.wsgi import get_wsgi_applicationapplication = get_wsgi_application() ÊøÄÊ¥ªÊñ∞ÈÖçËøôÈáå‰∏çÁî®ÂÜôË∑ØÂæÑ 1sudo a2ensite mysite Êàñ sudo a2ensite mysite.conf ÈáçÂêØapach1sudo service apache2 restart ËÆøÈóÆ ‰Ω†ÁöÑÁΩëÁ´ôÔºåËÆ∞ÂæóÂä†Á´ØÂè£Âè∑ 0.0.0.0:8080 Âá∫ÈîôÁúãlog1cat /var/log/apache2/error.log ËôöÊãüÁéØÂ¢ÉÈÉ®ÁΩ≤ÈÄöÂ∏∏Êàë‰ª¨ÁöÑÁ≥ªÁªü‰∏≠‰ºöÊúâÂ§ö‰∏™pythonÁéØÂ¢ÉÔºå‰ΩøÁî®virtualenvÁÆ°ÁêÜ Ê∫ê‰ª£Á†ÅÂÆâË£Öpython3.7‰∏äPythonÂÆòÁΩë‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨ÁöÑsourceÂåÖÔºåËß£ÂéãÂêéËøõÂÖ•ÂÆâË£ÖÁõÆÂΩïÔºåÈÖçÁΩÆmakefileÔºåÁºñËØëÔºåÂÆâË£Ö„ÄÇ123# ./configure --prefix=/usr/local --enable-shared --with-ssl# make# make install ‚Äìprefix=/usr/local ‚Äìenable-shared ÁöÑÊÑèÊÄùÊòØÂàõÂª∫ÂÖ±‰∫´ÈìæÊé•Ôºå‰ª•‰æøÂÖ∂‰ªñËΩØ‰ª∂ÁºñËØëÊó∂Ë∞ÉÁî® ‚Äìwith-ssl ÁöÑÊÑèÊÄùÊòØÂÖÅËÆ∏sslÔºåpipÂÆâË£ÖÁöÑÊó∂ÂÄô‰ºöÁî®Âà∞ ÂÆâË£ÖËôöÊãüÁéØÂ¢ÉPython ËôöÊãüÁéØÂ¢ÉÁî®‰∫éÂ∞ÜËΩØ‰ª∂ÂåÖÂÆâË£Ö‰∏éÁ≥ªÁªüÈöîÁ¶ªÂºÄÊù•„ÄÇ 12345678910111213141516171819ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑËôöÊãüÁéØÂ¢ÉÔºåÊñπÊ≥ïÊòØÈÄâÊã© Python Ëß£ÈáäÂô®Âπ∂ÂàõÂª∫‰∏Ä‰∏™ ./venv ÁõÆÂΩïÊù•Â≠òÊîæÂÆÉÔºö$ virtualenv --system-site-packages -p python3.7 ./venv‰ΩøÁî®ÁâπÂÆö‰∫é shell ÁöÑÂëΩ‰ª§ÊøÄÊ¥ªËØ•ËôöÊãüÁéØÂ¢ÉÔºö$ source ./venv/bin/activate # sh, bash, ksh, or zshÂΩì virtualenv Â§Ñ‰∫éÊúâÊïàÁä∂ÊÄÅÊó∂Ôºåshell ÊèêÁ§∫Á¨¶Â∏¶Êúâ (venv) ÂâçÁºÄ„ÄÇÂú®‰∏çÂΩ±Âìç‰∏ªÊú∫Á≥ªÁªüËÆæÁΩÆÁöÑÊÉÖÂÜµ‰∏ãÔºåÂú®ËôöÊãüÁéØÂ¢É‰∏≠ÂÆâË£ÖËΩØ‰ª∂ÂåÖ„ÄÇÈ¶ñÂÖàÂçáÁ∫ß pipÔºö$ pip install --upgrade pip$ pip list # show packages installed within the virtual environment‰πãÂêéË¶ÅÈÄÄÂá∫ virtualenvÔºåËØ∑‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§Ôºö$ deactivate # don't exit until you're done using TensorFlow ÁºñËØëmod_wsgimod_wsgiÂÆòÁΩë mod_wsgiÊòØ‰∏Ä‰∏™apacheÁöÑÊ®°ÂùóÔºåÁî®Êù•Êääpython webÂíåapacheËøûÊé•Ëµ∑Êù•ÔºåËØ¥ÂÆûËØùÔºå‰∏çÂíãÂ•ΩÁî®Ôºå‰∏ÄÂÆöË¶Å‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨ÔºåËÄÅÁâàÊú¨‰ºöÊúâ‰∏çÂ∞ëÈóÆÈ¢ò‰∏ãËΩΩÂú∞ÂùÄ Ëß£ÂéãÂêéËøõÂÖ•ÂÆâË£ÖÁõÆÂΩïÔºåÈÖçÁΩÆmakefileÔºåÁºñËØëÔºåÂÆâË£Ö„ÄÇ 123./configure --with-apxs=/usr/bin/apxs2 --with-python=py3.7env/venv/bin/python3.7makemake install apxs2Ê≤°ÊúâÁöÑËØù‰ª•Èò≤‰∏á‰∏ÄÂ∞±Ë£Ö‰∏Ä‰∏ãÔºå‚Äìwith-pythonÊåáÁöÑÊòØÊàë‰ª¨ÊÉ≥Ë¶ÅÈìæÊé•ÁöÑpythonÁõÆÊ†á ÈÖçÁΩÆApacheÂú®‰∏äÈù¢ÁöÑÈÖçÁΩÆÂü∫Á°Ä‰∏äÂä†‰∏§Ë°å123WSGIScriptAlias / /home/user/WebService/WebService/wsgi.py # Âú®ËøôË°å‰∏ãÂä†‰ø©WSGIDaemonProcess yourdomain.com python-path=/home/user/WebService:/home/user/py3.7env/venv/lib/python3.7/site-packagesWSGIProcessGroup yourdomain.com WSGIDaemonProcess ‰Ω†ÁöÑÂüüÂêç python-path=ÂàöÊâçÁî®virtualenvÂàõÂª∫ÁöÑpythonÂåÖÁöÑË∑ØÂæÑ ÈáçÂêØapache $ service apache2 restart ÁúãlogÊàë‰ª¨ÁöÑapacheÊàêÂäüÁöÑÈìæÊé•Âà∞python3.7Ôºö Apache/2.4.18 (Ubuntu) mod_wsgi/4.6.5 Python/3.7 configured ‚Äì resuming normal operations Â¶ÇÊûúÂá∫ÈîôÁúãÈîôËØØ‰ª£Á†ÅÊÖ¢ÊÖ¢Êü•ÔºåÊàëÁ†îÁ©∂‰∫Ü‰∏ÄÂ§©ÊâçÊàêÂäüÔºåÈ¶ñÂÖàÂ∞±ÊòØÁºñËØëÁöÑÊó∂ÂÄôconfigureÂêé‰∏ÄÂÆöË¶ÅÂ∏¶ÂØπÂèÇÊï∞ÔºåÁº∫Â∞ëÁöÑÂ∫ì‰πüË¶ÅÂÖ®ÊâãÂä®ÂÆâË£ÖÔºåËøòÊúâÈù†‰∏ÄÈÉ®ÂàÜËøêÊ∞îÊâçËÉΩÊàêÂäü„ÄÇ]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÊúØËØ≠Ë°®]]></title>
    <url>%2F2019%2F01%2F19%2FMachineLearningGlossary%2F</url>
    <content type="text"><![CDATA[Êú∫Âô®Â≠¶‰π†ÊúØËØ≠Ë°® Êú¨ÊúØËØ≠Ë°®‰∏≠ÂàóÂá∫‰∫Ü‰∏ÄËà¨ÁöÑÊú∫Âô®Â≠¶‰π†ÊúØËØ≠Âíå TensorFlow ‰∏ìÁî®ÊúØËØ≠ÁöÑÂÆö‰πâ„ÄÇ A A/B ÊµãËØï (A/B testing) ‰∏ÄÁßçÁªüËÆ°ÊñπÊ≥ïÔºåÁî®‰∫éÂ∞Ü‰∏§ÁßçÊàñÂ§öÁßçÊäÄÊúØËøõË°åÊØîËæÉÔºåÈÄöÂ∏∏ÊòØÂ∞ÜÂΩìÂâçÈááÁî®ÁöÑÊäÄÊúØ‰∏éÊñ∞ÊäÄÊúØËøõË°åÊØîËæÉ„ÄÇA/B ÊµãËØï‰∏ç‰ªÖÊó®Âú®Á°ÆÂÆöÂì™ÁßçÊäÄÊúØÁöÑÊïàÊûúÊõ¥Â•ΩÔºåËÄå‰∏îËøòÊúâÂä©‰∫é‰∫ÜËß£Áõ∏Â∫îÂ∑ÆÂºÇÊòØÂê¶ÂÖ∑ÊúâÊòæËëóÁöÑÁªüËÆ°ÊÑè‰πâ„ÄÇA/B ÊµãËØïÈÄöÂ∏∏ÊòØÈááÁî®‰∏ÄÁßçË°°ÈáèÊñπÂºèÂØπ‰∏§ÁßçÊäÄÊúØËøõË°åÊØîËæÉÔºå‰ΩÜ‰πüÈÄÇÁî®‰∫é‰ªªÊÑèÊúâÈôêÊï∞ÈáèÁöÑÊäÄÊúØÂíåË°°ÈáèÊñπÂºè„ÄÇ ÂáÜÁ°ÆÁéá (accuracy) ÂàÜÁ±ªÊ®°ÂûãÁöÑÊ≠£Á°ÆÈ¢ÑÊµãÊâÄÂç†ÁöÑÊØî‰æã„ÄÇÂú®Â§öÁ±ªÂà´ÂàÜÁ±ª‰∏≠ÔºåÂáÜÁ°ÆÁéáÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö $$\text{ÂáÜÁ°ÆÁéá} = \frac{\text{Ê≠£Á°ÆÁöÑÈ¢ÑÊµãÊï∞}} {\text{Ê†∑Êú¨ÊÄªÊï∞}}$$ Âú®‰∫åÂÖÉÂàÜÁ±ª‰∏≠ÔºåÂáÜÁ°ÆÁéáÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö $$\text{ÂáÜÁ°ÆÁéá} = \frac{\text{Ê≠£‰æãÊï∞} + \text{Ë¥ü‰æãÊï∞}} {\text{Ê†∑Êú¨ÊÄªÊï∞}}$$ ËØ∑ÂèÇÈòÖÊ≠£‰æãÂíåË¥ü‰æã„ÄÇ ÊøÄÊ¥ªÂáΩÊï∞ (activation function) ‰∏ÄÁßçÂáΩÊï∞Ôºà‰æãÂ¶Ç ReLU Êàñ S ÂûãÂáΩÊï∞ÔºâÔºåÁî®‰∫éÂØπ‰∏ä‰∏ÄÂ±ÇÁöÑÊâÄÊúâËæìÂÖ•Ê±ÇÂä†ÊùÉÂíåÔºåÁÑ∂ÂêéÁîüÊàê‰∏Ä‰∏™ËæìÂá∫ÂÄºÔºàÈÄöÂ∏∏‰∏∫ÈùûÁ∫øÊÄßÂÄºÔºâÔºåÂπ∂Â∞ÜÂÖ∂‰º†ÈÄíÁªô‰∏ã‰∏ÄÂ±Ç„ÄÇ AdaGrad ‰∏ÄÁßçÂÖàËøõÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºåÁî®‰∫éÈáçÊñ∞Ë∞ÉÊï¥ÊØè‰∏™ÂèÇÊï∞ÁöÑÊ¢ØÂ∫¶Ôºå‰ª•‰æøÊúâÊïàÂú∞‰∏∫ÊØè‰∏™ÂèÇÊï∞ÊåáÂÆöÁã¨Á´ãÁöÑÂ≠¶‰π†ÈÄüÁéá„ÄÇÂ¶ÇÈúÄÊü•ÁúãÂÆåÊï¥ÁöÑËß£ÈáäÔºåËØ∑ÂèÇÈòÖËøôÁØáËÆ∫Êñá„ÄÇ ROC Êõ≤Á∫ø‰∏ãÈù¢ÁßØ (AUC, Area under the ROC Curve) ‰∏ÄÁßç‰ºöËÄÉËôëÊâÄÊúâÂèØËÉΩÂàÜÁ±ªÈòàÂÄºÁöÑËØÑ‰º∞ÊåáÊ†á„ÄÇ ROC Êõ≤Á∫ø‰∏ãÈù¢ÁßØÊòØÔºåÂØπ‰∫éÈöèÊú∫ÈÄâÊã©ÁöÑÊ≠£Á±ªÂà´Ê†∑Êú¨Á°ÆÂÆû‰∏∫Ê≠£Á±ªÂà´Ôºå‰ª•ÂèäÈöèÊú∫ÈÄâÊã©ÁöÑË¥üÁ±ªÂà´Ê†∑Êú¨‰∏∫Ê≠£Á±ªÂà´ÔºåÂàÜÁ±ªÂô®Êõ¥Á°Æ‰ø°ÂâçËÄÖÁöÑÊ¶ÇÁéá„ÄÇ B ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï (backpropagation) Âú®Á•ûÁªèÁΩëÁªú‰∏äÊâßË°åÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÁöÑ‰∏ªË¶ÅÁÆóÊ≥ï„ÄÇËØ•ÁÆóÊ≥ï‰ºöÂÖàÊåâÂâçÂêë‰º†Êí≠ÊñπÂºèËÆ°ÁÆóÔºàÂπ∂ÁºìÂ≠òÔºâÊØè‰∏™ËäÇÁÇπÁöÑËæìÂá∫ÂÄºÔºåÁÑ∂ÂêéÂÜçÊåâÂèçÂêë‰º†Êí≠ÈÅçÂéÜÂõæÁöÑÊñπÂºèËÆ°ÁÆóÊçüÂ§±ÂáΩÊï∞ÂÄºÁõ∏ÂØπ‰∫éÊØè‰∏™ÂèÇÊï∞ÁöÑÂÅèÂØºÊï∞„ÄÇ Âü∫ÂáÜ (baseline) ‰∏ÄÁßçÁÆÄÂçïÁöÑÊ®°ÂûãÊàñÂêØÂèëÊ≥ïÔºåÁî®‰ΩúÊØîËæÉÊ®°ÂûãÊïàÊûúÊó∂ÁöÑÂèÇËÄÉÁÇπ„ÄÇÂü∫ÂáÜÊúâÂä©‰∫éÊ®°ÂûãÂºÄÂèëËÄÖÈíàÂØπÁâπÂÆöÈóÆÈ¢òÈáèÂåñÊúÄ‰ΩéÈ¢ÑÊúüÊïàÊûú„ÄÇ ÊâπÊ¨° (batch) Ê®°ÂûãËÆ≠ÁªÉÁöÑ‰∏ÄÊ¨°Ëø≠‰ª£ÔºàÂç≥‰∏ÄÊ¨°Ê¢ØÂ∫¶Êõ¥Êñ∞Ôºâ‰∏≠‰ΩøÁî®ÁöÑÊ†∑Êú¨ÈõÜ„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÊâπÊ¨°Â§ßÂ∞è„ÄÇ ÊâπÊ¨°Â§ßÂ∞è (batch size) ‰∏Ä‰∏™ÊâπÊ¨°‰∏≠ÁöÑÊ†∑Êú¨Êï∞„ÄÇ‰æãÂ¶ÇÔºåSGD ÁöÑÊâπÊ¨°Â§ßÂ∞è‰∏∫ 1ÔºåËÄåÂ∞èÊâπÊ¨°ÁöÑÂ§ßÂ∞èÈÄöÂ∏∏‰ªã‰∫é 10 Âà∞ 1000 ‰πãÈó¥„ÄÇÊâπÊ¨°Â§ßÂ∞èÂú®ËÆ≠ÁªÉÂíåÊé®Êñ≠ÊúüÈó¥ÈÄöÂ∏∏ÊòØÂõ∫ÂÆöÁöÑÔºõ‰∏çËøáÔºåTensorFlow ÂÖÅËÆ∏‰ΩøÁî®Âä®ÊÄÅÊâπÊ¨°Â§ßÂ∞è„ÄÇ ÂÅèÂ∑Æ (bias) Ë∑ùÁ¶ªÂéüÁÇπÁöÑÊà™Ë∑ùÊàñÂÅèÁßª„ÄÇÂÅèÂ∑ÆÔºà‰πüÁß∞‰∏∫ÂÅèÂ∑ÆÈ°πÔºâÂú®Êú∫Âô®Â≠¶‰π†Ê®°Âûã‰∏≠Áî® b Êàñ w0 Ë°®Á§∫„ÄÇ‰æãÂ¶ÇÔºåÂú®‰∏ãÈù¢ÁöÑÂÖ¨Âºè‰∏≠ÔºåÂÅèÂ∑Æ‰∏∫ bÔºö $$y' = b + w_1x_1 + w_2x_2 + ‚Ä¶ w_nx_n$$ ËØ∑Âãø‰∏éÈ¢ÑÊµãÂÅèÂ∑ÆÊ∑∑Ê∑Ü„ÄÇ ‰∫åÂÖÉÂàÜÁ±ª (binary classification) ‰∏ÄÁßçÂàÜÁ±ª‰ªªÂä°ÔºåÂèØËæìÂá∫‰∏§Áßç‰∫íÊñ•Á±ªÂà´‰πã‰∏Ä„ÄÇ‰æãÂ¶ÇÔºåÂØπÁîµÂ≠êÈÇÆ‰ª∂ËøõË°åËØÑ‰º∞Âπ∂ËæìÂá∫‚ÄúÂûÉÂúæÈÇÆ‰ª∂‚ÄùÊàñ‚ÄúÈùûÂûÉÂúæÈÇÆ‰ª∂‚ÄùÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂ∞±ÊòØ‰∏Ä‰∏™‰∫åÂÖÉÂàÜÁ±ªÂô®„ÄÇ ÂàÜÁÆ± (binning) ËØ∑ÂèÇÈòÖÂàÜÊ°∂„ÄÇ ÂàÜÊ°∂ (bucketing) Â∞Ü‰∏Ä‰∏™ÁâπÂæÅÔºàÈÄöÂ∏∏ÊòØËøûÁª≠ÁâπÂæÅÔºâËΩ¨Êç¢ÊàêÂ§ö‰∏™‰∫åÂÖÉÁâπÂæÅÔºàÁß∞‰∏∫Ê°∂ÊàñÁÆ±ÔºâÔºåÈÄöÂ∏∏Ê†πÊçÆÂÄºÂå∫Èó¥ËøõË°åËΩ¨Êç¢„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•Â∞ÜÊ∏©Â∫¶Âå∫Èó¥ÂàÜÂâ≤‰∏∫Á¶ªÊï£ÂàÜÁÆ±ÔºåËÄå‰∏çÊòØÂ∞ÜÊ∏©Â∫¶Ë°®Á§∫ÊàêÂçï‰∏™ËøûÁª≠ÁöÑÊµÆÁÇπÁâπÂæÅ„ÄÇÂÅáËÆæÊ∏©Â∫¶Êï∞ÊçÆÂèØÁ≤æÁ°ÆÂà∞Â∞èÊï∞ÁÇπÂêé‰∏Ä‰ΩçÔºåÂàôÂèØ‰ª•Â∞Ü‰ªã‰∫é 0.0 Âà∞ 15.0 Â∫¶‰πãÈó¥ÁöÑÊâÄÊúâÊ∏©Â∫¶ÈÉΩÂΩíÂÖ•‰∏Ä‰∏™ÂàÜÁÆ±ÔºåÂ∞Ü‰ªã‰∫é 15.1 Âà∞ 30.0 Â∫¶‰πãÈó¥ÁöÑÊâÄÊúâÊ∏©Â∫¶ÂΩíÂÖ•Á¨¨‰∫å‰∏™ÂàÜÁÆ±ÔºåÂπ∂Â∞Ü‰ªã‰∫é 30.1 Âà∞ 50.0 Â∫¶‰πãÈó¥ÁöÑÊâÄÊúâÊ∏©Â∫¶ÂΩíÂÖ•Á¨¨‰∏â‰∏™ÂàÜÁÆ±„ÄÇ C Ê†°ÂáÜÂ±Ç (calibration layer) ‰∏ÄÁßçÈ¢ÑÊµãÂêéË∞ÉÊï¥ÔºåÈÄöÂ∏∏ÊòØ‰∏∫‰∫ÜÈôç‰ΩéÈ¢ÑÊµãÂÅèÂ∑ÆÁöÑÂΩ±Âìç„ÄÇË∞ÉÊï¥ÂêéÁöÑÈ¢ÑÊµãÂíåÊ¶ÇÁéáÂ∫î‰∏éËßÇÂØüÂà∞ÁöÑÊ†áÁ≠æÈõÜÁöÑÂàÜÂ∏É‰∏ÄËá¥„ÄÇ ÂÄôÈÄâÈááÊ†∑ (candidate sampling) ‰∏ÄÁßçËÆ≠ÁªÉÊó∂ËøõË°åÁöÑ‰ºòÂåñÔºå‰ºö‰ΩøÁî®ÊüêÁßçÂáΩÊï∞Ôºà‰æãÂ¶Ç softmaxÔºâÈíàÂØπÊâÄÊúâÊ≠£Á±ªÂà´Ê†áÁ≠æËÆ°ÁÆóÊ¶ÇÁéáÔºå‰ΩÜÂØπ‰∫éË¥üÁ±ªÂà´Ê†áÁ≠æÔºåÂàô‰ªÖÈíàÂØπÂÖ∂ÈöèÊú∫Ê†∑Êú¨ËÆ°ÁÆóÊ¶ÇÁéá„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊüê‰∏™Ê†∑Êú¨ÁöÑÊ†áÁ≠æ‰∏∫‚ÄúÂ∞èÁåéÁä¨‚ÄùÂíå‚ÄúÁãó‚ÄùÔºåÂàôÂÄôÈÄâÈááÊ†∑Â∞ÜÈíàÂØπ‚ÄúÂ∞èÁåéÁä¨‚ÄùÂíå‚ÄúÁãó‚ÄùÁ±ªÂà´ËæìÂá∫‰ª•ÂèäÂÖ∂‰ªñÁ±ªÂà´ÔºàÁå´„ÄÅÊ£íÊ£íÁ≥ñ„ÄÅÊ†ÖÊ†èÔºâÁöÑÈöèÊú∫Â≠êÈõÜËÆ°ÁÆóÈ¢ÑÊµãÊ¶ÇÁéáÂíåÁõ∏Â∫îÁöÑÊçüÂ§±È°π„ÄÇËøôÁßçÈááÊ†∑Âü∫‰∫éÁöÑÊÉ≥Ê≥ïÊòØÔºåÂè™Ë¶ÅÊ≠£Á±ªÂà´ÂßãÁªàÂæóÂà∞ÈÄÇÂΩìÁöÑÊ≠£Â¢ûÂº∫ÔºåË¥üÁ±ªÂà´Â∞±ÂèØ‰ª•‰ªéÈ¢ëÁéáËæÉ‰ΩéÁöÑË¥üÂ¢ûÂº∫‰∏≠ËøõË°åÂ≠¶‰π†ÔºåËøôÁ°ÆÂÆûÊòØÂú®ÂÆûÈôÖ‰∏≠ËßÇÂØüÂà∞ÁöÑÊÉÖÂÜµ„ÄÇÂÄôÈÄâÈááÊ†∑ÁöÑÁõÆÁöÑÊòØÔºåÈÄöËøá‰∏çÈíàÂØπÊâÄÊúâË¥üÁ±ªÂà´ËÆ°ÁÆóÈ¢ÑÊµãÁªìÊûúÊù•ÊèêÈ´òËÆ°ÁÆóÊïàÁéá„ÄÇ ÂàÜÁ±ªÊï∞ÊçÆ (categorical data) ‰∏ÄÁßçÁâπÂæÅÔºåÊã•Êúâ‰∏ÄÁªÑÁ¶ªÊï£ÁöÑÂèØËÉΩÂÄº„ÄÇ‰ª•Êüê‰∏™Âêç‰∏∫ house style ÁöÑÂàÜÁ±ªÁâπÂæÅ‰∏∫‰æãÔºåËØ•ÁâπÂæÅÊã•Êúâ‰∏ÄÁªÑÁ¶ªÊï£ÁöÑÂèØËÉΩÂÄºÔºàÂÖ±‰∏â‰∏™ÔºâÔºåÂç≥ Tudor, ranch, colonial„ÄÇÈÄöËøáÂ∞Ü house style Ë°®Á§∫ÊàêÂàÜÁ±ªÊï∞ÊçÆÔºåÁõ∏Â∫îÊ®°ÂûãÂèØ‰ª•Â≠¶‰π† Tudor„ÄÅranch Âíå colonial ÂàÜÂà´ÂØπÊàø‰ª∑ÁöÑÂΩ±Âìç„ÄÇ ÊúâÊó∂ÔºåÁ¶ªÊï£ÈõÜ‰∏≠ÁöÑÂÄºÊòØ‰∫íÊñ•ÁöÑÔºåÂè™ËÉΩÂ∞ÜÂÖ∂‰∏≠‰∏Ä‰∏™ÂÄºÂ∫îÁî®‰∫éÊåáÂÆöÊ†∑Êú¨„ÄÇ‰æãÂ¶ÇÔºåcar maker ÂàÜÁ±ªÁâπÂæÅÂèØËÉΩÂè™ÂÖÅËÆ∏‰∏Ä‰∏™Ê†∑Êú¨Êúâ‰∏Ä‰∏™ÂÄº (Toyota)„ÄÇÂú®ÂÖ∂‰ªñÊÉÖÂÜµ‰∏ãÔºåÂàôÂèØ‰ª•Â∫îÁî®Â§ö‰∏™ÂÄº„ÄÇ‰∏ÄËæÜËΩ¶ÂèØËÉΩ‰ºöË¢´Âñ∑Ê∂ÇÂ§öÁßç‰∏çÂêåÁöÑÈ¢úËâ≤ÔºåÂõ†Ê≠§Ôºåcar color ÂàÜÁ±ªÁâπÂæÅÂèØËÉΩ‰ºöÂÖÅËÆ∏Âçï‰∏™Ê†∑Êú¨ÂÖ∑ÊúâÂ§ö‰∏™ÂÄºÔºà‰æãÂ¶Ç red Âíå whiteÔºâ„ÄÇ ÂàÜÁ±ªÁâπÂæÅÊúâÊó∂Áß∞‰∏∫Á¶ªÊï£ÁâπÂæÅ„ÄÇ ‰∏éÊï∞ÂÄºÊï∞ÊçÆÁõ∏ÂØπ„ÄÇ ÂΩ¢ÂøÉ (centroid) ËÅöÁ±ªÁöÑ‰∏≠ÂøÉÔºåÁî± k-means Êàñ k-median ÁÆóÊ≥ïÂÜ≥ÂÆö„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûú k ‰∏∫ 3ÔºåÂàô k-means Êàñ k-median ÁÆóÊ≥ï‰ºöÊâæÂá∫ 3 ‰∏™ÂΩ¢ÂøÉ„ÄÇ Ê£ÄÊü•ÁÇπ (checkpoint) ‰∏ÄÁßçÊï∞ÊçÆÔºåÁî®‰∫éÊçïËé∑Ê®°ÂûãÂèòÈáèÂú®ÁâπÂÆöÊó∂Èó¥ÁöÑÁä∂ÊÄÅ„ÄÇÂÄüÂä©Ê£ÄÊü•ÁÇπÔºåÂèØ‰ª•ÂØºÂá∫Ê®°ÂûãÊùÉÈáçÔºåË∑®Â§ö‰∏™‰ºöËØùÊâßË°åËÆ≠ÁªÉÔºå‰ª•Âèä‰ΩøËÆ≠ÁªÉÂú®ÂèëÁîüÈîôËØØ‰πãÂêéÂæó‰ª•ÁªßÁª≠Ôºà‰æãÂ¶Ç‰Ωú‰∏öÊä¢Âç†Ôºâ„ÄÇËØ∑Ê≥®ÊÑèÔºåÂõæÊú¨Ë∫´‰∏çÂåÖÂê´Âú®Ê£ÄÊü•ÁÇπ‰∏≠„ÄÇ Á±ªÂà´ (class) ‰∏∫Ê†áÁ≠æÊûö‰∏æÁöÑ‰∏ÄÁªÑÁõÆÊ†áÂÄº‰∏≠ÁöÑ‰∏Ä‰∏™„ÄÇ‰æãÂ¶ÇÔºåÂú®Ê£ÄÊµãÂûÉÂúæÈÇÆ‰ª∂ÁöÑ‰∫åÂÖÉÂàÜÁ±ªÊ®°Âûã‰∏≠Ôºå‰∏§ÁßçÁ±ªÂà´ÂàÜÂà´ÊòØ‚ÄúÂûÉÂúæÈÇÆ‰ª∂‚ÄùÂíå‚ÄúÈùûÂûÉÂúæÈÇÆ‰ª∂‚Äù„ÄÇÂú®ËØÜÂà´ÁãóÂìÅÁßçÁöÑÂ§öÁ±ªÂà´ÂàÜÁ±ªÊ®°Âûã‰∏≠ÔºåÁ±ªÂà´ÂèØ‰ª•ÊòØ‚ÄúË¥µÂÆæÁä¨‚Äù„ÄÅ‚ÄúÂ∞èÁåéÁä¨‚Äù„ÄÅ‚ÄúÂìàÂ∑¥Áä¨‚ÄùÁ≠âÁ≠â„ÄÇ ÂàÜÁ±ª‰∏çÂπ≥Ë°°ÁöÑÊï∞ÊçÆÈõÜ (class-imbalanced data set) ‰∏ÄÁßç‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÔºåÂú®Ê≠§Á±ªÈóÆÈ¢ò‰∏≠Ôºå‰∏§ÁßçÁ±ªÂà´ÁöÑÊ†áÁ≠æÂú®Âá∫Áé∞È¢ëÁéáÊñπÈù¢ÂÖ∑ÊúâÂæàÂ§ßÁöÑÂ∑ÆË∑ù„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∏™ÁñæÁóÖÊï∞ÊçÆÈõÜ‰∏≠Ôºå0.0001 ÁöÑÊ†∑Êú¨ÂÖ∑ÊúâÊ≠£Á±ªÂà´Ê†áÁ≠æÔºå0.9999 ÁöÑÊ†∑Êú¨ÂÖ∑ÊúâË¥üÁ±ªÂà´Ê†áÁ≠æÔºåËøôÂ∞±Â±û‰∫éÂàÜÁ±ª‰∏çÂπ≥Ë°°ÈóÆÈ¢òÔºõ‰ΩÜÂú®Êüê‰∏™Ë∂≥ÁêÉÊØîËµõÈ¢ÑÊµãÂô®‰∏≠Ôºå0.51 ÁöÑÊ†∑Êú¨ÁöÑÊ†áÁ≠æ‰∏∫ÂÖ∂‰∏≠‰∏Ä‰∏™ÁêÉÈòüËµ¢Ôºå0.49 ÁöÑÊ†∑Êú¨ÁöÑÊ†áÁ≠æ‰∏∫Âè¶‰∏Ä‰∏™ÁêÉÈòüËµ¢ÔºåËøôÂ∞±‰∏çÂ±û‰∫éÂàÜÁ±ª‰∏çÂπ≥Ë°°ÈóÆÈ¢ò„ÄÇ ÂàÜÁ±ªÊ®°Âûã (classification model) ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºåÁî®‰∫éÂå∫ÂàÜ‰∏§ÁßçÊàñÂ§öÁßçÁ¶ªÊï£Á±ªÂà´„ÄÇ‰æãÂ¶ÇÔºåÊüê‰∏™Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂàÜÁ±ªÊ®°ÂûãÂèØ‰ª•Á°ÆÂÆöËæìÂÖ•ÁöÑÂè•Â≠êÊòØÊ≥ïËØ≠„ÄÅË•øÁè≠ÁâôËØ≠ËøòÊòØÊÑèÂ§ßÂà©ËØ≠„ÄÇËØ∑‰∏éÂõûÂΩíÊ®°ÂûãËøõË°åÊØîËæÉ„ÄÇ ÂàÜÁ±ªÈòàÂÄº (classification threshold) ‰∏ÄÁßçÊ†áÈáèÂÄºÊù°‰ª∂ÔºåÂ∫îÁî®‰∫éÊ®°ÂûãÈ¢ÑÊµãÁöÑÂæóÂàÜÔºåÊó®Âú®Â∞ÜÊ≠£Á±ªÂà´‰∏éË¥üÁ±ªÂà´Âå∫ÂàÜÂºÄ„ÄÇÂ∞ÜÈÄªËæëÂõûÂΩíÁªìÊûúÊò†Â∞ÑÂà∞‰∫åÂÖÉÂàÜÁ±ªÊó∂‰ΩøÁî®„ÄÇ‰ª•Êüê‰∏™ÈÄªËæëÂõûÂΩíÊ®°Âûã‰∏∫‰æãÔºåËØ•Ê®°ÂûãÁî®‰∫éÁ°ÆÂÆöÊåáÂÆöÁîµÂ≠êÈÇÆ‰ª∂ÊòØÂûÉÂúæÈÇÆ‰ª∂ÁöÑÊ¶ÇÁéá„ÄÇÂ¶ÇÊûúÂàÜÁ±ªÈòàÂÄº‰∏∫ 0.9ÔºåÈÇ£‰πàÈÄªËæëÂõûÂΩíÂÄºÈ´ò‰∫é 0.9 ÁöÑÁîµÂ≠êÈÇÆ‰ª∂Â∞ÜË¢´ÂΩíÁ±ª‰∏∫‚ÄúÂûÉÂúæÈÇÆ‰ª∂‚ÄùÔºå‰Ωé‰∫é 0.9 ÁöÑÂàôË¢´ÂΩíÁ±ª‰∏∫‚ÄúÈùûÂûÉÂúæÈÇÆ‰ª∂‚Äù„ÄÇ ËÅöÁ±ª (clustering) Â∞ÜÂÖ≥ËÅîÁöÑÊ†∑Êú¨ÂàÜÊàê‰∏ÄÁªÑÔºå‰∏ÄËà¨Áî®‰∫éÈùûÁõëÁù£ÂºèÂ≠¶‰π†„ÄÇÂú®ÊâÄÊúâÊ†∑Êú¨ÂùáÂàÜÁªÑÂÆåÊØïÂêéÔºåÁõ∏ÂÖ≥‰∫∫Âëò‰æøÂèØÈÄâÊã©ÊÄßÂú∞‰∏∫ÊØè‰∏™ËÅöÁ±ªËµã‰∫àÂê´‰πâ„ÄÇ ËÅöÁ±ªÁÆóÊ≥ïÊúâÂæàÂ§ö„ÄÇ‰æãÂ¶ÇÔºåk-means ÁÆóÊ≥ï‰ºöÂü∫‰∫éÊ†∑Êú¨‰∏éÂΩ¢ÂøÉÁöÑÊé•ËøëÁ®ãÂ∫¶ËÅöÁ±ªÊ†∑Êú¨ÔºåÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö image/svg+xml 50 or so examples clustered into two groups. Ê†ë È´òÂ∫¶ Ê†ëÂÆΩÂ∫¶ ÂΩ¢ÂøÉ ËÅöÁ±ª 1 ËÅöÁ±ª 2 ‰πãÂêéÔºåÁ†îÁ©∂‰∫∫Âëò‰æøÂèØÊü•ÁúãËøô‰∫õËÅöÁ±ªÂπ∂ËøõË°åÂÖ∂‰ªñÊìç‰ΩúÔºå‰æãÂ¶ÇÔºåÂ∞ÜËÅöÁ±ª 1 Ê†áËÆ∞‰∏∫‚ÄúÁüÆÂûãÊ†ë‚ÄùÔºåÂ∞ÜËÅöÁ±ª 2 Ê†áËÆ∞‰∏∫‚ÄúÂÖ®Â∞∫ÂØ∏Ê†ë‚Äù„ÄÇ ÂÜç‰∏æ‰∏Ä‰∏™‰æãÂ≠êÔºå‰æãÂ¶ÇÂü∫‰∫éÊ†∑Êú¨‰∏é‰∏≠ÂøÉÁÇπË∑ùÁ¶ªÁöÑËÅöÁ±ªÁÆóÊ≥ïÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö image/svg+xml Three sets of examples, each somewhat further from the center. ËÅöÁ±ª 1 ËÅöÁ±ª 2 ËÅöÁ±ª 3 ÂçèÂêåËøáÊª§ (collaborative filtering) Ê†πÊçÆÂæàÂ§öÂÖ∂‰ªñÁî®Êà∑ÁöÑÂÖ¥Ë∂£Êù•È¢ÑÊµãÊüê‰ΩçÁî®Êà∑ÁöÑÂÖ¥Ë∂£„ÄÇÂçèÂêåËøáÊª§ÈÄöÂ∏∏Áî®Âú®Êé®ËçêÁ≥ªÁªü‰∏≠„ÄÇ Ê∑∑Ê∑ÜÁü©Èòµ (confusion matrix) ‰∏ÄÁßç NxN Ë°®Ê†ºÔºåÁî®‰∫éÊÄªÁªìÂàÜÁ±ªÊ®°ÂûãÁöÑÈ¢ÑÊµãÊïàÊûúÔºõÂç≥Ê†áÁ≠æÂíåÊ®°ÂûãÈ¢ÑÊµãÁöÑÂàÜÁ±ª‰πãÈó¥ÁöÑÂÖ≥ËÅî„ÄÇÂú®Ê∑∑Ê∑ÜÁü©Èòµ‰∏≠Ôºå‰∏Ä‰∏™ËΩ¥Ë°®Á§∫Ê®°ÂûãÈ¢ÑÊµãÁöÑÊ†áÁ≠æÔºåÂè¶‰∏Ä‰∏™ËΩ¥Ë°®Á§∫ÂÆûÈôÖÊ†áÁ≠æ„ÄÇN Ë°®Á§∫Á±ªÂà´‰∏™Êï∞„ÄÇÂú®‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÔºåN=2„ÄÇ‰æãÂ¶ÇÔºå‰∏ãÈù¢ÊòæÁ§∫‰∫Ü‰∏Ä‰∏™‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÁöÑÊ∑∑Ê∑ÜÁü©ÈòµÁ§∫‰æãÔºö ËÇøÁò§ÔºàÈ¢ÑÊµãÁöÑÊ†áÁ≠æÔºâ ÈùûËÇøÁò§ÔºàÈ¢ÑÊµãÁöÑÊ†áÁ≠æÔºâ ËÇøÁò§ÔºàÂÆûÈôÖÊ†áÁ≠æÔºâ 18 1 ÈùûËÇøÁò§ÔºàÂÆûÈôÖÊ†áÁ≠æÔºâ 6 452 ‰∏äÈù¢ÁöÑÊ∑∑Ê∑ÜÁü©ÈòµÊòæÁ§∫ÔºåÂú® 19 ‰∏™ÂÆûÈôÖÊúâËÇøÁò§ÁöÑÊ†∑Êú¨‰∏≠ÔºåËØ•Ê®°ÂûãÊ≠£Á°ÆÂú∞Â∞Ü 18 ‰∏™ÂΩíÁ±ª‰∏∫ÊúâËÇøÁò§Ôºà18 ‰∏™Ê≠£‰æãÔºâÔºåÈîôËØØÂú∞Â∞Ü 1 ‰∏™ÂΩíÁ±ª‰∏∫Ê≤°ÊúâËÇøÁò§Ôºà1 ‰∏™ÂÅáË¥ü‰æãÔºâ„ÄÇÂêåÊ†∑ÔºåÂú® 458 ‰∏™ÂÆûÈôÖÊ≤°ÊúâËÇøÁò§ÁöÑÊ†∑Êú¨‰∏≠ÔºåÊ®°ÂûãÂΩíÁ±ªÊ≠£Á°ÆÁöÑÊúâ 452 ‰∏™Ôºà452 ‰∏™Ë¥ü‰æãÔºâÔºåÂΩíÁ±ªÈîôËØØÁöÑÊúâ 6 ‰∏™Ôºà6 ‰∏™ÂÅáÊ≠£‰æãÔºâ„ÄÇ Â§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢òÁöÑÊ∑∑Ê∑ÜÁü©ÈòµÊúâÂä©‰∫éÁ°ÆÂÆöÂá∫ÈîôÊ®°Âºè„ÄÇ‰æãÂ¶ÇÔºåÊüê‰∏™Ê∑∑Ê∑ÜÁü©ÈòµÂèØ‰ª•Êè≠Á§∫ÔºåÊüê‰∏™ÁªèËøáËÆ≠ÁªÉ‰ª•ËØÜÂà´ÊâãÂÜôÊï∞Â≠óÁöÑÊ®°ÂûãÂæÄÂæÄ‰ºöÂ∞Ü 4 ÈîôËØØÂú∞È¢ÑÊµã‰∏∫ 9ÔºåÂ∞Ü 7 ÈîôËØØÂú∞È¢ÑÊµã‰∏∫ 1„ÄÇ Ê∑∑Ê∑ÜÁü©ÈòµÂåÖÂê´ËÆ°ÁÆóÂêÑÁßçÊïàÊûúÊåáÊ†áÔºàÂåÖÊã¨Á≤æÁ°ÆÁéáÂíåÂè¨ÂõûÁéáÔºâÊâÄÈúÄÁöÑÂÖÖË∂≥‰ø°ÊÅØ„ÄÇ ËøûÁª≠ÁâπÂæÅ (continuous feature) ‰∏ÄÁßçÊµÆÁÇπÁâπÂæÅÔºåÂèØËÉΩÂÄºÁöÑÂå∫Èó¥‰∏çÂèóÈôêÂà∂„ÄÇ‰∏éÁ¶ªÊï£ÁâπÂæÅÁõ∏ÂØπ„ÄÇ Êî∂Êïõ (convergence) ÈÄö‰øóÊù•ËØ¥ÔºåÊî∂ÊïõÈÄöÂ∏∏ÊòØÊåáÂú®ËÆ≠ÁªÉÊúüÈó¥ËææÂà∞ÁöÑ‰∏ÄÁßçÁä∂ÊÄÅÔºåÂç≥ÁªèËøá‰∏ÄÂÆöÊ¨°Êï∞ÁöÑËø≠‰ª£‰πãÂêéÔºåËÆ≠ÁªÉÊçüÂ§±ÂíåÈ™åËØÅÊçüÂ§±Âú®ÊØèÊ¨°Ëø≠‰ª£‰∏≠ÁöÑÂèòÂåñÈÉΩÈùûÂ∏∏Â∞èÊàñÊ†πÊú¨Ê≤°ÊúâÂèòÂåñ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂ¶ÇÊûúÈááÁî®ÂΩìÂâçÊï∞ÊçÆËøõË°åÈ¢ùÂ§ñÁöÑËÆ≠ÁªÉÂ∞ÜÊó†Ê≥ïÊîπËøõÊ®°ÂûãÔºåÊ®°ÂûãÂç≥ËææÂà∞Êî∂ÊïõÁä∂ÊÄÅ„ÄÇÂú®Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÔºåÊçüÂ§±ÂÄºÊúâÊó∂‰ºöÂú®ÊúÄÁªà‰∏ãÈôç‰πãÂâçÁöÑÂ§öÊ¨°Ëø≠‰ª£‰∏≠‰øùÊåÅ‰∏çÂèòÊàñÂá†‰πé‰øùÊåÅ‰∏çÂèòÔºåÊöÇÊó∂ÂΩ¢ÊàêÊî∂ÊïõÁöÑÂÅáË±°„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÊó©ÂÅúÊ≥ï„ÄÇ Âè¶ËØ∑ÂèÇÈòÖ Boyd Âíå Vandenberghe ÂêàËëóÁöÑ Convex OptimizationÔºà„ÄäÂá∏‰ºòÂåñ„ÄãÔºâ„ÄÇ Âá∏ÂáΩÊï∞ (convex function) ‰∏ÄÁßçÂáΩÊï∞ÔºåÂáΩÊï∞ÂõæÂÉè‰ª•‰∏äÁöÑÂå∫Âüü‰∏∫Âá∏ÈõÜ„ÄÇÂÖ∏ÂûãÂá∏ÂáΩÊï∞ÁöÑÂΩ¢Áä∂Á±ª‰ºº‰∫éÂ≠óÊØç U„ÄÇ‰æãÂ¶ÇÔºå‰ª•‰∏ãÈÉΩÊòØÂá∏ÂáΩÊï∞Ôºö Áõ∏ÂèçÔºå‰ª•‰∏ãÂáΩÊï∞Âàô‰∏çÊòØÂá∏ÂáΩÊï∞„ÄÇËØ∑Ê≥®ÊÑèÂõæÂÉè‰∏äÊñπÁöÑÂå∫ÂüüÂ¶Ç‰Ωï‰∏çÊòØÂá∏ÈõÜÔºö ÈùûÂá∏ÂáΩÊï∞ ÈùûÂá∏ÂáΩÊï∞„ÄÇ Â±ÄÈÉ®ÊúÄ‰ΩéÁÇπ Â±ÄÈÉ®ÊúÄ‰ΩéÁÇπ ÂÖ®Â±ÄÊúÄ‰ΩéÁÇπ ‰∏•Ê†ºÂá∏ÂáΩÊï∞Âè™Êúâ‰∏Ä‰∏™Â±ÄÈÉ®ÊúÄ‰ΩéÁÇπÔºåËØ•ÁÇπ‰πüÊòØÂÖ®Â±ÄÊúÄ‰ΩéÁÇπ„ÄÇÁªèÂÖ∏ÁöÑ U ÂΩ¢ÂáΩÊï∞ÈÉΩÊòØ‰∏•Ê†ºÂá∏ÂáΩÊï∞„ÄÇ‰∏çËøáÔºåÊúâ‰∫õÂá∏ÂáΩÊï∞Ôºà‰æãÂ¶ÇÁõ¥Á∫øÔºâÂàô‰∏çÊòØËøôÊ†∑„ÄÇ ÂæàÂ§öÂ∏∏ËßÅÁöÑÊçüÂ§±ÂáΩÊï∞ÔºàÂåÖÊã¨‰∏ãÂàóÂáΩÊï∞ÔºâÈÉΩÊòØÂá∏ÂáΩÊï∞Ôºö L2 ÊçüÂ§±ÂáΩÊï∞ ÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ L1 Ê≠£ÂàôÂåñ L2 Ê≠£ÂàôÂåñ Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÁöÑÂæàÂ§öÂèò‰ΩìÈÉΩ‰∏ÄÂÆöËÉΩÊâæÂà∞‰∏Ä‰∏™Êé•Ëøë‰∏•Ê†ºÂá∏ÂáΩÊï∞ÊúÄÂ∞èÂÄºÁöÑÁÇπ„ÄÇÂêåÊ†∑ÔºåÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÁöÑÂæàÂ§öÂèò‰ΩìÈÉΩÊúâÂæàÈ´òÁöÑÂèØËÉΩÊÄßËÉΩÂ§üÊâæÂà∞Êé•Ëøë‰∏•Ê†ºÂá∏ÂáΩÊï∞ÊúÄÂ∞èÂÄºÁöÑÁÇπÔºà‰ΩÜÂπ∂Èùû‰∏ÄÂÆöËÉΩÊâæÂà∞Ôºâ„ÄÇ ‰∏§‰∏™Âá∏ÂáΩÊï∞ÁöÑÂíåÔºà‰æãÂ¶Ç L2 ÊçüÂ§±ÂáΩÊï∞ + L1 Ê≠£ÂàôÂåñÔºâ‰πüÊòØÂá∏ÂáΩÊï∞„ÄÇ Ê∑±Â∫¶Ê®°ÂûãÁªù‰∏ç‰ºöÊòØÂá∏ÂáΩÊï∞„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰∏ìÈó®ÈíàÂØπÂá∏‰ºòÂåñËÆæËÆ°ÁöÑÁÆóÊ≥ïÂæÄÂæÄÊÄªËÉΩÂú®Ê∑±Â∫¶ÁΩëÁªú‰∏äÊâæÂà∞ÈùûÂ∏∏Â•ΩÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåËôΩÁÑ∂Ëøô‰∫õËß£ÂÜ≥ÊñπÊ°àÂπ∂‰∏ç‰∏ÄÂÆöÂØπÂ∫î‰∫éÂÖ®Â±ÄÊúÄÂ∞èÂÄº„ÄÇ Âá∏‰ºòÂåñ (convex optimization) ‰ΩøÁî®Êï∞Â≠¶ÊñπÊ≥ïÔºà‰æãÂ¶ÇÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºâÂØªÊâæÂá∏ÂáΩÊï∞ÊúÄÂ∞èÂÄºÁöÑËøáÁ®ã„ÄÇÊú∫Âô®Â≠¶‰π†ÊñπÈù¢ÁöÑÂ§ßÈáèÁ†îÁ©∂ÈÉΩÊòØ‰∏ìÊ≥®‰∫éÂ¶Ç‰ΩïÈÄöËøáÂÖ¨ÂºèÂ∞ÜÂêÑÁßçÈóÆÈ¢òË°®Á§∫ÊàêÂá∏‰ºòÂåñÈóÆÈ¢òÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊõ¥È´òÊïàÂú∞Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇ Â¶ÇÈúÄÂÆåÊï¥ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ Boyd Âíå Vandenberghe ÂêàËëóÁöÑ Convex OptimizationÔºà„ÄäÂá∏‰ºòÂåñ„ÄãÔºâ„ÄÇ Âá∏ÈõÜ (convex set) Ê¨ßÂá†ÈáåÂæóÁ©∫Èó¥ÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºåÂÖ∂‰∏≠‰ªªÊÑè‰∏§ÁÇπ‰πãÈó¥ÁöÑËøûÁ∫ø‰ªçÂÆåÂÖ®ËêΩÂú®ËØ•Â≠êÈõÜÂÜÖ„ÄÇ‰æãÂ¶ÇÔºå‰∏ãÈù¢ÁöÑ‰∏§‰∏™ÂõæÂΩ¢ÈÉΩÊòØÂá∏ÈõÜÔºö Áõ∏ÂèçÔºå‰∏ãÈù¢ÁöÑ‰∏§‰∏™ÂõæÂΩ¢ÈÉΩ‰∏çÊòØÂá∏ÈõÜÔºö Âç∑ÁßØ (convolution) ÁÆÄÂçïÊù•ËØ¥ÔºåÂç∑ÁßØÂú®Êï∞Â≠¶‰∏≠Êåá‰∏§‰∏™ÂáΩÊï∞ÁöÑÁªÑÂêà„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÂç∑ÁßØÁªìÂêà‰ΩøÁî®Âç∑ÁßØËøáÊª§Âô®ÂíåËæìÂÖ•Áü©ÈòµÊù•ËÆ≠ÁªÉÊùÉÈáç„ÄÇ Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑ‚ÄúÂç∑ÁßØ‚Äù‰∏ÄËØçÈÄöÂ∏∏ÊòØÂç∑ÁßØËøêÁÆóÊàñÂç∑ÁßØÂ±ÇÁöÑÁÆÄÁß∞„ÄÇ Â¶ÇÊûúÊ≤°ÊúâÂç∑ÁßØÔºåÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂ∞±ÈúÄË¶ÅÂ≠¶‰π†Â§ßÂº†Èáè‰∏≠ÊØè‰∏™ÂçïÂÖÉÊ†ºÂêÑËá™ÁöÑÊùÉÈáç„ÄÇ‰æãÂ¶ÇÔºåÁî® 2K x 2K ÂõæÂÉèËÆ≠ÁªÉÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂ∞ÜË¢´Ëø´ÊâæÂá∫ 400 ‰∏á‰∏™ÂçïÁã¨ÁöÑÊùÉÈáç„ÄÇËÄå‰ΩøÁî®Âç∑ÁßØÔºåÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂè™ÈúÄÂú®Âç∑ÁßØËøáÊª§Âô®‰∏≠ÊâæÂá∫ÊØè‰∏™ÂçïÂÖÉÊ†ºÁöÑÊùÉÈáçÔºåÂ§ßÂ§ßÂáèÂ∞ë‰∫ÜËÆ≠ÁªÉÊ®°ÂûãÊâÄÈúÄÁöÑÂÜÖÂ≠ò„ÄÇÂú®Â∫îÁî®Âç∑ÁßØËøáÊª§Âô®ÂêéÔºåÂÆÉÂè™ÈúÄË∑®ÂçïÂÖÉÊ†ºËøõË°åÂ§çÂà∂ÔºåÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩ‰ºö‰∏éËøáÊª§Âô®Áõ∏‰πò„ÄÇ Âç∑ÁßØËøáÊª§Âô® (convolutional filter) Âç∑ÁßØËøêÁÆó‰∏≠ÁöÑ‰∏§‰∏™ÂèÇ‰∏éÊñπ‰πã‰∏Ä„ÄÇÔºàÂè¶‰∏Ä‰∏™ÂèÇ‰∏éÊñπÊòØËæìÂÖ•Áü©ÈòµÂàáÁâá„ÄÇÔºâÂç∑ÁßØËøáÊª§Âô®ÊòØ‰∏ÄÁßçÁü©ÈòµÔºåÂÖ∂Á≠âÁ∫ß‰∏éËæìÂÖ•Áü©ÈòµÁõ∏ÂêåÔºå‰ΩÜÂΩ¢Áä∂Â∞è‰∏Ä‰∫õ„ÄÇ‰ª• 28√ó28 ÁöÑËæìÂÖ•Áü©Èòµ‰∏∫‰æãÔºåËøáÊª§Âô®ÂèØ‰ª•ÊòØÂ∞è‰∫é 28√ó28 ÁöÑ‰ªª‰Ωï‰∫åÁª¥Áü©Èòµ„ÄÇ Âú®ÂõæÂΩ¢Êìç‰Ωú‰∏≠ÔºåÂç∑ÁßØËøáÊª§Âô®‰∏≠ÁöÑÊâÄÊúâÂçïÂÖÉÊ†ºÈÄöÂ∏∏ÊåâÁÖßÂõ∫ÂÆöÊ®°ÂºèËÆæÁΩÆ‰∏∫ 1 Âíå 0„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÂç∑ÁßØËøáÊª§Âô®ÈÄöÂ∏∏ÂÖàÈÄâÊã©ÈöèÊú∫Êï∞Â≠óÔºåÁÑ∂ÂêéÁî±ÁΩëÁªúËÆ≠ÁªÉÂá∫ÁêÜÊÉ≥ÂÄº„ÄÇ Âç∑ÁßØÂ±Ç (convolutional layer) Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑ‰∏Ä‰∏™Â±ÇÔºåÂç∑ÁßØËøáÊª§Âô®‰ºöÂú®ÂÖ∂‰∏≠‰º†ÈÄíËæìÂÖ•Áü©Èòµ„ÄÇ‰ª•‰∏ãÈù¢ÁöÑ 3x3 Âç∑ÁßØËøáÊª§Âô®‰∏∫‰æãÔºö ‰∏ãÈù¢ÁöÑÂä®ÁîªÊòæÁ§∫‰∫Ü‰∏Ä‰∏™Áî± 9 ‰∏™Âç∑ÁßØËøêÁÆóÔºàÊ∂âÂèä 5x5 ËæìÂÖ•Áü©ÈòµÔºâÁªÑÊàêÁöÑÂç∑ÁßØÂ±Ç„ÄÇËØ∑Ê≥®ÊÑèÔºåÊØè‰∏™Âç∑ÁßØËøêÁÆóÈÉΩÊ∂âÂèä‰∏Ä‰∏™‰∏çÂêåÁöÑ 3x3 ËæìÂÖ•Áü©ÈòµÂàáÁâá„ÄÇÁî±Ê≠§‰∫ßÁîüÁöÑ 3√ó3 Áü©ÈòµÔºàÂè≥‰æßÔºâÂ∞±ÂåÖÂê´ 9 ‰∏™Âç∑ÁßØËøêÁÆóÁöÑÁªìÊûúÔºö Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (convolutional neural network) ‰∏ÄÁßçÁ•ûÁªèÁΩëÁªúÔºåÂÖ∂‰∏≠Ëá≥Â∞ëÊúâ‰∏ÄÂ±Ç‰∏∫Âç∑ÁßØÂ±Ç„ÄÇÂÖ∏ÂûãÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÂåÖÂê´‰ª•‰∏ãÂá†Â±ÇÁöÑÁªÑÂêàÔºö Âç∑ÁßØÂ±Ç Ê±†ÂåñÂ±Ç ÂØÜÈõÜÂ±Ç Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÂú®Ëß£ÂÜ≥Êüê‰∫õÁ±ªÂûãÁöÑÈóÆÈ¢òÔºàÂ¶ÇÂõæÂÉèËØÜÂà´Ôºâ‰∏äÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂäü„ÄÇ Âç∑ÁßØËøêÁÆó (convolutional operation) Â¶Ç‰∏ãÊâÄÁ§∫ÁöÑ‰∏§Ê≠•Êï∞Â≠¶ËøêÁÆóÔºö ÂØπÂç∑ÁßØËøáÊª§Âô®ÂíåËæìÂÖ•Áü©ÈòµÂàáÁâáÊâßË°åÂÖÉÁ¥†Á∫ß‰πòÊ≥ï„ÄÇÔºàËæìÂÖ•Áü©ÈòµÂàáÁâá‰∏éÂç∑ÁßØËøáÊª§Âô®ÂÖ∑ÊúâÁõ∏ÂêåÁöÑÁ≠âÁ∫ßÂíåÂ§ßÂ∞è„ÄÇÔºâ ÂØπÁîüÊàêÁöÑÁßØÁü©Èòµ‰∏≠ÁöÑÊâÄÊúâÂÄºÊ±ÇÂíå„ÄÇ ‰ª•‰∏ãÈù¢ÁöÑ 5x5 ËæìÂÖ•Áü©Èòµ‰∏∫‰æãÔºö Áé∞Âú®Ôºå‰ª•‰∏ãÈù¢Ëøô‰∏™ 2x2 Âç∑ÁßØËøáÊª§Âô®‰∏∫‰æãÔºö ÊØè‰∏™Âç∑ÁßØËøêÁÆóÈÉΩÊ∂âÂèä‰∏Ä‰∏™ 2x2 ËæìÂÖ•Áü©ÈòµÂàáÁâá„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊàë‰ª¨‰ΩøÁî®ËæìÂÖ•Áü©ÈòµÂ∑¶‰∏äËßíÁöÑ 2x2 ÂàáÁâá„ÄÇËøôÊ†∑‰∏ÄÊù•ÔºåÂØπÊ≠§ÂàáÁâáËøõË°åÂç∑ÁßØËøêÁÆóÂ∞ÜÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö Âç∑ÁßØÂ±ÇÁî±‰∏ÄÁ≥ªÂàóÂç∑ÁßØËøêÁÆóÁªÑÊàêÔºåÊØè‰∏™Âç∑ÁßØËøêÁÆóÈÉΩÈíàÂØπ‰∏çÂêåÁöÑËæìÂÖ•Áü©ÈòµÂàáÁâá„ÄÇ ÊàêÊú¨ (cost) ‰∏éÊçüÂ§±ÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ ‰∫§ÂèâÁÜµ (cross-entropy) ÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ÂêëÂ§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢òÁöÑ‰∏ÄÁßçÊ≥õÂåñ„ÄÇ‰∫§ÂèâÁÜµÂèØ‰ª•ÈáèÂåñ‰∏§ÁßçÊ¶ÇÁéáÂàÜÂ∏É‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÂè¶ËØ∑ÂèÇÈòÖÂõ∞ÊÉëÂ∫¶„ÄÇ Ëá™ÂÆö‰πâ Estimator (custom Estimator) ÊÇ®ÊåâÁÖßËøô‰∫õËØ¥ÊòéËá™Ë°åÁºñÂÜôÁöÑ Estimator„ÄÇ ‰∏éÈ¢ÑÂàõÂª∫ÁöÑ Estimator Áõ∏ÂØπ„ÄÇ D Êï∞ÊçÆÂàÜÊûê (data analysis) Ê†πÊçÆÊ†∑Êú¨„ÄÅÊµãÈáèÁªìÊûúÂíåÂèØËßÜÂåñÂÜÖÂÆπÊù•ÁêÜËß£Êï∞ÊçÆ„ÄÇÊï∞ÊçÆÂàÜÊûêÂú®È¶ñÊ¨°Êî∂Âà∞Êï∞ÊçÆÈõÜ„ÄÅÊûÑÂª∫Á¨¨‰∏Ä‰∏™Ê®°Âûã‰πãÂâçÁâπÂà´ÊúâÁî®„ÄÇÊ≠§Â§ñÔºåÊï∞ÊçÆÂàÜÊûêÂú®ÁêÜËß£ÂÆûÈ™åÂíåË∞ÉËØïÁ≥ªÁªüÈóÆÈ¢òÊñπÈù¢‰πüËá≥ÂÖ≥ÈáçË¶Å„ÄÇ DataFrame ‰∏ÄÁßçÁÉ≠Èó®ÁöÑÊï∞ÊçÆÁ±ªÂûãÔºåÁî®‰∫éË°®Á§∫ Pandas ‰∏≠ÁöÑÊï∞ÊçÆÈõÜ„ÄÇDataFrame Á±ª‰ºº‰∫éË°®Ê†º„ÄÇDataFrame ÁöÑÊØè‰∏ÄÂàóÈÉΩÊúâ‰∏Ä‰∏™ÂêçÁß∞ÔºàÊ†áÈ¢òÔºâÔºåÊØè‰∏ÄË°åÈÉΩÁî±‰∏Ä‰∏™Êï∞Â≠óÊ†áËØÜ„ÄÇ Êï∞ÊçÆÈõÜ (data set) ‰∏ÄÁªÑÊ†∑Êú¨ÁöÑÈõÜÂêà„ÄÇ Dataset API (tf.data) ‰∏ÄÁßçÈ´òÁ∫ßÂà´ÁöÑ TensorFlow APIÔºåÁî®‰∫éËØªÂèñÊï∞ÊçÆÂπ∂Â∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊâÄÈúÄÁöÑÊ†ºÂºè„ÄÇtf.data.Dataset ÂØπË±°Ë°®Á§∫‰∏ÄÁ≥ªÂàóÂÖÉÁ¥†ÔºåÂÖ∂‰∏≠ÊØè‰∏™ÂÖÉÁ¥†ÈÉΩÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™Âº†Èáè„ÄÇtf.data.Iterator ÂØπË±°ÂèØËé∑Âèñ Dataset ‰∏≠ÁöÑÂÖÉÁ¥†„ÄÇ Â¶ÇÈúÄËØ¶ÁªÜ‰∫ÜËß£ Dataset APIÔºåËØ∑ÂèÇÈòÖ„ÄäTensorFlow ÁºñÁ®ã‰∫∫ÂëòÊåáÂçó„Äã‰∏≠ÁöÑÂØºÂÖ•Êï∞ÊçÆ„ÄÇ ÂÜ≥Á≠ñËæπÁïå (decision boundary) Âú®‰∫åÂÖÉÂàÜÁ±ªÊàñÂ§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÔºåÊ®°ÂûãÂ≠¶Âà∞ÁöÑÁ±ªÂà´‰πãÈó¥ÁöÑÂàÜÁïåÁ∫ø„ÄÇ‰æãÂ¶ÇÔºåÂú®‰ª•‰∏ãË°®Á§∫Êüê‰∏™‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÁöÑÂõæÁâá‰∏≠ÔºåÂÜ≥Á≠ñËæπÁïåÊòØÊ©ôËâ≤Á±ªÂà´ÂíåËìùËâ≤Á±ªÂà´‰πãÈó¥ÁöÑÂàÜÁïåÁ∫øÔºö ÂØÜÈõÜÂ±Ç (dense layer) ‰∏éÂÖ®ËøûÊé•Â±ÇÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ Ê∑±Â∫¶Ê®°Âûã (deep model) ‰∏ÄÁßçÁ•ûÁªèÁΩëÁªúÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§ö‰∏™ÈöêËóèÂ±Ç„ÄÇÊ∑±Â∫¶Ê®°Âûã‰æùËµñ‰∫éÂèØËÆ≠ÁªÉÁöÑÈùûÁ∫øÊÄßÂÖ≥Á≥ª„ÄÇ ‰∏éÂÆΩÂ∫¶Ê®°ÂûãÁõ∏ÂØπ„ÄÇ ÂØÜÈõÜÁâπÂæÅ (dense feature) ‰∏ÄÁßçÂ§ßÈÉ®ÂàÜÂÄºÊòØÈùûÈõ∂ÂÄºÁöÑÁâπÂæÅÔºåÈÄöÂ∏∏ÊòØÊµÆÁÇπÂÄºÂº†Èáè„ÄÇ‰∏éÁ®ÄÁñèÁâπÂæÅÁõ∏ÂØπ„ÄÇ ËÆæÂ§á (device) ‰∏ÄÁ±ªÂèØËøêË°å TensorFlow ‰ºöËØùÁöÑÁ°¨‰ª∂ÔºåÂåÖÊã¨ CPU„ÄÅGPU Âíå TPU„ÄÇ Á¶ªÊï£ÁâπÂæÅ (discrete feature) ‰∏ÄÁßçÁâπÂæÅÔºåÂåÖÂê´ÊúâÈôê‰∏™ÂèØËÉΩÂÄº„ÄÇ‰æãÂ¶ÇÔºåÊüê‰∏™ÂÄºÂè™ËÉΩÊòØ‚ÄúÂä®Áâ©‚Äù„ÄÅ‚ÄúËî¨Ëèú‚ÄùÊàñ‚ÄúÁüøÁâ©‚ÄùÁöÑÁâπÂæÅ‰æøÊòØ‰∏Ä‰∏™Á¶ªÊï£ÁâπÂæÅÔºàÊàñÂàÜÁ±ªÁâπÂæÅÔºâ„ÄÇ‰∏éËøûÁª≠ÁâπÂæÅÁõ∏ÂØπ„ÄÇ ‰∏¢ÂºÉÊ≠£ÂàôÂåñ (dropout regularization) Ê≠£ÂàôÂåñÁöÑ‰∏ÄÁßçÂΩ¢ÂºèÔºåÂú®ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÊñπÈù¢ÈùûÂ∏∏ÊúâÁî®„ÄÇ‰∏¢ÂºÉÊ≠£ÂàôÂåñÁöÑËøê‰ΩúÊú∫Âà∂ÊòØÔºåÂú®‰∏Ä‰∏™Ê¢ØÂ∫¶Ê≠•Èïø‰∏≠ÁßªÈô§‰ªéÁ•ûÁªèÁΩëÁªúÂ±Ç‰∏≠ÈöèÊú∫ÈÄâÊã©ÁöÑÂõ∫ÂÆöÊï∞ÈáèÁöÑÂçïÂÖÉ„ÄÇ‰∏¢ÂºÉÁöÑÂçïÂÖÉË∂äÂ§öÔºåÊ≠£ÂàôÂåñÊïàÊûúÂ∞±Ë∂äÂº∫„ÄÇËøôÁ±ª‰ºº‰∫éËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú‰ª•Ê®°ÊãüËæÉÂ∞èÁΩëÁªúÁöÑÊåáÊï∞Á∫ßËßÑÊ®°ÈõÜÊàêÂ≠¶‰π†„ÄÇÂ¶ÇÈúÄÂÆåÊï¥ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ Dropout: A Simple Way to Prevent Neural Networks from OverfittingÔºà„Ää‰∏¢ÂºÉÔºö‰∏ÄÁßçÈò≤Ê≠¢Á•ûÁªèÁΩëÁªúËøáÊãüÂêàÁöÑÁÆÄÂçïÊñπÊ≥ï„ÄãÔºâ„ÄÇ Âä®ÊÄÅÊ®°Âûã (dynamic model) ‰∏ÄÁßçÊ®°ÂûãÔºå‰ª•ÊåÅÁª≠Êõ¥Êñ∞ÁöÑÊñπÂºèÂú®Á∫øÊé•ÂèóËÆ≠ÁªÉ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÊï∞ÊçÆ‰ºöÊ∫êÊ∫ê‰∏çÊñ≠Âú∞ËøõÂÖ•ËøôÁßçÊ®°Âûã„ÄÇ E Êó©ÂÅúÊ≥ï (early stopping) ‰∏ÄÁßçÊ≠£ÂàôÂåñÊñπÊ≥ïÔºåÊòØÊåáÂú®ËÆ≠ÁªÉÊçüÂ§±‰ªçÂèØ‰ª•ÁªßÁª≠Èôç‰Ωé‰πãÂâçÁªìÊùüÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ‰ΩøÁî®Êó©ÂÅúÊ≥ïÊó∂ÔºåÊÇ®‰ºöÂú®È™åËØÅÊï∞ÊçÆÈõÜÁöÑÊçüÂ§±ÂºÄÂßãÂ¢ûÂ§ßÔºà‰πüÂ∞±ÊòØÊ≥õÂåñÊïàÊûúÂèòÂ∑ÆÔºâÊó∂ÁªìÊùüÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ ÂµåÂ•ó (embeddings) ‰∏ÄÁßçÂàÜÁ±ªÁâπÂæÅÔºå‰ª•ËøûÁª≠ÂÄºÁâπÂæÅË°®Á§∫„ÄÇÈÄöÂ∏∏ÔºåÂµåÂ•óÊòØÊåáÂ∞ÜÈ´òÁª¥Â∫¶ÂêëÈáèÊò†Â∞ÑÂà∞‰ΩéÁª¥Â∫¶ÁöÑÁ©∫Èó¥„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•ÈááÁî®‰ª•‰∏ã‰∏§ÁßçÊñπÂºè‰πã‰∏ÄÊù•Ë°®Á§∫Ëã±ÊñáÂè•Â≠ê‰∏≠ÁöÑÂçïËØçÔºö Ë°®Á§∫ÊàêÂåÖÂê´Áôæ‰∏á‰∏™ÂÖÉÁ¥†ÔºàÈ´òÁª¥Â∫¶ÔºâÁöÑÁ®ÄÁñèÂêëÈáèÔºåÂÖ∂‰∏≠ÊâÄÊúâÂÖÉÁ¥†ÈÉΩÊòØÊï¥Êï∞„ÄÇÂêëÈáè‰∏≠ÁöÑÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩË°®Á§∫‰∏Ä‰∏™ÂçïÁã¨ÁöÑËã±ÊñáÂçïËØçÔºåÂçïÂÖÉÊ†º‰∏≠ÁöÑÂÄºË°®Á§∫Áõ∏Â∫îÂçïËØçÂú®Âè•Â≠ê‰∏≠Âá∫Áé∞ÁöÑÊ¨°Êï∞„ÄÇÁî±‰∫éÂçï‰∏™Ëã±ÊñáÂè•Â≠êÂåÖÂê´ÁöÑÂçïËØç‰∏çÂ§™ÂèØËÉΩË∂ÖËøá 50 ‰∏™ÔºåÂõ†Ê≠§ÂêëÈáè‰∏≠Âá†‰πéÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩÂåÖÂê´ 0„ÄÇÂ∞ëÊï∞Èùû 0 ÁöÑÂçïÂÖÉÊ†º‰∏≠Â∞ÜÂåÖÂê´‰∏Ä‰∏™ÈùûÂ∏∏Â∞èÁöÑÊï¥Êï∞ÔºàÈÄöÂ∏∏‰∏∫ 1ÔºâÔºåËØ•Êï¥Êï∞Ë°®Á§∫Áõ∏Â∫îÂçïËØçÂú®Âè•Â≠ê‰∏≠Âá∫Áé∞ÁöÑÊ¨°Êï∞„ÄÇ Ë°®Á§∫ÊàêÂåÖÂê´Êï∞Áôæ‰∏™ÂÖÉÁ¥†Ôºà‰ΩéÁª¥Â∫¶ÔºâÁöÑÂØÜÈõÜÂêëÈáèÔºåÂÖ∂‰∏≠ÊØè‰∏™ÂÖÉÁ¥†ÈÉΩÂ≠òÂÇ®‰∏Ä‰∏™‰ªã‰∫é 0 Âà∞ 1 ‰πãÈó¥ÁöÑÊµÆÁÇπÂÄº„ÄÇËøôÂ∞±ÊòØ‰∏ÄÁßçÂµåÂ•ó„ÄÇ Âú® TensorFlow ‰∏≠Ôºå‰ºöÊåâÂèçÂêë‰º†Êí≠ÊçüÂ§±ËÆ≠ÁªÉÂµåÂ•óÔºåÂíåËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑ‰ªª‰ΩïÂÖ∂‰ªñÂèÇÊï∞‰∏ÄÊ†∑„ÄÇ ÁªèÈ™åÈ£éÈô©ÊúÄÂ∞èÂåñ (ERM, empirical risk minimization) Áî®‰∫éÈÄâÊã©ÂèØ‰ª•Â∞ÜÂü∫‰∫éËÆ≠ÁªÉÈõÜÁöÑÊçüÂ§±ÈôçËá≥ÊúÄ‰ΩéÁöÑÂáΩÊï∞„ÄÇ‰∏éÁªìÊûÑÈ£éÈô©ÊúÄÂ∞èÂåñÁõ∏ÂØπ„ÄÇ ÈõÜÊàêÂ≠¶‰π† (ensemble) Â§ö‰∏™Ê®°ÂûãÁöÑÈ¢ÑÊµãÁªìÊûúÁöÑÂπ∂ÈõÜ„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ã‰∏ÄÈ°πÊàñÂ§öÈ°πÊù•ÂàõÂª∫ÈõÜÊàêÂ≠¶‰π†Ôºö ‰∏çÂêåÁöÑÂàùÂßãÂåñ ‰∏çÂêåÁöÑË∂ÖÂèÇÊï∞ ‰∏çÂêåÁöÑÊï¥‰ΩìÁªìÊûÑ Ê∑±Â∫¶Ê®°ÂûãÂíåÂÆΩÂ∫¶Ê®°ÂûãÂ±û‰∫é‰∏ÄÁßçÈõÜÊàêÂ≠¶‰π†„ÄÇ Âë®Êúü (epoch) Âú®ËÆ≠ÁªÉÊó∂ÔºåÊï¥‰∏™Êï∞ÊçÆÈõÜÁöÑ‰∏ÄÊ¨°ÂÆåÊï¥ÈÅçÂéÜÔºå‰ª•‰æø‰∏çÊºèÊéâ‰ªª‰Ωï‰∏Ä‰∏™Ê†∑Êú¨„ÄÇÂõ†Ê≠§Ôºå‰∏Ä‰∏™Âë®ÊúüË°®Á§∫ÔºàN/ÊâπÊ¨°Â§ßÂ∞èÔºâÊ¨°ËÆ≠ÁªÉËø≠‰ª£ÔºåÂÖ∂‰∏≠ N ÊòØÊ†∑Êú¨ÊÄªÊï∞„ÄÇ Estimator tf.Estimator Á±ªÁöÑ‰∏Ä‰∏™ÂÆû‰æãÔºåÁî®‰∫éÂ∞ÅË£ÖË¥üË¥£ÊûÑÂª∫ TensorFlow ÂõæÂπ∂ËøêË°å TensorFlow ‰ºöËØùÁöÑÈÄªËæë„ÄÇÊÇ®ÂèØ‰ª•ÂàõÂª∫Ëá™ÂÆö‰πâ EstimatorÔºàÂ¶ÇÈúÄÁõ∏ÂÖ≥‰ªãÁªçÔºåËØ∑ÁÇπÂáªÊ≠§Â§ÑÔºâÔºå‰πüÂèØ‰ª•ÂÆû‰æãÂåñÂÖ∂‰ªñ‰∫∫È¢ÑÂàõÂª∫ÁöÑ Estimator„ÄÇ Ê†∑Êú¨ (example) Êï∞ÊçÆÈõÜÁöÑ‰∏ÄË°å„ÄÇ‰∏Ä‰∏™Ê†∑Êú¨ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÁâπÂæÅÔºåÊ≠§Â§ñËøòÂèØËÉΩÂåÖÂê´‰∏Ä‰∏™Ê†áÁ≠æ„ÄÇÂè¶ËØ∑ÂèÇÈòÖÊúâÊ†áÁ≠æÊ†∑Êú¨ÂíåÊó†Ê†áÁ≠æÊ†∑Êú¨„ÄÇ F ÂÅáË¥ü‰æã (FN, false negative) Ë¢´Ê®°ÂûãÈîôËØØÂú∞È¢ÑÊµã‰∏∫Ë¥üÁ±ªÂà´ÁöÑÊ†∑Êú¨„ÄÇ‰æãÂ¶ÇÔºåÊ®°ÂûãÊé®Êñ≠Âá∫ÊüêÂ∞ÅÁîµÂ≠êÈÇÆ‰ª∂‰∏çÊòØÂûÉÂúæÈÇÆ‰ª∂ÔºàË¥üÁ±ªÂà´ÔºâÔºå‰ΩÜËØ•ÁîµÂ≠êÈÇÆ‰ª∂ÂÖ∂ÂÆûÊòØÂûÉÂúæÈÇÆ‰ª∂„ÄÇ ÂÅáÊ≠£‰æã (FP, false positive) Ë¢´Ê®°ÂûãÈîôËØØÂú∞È¢ÑÊµã‰∏∫Ê≠£Á±ªÂà´ÁöÑÊ†∑Êú¨„ÄÇ‰æãÂ¶ÇÔºåÊ®°ÂûãÊé®Êñ≠Âá∫ÊüêÂ∞ÅÁîµÂ≠êÈÇÆ‰ª∂ÊòØÂûÉÂúæÈÇÆ‰ª∂ÔºàÊ≠£Á±ªÂà´ÔºâÔºå‰ΩÜËØ•ÁîµÂ≠êÈÇÆ‰ª∂ÂÖ∂ÂÆû‰∏çÊòØÂûÉÂúæÈÇÆ‰ª∂„ÄÇ ÂÅáÊ≠£‰æãÁéáÔºàfalse positive rate, ÁÆÄÁß∞ FP ÁéáÔºâ ROC Êõ≤Á∫ø‰∏≠ÁöÑ x ËΩ¥„ÄÇFP ÁéáÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö $$\text{ÂÅáÊ≠£‰æãÁéá} = \frac{\text{ÂÅáÊ≠£‰æãÊï∞}}{\text{ÂÅáÊ≠£‰æãÊï∞} + \text{Ë¥ü‰æãÊï∞}}$$ ÁâπÂæÅ (feature) Âú®ËøõË°åÈ¢ÑÊµãÊó∂‰ΩøÁî®ÁöÑËæìÂÖ•ÂèòÈáè„ÄÇ ÁâπÂæÅÂàó (tf.feature_column) ÊåáÂÆöÊ®°ÂûãÂ∫îËØ•Â¶Ç‰ΩïËß£ËØªÁâπÂÆöÁâπÂæÅÁöÑ‰∏ÄÁßçÂáΩÊï∞„ÄÇÊ≠§Á±ªÂáΩÊï∞ÁöÑËæìÂá∫ÁªìÊûúÊòØÊâÄÊúâ Estimators ÊûÑÈÄ†ÂáΩÊï∞ÁöÑÂøÖÈúÄÂèÇÊï∞„ÄÇ ÂÄüÂä© tf.feature_column ÂáΩÊï∞ÔºåÊ®°ÂûãÂèØÂØπËæìÂÖ•ÁâπÂæÅÁöÑ‰∏çÂêåË°®Á§∫Ê≥ïËΩªÊùæËøõË°åÂÆûÈ™å„ÄÇÊúâÂÖ≥ËØ¶ÊÉÖÔºåËØ∑ÂèÇÈòÖ„ÄäTensorFlow ÁºñÁ®ã‰∫∫ÂëòÊåáÂçó„Äã‰∏≠ÁöÑÁâπÂæÅÂàó‰∏ÄÁ´†„ÄÇ ‚ÄúÁâπÂæÅÂàó‚ÄùÊòØ Google ‰∏ìÁî®ÁöÑÊúØËØ≠„ÄÇÁâπÂæÅÂàóÂú® Yahoo/Microsoft ‰ΩøÁî®ÁöÑ VW Á≥ªÁªü‰∏≠Áß∞‰∏∫‚ÄúÂëΩÂêçÁ©∫Èó¥‚ÄùÔºå‰πüÁß∞‰∏∫Âú∫„ÄÇ ÁâπÂæÅÁªÑÂêà (feature cross) ÈÄöËøáÂ∞ÜÂçïÁã¨ÁöÑÁâπÂæÅËøõË°åÁªÑÂêàÔºàÊ±ÇÁ¨õÂç°Â∞îÁßØÔºâËÄåÂΩ¢ÊàêÁöÑÂêàÊàêÁâπÂæÅ„ÄÇÁâπÂæÅÁªÑÂêàÊúâÂä©‰∫éË°®ËææÈùûÁ∫øÊÄßÂÖ≥Á≥ª„ÄÇ ÁâπÂæÅÂ∑•Á®ã (feature engineering) Êåá‰ª•‰∏ãËøáÁ®ãÔºöÁ°ÆÂÆöÂì™‰∫õÁâπÂæÅÂèØËÉΩÂú®ËÆ≠ÁªÉÊ®°ÂûãÊñπÈù¢ÈùûÂ∏∏ÊúâÁî®ÔºåÁÑ∂ÂêéÂ∞ÜÊó•ÂøóÊñá‰ª∂ÂèäÂÖ∂‰ªñÊù•Ê∫êÁöÑÂéüÂßãÊï∞ÊçÆËΩ¨Êç¢‰∏∫ÊâÄÈúÄÁöÑÁâπÂæÅ„ÄÇÂú® TensorFlow ‰∏≠ÔºåÁâπÂæÅÂ∑•Á®ãÈÄöÂ∏∏ÊòØÊåáÂ∞ÜÂéüÂßãÊó•ÂøóÊñá‰ª∂Êù°ÁõÆËΩ¨Êç¢‰∏∫ tf.Example ÂçèËÆÆÁºìÂÜ≤Âå∫„ÄÇÂè¶ËØ∑ÂèÇÈòÖ tf.Transform„ÄÇ ÁâπÂæÅÂ∑•Á®ãÊúâÊó∂Áß∞‰∏∫ÁâπÂæÅÊèêÂèñ„ÄÇ ÁâπÂæÅÈõÜ (feature set) ËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÊó∂ÈááÁî®ÁöÑ‰∏ÄÁªÑÁâπÂæÅ„ÄÇ‰æãÂ¶ÇÔºåÂØπ‰∫éÊüê‰∏™Áî®‰∫éÈ¢ÑÊµãÊàø‰ª∑ÁöÑÊ®°ÂûãÔºåÈÇÆÊîøÁºñÁ†Å„ÄÅÊàøÂ±ãÈù¢ÁßØ‰ª•ÂèäÊàøÂ±ãÁä∂ÂÜµÂèØ‰ª•ÁªÑÊàê‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁâπÂæÅÈõÜ„ÄÇ ÁâπÂæÅËßÑËåÉ (feature spec) Áî®‰∫éÊèèËø∞Â¶Ç‰Ωï‰ªé tf.Example ÂçèËÆÆÁºìÂÜ≤Âå∫ÊèêÂèñÁâπÂæÅÊï∞ÊçÆ„ÄÇÁî±‰∫é tf.Example ÂçèËÆÆÁºìÂÜ≤Âå∫Âè™ÊòØ‰∏Ä‰∏™Êï∞ÊçÆÂÆπÂô®ÔºåÂõ†Ê≠§ÊÇ®ÂøÖÈ°ªÊåáÂÆö‰ª•‰∏ãÂÜÖÂÆπÔºö Ë¶ÅÊèêÂèñÁöÑÊï∞ÊçÆÔºàÂç≥ÁâπÂæÅÁöÑÈîÆÔºâ Êï∞ÊçÆÁ±ªÂûãÔºà‰æãÂ¶Ç float Êàñ intÔºâ ÈïøÂ∫¶ÔºàÂõ∫ÂÆöÊàñÂèØÂèòÔºâ Estimator API Êèê‰æõ‰∫Ü‰∏Ä‰∫õÂèØÁî®Êù•Ê†πÊçÆÁªôÂÆö FeatureColumns ÂàóË°®ÁîüÊàêÁâπÂæÅËßÑËåÉÁöÑÂ∑•ÂÖ∑„ÄÇ Â∞ëÈáèÊ†∑Êú¨Â≠¶‰π† (few-shot learning) ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºàÈÄöÂ∏∏Áî®‰∫éÂØπË±°ÂàÜÁ±ªÔºâÔºåÊó®Âú®‰ªÖÈÄöËøáÂ∞ëÈáèËÆ≠ÁªÉÊ†∑Êú¨Â≠¶‰π†ÊúâÊïàÁöÑÂàÜÁ±ªÂô®„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÂçïÊ†∑Êú¨Â≠¶‰π†„ÄÇ ÂÆåÊï¥ softmax (full softmax) ËØ∑ÂèÇÈòÖ softmax„ÄÇ‰∏éÂÄôÈÄâÈááÊ†∑Áõ∏ÂØπ„ÄÇ ÂÖ®ËøûÊé•Â±Ç (fully connected layer) ‰∏ÄÁßçÈöêËóèÂ±ÇÔºåÂÖ∂‰∏≠ÁöÑÊØè‰∏™ËäÇÁÇπÂùá‰∏é‰∏ã‰∏Ä‰∏™ÈöêËóèÂ±Ç‰∏≠ÁöÑÊØè‰∏™ËäÇÁÇπÁõ∏Ëøû„ÄÇ ÂÖ®ËøûÊé•Â±ÇÂèàÁß∞‰∏∫ÂØÜÈõÜÂ±Ç„ÄÇ G Ê≥õÂåñ (generalization) ÊåáÁöÑÊòØÊ®°Âûã‰æùÊçÆËÆ≠ÁªÉÊó∂ÈááÁî®ÁöÑÊï∞ÊçÆÔºåÈíàÂØπ‰ª•ÂâçÊú™ËßÅËøáÁöÑÊñ∞Êï∞ÊçÆÂÅöÂá∫Ê≠£Á°ÆÈ¢ÑÊµãÁöÑËÉΩÂäõ„ÄÇ Âπø‰πâÁ∫øÊÄßÊ®°Âûã (generalized linear model) ÊúÄÂ∞è‰∫å‰πòÂõûÂΩíÊ®°ÂûãÔºàÂü∫‰∫éÈ´òÊñØÂô™Â£∞ÔºâÂêëÂÖ∂‰ªñÁ±ªÂûãÁöÑÊ®°ÂûãÔºàÂü∫‰∫éÂÖ∂‰ªñÁ±ªÂûãÁöÑÂô™Â£∞Ôºå‰æãÂ¶ÇÊ≥äÊùæÂô™Â£∞ÊàñÂàÜÁ±ªÂô™Â£∞ÔºâËøõË°åÁöÑ‰∏ÄÁßçÊ≥õÂåñ„ÄÇÂπø‰πâÁ∫øÊÄßÊ®°ÂûãÁöÑÁ§∫‰æãÂåÖÊã¨Ôºö ÈÄªËæëÂõûÂΩí Â§öÁ±ªÂà´ÂõûÂΩí ÊúÄÂ∞è‰∫å‰πòÂõûÂΩí ÂèØ‰ª•ÈÄöËøáÂá∏‰ºòÂåñÊâæÂà∞Âπø‰πâÁ∫øÊÄßÊ®°ÂûãÁöÑÂèÇÊï∞„ÄÇ Âπø‰πâÁ∫øÊÄßÊ®°ÂûãÂÖ∑Êúâ‰ª•‰∏ãÁâπÊÄßÔºö ÊúÄ‰ºòÁöÑÊúÄÂ∞è‰∫å‰πòÂõûÂΩíÊ®°ÂûãÁöÑÂπ≥ÂùáÈ¢ÑÊµãÁªìÊûúÁ≠â‰∫éËÆ≠ÁªÉÊï∞ÊçÆÁöÑÂπ≥ÂùáÊ†áÁ≠æ„ÄÇ ÊúÄ‰ºòÁöÑÈÄªËæëÂõûÂΩíÊ®°ÂûãÈ¢ÑÊµãÁöÑÂπ≥ÂùáÊ¶ÇÁéáÁ≠â‰∫éËÆ≠ÁªÉÊï∞ÊçÆÁöÑÂπ≥ÂùáÊ†áÁ≠æ„ÄÇ Âπø‰πâÁ∫øÊÄßÊ®°ÂûãÁöÑÂäüËÉΩÂèóÂÖ∂ÁâπÂæÅÁöÑÈôêÂà∂„ÄÇ‰∏éÊ∑±Â∫¶Ê®°Âûã‰∏çÂêåÔºåÂπø‰πâÁ∫øÊÄßÊ®°ÂûãÊó†Ê≥ï‚ÄúÂ≠¶‰π†Êñ∞ÁâπÂæÅ‚Äù„ÄÇ Ê¢ØÂ∫¶ (gradient) ÂÅèÂØºÊï∞Áõ∏ÂØπ‰∫éÊâÄÊúâËá™ÂèòÈáèÁöÑÂêëÈáè„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÊ¢ØÂ∫¶ÊòØÊ®°ÂûãÂáΩÊï∞ÂÅèÂØºÊï∞ÁöÑÂêëÈáè„ÄÇÊ¢ØÂ∫¶ÊåáÂêëÊúÄÈ´òÈÄü‰∏äÂçáÁöÑÊñπÂêë„ÄÇ Ê¢ØÂ∫¶Ë£ÅÂâ™ (gradient clipping) Âú®Â∫îÁî®Ê¢ØÂ∫¶ÂÄº‰πãÂâçÂÖàËÆæÁΩÆÂÖ∂‰∏äÈôê„ÄÇÊ¢ØÂ∫¶Ë£ÅÂâ™ÊúâÂä©‰∫éÁ°Æ‰øùÊï∞ÂÄºÁ®≥ÂÆöÊÄß‰ª•ÂèäÈò≤Ê≠¢Ê¢ØÂ∫¶ÁàÜÁÇ∏„ÄÇ Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï (gradient descent) ‰∏ÄÁßçÈÄöËøáËÆ°ÁÆóÂπ∂‰∏îÂáèÂ∞èÊ¢ØÂ∫¶Â∞ÜÊçüÂ§±ÈôçËá≥ÊúÄ‰ΩéÁöÑÊäÄÊúØÔºåÂÆÉ‰ª•ËÆ≠ÁªÉÊï∞ÊçÆ‰∏∫Êù°‰ª∂ÔºåÊù•ËÆ°ÁÆóÊçüÂ§±Áõ∏ÂØπ‰∫éÊ®°ÂûãÂèÇÊï∞ÁöÑÊ¢ØÂ∫¶„ÄÇÈÄö‰øóÊù•ËØ¥ÔºåÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ï‰ª•Ëø≠‰ª£ÊñπÂºèË∞ÉÊï¥ÂèÇÊï∞ÔºåÈÄêÊ∏êÊâæÂà∞ÊùÉÈáçÂíåÂÅèÂ∑ÆÁöÑÊúÄ‰Ω≥ÁªÑÂêàÔºå‰ªéËÄåÂ∞ÜÊçüÂ§±ÈôçËá≥ÊúÄ‰Ωé„ÄÇ Âõæ (graph) TensorFlow ‰∏≠ÁöÑ‰∏ÄÁßçËÆ°ÁÆóËßÑËåÉ„ÄÇÂõæ‰∏≠ÁöÑËäÇÁÇπË°®Á§∫Êìç‰Ωú„ÄÇËæπÁºòÂÖ∑ÊúâÊñπÂêëÔºåË°®Á§∫Â∞ÜÊüêÈ°πÊìç‰ΩúÁöÑÁªìÊûúÔºà‰∏Ä‰∏™Âº†ÈáèÔºâ‰Ωú‰∏∫‰∏Ä‰∏™Êìç‰ΩúÊï∞‰º†ÈÄíÁªôÂè¶‰∏ÄÈ°πÊìç‰Ωú„ÄÇÂèØ‰ª•‰ΩøÁî® TensorBoard Áõ¥ËßÇÂëàÁé∞Âõæ„ÄÇ H ÂêØÂèëÊ≥ï (heuristic) ‰∏ÄÁßçÈùûÊúÄ‰ºò‰ΩÜÂÆûÁî®ÁöÑÈóÆÈ¢òËß£ÂÜ≥ÊñπÊ°àÔºåË∂≥‰ª•Áî®‰∫éËøõË°åÊîπËøõÊàñ‰ªé‰∏≠Â≠¶‰π†„ÄÇ ÈöêËóèÂ±Ç (hidden layer) Á•ûÁªèÁΩëÁªú‰∏≠ÁöÑÂêàÊàêÂ±ÇÔºå‰ªã‰∫éËæìÂÖ•Â±ÇÔºàÂç≥ÁâπÂæÅÔºâÂíåËæìÂá∫Â±ÇÔºàÂç≥È¢ÑÊµãÔºâ‰πãÈó¥„ÄÇÁ•ûÁªèÁΩëÁªúÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÈöêËóèÂ±Ç„ÄÇ ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ (hinge loss) ‰∏ÄÁ≥ªÂàóÁî®‰∫éÂàÜÁ±ªÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÊó®Âú®ÊâæÂà∞Ë∑ùÁ¶ªÊØè‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÈÉΩÂ∞ΩÂèØËÉΩËøúÁöÑÂÜ≥Á≠ñËæπÁïåÔºå‰ªéËÄå‰ΩøÊ†∑Êú¨ÂíåËæπÁïå‰πãÈó¥ÁöÑË£ïÂ∫¶ÊúÄÂ§ßÂåñ„ÄÇ KSVM ‰ΩøÁî®ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ÔºàÊàñÁõ∏ÂÖ≥ÂáΩÊï∞Ôºå‰æãÂ¶ÇÂπ≥ÊñπÂêàÈ°µÊçüÂ§±ÂáΩÊï∞Ôºâ„ÄÇÂØπ‰∫é‰∫åÂÖÉÂàÜÁ±ªÔºåÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö $$\text{loss} = \text{max}(0, 1 - (y' * y))$$ ÂÖ∂‰∏≠‚Äúy'‚ÄùË°®Á§∫ÂàÜÁ±ªÂô®Ê®°ÂûãÁöÑÂéüÂßãËæìÂá∫Ôºö $$y' = b + w_1x_1 + w_2x_2 + ‚Ä¶ w_nx_n$$ ‚Äúy‚ÄùË°®Á§∫ÁúüÊ†áÁ≠æÔºåÂÄº‰∏∫ -1 Êàñ +1„ÄÇ Âõ†Ê≠§ÔºåÂêàÈ°µÊçüÂ§±‰∏é (y * y') ÁöÑÂÖ≥Á≥ªÂõæÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ ‰∏é (y * y') ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞‰∏éÂéüÂßãÂàÜÁ±ªÂô®ÂæóÂàÜÁöÑÂÖ≥Á≥ªÂõæÂú®ÂùêÊ†á (1,0) Â§ÑÊòæÁ§∫ÊòéÊòæÁöÑÂêàÈ°µ„ÄÇ 0 -2 -1 1 2 3 1 2 3 4 0 ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ (y * y') Áª¥ÊåÅÊï∞ÊçÆ (holdout data) ËÆ≠ÁªÉÊúüÈó¥ÊïÖÊÑè‰∏ç‰ΩøÁî®Ôºà‚ÄúÁª¥ÊåÅ‚ÄùÔºâÁöÑÊ†∑Êú¨„ÄÇÈ™åËØÅÊï∞ÊçÆÈõÜÂíåÊµãËØïÊï∞ÊçÆÈõÜÈÉΩÂ±û‰∫éÁª¥ÊåÅÊï∞ÊçÆ„ÄÇÁª¥ÊåÅÊï∞ÊçÆÊúâÂä©‰∫éËØÑ‰º∞Ê®°ÂûãÂêëËÆ≠ÁªÉÊó∂ÊâÄÁî®Êï∞ÊçÆ‰πãÂ§ñÁöÑÊï∞ÊçÆËøõË°åÊ≥õÂåñÁöÑËÉΩÂäõ„ÄÇ‰∏éÂü∫‰∫éËÆ≠ÁªÉÊï∞ÊçÆÈõÜÁöÑÊçüÂ§±Áõ∏ÊØîÔºåÂü∫‰∫éÁª¥ÊåÅÊï∞ÊçÆÈõÜÁöÑÊçüÂ§±ÊúâÂä©‰∫éÊõ¥Â•ΩÂú∞‰º∞ÁÆóÂü∫‰∫éÊú™ËßÅËøáÁöÑÊï∞ÊçÆÈõÜÁöÑÊçüÂ§±„ÄÇ Ë∂ÖÂèÇÊï∞ (hyperparameter) Âú®Ê®°ÂûãËÆ≠ÁªÉÁöÑËøûÁª≠ËøáÁ®ã‰∏≠ÔºåÊÇ®Ë∞ÉËäÇÁöÑ‚ÄúÊóãÈíÆ‚Äù„ÄÇ‰æãÂ¶ÇÔºåÂ≠¶‰π†ÈÄüÁéáÂ∞±ÊòØ‰∏ÄÁßçË∂ÖÂèÇÊï∞„ÄÇ ‰∏éÂèÇÊï∞Áõ∏ÂØπ„ÄÇ Ë∂ÖÂπ≥Èù¢ (hyperplane) Â∞Ü‰∏Ä‰∏™Á©∫Èó¥ÂàíÂàÜ‰∏∫‰∏§‰∏™Â≠êÁ©∫Èó¥ÁöÑËæπÁïå„ÄÇ‰æãÂ¶ÇÔºåÂú®‰∫åÁª¥Á©∫Èó¥‰∏≠ÔºåÁõ¥Á∫øÂ∞±ÊòØ‰∏Ä‰∏™Ë∂ÖÂπ≥Èù¢ÔºåÂú®‰∏âÁª¥Á©∫Èó¥‰∏≠ÔºåÂπ≥Èù¢ÂàôÊòØ‰∏Ä‰∏™Ë∂ÖÂπ≥Èù¢„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Êõ¥ÂÖ∏ÂûãÁöÑÊòØÔºöË∂ÖÂπ≥Èù¢ÊòØÂàÜÈöîÈ´òÁª¥Â∫¶Á©∫Èó¥ÁöÑËæπÁïå„ÄÇÊ†∏ÊîØÊåÅÂêëÈáèÊú∫Âà©Áî®Ë∂ÖÂπ≥Èù¢Â∞ÜÊ≠£Á±ªÂà´ÂíåË¥üÁ±ªÂà´Âå∫ÂàÜÂºÄÊù•ÔºàÈÄöÂ∏∏ÊòØÂú®ÊûÅÈ´òÁª¥Â∫¶Á©∫Èó¥‰∏≠Ôºâ„ÄÇ I Áã¨Á´ãÂêåÁ≠âÂàÜÂ∏É (i.i.d, independently and identically distributed) ‰ªé‰∏ç‰ºöÊîπÂèòÁöÑÂàÜÂ∏É‰∏≠ÊèêÂèñÁöÑÊï∞ÊçÆÔºåÂÖ∂‰∏≠ÊèêÂèñÁöÑÊØè‰∏™ÂÄºÈÉΩ‰∏ç‰æùËµñ‰∫é‰πãÂâçÊèêÂèñÁöÑÂÄº„ÄÇi.i.d. ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÁêÜÊÉ≥Ê∞î‰Ωì - ‰∏ÄÁßçÂÆûÁî®ÁöÑÊï∞Â≠¶ÁªìÊûÑÔºå‰ΩÜÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠Âá†‰πé‰ªéÊú™ÂèëÁé∞Ëøá„ÄÇ‰æãÂ¶ÇÔºåÊüê‰∏™ÁΩëÈ°µÁöÑËÆøÈóÆËÄÖÂú®Áü≠Êó∂Èó¥ÂÜÖÁöÑÂàÜÂ∏ÉÂèØËÉΩ‰∏∫ i.i.d.ÔºåÂç≥ÂàÜÂ∏ÉÂú®ËØ•Áü≠Êó∂Èó¥ÂÜÖÊ≤°ÊúâÂèòÂåñÔºå‰∏î‰∏Ä‰ΩçÁî®Êà∑ÁöÑËÆøÈóÆË°å‰∏∫ÈÄöÂ∏∏‰∏éÂè¶‰∏Ä‰ΩçÁî®Êà∑ÁöÑËÆøÈóÆË°å‰∏∫Êó†ÂÖ≥„ÄÇ‰∏çËøáÔºåÂ¶ÇÊûúÂ∞ÜÊó∂Èó¥Á™óÂè£Êâ©Â§ßÔºåÁΩëÈ°µËÆøÈóÆËÄÖÁöÑÂàÜÂ∏ÉÂèØËÉΩÂëàÁé∞Âá∫Â≠£ËäÇÊÄßÂèòÂåñ„ÄÇ Êé®Êñ≠ (inference) Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÊé®Êñ≠ÈÄöÂ∏∏Êåá‰ª•‰∏ãËøáÁ®ãÔºöÈÄöËøáÂ∞ÜËÆ≠ÁªÉËøáÁöÑÊ®°ÂûãÂ∫îÁî®‰∫éÊó†Ê†áÁ≠æÊ†∑Êú¨Êù•ÂÅöÂá∫È¢ÑÊµã„ÄÇÂú®ÁªüËÆ°Â≠¶‰∏≠ÔºåÊé®Êñ≠ÊòØÊåáÂú®Êüê‰∫õËßÇÊµãÊï∞ÊçÆÊù°‰ª∂‰∏ãÊãüÂêàÂàÜÂ∏ÉÂèÇÊï∞ÁöÑËøáÁ®ã„ÄÇÔºàËØ∑ÂèÇÈòÖÁª¥Âü∫ÁôæÁßë‰∏≠ÊúâÂÖ≥ÁªüËÆ°Â≠¶Êé®Êñ≠ÁöÑÊñáÁ´†„ÄÇÔºâ ËæìÂÖ•ÂáΩÊï∞ (input function) Âú® TensorFlow ‰∏≠ÔºåÁî®‰∫éÂ∞ÜËæìÂÖ•Êï∞ÊçÆËøîÂõûÂà∞ Estimator ÁöÑËÆ≠ÁªÉ„ÄÅËØÑ‰º∞ÊàñÈ¢ÑÊµãÊñπÊ≥ïÁöÑÂáΩÊï∞„ÄÇ‰æãÂ¶ÇÔºåËÆ≠ÁªÉËæìÂÖ•ÂáΩÊï∞‰ºöËøîÂõûËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑ‰∏ÄÊâπÁâπÂæÅÂíåÊ†áÁ≠æ„ÄÇ ËæìÂÖ•Â±Ç (input layer) Á•ûÁªèÁΩëÁªú‰∏≠ÁöÑÁ¨¨‰∏ÄÂ±ÇÔºàÊé•Êî∂ËæìÂÖ•Êï∞ÊçÆÁöÑÂ±ÇÔºâ„ÄÇ ÂÆû‰æã (instance) ‰∏éÊ†∑Êú¨ÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ ÂèØËß£ÈáäÊÄß (interpretability) Ê®°ÂûãÁöÑÈ¢ÑÊµãÂèØËß£ÈáäÁöÑÈöæÊòìÁ®ãÂ∫¶„ÄÇÊ∑±Â∫¶Ê®°ÂûãÈÄöÂ∏∏‰∏çÂèØËß£ÈáäÔºå‰πüÂ∞±ÊòØËØ¥ÔºåÂæàÈöæÂØπÊ∑±Â∫¶Ê®°ÂûãÁöÑ‰∏çÂêåÂ±ÇËøõË°åËß£Èáä„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÁ∫øÊÄßÂõûÂΩíÊ®°ÂûãÂíåÂÆΩÂ∫¶Ê®°ÂûãÁöÑÂèØËß£ÈáäÊÄßÈÄöÂ∏∏Ë¶ÅÂ•ΩÂæóÂ§ö„ÄÇ ËØÑÂàÜËÄÖÈó¥‰∏ÄËá¥ÊÄß‰ø°Â∫¶ (inter-rater agreement) ‰∏ÄÁßçË°°ÈáèÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèÂú®ÊâßË°åÊüêÈ°π‰ªªÂä°Êó∂ËØÑÂàÜËÄÖËææÊàê‰∏ÄËá¥ÁöÑÈ¢ëÁéá„ÄÇÂ¶ÇÊûúËØÑÂàÜËÄÖÊú™ËææÊàê‰∏ÄËá¥ÔºåÂàôÂèØËÉΩÈúÄË¶ÅÊîπËøõ‰ªªÂä°ËØ¥Êòé„ÄÇÊúâÊó∂‰πüÁß∞‰∏∫Ê≥®ÈáäËÄÖÈó¥‰∏ÄËá¥ÊÄß‰ø°Â∫¶ÊàñËØÑÂàÜËÄÖÈó¥ÂèØÈù†ÊÄß‰ø°Â∫¶„ÄÇÂè¶ËØ∑ÂèÇÈòÖ Cohen's kappaÔºàÊúÄÁÉ≠Èó®ÁöÑËØÑÂàÜËÄÖÈó¥‰∏ÄËá¥ÊÄß‰ø°Â∫¶Ë°°ÈáèÊåáÊ†á‰πã‰∏ÄÔºâ„ÄÇ Ëø≠‰ª£ (iteration) Ê®°ÂûãÁöÑÊùÉÈáçÂú®ËÆ≠ÁªÉÊúüÈó¥ÁöÑ‰∏ÄÊ¨°Êõ¥Êñ∞„ÄÇËø≠‰ª£ÂåÖÂê´ËÆ°ÁÆóÂèÇÊï∞Âú®ÂçïÊâπÊ¨°Êï∞ÊçÆ‰∏äÁöÑÊ¢ØÂ∫¶ÊçüÂ§±„ÄÇ K k-means ‰∏ÄÁßçÁÉ≠Èó®ÁöÑËÅöÁ±ªÁÆóÊ≥ïÔºåÁî®‰∫éÂØπÈùûÁõëÁù£ÂºèÂ≠¶‰π†‰∏≠ÁöÑÊ†∑Êú¨ËøõË°åÂàÜÁªÑ„ÄÇk-means ÁÆóÊ≥ïÂü∫Êú¨‰∏ä‰ºöÊâßË°å‰ª•‰∏ãÊìç‰ΩúÔºö ‰ª•Ëø≠‰ª£ÊñπÂºèÁ°ÆÂÆöÊúÄ‰Ω≥ÁöÑ k ‰∏≠ÂøÉÁÇπÔºàÁß∞‰∏∫ÂΩ¢ÂøÉÔºâ„ÄÇ Â∞ÜÊØè‰∏™Ê†∑Êú¨ÂàÜÈÖçÂà∞ÊúÄËøëÁöÑÂΩ¢ÂøÉ„ÄÇ‰∏éÂêå‰∏Ä‰∏™ÂΩ¢ÂøÉË∑ùÁ¶ªÊúÄËøëÁöÑÊ†∑Êú¨Â±û‰∫éÂêå‰∏Ä‰∏™ÁªÑ„ÄÇ k-means ÁÆóÊ≥ï‰ºöÊåëÈÄâÂΩ¢ÂøÉ‰ΩçÁΩÆÔºå‰ª•ÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂáèÂ∞èÊØè‰∏™Ê†∑Êú¨‰∏éÂÖ∂ÊúÄÊé•ËøëÂΩ¢ÂøÉ‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÁ¥ØÁßØÂπ≥Êñπ„ÄÇ ‰ª•‰∏ãÈù¢ÁöÑÂ∞èÁãóÈ´òÂ∫¶‰∏éÂ∞èÁãóÂÆΩÂ∫¶ÁöÑÂÖ≥Á≥ªÂõæ‰∏∫‰æãÔºö image/svg+xml 50 or so examples along a two-dimensional graph. È´òÂ∫¶ ÂÆΩÂ∫¶ Â¶ÇÊûú k=3ÔºåÂàô k-means ÁÆóÊ≥ï‰ºöÁ°ÆÂÆö‰∏â‰∏™ÂΩ¢ÂøÉ„ÄÇÊØè‰∏™Ê†∑Êú¨ÈÉΩË¢´ÂàÜÈÖçÂà∞‰∏éÂÖ∂ÊúÄÊé•ËøëÁöÑÂΩ¢ÂøÉÔºåÊúÄÁªà‰∫ßÁîü‰∏â‰∏™ÁªÑÔºö image/svg+xml The same 50 examples clustered into 3 groups. È´òÂ∫¶ ÂÆΩÂ∫¶ ÂΩ¢ÂøÉ ËÅöÁ±ª 1 ËÅöÁ±ª 2 ËÅöÁ±ª 3 ÂÅáËÆæÂà∂ÈÄ†ÂïÜÊÉ≥Ë¶ÅÁ°ÆÂÆöÂ∞è„ÄÅ‰∏≠ÂíåÂ§ßÂè∑ÁãóÊØõË°£ÁöÑÁêÜÊÉ≥Â∞∫ÂØ∏„ÄÇÂú®ËØ•ËÅöÁ±ª‰∏≠Ôºå‰∏â‰∏™ÂΩ¢ÂøÉÁî®‰∫éÊ†áËØÜÊØèÂè™ÁãóÁöÑÂπ≥ÂùáÈ´òÂ∫¶ÂíåÂπ≥ÂùáÂÆΩÂ∫¶„ÄÇÂõ†Ê≠§ÔºåÂà∂ÈÄ†ÂïÜÂèØËÉΩÂ∫îËØ•Ê†πÊçÆËøô‰∏â‰∏™ÂΩ¢ÂøÉÁ°ÆÂÆöÊØõË°£Â∞∫ÂØ∏„ÄÇËØ∑Ê≥®ÊÑèÔºåËÅöÁ±ªÁöÑÂΩ¢ÂøÉÈÄöÂ∏∏‰∏çÊòØËÅöÁ±ª‰∏≠ÁöÑÊ†∑Êú¨„ÄÇ ‰∏äÂõæÊòæÁ§∫‰∫Ü k-means Â∫îÁî®‰∫é‰ªÖÂÖ∑Êúâ‰∏§‰∏™ÁâπÂæÅÔºàÈ´òÂ∫¶ÂíåÂÆΩÂ∫¶ÔºâÁöÑÊ†∑Êú¨„ÄÇËØ∑Ê≥®ÊÑèÔºåk-means ÂèØ‰ª•Ë∑®Â§ö‰∏™ÁâπÂæÅ‰∏∫Ê†∑Êú¨ÂàÜÁªÑ„ÄÇ k-median ‰∏é k-means Á¥ßÂØÜÁõ∏ÂÖ≥ÁöÑËÅöÁ±ªÁÆóÊ≥ï„ÄÇ‰∏§ËÄÖÁöÑÂÆûÈôÖÂå∫Âà´Â¶Ç‰∏ãÔºö ÂØπ‰∫é k-meansÔºåÁ°ÆÂÆöÂΩ¢ÂøÉÁöÑÊñπÊ≥ïÊòØÔºåÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂáèÂ∞èÂÄôÈÄâÂΩ¢ÂøÉ‰∏éÂÆÉÁöÑÊØè‰∏™Ê†∑Êú¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÂπ≥ÊñπÂíå„ÄÇ ÂØπ‰∫é k-medianÔºåÁ°ÆÂÆöÂΩ¢ÂøÉÁöÑÊñπÊ≥ïÊòØÔºåÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂáèÂ∞èÂÄôÈÄâÂΩ¢ÂøÉ‰∏éÂÆÉÁöÑÊØè‰∏™Ê†∑Êú¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÊÄªÂíå„ÄÇ ËØ∑Ê≥®ÊÑèÔºåË∑ùÁ¶ªÁöÑÂÆö‰πâ‰πüÊúâÊâÄ‰∏çÂêåÔºö k-means ÈááÁî®‰ªéÂΩ¢ÂøÉÂà∞Ê†∑Êú¨ÁöÑÊ¨ßÂá†ÈáåÂæóË∑ùÁ¶ª„ÄÇÔºàÂú®‰∫åÁª¥Á©∫Èó¥‰∏≠ÔºåÊ¨ßÂá†ÈáåÂæóË∑ùÁ¶ªÂç≥‰ΩøÁî®ÂãæËÇ°ÂÆöÁêÜÊù•ËÆ°ÁÆóÊñúËæπ„ÄÇÔºâ‰æãÂ¶ÇÔºå(2,2) ‰∏é (5,-2) ‰πãÈó¥ÁöÑ k-means Ë∑ùÁ¶ª‰∏∫Ôºö $${\text{Ê¨ßÂá†ÈáåÂæ∑Ë∑ùÁ¶ª}} = {\sqrt {(2-5)^2 + (2--2)^2}} = 5$$ k-median ÈááÁî®‰ªéÂΩ¢ÂøÉÂà∞Ê†∑Êú¨ÁöÑÊõºÂìàÈ°øË∑ùÁ¶ª„ÄÇËøô‰∏™Ë∑ùÁ¶ªÊòØÊØè‰∏™Áª¥Â∫¶‰∏≠ÁªùÂØπÂ∑ÆÂºÇÂÄºÁöÑÊÄªÂíå„ÄÇ‰æãÂ¶ÇÔºå(2,2) ‰∏é (5,-2) ‰πãÈó¥ÁöÑ k-median Ë∑ùÁ¶ª‰∏∫Ôºö $${\text{ÊõºÂìàÈ°øË∑ùÁ¶ª}} = \lvert 2-5 \rvert + \lvert 2--2 \rvert = 7$$ Keras ‰∏ÄÁßçÁÉ≠Èó®ÁöÑ Python Êú∫Âô®Â≠¶‰π† API„ÄÇKeras ËÉΩÂ§üÂú®Â§öÁßçÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂‰∏äËøêË°åÔºåÂÖ∂‰∏≠ÂåÖÊã¨ TensorFlowÔºàÂú®ËØ•Ê°ÜÊû∂‰∏äÔºåKeras ‰Ωú‰∏∫ tf.keras Êèê‰æõÔºâ„ÄÇ Ê†∏ÊîØÊåÅÂêëÈáèÊú∫ (KSVM, Kernel Support Vector Machines) ‰∏ÄÁßçÂàÜÁ±ªÁÆóÊ≥ïÔºåÊó®Âú®ÈÄöËøáÂ∞ÜËæìÂÖ•Êï∞ÊçÆÂêëÈáèÊò†Â∞ÑÂà∞Êõ¥È´òÁª¥Â∫¶ÁöÑÁ©∫Èó¥ÔºåÊù•ÊúÄÂ§ßÂåñÊ≠£Á±ªÂà´ÂíåË¥üÁ±ªÂà´‰πãÈó¥ÁöÑË£ïÂ∫¶„ÄÇ‰ª•Êüê‰∏™ËæìÂÖ•Êï∞ÊçÆÈõÜÂåÖÂê´‰∏ÄÁôæ‰∏™ÁâπÂæÅÁöÑÂàÜÁ±ªÈóÆÈ¢ò‰∏∫‰æã„ÄÇ‰∏∫‰∫ÜÊúÄÂ§ßÂåñÊ≠£Á±ªÂà´ÂíåË¥üÁ±ªÂà´‰πãÈó¥ÁöÑË£ïÂ∫¶ÔºåKSVM ÂèØ‰ª•Âú®ÂÜÖÈÉ®Â∞ÜËøô‰∫õÁâπÂæÅÊò†Â∞ÑÂà∞Áôæ‰∏áÁª¥Â∫¶ÁöÑÁ©∫Èó¥„ÄÇKSVM ‰ΩøÁî®ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞„ÄÇ L L1 ÊçüÂ§±ÂáΩÊï∞ (L‚ÇÅ loss) ‰∏ÄÁßçÊçüÂ§±ÂáΩÊï∞ÔºåÂü∫‰∫éÊ®°ÂûãÈ¢ÑÊµãÁöÑÂÄº‰∏éÊ†áÁ≠æÁöÑÂÆûÈôÖÂÄº‰πãÂ∑ÆÁöÑÁªùÂØπÂÄº„ÄÇ‰∏é L2 ÊçüÂ§±ÂáΩÊï∞Áõ∏ÊØîÔºåL1 ÊçüÂ§±ÂáΩÊï∞ÂØπÁ¶ªÁæ§ÂÄºÁöÑÊïèÊÑüÊÄßÂº±‰∏Ä‰∫õ„ÄÇ L1 Ê≠£ÂàôÂåñ (L‚ÇÅ regularization) ‰∏ÄÁßçÊ≠£ÂàôÂåñÔºåÊ†πÊçÆÊùÉÈáçÁöÑÁªùÂØπÂÄºÁöÑÊÄªÂíåÊù•ÊÉ©ÁΩöÊùÉÈáç„ÄÇÂú®‰æùËµñÁ®ÄÁñèÁâπÂæÅÁöÑÊ®°Âûã‰∏≠ÔºåL1 Ê≠£ÂàôÂåñÊúâÂä©‰∫é‰Ωø‰∏çÁõ∏ÂÖ≥ÊàñÂá†‰πé‰∏çÁõ∏ÂÖ≥ÁöÑÁâπÂæÅÁöÑÊùÉÈáçÊ≠£Â•Ω‰∏∫ 0Ôºå‰ªéËÄåÂ∞ÜËøô‰∫õÁâπÂæÅ‰ªéÊ®°Âûã‰∏≠ÁßªÈô§„ÄÇ‰∏é L2 Ê≠£ÂàôÂåñÁõ∏ÂØπ„ÄÇ L2 ÊçüÂ§±ÂáΩÊï∞ (L‚ÇÇ loss) ËØ∑ÂèÇÈòÖÂπ≥ÊñπÊçüÂ§±ÂáΩÊï∞„ÄÇ L2 Ê≠£ÂàôÂåñ (L‚ÇÇ regularization) ‰∏ÄÁßçÊ≠£ÂàôÂåñÔºåÊ†πÊçÆÊùÉÈáçÁöÑÂπ≥ÊñπÂíåÊù•ÊÉ©ÁΩöÊùÉÈáç„ÄÇL2 Ê≠£ÂàôÂåñÊúâÂä©‰∫é‰ΩøÁ¶ªÁæ§ÂÄºÔºàÂÖ∑ÊúâËæÉÂ§ßÊ≠£ÂÄºÊàñËæÉÂ∞èË¥üÂÄºÔºâÊùÉÈáçÊé•Ëøë‰∫é 0Ôºå‰ΩÜÂèà‰∏çÊ≠£Â•Ω‰∏∫ 0„ÄÇÔºà‰∏é L1 Ê≠£ÂàôÂåñÁõ∏ÂØπ„ÄÇÔºâÂú®Á∫øÊÄßÊ®°Âûã‰∏≠ÔºåL2 Ê≠£ÂàôÂåñÂßãÁªàÂèØ‰ª•ÊîπËøõÊ≥õÂåñ„ÄÇ Ê†áÁ≠æ (label) Âú®ÁõëÁù£ÂºèÂ≠¶‰π†‰∏≠ÔºåÊ†áÁ≠æÊåáÊ†∑Êú¨ÁöÑ‚ÄúÁ≠îÊ°à‚ÄùÊàñ‚ÄúÁªìÊûú‚ÄùÈÉ®ÂàÜ„ÄÇÊúâÊ†áÁ≠æÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏™Ê†∑Êú¨ÈÉΩÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÁâπÂæÅ‰ª•Âèä‰∏Ä‰∏™Ê†áÁ≠æ„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊàøÂ±ãÊï∞ÊçÆÈõÜ‰∏≠ÔºåÁâπÂæÅÂèØËÉΩÂåÖÊã¨ÂçßÂÆ§Êï∞„ÄÅÂç´ÁîüÈó¥Êï∞‰ª•ÂèäÊàøÈæÑÔºåËÄåÊ†áÁ≠æÂàôÂèØËÉΩÊòØÊàø‰ª∑„ÄÇÂú®ÂûÉÂúæÈÇÆ‰ª∂Ê£ÄÊµãÊï∞ÊçÆÈõÜ‰∏≠ÔºåÁâπÂæÅÂèØËÉΩÂåÖÊã¨‰∏ªÈ¢òË°å„ÄÅÂèë‰ª∂‰∫∫‰ª•ÂèäÁîµÂ≠êÈÇÆ‰ª∂Êú¨Ë∫´ÔºåËÄåÊ†áÁ≠æÂàôÂèØËÉΩÊòØ‚ÄúÂûÉÂúæÈÇÆ‰ª∂‚ÄùÊàñ‚ÄúÈùûÂûÉÂúæÈÇÆ‰ª∂‚Äù„ÄÇ ÊúâÊ†áÁ≠æÊ†∑Êú¨ (labeled example) ÂåÖÂê´ÁâπÂæÅÂíåÊ†áÁ≠æÁöÑÊ†∑Êú¨„ÄÇÂú®ÁõëÁù£ÂºèËÆ≠ÁªÉ‰∏≠ÔºåÊ®°Âûã‰ªéÊúâÊ†áÁ≠æÊ†∑Êú¨‰∏≠Â≠¶‰π†ËßÑÂæã„ÄÇ lambda ‰∏éÊ≠£ÂàôÂåñÁéáÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ ÔºàÂ§öÂê´‰πâÊúØËØ≠ÔºåÊàë‰ª¨Âú®Ê≠§ÂÖ≥Ê≥®ÁöÑÊòØËØ•ÊúØËØ≠Âú®Ê≠£ÂàôÂåñ‰∏≠ÁöÑÂÆö‰πâ„ÄÇÔºâ Â±Ç (layer) Á•ûÁªèÁΩëÁªú‰∏≠ÁöÑ‰∏ÄÁªÑÁ•ûÁªèÂÖÉÔºåË¥üË¥£Â§ÑÁêÜ‰∏ÄÁªÑËæìÂÖ•ÁâπÂæÅÔºåÊàñ‰∏ÄÁªÑÁ•ûÁªèÂÖÉÁöÑËæìÂá∫„ÄÇ Ê≠§Â§ñËøòÊåá TensorFlow ‰∏≠ÁöÑÊäΩË±°Â±Ç„ÄÇÂ±ÇÊòØ Python ÂáΩÊï∞Ôºå‰ª•Âº†ÈáèÂíåÈÖçÁΩÆÈÄâÈ°π‰Ωú‰∏∫ËæìÂÖ•ÔºåÁÑ∂ÂêéÁîüÊàêÂÖ∂‰ªñÂº†Èáè‰Ωú‰∏∫ËæìÂá∫„ÄÇÂΩìÂøÖË¶ÅÁöÑÂº†ÈáèÁªÑÂêàËµ∑Êù•ÂêéÔºåÁî®Êà∑‰æøÂèØ‰ª•ÈÄöËøáÊ®°ÂûãÂáΩÊï∞Â∞ÜÁªìÊûúËΩ¨Êç¢‰∏∫ Estimator„ÄÇ Layers API (tf.layers) ‰∏ÄÁßç TensorFlow APIÔºåÁî®‰∫é‰ª•Â±ÇÁªÑÂêàÁöÑÊñπÂºèÊûÑÂª∫Ê∑±Â∫¶Á•ûÁªèÁΩëÁªú„ÄÇÈÄöËøá Layers APIÔºåÊÇ®ÂèØ‰ª•ÊûÑÂª∫‰∏çÂêåÁ±ªÂûãÁöÑÂ±ÇÔºå‰æãÂ¶ÇÔºö ÈÄöËøá tf.layers.Dense ÊûÑÂª∫ÂÖ®ËøûÊé•Â±Ç„ÄÇ ÈÄöËøá tf.layers.Conv2D ÊûÑÂª∫Âç∑ÁßØÂ±Ç„ÄÇ Âú®ÁºñÂÜôËá™ÂÆö‰πâ Estimator Êó∂ÔºåÊÇ®ÂèØ‰ª•ÁºñÂÜô‚ÄúÂ±Ç‚ÄùÂØπË±°Êù•ÂÆö‰πâÊâÄÊúâÈöêËóèÂ±ÇÁöÑÁâπÂæÅ„ÄÇ Layers API ÈÅµÂæ™ Keras layers API ËßÑËåÉ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÈô§‰∫ÜÂâçÁºÄ‰∏çÂêå‰ª•Â§ñÔºåLayers API ‰∏≠ÁöÑÊâÄÊúâÂáΩÊï∞Âùá‰∏é Keras layers API ‰∏≠ÁöÑÂØπÂ∫îÂáΩÊï∞ÂÖ∑ÊúâÁõ∏ÂêåÁöÑÂêçÁß∞ÂíåÁ≠æÂêç„ÄÇ Â≠¶‰π†ÈÄüÁéá (learning rate) Âú®ËÆ≠ÁªÉÊ®°ÂûãÊó∂Áî®‰∫éÊ¢ØÂ∫¶‰∏ãÈôçÁöÑ‰∏Ä‰∏™Ê†áÈáè„ÄÇÂú®ÊØèÊ¨°Ëø≠‰ª£ÊúüÈó¥ÔºåÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÈÉΩ‰ºöÂ∞ÜÂ≠¶‰π†ÈÄüÁéá‰∏éÊ¢ØÂ∫¶Áõ∏‰πò„ÄÇÂæóÂá∫ÁöÑ‰πòÁßØÁß∞‰∏∫Ê¢ØÂ∫¶Ê≠•Èïø„ÄÇ Â≠¶‰π†ÈÄüÁéáÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑË∂ÖÂèÇÊï∞„ÄÇ ÊúÄÂ∞è‰∫å‰πòÂõûÂΩí (least squares regression) ‰∏ÄÁßçÈÄöËøáÊúÄÂ∞èÂåñ L2 ÊçüÂ§±ËÆ≠ÁªÉÂá∫ÁöÑÁ∫øÊÄßÂõûÂΩíÊ®°Âûã„ÄÇ Á∫øÊÄßÂõûÂΩí (linear regression) ‰∏ÄÁßçÂõûÂΩíÊ®°ÂûãÔºåÈÄöËøáÂ∞ÜËæìÂÖ•ÁâπÂæÅËøõË°åÁ∫øÊÄßÁªÑÂêàËæìÂá∫ËøûÁª≠ÂÄº„ÄÇ ÈÄªËæëÂõûÂΩí (logistic regression) ‰∏ÄÁßçÊ®°ÂûãÔºåÈÄöËøáÂ∞Ü S ÂûãÂáΩÊï∞Â∫îÁî®‰∫éÁ∫øÊÄßÈ¢ÑÊµãÔºåÁîüÊàêÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÊØè‰∏™ÂèØËÉΩÁöÑÁ¶ªÊï£Ê†áÁ≠æÂÄºÁöÑÊ¶ÇÁéá„ÄÇËôΩÁÑ∂ÈÄªËæëÂõûÂΩíÁªèÂ∏∏Áî®‰∫é‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÔºå‰ΩÜ‰πüÂèØÁî®‰∫éÂ§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢òÔºàÂÖ∂Âè´Ê≥ïÂèò‰∏∫Â§öÁ±ªÂà´ÈÄªËæëÂõûÂΩíÊàñÂ§öÈ°πÂõûÂΩíÔºâ„ÄÇ ÂØπÊï∞ (logits) ÂàÜÁ±ªÊ®°ÂûãÁîüÊàêÁöÑÂéüÂßãÔºàÈùûÊ†áÂáÜÂåñÔºâÈ¢ÑÊµãÂêëÈáèÔºåÈÄöÂ∏∏‰ºö‰º†ÈÄíÁªôÊ†áÂáÜÂåñÂáΩÊï∞„ÄÇÂ¶ÇÊûúÊ®°ÂûãË¶ÅËß£ÂÜ≥Â§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢òÔºåÂàôÂØπÊï∞ÈÄöÂ∏∏ÂèòÊàê softmax ÂáΩÊï∞ÁöÑËæìÂÖ•„ÄÇ‰πãÂêéÔºåsoftmax ÂáΩÊï∞‰ºöÁîüÊàê‰∏Ä‰∏™ÔºàÊ†áÂáÜÂåñÔºâÊ¶ÇÁéáÂêëÈáèÔºåÂØπÂ∫î‰∫éÊØè‰∏™ÂèØËÉΩÁöÑÁ±ªÂà´„ÄÇ Ê≠§Â§ñÔºåÂØπÊï∞ÊúâÊó∂‰πüÁß∞‰∏∫ S ÂûãÂáΩÊï∞ÁöÑÂÖÉÁ¥†Á∫ßÂèçÂáΩÊï∞„ÄÇÂ¶ÇÈúÄ‰∫ÜËß£ËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ tf.nn.sigmoid_cross_entropy_with_logits„ÄÇ ÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ (Log Loss) ‰∫åÂÖÉÈÄªËæëÂõûÂΩí‰∏≠‰ΩøÁî®ÁöÑÊçüÂ§±ÂáΩÊï∞„ÄÇ ÂØπÊï∞Âá†Áéá (log-odds) Êüê‰∏™‰∫ã‰ª∂Âá†ÁéáÁöÑÂØπÊï∞„ÄÇ Â¶ÇÊûú‰∫ã‰ª∂Ê∂âÂèä‰∫åÂÖÉÊ¶ÇÁéáÔºåÂàôÂá†ÁéáÊåáÁöÑÊòØÊàêÂäüÊ¶ÇÁéá (p) ‰∏éÂ§±Ë¥•Ê¶ÇÁéá (1-p) ‰πãÊØî„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊüê‰∏™ÁªôÂÆö‰∫ã‰ª∂ÁöÑÊàêÂäüÊ¶ÇÁéá‰∏∫ 90ÔºÖÔºåÂ§±Ë¥•Ê¶ÇÁéá‰∏∫ 10ÔºÖ„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂá†ÁéáÁöÑËÆ°ÁÆóÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö $${\text{Âá†Áéá}} = \frac{\text{p}} {\text{(1-p)}} = \frac{.9} {.1} = {\text{9}}$$ ÁÆÄÂçïÊù•ËØ¥ÔºåÂØπÊï∞Âá†ÁéáÂç≥Âá†ÁéáÁöÑÂØπÊï∞„ÄÇÊåâÁÖßÊÉØ‰æãÔºå‚ÄúÂØπÊï∞‚ÄùÊåáËá™ÁÑ∂ÂØπÊï∞Ôºå‰ΩÜÂØπÊï∞ÁöÑÂü∫Êï∞ÂÖ∂ÂÆûÂèØ‰ª•ÊòØ‰ªª‰ΩïÂ§ß‰∫é 1 ÁöÑÊï∞„ÄÇËã•ÈÅµÂæ™ÊÉØ‰æãÔºå‰∏äËø∞Á§∫‰æãÁöÑÂØπÊï∞Âá†ÁéáÂ∫î‰∏∫Ôºö $${\text{ÂØπÊï∞Âá†Áéá}} = ln(9) ~= 2.2$$ ÂØπÊï∞Âá†ÁéáÊòØ S ÂûãÂáΩÊï∞ÁöÑÂèçÂáΩÊï∞„ÄÇ ÊçüÂ§± (Loss) ‰∏ÄÁßçË°°ÈáèÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèÊ®°ÂûãÁöÑÈ¢ÑÊµãÂÅèÁ¶ªÂÖ∂Ê†áÁ≠æÁöÑÁ®ãÂ∫¶„ÄÇÊàñËÄÖÊõ¥ÊÇ≤ËßÇÂú∞ËØ¥ÊòØË°°ÈáèÊ®°ÂûãÊúâÂ§öÂ∑Æ„ÄÇË¶ÅÁ°ÆÂÆöÊ≠§ÂÄºÔºåÊ®°ÂûãÂøÖÈ°ªÂÆö‰πâÊçüÂ§±ÂáΩÊï∞„ÄÇ‰æãÂ¶ÇÔºåÁ∫øÊÄßÂõûÂΩíÊ®°ÂûãÈÄöÂ∏∏Â∞ÜÂùáÊñπËØØÂ∑ÆÁî®‰ΩúÊçüÂ§±ÂáΩÊï∞ÔºåËÄåÈÄªËæëÂõûÂΩíÊ®°ÂûãÂàô‰ΩøÁî®ÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞„ÄÇ M Êú∫Âô®Â≠¶‰π† (machine learning) ‰∏ÄÁßçÁ®ãÂ∫èÊàñÁ≥ªÁªüÔºåÁî®‰∫éÊ†πÊçÆËæìÂÖ•Êï∞ÊçÆÊûÑÂª∫ÔºàËÆ≠ÁªÉÔºâÈ¢ÑÊµãÊ®°Âûã„ÄÇËøôÁßçÁ≥ªÁªü‰ºöÂà©Áî®Â≠¶Âà∞ÁöÑÊ®°ÂûãÊ†πÊçÆ‰ªéÂàÜÂ∏ÉÔºàËÆ≠ÁªÉËØ•Ê®°ÂûãÊó∂‰ΩøÁî®ÁöÑÂêå‰∏ÄÂàÜÂ∏ÉÔºâ‰∏≠ÊèêÂèñÁöÑÊñ∞Êï∞ÊçÆÔºà‰ª•Ââç‰ªéÊú™ËßÅËøáÁöÑÊï∞ÊçÆÔºâËøõË°åÂÆûÁî®ÁöÑÈ¢ÑÊµã„ÄÇÊú∫Âô®Â≠¶‰π†ËøòÊåá‰∏éËøô‰∫õÁ®ãÂ∫èÊàñÁ≥ªÁªüÁõ∏ÂÖ≥ÁöÑÁ†îÁ©∂È¢ÜÂüü„ÄÇ ÂùáÊñπËØØÂ∑Æ (MSE, Mean Squared Error) ÊØè‰∏™Ê†∑Êú¨ÁöÑÂπ≥ÂùáÂπ≥ÊñπÊçüÂ§±„ÄÇMSE ÁöÑËÆ°ÁÆóÊñπÊ≥ïÊòØÂπ≥ÊñπÊçüÂ§±Èô§‰ª•Ê†∑Êú¨Êï∞„ÄÇTensorFlow Playground ÊòæÁ§∫ÁöÑ‚ÄúËÆ≠ÁªÉÊçüÂ§±‚ÄùÂÄºÂíå‚ÄúÊµãËØïÊçüÂ§±‚ÄùÂÄºÈÉΩÊòØ MSE„ÄÇ ÊåáÊ†á (metric) ÊÇ®ÂÖ≥ÂøÉÁöÑ‰∏Ä‰∏™Êï∞ÂÄº„ÄÇÂèØËÉΩÂèØ‰ª•‰πüÂèØËÉΩ‰∏çÂèØ‰ª•Áõ¥Êé•Âú®Êú∫Âô®Â≠¶‰π†Á≥ªÁªü‰∏≠ÂæóÂà∞‰ºòÂåñ„ÄÇÊÇ®ÁöÑÁ≥ªÁªüÂ∞ùËØï‰ºòÂåñÁöÑÊåáÊ†áÁß∞‰∏∫ÁõÆÊ†á„ÄÇ Metrics API (tf.metrics) ‰∏ÄÁßçÁî®‰∫éËØÑ‰º∞Ê®°ÂûãÁöÑ TensorFlow API„ÄÇ‰æãÂ¶ÇÔºåtf.metrics.accuracy Áî®‰∫éÁ°ÆÂÆöÊ®°ÂûãÁöÑÈ¢ÑÊµã‰∏éÊ†áÁ≠æÂåπÈÖçÁöÑÈ¢ëÁéá„ÄÇÂú®ÁºñÂÜôËá™ÂÆö‰πâ Estimator Êó∂ÔºåÊÇ®ÂèØ‰ª•Ë∞ÉÁî® Metrics API ÂáΩÊï∞Êù•ÊåáÂÆöÂ∫îÂ¶Ç‰ΩïËØÑ‰º∞ÊÇ®ÁöÑÊ®°Âûã„ÄÇ Â∞èÊâπÊ¨° (mini-batch) ‰ªéÊï¥ÊâπÊ†∑Êú¨ÂÜÖÈöèÊú∫ÈÄâÊã©Âπ∂Âú®ËÆ≠ÁªÉÊàñÊé®Êñ≠ËøáÁ®ãÁöÑ‰∏ÄÊ¨°Ëø≠‰ª£‰∏≠‰∏ÄËµ∑ËøêË°åÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÊ†∑Êú¨„ÄÇÂ∞èÊâπÊ¨°ÁöÑÊâπÊ¨°Â§ßÂ∞èÈÄöÂ∏∏‰ªã‰∫é 10 Âà∞ 1000 ‰πãÈó¥„ÄÇ‰∏éÂü∫‰∫éÂÆåÊï¥ÁöÑËÆ≠ÁªÉÊï∞ÊçÆËÆ°ÁÆóÊçüÂ§±Áõ∏ÊØîÔºåÂü∫‰∫éÂ∞èÊâπÊ¨°Êï∞ÊçÆËÆ°ÁÆóÊçüÂ§±Ë¶ÅÈ´òÊïàÂæóÂ§ö„ÄÇ Â∞èÊâπÊ¨°ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï (SGD, mini-batch stochastic gradient descent) ‰∏ÄÁßçÈááÁî®Â∞èÊâπÊ¨°Ê†∑Êú¨ÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ï„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂ∞èÊâπÊ¨° SGD ‰ºöÊ†πÊçÆ‰∏ÄÂ∞èÈÉ®ÂàÜËÆ≠ÁªÉÊï∞ÊçÆÊù•‰º∞ÁÆóÊ¢ØÂ∫¶„ÄÇVanilla SGD ‰ΩøÁî®ÁöÑÂ∞èÊâπÊ¨°ÁöÑÂ§ßÂ∞è‰∏∫ 1„ÄÇ ML Êú∫Âô®Â≠¶‰π†ÁöÑÁº©ÂÜô„ÄÇ Ê®°Âûã (model) Êú∫Âô®Â≠¶‰π†Á≥ªÁªü‰ªéËÆ≠ÁªÉÊï∞ÊçÆÂ≠¶Âà∞ÁöÑÂÜÖÂÆπÁöÑË°®Á§∫ÂΩ¢Âºè„ÄÇÂ§öÂê´‰πâÊúØËØ≠ÔºåÂèØ‰ª•ÁêÜËß£‰∏∫‰∏ãÂàó‰∏§ÁßçÁõ∏ÂÖ≥Âê´‰πâ‰πã‰∏ÄÔºö ‰∏ÄÁßç TensorFlow ÂõæÔºåÁî®‰∫éË°®Á§∫È¢ÑÊµãÁöÑËÆ°ÁÆóÁªìÊûÑ„ÄÇ ËØ• TensorFlow ÂõæÁöÑÁâπÂÆöÊùÉÈáçÂíåÂÅèÂ∑ÆÔºåÈÄöËøáËÆ≠ÁªÉÂÜ≥ÂÆö„ÄÇ Ê®°ÂûãÂáΩÊï∞ (model function) Estimator ‰∏≠ÁöÑÂáΩÊï∞ÔºåÁî®‰∫éÂÆûÁé∞Êú∫Âô®Â≠¶‰π†ËÆ≠ÁªÉ„ÄÅËØÑ‰º∞ÂíåÊé®Êñ≠„ÄÇ‰æãÂ¶ÇÔºåÊ®°ÂûãÂáΩÊï∞ÁöÑËÆ≠ÁªÉÈÉ®ÂàÜÂèØ‰ª•Â§ÑÁêÜ‰ª•‰∏ã‰ªªÂä°ÔºöÂÆö‰πâÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑÊãìÊâëÂπ∂Á°ÆÂÆöÂÖ∂‰ºòÂåñÂô®ÂáΩÊï∞„ÄÇÂ¶ÇÊûú‰ΩøÁî®È¢ÑÂàõÂª∫ÁöÑ EstimatorÔºåÂàôÊúâ‰∫∫Â∑≤‰∏∫ÊÇ®ÁºñÂÜô‰∫ÜÊ®°ÂûãÂáΩÊï∞„ÄÇÂ¶ÇÊûú‰ΩøÁî®Ëá™ÂÆö‰πâ EstimatorÔºåÂàôÂøÖÈ°ªËá™Ë°åÁºñÂÜôÊ®°ÂûãÂáΩÊï∞„ÄÇ ÊúâÂÖ≥ÁºñÂÜôÊ®°ÂûãÂáΩÊï∞ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖÂàõÂª∫Ëá™ÂÆö‰πâ Estimator„ÄÇ Ê®°ÂûãËÆ≠ÁªÉ (model training) Á°ÆÂÆöÊúÄ‰Ω≥Ê®°ÂûãÁöÑËøáÁ®ã„ÄÇ Âä®Èáè (Momentum) ‰∏ÄÁßçÂÖàËøõÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºåÂÖ∂‰∏≠Â≠¶‰π†Ê≠•Èïø‰∏ç‰ªÖÂèñÂÜ≥‰∫éÂΩìÂâçÊ≠•ÈïøÁöÑÂØºÊï∞ÔºåËøòÂèñÂÜ≥‰∫é‰πãÂâç‰∏ÄÊ≠•ÊàñÂ§öÊ≠•ÁöÑÊ≠•ÈïøÁöÑÂØºÊï∞„ÄÇÂä®ÈáèÊ∂âÂèäËÆ°ÁÆóÊ¢ØÂ∫¶ÈöèÊó∂Èó¥ËÄåÂèòÂåñÁöÑÊåáÊï∞Á∫ßÂä†ÊùÉÁßªÂä®Âπ≥ÂùáÂÄºÔºå‰∏éÁâ©ÁêÜÂ≠¶‰∏≠ÁöÑÂä®ÈáèÁ±ª‰ºº„ÄÇÂä®ÈáèÊúâÊó∂ÂèØ‰ª•Èò≤Ê≠¢Â≠¶‰π†ËøáÁ®ãË¢´Âç°Âú®Â±ÄÈÉ®ÊúÄÂ∞èÁöÑÊÉÖÂÜµ„ÄÇ Â§öÁ±ªÂà´ÂàÜÁ±ª (multi-class classification) Âå∫ÂàÜ‰∏§Áßç‰ª•‰∏äÁ±ªÂà´ÁöÑÂàÜÁ±ªÈóÆÈ¢ò„ÄÇ‰æãÂ¶ÇÔºåÊû´Ê†ëÂ§ßÁ∫¶Êúâ 128 ÁßçÔºåÂõ†Ê≠§ÔºåÁ°ÆÂÆöÊû´Ê†ëÁßçÁ±ªÁöÑÊ®°ÂûãÂ∞±Â±û‰∫éÂ§öÁ±ªÂà´Ê®°Âûã„ÄÇÂèç‰πãÔºå‰ªÖÂ∞ÜÁîµÂ≠êÈÇÆ‰ª∂ÂàÜ‰∏∫‰∏§Á±ªÔºà‚ÄúÂûÉÂúæÈÇÆ‰ª∂‚ÄùÂíå‚ÄúÈùûÂûÉÂúæÈÇÆ‰ª∂‚ÄùÔºâÁöÑÊ®°ÂûãÂ±û‰∫é‰∫åÂÖÉÂàÜÁ±ªÊ®°Âûã„ÄÇ Â§öÈ°πÂàÜÁ±ª (multinomial classification) ‰∏éÂ§öÁ±ªÂà´ÂàÜÁ±ªÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ N NaN Èô∑Èò± (NaN trap) Ê®°Âûã‰∏≠ÁöÑ‰∏Ä‰∏™Êï∞Â≠óÂú®ËÆ≠ÁªÉÊúüÈó¥ÂèòÊàê NaNÔºåËøô‰ºöÂØºËá¥Ê®°Âûã‰∏≠ÁöÑÂæàÂ§öÊàñÊâÄÊúâÂÖ∂‰ªñÊï∞Â≠óÊúÄÁªà‰πü‰ºöÂèòÊàê NaN„ÄÇ NaN ÊòØ‚ÄúÈùûÊï∞Â≠ó‚ÄùÁöÑÁº©ÂÜô„ÄÇ Ë¥üÁ±ªÂà´ (negative class) Âú®‰∫åÂÖÉÂàÜÁ±ª‰∏≠Ôºå‰∏ÄÁßçÁ±ªÂà´Áß∞‰∏∫Ê≠£Á±ªÂà´ÔºåÂè¶‰∏ÄÁßçÁ±ªÂà´Áß∞‰∏∫Ë¥üÁ±ªÂà´„ÄÇÊ≠£Á±ªÂà´ÊòØÊàë‰ª¨Ë¶ÅÂØªÊâæÁöÑÁ±ªÂà´ÔºåË¥üÁ±ªÂà´ÂàôÊòØÂè¶‰∏ÄÁßçÂèØËÉΩÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂåªÂ≠¶Ê£ÄÊü•‰∏≠ÔºåË¥üÁ±ªÂà´ÂèØ‰ª•ÊòØ‚ÄúÈùûËÇøÁò§‚Äù„ÄÇÂú®ÁîµÂ≠êÈÇÆ‰ª∂ÂàÜÁ±ªÂô®‰∏≠ÔºåË¥üÁ±ªÂà´ÂèØ‰ª•ÊòØ‚ÄúÈùûÂûÉÂúæÈÇÆ‰ª∂‚Äù„ÄÇÂè¶ËØ∑ÂèÇÈòÖÊ≠£Á±ªÂà´„ÄÇ Á•ûÁªèÁΩëÁªú (neural network) ‰∏ÄÁßçÊ®°ÂûãÔºåÁÅµÊÑüÊù•Ê∫ê‰∫éËÑëÈÉ®ÁªìÊûÑÔºåÁî±Â§ö‰∏™Â±ÇÊûÑÊàêÔºàËá≥Â∞ëÊúâ‰∏Ä‰∏™ÊòØÈöêËóèÂ±ÇÔºâÔºåÊØè‰∏™Â±ÇÈÉΩÂåÖÂê´ÁÆÄÂçïÁõ∏ËøûÁöÑÂçïÂÖÉÊàñÁ•ûÁªèÂÖÉÔºàÂÖ∑ÊúâÈùûÁ∫øÊÄßÂÖ≥Á≥ªÔºâ„ÄÇ Á•ûÁªèÂÖÉ (neuron) Á•ûÁªèÁΩëÁªú‰∏≠ÁöÑËäÇÁÇπÔºåÈÄöÂ∏∏‰ºöÊé•Êî∂Â§ö‰∏™ËæìÂÖ•ÂÄºÂπ∂ÁîüÊàê‰∏Ä‰∏™ËæìÂá∫ÂÄº„ÄÇÁ•ûÁªèÂÖÉÈÄöËøáÂ∞ÜÊøÄÊ¥ªÂáΩÊï∞ÔºàÈùûÁ∫øÊÄßËΩ¨Êç¢ÔºâÂ∫îÁî®‰∫éËæìÂÖ•ÂÄºÁöÑÂä†ÊùÉÂíåÊù•ËÆ°ÁÆóËæìÂá∫ÂÄº„ÄÇ ËäÇÁÇπ (node) Â§öÂê´‰πâÊúØËØ≠ÔºåÂèØ‰ª•ÁêÜËß£‰∏∫‰∏ãÂàó‰∏§ÁßçÂê´‰πâ‰πã‰∏ÄÔºö ÈöêËóèÂ±Ç‰∏≠ÁöÑÁ•ûÁªèÂÖÉ„ÄÇ TensorFlow Âõæ‰∏≠ÁöÑÊìç‰Ωú„ÄÇ Ê†áÂáÜÂåñ (normalization) Â∞ÜÂÆûÈôÖÁöÑÂÄºÂå∫Èó¥ËΩ¨Êç¢‰∏∫Ê†áÂáÜÁöÑÂÄºÂå∫Èó¥ÔºàÈÄöÂ∏∏‰∏∫ -1 Âà∞ +1 Êàñ 0 Âà∞ 1ÔºâÁöÑËøáÁ®ã„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊüê‰∏™ÁâπÂæÅÁöÑËá™ÁÑ∂Âå∫Èó¥ÊòØ 800 Âà∞ 6000„ÄÇÈÄöËøáÂáèÊ≥ïÂíåÈô§Ê≥ïËøêÁÆóÔºåÊÇ®ÂèØ‰ª•Â∞ÜËøô‰∫õÂÄºÊ†áÂáÜÂåñ‰∏∫‰Ωç‰∫é -1 Âà∞ +1 Âå∫Èó¥ÂÜÖ„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÁº©Êîæ„ÄÇ Êï∞ÂÄºÊï∞ÊçÆ (numerical data) Áî®Êï¥Êï∞ÊàñÂÆûÊï∞Ë°®Á§∫ÁöÑÁâπÂæÅ„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊàøÂú∞‰∫ßÊ®°Âûã‰∏≠ÔºåÊÇ®ÂèØËÉΩ‰ºöÁî®Êï∞ÂÄºÊï∞ÊçÆË°®Á§∫ÊàøÂ≠êÂ§ßÂ∞èÔºà‰ª•Âπ≥ÊñπËã±Â∞∫ÊàñÂπ≥ÊñπÁ±≥‰∏∫Âçï‰ΩçÔºâ„ÄÇÂ¶ÇÊûúÁî®Êï∞ÂÄºÊï∞ÊçÆË°®Á§∫ÁâπÂæÅÔºåÂàôÂèØ‰ª•Ë°®ÊòéÁâπÂæÅÁöÑÂÄºÁõ∏‰∫í‰πãÈó¥ÂÖ∑ÊúâÊï∞Â≠¶ÂÖ≥Á≥ªÔºåÂπ∂‰∏î‰∏éÊ†áÁ≠æÂèØËÉΩ‰πüÊúâÊï∞Â≠¶ÂÖ≥Á≥ª„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÁî®Êï∞ÂÄºÊï∞ÊçÆË°®Á§∫ÊàøÂ≠êÂ§ßÂ∞èÔºåÂàôÂèØ‰ª•Ë°®ÊòéÈù¢ÁßØ‰∏∫ 200 Âπ≥ÊñπÁ±≥ÁöÑÊàøÂ≠êÊòØÈù¢ÁßØ‰∏∫ 100 Âπ≥ÊñπÁ±≥ÁöÑÊàøÂ≠êÁöÑ‰∏§ÂÄç„ÄÇÊ≠§Â§ñÔºåÊàøÂ≠êÈù¢ÁßØÁöÑÂπ≥ÊñπÁ±≥Êï∞ÂèØËÉΩ‰∏éÊàø‰ª∑Â≠òÂú®‰∏ÄÂÆöÁöÑÊï∞Â≠¶ÂÖ≥Á≥ª„ÄÇ Âπ∂ÈùûÊâÄÊúâÊï¥Êï∞Êï∞ÊçÆÈÉΩÂ∫îË°®Á§∫ÊàêÊï∞ÂÄºÊï∞ÊçÆ„ÄÇ‰æãÂ¶ÇÔºå‰∏ñÁïå‰∏äÊüê‰∫õÂú∞Âå∫ÁöÑÈÇÆÊîøÁºñÁ†ÅÊòØÊï¥Êï∞Ôºå‰ΩÜÂú®Ê®°Âûã‰∏≠Ôºå‰∏çÂ∫îÂ∞ÜÊï¥Êï∞ÈÇÆÊîøÁºñÁ†ÅË°®Á§∫ÊàêÊï∞ÂÄºÊï∞ÊçÆ„ÄÇËøôÊòØÂõ†‰∏∫ÈÇÆÊîøÁºñÁ†Å 20000 Âú®ÊïàÂäõ‰∏äÂπ∂‰∏çÊòØÈÇÆÊîøÁºñÁ†Å 10000 ÁöÑ‰∏§ÂÄçÔºàÊàñ‰∏ÄÂçäÔºâ„ÄÇÊ≠§Â§ñÔºåËôΩÁÑ∂‰∏çÂêåÁöÑÈÇÆÊîøÁºñÁ†ÅÁ°ÆÂÆû‰∏é‰∏çÂêåÁöÑÊàøÂú∞‰∫ß‰ª∑ÂÄºÊúâÂÖ≥Ôºå‰ΩÜÊàë‰ª¨‰πü‰∏çËÉΩÂÅáËÆæÈÇÆÊîøÁºñÁ†Å‰∏∫ 20000 ÁöÑÊàøÂú∞‰∫ßÂú®‰ª∑ÂÄº‰∏äÊòØÈÇÆÊîøÁºñÁ†Å‰∏∫ 10000 ÁöÑÊàøÂú∞‰∫ßÁöÑ‰∏§ÂÄç„ÄÇÈÇÆÊîøÁºñÁ†ÅÂ∫îË°®Á§∫ÊàêÂàÜÁ±ªÊï∞ÊçÆ„ÄÇ Êï∞ÂÄºÁâπÂæÅÊúâÊó∂Áß∞‰∏∫ËøûÁª≠ÁâπÂæÅ„ÄÇ Numpy ‰∏Ä‰∏™ÂºÄÊîæÊ∫ê‰ª£Á†ÅÊï∞Â≠¶Â∫ìÔºåÂú® Python ‰∏≠Êèê‰æõÈ´òÊïàÁöÑÊï∞ÁªÑÊìç‰Ωú„ÄÇPandas Âª∫Á´ãÂú® Numpy ‰πã‰∏ä„ÄÇ O ÁõÆÊ†á (objective) ÁÆóÊ≥ïÂ∞ùËØï‰ºòÂåñÁöÑÊåáÊ†á„ÄÇ Á¶ªÁ∫øÊé®Êñ≠ (offline inference) ÁîüÊàê‰∏ÄÁªÑÈ¢ÑÊµãÔºåÂ≠òÂÇ®Ëøô‰∫õÈ¢ÑÊµãÔºåÁÑ∂ÂêéÊ†πÊçÆÈúÄÊ±ÇÊ£ÄÁ¥¢Ëøô‰∫õÈ¢ÑÊµã„ÄÇ‰∏éÂú®Á∫øÊé®Êñ≠Áõ∏ÂØπ„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (one-hot encoding) ‰∏ÄÁßçÁ®ÄÁñèÂêëÈáèÔºåÂÖ∂‰∏≠Ôºö ‰∏Ä‰∏™ÂÖÉÁ¥†ËÆæ‰∏∫ 1„ÄÇ ÊâÄÊúâÂÖ∂‰ªñÂÖÉÁ¥†ÂùáËÆæ‰∏∫ 0„ÄÇ Áã¨ÁÉ≠ÁºñÁ†ÅÂ∏∏Áî®‰∫éË°®Á§∫Êã•ÊúâÊúâÈôê‰∏™ÂèØËÉΩÂÄºÁöÑÂ≠óÁ¨¶‰∏≤ÊàñÊ†áËØÜÁ¨¶„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊüê‰∏™ÊåáÂÆöÁöÑÊ§çÁâ©Â≠¶Êï∞ÊçÆÈõÜËÆ∞ÂΩï‰∫Ü 15000 ‰∏™‰∏çÂêåÁöÑÁâ©ÁßçÔºåÂÖ∂‰∏≠ÊØè‰∏™Áâ©ÁßçÈÉΩÁî®Áã¨‰∏ÄÊó†‰∫åÁöÑÂ≠óÁ¨¶‰∏≤Ê†áËØÜÁ¨¶Êù•Ë°®Á§∫„ÄÇÂú®ÁâπÂæÅÂ∑•Á®ãËøáÁ®ã‰∏≠ÔºåÊÇ®ÂèØËÉΩÈúÄË¶ÅÂ∞ÜËøô‰∫õÂ≠óÁ¨¶‰∏≤Ê†áËØÜÁ¨¶ÁºñÁ†Å‰∏∫Áã¨ÁÉ≠ÂêëÈáèÔºåÂêëÈáèÁöÑÂ§ßÂ∞è‰∏∫ 15000„ÄÇ ÂçïÊ†∑Êú¨Â≠¶‰π†Ôºàone-shot learningÔºåÈÄöÂ∏∏Áî®‰∫éÂØπË±°ÂàÜÁ±ªÔºâ ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºåÈÄöÂ∏∏Áî®‰∫éÂØπË±°ÂàÜÁ±ªÔºåÊó®Âú®ÈÄöËøáÂçï‰∏™ËÆ≠ÁªÉÊ†∑Êú¨Â≠¶‰π†ÊúâÊïàÁöÑÂàÜÁ±ªÂô®„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÂ∞ëÈáèÊ†∑Êú¨Â≠¶‰π†„ÄÇ ‰∏ÄÂØπÂ§ö (one-vs.-all) ÂÅáËÆæÊüê‰∏™ÂàÜÁ±ªÈóÆÈ¢òÊúâ N ÁßçÂèØËÉΩÁöÑËß£ÂÜ≥ÊñπÊ°àÔºå‰∏ÄÂØπÂ§öËß£ÂÜ≥ÊñπÊ°àÂ∞ÜÂåÖÂê´ N ‰∏™ÂçïÁã¨ÁöÑ‰∫åÂÖÉÂàÜÁ±ªÂô® - ‰∏Ä‰∏™‰∫åÂÖÉÂàÜÁ±ªÂô®ÂØπÂ∫î‰∏ÄÁßçÂèØËÉΩÁöÑÁªìÊûú„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊüê‰∏™Ê®°ÂûãÁî®‰∫éÂå∫ÂàÜÊ†∑Êú¨Â±û‰∫éÂä®Áâ©„ÄÅËî¨ËèúËøòÊòØÁüøÁâ©Ôºå‰∏ÄÂØπÂ§öËß£ÂÜ≥ÊñπÊ°àÂ∞ÜÊèê‰æõ‰∏ãÂàó‰∏â‰∏™ÂçïÁã¨ÁöÑ‰∫åÂÖÉÂàÜÁ±ªÂô®Ôºö Âä®Áâ©ÂíåÈùûÂä®Áâ© Ëî¨ËèúÂíåÈùûËî¨Ëèú ÁüøÁâ©ÂíåÈùûÁüøÁâ© Âú®Á∫øÊé®Êñ≠ (online inference) Ê†πÊçÆÈúÄÊ±ÇÁîüÊàêÈ¢ÑÊµã„ÄÇ‰∏éÁ¶ªÁ∫øÊé®Êñ≠Áõ∏ÂØπ„ÄÇ Êìç‰Ωú (op, Operation) TensorFlow Âõæ‰∏≠ÁöÑËäÇÁÇπ„ÄÇÂú® TensorFlow ‰∏≠Ôºå‰ªª‰ΩïÂàõÂª∫„ÄÅÊìçÁ∫µÊàñÈîÄÊØÅÂº†ÈáèÁöÑËøáÁ®ãÈÉΩÂ±û‰∫éÊìç‰Ωú„ÄÇ‰æãÂ¶ÇÔºåÁü©ÈòµÁõ∏‰πòÂ∞±ÊòØ‰∏ÄÁßçÊìç‰ΩúÔºåËØ•Êìç‰Ωú‰ª•‰∏§‰∏™Âº†Èáè‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂ÁîüÊàê‰∏Ä‰∏™Âº†Èáè‰Ωú‰∏∫ËæìÂá∫„ÄÇ ‰ºòÂåñÂô® (optimizer) Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÁöÑ‰∏ÄÁßçÂÖ∑‰ΩìÂÆûÁé∞„ÄÇTensorFlow ÁöÑ‰ºòÂåñÂô®Âü∫Á±ªÊòØ tf.train.Optimizer„ÄÇ‰∏çÂêåÁöÑ‰ºòÂåñÂô®ÂèØËÉΩ‰ºöÂà©Áî®‰ª•‰∏ã‰∏Ä‰∏™ÊàñÂ§ö‰∏™Ê¶ÇÂøµÊù•Â¢ûÂº∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂú®ÊåáÂÆöËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑÊïàÊûúÔºö Âä®Èáè (Momentum) Êõ¥Êñ∞È¢ëÁéáÔºàAdaGrad = ADAptive GRADient descentÔºõAdam = ADAptive with MomentumÔºõRMSPropÔºâ Á®ÄÁñèÊÄß/Ê≠£ÂàôÂåñ (Ftrl) Êõ¥Â§çÊùÇÁöÑÊï∞Â≠¶ÊñπÊ≥ïÔºàProximalÔºåÁ≠âÁ≠âÔºâ ÁîöËá≥ËøòÂåÖÊã¨ NN È©±Âä®ÁöÑ‰ºòÂåñÂô®„ÄÇ Á¶ªÁæ§ÂÄº (outlier) ‰∏éÂ§ßÂ§öÊï∞ÂÖ∂‰ªñÂÄºÂ∑ÆÂà´ÂæàÂ§ßÁöÑÂÄº„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Ôºå‰∏ãÂàóÊâÄÊúâÂÄºÈÉΩÊòØÁ¶ªÁæ§ÂÄº„ÄÇ ÁªùÂØπÂÄºÂæàÈ´òÁöÑÊùÉÈáç„ÄÇ ‰∏éÂÆûÈôÖÂÄºÁõ∏Â∑ÆÂæàÂ§ßÁöÑÈ¢ÑÊµãÂÄº„ÄÇ ÂÄºÊØîÂπ≥ÂùáÂÄºÈ´òÂ§ßÁ∫¶ 3 ‰∏™Ê†áÂáÜÂÅèÂ∑ÆÁöÑËæìÂÖ•Êï∞ÊçÆ„ÄÇ Á¶ªÁæ§ÂÄºÂ∏∏Â∏∏‰ºöÂØºËá¥Ê®°ÂûãËÆ≠ÁªÉÂá∫Áé∞ÈóÆÈ¢ò„ÄÇ ËæìÂá∫Â±Ç (output layer) Á•ûÁªèÁΩëÁªúÁöÑ‚ÄúÊúÄÂêé‚Äù‰∏ÄÂ±ÇÔºå‰πüÊòØÂåÖÂê´Á≠îÊ°àÁöÑÂ±Ç„ÄÇ ËøáÊãüÂêà (overfitting) ÂàõÂª∫ÁöÑÊ®°Âûã‰∏éËÆ≠ÁªÉÊï∞ÊçÆËøá‰∫éÂåπÈÖçÔºå‰ª•Ëá¥‰∫éÊ®°ÂûãÊó†Ê≥ïÊ†πÊçÆÊñ∞Êï∞ÊçÆÂÅöÂá∫Ê≠£Á°ÆÁöÑÈ¢ÑÊµã„ÄÇ P Pandas Èù¢ÂêëÂàóÁöÑÊï∞ÊçÆÂàÜÊûê API„ÄÇÂæàÂ§öÊú∫Âô®Â≠¶‰π†Ê°ÜÊû∂ÔºàÂåÖÊã¨ TensorFlowÔºâÈÉΩÊîØÊåÅÂ∞Ü Pandas Êï∞ÊçÆÁªìÊûÑ‰Ωú‰∏∫ËæìÂÖ•„ÄÇËØ∑ÂèÇÈòÖ Pandas ÊñáÊ°£„ÄÇ ÂèÇÊï∞ (parameter) Êú∫Âô®Â≠¶‰π†Á≥ªÁªüËá™Ë°åËÆ≠ÁªÉÁöÑÊ®°ÂûãÁöÑÂèòÈáè„ÄÇ‰æãÂ¶ÇÔºåÊùÉÈáçÂ∞±ÊòØ‰∏ÄÁßçÂèÇÊï∞ÔºåÂÆÉ‰ª¨ÁöÑÂÄºÊòØÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÈÄöËøáËøûÁª≠ÁöÑËÆ≠ÁªÉËø≠‰ª£ÈÄêÊ∏êÂ≠¶‰π†Âà∞ÁöÑ„ÄÇ‰∏éË∂ÖÂèÇÊï∞Áõ∏ÂØπ„ÄÇ ÂèÇÊï∞ÊúçÂä°Âô® (PS, Parameter Server) ‰∏ÄÁßç‰Ωú‰∏öÔºåË¥üË¥£Âú®ÂàÜÂ∏ÉÂºèËÆæÁΩÆ‰∏≠Ë∑üË∏™Ê®°ÂûãÂèÇÊï∞„ÄÇ ÂèÇÊï∞Êõ¥Êñ∞ (parameter update) Âú®ËÆ≠ÁªÉÊúüÈó¥ÔºàÈÄöÂ∏∏ÊòØÂú®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÁöÑÂçïÊ¨°Ëø≠‰ª£‰∏≠ÔºâË∞ÉÊï¥Ê®°ÂûãÂèÇÊï∞ÁöÑÊìç‰Ωú„ÄÇ ÂÅèÂØºÊï∞ (partial derivative) ‰∏ÄÁßçÂØºÊï∞ÔºåÈô§‰∏Ä‰∏™ÂèòÈáè‰πãÂ§ñÁöÑÊâÄÊúâÂèòÈáèÈÉΩË¢´ËßÜ‰∏∫Â∏∏Èáè„ÄÇ‰æãÂ¶ÇÔºåf(x, y) ÂØπ x ÁöÑÂÅèÂØºÊï∞Â∞±ÊòØ f(x) ÁöÑÂØºÊï∞ÔºàÂç≥Ôºå‰Ωø y ‰øùÊåÅÊÅíÂÆöÔºâ„ÄÇf ÂØπ x ÁöÑÂÅèÂØºÊï∞‰ªÖÂÖ≥Ê≥® x Â¶Ç‰ΩïÂèòÂåñÔºåËÄåÂøΩÁï•ÂÖ¨Âºè‰∏≠ÁöÑÊâÄÊúâÂÖ∂‰ªñÂèòÈáè„ÄÇ ÂàíÂàÜÁ≠ñÁï• (partitioning strategy) Âú®ÂèÇÊï∞ÊúçÂä°Âô®Èó¥ÂàÜÂâ≤ÂèòÈáèÁöÑÁÆóÊ≥ï„ÄÇ ÊÄßËÉΩ (performance) Â§öÂê´‰πâÊúØËØ≠ÔºåÂÖ∑Êúâ‰ª•‰∏ãÂê´‰πâÔºö Âú®ËΩØ‰ª∂Â∑•Á®ã‰∏≠ÁöÑ‰º†ÁªüÂê´‰πâ„ÄÇÂç≥ÔºöÁõ∏Â∫îËΩØ‰ª∂ÁöÑËøêË°åÈÄüÂ∫¶ÊúâÂ§öÂø´ÔºàÊàñÊúâÂ§öÈ´òÊïàÔºâÔºü Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÂê´‰πâ„ÄÇÂú®Êú∫Âô®Â≠¶‰π†È¢ÜÂüüÔºåÊÄßËÉΩÊó®Âú®ÂõûÁ≠î‰ª•‰∏ãÈóÆÈ¢òÔºöÁõ∏Â∫îÊ®°ÂûãÁöÑÂáÜÁ°ÆÂ∫¶ÊúâÂ§öÈ´òÔºüÂç≥Ê®°ÂûãÂú®È¢ÑÊµãÊñπÈù¢ÁöÑË°®Áé∞ÊúâÂ§öÂ•ΩÔºü Âõ∞ÊÉëÂ∫¶ (perplexity) ‰∏ÄÁßçË°°ÈáèÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèÊ®°ÂûãËÉΩÂ§üÂ§öÂ•ΩÂú∞ÂÆåÊàê‰ªªÂä°„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæ‰ªªÂä°ÊòØËØªÂèñÁî®Êà∑‰ΩøÁî®Êô∫ËÉΩÊâãÊú∫ÈîÆÁõòËæìÂÖ•Â≠óËØçÊó∂ËæìÂÖ•ÁöÑÂâçÂá†‰∏™Â≠óÊØçÔºåÁÑ∂ÂêéÂàóÂá∫‰∏ÄÁªÑÂèØËÉΩÁöÑÂÆåÊï¥Â≠óËØç„ÄÇÊ≠§‰ªªÂä°ÁöÑÂõ∞ÊÉëÂ∫¶ (P) ÊòØÔºö‰∏∫‰∫Ü‰ΩøÂàóÂá∫ÁöÑÂ≠óËØç‰∏≠ÂåÖÂê´Áî®Êà∑Â∞ùËØïËæìÂÖ•ÁöÑÂÆûÈôÖÂ≠óËØçÔºåÊÇ®ÈúÄË¶ÅÊèê‰æõÁöÑÁåúÊµãÈ°πÁöÑ‰∏™Êï∞„ÄÇ Âõ∞ÊÉëÂ∫¶‰∏é‰∫§ÂèâÁÜµÁöÑÂÖ≥Á≥ªÂ¶Ç‰∏ãÔºö $$P= 2^{-\text{cross entropy}}$$ ÊµÅÊ∞¥Á∫ø (pipeline) Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÂü∫Á°ÄÊû∂ÊûÑ„ÄÇÊµÅÊ∞¥Á∫øÂåÖÊã¨Êî∂ÈõÜÊï∞ÊçÆ„ÄÅÂ∞ÜÊï∞ÊçÆÊîæÂÖ•ËÆ≠ÁªÉÊï∞ÊçÆÊñá‰ª∂„ÄÅËÆ≠ÁªÉ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Ê®°ÂûãÔºå‰ª•ÂèäÂ∞ÜÊ®°ÂûãÂØºÂá∫Âà∞Áîü‰∫ßÁéØÂ¢É„ÄÇ Ê±†Âåñ (pooling) Â∞Ü‰∏Ä‰∏™ÊàñÂ§ö‰∏™Áî±ÂâçË∂ãÁöÑÂç∑ÁßØÂ±ÇÂàõÂª∫ÁöÑÁü©ÈòµÂéãÁº©‰∏∫ËæÉÂ∞èÁöÑÁü©Èòµ„ÄÇÊ±†ÂåñÈÄöÂ∏∏ÊòØÂèñÊï¥‰∏™Ê±†ÂåñÂå∫ÂüüÁöÑÊúÄÂ§ßÂÄºÊàñÂπ≥ÂùáÂÄº„ÄÇ‰ª•‰∏ãÈù¢ÁöÑ 3x3 Áü©Èòµ‰∏∫‰æãÔºö Ê±†ÂåñËøêÁÆó‰∏éÂç∑ÁßØËøêÁÆóÁ±ª‰ººÔºöÂ∞ÜÁü©ÈòµÂàÜÂâ≤‰∏∫Â§ö‰∏™ÂàáÁâáÔºåÁÑ∂ÂêéÊåâÊ≠•ÈïøÈÄê‰∏™ËøêË°åÂç∑ÁßØËøêÁÆó„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊ±†ÂåñËøêÁÆóÊåâ 1x1 Ê≠•ÈïøÂ∞ÜÂç∑ÁßØÁü©ÈòµÂàÜÂâ≤‰∏∫ 2x2 ‰∏™ÂàáÁâá„ÄÇÂ¶Ç‰∏ãÂõæÊâÄÁ§∫ÔºåËøõË°å‰∫ÜÂõõ‰∏™Ê±†ÂåñËøêÁÆó„ÄÇÂÅáËÆæÊØè‰∏™Ê±†ÂåñËøêÁÆóÈÉΩÈÄâÊã©ËØ•ÂàáÁâá‰∏≠Âõõ‰∏™ÂÄºÁöÑÊúÄÂ§ßÂÄºÔºö Ê±†ÂåñÊúâÂä©‰∫éÂú®ËæìÂÖ•Áü©Èòµ‰∏≠ÂÆûÁé∞Âπ≥Áßª‰∏çÂèòÊÄß„ÄÇ ÂØπ‰∫éËßÜËßâÂ∫îÁî®Êù•ËØ¥ÔºåÊ±†ÂåñÁöÑÊõ¥Ê≠£ÂºèÂêçÁß∞‰∏∫Á©∫Èó¥Ê±†Âåñ„ÄÇÊó∂Èó¥Â∫èÂàóÂ∫îÁî®ÈÄöÂ∏∏Â∞ÜÊ±†ÂåñÁß∞‰∏∫Êó∂Â∫èÊ±†Âåñ„ÄÇÊåâÁÖß‰∏çÂ§™Ê≠£ÂºèÁöÑËØ¥Ê≥ïÔºåÊ±†ÂåñÈÄöÂ∏∏Áß∞‰∏∫‰∏ãÈááÊ†∑ÊàñÈôçÈááÊ†∑„ÄÇ Ê≠£Á±ªÂà´ (positive class) Âú®‰∫åÂÖÉÂàÜÁ±ª‰∏≠Ôºå‰∏§ÁßçÂèØËÉΩÁöÑÁ±ªÂà´ÂàÜÂà´Ë¢´Ê†áËÆ∞‰∏∫Ê≠£Á±ªÂà´ÂíåË¥üÁ±ªÂà´„ÄÇÊ≠£Á±ªÂà´ÁªìÊûúÊòØÊàë‰ª¨Ë¶ÅÊµãËØïÁöÑÂØπË±°„ÄÇÔºà‰∏çÂèØÂê¶ËÆ§ÁöÑÊòØÔºåÊàë‰ª¨‰ºöÂêåÊó∂ÊµãËØïËøô‰∏§ÁßçÁªìÊûúÔºå‰ΩÜÂè™ÂÖ≥Ê≥®Ê≠£Á±ªÂà´ÁªìÊûú„ÄÇÔºâ‰æãÂ¶ÇÔºåÂú®ÂåªÂ≠¶Ê£ÄÊü•‰∏≠ÔºåÊ≠£Á±ªÂà´ÂèØ‰ª•ÊòØ‚ÄúËÇøÁò§‚Äù„ÄÇÂú®ÁîµÂ≠êÈÇÆ‰ª∂ÂàÜÁ±ªÂô®‰∏≠ÔºåÊ≠£Á±ªÂà´ÂèØ‰ª•ÊòØ‚ÄúÂûÉÂúæÈÇÆ‰ª∂‚Äù„ÄÇ ‰∏éË¥üÁ±ªÂà´Áõ∏ÂØπ„ÄÇ Á≤æÁ°ÆÁéá (precision) ‰∏ÄÁßçÂàÜÁ±ªÊ®°ÂûãÊåáÊ†á„ÄÇÁ≤æÁ°ÆÁéáÊåáÊ®°ÂûãÊ≠£Á°ÆÈ¢ÑÊµãÊ≠£Á±ªÂà´ÁöÑÈ¢ëÁéáÔºåÂç≥Ôºö $$\text{Á≤æÁ°ÆÁéá} = \frac{\text{Ê≠£‰æãÊï∞}} {\text{Ê≠£‰æãÊï∞} + \text{ÂÅáÊ≠£‰æãÊï∞}}$$ È¢ÑÊµã (prediction) Ê®°ÂûãÂú®Êî∂Âà∞ËæìÂÖ•Ê†∑Êú¨ÂêéÁöÑËæìÂá∫„ÄÇ È¢ÑÊµãÂÅèÂ∑Æ (prediction bias) ‰∏ÄÁßçÂÄºÔºåÁî®‰∫éË°®ÊòéÈ¢ÑÊµãÂπ≥ÂùáÂÄº‰∏éÊï∞ÊçÆÈõÜ‰∏≠Ê†áÁ≠æÁöÑÂπ≥ÂùáÂÄºÁõ∏Â∑ÆÊúâÂ§öÂ§ß„ÄÇ È¢ÑÂàõÂª∫ÁöÑ Estimator (pre-made Estimator) ÂÖ∂‰ªñ‰∫∫Â∑≤Âª∫Â•ΩÁöÑ Estimator„ÄÇTensorFlow Êèê‰æõ‰∫Ü‰∏Ä‰∫õÈ¢ÑÂàõÂª∫ÁöÑ EstimatorÔºåÂåÖÊã¨ DNNClassifier„ÄÅDNNRegressor Âíå LinearClassifier„ÄÇÊÇ®ÂèØ‰ª•ÊåâÁÖßËøô‰∫õËØ¥ÊòéÊûÑÂª∫Ëá™Â∑±È¢ÑÂàõÂª∫ÁöÑ Estimator„ÄÇ È¢ÑËÆ≠ÁªÉÊ®°Âûã (pre-trained model) Â∑≤ÁªèËøáËÆ≠ÁªÉÁöÑÊ®°ÂûãÊàñÊ®°ÂûãÁªÑ‰ª∂Ôºà‰æãÂ¶ÇÂµåÂ•óÔºâ„ÄÇÊúâÊó∂ÔºåÊÇ®ÈúÄË¶ÅÂ∞ÜÈ¢ÑËÆ≠ÁªÉÁöÑÂµåÂ•óÈ¶àÈÄÅÂà∞Á•ûÁªèÁΩëÁªú„ÄÇÂú®ÂÖ∂‰ªñÊó∂ÂÄôÔºåÊÇ®ÁöÑÊ®°ÂûãÂ∞ÜËá™Ë°åËÆ≠ÁªÉÂµåÂ•óÔºåËÄå‰∏ç‰æùËµñ‰∫éÈ¢ÑËÆ≠ÁªÉÁöÑÂµåÂ•ó„ÄÇ ÂÖàÈ™å‰ø°Âøµ (prior belief) Âú®ÂºÄÂßãÈááÁî®Áõ∏Â∫îÊï∞ÊçÆËøõË°åËÆ≠ÁªÉ‰πãÂâçÔºåÊÇ®ÂØπËøô‰∫õÊï∞ÊçÆÊä±ÊúâÁöÑ‰ø°Âøµ„ÄÇ‰æãÂ¶ÇÔºåL2 Ê≠£ÂàôÂåñ‰æùËµñÁöÑÂÖàÈ™å‰ø°ÂøµÊòØÊùÉÈáçÂ∫îËØ•ÂæàÂ∞è‰∏îÂ∫î‰ª• 0 ‰∏∫‰∏≠ÂøÉÂëàÊ≠£ÊÄÅÂàÜÂ∏É„ÄÇ Q ÈòüÂàó (queue) ‰∏ÄÁßç TensorFlow Êìç‰ΩúÔºåÁî®‰∫éÂÆûÁé∞ÈòüÂàóÊï∞ÊçÆÁªìÊûÑ„ÄÇÈÄöÂ∏∏Áî®‰∫é I/O ‰∏≠„ÄÇ R Á≠âÁ∫ß (rank) Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑ‰∏Ä‰∏™Â§öÂê´‰πâÊúØËØ≠ÔºåÂèØ‰ª•ÁêÜËß£‰∏∫‰∏ãÂàóÂê´‰πâ‰πã‰∏ÄÔºö Âº†Èáè‰∏≠ÁöÑÁª¥Êï∞„ÄÇ‰æãÂ¶ÇÔºåÊ†áÈáèÁ≠âÁ∫ß‰∏∫ 0ÔºåÂêëÈáèÁ≠âÁ∫ß‰∏∫ 1ÔºåÁü©ÈòµÁ≠âÁ∫ß‰∏∫ 2„ÄÇ Âú®Â∞ÜÁ±ªÂà´‰ªéÊúÄÈ´òÂà∞ÊúÄ‰ΩéËøõË°åÊéíÂ∫èÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢ò‰∏≠ÔºåÁ±ªÂà´ÁöÑÈ°∫Â∫è‰ΩçÁΩÆ„ÄÇ‰æãÂ¶ÇÔºåË°å‰∏∫ÊéíÂ∫èÁ≥ªÁªüÂèØ‰ª•Â∞ÜÁãóÁãóÁöÑÂ•ñÂä±‰ªéÊúÄÈ´òÔºàÁâõÊéíÔºâÂà∞ÊúÄ‰ΩéÔºàÊûØËêéÁöÑÁæΩË°£ÁîòËìùÔºâËøõË°åÊéíÂ∫è„ÄÇ ËØÑÂàÜËÄÖ (rater) ‰∏∫Ê†∑Êú¨Êèê‰æõÊ†áÁ≠æÁöÑ‰∫∫„ÄÇÊúâÊó∂Áß∞‰∏∫‚ÄúÊ≥®ÈáäËÄÖ‚Äù„ÄÇ Âè¨ÂõûÁéá (recall) ‰∏ÄÁßçÂàÜÁ±ªÊ®°ÂûãÊåáÊ†áÔºåÁî®‰∫éÂõûÁ≠î‰ª•‰∏ãÈóÆÈ¢òÔºöÂú®ÊâÄÊúâÂèØËÉΩÁöÑÊ≠£Á±ªÂà´Ê†áÁ≠æ‰∏≠ÔºåÊ®°ÂûãÊ≠£Á°ÆÂú∞ËØÜÂà´Âá∫‰∫ÜÂ§öÂ∞ë‰∏™ÔºüÂç≥Ôºö $$\text{Âè¨ÂõûÁéá} = \frac{\text{Ê≠£‰æãÊï∞}} {\text{Ê≠£‰æãÊï∞} + \text{ÂÅáË¥ü‰æãÊï∞}}$$ ‰øÆÊ≠£Á∫øÊÄßÂçïÂÖÉ (ReLU, Rectified Linear Unit) ‰∏ÄÁßçÊøÄÊ¥ªÂáΩÊï∞ÔºåÂÖ∂ËßÑÂàôÂ¶Ç‰∏ãÔºö Â¶ÇÊûúËæìÂÖ•‰∏∫Ë¥üÊï∞Êàñ 0ÔºåÂàôËæìÂá∫ 0„ÄÇ Â¶ÇÊûúËæìÂÖ•‰∏∫Ê≠£Êï∞ÔºåÂàôËæìÂá∫Á≠â‰∫éËæìÂÖ•„ÄÇ ÂõûÂΩíÊ®°Âûã (regression model) ‰∏ÄÁßçÊ®°ÂûãÔºåËÉΩÂ§üËæìÂá∫ËøûÁª≠ÁöÑÂÄºÔºàÈÄöÂ∏∏‰∏∫ÊµÆÁÇπÂÄºÔºâ„ÄÇËØ∑‰∏éÂàÜÁ±ªÊ®°ÂûãËøõË°åÊØîËæÉÔºåÂàÜÁ±ªÊ®°Âûã‰ºöËæìÂá∫Á¶ªÊï£ÂÄºÔºå‰æãÂ¶Ç‚ÄúÈªÑËä±Ëèú‚ÄùÊàñ‚ÄúËôéÁöÆÁôæÂêà‚Äù„ÄÇ Ê≠£ÂàôÂåñ (regularization) ÂØπÊ®°ÂûãÂ§çÊùÇÂ∫¶ÁöÑÊÉ©ÁΩö„ÄÇÊ≠£ÂàôÂåñÊúâÂä©‰∫éÈò≤Ê≠¢Âá∫Áé∞ËøáÊãüÂêàÔºåÂåÖÂê´‰ª•‰∏ãÁ±ªÂûãÔºö L1 Ê≠£ÂàôÂåñ L2 Ê≠£ÂàôÂåñ ‰∏¢ÂºÉÊ≠£ÂàôÂåñ Êó©ÂÅúÊ≥ïÔºàËøô‰∏çÊòØÊ≠£ÂºèÁöÑÊ≠£ÂàôÂåñÊñπÊ≥ïÔºå‰ΩÜÂèØ‰ª•ÊúâÊïàÈôêÂà∂ËøáÊãüÂêàÔºâ Ê≠£ÂàôÂåñÁéá (regularization rate) ‰∏ÄÁßçÊ†áÈáèÂÄºÔºå‰ª• lambda Ë°®Á§∫ÔºåÁî®‰∫éÊåáÂÆöÊ≠£ÂàôÂåñÂáΩÊï∞ÁöÑÁõ∏ÂØπÈáçË¶ÅÊÄß„ÄÇ‰ªé‰∏ãÈù¢ÁÆÄÂåñÁöÑÊçüÂ§±ÂÖ¨Âºè‰∏≠ÂèØ‰ª•ÁúãÂá∫Ê≠£ÂàôÂåñÁéáÁöÑÂΩ±ÂìçÔºö $$\text{ÊúÄÂ∞èÂåñ(ÊçüÂ§±ÊñπÁ®ã + }\lambda\text{(Ê≠£ÂàôÂåñÊñπÁ®ã))}$$ ÊèêÈ´òÊ≠£ÂàôÂåñÁéáÂèØ‰ª•ÂáèÂ∞ëËøáÊãüÂêàÔºå‰ΩÜÂèØËÉΩ‰ºö‰ΩøÊ®°ÂûãÁöÑÂáÜÁ°ÆÁéáÈôç‰Ωé„ÄÇ Ë°®Á§∫Ê≥ï (representation) Â∞ÜÊï∞ÊçÆÊò†Â∞ÑÂà∞ÂÆûÁî®ÁâπÂæÅÁöÑËøáÁ®ã„ÄÇ ÂèóËØïËÄÖÂ∑•‰ΩúÁâπÂæÅÊõ≤Á∫øÔºàreceiver operating characteristicÔºåÁÆÄÁß∞ ROC Êõ≤Á∫øÔºâ ‰∏çÂêåÂàÜÁ±ªÈòàÂÄº‰∏ãÁöÑÊ≠£‰æãÁéáÂíåÂÅáÊ≠£‰æãÁéáÊûÑÊàêÁöÑÊõ≤Á∫ø„ÄÇÂè¶ËØ∑ÂèÇÈòÖÊõ≤Á∫ø‰∏ãÈù¢ÁßØ„ÄÇ Ê†πÁõÆÂΩï (root directory) ÊÇ®ÊåáÂÆöÁöÑÁõÆÂΩïÔºåÁî®‰∫éÊâòÁÆ°Â§ö‰∏™Ê®°ÂûãÁöÑ TensorFlow Ê£ÄÊü•ÁÇπÂíå‰∫ã‰ª∂Êñá‰ª∂ÁöÑÂ≠êÁõÆÂΩï„ÄÇ ÂùáÊñπÊ†πËØØÂ∑Æ (RMSE, Root Mean Squared Error) ÂùáÊñπËØØÂ∑ÆÁöÑÂπ≥ÊñπÊ†π„ÄÇ ÊóãËΩ¨‰∏çÂèòÊÄß (rotational invariance) Âú®ÂõæÂÉèÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÔºåÂç≥‰ΩøÂõæÂÉèÁöÑÊñπÂêëÂèëÁîüÂèòÂåñÔºåÁÆóÊ≥ï‰πüËÉΩÊàêÂäüÂú∞ÂØπÂõæÂÉèËøõË°åÂàÜÁ±ª„ÄÇ‰æãÂ¶ÇÔºåÊó†ËÆ∫ÁΩëÁêÉÊãçÊúù‰∏ä„ÄÅ‰æßÂêëËøòÊòØÊúù‰∏ãÊîæÁΩÆÔºåËØ•ÁÆóÊ≥ï‰ªçÁÑ∂ÂèØ‰ª•ËØÜÂà´ÂÆÉ„ÄÇËØ∑Ê≥®ÊÑèÔºåÂπ∂ÈùûÊÄªÊòØÂ∏åÊúõÊóãËΩ¨‰∏çÂèòÔºõ‰æãÂ¶ÇÔºåÂÄíÁΩÆÁöÑ‚Äú9‚Äù‰∏çÂ∫îÂàÜÁ±ª‰∏∫‚Äú9‚Äù„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÂπ≥Áßª‰∏çÂèòÊÄßÂíåÂ§ßÂ∞è‰∏çÂèòÊÄß„ÄÇ S SavedModel ‰øùÂ≠òÂíåÊÅ¢Â§ç TensorFlow Ê®°ÂûãÊó∂Âª∫ËÆÆ‰ΩøÁî®ÁöÑÊ†ºÂºè„ÄÇSavedModel ÊòØ‰∏ÄÁßçÁã¨Á´ã‰∫éËØ≠Ë®Ä‰∏îÂèØÊÅ¢Â§çÁöÑÂ∫èÂàóÂåñÊ†ºÂºèÔºå‰ΩøËæÉÈ´òÁ∫ßÂà´ÁöÑÁ≥ªÁªüÂíåÂ∑•ÂÖ∑ÂèØ‰ª•ÂàõÂª∫„ÄÅ‰ΩøÁî®ÂíåËΩ¨Êç¢ TensorFlow Ê®°Âûã„ÄÇ Â¶ÇÈúÄÂÆåÊï¥ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ„ÄäTensorFlow ÁºñÁ®ã‰∫∫ÂëòÊåáÂçó„Äã‰∏≠ÁöÑ‰øùÂ≠òÂíåÊÅ¢Â§ç„ÄÇ Saver ‰∏ÄÁßç TensorFlow ÂØπË±°ÔºåË¥üË¥£‰øùÂ≠òÊ®°ÂûãÊ£ÄÊü•ÁÇπ„ÄÇ Áº©Êîæ (scaling) ÁâπÂæÅÂ∑•Á®ã‰∏≠ÁöÑ‰∏ÄÁßçÂ∏∏Áî®ÂÅöÊ≥ïÔºåÊòØÊåáÂØπÊüê‰∏™ÁâπÂæÅÁöÑÂÄºÂå∫Èó¥ËøõË°åË∞ÉÊï¥Ôºå‰Ωø‰πã‰∏éÊï∞ÊçÆÈõÜ‰∏≠ÂÖ∂‰ªñÁâπÂæÅÁöÑÂÄºÂå∫Èó¥‰∏ÄËá¥„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊÇ®Â∏åÊúõÊï∞ÊçÆÈõÜ‰∏≠ÊâÄÊúâÊµÆÁÇπÁâπÂæÅÁöÑÂÄºÈÉΩ‰Ωç‰∫é 0 Âà∞ 1 Âå∫Èó¥ÂÜÖÔºåÂ¶ÇÊûúÊüê‰∏™ÁâπÂæÅÁöÑÂÄº‰Ωç‰∫é 0 Âà∞ 500 Âå∫Èó¥ÂÜÖÔºåÊÇ®Â∞±ÂèØ‰ª•ÈÄöËøáÂ∞ÜÊØè‰∏™ÂÄºÈô§‰ª• 500 Êù•Áº©ÊîæËØ•ÁâπÂæÅ„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÊ†áÂáÜÂåñ„ÄÇ scikit-learn ‰∏Ä‰∏™ÁÉ≠Èó®ÁöÑÂºÄÊîæÊ∫ê‰ª£Á†ÅÊú∫Âô®Â≠¶‰π†Âπ≥Âè∞„ÄÇËØ∑ËÆøÈóÆ www.scikit-learn.org„ÄÇ ÂçäÁõëÁù£ÂºèÂ≠¶‰π† (semi-supervised learning) ËÆ≠ÁªÉÊ®°ÂûãÊó∂ÈááÁî®ÁöÑÊï∞ÊçÆ‰∏≠ÔºåÊüê‰∫õËÆ≠ÁªÉÊ†∑Êú¨ÊúâÊ†áÁ≠æÔºåËÄåÂÖ∂‰ªñÊ†∑Êú¨ÂàôÊ≤°ÊúâÊ†áÁ≠æ„ÄÇÂçäÁõëÁù£ÂºèÂ≠¶‰π†ÈááÁî®ÁöÑ‰∏ÄÁßçÊäÄÊúØÊòØÊé®Êñ≠Êó†Ê†áÁ≠æÊ†∑Êú¨ÁöÑÊ†áÁ≠æÔºåÁÑ∂Âêé‰ΩøÁî®Êé®Êñ≠Âá∫ÁöÑÊ†áÁ≠æËøõË°åËÆ≠ÁªÉÔºå‰ª•ÂàõÂª∫Êñ∞Ê®°Âûã„ÄÇÂ¶ÇÊûúËé∑ÂæóÊúâÊ†áÁ≠æÊ†∑Êú¨ÈúÄË¶ÅÈ´òÊòÇÁöÑÊàêÊú¨ÔºåËÄåÊó†Ê†áÁ≠æÊ†∑Êú¨ÂàôÊúâÂæàÂ§öÔºåÈÇ£‰πàÂçäÁõëÁù£ÂºèÂ≠¶‰π†Â∞ÜÈùûÂ∏∏ÊúâÁî®„ÄÇ Â∫èÂàóÊ®°Âûã (sequence model) ‰∏ÄÁßçÊ®°ÂûãÔºåÂÖ∂ËæìÂÖ•ÂÖ∑ÊúâÂ∫èÂàó‰æùËµñÊÄß„ÄÇ‰æãÂ¶ÇÔºåÊ†πÊçÆ‰πãÂâçËßÇÁúãËøáÁöÑ‰∏ÄÁ≥ªÂàóËßÜÈ¢ëÂØπËßÇÁúãÁöÑ‰∏ã‰∏Ä‰∏™ËßÜÈ¢ëËøõË°åÈ¢ÑÊµã„ÄÇ ‰ºöËØù (tf.session) Â∞ÅË£Ö‰∫Ü TensorFlow ËøêË°åÊó∂Áä∂ÊÄÅÁöÑÂØπË±°ÔºåÁî®‰∫éËøêË°åÂÖ®ÈÉ®ÊàñÈÉ®ÂàÜÂõæ„ÄÇÂú®‰ΩøÁî®Â∫ïÂ±Ç TensorFlow API Êó∂ÔºåÊÇ®ÂèØ‰ª•Áõ¥Êé•ÂàõÂª∫Âπ∂ÁÆ°ÁêÜ‰∏Ä‰∏™ÊàñÂ§ö‰∏™ tf.session ÂØπË±°„ÄÇÂú®‰ΩøÁî® Estimator API Êó∂ÔºåEstimator ‰ºö‰∏∫ÊÇ®ÂàõÂª∫‰ºöËØùÂØπË±°„ÄÇ S ÂûãÂáΩÊï∞ (sigmoid function) ‰∏ÄÁßçÂáΩÊï∞ÔºåÂèØÂ∞ÜÈÄªËæëÂõûÂΩíËæìÂá∫ÊàñÂ§öÈ°πÂõûÂΩíËæìÂá∫ÔºàÂØπÊï∞Âá†ÁéáÔºâÊò†Â∞ÑÂà∞Ê¶ÇÁéáÔºå‰ª•ËøîÂõû‰ªã‰∫é 0 Âà∞ 1 ‰πãÈó¥ÁöÑÂÄº„ÄÇS ÂûãÂáΩÊï∞ÁöÑÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö $$y = \frac{1}{1 + e^{-\sigma}}$$ Âú®ÈÄªËæëÂõûÂΩíÈóÆÈ¢ò‰∏≠Ôºå\(\sigma\) ÈùûÂ∏∏ÁÆÄÂçïÔºö $$\sigma = b + w_1x_1 + w_2x_2 + ‚Ä¶ w_nx_n$$ Êç¢Âè•ËØùËØ¥ÔºåS ÂûãÂáΩÊï∞ÂèØÂ∞Ü \(\sigma\) ËΩ¨Êç¢‰∏∫‰ªã‰∫é 0 Âà∞ 1 ‰πãÈó¥ÁöÑÊ¶ÇÁéá„ÄÇ Âú®Êüê‰∫õÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåS ÂûãÂáΩÊï∞ÂèØ‰Ωú‰∏∫ÊøÄÊ¥ªÂáΩÊï∞‰ΩøÁî®„ÄÇ Â§ßÂ∞è‰∏çÂèòÊÄß (size invariance) Âú®ÂõæÂÉèÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÔºåÂç≥‰ΩøÂõæÂÉèÁöÑÂ§ßÂ∞èÂèëÁîüÂèòÂåñÔºåÁÆóÊ≥ï‰πüËÉΩÊàêÂäüÂú∞ÂØπÂõæÂÉèËøõË°åÂàÜÁ±ª„ÄÇ‰æãÂ¶ÇÔºåÊó†ËÆ∫‰∏ÄÂè™Áå´‰ª• 200 ‰∏áÂÉèÁ¥†ËøòÊòØ 20 ‰∏áÂÉèÁ¥†ÂëàÁé∞ÔºåËØ•ÁÆóÊ≥ï‰ªçÁÑ∂ÂèØ‰ª•ËØÜÂà´ÂÆÉ„ÄÇËØ∑Ê≥®ÊÑèÔºåÂç≥‰ΩøÊòØÊúÄÂ•ΩÁöÑÂõæÂÉèÂàÜÁ±ªÁÆóÊ≥ïÔºåÂú®Â§ßÂ∞è‰∏çÂèòÊÄßÊñπÈù¢‰ªçÁÑ∂‰ºöÂ≠òÂú®ÂàáÂÆûÁöÑÈôêÂà∂„ÄÇ‰æãÂ¶ÇÔºåÂØπ‰∫é‰ªÖ‰ª• 20 ÂÉèÁ¥†ÂëàÁé∞ÁöÑÁå´ÂõæÂÉèÔºåÁÆóÊ≥ïÔºàÊàñ‰∫∫Ôºâ‰∏çÂèØËÉΩÊ≠£Á°ÆÂØπÂÖ∂ËøõË°åÂàÜÁ±ª„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÂπ≥Áßª‰∏çÂèòÊÄßÂíåÊóãËΩ¨‰∏çÂèòÊÄß„ÄÇ softmax ‰∏ÄÁßçÂáΩÊï∞ÔºåÂèØÊèê‰æõÂ§öÁ±ªÂà´ÂàÜÁ±ªÊ®°Âûã‰∏≠ÊØè‰∏™ÂèØËÉΩÁ±ªÂà´ÁöÑÊ¶ÇÁéá„ÄÇËøô‰∫õÊ¶ÇÁéáÁöÑÊÄªÂíåÊ≠£Â•Ω‰∏∫ 1.0„ÄÇ‰æãÂ¶ÇÔºåsoftmax ÂèØËÉΩ‰ºöÂæóÂá∫Êüê‰∏™ÂõæÂÉèÊòØÁãó„ÄÅÁå´ÂíåÈ©¨ÁöÑÊ¶ÇÁéáÂàÜÂà´ÊòØ 0.9„ÄÅ0.08 Âíå 0.02„ÄÇÔºà‰πüÁß∞‰∏∫ÂÆåÊï¥ softmax„ÄÇÔºâ ‰∏éÂÄôÈÄâÈááÊ†∑Áõ∏ÂØπ„ÄÇ Á®ÄÁñèÁâπÂæÅ (sparse feature) ‰∏ÄÁßçÁâπÂæÅÂêëÈáèÔºåÂÖ∂‰∏≠ÁöÑÂ§ßÂ§öÊï∞ÂÄºÈÉΩ‰∏∫ 0 Êàñ‰∏∫Á©∫„ÄÇ‰æãÂ¶ÇÔºåÊüê‰∏™ÂêëÈáèÂåÖÂê´‰∏Ä‰∏™‰∏∫ 1 ÁöÑÂÄºÂíå‰∏ÄÁôæ‰∏á‰∏™‰∏∫ 0 ÁöÑÂÄºÔºåÂàôËØ•ÂêëÈáèÂ∞±Â±û‰∫éÁ®ÄÁñèÂêëÈáè„ÄÇÂÜç‰∏æ‰∏Ä‰∏™‰æãÂ≠êÔºåÊêúÁ¥¢Êü•ËØ¢‰∏≠ÁöÑÂçïËØç‰πüÂèØËÉΩÂ±û‰∫éÁ®ÄÁñèÁâπÂæÅ - Âú®ÊüêÁßçÊåáÂÆöËØ≠Ë®Ä‰∏≠ÊúâÂæàÂ§öÂèØËÉΩÁöÑÂçïËØçÔºå‰ΩÜÂú®Êüê‰∏™ÊåáÂÆöÁöÑÊü•ËØ¢‰∏≠‰ªÖÂåÖÂê´ÂÖ∂‰∏≠Âá†‰∏™„ÄÇ ‰∏éÂØÜÈõÜÁâπÂæÅÁõ∏ÂØπ„ÄÇ Á®ÄÁñèË°®Á§∫Ê≥ï (sparse representation) ‰∏ÄÁßçÂº†ÈáèË°®Á§∫Ê≥ïÔºå‰ªÖÂ≠òÂÇ®ÈùûÈõ∂ÂÖÉÁ¥†„ÄÇ ‰æãÂ¶ÇÔºåËã±ËØ≠‰∏≠ÂåÖÂê´Á∫¶‰∏ÄÁôæ‰∏á‰∏™ÂçïËØç„ÄÇË°®Á§∫‰∏Ä‰∏™Ëã±ËØ≠Âè•Â≠ê‰∏≠ÊâÄÁî®ÂçïËØçÁöÑÊï∞ÈáèÔºåËÄÉËôë‰ª•‰∏ã‰∏§ÁßçÊñπÂºèÔºö Ë¶ÅÈááÁî®ÂØÜÈõÜË°®Á§∫Ê≥ïÊù•Ë°®Á§∫Ê≠§Âè•Â≠êÔºåÂàôÂøÖÈ°ª‰∏∫ÊâÄÊúâ‰∏ÄÁôæ‰∏á‰∏™ÂçïÂÖÉÊ†ºËÆæÁΩÆ‰∏Ä‰∏™Êï¥Êï∞ÔºåÁÑ∂ÂêéÂú®Â§ßÈÉ®ÂàÜÂçïÂÖÉÊ†º‰∏≠ÊîæÂÖ• 0ÔºåÂú®Â∞ëÊï∞ÂçïÂÖÉÊ†º‰∏≠ÊîæÂÖ•‰∏Ä‰∏™ÈùûÂ∏∏Â∞èÁöÑÊï¥Êï∞„ÄÇ Ë¶ÅÈááÁî®Á®ÄÁñèË°®Á§∫Ê≥ïÊù•Ë°®Á§∫Ê≠§Âè•Â≠êÔºåÂàô‰ªÖÂ≠òÂÇ®Ë±°ÂæÅÂè•Â≠ê‰∏≠ÂÆûÈôÖÂ≠òÂú®ÁöÑÂçïËØçÁöÑÂçïÂÖÉÊ†º„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÂè•Â≠êÂè™ÂåÖÂê´ 20 ‰∏™Áã¨‰∏ÄÊó†‰∫åÁöÑÂçïËØçÔºåÈÇ£‰πàËØ•Âè•Â≠êÁöÑÁ®ÄÁñèË°®Á§∫Ê≥ïÂ∞Ü‰ªÖÂú® 20 ‰∏™ÂçïÂÖÉÊ†º‰∏≠Â≠òÂÇ®‰∏Ä‰∏™Êï¥Êï∞„ÄÇ ‰æãÂ¶ÇÔºåÂÅáËÆæ‰ª•‰∏§ÁßçÊñπÂºèÊù•Ë°®Á§∫Âè•Â≠ê‚ÄúDogs wag tails.‚Äù„ÄÇÂ¶Ç‰∏ãË°®ÊâÄÁ§∫ÔºåÂØÜÈõÜË°®Á§∫Ê≥ïÂ∞Ü‰ΩøÁî®Á∫¶‰∏ÄÁôæ‰∏á‰∏™ÂçïÂÖÉÊ†ºÔºõÁ®ÄÁñèË°®Á§∫Ê≥ïÂàôÂè™‰ΩøÁî® 3 ‰∏™ÂçïÂÖÉÊ†ºÔºö ÂØÜÈõÜË°®Á§∫Ê≥ï ÂçïÂÖÉÊ†ºÁºñÂè∑ ÂçïËØç Âá∫Áé∞Ê¨°Êï∞ 0 a 0 1 aardvark 0 2 aargh 0 3 aarti 0 ‚Ä¶ Âá∫Áé∞Ê¨°Êï∞‰∏∫ 0 ÁöÑÂè¶Â§ñ 140391 ‰∏™ÂçïËØç 140395 dogs 1 ‚Ä¶ Âá∫Áé∞Ê¨°Êï∞‰∏∫ 0 ÁöÑ 633062 ‰∏™ÂçïËØç 773458 tails 1 ‚Ä¶ Âá∫Áé∞Ê¨°Êï∞‰∏∫ 0 ÁöÑ 189136 ‰∏™ÂçïËØç 962594 wag 1 ‚Ä¶ Âá∫Áé∞Ê¨°Êï∞‰∏∫ 0 ÁöÑÂæàÂ§öÂÖ∂‰ªñÂçïËØç Á®ÄÁñèË°®Á§∫Ê≥ï ÂçïÂÖÉÊ†ºÁºñÂè∑ ÂçïËØç Âá∫Áé∞Ê¨°Êï∞ 140395 dogs 1 773458 tails 1 962594 wag 1 Á®ÄÁñèÊÄß (sparsity) ÂêëÈáèÊàñÁü©Èòµ‰∏≠ËÆæÁΩÆ‰∏∫ 0ÔºàÊàñÁ©∫ÔºâÁöÑÂÖÉÁ¥†Êï∞Èô§‰ª•ËØ•ÂêëÈáèÊàñÁü©Èòµ‰∏≠ÁöÑÊù°ÁõÆÊÄªÊï∞„ÄÇ‰ª•‰∏Ä‰∏™ 10x10 Áü©ÈòµÔºàÂÖ∂‰∏≠ 98 ‰∏™ÂçïÂÖÉÊ†ºÈÉΩÂåÖÂê´ 0Ôºâ‰∏∫‰æã„ÄÇÁ®ÄÁñèÊÄßÁöÑËÆ°ÁÆóÊñπÊ≥ïÂ¶Ç‰∏ãÔºö $${\text{Á®ÄÁñèÊÄß}} = \frac{\text{98}} {\text{100}} = {\text{0.98}}$$ ÁâπÂæÅÁ®ÄÁñèÊÄßÊòØÊåáÁâπÂæÅÂêëÈáèÁöÑÁ®ÄÁñèÊÄßÔºõÊ®°ÂûãÁ®ÄÁñèÊÄßÊòØÊåáÊ®°ÂûãÊùÉÈáçÁöÑÁ®ÄÁñèÊÄß„ÄÇ Á©∫Èó¥Ê±†Âåñ (spatial pooling) ËØ∑ÂèÇÈòÖÊ±†Âåñ„ÄÇ Âπ≥ÊñπÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ (squared hinge loss) ÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ÁöÑÂπ≥Êñπ„ÄÇ‰∏éÂ∏∏ËßÑÂêàÈ°µÊçüÂ§±ÂáΩÊï∞Áõ∏ÊØîÔºåÂπ≥ÊñπÂêàÈ°µÊçüÂ§±ÂáΩÊï∞ÂØπÁ¶ªÁæ§ÂÄºÁöÑÊÉ©ÁΩöÊõ¥‰∏•Âéâ„ÄÇ Âπ≥ÊñπÊçüÂ§±ÂáΩÊï∞ (squared loss) Âú®Á∫øÊÄßÂõûÂΩí‰∏≠‰ΩøÁî®ÁöÑÊçüÂ§±ÂáΩÊï∞Ôºà‰πüÁß∞‰∏∫ L2 ÊçüÂ§±ÂáΩÊï∞Ôºâ„ÄÇËØ•ÂáΩÊï∞ÂèØËÆ°ÁÆóÊ®°Âûã‰∏∫ÊúâÊ†áÁ≠æÊ†∑Êú¨È¢ÑÊµãÁöÑÂÄºÂíåÊ†áÁ≠æÁöÑÂÆûÈôÖÂÄº‰πãÂ∑ÆÁöÑÂπ≥Êñπ„ÄÇÁî±‰∫éÂèñÂπ≥ÊñπÂÄºÔºåÂõ†Ê≠§ËØ•ÊçüÂ§±ÂáΩÊï∞‰ºöÊîæÂ§ß‰∏ç‰Ω≥È¢ÑÊµãÁöÑÂΩ±Âìç„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰∏é L1 ÊçüÂ§±ÂáΩÊï∞Áõ∏ÊØîÔºåÂπ≥ÊñπÊçüÂ§±ÂáΩÊï∞ÂØπÁ¶ªÁæ§ÂÄºÁöÑÂèçÂ∫îÊõ¥Âº∫ÁÉà„ÄÇ ÈùôÊÄÅÊ®°Âûã (static model) Á¶ªÁ∫øËÆ≠ÁªÉÁöÑ‰∏ÄÁßçÊ®°Âûã„ÄÇ Âπ≥Á®≥ÊÄß (stationarity) Êï∞ÊçÆÈõÜ‰∏≠Êï∞ÊçÆÁöÑ‰∏ÄÁßçÂ±ûÊÄßÔºåË°®Á§∫Êï∞ÊçÆÂàÜÂ∏ÉÂú®‰∏Ä‰∏™ÊàñÂ§ö‰∏™Áª¥Â∫¶‰øùÊåÅ‰∏çÂèò„ÄÇËøôÁßçÁª¥Â∫¶ÊúÄÂ∏∏ËßÅÁöÑÊòØÊó∂Èó¥ÔºåÂç≥Ë°®ÊòéÂπ≥Á®≥ÊÄßÁöÑÊï∞ÊçÆ‰∏çÈöèÊó∂Èó¥ËÄåÂèòÂåñ„ÄÇ‰æãÂ¶ÇÔºå‰ªé 9 ÊúàÂà∞ 12 ÊúàÔºåË°®ÊòéÂπ≥Á®≥ÊÄßÁöÑÊï∞ÊçÆÊ≤°ÊúâÂèëÁîüÂèòÂåñ„ÄÇ Ê≠• (step) ÂØπ‰∏Ä‰∏™ÊâπÊ¨°ÁöÑÂêëÂâçÂíåÂêëÂêéËØÑ‰º∞„ÄÇ Ê≠•Èïø (step size) ‰∏éÂ≠¶‰π†ÈÄüÁéáÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï (SGD, stochastic gradient descent) ÊâπÊ¨°Â§ßÂ∞è‰∏∫ 1 ÁöÑ‰∏ÄÁßçÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ï„ÄÇÊç¢Âè•ËØùËØ¥ÔºåSGD ‰æùËµñ‰∫é‰ªéÊï∞ÊçÆÈõÜ‰∏≠ÈöèÊú∫ÂùáÂåÄÈÄâÊã©ÁöÑÂçï‰∏™Ê†∑Êú¨Êù•ËÆ°ÁÆóÊØèÊ≠•ÁöÑÊ¢ØÂ∫¶‰º∞ÁÆóÂÄº„ÄÇ ÁªìÊûÑÈ£éÈô©ÊúÄÂ∞èÂåñ (SRM, structural risk minimization) ‰∏ÄÁßçÁÆóÊ≥ïÔºåÁî®‰∫éÂπ≥Ë°°‰ª•‰∏ã‰∏§‰∏™ÁõÆÊ†áÔºö ÊúüÊúõÊûÑÂª∫ÊúÄÂÖ∑È¢ÑÊµãÊÄßÁöÑÊ®°ÂûãÔºà‰æãÂ¶ÇÊçüÂ§±ÊúÄ‰ΩéÔºâ„ÄÇ ÊúüÊúõ‰ΩøÊ®°ÂûãÂ∞ΩÂèØËÉΩÁÆÄÂçïÔºà‰æãÂ¶ÇÂº∫Â§ßÁöÑÊ≠£ÂàôÂåñÔºâ„ÄÇ ‰æãÂ¶ÇÔºåÊó®Âú®Â∞ÜÂü∫‰∫éËÆ≠ÁªÉÈõÜÁöÑÊçüÂ§±ÂíåÊ≠£ÂàôÂåñÈôçËá≥ÊúÄ‰ΩéÁöÑÂáΩÊï∞Â∞±ÊòØ‰∏ÄÁßçÁªìÊûÑÈ£éÈô©ÊúÄÂ∞èÂåñÁÆóÊ≥ï„ÄÇ Â¶ÇÈúÄÊõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖ http://www.svms.org/srm/„ÄÇ ‰∏éÁªèÈ™åÈ£éÈô©ÊúÄÂ∞èÂåñÁõ∏ÂØπ„ÄÇ Ê≠•Èïø (stride) Âú®Âç∑ÁßØËøêÁÆóÊàñÊ±†Âåñ‰∏≠Ôºå‰∏ã‰∏Ä‰∏™Á≥ªÂàóÁöÑËæìÂÖ•ÂàáÁâáÁöÑÊØè‰∏™Áª¥Â∫¶‰∏≠ÁöÑÂ¢ûÈáè„ÄÇ‰æãÂ¶ÇÔºå‰∏ãÈù¢ÁöÑÂä®ÁîªÊºîÁ§∫‰∫ÜÂç∑ÁßØËøêÁÆóËøáÁ®ã‰∏≠ÁöÑ‰∏Ä‰∏™ (1,1) Ê≠•Èïø„ÄÇÂõ†Ê≠§Ôºå‰∏ã‰∏Ä‰∏™ËæìÂÖ•ÂàáÁâáÊòØ‰ªé‰∏ä‰∏Ä‰∏™ËæìÂÖ•ÂàáÁâáÂêëÂè≥ÁßªÂä®‰∏Ä‰∏™Ê≠•ÈïøÁöÑ‰ΩçÁΩÆÂºÄÂßã„ÄÇÂΩìËøêÁÆóÂà∞ËææÂè≥‰æßËæπÁºòÊó∂Ôºå‰∏ã‰∏Ä‰∏™ÂàáÁâáÂ∞ÜÂõûÂà∞ÊúÄÂ∑¶ËæπÔºå‰ΩÜÊòØ‰∏ãÁßª‰∏Ä‰∏™‰ΩçÁΩÆ„ÄÇ ÂâçÈù¢ÁöÑÁ§∫‰æãÊºîÁ§∫‰∫Ü‰∏Ä‰∏™‰∫åÁª¥Ê≠•Èïø„ÄÇÂ¶ÇÊûúËæìÂÖ•Áü©Èòµ‰∏∫‰∏âÁª¥ÔºåÈÇ£‰πàÊ≠•Èïø‰πüÂ∞ÜÊòØ‰∏âÁª¥„ÄÇ ‰∏ãÈááÊ†∑ (subsampling) ËØ∑ÂèÇÈòÖÊ±†Âåñ„ÄÇ ÊÄªÁªì (summary) Âú® TensorFlow ‰∏≠ÁöÑÊüê‰∏ÄÊ≠•ËÆ°ÁÆóÂá∫ÁöÑ‰∏Ä‰∏™ÂÄºÊàñ‰∏ÄÁªÑÂÄºÔºåÈÄöÂ∏∏Áî®‰∫éÂú®ËÆ≠ÁªÉÊúüÈó¥Ë∑üË∏™Ê®°ÂûãÊåáÊ†á„ÄÇ ÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π† (supervised machine learning) Ê†πÊçÆËæìÂÖ•Êï∞ÊçÆÂèäÂÖ∂ÂØπÂ∫îÁöÑÊ†áÁ≠æÊù•ËÆ≠ÁªÉÊ®°Âûã„ÄÇÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†Á±ª‰ºº‰∫éÂ≠¶ÁîüÈÄöËøáÁ†îÁ©∂‰∏ÄÁ≥ªÂàóÈóÆÈ¢òÂèäÂÖ∂ÂØπÂ∫îÁöÑÁ≠îÊ°àÊù•Â≠¶‰π†Êüê‰∏™‰∏ªÈ¢ò„ÄÇÂú®ÊéåÊè°‰∫ÜÈóÆÈ¢òÂíåÁ≠îÊ°à‰πãÈó¥ÁöÑÂØπÂ∫îÂÖ≥Á≥ªÂêéÔºåÂ≠¶Áîü‰æøÂèØ‰ª•ÂõûÁ≠îÂÖ≥‰∫éÂêå‰∏Ä‰∏ªÈ¢òÁöÑÊñ∞ÈóÆÈ¢òÔºà‰ª•Ââç‰ªéÊú™ËßÅËøáÁöÑÈóÆÈ¢òÔºâ„ÄÇËØ∑‰∏éÈùûÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†ËøõË°åÊØîËæÉ„ÄÇ ÂêàÊàêÁâπÂæÅ (synthetic feature) ‰∏ÄÁßçÁâπÂæÅÔºå‰∏çÂú®ËæìÂÖ•ÁâπÂæÅ‰πãÂàóÔºåËÄåÊòØ‰ªé‰∏Ä‰∏™ÊàñÂ§ö‰∏™ËæìÂÖ•ÁâπÂæÅË°çÁîüËÄåÊù•„ÄÇÂêàÊàêÁâπÂæÅÂåÖÊã¨‰ª•‰∏ãÁ±ªÂûãÔºö ÂØπËøûÁª≠ÁâπÂæÅËøõË°åÂàÜÊ°∂Ôºå‰ª•ÂàÜ‰∏∫Â§ö‰∏™Âå∫Èó¥ÂàÜÁÆ±„ÄÇ Â∞Ü‰∏Ä‰∏™ÁâπÂæÅÂÄº‰∏éÂÖ∂‰ªñÁâπÂæÅÂÄºÊàñÂÖ∂Êú¨Ë∫´Áõ∏‰πòÔºàÊàñÁõ∏Èô§Ôºâ„ÄÇ ÂàõÂª∫‰∏Ä‰∏™ÁâπÂæÅÁªÑÂêà„ÄÇ ‰ªÖÈÄöËøáÊ†áÂáÜÂåñÊàñÁº©ÊîæÂàõÂª∫ÁöÑÁâπÂæÅ‰∏çÂ±û‰∫éÂêàÊàêÁâπÂæÅ„ÄÇ T ÁõÆÊ†á (target) ‰∏éÊ†áÁ≠æÁöÑÂê´‰πâÁõ∏Âêå„ÄÇ Êó∂ÊÄÅÊï∞ÊçÆ (temporal data) Âú®‰∏çÂêåÊó∂Èó¥ÁÇπËÆ∞ÂΩïÁöÑÊï∞ÊçÆ„ÄÇ‰æãÂ¶ÇÔºåËÆ∞ÂΩïÁöÑ‰∏ÄÂπ¥‰∏≠ÊØè‰∏ÄÂ§©ÁöÑÂÜ¨Â§ñÂ•óÈîÄÈáèÂ∞±Â±û‰∫éÊó∂ÊÄÅÊï∞ÊçÆ„ÄÇ Âº†Èáè (Tensor) TensorFlow Á®ãÂ∫è‰∏≠ÁöÑ‰∏ªË¶ÅÊï∞ÊçÆÁªìÊûÑ„ÄÇÂº†ÈáèÊòØ N Áª¥ÔºàÂÖ∂‰∏≠ N ÂèØËÉΩÈùûÂ∏∏Â§ßÔºâÊï∞ÊçÆÁªìÊûÑÔºåÊúÄÂ∏∏ËßÅÁöÑÊòØÊ†áÈáè„ÄÅÂêëÈáèÊàñÁü©Èòµ„ÄÇÂº†ÈáèÁöÑÂÖÉÁ¥†ÂèØ‰ª•ÂåÖÂê´Êï¥Êï∞ÂÄº„ÄÅÊµÆÁÇπÂÄºÊàñÂ≠óÁ¨¶‰∏≤ÂÄº„ÄÇ Âº†ÈáèÂ§ÑÁêÜÂçïÂÖÉ (TPU, Tensor Processing Unit) ‰∏ÄÁßç ASICÔºàÂ∫îÁî®‰∏ìÁî®ÈõÜÊàêÁîµË∑ØÔºâÔºåÁî®‰∫é‰ºòÂåñ TensorFlow Á®ãÂ∫èÁöÑÊÄßËÉΩ„ÄÇ Âº†ÈáèÁ≠âÁ∫ß (Tensor rank) ËØ∑ÂèÇÈòÖÁ≠âÁ∫ß„ÄÇ Âº†ÈáèÂΩ¢Áä∂ (Tensor shape) Âº†ÈáèÂú®ÂêÑÁßçÁª¥Â∫¶‰∏≠ÂåÖÂê´ÁöÑÂÖÉÁ¥†Êï∞„ÄÇ‰æãÂ¶ÇÔºåÂº†Èáè [5, 10] Âú®‰∏Ä‰∏™Áª¥Â∫¶‰∏≠ÁöÑÂΩ¢Áä∂‰∏∫ 5ÔºåÂú®Âè¶‰∏Ä‰∏™Áª¥Â∫¶‰∏≠ÁöÑÂΩ¢Áä∂‰∏∫ 10„ÄÇ Âº†ÈáèÂ§ßÂ∞è (Tensor size) Âº†ÈáèÂåÖÂê´ÁöÑÊ†áÈáèÊÄªÊï∞„ÄÇ‰æãÂ¶ÇÔºåÂº†Èáè [5, 10] ÁöÑÂ§ßÂ∞è‰∏∫ 50„ÄÇ TensorBoard ‰∏Ä‰∏™‰ø°ÊÅØ‰∏≠ÂøÉÔºåÁî®‰∫éÊòæÁ§∫Âú®ÊâßË°å‰∏Ä‰∏™ÊàñÂ§ö‰∏™ TensorFlow Á®ãÂ∫èÊúüÈó¥‰øùÂ≠òÁöÑÊëòË¶Å‰ø°ÊÅØ„ÄÇ TensorFlow ‰∏Ä‰∏™Â§ßÂûãÁöÑÂàÜÂ∏ÉÂºèÊú∫Âô®Â≠¶‰π†Âπ≥Âè∞„ÄÇËØ•ÊúØËØ≠ËøòÊåá TensorFlow Â†ÜÊ†à‰∏≠ÁöÑÂü∫Êú¨ API Â±ÇÔºåËØ•Â±ÇÊîØÊåÅÂØπÊï∞ÊçÆÊµÅÂõæËøõË°å‰∏ÄËà¨ËÆ°ÁÆó„ÄÇ ËôΩÁÑ∂ TensorFlow ‰∏ªË¶ÅÂ∫îÁî®‰∫éÊú∫Âô®Â≠¶‰π†È¢ÜÂüüÔºå‰ΩÜ‰πüÂèØÁî®‰∫éÈúÄË¶Å‰ΩøÁî®Êï∞ÊçÆÊµÅÂõæËøõË°åÊï∞ÂÄºËÆ°ÁÆóÁöÑÈùûÊú∫Âô®Â≠¶‰π†‰ªªÂä°„ÄÇ TensorFlow Playground ‰∏ÄÊ¨æÁî®‰∫éÁõ¥ËßÇÂëàÁé∞‰∏çÂêåÁöÑË∂ÖÂèÇÊï∞ÂØπÊ®°ÂûãÔºà‰∏ªË¶ÅÊòØÁ•ûÁªèÁΩëÁªúÔºâËÆ≠ÁªÉÁöÑÂΩ±ÂìçÁöÑÁ®ãÂ∫è„ÄÇË¶ÅËØïÁî® TensorFlow PlaygroundÔºåËØ∑ÂâçÂæÄ http://playground.tensorflow.org„ÄÇ TensorFlow Serving ‰∏Ä‰∏™Âπ≥Âè∞ÔºåÁî®‰∫éÂ∞ÜËÆ≠ÁªÉËøáÁöÑÊ®°ÂûãÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢É„ÄÇ ÊµãËØïÈõÜ (test set) Êï∞ÊçÆÈõÜÁöÑÂ≠êÈõÜÔºåÁî®‰∫éÂú®Ê®°ÂûãÁªèÁî±È™åËØÅÈõÜÁöÑÂàùÊ≠•È™åËØÅ‰πãÂêéÊµãËØïÊ®°Âûã„ÄÇ ‰∏éËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÁõ∏ÂØπ„ÄÇ tf.Example ‰∏ÄÁßçÊ†áÂáÜÂçèËÆÆÁºìÂÜ≤Âå∫ÔºåÊó®Âú®ÊèèËø∞Áî®‰∫éÊú∫Âô®Â≠¶‰π†Ê®°ÂûãËÆ≠ÁªÉÊàñÊé®Êñ≠ÁöÑËæìÂÖ•Êï∞ÊçÆ„ÄÇ Êó∂Èó¥Â∫èÂàóÂàÜÊûê (time series analysis) Êú∫Âô®Â≠¶‰π†ÂíåÁªüËÆ°Â≠¶ÁöÑ‰∏Ä‰∏™Â≠êÈ¢ÜÂüüÔºåÊó®Âú®ÂàÜÊûêÊó∂ÊÄÅÊï∞ÊçÆ„ÄÇÂæàÂ§öÁ±ªÂûãÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÈÉΩÈúÄË¶ÅÊó∂Èó¥Â∫èÂàóÂàÜÊûêÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÂàÜÁ±ª„ÄÅËÅöÁ±ª„ÄÅÈ¢ÑÊµãÂíåÂºÇÂ∏∏Ê£ÄÊµã„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•Âà©Áî®Êó∂Èó¥Â∫èÂàóÂàÜÊûêÊ†πÊçÆÂéÜÂè≤ÈîÄÈáèÊï∞ÊçÆÈ¢ÑÊµãÊú™Êù•ÊØèÊúàÁöÑÂÜ¨Â§ñÂ•óÈîÄÈáè„ÄÇ ËÆ≠ÁªÉ (training) Á°ÆÂÆöÊûÑÊàêÊ®°ÂûãÁöÑÁêÜÊÉ≥ÂèÇÊï∞ÁöÑËøáÁ®ã„ÄÇ ËÆ≠ÁªÉÈõÜ (training set) Êï∞ÊçÆÈõÜÁöÑÂ≠êÈõÜÔºåÁî®‰∫éËÆ≠ÁªÉÊ®°Âûã„ÄÇ ‰∏éÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜÁõ∏ÂØπ„ÄÇ ËøÅÁßªÂ≠¶‰π† (transfer learning) Â∞Ü‰ø°ÊÅØ‰ªé‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†‰ªªÂä°ËøÅÁßªÂà∞Âè¶‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†‰ªªÂä°„ÄÇ‰æãÂ¶ÇÔºåÂú®Â§ö‰ªªÂä°Â≠¶‰π†‰∏≠Ôºå‰∏Ä‰∏™Ê®°ÂûãÂèØ‰ª•ÂÆåÊàêÂ§öÈ°π‰ªªÂä°Ôºå‰æãÂ¶ÇÈíàÂØπ‰∏çÂêå‰ªªÂä°ÂÖ∑Êúâ‰∏çÂêåËæìÂá∫ËäÇÁÇπÁöÑÊ∑±Â∫¶Ê®°Âûã„ÄÇËøÅÁßªÂ≠¶‰π†ÂèØËÉΩÊ∂âÂèäÂ∞ÜÁü•ËØÜ‰ªéËæÉÁÆÄÂçï‰ªªÂä°ÁöÑËß£ÂÜ≥ÊñπÊ°àËøÅÁßªÂà∞ËæÉÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÊàñËÄÖÂ∞ÜÁü•ËØÜ‰ªéÊï∞ÊçÆËæÉÂ§öÁöÑ‰ªªÂä°ËøÅÁßªÂà∞Êï∞ÊçÆËæÉÂ∞ëÁöÑ‰ªªÂä°„ÄÇ Â§ßÂ§öÊï∞Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÈÉΩÂè™ËÉΩÂÆåÊàê‰∏ÄÈ°π‰ªªÂä°„ÄÇËøÅÁßªÂ≠¶‰π†ÊòØËøàÂêë‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∏ÄÂ∞èÊ≠•ÔºõÂú®‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÔºåÂçï‰∏™Á®ãÂ∫èÂèØ‰ª•ÂÆåÊàêÂ§öÈ°π‰ªªÂä°„ÄÇ Âπ≥Áßª‰∏çÂèòÊÄß (translational invariance) Âú®ÂõæÂÉèÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÔºåÂç≥‰ΩøÂõæÂÉè‰∏≠ÂØπË±°ÁöÑ‰ΩçÁΩÆÂèëÁîüÂèòÂåñÔºåÁÆóÊ≥ï‰πüËÉΩÊàêÂäüÂØπÂõæÂÉèËøõË°åÂàÜÁ±ª„ÄÇ‰æãÂ¶ÇÔºåÊó†ËÆ∫‰∏ÄÂè™Áãó‰Ωç‰∫éÁîªÈù¢Ê≠£‰∏≠Â§ÆËøòÊòØÁîªÈù¢Â∑¶‰æßÔºåËØ•ÁÆóÊ≥ï‰ªçÁÑ∂ÂèØ‰ª•ËØÜÂà´ÂÆÉ„ÄÇ Âè¶ËØ∑ÂèÇÈòÖÂ§ßÂ∞è‰∏çÂèòÊÄßÂíåÊóãËΩ¨‰∏çÂèòÊÄß„ÄÇ Ë¥ü‰æã (TN, true negative) Ë¢´Ê®°ÂûãÊ≠£Á°ÆÂú∞È¢ÑÊµã‰∏∫Ë¥üÁ±ªÂà´ÁöÑÊ†∑Êú¨„ÄÇ‰æãÂ¶ÇÔºåÊ®°ÂûãÊé®Êñ≠Âá∫ÊüêÂ∞ÅÁîµÂ≠êÈÇÆ‰ª∂‰∏çÊòØÂûÉÂúæÈÇÆ‰ª∂ÔºåËÄåËØ•ÁîµÂ≠êÈÇÆ‰ª∂Á°ÆÂÆû‰∏çÊòØÂûÉÂúæÈÇÆ‰ª∂„ÄÇ Ê≠£‰æã (TP, true positive) Ë¢´Ê®°ÂûãÊ≠£Á°ÆÂú∞È¢ÑÊµã‰∏∫Ê≠£Á±ªÂà´ÁöÑÊ†∑Êú¨„ÄÇ‰æãÂ¶ÇÔºåÊ®°ÂûãÊé®Êñ≠Âá∫ÊüêÂ∞ÅÁîµÂ≠êÈÇÆ‰ª∂ÊòØÂûÉÂúæÈÇÆ‰ª∂ÔºåËÄåËØ•ÁîµÂ≠êÈÇÆ‰ª∂Á°ÆÂÆûÊòØÂûÉÂúæÈÇÆ‰ª∂„ÄÇ Ê≠£‰æãÁéáÔºàtrue positive rate, ÁÆÄÁß∞ TP ÁéáÔºâ ‰∏éÂè¨ÂõûÁéáÁöÑÂê´‰πâÁõ∏ÂêåÔºåÂç≥Ôºö $$\text{Ê≠£‰æãÁéá} = \frac{\text{Ê≠£‰æãÊï∞}} {\text{Ê≠£‰æãÊï∞} + \text{ÂÅáË¥ü‰æãÊï∞}}$$ Ê≠£‰æãÁéáÊòØ ROC Êõ≤Á∫øÁöÑ y ËΩ¥„ÄÇ U Êó†Ê†áÁ≠æÊ†∑Êú¨ (unlabeled example) ÂåÖÂê´ÁâπÂæÅ‰ΩÜÊ≤°ÊúâÊ†áÁ≠æÁöÑÊ†∑Êú¨„ÄÇÊó†Ê†áÁ≠æÊ†∑Êú¨ÊòØÁî®‰∫éËøõË°åÊé®Êñ≠ÁöÑËæìÂÖ•ÂÜÖÂÆπ„ÄÇÂú®ÂçäÁõëÁù£ÂºèÂíåÈùûÁõëÁù£ÂºèÂ≠¶‰π†‰∏≠ÔºåÂú®ËÆ≠ÁªÉÊúüÈó¥‰ºö‰ΩøÁî®Êó†Ê†áÁ≠æÊ†∑Êú¨„ÄÇ ÈùûÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π† (unsupervised machine learning) ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ª•ÊâæÂá∫Êï∞ÊçÆÈõÜÔºàÈÄöÂ∏∏ÊòØÊó†Ê†áÁ≠æÊï∞ÊçÆÈõÜÔºâ‰∏≠ÁöÑËßÑÂæã„ÄÇ ÈùûÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†ÊúÄÂ∏∏ËßÅÁöÑÁî®ÈÄîÊòØÂ∞ÜÊï∞ÊçÆÂàÜ‰∏∫‰∏çÂêåÁöÑËÅöÁ±ªÔºå‰ΩøÁõ∏‰ººÁöÑÊ†∑Êú¨‰Ωç‰∫éÂêå‰∏ÄÁªÑ‰∏≠„ÄÇ‰æãÂ¶ÇÔºåÈùûÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂèØ‰ª•Ê†πÊçÆÈü≥‰πêÁöÑÂêÑÁßçÂ±ûÊÄßÂ∞ÜÊ≠åÊõ≤ÂàÜ‰∏∫‰∏çÂêåÁöÑËÅöÁ±ª„ÄÇÊâÄÂæóËÅöÁ±ªÂèØ‰ª•‰Ωú‰∏∫ÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºà‰æãÂ¶ÇÈü≥‰πêÊé®ËçêÊúçÂä°ÔºâÁöÑËæìÂÖ•„ÄÇÂú®ÂæàÈöæËé∑ÂèñÁúüÊ†áÁ≠æÁöÑÈ¢ÜÂüüÔºåËÅöÁ±ªÂèØËÉΩ‰ºöÈùûÂ∏∏ÊúâÁî®„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂèçÊª•Áî®ÂíåÂèçÊ¨∫ËØàÁ≠âÈ¢ÜÂüüÔºåËÅöÁ±ªÊúâÂä©‰∫é‰∫∫‰ª¨Êõ¥Â•ΩÂú∞‰∫ÜËß£Áõ∏ÂÖ≥Êï∞ÊçÆ„ÄÇ ÈùûÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†ÁöÑÂè¶‰∏Ä‰∏™‰æãÂ≠êÊòØ‰∏ªÊàêÂàÜÂàÜÊûê (PCA)„ÄÇ‰æãÂ¶ÇÔºåÈÄöËøáÂØπÂåÖÂê´Êï∞Áôæ‰∏áË¥≠Áâ©ËΩ¶‰∏≠Áâ©ÂìÅÁöÑÊï∞ÊçÆÈõÜËøõË°å‰∏ªÊàêÂàÜÂàÜÊûêÔºåÂèØËÉΩ‰ºöÂèëÁé∞ÊúâÊü†Ê™¨ÁöÑË¥≠Áâ©ËΩ¶‰∏≠ÂæÄÂæÄ‰πüÊúâÊäóÈÖ∏ËçØ„ÄÇ ËØ∑‰∏éÁõëÁù£ÂºèÊú∫Âô®Â≠¶‰π†ËøõË°åÊØîËæÉ„ÄÇ V È™åËØÅÈõÜ (validation set) Êï∞ÊçÆÈõÜÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºå‰ªéËÆ≠ÁªÉÈõÜÂàÜÁ¶ªËÄåÊù•ÔºåÁî®‰∫éË∞ÉÊï¥Ë∂ÖÂèÇÊï∞„ÄÇ ‰∏éËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÁõ∏ÂØπ„ÄÇ W ÊùÉÈáç (weight) Á∫øÊÄßÊ®°Âûã‰∏≠ÁâπÂæÅÁöÑÁ≥ªÊï∞ÔºåÊàñÊ∑±Â∫¶ÁΩëÁªú‰∏≠ÁöÑËæπ„ÄÇËÆ≠ÁªÉÁ∫øÊÄßÊ®°ÂûãÁöÑÁõÆÊ†áÊòØÁ°ÆÂÆöÊØè‰∏™ÁâπÂæÅÁöÑÁêÜÊÉ≥ÊùÉÈáç„ÄÇÂ¶ÇÊûúÊùÉÈáç‰∏∫ 0ÔºåÂàôÁõ∏Â∫îÁöÑÁâπÂæÅÂØπÊ®°ÂûãÊù•ËØ¥Ê≤°Êúâ‰ªª‰ΩïË¥°ÁåÆ„ÄÇ ÂÆΩÂ∫¶Ê®°Âûã (wide model) ‰∏ÄÁßçÁ∫øÊÄßÊ®°ÂûãÔºåÈÄöÂ∏∏ÊúâÂæàÂ§öÁ®ÄÁñèËæìÂÖ•ÁâπÂæÅ„ÄÇÊàë‰ª¨‰πãÊâÄ‰ª•Áß∞‰πã‰∏∫‚ÄúÂÆΩÂ∫¶Ê®°Âûã‚ÄùÔºåÊòØÂõ†‰∏∫ËøôÊòØ‰∏ÄÁßçÁâπÊÆäÁ±ªÂûãÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂÖ∂Â§ßÈáèËæìÂÖ•ÂùáÁõ¥Êé•‰∏éËæìÂá∫ËäÇÁÇπÁõ∏Ëøû„ÄÇ‰∏éÊ∑±Â∫¶Ê®°ÂûãÁõ∏ÊØîÔºåÂÆΩÂ∫¶Ê®°ÂûãÈÄöÂ∏∏Êõ¥Êòì‰∫éË∞ÉËØïÂíåÊ£ÄÊü•„ÄÇËôΩÁÑ∂ÂÆΩÂ∫¶Ê®°ÂûãÊó†Ê≥ïÈÄöËøáÈöêËóèÂ±ÇÊù•Ë°®Á§∫ÈùûÁ∫øÊÄßÂÖ≥Á≥ªÔºå‰ΩÜÂèØ‰ª•Âà©Áî®ÁâπÂæÅÁªÑÂêà„ÄÅÂàÜÊ°∂Á≠âËΩ¨Êç¢‰ª•‰∏çÂêåÁöÑÊñπÂºè‰∏∫ÈùûÁ∫øÊÄßÂÖ≥Á≥ªÂª∫Ê®°„ÄÇ ‰∏éÊ∑±Â∫¶Ê®°ÂûãÁõ∏ÂØπ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 7]]></title>
    <url>%2F2019%2F01%2F14%2FTensorFlow_7%2F</url>
    <content type="text"><![CDATA[Ê≠£ÂàôÂåñ (Regularization for Simplicity)Áï• Êü•ÂáÜÁéáÂíåÂè¨ÂõûÁéáÁï• ÈÄªËæëÂõûÂΩí ‰∏éÂú®‰πãÂâçÁöÑÁªÉ‰π†‰∏≠‰∏ÄÊ†∑ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®Âä†Âà©Á¶èÂ∞º‰∫öÂ∑û‰ΩèÊàøÊï∞ÊçÆÈõÜÔºå‰ΩÜËøôÊ¨°Êàë‰ª¨‰ºöÈ¢ÑÊµãÊüê‰∏™ÂüéÂ∏ÇË°óÂå∫ÁöÑ‰ΩèÊàøÊàêÊú¨ÊòØÂê¶È´òÊòÇÔºå‰ªéËÄåÂ∞ÜÂÖ∂ËΩ¨Êç¢Êàê‰∏Ä‰∏™‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ëøò‰ºöÊöÇÊó∂ÊÅ¢Â§ç‰ΩøÁî®ÈªòËÆ§ÁâπÂæÅ„ÄÇ ÊûÑÂª∫‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÊï∞ÊçÆÈõÜÁöÑÁõÆÊ†áÊòØ median_house_valueÔºåÂÆÉÊòØ‰∏Ä‰∏™Êï∞ÂÄºÔºàËøûÁª≠ÂÄºÔºâÁâπÂæÅ„ÄÇÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÂêëÊ≠§ËøûÁª≠ÂÄº‰ΩøÁî®ÈòàÂÄºÊù•ÂàõÂª∫‰∏Ä‰∏™Â∏ÉÂ∞îÂÄºÊ†áÁ≠æ„ÄÇ Êàë‰ª¨Â∏åÊúõÈÄöËøáÊüê‰∏™ÂüéÂ∏ÇË°óÂå∫ÁöÑÁâπÂæÅÈ¢ÑÊµãËØ•Ë°óÂå∫ÁöÑ‰ΩèÊàøÊàêÊú¨ÊòØÂê¶È´òÊòÇ„ÄÇ‰∏∫‰∫ÜÁªôËÆ≠ÁªÉÊï∞ÊçÆÂíåËØÑ‰º∞Êï∞ÊçÆÂáÜÂ§áÁõÆÊ†áÔºåÊàë‰ª¨ÈíàÂØπÊàøÂ±ã‰ª∑ÂÄº‰∏≠‰ΩçÊï∞ÂÆö‰πâ‰∫ÜÂàÜÁ±ªÈòàÂÄº - Á¨¨ 75 ÁôæÂàÜ‰ΩçÊï∞ÔºàÁ∫¶‰∏∫ 265000Ôºâ„ÄÇÊâÄÊúâÈ´ò‰∫éÊ≠§ÈòàÂÄºÁöÑÊàøÂ±ã‰ª∑ÂÄºÊ†áËÆ∞‰∏∫ 1ÔºåÂÖ∂‰ªñÂÄºÊ†áËÆ∞‰∏∫ 0„ÄÇ ËÆæÁΩÆ12345678910111213141516171819202122from __future__ import print_functionimport mathfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10pd.options.display.float_format = '&#123;:.1f&#125;'.formatcalifornia_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",")california_housing_dataframe = california_housing_dataframe.reindex( np.random.permutation(california_housing_dataframe.index)) Ê≥®ÊÑè‰ª•‰∏ã‰ª£Á†Å‰∏é‰πãÂâçÁªÉ‰π†‰∏≠ÁöÑ‰ª£Á†Å‰πãÈó¥Á®çÊúâ‰∏çÂêå„ÄÇÊàë‰ª¨Âπ∂Ê≤°ÊúâÂ∞Ü median_house_value Áî®‰ΩúÁõÆÊ†áÔºåËÄåÊòØÂàõÂª∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑ‰∫åÂÖÉÁõÆÊ†á median_house_value_is_high„ÄÇ 123456789101112131415161718192021def preprocess_features(california_housing_dataframe): selected_features = california_housing_dataframe[ ["latitude", "longitude", "housing_median_age", "total_rooms", "total_bedrooms", "population", "households", "median_income"]] processed_features = selected_features.copy() processed_features["rooms_per_person"] = ( california_housing_dataframe["total_rooms"] / california_housing_dataframe["population"]) return processed_featuresdef preprocess_targets(california_housing_dataframe): output_targets = pd.DataFrame() output_targets["median_house_value_is_high"] = ( california_housing_dataframe["median_house_value"] &gt; 265000).astype(float) return output_targets 123456789101112131415training_examples = preprocess_features(california_housing_dataframe.head(12000))training_targets = preprocess_targets(california_housing_dataframe.head(12000))validation_examples = preprocess_features(california_housing_dataframe.tail(5000))validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))print("Training examples summary:")display.display(training_examples.describe())print("Validation examples summary:")display.display(validation_examples.describe())print("Training targets summary:")display.display(training_targets.describe())print("Validation targets summary:")display.display(validation_targets.describe()) Training examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 mean 35.6 -119.6 28.6 2630.6 537.6 1426.3 499.6 3.9 2.0 std 2.1 2.0 12.6 2156.5 415.3 1158.6 379.3 1.9 1.2 min 32.5 -124.3 1.0 2.0 1.0 6.0 1.0 0.5 0.0 25% 33.9 -121.8 18.0 1460.8 297.0 790.0 282.0 2.6 1.5 50% 34.2 -118.5 29.0 2113.5 432.0 1168.0 408.0 3.5 1.9 75% 37.7 -118.0 37.0 3138.2 647.0 1717.2 603.0 4.8 2.3 max 42.0 -114.3 52.0 37937.0 6445.0 35682.0 6082.0 15.0 55.2 Validation examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 mean 35.7 -119.6 28.6 2675.1 543.8 1437.5 505.0 3.9 2.0 std 2.1 2.0 12.5 2235.0 436.1 1121.7 396.8 1.9 1.0 min 32.5 -124.3 2.0 12.0 4.0 3.0 3.0 0.5 0.3 25% 33.9 -121.8 18.0 1465.8 295.8 788.0 278.0 2.6 1.5 50% 34.3 -118.5 28.0 2172.0 438.0 1165.0 411.0 3.5 1.9 75% 37.7 -118.0 37.0 3176.0 652.0 1732.2 609.0 4.8 2.3 max 41.9 -114.6 52.0 32054.0 5290.0 15507.0 5050.0 15.0 27.1 Training targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value_is_high count 12000.0 mean 0.2 std 0.4 min 0.0 25% 0.0 50% 0.0 75% 0.0 max 1.0 Validation targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value_is_high count 5000.0 mean 0.3 std 0.4 min 0.0 25% 0.0 50% 0.0 75% 1.0 max 1.0 Á∫øÊÄßÂõûÂΩíÁöÑË°®Áé∞‰∏∫‰∫Ü‰∫ÜËß£ÈÄªËæëÂõûÂΩí‰∏∫‰ªÄ‰πàÊúâÊïàÔºåÊàë‰ª¨È¶ñÂÖàËÆ≠ÁªÉ‰∏Ä‰∏™‰ΩøÁî®Á∫øÊÄßÂõûÂΩíÁöÑÁÆÄÂçïÊ®°Âûã„ÄÇËØ•Ê®°ÂûãÂ∞Ü‰ΩøÁî® {0, 1} ‰∏≠ÁöÑÂÄº‰∏∫Ê†áÁ≠æÔºåÂπ∂Â∞ùËØïÈ¢ÑÊµã‰∏Ä‰∏™Â∞ΩÂèØËÉΩÊé•Ëøë 0 Êàñ 1 ÁöÑËøûÁª≠ÂÄº„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Â∏åÊúõÂ∞ÜËæìÂá∫Ëß£ËØª‰∏∫Ê¶ÇÁéáÔºåÊâÄ‰ª•ÊúÄÂ•ΩÊ®°ÂûãÁöÑËæìÂá∫ÂÄºÂèØ‰ª•‰Ωç‰∫é (0, 1) ËåÉÂõ¥ÂÜÖ„ÄÇÁÑ∂ÂêéÊàë‰ª¨‰ºöÂ∫îÁî®ÈòàÂÄº 0.5Ôºå‰ª•Á°ÆÂÆöÊ†áÁ≠æ„ÄÇ ËøêË°å‰ª•‰∏ãÂçïÂÖÉÊ†ºÔºå‰ª•‰ΩøÁî® LinearRegressor ËÆ≠ÁªÉÁ∫øÊÄßÂõûÂΩíÊ®°Âûã„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136def construct_feature_columns(input_features): """Construct the TensorFlow Feature Columns. Args: input_features: The names of the numerical input features to use. Returns: A set of feature columns """ return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features])def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): """Trains a linear regression model. Args: features: pandas DataFrame of features targets: pandas DataFrame of targets batch_size: Size of batches to be passed to the model shuffle: True or False. Whether to shuffle the data. num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely Returns: Tuple of (features, labels) for next data batch """ # Convert pandas data into a dict of np arrays. features = &#123;key:np.array(value) for key,value in dict(features).items()&#125; # Construct a dataset, and configure batching/repeating. ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit ds = ds.batch(batch_size).repeat(num_epochs) # Shuffle the data, if specified. if shuffle: ds = ds.shuffle(10000) # Return the next batch of data. features, labels = ds.make_one_shot_iterator().get_next() return features, labelsdef train_linear_regressor_model( learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets): """Trains a linear regression model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: learning_rate: A `float`, the learning rate. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A `LinearRegressor` object trained on the training data. """ periods = 10 steps_per_period = steps / periods # Create a linear regressor object. my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_regressor = tf.estimator.LinearRegressor( feature_columns=construct_feature_columns(training_examples), optimizer=my_optimizer ) # Create input functions. training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value_is_high"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value_is_high"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value_is_high"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_regressor.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute predictions. training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # Compute training and validation loss. training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() return linear_regressor 12345678linear_regressor = train_linear_regressor_model( learning_rate=0.000001, steps=200, batch_size=20, training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 0.45 period 01 : 0.45 period 02 : 0.45 period 03 : 0.45 period 04 : 0.46 period 05 : 0.44 period 06 : 0.44 period 07 : 0.44 period 08 : 0.45 period 09 : 0.44 Model training finished. ËÆ°ÁÆóÈ¢ÑÊµãÁöÑÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞Ê£ÄÊü•È¢ÑÊµãÔºåÂπ∂Á°ÆÂÆöÊòØÂê¶ÂèØ‰ª•‰ΩøÁî®ÂÆÉ‰ª¨Êù•ËÆ°ÁÆóÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞„ÄÇ LinearRegressor ‰ΩøÁî®ÁöÑÊòØ L2 ÊçüÂ§±ÔºåÂú®Â∞ÜËæìÂá∫Ëß£ËØª‰∏∫Ê¶ÇÁéáÊó∂ÔºåÂÆÉÂπ∂‰∏çËÉΩÊúâÊïàÂú∞ÊÉ©ÁΩöËØØÂàÜÁ±ª„ÄÇ‰æãÂ¶ÇÔºåÂØπ‰∫éÊ¶ÇÁéáÂàÜÂà´‰∏∫ 0.9 Âíå 0.9999 ÁöÑË¥üÂàÜÁ±ªÊ†∑Êú¨ÊòØÂê¶Ë¢´ÂàÜÁ±ª‰∏∫Ê≠£ÂàÜÁ±ªÔºå‰∫åËÄÖ‰πãÈó¥ÁöÑÂ∑ÆÂºÇÂ∫îËØ•ÂæàÂ§ßÔºå‰ΩÜ L2 ÊçüÂ§±Âπ∂‰∏ç‰ºöÊòéÊòæÂå∫ÂàÜËøô‰∫õÊÉÖÂÜµ„ÄÇ Áõ∏ÊØî‰πã‰∏ãÔºåLogLossÔºàÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ÔºâÂØπËøô‰∫õ‚ÄùÁΩÆ‰ø°ÈîôËØØ‚ÄùÁöÑÊÉ©ÁΩöÂäõÂ∫¶Êõ¥Â§ß„ÄÇËØ∑Ê≥®ÊÑèÔºåLogLoss ÁöÑÂÆö‰πâÂ¶Ç‰∏ãÔºö $$Log Loss = \sum_{(x,y)\in D} -y \cdot log(y_{pred}) - (1 - y) \cdot log(1 - y_{pred})$$ ‰ΩÜÊàë‰ª¨È¶ñÂÖàÈúÄË¶ÅËé∑ÂæóÈ¢ÑÊµãÂÄº„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® LinearRegressor.predict Ëé∑ÂæóÈ¢ÑÊµãÂÄº„ÄÇ Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®È¢ÑÊµãÂíåÁõ∏Â∫îÁõÆÊ†áËÆ°ÁÆó LogLoss ÂêóÔºü 12345678predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value_is_high"], num_epochs=1, shuffle=False)validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])_ = plt.hist(validation_predictions) ËÆ≠ÁªÉÈÄªËæëÂõûÂΩíÊ®°ÂûãÂπ∂ËÆ°ÁÆóÈ™åËØÅÈõÜÁöÑÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞Ë¶Å‰ΩøÁî®ÈÄªËæëÂõûÂΩíÈùûÂ∏∏ÁÆÄÂçïÔºåÁî® LinearClassifier Êõø‰ª£ LinearRegressor Âç≥ÂèØ„ÄÇÂÆåÊàê‰ª•‰∏ã‰ª£Á†Å„ÄÇ Ê≥®ÊÑèÔºöÂú® LinearClassifier Ê®°Âûã‰∏äËøêË°å train() Âíå predict() Êó∂ÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáËøîÂõûÁöÑÂ≠óÂÖ∏Ôºà‰æãÂ¶Ç predictions[&quot;probabilities&quot;]Ôºâ‰∏≠ÁöÑ &quot;probabilities&quot; ÈîÆËé∑ÂèñÂÆûÂÄºÈ¢ÑÊµãÊ¶ÇÁéá„ÄÇSklearn ÁöÑ log_loss ÂáΩÊï∞ÂèØÂü∫‰∫éËøô‰∫õÊ¶ÇÁéáËÆ°ÁÆóÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ÔºåÈùûÂ∏∏Êñπ‰æø„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293def train_linear_classifier_model( learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets): """Trains a linear classification model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: learning_rate: A `float`, the learning rate. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A `LinearClassifier` object trained on the training data. """ periods = 10 steps_per_period = steps / periods # Create a linear classifier object. my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_classifier = tf.estimator.LinearClassifier( feature_columns=construct_feature_columns(training_examples), optimizer=my_optimizer ) # Create input functions. training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value_is_high"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value_is_high"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value_is_high"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("LogLoss (on training data):") training_log_losses = [] validation_log_losses = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_classifier.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute predictions. training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn) training_probabilities = np.array([item['probabilities'] for item in training_probabilities]) validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn) validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities]) training_log_loss = metrics.log_loss(training_targets, training_probabilities) validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_log_loss)) # Add the loss metrics from this period to our list. training_log_losses.append(training_log_loss) validation_log_losses.append(validation_log_loss) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("LogLoss") plt.xlabel("Periods") plt.title("LogLoss vs. Periods") plt.tight_layout() plt.plot(training_log_losses, label="training") plt.plot(validation_log_losses, label="validation") plt.legend() return linear_classifier 12345678linear_classifier = train_linear_classifier_model( learning_rate=0.000005, steps=500, batch_size=20, training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... LogLoss (on training data): period 00 : 0.60 period 01 : 0.58 period 02 : 0.57 period 03 : 0.56 period 04 : 0.55 period 05 : 0.55 period 06 : 0.54 period 07 : 0.55 period 08 : 0.54 period 09 : 0.53 Model training finished. ËÆ°ÁÆóÊü•ÂáÜÁéáÂπ∂‰∏∫È™åËØÅÈõÜÁªòÂà∂ ROC Êõ≤Á∫øÂàÜÁ±ªÊó∂ÈùûÂ∏∏ÊúâÁî®ÁöÑ‰∏Ä‰∫õÊåáÊ†áÂåÖÊã¨ÔºöÊ®°ÂûãÂáÜÁ°ÆÁéá„ÄÅROC Êõ≤Á∫øÂíå ROC Êõ≤Á∫ø‰∏ãÈù¢ÁßØ (AUC)„ÄÇÊàë‰ª¨‰ºöÊ£ÄÊü•Ëøô‰∫õÊåáÊ†á„ÄÇ LinearClassifier.evaluate ÂèØËÆ°ÁÆóÂáÜÁ°ÆÁéáÂíå AUC Á≠âÂÆûÁî®ÊåáÊ†á„ÄÇ 1234evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)print("AUC on the validation set: %0.2f" % evaluation_metrics['auc'])print("Accuracy on the validation set: %0.2f" % evaluation_metrics['accuracy']) AUC on the validation set: 0.73 Accuracy on the validation set: 0.76 ÊÇ®ÂèØ‰ª•‰ΩøÁî®Á±ªÂà´Ê¶ÇÁéáÔºà‰æãÂ¶ÇÁî± LinearClassifier.predictÂíå Sklearn ÁöÑ roc_curve ËÆ°ÁÆóÁöÑÊ¶ÇÁéáÔºâÊù•Ëé∑ÂæóÁªòÂà∂ ROC Êõ≤Á∫øÊâÄÈúÄÁöÑÁúüÊ≠£‰æãÁéáÂíåÂÅáÊ≠£‰æãÁéá„ÄÇ 123456789validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)# Get just the probabilities for the positive class.validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve( validation_targets, validation_probabilities)plt.plot(false_positive_rate, true_positive_rate, label="our model")plt.plot([0, 1], [0, 1], label="random classifier")_ = plt.legend(loc=2) ÁúãÁúãÊÇ®ÊòØÂê¶ÂèØ‰ª•Ë∞ÉÊï¥ËÆ≠ÁªÉÁöÑÊ®°ÂûãÁöÑÂ≠¶‰π†ËÆæÁΩÆÔºå‰ª•ÊîπÂñÑ AUC„ÄÇ ÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåÊüê‰∫õÊåáÊ†áÂú®ÊèêÂçáÁöÑÂêåÊó∂‰ºöÊçüÂÆ≥ÂÖ∂‰ªñÊåáÊ†áÔºåÂõ†Ê≠§ÊÇ®ÈúÄË¶ÅÊâæÂà∞ÂèØ‰ª•ÂÆûÁé∞ÁêÜÊÉ≥Êäò‰∏≠ÊÉÖÂÜµÁöÑËÆæÁΩÆ„ÄÇ È™åËØÅÊâÄÊúâÊåáÊ†áÊòØÂê¶ÂêåÊó∂ÊúâÊâÄÊèêÂçá„ÄÇ ‰∏Ä‰∏™ÂèØËÉΩÊúâÁî®ÁöÑËß£ÂÜ≥ÊñπÊ°àÊòØÔºåÂè™Ë¶Å‰∏çËøáÊãüÂêàÔºåÂ∞±ËÆ≠ÁªÉÊõ¥ÈïøÊó∂Èó¥„ÄÇ Ë¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåÊàë‰ª¨ÂèØ‰ª•Â¢ûÂä†Ê≠•Êï∞Âíå/ÊàñÊâπÈáèÂ§ßÂ∞è„ÄÇ ÊâÄÊúâÊåáÊ†áÂêåÊó∂ÊèêÂçáÔºåËøôÊ†∑ÔºåÊàë‰ª¨ÁöÑÊçüÂ§±ÊåáÊ†áÂ∞±ÂèØ‰ª•ÂæàÂ•ΩÂú∞‰ª£ÁêÜ AUC ÂíåÂáÜÁ°ÆÁéá‰∫Ü„ÄÇ Ê≥®ÊÑèÂÆÉÊòØÂ¶Ç‰ΩïËøõË°åÂæàÂ§öÂæàÂ§öÊ¨°Ëø≠‰ª£ÔºåÂè™ÊòØ‰∏∫‰∫ÜÂÜçÂ∞ΩÈáèÂ¢ûÂä†‰∏ÄÁÇπ AUC„ÄÇËøôÁßçÊÉÖÂÜµÂæàÂ∏∏ËßÅÔºå‰ΩÜÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåÂç≥‰ΩøÂè™Êúâ‰∏ÄÁÇπÂ∞èÂ∞èÁöÑÊî∂Ëé∑ÔºåÊäïÂÖ•ÁöÑÊàêÊú¨‰πüÊòØÂÄºÂæóÁöÑ„ÄÇ 1234567891011121314# TUNE THE SETTINGS BELOW TO IMPROVE AUClinear_classifier = train_linear_classifier_model( learning_rate=0.0000035, steps=20000, batch_size=500, training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets)evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)print("AUC on the validation set: %0.2f" % evaluation_metrics['auc'])print("Accuracy on the validation set: %0.2f" % evaluation_metrics['accuracy']) Training model... LogLoss (on training data): period 00 : 0.50 period 01 : 0.49 period 02 : 0.48 period 03 : 0.48 period 04 : 0.48 period 05 : 0.47 period 06 : 0.47 period 07 : 0.47 period 08 : 0.47 period 09 : 0.47 Model training finished. AUC on the validation set: 0.81 Accuracy on the validation set: 0.79 Á®ÄÁñèÊÄßÂíå L1 Ê≠£ÂàôÂåñ Èôç‰ΩéÂ§çÊùÇÊÄßÁöÑ‰∏ÄÁßçÊñπÊ≥ïÊòØ‰ΩøÁî®Ê≠£ÂàôÂåñÂáΩÊï∞ÔºåÂÆÉ‰ºö‰ΩøÊùÉÈáçÊ≠£Â•Ω‰∏∫Èõ∂„ÄÇÂØπ‰∫éÁ∫øÊÄßÊ®°ÂûãÔºà‰æãÂ¶ÇÁ∫øÊÄßÂõûÂΩíÔºâÔºåÊùÉÈáç‰∏∫Èõ∂Â∞±Áõ∏ÂΩì‰∫éÂÆåÂÖ®Ê≤°Êúâ‰ΩøÁî®Áõ∏Â∫îÁâπÂæÅ„ÄÇÈô§‰∫ÜÂèØÈÅøÂÖçËøáÊãüÂêà‰πãÂ§ñÔºåÁîüÊàêÁöÑÊ®°ÂûãËøò‰ºöÊõ¥Âä†ÊúâÊïà„ÄÇ L1 Ê≠£ÂàôÂåñÊòØ‰∏ÄÁßçÂ¢ûÂä†Á®ÄÁñèÊÄßÁöÑÂ•ΩÊñπÊ≥ï„ÄÇ ËÆæÁΩÆÂä†ËΩΩÊï∞ÊçÆÂπ∂ÂàõÂª∫ÁâπÂæÅÂÆö‰πâ„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): """Trains a linear regression model. Args: features: pandas DataFrame of features targets: pandas DataFrame of targets batch_size: Size of batches to be passed to the model shuffle: True or False. Whether to shuffle the data. num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely Returns: Tuple of (features, labels) for next data batch """ # Convert pandas data into a dict of np arrays. features = &#123;key:np.array(value) for key,value in dict(features).items()&#125; # Construct a dataset, and configure batching/repeating. ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit ds = ds.batch(batch_size).repeat(num_epochs) # Shuffle the data, if specified. if shuffle: ds = ds.shuffle(10000) # Return the next batch of data. features, labels = ds.make_one_shot_iterator().get_next() return features, labels# ÂàÜÊ°∂def get_quantile_based_buckets(feature_values, num_buckets): quantiles = feature_values.quantile( [(i+1.)/(num_buckets + 1.) for i in range(num_buckets)]) return [quantiles[q] for q in quantiles.keys()]# ÊûÑÈÄ†ÁâπÂæÅÂàódef construct_feature_columns(): """Construct the TensorFlow Feature Columns. Returns: A set of feature columns """ bucketized_households = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("households"), boundaries=get_quantile_based_buckets(training_examples["households"], 10)) bucketized_longitude = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("longitude"), boundaries=get_quantile_based_buckets(training_examples["longitude"], 50)) bucketized_latitude = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("latitude"), boundaries=get_quantile_based_buckets(training_examples["latitude"], 50)) bucketized_housing_median_age = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("housing_median_age"), boundaries=get_quantile_based_buckets( training_examples["housing_median_age"], 10)) bucketized_total_rooms = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("total_rooms"), boundaries=get_quantile_based_buckets(training_examples["total_rooms"], 10)) bucketized_total_bedrooms = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("total_bedrooms"), boundaries=get_quantile_based_buckets(training_examples["total_bedrooms"], 10)) bucketized_population = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("population"), boundaries=get_quantile_based_buckets(training_examples["population"], 10)) bucketized_median_income = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("median_income"), boundaries=get_quantile_based_buckets(training_examples["median_income"], 10)) bucketized_rooms_per_person = tf.feature_column.bucketized_column( tf.feature_column.numeric_column("rooms_per_person"), boundaries=get_quantile_based_buckets( training_examples["rooms_per_person"], 10)) long_x_lat = tf.feature_column.crossed_column( set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000) feature_columns = set([ long_x_lat, bucketized_longitude, bucketized_latitude, bucketized_housing_median_age, bucketized_total_rooms, bucketized_total_bedrooms, bucketized_population, bucketized_households, bucketized_median_income, bucketized_rooms_per_person]) return feature_columnsdef train_linear_classifier_model( learning_rate, regularization_strength, steps, batch_size, feature_columns, training_examples, training_targets, validation_examples, validation_targets): """Trains a linear regression model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: learning_rate: A `float`, the learning rate. regularization_strength: A `float` that indicates the strength of the L1 regularization. A value of `0.0` means no regularization. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. feature_columns: A `set` specifying the input feature columns to use. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A `LinearClassifier` object trained on the training data. """ periods = 7 steps_per_period = steps / periods # Create a linear classifier object. my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate, l1_regularization_strength=regularization_strength) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_classifier = tf.estimator.LinearClassifier( feature_columns=feature_columns, optimizer=my_optimizer ) # Create input functions. training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value_is_high"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value_is_high"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value_is_high"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("LogLoss (on validation data):") training_log_losses = [] validation_log_losses = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_classifier.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute predictions. training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn) training_probabilities = np.array([item['probabilities'] for item in training_probabilities]) validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn) validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities]) # Compute training and validation loss. training_log_loss = metrics.log_loss(training_targets, training_probabilities) validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, validation_log_loss)) # Add the loss metrics from this period to our list. training_log_losses.append(training_log_loss) validation_log_losses.append(validation_log_loss) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("LogLoss") plt.xlabel("Periods") plt.title("LogLoss vs. Periods") plt.tight_layout() plt.plot(training_log_losses, label="training") plt.plot(validation_log_losses, label="validation") plt.legend() return linear_classifier ËÆ°ÁÆóÊ®°ÂûãÂ§ßÂ∞èË¶ÅËÆ°ÁÆóÊ®°ÂûãÂ§ßÂ∞èÔºåÂè™ÈúÄËÆ°ÁÆóÈùûÈõ∂ÂèÇÊï∞ÁöÑÊï∞ÈáèÂç≥ÂèØ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨Âú®‰∏ãÈù¢Êèê‰æõ‰∫Ü‰∏Ä‰∏™ËæÖÂä©ÂáΩÊï∞„ÄÇËØ•ÂáΩÊï∞Ê∑±ÂÖ•‰ΩøÁî®‰∫Ü Estimator APIÔºåÂ¶ÇÊûú‰∏ç‰∫ÜËß£ÂÆÉÁöÑÂ∑•‰ΩúÂéüÁêÜÔºå‰πü‰∏çÁî®ÊãÖÂøÉ„ÄÇ 123456789101112def model_size(estimator): variables = estimator.get_variable_names() size = 0 for variable in variables: if not any(x in variable for x in ['global_step', 'centered_bias_weight', 'bias_weight', 'Ftrl'] ): size += np.count_nonzero(estimator.get_variable_value(variable)) return size ÂáèÂ∞èÊ®°ÂûãÂ§ßÂ∞èÊÇ®ÁöÑÂõ¢ÈòüÈúÄË¶ÅÈíàÂØπ SmartRing ÊûÑÂª∫‰∏Ä‰∏™ÂáÜÁ°ÆÂ∫¶È´òÁöÑÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºåËøôÁßçÊåáÁéØÈùûÂ∏∏Êô∫ËÉΩÔºåÂèØ‰ª•ÊÑüÂ∫îÂüéÂ∏ÇË°óÂå∫ÁöÑ‰∫∫Âè£ÁªüËÆ°ÁâπÂæÅÔºàmedian_income„ÄÅavg_rooms„ÄÅhouseholds Á≠âÁ≠âÔºâÔºåÂπ∂ÂëäËØâÊÇ®ÊåáÂÆöÂüéÂ∏ÇË°óÂå∫ÁöÑ‰ΩèÊàøÊàêÊú¨ÊòØÂê¶È´òÊòÇ„ÄÇ Áî±‰∫é SmartRing ÂæàÂ∞èÔºåÂõ†Ê≠§Â∑•Á®ãÂõ¢ÈòüÂ∑≤Á°ÆÂÆöÂÆÉÂè™ËÉΩÂ§ÑÁêÜÂèÇÊï∞Êï∞Èáè‰∏çË∂ÖËøá 600 ‰∏™ÁöÑÊ®°Âûã„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰∫ßÂìÅÁÆ°ÁêÜÂõ¢Èòü‰πüÂ∑≤Á°ÆÂÆöÔºåÈô§ÈùûÊâÄ‰øùÁïôÊµãËØïÈõÜÁöÑÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞‰Ωé‰∫é 0.35ÔºåÂê¶ÂàôËØ•Ê®°Âûã‰∏çËÉΩÂèëÂ∏É„ÄÇ ÊÇ®ÂèØ‰ª•‰ΩøÁî®ÁßòÂØÜÊ≠¶Âô®‚ÄúL1 Ê≠£ÂàôÂåñ‚ÄùË∞ÉÊï¥Ê®°ÂûãÔºå‰ΩøÂÖ∂ÂêåÊó∂Êª°Ë∂≥Â§ßÂ∞èÂíåÂáÜÁ°ÆÁéáÈôêÂà∂Êù°‰ª∂ÂêóÔºü Êü•ÊâæÂêàÈÄÇÁöÑÊ≠£ÂàôÂåñÁ≥ªÊï∞„ÄÇÊü•ÊâæÂèØÂêåÊó∂Êª°Ë∂≥‰ª•‰∏ã‰∏§ÁßçÈôêÂà∂Êù°‰ª∂ÁöÑ L1 Ê≠£ÂàôÂåñÂº∫Â∫¶ÂèÇÊï∞ÔºöÊ®°ÂûãÁöÑÂèÇÊï∞Êï∞Èáè‰∏çË∂ÖËøá 600 ‰∏™‰∏îÈ™åËØÅÈõÜÁöÑÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞‰Ωé‰∫é 0.35„ÄÇ ‰ª•‰∏ã‰ª£Á†ÅÂèØÂ∏ÆÂä©ÊÇ®Âø´ÈÄüÂºÄÂßã„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøáÂ§öÁßçÊñπÊ≥ïÂêëÊÇ®ÁöÑÊ®°ÂûãÂ∫îÁî®Ê≠£ÂàôÂåñ„ÄÇÂú®Ê≠§ÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨ÈÄâÊã©‰ΩøÁî® FtrlOptimizer Êù•Â∫îÁî®Ê≠£ÂàôÂåñ„ÄÇFtrlOptimizer ÊòØ‰∏ÄÁßçËÆæËÆ°Êàê‰ΩøÁî® L1 Ê≠£ÂàôÂåñÊØîÊ†áÂáÜÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂæóÂà∞Êõ¥Â•ΩÁªìÊûúÁöÑÊñπÊ≥ï„ÄÇ ÈáçÁî≥‰∏ÄÊ¨°ÔºåÊàë‰ª¨‰ºö‰ΩøÁî®Êï¥‰∏™Êï∞ÊçÆÈõÜÊù•ËÆ≠ÁªÉËØ•Ê®°ÂûãÔºåÂõ†Ê≠§È¢ÑËÆ°ÂÖ∂ËøêË°åÈÄüÂ∫¶‰ºöÊØîÈÄöÂ∏∏Ë¶ÅÊÖ¢„ÄÇ Ê≠£ÂàôÂåñÂº∫Â∫¶‰∏∫ 0.1 Â∫îËØ•Â∞±Ë∂≥Â§ü‰∫Ü„ÄÇËØ∑Ê≥®ÊÑèÔºåÊúâ‰∏Ä‰∏™ÈúÄË¶ÅÂÅöÂá∫Êäò‰∏≠ÈÄâÊã©ÁöÑÂú∞ÊñπÔºöÊ≠£ÂàôÂåñË∂äÂº∫ÔºåÊàë‰ª¨Ëé∑ÂæóÁöÑÊ®°ÂûãÂ∞±Ë∂äÂ∞èÔºå‰ΩÜ‰ºöÂΩ±ÂìçÂàÜÁ±ªÊçüÂ§±„ÄÇ 123456789101112linear_classifier = train_linear_classifier_model( learning_rate=0.1, # TWEAK THE REGULARIZATION VALUE BELOW regularization_strength=0.0, steps=300, batch_size=100, feature_columns=construct_feature_columns(), training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets)print("Model size:", model_size(linear_classifier)) Training model... LogLoss (on validation data): period 00 : 0.30 period 01 : 0.27 period 02 : 0.26 period 03 : 0.25 period 04 : 0.24 period 05 : 0.24 period 06 : 0.23 Model training finished. Model size: 790 1234567891011linear_classifier = train_linear_classifier_model( learning_rate=0.1, regularization_strength=0.1, steps=300, batch_size=100, feature_columns=construct_feature_columns(), training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets)print("Model size:", model_size(linear_classifier)) Training model... LogLoss (on validation data): period 00 : 0.31 period 01 : 0.27 period 02 : 0.26 period 03 : 0.25 period 04 : 0.24 period 05 : 0.24 period 06 : 0.23 Model training finished. Model size: 764]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 6]]></title>
    <url>%2F2019%2F01%2F14%2FTensorFlow_6%2F</url>
    <content type="text"><![CDATA[ÁâπÂæÅÁªÑÂêà (Feature Crosses)ÁâπÂæÅÁªÑÂêàÊòØÊåá‰∏§‰∏™ÊàñÂ§ö‰∏™ÁâπÂæÅÁõ∏‰πòÂΩ¢ÊàêÁöÑÂêàÊàêÁâπÂæÅ„ÄÇÁâπÂæÅÁöÑÁõ∏‰πòÁªÑÂêàÂèØ‰ª•Êèê‰æõË∂ÖÂá∫Ëøô‰∫õÁâπÂæÅÂçïÁã¨ËÉΩÂ§üÊèê‰æõÁöÑÈ¢ÑÊµãËÉΩÂäõ„ÄÇ ÂØπÈùûÁ∫øÊÄßËßÑÂæãËøõË°åÁºñÁ†ÅÁªÑÂêàÁã¨ÁÉ≠Áü¢ÈáèÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊàë‰ª¨Â∑≤ÁªèÈáçÁÇπ‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÂØπ‰∏§‰∏™ÂçïÁã¨ÁöÑÊµÆÁÇπÁâπÂæÅËøõË°åÁâπÂæÅÁªÑÂêà„ÄÇÂú®ÂÆûË∑µ‰∏≠ÔºåÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂæàÂ∞ë‰ºöÁªÑÂêàËøûÁª≠ÁâπÂæÅ„ÄÇ‰∏çËøáÔºåÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂç¥ÁªèÂ∏∏ÁªÑÂêàÁã¨ÁÉ≠ÁâπÂæÅÁü¢ÈáèÔºåÂ∞ÜÁã¨ÁÉ≠ÁâπÂæÅÁü¢ÈáèÁöÑÁâπÂæÅÁªÑÂêàËßÜ‰∏∫ÈÄªËæëËøûÊé•„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÊàë‰ª¨ÂÖ∑Êúâ‰ª•‰∏ã‰∏§‰∏™ÁâπÂæÅÔºöÂõΩÂÆ∂/Âú∞Âå∫ÂíåËØ≠Ë®Ä„ÄÇÂØπÊØè‰∏™ÁâπÂæÅËøõË°åÁã¨ÁÉ≠ÁºñÁ†Å‰ºöÁîüÊàêÂÖ∑Êúâ‰∫åÂÖÉÁâπÂæÅÁöÑÁü¢ÈáèÔºåËøô‰∫õ‰∫åÂÖÉÁâπÂæÅÂèØËß£ËØª‰∏∫ country=USA, country=France Êàñ language=English, language=Spanish„ÄÇÁÑ∂ÂêéÔºåÂ¶ÇÊûúÊÇ®ÂØπËøô‰∫õÁã¨ÁÉ≠ÁºñÁ†ÅËøõË°åÁâπÂæÅÁªÑÂêàÔºåÂàô‰ºöÂæóÂà∞ÂèØËß£ËØª‰∏∫ÈÄªËæëËøûÊé•ÁöÑ‰∫åÂÖÉÁâπÂæÅÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö country:usa AND language:spanish ÂÜç‰∏æ‰∏Ä‰∏™‰æãÂ≠êÔºåÂÅáËÆæÊÇ®ÂØπÁ∫¨Â∫¶ÂíåÁªèÂ∫¶ËøõË°åÂàÜÁÆ±ÔºåËé∑ÂæóÂçïÁã¨ÁöÑÁã¨ÁÉ≠ 5 ÂÖÉÁ¥†ÁâπÂæÅÁü¢Èáè„ÄÇ‰æãÂ¶ÇÔºåÊåáÂÆöÁöÑÁ∫¨Â∫¶ÂíåÁªèÂ∫¶ÂèØ‰ª•Ë°®Á§∫Â¶Ç‰∏ãÔºö binned_latitude = [0, 0, 0, 1, 0] binned_longitude = [0, 1, 0, 0, 0] ÂÅáËÆæÊÇ®ÂØπËøô‰∏§‰∏™ÁâπÂæÅÁü¢ÈáèÂàõÂª∫‰∫ÜÁâπÂæÅÁªÑÂêàÔºö binned_latitude X binned_longitude Ê≠§ÁâπÂæÅÁªÑÂêàÊòØ‰∏Ä‰∏™ 25 ÂÖÉÁ¥†Áã¨ÁÉ≠Áü¢ÈáèÔºà24 ‰∏™ 0 Âíå 1 ‰∏™ 1Ôºâ„ÄÇËØ•ÁªÑÂêà‰∏≠ÁöÑÂçï‰∏™ 1 Ë°®Á§∫Á∫¨Â∫¶‰∏éÁªèÂ∫¶ÁöÑÁâπÂÆöËøûÊé•„ÄÇÁÑ∂ÂêéÔºåÊÇ®ÁöÑÊ®°ÂûãÂ∞±ÂèØ‰ª•‰∫ÜËß£Âà∞ÊúâÂÖ≥ËøôÁßçËøûÊé•ÁöÑÁâπÂÆöÂÖ≥ËÅîÊÄß„ÄÇ ÂÅáËÆæÊàë‰ª¨Êõ¥Á≤óÁï•Âú∞ÂØπÁ∫¨Â∫¶ÂíåÁªèÂ∫¶ËøõË°åÂàÜÁÆ±ÔºåÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö binned_latitude(lat) = [ 0 &lt; lat &lt;= 10 10 &lt; lat &lt;= 20 20 &lt; lat &lt;= 30 ] binned_longitude(lon) = [ 0 &lt; lon &lt;= 15 15 &lt; lon &lt;= 30 ] ÈíàÂØπËøô‰∫õÁ≤óÁï•ÂàÜÁÆ±ÂàõÂª∫ÁâπÂæÅÁªÑÂêà‰ºöÁîüÊàêÂÖ∑Êúâ‰ª•‰∏ãÂê´‰πâÁöÑÂêàÊàêÁâπÂæÅÔºö binned_latitude_X_longitude(lat, lon) = [ 0 &lt; lat &lt;= 10 AND 0 &lt; lon &lt;= 15 0 &lt; lat &lt;= 10 AND 15 &lt; lon &lt;= 30 10 &lt; lat &lt;= 20 AND 0 &lt; lon &lt;= 15 10 &lt; lat &lt;= 20 AND 15 &lt; lon &lt;= 30 20 &lt; lat &lt;= 30 AND 0 &lt; lon &lt;= 15 20 &lt; lat &lt;= 30 AND 15 &lt; lon &lt;= 30 ] Áé∞Âú®ÔºåÂÅáËÆæÊàë‰ª¨ÁöÑÊ®°ÂûãÈúÄË¶ÅÊ†πÊçÆ‰ª•‰∏ã‰∏§‰∏™ÁâπÂæÅÊù•È¢ÑÊµãÁãó‰∏ª‰∫∫ÂØπÁãóÁãóÁöÑÊª°ÊÑèÁ®ãÂ∫¶Ôºö Ë°å‰∏∫Á±ªÂûãÔºàÂê†Âè´„ÄÅÂè´„ÄÅÂÅé‰æùÁ≠âÔºâÊó∂ÊÆµÂ¶ÇÊûúÊàë‰ª¨Ê†πÊçÆËøô‰∏§‰∏™ÁâπÂæÅÊûÑÂª∫‰ª•‰∏ãÁâπÂæÅÁªÑÂêàÔºö [behavior type X time of day] Êàë‰ª¨ÊúÄÁªàËé∑ÂæóÁöÑÈ¢ÑÊµãËÉΩÂäõÂ∞ÜËøúËøúË∂ÖËøá‰ªª‰∏ÄÁâπÂæÅÂçïÁã¨ÁöÑÈ¢ÑÊµãËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÁãóÁãóÂú®‰∏ãÂçà 5 ÁÇπ‰∏ª‰∫∫‰∏ãÁè≠ÂõûÊù•Êó∂ÔºàÂø´‰πêÂú∞ÔºâÂè´ÂñäÔºåÂèØËÉΩË°®Á§∫ÂØπ‰∏ª‰∫∫Êª°ÊÑèÂ∫¶ÁöÑÊ≠£Èù¢È¢ÑÊµãÁªìÊûú„ÄÇÂ¶ÇÊûúÁãóÁãóÂú®ÂáåÊô® 3 ÁÇπ‰∏ª‰∫∫ÁÜüÁù°Êó∂Ôºà‰πüËÆ∏ÁóõËã¶Âú∞ÔºâÂìÄÂè´ÔºåÂèØËÉΩË°®Á§∫ÂØπ‰∏ª‰∫∫Êª°ÊÑèÂ∫¶ÁöÑÂº∫ÁÉàË¥üÈù¢È¢ÑÊµãÁªìÊûú„ÄÇ Á∫øÊÄßÂ≠¶‰π†Âô®ÂèØ‰ª•ÂæàÂ•ΩÂú∞Êâ©Â±ïÂà∞Â§ßÈáèÊï∞ÊçÆ„ÄÇÂØπÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰ΩøÁî®ÁâπÂæÅÁªÑÂêàÊòØÂ≠¶‰π†È´òÂ∫¶Â§çÊùÇÊ®°ÂûãÁöÑ‰∏ÄÁßçÊúâÊïàÁ≠ñÁï•„ÄÇÁ•ûÁªèÁΩëÁªúÂèØÊèê‰æõÂè¶‰∏ÄÁßçÁ≠ñÁï•„ÄÇ ÁºñÁ®ãÁªÉ‰π† ÈÄöËøáÊ∑ªÂä†ÂÖ∂‰ªñÂêàÊàêÁâπÂæÅÊù•ÊîπËøõÁ∫øÊÄßÂõûÂΩíÊ®°ÂûãÔºàËøôÊòØÂâç‰∏Ä‰∏™ÁªÉ‰π†ÁöÑÂª∂Áª≠Ôºâ ‰ΩøÁî®ËæìÂÖ•ÂáΩÊï∞Â∞Ü Pandas DataFrame ÂØπË±°ËΩ¨Êç¢‰∏∫ TensorsÔºåÂπ∂Âú® fit() Âíå predict() ‰∏≠Ë∞ÉÁî®ËæìÂÖ•ÂáΩÊï∞ ‰ΩøÁî® FTRL ‰ºòÂåñÁÆóÊ≥ïËøõË°åÊ®°ÂûãËÆ≠ÁªÉ ÈÄöËøáÁã¨ÁÉ≠ÁºñÁ†Å„ÄÅÂàÜÁÆ±ÂíåÁâπÂæÅÁªÑÂêàÂàõÂª∫Êñ∞ÁöÑÂêàÊàêÁâπÂæÅ ËÆæÁΩÆ È¶ñÂÖàÔºåÊàë‰ª¨Êù•ÂÆö‰πâËæìÂÖ•Âπ∂ÂàõÂª∫Êï∞ÊçÆÂä†ËΩΩ‰ª£Á†ÅÔºåÊ≠£Â¶ÇÊàë‰ª¨Âú®‰πãÂâçÁöÑÁªÉ‰π†‰∏≠ÊâÄÂÅöÁöÑÈÇ£Ê†∑„ÄÇ 12345678910111213141516171819202122from __future__ import print_functionimport mathfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10pd.options.display.float_format = '&#123;:.1f&#125;'.formatcalifornia_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",")california_housing_dataframe = california_housing_dataframe.reindex( np.random.permutation(california_housing_dataframe.index)) 12345678910111213141516171819202122232425262728293031323334353637383940def preprocess_features(california_housing_dataframe): """Prepares input features from California housing data set. Args: california_housing_dataframe: A Pandas DataFrame expected to contain data from the California housing data set. Returns: A DataFrame that contains the features to be used for the model, including synthetic features. """ selected_features = california_housing_dataframe[ ["latitude", "longitude", "housing_median_age", "total_rooms", "total_bedrooms", "population", "households", "median_income"]] processed_features = selected_features.copy() # Create a synthetic feature. processed_features["rooms_per_person"] = ( california_housing_dataframe["total_rooms"] / california_housing_dataframe["population"]) return processed_featuresdef preprocess_targets(california_housing_dataframe): """Prepares target features (i.e., labels) from California housing data set. Args: california_housing_dataframe: A Pandas DataFrame expected to contain data from the California housing data set. Returns: A DataFrame that contains the target feature. """ output_targets = pd.DataFrame() # Scale the target to be in units of thousands of dollars. output_targets["median_house_value"] = ( california_housing_dataframe["median_house_value"] / 1000.0) return output_targets 123456789101112131415161718# Choose the first 12000 (out of 17000) examples for training.training_examples = preprocess_features(california_housing_dataframe.head(12000))training_targets = preprocess_targets(california_housing_dataframe.head(12000))# Choose the last 5000 (out of 17000) examples for validation.validation_examples = preprocess_features(california_housing_dataframe.tail(5000))validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))# Double-check that we've done the right thing.print("Training examples summary:")display.display(training_examples.describe())print("Validation examples summary:")display.display(validation_examples.describe())print("Training targets summary:")display.display(training_targets.describe())print("Validation targets summary:")display.display(validation_targets.describe()) Training examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 mean 35.6 -119.5 28.6 2643.5 539.4 1430.0 501.4 3.9 2.0 std 2.1 2.0 12.6 2203.2 423.9 1153.9 388.0 1.9 1.2 min 32.5 -124.3 1.0 8.0 1.0 3.0 1.0 0.5 0.1 25% 33.9 -121.8 18.0 1457.8 295.0 788.0 280.0 2.6 1.5 50% 34.2 -118.5 29.0 2121.0 432.0 1165.0 407.0 3.5 1.9 75% 37.7 -118.0 37.0 3149.2 647.0 1717.0 603.2 4.8 2.3 max 42.0 -114.3 52.0 37937.0 5471.0 35682.0 5189.0 15.0 55.2 Validation examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 mean 35.7 -119.6 28.7 2644.1 539.3 1428.5 500.7 3.9 2.0 std 2.1 2.0 12.6 2123.4 415.6 1133.3 376.0 1.9 1.1 min 32.5 -124.3 1.0 2.0 2.0 6.0 2.0 0.5 0.0 25% 33.9 -121.8 18.0 1473.0 300.0 792.0 285.0 2.6 1.5 50% 34.3 -118.5 29.0 2148.5 437.0 1172.0 413.5 3.5 2.0 75% 37.7 -118.0 37.0 3153.2 652.2 1737.0 608.0 4.8 2.3 max 42.0 -114.6 52.0 32627.0 6445.0 28566.0 6082.0 15.0 41.3 Training targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 12000.0 mean 207.6 std 116.2 min 15.0 25% 119.8 50% 180.4 75% 265.7 max 500.0 Validation targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 5000.0 mean 206.5 std 115.6 min 15.0 25% 118.8 50% 180.1 75% 263.4 max 500.0 12345678910def construct_feature_columns(input_features): """Construct the TensorFlow Feature Columns. Args: input_features: The names of the numerical input features to use. Returns: A set of feature columns """ return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features]) 123456789101112131415161718192021222324252627def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): """Trains a linear regression model. Args: features: pandas DataFrame of features targets: pandas DataFrame of targets batch_size: Size of batches to be passed to the model shuffle: True or False. Whether to shuffle the data. num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely Returns: Tuple of (features, labels) for next data batch """ # Convert pandas data into a dict of np arrays. features = &#123;key:np.array(value) for key,value in dict(features).items()&#125; # Construct a dataset, and configure batching/repeating. ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit ds = ds.batch(batch_size).repeat(num_epochs) # Shuffle the data, if specified. if shuffle: ds = ds.shuffle(10000) # Return the next batch of data. features, labels = ds.make_one_shot_iterator().get_next() return features, labels FTRL ‰ºòÂåñÁÆóÊ≥ïÈ´òÁª¥Â∫¶Á∫øÊÄßÊ®°ÂûãÂèØÂèóÁõä‰∫é‰ΩøÁî®‰∏ÄÁßçÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑ‰ºòÂåñÊñπÊ≥ïÔºåÂè´ÂÅö FTRL„ÄÇËØ•ÁÆóÊ≥ïÁöÑ‰ºòÂäøÊòØÈíàÂØπ‰∏çÂêåÁ≥ªÊï∞‰ª•‰∏çÂêåÊñπÂºèË∞ÉÊï¥Â≠¶‰π†ÈÄüÁéáÔºåÂ¶ÇÊûúÊüê‰∫õÁâπÂæÅÂæàÂ∞ëÈááÁî®ÈùûÈõ∂ÂÄºÔºåËØ•ÁÆóÊ≥ïÂèØËÉΩÊØîËæÉÂÆûÁî®Ôºà‰πüÈùûÂ∏∏ÈÄÇÂêàÊîØÊåÅ L1 Ê≠£ÂàôÂåñÔºâ„ÄÇÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® FtrlOptimizer Êù•Â∫îÁî® FTRL„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596def train_model( learning_rate, steps, batch_size, feature_columns, training_examples, training_targets, validation_examples, validation_targets): """Trains a linear regression model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: learning_rate: A `float`, the learning rate. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. feature_columns: A `set` specifying the input feature columns to use. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A `LinearRegressor` object trained on the training data. """ periods = 10 steps_per_period = steps / periods # Create a linear regressor object. my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, optimizer=my_optimizer ) training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_regressor.train( input_fn=training_input_fn, steps=steps_per_period ) # Take a break and compute predictions. training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # Compute training and validation loss. training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() return linear_regressor 123456789_ = train_model( learning_rate=1.0, steps=500, batch_size=100, feature_columns=construct_feature_columns(training_examples), training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 180.73 period 01 : 170.12 period 02 : 111.43 period 03 : 157.79 period 04 : 147.28 period 05 : 139.07 period 06 : 120.82 period 07 : 148.39 period 08 : 118.07 period 09 : 117.32 Model training finished. Á¶ªÊï£ÁâπÂæÅÁöÑÁã¨ÁÉ≠ÁºñÁ†ÅÈÄöÂ∏∏ÔºåÂú®ËÆ≠ÁªÉÈÄªËæëÂõûÂΩíÊ®°Âûã‰πãÂâçÔºåÁ¶ªÊï£ÔºàÂç≥Â≠óÁ¨¶‰∏≤„ÄÅÊûö‰∏æ„ÄÅÊï¥Êï∞ÔºâÁâπÂæÅ‰ºöËΩ¨Êç¢‰∏∫‰∫åÂÖÉÁâπÂæÅÁ≥ªÂàó„ÄÇ ‰æãÂ¶ÇÔºåÂÅáËÆæÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂêàÊàêÁâπÂæÅÔºåÂèØ‰ª•ÈááÁî® 0„ÄÅ1 Êàñ 2 ‰∏≠ÁöÑ‰ªª‰ΩïÂÄºÔºåÂπ∂‰∏îÊàë‰ª¨ËøòÂÖ∑Êúâ‰ª•‰∏ãÂá†‰∏™ËÆ≠ÁªÉÁÇπÔºö feature_value 0 2 1 0 2 1 ÂØπ‰∫éÊØè‰∏™ÂèØËÉΩÁöÑÂàÜÁ±ªÂÄºÔºåÊàë‰ª¨ÈÉΩ‰ºöÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑ‰∫åÂÖÉÂÆûÂÄºÁâπÂæÅÔºåËØ•ÁâπÂæÅÂè™ËÉΩÈááÁî®‰∏§‰∏™ÂèØËÉΩÂÄº‰∏≠ÁöÑ‰∏Ä‰∏™ÔºöÂ¶ÇÊûúÁ§∫‰æã‰∏≠ÂåÖÂê´ËØ•ÂÄºÔºåÂàôÂÄº‰∏∫ 1.0ÔºõÂ¶ÇÊûú‰∏çÂåÖÂê´ÔºåÂàôÂÄº‰∏∫ 0.0„ÄÇÂú®‰∏äËø∞Á§∫‰æã‰∏≠ÔºåÂàÜÁ±ªÁâπÂæÅ‰ºöË¢´ËΩ¨Êç¢Êàê‰∏â‰∏™ÁâπÂæÅÔºåÁé∞Âú®ËÆ≠ÁªÉÁÇπÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö feature_value_0 feature_value_1 feature_value_2 0 0.0 0.0 1.0 1 1.0 0.0 0.0 2 0.0 1.0 0.0 ÂàÜÊ°∂ÔºàÂàÜÁÆ±ÔºâÁâπÂæÅÂàÜÊ°∂‰πüÁß∞‰∏∫ÂàÜÁÆ±„ÄÇ ‰æãÂ¶ÇÔºåÊàë‰ª¨ÂèØ‰ª•Â∞Ü population ÂàÜ‰∏∫‰ª•‰∏ã 3 ‰∏™ÂàÜÊ°∂Ôºö bucket_0 (&lt; 5000)ÔºöÂØπÂ∫î‰∫é‰∫∫Âè£ÂàÜÂ∏ÉËæÉÂ∞ëÁöÑË°óÂå∫ bucket_1 (5000 - 25000)ÔºöÂØπÂ∫î‰∫é‰∫∫Âè£ÂàÜÂ∏ÉÈÄÇ‰∏≠ÁöÑË°óÂå∫ bucket_2 (&gt; 25000)ÔºöÂØπÂ∫î‰∫é‰∫∫Âè£ÂàÜÂ∏ÉËæÉÂ§öÁöÑË°óÂå∫ Ê†πÊçÆÂâçÈù¢ÁöÑÂàÜÊ°∂ÂÆö‰πâÔºå‰ª•‰∏ã population Áü¢ÈáèÔºö [[10001], [42004], [2500], [18000]] Â∞ÜÂèòÊàê‰ª•‰∏ãÁªèËøáÂàÜÊ°∂ÁöÑÁâπÂæÅÁü¢ÈáèÔºö [[1], [2], [0], [1]] Ëøô‰∫õÁâπÂæÅÂÄºÁé∞Âú®ÊòØÂàÜÊ°∂Á¥¢Âºï„ÄÇËØ∑Ê≥®ÊÑèÔºåËøô‰∫õÁ¥¢ÂºïË¢´ËßÜ‰∏∫Á¶ªÊï£ÁâπÂæÅ„ÄÇÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåËøô‰∫õÁâπÂæÅÂ∞ÜË¢´Ëøõ‰∏ÄÊ≠•ËΩ¨Êç¢‰∏∫‰∏äËø∞Áã¨ÁÉ≠Ë°®Á§∫Ê≥ïÔºå‰ΩÜËøôÊòØ‰ª•ÈÄèÊòéÊñπÂºèÂÆûÁé∞ÁöÑ„ÄÇ Ë¶Å‰∏∫ÂàÜÊ°∂ÁâπÂæÅÂÆö‰πâÁâπÂæÅÂàóÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® bucketized_columnÔºàËÄå‰∏çÊòØ‰ΩøÁî® numeric_columnÔºâÔºåËØ•ÂàóÂ∞ÜÊï∞Â≠óÂàó‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂‰ΩøÁî® boundaries ÂèÇÊï∞‰∏≠ÊåáÂÆöÁöÑÂàÜÊ°∂ËæπÁïåÂ∞ÜÂÖ∂ËΩ¨Êç¢‰∏∫ÂàÜÊ°∂ÁâπÂæÅ„ÄÇ‰ª•‰∏ã‰ª£Á†Å‰∏∫ households Âíå longitude ÂÆö‰πâ‰∫ÜÂàÜÊ°∂ÁâπÂæÅÂàóÔºõget_quantile_based_boundaries ÂáΩÊï∞‰ºöÊ†πÊçÆÂàÜ‰ΩçÊï∞ËÆ°ÁÆóËæπÁïåÔºå‰ª•‰æøÊØè‰∏™ÂàÜÊ°∂ÂåÖÂê´Áõ∏ÂêåÊï∞ÈáèÁöÑÂÖÉÁ¥†„ÄÇ 12345678910111213141516def get_quantile_based_boundaries(feature_values, num_buckets): boundaries = np.arange(1.0, num_buckets) / num_buckets quantiles = feature_values.quantile(boundaries) return [quantiles[q] for q in quantiles.keys()] # Êää households ÂàÜÊàê7Ê°∂households = tf.feature_column.numeric_column("housholds")bucketized_households = tf.feature_column.bucketized_column( households, boundaries=get_quantile_based_boundaries( california_housing_dataframe["households"], 7))# Êää longitude ÂàÜÊàê10Ê°∂longitude = tf.feature_column.numeric_column("longitude")bucketized_longitude = tf.feature_column.bucketized_column( longitude, boundaries=get_quantile_based_boundaries( california_housing_dataframe["longitude"], 10)) ‰ªªÂä° 1Ôºö‰ΩøÁî®ÂàÜÊ°∂ÁâπÂæÅÂàóËÆ≠ÁªÉÊ®°ÂûãÂ∞ÜÊàë‰ª¨Á§∫‰æã‰∏≠ÁöÑÊâÄÊúâÂÆûÂÄºÁâπÂæÅËøõË°åÂàÜÊ°∂ÔºåËÆ≠ÁªÉÊ®°ÂûãÔºåÁÑ∂ÂêéÊü•ÁúãÁªìÊûúÊòØÂê¶ÊúâÊâÄÊîπÂñÑ„ÄÇ Âú®ÂâçÈù¢ÁöÑ‰ª£Á†ÅÂùó‰∏≠Ôºå‰∏§‰∏™ÂÆûÂÄºÂàóÔºàÂç≥ households Âíå longitudeÔºâÂ∑≤Ë¢´ËΩ¨Êç¢‰∏∫ÂàÜÊ°∂ÁâπÂæÅÂàó„ÄÇÊÇ®ÁöÑ‰ªªÂä°ÊòØÂØπÂÖ∂‰ΩôÁöÑÂàóËøõË°åÂàÜÊ°∂ÔºåÁÑ∂ÂêéËøêË°å‰ª£Á†ÅÊù•ËÆ≠ÁªÉÊ®°Âûã„ÄÇÊÇ®ÂèØ‰ª•ÈááÁî®ÂêÑÁßçÂêØÂèëÊ≥ïÊù•Á°ÆÂÆöÂàÜÊ°∂ÁöÑËåÉÂõ¥„ÄÇÊú¨ÁªÉ‰π†‰ΩøÁî®‰∫ÜÂàÜ‰ΩçÊï∞ÊäÄÂ∑ßÔºåÈÄöËøáËøôÁßçÊñπÂºèÈÄâÊã©ÂàÜÊ°∂ËæπÁïåÂêéÔºåÊØè‰∏™ÂàÜÊ°∂Â∞ÜÂåÖÂê´Áõ∏ÂêåÊï∞ÈáèÁöÑÊ†∑Êú¨„ÄÇ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def construct_feature_columns(): """Construct the TensorFlow Feature Columns. Returns: A set of feature columns """ households = tf.feature_column.numeric_column("households") longitude = tf.feature_column.numeric_column("longitude") latitude = tf.feature_column.numeric_column("latitude") housing_median_age = tf.feature_column.numeric_column("housing_median_age") median_income = tf.feature_column.numeric_column("median_income") rooms_per_person = tf.feature_column.numeric_column("rooms_per_person") # Divide households into 7 buckets. bucketized_households = tf.feature_column.bucketized_column( households, boundaries=get_quantile_based_boundaries( training_examples["households"], 7)) # Divide longitude into 10 buckets. bucketized_longitude = tf.feature_column.bucketized_column( longitude, boundaries=get_quantile_based_boundaries( training_examples["longitude"], 10)) # Divide latitude into 10 buckets. bucketized_latitude = tf.feature_column.bucketized_column( latitude, boundaries=get_quantile_based_boundaries( training_examples["latitude"], 10)) # Divide housing_median_age into 7 buckets. bucketized_housing_median_age = tf.feature_column.bucketized_column( housing_median_age, boundaries=get_quantile_based_boundaries( training_examples["housing_median_age"], 7)) # Divide median_income into 7 buckets. bucketized_median_income = tf.feature_column.bucketized_column( median_income, boundaries=get_quantile_based_boundaries( training_examples["median_income"], 7)) # Divide rooms_per_person into 7 buckets. bucketized_rooms_per_person = tf.feature_column.bucketized_column( rooms_per_person, boundaries=get_quantile_based_boundaries( training_examples["rooms_per_person"], 7)) feature_columns = set([ bucketized_longitude, bucketized_latitude, bucketized_housing_median_age, bucketized_households, bucketized_median_income, bucketized_rooms_per_person]) return feature_columns 123456789_ = train_model( learning_rate=1.0, steps=500, batch_size=100, feature_columns=construct_feature_columns(), training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 169.83 period 01 : 143.51 period 02 : 126.97 period 03 : 115.77 period 04 : 107.83 period 05 : 101.97 period 06 : 97.44 period 07 : 93.81 period 08 : 90.89 period 09 : 88.49 Model training finished. ÁâπÂæÅÁªÑÂêàÁªÑÂêà‰∏§‰∏™ÔºàÊàñÊõ¥Â§ö‰∏™ÔºâÁâπÂæÅÊòØ‰ΩøÁî®Á∫øÊÄßÊ®°ÂûãÊù•Â≠¶‰π†ÈùûÁ∫øÊÄßÂÖ≥Á≥ªÁöÑ‰∏ÄÁßçËÅ™ÊòéÂÅöÊ≥ï„ÄÇÂú®Êàë‰ª¨ÁöÑÈóÆÈ¢ò‰∏≠ÔºåÂ¶ÇÊûúÊàë‰ª¨Âè™‰ΩøÁî® latitude ÁâπÂæÅËøõË°åÂ≠¶‰π†ÔºåÈÇ£‰πàËØ•Ê®°ÂûãÂèØËÉΩ‰ºöÂèëÁé∞ÁâπÂÆöÁ∫¨Â∫¶ÔºàÊàñÁâπÂÆöÁ∫¨Â∫¶ËåÉÂõ¥ÂÜÖÔºåÂõ†‰∏∫Êàë‰ª¨Â∑≤ÁªèÂ∞ÜÂÖ∂ÂàÜÊ°∂ÔºâÁöÑÂüéÂ∏ÇË°óÂå∫Êõ¥ÂèØËÉΩÊØîÂÖ∂‰ªñË°óÂå∫‰ΩèÊàøÊàêÊú¨È´òÊòÇ„ÄÇlongitude ÁâπÂæÅÁöÑÊÉÖÂÜµ‰∏éÊ≠§Á±ª‰ºº„ÄÇ‰ΩÜÊòØÔºåÂ¶ÇÊûúÊàë‰ª¨Â∞Ü longitude ‰∏é latitude ÁªÑÂêàÔºå‰∫ßÁîüÁöÑÁªÑÂêàÁâπÂæÅÂàô‰ª£Ë°®‰∏Ä‰∏™ÊòéÁ°ÆÁöÑÂüéÂ∏ÇË°óÂå∫„ÄÇÂ¶ÇÊûúÊ®°ÂûãÂèëÁé∞Êüê‰∫õÂüéÂ∏ÇË°óÂå∫Ôºà‰Ωç‰∫éÁâπÂÆöÁ∫¨Â∫¶ÂíåÁªèÂ∫¶ËåÉÂõ¥ÂÜÖÔºâÊõ¥ÂèØËÉΩÊØîÂÖ∂‰ªñË°óÂå∫‰ΩèÊàøÊàêÊú¨È´òÊòÇÔºåÈÇ£‰πàËøôÂ∞ÜÊòØÊØîÂçïÁã¨ËÄÉËôë‰∏§‰∏™ÁâπÂæÅÊõ¥Âº∫ÁÉàÁöÑ‰ø°Âè∑„ÄÇ ÁõÆÂâçÔºåÁâπÂæÅÂàó API ‰ªÖÊîØÊåÅÁªÑÂêàÁ¶ªÊï£ÁâπÂæÅ„ÄÇË¶ÅÁªÑÂêà‰∏§‰∏™ËøûÁª≠ÁöÑÂÄºÔºàÊØîÂ¶Ç latitude Êàñ longitudeÔºâÔºåÊàë‰ª¨ÂèØ‰ª•ÂØπÂÖ∂ËøõË°åÂàÜÊ°∂„ÄÇ Â¶ÇÊûúÊàë‰ª¨ÁªÑÂêà latitude Âíå longitude ÁâπÂæÅÔºà‰æãÂ¶ÇÔºåÂÅáËÆæ longitude Ë¢´ÂàÜÂà∞ 2 ‰∏™ÂàÜÊ°∂‰∏≠ÔºåËÄå latitude Êúâ 3 ‰∏™ÂàÜÊ°∂ÔºâÔºåÊàë‰ª¨ÂÆûÈôÖ‰∏ä‰ºöÂæóÂà∞ 6 ‰∏™ÁªÑÂêàÁöÑ‰∫åÂÖÉÁâπÂæÅ„ÄÇÂΩìÊàë‰ª¨ËÆ≠ÁªÉÊ®°ÂûãÊó∂ÔºåÊØè‰∏™ÁâπÂæÅÈÉΩ‰ºöÂàÜÂà´Ëé∑ÂæóËá™Â∑±ÁöÑÊùÉÈáç„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def construct_feature_columns(): """Construct the TensorFlow Feature Columns. Returns: A set of feature columns """ households = tf.feature_column.numeric_column("households") longitude = tf.feature_column.numeric_column("longitude") latitude = tf.feature_column.numeric_column("latitude") housing_median_age = tf.feature_column.numeric_column("housing_median_age") median_income = tf.feature_column.numeric_column("median_income") rooms_per_person = tf.feature_column.numeric_column("rooms_per_person") # Divide households into 7 buckets. bucketized_households = tf.feature_column.bucketized_column( households, boundaries=get_quantile_based_boundaries( training_examples["households"], 7)) # Divide longitude into 10 buckets. bucketized_longitude = tf.feature_column.bucketized_column( longitude, boundaries=get_quantile_based_boundaries( training_examples["longitude"], 10)) # Divide latitude into 10 buckets. bucketized_latitude = tf.feature_column.bucketized_column( latitude, boundaries=get_quantile_based_boundaries( training_examples["latitude"], 10)) # Divide housing_median_age into 7 buckets. bucketized_housing_median_age = tf.feature_column.bucketized_column( housing_median_age, boundaries=get_quantile_based_boundaries( training_examples["housing_median_age"], 7)) # Divide median_income into 7 buckets. bucketized_median_income = tf.feature_column.bucketized_column( median_income, boundaries=get_quantile_based_boundaries( training_examples["median_income"], 7)) # Divide rooms_per_person into 7 buckets. bucketized_rooms_per_person = tf.feature_column.bucketized_column( rooms_per_person, boundaries=get_quantile_based_boundaries( training_examples["rooms_per_person"], 7)) # ‰∏∫long_x_lat feature crossÂÅö‰∏Ä‰∏™ÁâπÊÄßÂàó long_x_lat = tf.feature_column.crossed_column( set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000) feature_columns = set([ bucketized_longitude, bucketized_latitude, bucketized_housing_median_age, bucketized_households, bucketized_median_income, bucketized_rooms_per_person, long_x_lat]) return feature_columns 123456789_ = train_model( learning_rate=1.0, steps=500, batch_size=100, feature_columns=construct_feature_columns(), training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 163.99 period 01 : 135.79 period 02 : 118.69 period 03 : 107.28 period 04 : 99.33 period 05 : 93.53 period 06 : 89.03 period 07 : 85.54 period 08 : 82.65 period 09 : 80.32 Model training finished.]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 5]]></title>
    <url>%2F2019%2F01%2F09%2FTensorFlow_5%2F</url>
    <content type="text"><![CDATA[Ë°®Á§∫Ê≥ïÔºàRepresentationÔºâÊú∫Âô®Â≠¶‰π†Ê®°Âûã‰∏çËÉΩÁõ¥Êé•ÁúãÂà∞„ÄÅÂê¨Âà∞ÊàñÊÑüÁü•ËæìÂÖ•Ê†∑Êú¨„ÄÇÂøÖÈ°ªÂàõÂª∫Êï∞ÊçÆË°®Á§∫Ôºå‰∏∫Ê®°ÂûãÊèê‰æõÊúâÁî®ÁöÑ‰ø°Âè∑Êù•‰∫ÜËß£Êï∞ÊçÆÁöÑÂÖ≥ÈîÆÁâπÊÄß„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰∏∫‰∫ÜËÆ≠ÁªÉÊ®°ÂûãÔºåÂøÖÈ°ªÈÄâÊã©ÊúÄËÉΩ‰ª£Ë°®Êï∞ÊçÆÁöÑÁâπÂæÅÈõÜ„ÄÇ ÁâπÂæÅÂ∑•Á®ã‰º†ÁªüÁºñÁ®ãÁöÑÂÖ≥Ê≥®ÁÇπÊòØ‰ª£Á†Å„ÄÇÂú®Êú∫Âô®Â≠¶‰π†È°πÁõÆ‰∏≠ÔºåÂÖ≥Ê≥®ÁÇπÂèòÊàê‰∫ÜË°®Á§∫„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂºÄÂèëËÄÖÈÄöËøáÊ∑ªÂä†ÂíåÊîπÂñÑÁâπÂæÅÊù•Ë∞ÉÊï¥Ê®°Âûã„ÄÇ Â∞ÜÂéüÂßãÊï∞ÊçÆÊò†Â∞ÑÂà∞ÁâπÂæÅ‰∏ãÂõæÂ∑¶‰æßËæπÊòØÊù•Ëá™Êï∞ÊçÆÊ∫êÁöÑÂéüÂßãÊï∞ÊçÆÔºåÂè≥‰æßË°®Á§∫ÁâπÂæÅÁü¢ÈáèÔºå‰πüÂ∞±ÊòØÁªÑÊàêÊï∞ÊçÆÈõÜ‰∏≠Ê†∑Êú¨ÁöÑÊµÆÁÇπÂÄºÈõÜ„ÄÇ ÁâπÂæÅÂ∑•Á®ãÊåáÁöÑÊòØÂ∞ÜÂéüÂßãÊï∞ÊçÆËΩ¨Êç¢‰∏∫ÁâπÂæÅÁü¢Èáè„ÄÇËøõË°åÁâπÂæÅÂ∑•Á®ãÈ¢ÑËÆ°ÈúÄË¶ÅÂ§ßÈáèÊó∂Èó¥„ÄÇ Êú∫Âô®Â≠¶‰π†Ê®°ÂûãÈÄöÂ∏∏ÊúüÊúõÊ†∑Êú¨Ë°®Á§∫‰∏∫ÂÆûÊï∞Áü¢Èáè„ÄÇËøôÁßçÁü¢ÈáèÁöÑÊûÑÂª∫ÊñπÊ≥ïÂ¶Ç‰∏ãÔºö‰∏∫ÊØè‰∏™Â≠óÊÆµË°çÁîüÁâπÂæÅÔºåÁÑ∂ÂêéÂ∞ÜÂÆÉ‰ª¨ÂÖ®ÈÉ®ËøûÊé•Âà∞‰∏ÄËµ∑ Êò†Â∞ÑÊï∞ÂÄºÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÊ†πÊçÆÊµÆÁÇπÂÄºËøõË°åËÆ≠ÁªÉÔºåÂõ†Ê≠§Êï¥Êï∞ÂíåÊµÆÁÇπÂéüÂßãÊï∞ÊçÆ‰∏çÈúÄË¶ÅÁâπÊÆäÁºñÁ†Å„ÄÇÊ≠£Â¶Ç‰∏ãÂõæ ÊâÄÁ§∫ÔºåÂ∞ÜÂéüÂßãÊï¥Êï∞ÂÄº 6 ËΩ¨Êç¢‰∏∫ÁâπÂæÅÂÄº 6.0 ÊòØÊ≤°ÊúâÊÑè‰πâÁöÑÔºö Êò†Â∞ÑÂ≠óÁ¨¶‰∏≤ÂÄºÊ®°ÂûãÊó†Ê≥ïÈÄöËøáÂ≠óÁ¨¶‰∏≤ÂÄºÂ≠¶‰π†ËßÑÂæãÔºåÂõ†Ê≠§ÊÇ®ÈúÄË¶ÅËøõË°å‰∏Ä‰∫õÁâπÂæÅÂ∑•Á®ãÊù•Â∞ÜËøô‰∫õÂÄºËΩ¨Êç¢‰∏∫Êï∞Â≠óÂΩ¢ÂºèÔºö 1.È¶ñÂÖàÔºå‰∏∫ÊÇ®Ë¶ÅË°®Á§∫ÁöÑÊâÄÊúâÁâπÂæÅÁöÑÂ≠óÁ¨¶‰∏≤ÂÄºÂÆö‰πâ‰∏Ä‰∏™ËØçÊ±áË°®„ÄÇÂØπ‰∫é street_name ÁâπÂæÅÔºåËØ•ËØçÊ±áË°®‰∏≠Â∞ÜÂåÖÂê´ÊÇ®Áü•ÈÅìÁöÑÊâÄÊúâË°óÈÅì„ÄÇ 2.ÁÑ∂ÂêéÔºå‰ΩøÁî®ËØ•ËØçÊ±áË°®ÂàõÂª∫‰∏Ä‰∏™Áã¨ÁÉ≠ÁºñÁ†ÅÔºåÁî®‰∫éÂ∞ÜÊåáÂÆöÂ≠óÁ¨¶‰∏≤ÂÄºË°®Á§∫‰∏∫‰∫åÂÖÉÁü¢Èáè„ÄÇÂú®ËØ•Áü¢ÈáèÔºà‰∏éÊåáÂÆöÁöÑÂ≠óÁ¨¶‰∏≤ÂÄºÂØπÂ∫îÔºâ‰∏≠Ôºö ¬∑Âè™Êúâ‰∏Ä‰∏™ÂÖÉÁ¥†ËÆæ‰∏∫ 1„ÄÇ ¬∑ÂÖ∂‰ªñÊâÄÊúâÂÖÉÁ¥†ÂùáËÆæ‰∏∫ 0„ÄÇ ¬∑ËØ•Áü¢ÈáèÁöÑÈïøÂ∫¶Á≠â‰∫éËØçÊ±áË°®‰∏≠ÁöÑÂÖÉÁ¥†Êï∞„ÄÇ ‰∏ãÂõæÊòæÁ§∫‰∫ÜÊüêÊù°ÁâπÂÆöË°óÈÅì (Shorebird Way) ÁöÑÁã¨ÁÉ≠ÁºñÁ†Å„ÄÇÂú®Ê≠§‰∫åÂÖÉÁü¢Èáè‰∏≠Ôºå‰ª£Ë°® Shorebird Way ÁöÑÂÖÉÁ¥†ÁöÑÂÄº‰∏∫ 1ÔºåËÄå‰ª£Ë°®ÊâÄÊúâÂÖ∂‰ªñË°óÈÅìÁöÑÂÖÉÁ¥†ÁöÑÂÄº‰∏∫ Œ∏„ÄÇ Êò†Â∞ÑÂàÜÁ±ªÔºàÊûö‰∏æÔºâÂÄºÂàÜÁ±ªÁâπÂæÅÂÖ∑Êúâ‰∏ÄÁªÑÁ¶ªÊï£ÁöÑÂèØËÉΩÂÄº„ÄÇ‰æãÂ¶ÇÔºåÂêç‰∏∫ Lowland Countries ÁöÑÁâπÂæÅÂè™ÂåÖÂê´ 3 ‰∏™ÂèØËÉΩÂÄºÔºö {&apos;Netherlands&apos;, &apos;Belgium&apos;, &apos;Luxembourg&apos;} ÊÇ®ÂèØËÉΩ‰ºöÂ∞ÜÂàÜÁ±ªÁâπÂæÅÔºàÂ¶Ç Lowland CountriesÔºâÁºñÁ†Å‰∏∫Êûö‰∏æÁ±ªÂûãÊàñË°®Á§∫‰∏çÂêåÂÄºÁöÑÊï¥Êï∞Á¶ªÊï£ÈõÜ„ÄÇ‰æãÂ¶ÇÔºö Â∞ÜËç∑ÂÖ∞Ë°®Á§∫‰∏∫ 0 Â∞ÜÊØîÂà©Êó∂Ë°®Á§∫‰∏∫ 1 Â∞ÜÂç¢Ê£ÆÂ†°Ë°®Á§∫‰∏∫ 2 ‰∏çËøáÔºåÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÈÄöÂ∏∏Â∞ÜÊØè‰∏™ÂàÜÁ±ªÁâπÂæÅË°®Á§∫‰∏∫ÂçïÁã¨ÁöÑÂ∏ÉÂ∞îÂÄº„ÄÇ‰æãÂ¶ÇÔºåLowland Countries Âú®Ê®°Âûã‰∏≠ÂèØ‰ª•Ë°®Á§∫‰∏∫ 3 ‰∏™ÂçïÁã¨ÁöÑÂ∏ÉÂ∞îÂÄºÁâπÂæÅÔºö x1ÔºöÊòØËç∑ÂÖ∞ÂêóÔºü x2ÔºöÊòØÊØîÂà©Êó∂ÂêóÔºü x3ÔºöÊòØÂç¢Ê£ÆÂ†°ÂêóÔºü ÈááÁî®ËøôÁßçÊñπÊ≥ïÁºñÁ†ÅËøòÂèØ‰ª•ÁÆÄÂåñÊüê‰∏™ÂÄºÂèØËÉΩÂ±û‰∫éÂ§ö‰∏™ÂàÜÁ±ªËøôÁßçÊÉÖÂÜµÔºà‰æãÂ¶ÇÔºå‚Äú‰∏éÊ≥ïÂõΩÊé•Â£§‚ÄùÂØπ‰∫éÊØîÂà©Êó∂ÂíåÂç¢Ê£ÆÂ†°Êù•ËØ¥ÈÉΩÊòØ TrueÔºâ„ÄÇ ËâØÂ•ΩÁâπÂæÅÁöÑÁâπÁÇπÊàë‰ª¨Êé¢Á¥¢‰∫ÜÂ∞ÜÂéüÂßãÊï∞ÊçÆÊò†Â∞ÑÂà∞ÂêàÈÄÇÁâπÂæÅÁü¢ÈáèÁöÑÊñπÊ≥ïÔºå‰ΩÜËøôÂè™ÊòØÂ∑•‰ΩúÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÁé∞Âú®ÔºåÊàë‰ª¨ÂøÖÈ°ªÊé¢Á¥¢‰ªÄ‰πàÊ†∑ÁöÑÂÄºÊâçÁÆóËøô‰∫õÁâπÂæÅÁü¢Èáè‰∏≠ËâØÂ•ΩÁöÑÁâπÂæÅ„ÄÇ ÈÅøÂÖçÂæàÂ∞ë‰ΩøÁî®ÁöÑÁ¶ªÊï£ÁâπÂæÅÂÄºËâØÂ•ΩÁöÑÁâπÂæÅÂÄºÂ∫îËØ•Âú®Êï∞ÊçÆÈõÜ‰∏≠Âá∫Áé∞Â§ßÁ∫¶ 5 Ê¨°‰ª•‰∏ä„ÄÇËøôÊ†∑‰∏ÄÊù•ÔºåÊ®°ÂûãÂ∞±ÂèØ‰ª•Â≠¶‰π†ËØ•ÁâπÂæÅÂÄº‰∏éÊ†áÁ≠æÊòØÂ¶Ç‰ΩïÂÖ≥ËÅîÁöÑ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂ§ßÈáèÁ¶ªÊï£ÂÄºÁõ∏ÂêåÁöÑÊ†∑Êú¨ÂèØËÆ©Ê®°ÂûãÊúâÊú∫‰ºö‰∫ÜËß£‰∏çÂêåËÆæÁΩÆ‰∏≠ÁöÑÁâπÂæÅÔºå‰ªéËÄåÂà§Êñ≠‰ΩïÊó∂ÂèØ‰ª•ÂØπÊ†áÁ≠æÂæàÂ•ΩÂú∞ÂÅöÂá∫È¢ÑÊµã„ÄÇ ‰æãÂ¶ÇÔºåhouse_type ÁâπÂæÅÂèØËÉΩÂåÖÂê´Â§ßÈáèÊ†∑Êú¨ÔºåÂÖ∂‰∏≠ÂÆÉÁöÑÂÄº‰∏∫ victorianÔºö house_type: victorian Áõ∏ÂèçÔºåÂ¶ÇÊûúÊüê‰∏™ÁâπÂæÅÁöÑÂÄº‰ªÖÂá∫Áé∞‰∏ÄÊ¨°ÊàñËÄÖÂæàÂ∞ëÂá∫Áé∞ÔºåÂàôÊ®°ÂûãÂ∞±Êó†Ê≥ïÊ†πÊçÆËØ•ÁâπÂæÅËøõË°åÈ¢ÑÊµã„ÄÇ ‰æãÂ¶ÇÔºåunique_house_id Â∞±‰∏çÈÄÇÂêà‰Ωú‰∏∫ÁâπÂæÅÔºåÂõ†‰∏∫ÊØè‰∏™ÂÄºÂè™‰ΩøÁî®‰∏ÄÊ¨°ÔºåÊ®°ÂûãÊó†Ê≥ï‰ªé‰∏≠Â≠¶‰π†‰ªª‰ΩïËßÑÂæãÔºö unique_house_id: 8SK982ZZ1242Z ÊúÄÂ•ΩÂÖ∑ÊúâÊ∏ÖÊô∞ÊòéÁ°ÆÁöÑÂê´‰πâÊØè‰∏™ÁâπÂæÅÂØπ‰∫éÈ°πÁõÆ‰∏≠ÁöÑ‰ªª‰Ωï‰∫∫Êù•ËØ¥ÈÉΩÂ∫îËØ•ÂÖ∑ÊúâÊ∏ÖÊô∞ÊòéÁ°ÆÁöÑÂê´‰πâ„ÄÇ ‰æãÂ¶ÇÔºå‰∏ãÈù¢ÁöÑÊàøÈæÑÈÄÇÂêà‰Ωú‰∏∫ÁâπÂæÅÔºåÂèØÁ´ãÂç≥ËØÜÂà´‰∏∫Âπ¥ÈæÑÔºö house_age: 27 Áõ∏ÂèçÔºåÂØπ‰∫é‰∏ãÊñπÁâπÂæÅÂÄºÁöÑÂê´‰πâÔºåÈô§‰∫ÜÂàõÂª∫ÂÆÉÁöÑÂ∑•Á®ãÂ∏àÔºåÂÖ∂‰ªñ‰∫∫ÊÅêÊÄïËæ®ËØÜ‰∏çÂá∫Ôºö house_age: 851472000 Âú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÊ∑∑‰π±ÁöÑÊï∞ÊçÆÔºàËÄå‰∏çÊòØÁ≥üÁ≥ïÁöÑÂ∑•Á®ãÈÄâÊã©Ôºâ‰ºöÂØºËá¥Âê´‰πâ‰∏çÊ∏ÖÊô∞ÁöÑÂÄº„ÄÇ ‰æãÂ¶ÇÔºå‰ª•‰∏ã user_age ÁöÑÊù•Ê∫êÊ≤°ÊúâÊ£ÄÊü•ÂÄºÊÅ∞ÂΩì‰∏éÂê¶Ôºö user_age: 277 ‰∏çË¶ÅÂ∞Ü‚ÄúÁ•ûÂ•á‚ÄùÁöÑÂÄº‰∏éÂÆûÈôÖÊï∞ÊçÆÊ∑∑‰∏∫‰∏ÄË∞àËâØÂ•ΩÁöÑÊµÆÁÇπÁâπÂæÅ‰∏çÂåÖÂê´Ë∂ÖÂá∫ËåÉÂõ¥ÁöÑÂºÇÂ∏∏Êñ≠ÁÇπÊàñ‚ÄúÁ•ûÂ•á‚ÄùÁöÑÂÄº„ÄÇ ‰æãÂ¶ÇÔºåÂÅáËÆæ‰∏Ä‰∏™ÁâπÂæÅÂÖ∑Êúâ 0 Âà∞ 1 ‰πãÈó¥ÁöÑÊµÆÁÇπÂÄº„ÄÇÈÇ£‰πàÔºåÂ¶Ç‰∏ãÂÄºÊòØÂèØ‰ª•Êé•ÂèóÁöÑÔºö quality_rating: 0.82 quality_rating: 0.37 ‰∏çËøáÔºåÂ¶ÇÊûúÁî®Êà∑Ê≤°ÊúâËæìÂÖ• quality_ratingÔºåÂàôÊï∞ÊçÆÈõÜÂèØËÉΩ‰ΩøÁî®Â¶Ç‰∏ãÁ•ûÂ•áÂÄºÊù•Ë°®Á§∫‰∏çÂ≠òÂú®ËØ•ÂÄºÔºö quality_rating: -1 ‰∏∫Ëß£ÂÜ≥Á•ûÂ•áÂÄºÁöÑÈóÆÈ¢òÔºåÈúÄÂ∞ÜËØ•ÁâπÂæÅËΩ¨Êç¢‰∏∫‰∏§‰∏™ÁâπÂæÅÔºö ‰∏Ä‰∏™ÁâπÂæÅÂè™Â≠òÂÇ®Ë¥®ÈáèËØÑÂàÜÔºå‰∏çÂê´Á•ûÂ•áÂÄº„ÄÇ ‰∏Ä‰∏™ÁâπÂæÅÂ≠òÂÇ®Â∏ÉÂ∞îÂÄºÔºåË°®Á§∫ÊòØÂê¶Êèê‰æõ‰∫Ü quality_rating„ÄÇ‰∏∫ËØ•Â∏ÉÂ∞îÂÄºÁâπÂæÅÊåáÂÆö‰∏Ä‰∏™ÂêçÁß∞Ôºå‰æãÂ¶Ç is_quality_rating_defined„ÄÇ ËÄÉËôë‰∏äÊ∏∏‰∏çÁ®≥ÂÆöÊÄßÁâπÂæÅÁöÑÂÆö‰πâ‰∏çÂ∫îÈöèÊó∂Èó¥ÂèëÁîüÂèòÂåñ„ÄÇ ‰æãÂ¶ÇÔºå‰∏ãÂàóÂÄºÊòØÊúâÁî®ÁöÑÔºåÂõ†‰∏∫ÂüéÂ∏ÇÂêçÁß∞‰∏ÄËà¨‰∏ç‰ºöÊîπÂèò„ÄÇÔºàÊ≥®ÊÑèÔºåÊàë‰ª¨‰ªçÁÑ∂ÈúÄË¶ÅÂ∞Ü‚Äúbr/sao_paulo‚ÄùËøôÊ†∑ÁöÑÂ≠óÁ¨¶‰∏≤ËΩ¨Êç¢‰∏∫Áã¨ÁÉ≠Áü¢Èáè„ÄÇÔºâ city_id: &quot;br/sao_paulo&quot; ‰ΩÜÊî∂ÈõÜÁî±ÂÖ∂‰ªñÊ®°ÂûãÊé®ÁêÜÁöÑÂÄº‰ºö‰∫ßÁîüÈ¢ùÂ§ñÊàêÊú¨„ÄÇÂèØËÉΩÂÄº‚Äú219‚ÄùÁõÆÂâç‰ª£Ë°®Âú£‰øùÁΩóÔºå‰ΩÜËøôÁßçË°®Á§∫Âú®Êú™Êù•ËøêË°åÂÖ∂‰ªñÊ®°ÂûãÊó∂ÂèØËÉΩËΩªÊòìÂèëÁîüÂèòÂåñÔºö inferred_city_cluster: &quot;219&quot; Êï∞ÊçÆÊ∏ÖÁêÜËãπÊûúÊ†ëÁªìÂá∫ÁöÑÊûúÂ≠êÊúâÂìÅÁõ∏‰∏ä‰πòÁöÑÔºå‰πüÊúâËô´ËõÄÂùèÊûú„ÄÇËÄåÈ´òÁ´Ø‰æøÂà©Â∫óÂá∫ÂîÆÁöÑËãπÊûúÊòØ 100% ÂÆåÁæéÁöÑÊ∞¥Êûú„ÄÇ‰ªéÊûúÂõ≠Âà∞Ê∞¥ÊûúÂ∫ó‰πãÈó¥Ôºå‰∏ìÈó®Êúâ‰∫∫Ëä±Ë¥πÂ§ßÈáèÊó∂Èó¥Â∞ÜÂùèËãπÊûúÂâîÈô§ÊàñÁªôÂèØ‰ª•ÊåΩÊïëÁöÑËãπÊûúÊ∂Ç‰∏ä‰∏ÄÂ±ÇËñÑËñÑÁöÑËú°„ÄÇ‰Ωú‰∏∫‰∏ÄÂêçÊú∫Âô®Â≠¶‰π†Â∑•Á®ãÂ∏àÔºåÊÇ®Â∞ÜËä±Ë¥πÂ§ßÈáèÁöÑÊó∂Èó¥ÊåëÂá∫ÂùèÊ†∑Êú¨Âπ∂Âä†Â∑•ÂèØ‰ª•ÊåΩÊïëÁöÑÊ†∑Êú¨„ÄÇÂç≥‰ΩøÊòØÈùûÂ∏∏Â∞ëÈáèÁöÑ‚ÄúÂùèËãπÊûú‚Äù‰πü‰ºöÁ†¥ÂùèÊéâ‰∏Ä‰∏™Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜ„ÄÇ Áº©ÊîæÁâπÂæÅÂÄºÁº©ÊîæÊòØÊåáÂ∞ÜÊµÆÁÇπÁâπÂæÅÂÄº‰ªéËá™ÁÑ∂ËåÉÂõ¥Ôºà‰æãÂ¶Ç 100 Âà∞ 900ÔºâËΩ¨Êç¢‰∏∫Ê†áÂáÜËåÉÂõ¥Ôºà‰æãÂ¶Ç 0 Âà∞ 1 Êàñ -1 Âà∞ +1Ôºâ„ÄÇÂ¶ÇÊûúÊüê‰∏™ÁâπÂæÅÈõÜÂè™ÂåÖÂê´‰∏Ä‰∏™ÁâπÂæÅÔºåÂàôÁº©ÊîæÂèØ‰ª•Êèê‰æõÁöÑÂÆûÈôÖÂ•ΩÂ§ÑÂæÆ‰πéÂÖ∂ÂæÆÊàñÊ†πÊú¨Ê≤°Êúâ„ÄÇ‰∏çËøáÔºåÂ¶ÇÊûúÁâπÂæÅÈõÜÂåÖÂê´Â§ö‰∏™ÁâπÂæÅÔºåÂàôÁº©ÊîæÁâπÂæÅÂèØ‰ª•Â∏¶Êù•‰ª•‰∏ã‰ºòÂäøÔºö ¬∑Â∏ÆÂä©Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÊõ¥Âø´ÈÄüÂú∞Êî∂Êïõ„ÄÇ ¬∑Â∏ÆÂä©ÈÅøÂÖç‚ÄúNaN Èô∑Èò±‚Äù„ÄÇÂú®ËøôÁßçÈô∑Èò±‰∏≠ÔºåÊ®°Âûã‰∏≠ÁöÑ‰∏Ä‰∏™Êï∞ÂÄºÂèòÊàê NaNÔºà‰æãÂ¶ÇÔºåÂΩìÊüê‰∏™ÂÄºÂú®ËÆ≠ÁªÉÊúüÈó¥Ë∂ÖÂá∫ÊµÆÁÇπÁ≤æÁ°ÆÁéáÈôêÂà∂Êó∂ÔºâÔºåÂπ∂‰∏îÊ®°Âûã‰∏≠ÁöÑÊâÄÊúâÂÖ∂‰ªñÊï∞ÂÄºÊúÄÁªà‰πü‰ºöÂõ†Êï∞Â≠¶ËøêÁÆóËÄåÂèòÊàê NaN„ÄÇ ¬∑Â∏ÆÂä©Ê®°Âûã‰∏∫ÊØè‰∏™ÁâπÂæÅÁ°ÆÂÆöÂêàÈÄÇÁöÑÊùÉÈáç„ÄÇÂ¶ÇÊûúÊ≤°ÊúâËøõË°åÁâπÂæÅÁº©ÊîæÔºåÂàôÊ®°Âûã‰ºöÂØπËåÉÂõ¥ËæÉÂ§ßÁöÑÁâπÂæÅÊäïÂÖ•ËøáÂ§öÁ≤æÂäõ„ÄÇ ÊÇ®‰∏çÈúÄË¶ÅÂØπÊØè‰∏™ÊµÆÁÇπÁâπÂæÅËøõË°åÂÆåÂÖ®Áõ∏ÂêåÁöÑÁº©Êîæ„ÄÇÂç≥‰ΩøÁâπÂæÅ A ÁöÑËåÉÂõ¥ÊòØ -1 Âà∞ +1ÔºåÂêåÊó∂ÁâπÂæÅ B ÁöÑËåÉÂõ¥ÊòØ -3 Âà∞ +3Ôºå‰πü‰∏ç‰ºö‰∫ßÁîü‰ªÄ‰πàÊÅ∂Âä£ÁöÑÂΩ±Âìç„ÄÇ‰∏çËøáÔºåÂ¶ÇÊûúÁâπÂæÅ B ÁöÑËåÉÂõ¥ÊòØ 5000 Âà∞ 100000ÔºåÊÇ®ÁöÑÊ®°Âûã‰ºöÂá∫Áé∞Á≥üÁ≥ïÁöÑÂìçÂ∫î„ÄÇ 1234567891011121314151617Ë¶ÅÁº©ÊîæÊï∞Â≠óÊï∞ÊçÆÔºå‰∏ÄÁßçÊòæËÄåÊòìËßÅÁöÑÊñπÊ≥ïÊòØÂ∞Ü [ÊúÄÂ∞èÂÄºÔºåÊúÄÂ§ßÂÄº] ‰ª•Á∫øÊÄßÊñπÂºèÊò†Â∞ÑÂà∞ËæÉÂ∞èÁöÑËåÉÂõ¥Ôºå‰æãÂ¶Ç [-1Ôºå+1]„ÄÇÂè¶‰∏ÄÁßçÁÉ≠Èó®ÁöÑÁº©ÊîæÁ≠ñÁï•ÊòØËÆ°ÁÆóÊØè‰∏™ÂÄºÁöÑ Z ÂæóÂàÜ„ÄÇZ ÂæóÂàÜ‰∏éË∑ùÁ¶ªÂùáÂÄºÁöÑÊ†áÂáÜÂÅèÂ∑ÆÊï∞Áõ∏ÂÖ≥„ÄÇÊç¢ËÄåË®Ä‰πãÔºö scaled value = (value - mean) / stddev ‰æãÂ¶ÇÔºåÁªôÂÆö‰ª•‰∏ãÊù°‰ª∂Ôºö ¬∑ÂùáÂÄº = 100 ¬∑Ê†áÂáÜÂÅèÂ∑Æ = 20 ¬∑ÂéüÂßãÂÄº = 130 ÂàôÔºö scaled_value = (130 - 100) / 20 scaled_value = 1.5‰ΩøÁî® Z ÂæóÂàÜËøõË°åÁº©ÊîæÊÑèÂë≥ÁùÄÔºåÂ§ßÂ§öÊï∞Áº©ÊîæÂêéÁöÑÂÄºÂ∞Ü‰ªã‰∫é -3 Âíå +3 ‰πãÈó¥ÔºåËÄåÂ∞ëÈáèÂÄºÂ∞ÜÁï•È´ò‰∫éÊàñ‰Ωé‰∫éËØ•ËåÉÂõ¥„ÄÇ Â§ÑÁêÜÊûÅÁ´ØÁ¶ªÁæ§ÂÄºÂàÜÁÆ± Ê∏ÖÊü•Êà™Ëá≥ÁõÆÂâçÔºåÊàë‰ª¨ÂÅáÂÆöÁî®‰∫éËÆ≠ÁªÉÂíåÊµãËØïÁöÑÊâÄÊúâÊï∞ÊçÆÈÉΩÊòØÂÄºÂæó‰ø°ËµñÁöÑ„ÄÇÂú®Áé∞ÂÆûÁîüÊ¥ª‰∏≠ÔºåÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÂæàÂ§öÊ†∑Êú¨ÊòØ‰∏çÂèØÈù†ÁöÑÔºåÂéüÂõ†Êúâ‰ª•‰∏ã‰∏ÄÁßçÊàñÂ§öÁßçÔºö ÈÅóÊºèÂÄº„ÄÇ ‰æãÂ¶ÇÔºåÊúâ‰∫∫ÂøòËÆ∞‰∏∫Êüê‰∏™ÊàøÂ±ãÁöÑÂπ¥ÈæÑËæìÂÖ•ÂÄº„ÄÇ ÈáçÂ§çÊ†∑Êú¨„ÄÇ ‰æãÂ¶ÇÔºåÊúçÂä°Âô®ÈîôËØØÂú∞Â∞ÜÂêå‰∏ÄÊù°ËÆ∞ÂΩï‰∏ä‰º†‰∫Ü‰∏§Ê¨°„ÄÇ ‰∏çËâØÊ†áÁ≠æ„ÄÇ ‰æãÂ¶ÇÔºåÊúâ‰∫∫ÈîôËØØÂú∞Â∞Ü‰∏ÄÈ¢óÊ©°Ê†ëÁöÑÂõæÁâáÊ†áËÆ∞‰∏∫Êû´Ê†ë„ÄÇ ‰∏çËâØÁâπÂæÅÂÄº„ÄÇ ‰æãÂ¶ÇÔºåÊúâ‰∫∫ËæìÂÖ•‰∫ÜÂ§ö‰ΩôÁöÑ‰ΩçÊï∞ÔºåÊàñËÄÖÊ∏©Â∫¶ËÆ°Ë¢´ÈÅóËêΩÂú®Â§™Èò≥Â∫ï‰∏ã„ÄÇ ‰∏ÄÊó¶Ê£ÄÊµãÂà∞Â≠òÂú®Ëøô‰∫õÈóÆÈ¢òÔºåÊÇ®ÈÄöÂ∏∏ÈúÄË¶ÅÂ∞ÜÁõ∏Â∫îÊ†∑Êú¨‰ªéÊï∞ÊçÆÈõÜ‰∏≠ÁßªÈô§Ôºå‰ªéËÄå‚Äú‰øÆÊ≠£‚Äù‰∏çËâØÊ†∑Êú¨„ÄÇË¶ÅÊ£ÄÊµãÈÅóÊºèÂÄºÊàñÈáçÂ§çÊ†∑Êú¨ÔºåÂèØ‰ª•ÁºñÂÜô‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ®ãÂ∫è„ÄÇÊ£ÄÊµã‰∏çËâØÁâπÂæÅÂÄºÊàñÊ†áÁ≠æÂèØËÉΩ‰ºöÊØîËæÉÊ£òÊâã„ÄÇ Èô§‰∫ÜÊ£ÄÊµãÂêÑ‰∏™‰∏çËâØÊ†∑Êú¨‰πãÂ§ñÔºåËøòÂøÖÈ°ªÊ£ÄÊµãÈõÜÂêà‰∏≠ÁöÑ‰∏çËâØÊï∞ÊçÆ„ÄÇÁõ¥ÊñπÂõæÊòØ‰∏ÄÁßçÁî®‰∫éÂèØËßÜÂåñÈõÜÂêà‰∏≠Êï∞ÊçÆÁöÑÂæàÂ•ΩÊú∫Âà∂„ÄÇÊ≠§Â§ñÔºåÊî∂ÈõÜÂ¶Ç‰∏ãÁªüËÆ°‰ø°ÊÅØ‰πü‰ºöÊúâÊâÄÂ∏ÆÂä©Ôºö ÊúÄÂ§ßÂÄºÂíåÊúÄÂ∞èÂÄº ÂùáÂÄºÂíå‰∏≠Èó¥ÂÄº Ê†áÂáÜÂÅèÂ∑Æ ËÄÉËôëÁîüÊàêÁ¶ªÊï£ÁâπÂæÅÁöÑÊúÄÂ∏∏ËßÅÂÄºÂàóË°®„ÄÇ‰æãÂ¶ÇÔºåcountry:uk ÁöÑÊ†∑Êú¨Êï∞ÊòØÂê¶Á¨¶ÂêàÊÇ®ÁöÑÈ¢ÑÊúüÔºülanguage:jp ÊòØÂê¶ÁúüÁöÑÂ∫îËØ•‰Ωú‰∏∫ÊÇ®Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÊúÄÂ∏∏Áî®ËØ≠Ë®ÄÔºü ‰∫ÜËß£Êï∞ÊçÆ ÈÅµÂæ™‰ª•‰∏ãËßÑÂàôÔºö ËÆ∞‰ΩèÈ¢ÑÊúüÁöÑÊï∞ÊçÆÁä∂ÊÄÅ„ÄÇ Á°ÆËÆ§Êï∞ÊçÆÊòØÂê¶Êª°Ë∂≥Ëøô‰∫õÈ¢ÑÊúüÔºàÊàñËÄÖÊÇ®ÂèØ‰ª•Ëß£Èáä‰∏∫‰ΩïÊï∞ÊçÆ‰∏çÊª°Ë∂≥È¢ÑÊúüÔºâ„ÄÇ ‰ªîÁªÜÊ£ÄÊü•ËÆ≠ÁªÉÊï∞ÊçÆÊòØÂê¶‰∏éÂÖ∂‰ªñÊù•Ê∫êÔºà‰æãÂ¶Ç‰ø°ÊÅØ‰∏≠ÂøÉÔºâÁöÑÊï∞ÊçÆ‰∏ÄËá¥„ÄÇ ÂÉèÂ§ÑÁêÜ‰ªª‰Ωï‰ªªÂä°ÂÖ≥ÈîÆÂûã‰ª£Á†Å‰∏ÄÊ†∑Ë∞®ÊÖéÂ§ÑÁêÜÊÇ®ÁöÑÊï∞ÊçÆ„ÄÇËâØÂ•ΩÁöÑÊú∫Âô®Â≠¶‰π†‰æùËµñ‰∫éËâØÂ•ΩÁöÑÊï∞ÊçÆ„ÄÇ ÁâπÂæÅÈõÜÁºñÁ®ãÁªÉ‰π†ÂàõÂª∫‰∏Ä‰∏™ÂåÖÂê´ÊûÅÂ∞ëÁâπÂæÅ‰ΩÜÊïàÊûú‰∏éÊõ¥Â§çÊùÇÁöÑÁâπÂæÅÈõÜ‰∏ÄÊ†∑Âá∫Ëâ≤ÁöÑÈõÜÂêà ËÆæÁΩÆÂíå‰πãÂâç‰∏ÄÊ†∑ÔºåÊàë‰ª¨ÂÖàÂä†ËΩΩÂπ∂ÂáÜÂ§áÂä†Âà©Á¶èÂ∞º‰∫öÂ∑û‰ΩèÊàøÊï∞ÊçÆ„ÄÇ 12345678910111213141516171819202122from __future__ import print_functionimport mathfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10pd.options.display.float_format = '&#123;:.1f&#125;'.formatcalifornia_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",")california_housing_dataframe = california_housing_dataframe.reindex( np.random.permutation(california_housing_dataframe.index)) 12345678910111213141516171819202122232425# È¢ÑÂ§ÑÁêÜdef preprocess_features(california_housing_dataframe): selected_features = california_housing_dataframe[ ["latitude", "longitude", "housing_median_age", "total_rooms", "total_bedrooms", "population", "households", "median_income"]] processed_features = selected_features.copy() processed_features["rooms_per_person"] = ( california_housing_dataframe["total_rooms"]/ california_housing_dataframe["population"]) return processed_featuresdef preprocess_targets(california_housing_dataframe): output_targets = pd.DataFrame() # Scale the target to be in units of thousands of dollars. output_targets["median_house_value"] = ( california_housing_dataframe["median_house_value"] / 1000.0) return output_targets 123456789101112131415161718# ÊäΩÂèñÂâç 12000 ‰∏™Êï∞ÊçÆ‰ΩúËÆ≠ÁªÉÈõÜtraining_examples = preprocess_features(california_housing_dataframe.head(12000))training_targets = preprocess_targets(california_housing_dataframe.head(12000))# ÊäΩÂèñÊúÄÂêé 5000 ‰∏™‰ΩúÈ™åËØÅÈõÜvalidation_examples = preprocess_features(california_housing_dataframe.tail(5000))validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))# Ê£ÄÊü•‰∏Ä‰∏ãÊàë‰ª¨ÁöÑÊï∞ÊçÆÊòØÂê¶Ê≠£Â∏∏ÂêàÁêÜprint("Training examples summary:")display.display(training_examples.describe())print("Validation examples summary:")display.display(validation_examples.describe())print("Training targets summary:")display.display(training_targets.describe())print("Validation targets summary:")display.display(validation_targets.describe()) Training examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 mean 35.6 -119.6 28.6 2655.8 543.1 1433.2 504.6 3.9 2.0 std 2.1 2.0 12.6 2180.4 425.2 1122.9 387.0 1.9 1.1 min 32.5 -124.3 2.0 2.0 1.0 3.0 1.0 0.5 0.1 25% 33.9 -121.8 18.0 1467.0 298.0 793.0 283.0 2.6 1.5 50% 34.2 -118.5 29.0 2127.0 435.0 1170.0 410.0 3.5 1.9 75% 37.7 -118.0 37.0 3157.2 653.0 1726.0 608.0 4.8 2.3 max 42.0 -114.6 52.0 32627.0 6445.0 28566.0 6082.0 15.0 55.2 Validation examples summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 mean 35.7 -119.6 28.6 2614.5 530.5 1420.8 493.0 3.9 2.0 std 2.1 2.0 12.6 2178.9 412.5 1205.6 378.5 2.0 1.3 min 32.5 -124.3 1.0 18.0 3.0 8.0 3.0 0.5 0.0 25% 33.9 -121.8 18.0 1445.0 294.0 780.0 276.8 2.6 1.5 50% 34.3 -118.5 29.0 2130.5 430.0 1159.5 406.0 3.5 1.9 75% 37.7 -118.0 37.0 3129.2 637.0 1700.8 595.0 4.7 2.3 max 41.8 -114.3 52.0 37937.0 5471.0 35682.0 5189.0 15.0 52.0 Training targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 12000.0 mean 207.5 std 115.4 min 15.0 25% 119.9 50% 181.1 75% 265.6 max 500.0 Validation targets summary: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 5000.0 mean 206.9 std 117.5 min 15.0 25% 118.8 50% 178.4 75% 263.1 max 500.0 ÊûÑÂª∫ËâØÂ•ΩÁöÑÁâπÂæÅÈõÜÂ¶ÇÊûúÂè™‰ΩøÁî® 2 ‰∏™Êàñ 3 ‰∏™ÁâπÂæÅÔºåÊÇ®ÂèØ‰ª•Ëé∑ÂæóÁöÑÊúÄ‰Ω≥ÊïàÊûúÊòØ‰ªÄ‰πàÔºü Áõ∏ÂÖ≥Áü©ÈòµÂ±ïÁé∞‰∫Ü‰∏§‰∏§ÊØîËæÉÁöÑÁõ∏ÂÖ≥ÊÄßÔºåÊó¢ÂåÖÊã¨ÊØè‰∏™ÁâπÂæÅ‰∏éÁõÆÊ†áÁâπÂæÅ‰πãÈó¥ÁöÑÊØîËæÉÔºå‰πüÂåÖÊã¨ÊØè‰∏™ÁâπÂæÅ‰∏éÂÖ∂‰ªñÁâπÂæÅ‰πãÈó¥ÁöÑÊØîËæÉ„ÄÇ Âú®ËøôÈáåÔºåÁõ∏ÂÖ≥ÊÄßË¢´ÂÆö‰πâ‰∏∫ÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥Á≥ªÊï∞„ÄÇÊÇ®‰∏çÂøÖÁêÜËß£ÂÖ∑‰ΩìÊï∞Â≠¶ÂéüÁêÜ‰πüÂèØÂÆåÊàêÊú¨ÁªÉ‰π†„ÄÇ Áõ∏ÂÖ≥ÊÄßÂÄºÂÖ∑Êúâ‰ª•‰∏ãÂê´‰πâÔºö -1.0ÔºöÂÆåÂÖ®Ë¥üÁõ∏ÂÖ≥ 0.0Ôºö‰∏çÁõ∏ÂÖ≥ 1.0ÔºöÂÆåÂÖ®Ê≠£Áõ∏ÂÖ≥ 1234correlation_dataframe = training_examples.copy()correlation_dataframe["target"] = training_targets["median_house_value"]correlation_dataframe.corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person target latitude 1.0 -0.9 0.0 -0.0 -0.1 -0.1 -0.1 -0.1 0.1 -0.1 longitude -0.9 1.0 -0.1 0.0 0.1 0.1 0.1 -0.0 -0.1 -0.0 housing_median_age 0.0 -0.1 1.0 -0.4 -0.3 -0.3 -0.3 -0.1 -0.1 0.1 total_rooms -0.0 0.0 -0.4 1.0 0.9 0.9 0.9 0.2 0.1 0.1 total_bedrooms -0.1 0.1 -0.3 0.9 1.0 0.9 1.0 -0.0 0.1 0.0 population -0.1 0.1 -0.3 0.9 0.9 1.0 0.9 -0.0 -0.1 -0.0 households -0.1 0.1 -0.3 0.9 1.0 0.9 1.0 0.0 -0.0 0.1 median_income -0.1 -0.0 -0.1 0.2 -0.0 -0.0 0.0 1.0 0.3 0.7 rooms_per_person 0.1 -0.1 -0.1 0.1 0.1 -0.1 -0.0 0.3 1.0 0.2 target -0.1 -0.0 0.1 0.1 0.0 -0.0 0.1 0.7 0.2 1.0 ÁêÜÊÉ≥ÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨Â∏åÊúõÂÖ∑Êúâ‰∏éÁõÆÊ†áÂØÜÂàáÁõ∏ÂÖ≥ÁöÑÁâπÂæÅ„ÄÇ Ê≠§Â§ñÔºåÊàë‰ª¨ËøòÂ∏åÊúõÊúâ‰∏Ä‰∫õÁõ∏‰∫í‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß‰∏çÂ§™ÂØÜÂàáÁöÑÁâπÂæÅÔºå‰ª•‰æøÂÆÉ‰ª¨Ê∑ªÂä†Áã¨Á´ã‰ø°ÊÅØ„ÄÇ Âà©Áî®Ëøô‰∫õ‰ø°ÊÅØÊù•Â∞ùËØïÁßªÈô§ÁâπÂæÅ„ÄÇÊÇ®‰πüÂèØ‰ª•Â∞ùËØïÊûÑÂª∫ÂÖ∂‰ªñÂêàÊàêÁâπÂæÅÔºå‰æãÂ¶Ç‰∏§‰∏™ÂéüÂßãÁâπÂæÅÁöÑÊØî‰æã„ÄÇ ‰∏∫Êñπ‰æøËµ∑ËßÅÔºåÊàë‰ª¨Â∑≤ÁªèÊ∑ªÂä†‰∫ÜÂâç‰∏Ä‰∏™ÁªÉ‰π†ÁöÑËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136def construct_feature_columns(input_features): """Construct the TensorFlow Feature Columns. Args: input_features: The names of the numerical input features to use. Returns: A set of feature columns """ return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features])def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): """Trains a linear regression model. Args: features: pandas DataFrame of features targets: pandas DataFrame of targets batch_size: Size of batches to be passed to the model shuffle: True or False. Whether to shuffle the data. num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely Returns: Tuple of (features, labels) for next data batch """ # Convert pandas data into a dict of np arrays. features = &#123;key:np.array(value) for key,value in dict(features).items()&#125; # Construct a dataset, and configure batching/repeating. ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit ds = ds.batch(batch_size).repeat(num_epochs) # Shuffle the data, if specified. if shuffle: ds = ds.shuffle(10000) # Return the next batch of data. features, labels = ds.make_one_shot_iterator().get_next() return features, labelsdef train_model( learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets): """Trains a linear regression model. In addition to training, this function also prints training progress information, as well as a plot of the training and validation loss over time. Args: learning_rate: A `float`, the learning rate. steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch. batch_size: A non-zero `int`, the batch size. training_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for training. training_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for training. validation_examples: A `DataFrame` containing one or more columns from `california_housing_dataframe` to use as input features for validation. validation_targets: A `DataFrame` containing exactly one column from `california_housing_dataframe` to use as target for validation. Returns: A `LinearRegressor` object trained on the training data. """ periods = 10 steps_per_period = steps / periods # Create a linear regressor object. my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_regressor = tf.estimator.LinearRegressor( feature_columns=construct_feature_columns(training_examples), optimizer=my_optimizer ) # Create input functions. training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value"], num_epochs=1, shuffle=False) # Train the model, but do so inside a loop so that we can periodically assess # loss metrics. print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_regressor.train( input_fn=training_input_fn, steps=steps_per_period, ) # Take a break and compute predictions. training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # Compute training and validation loss. training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() return linear_regressor ÊêúÁ¥¢‰∏ÄÁªÑÊïàÊûúËâØÂ•ΩÁöÑÁâπÂæÅÂíåËÆ≠ÁªÉÂèÇÊï∞ 12345678910111213141516171819202122232425262728293031323334353637minimal_features = [ "latitude", "longitude",]minimal_training_examples = training_examples[minimal_features]minimal_validation_examples = validation_examples[minimal_features]_ = train_model( learning_rate=0.01, steps=500, batch_size=5, training_examples=minimal_training_examples, training_targets=training_targets, validation_examples=minimal_validation_examples, validation_targets=validation_targets)plt.show()minimal_features = [ "median_income", "latitude",]minimal_training_examples = training_examples[minimal_features]minimal_validation_examples = validation_examples[minimal_features]_ = train_model( learning_rate=0.01, steps=500, batch_size=5, training_examples=minimal_training_examples, training_targets=training_targets, validation_examples=minimal_validation_examples, validation_targets=validation_targets)plt.show() Training model... RMSE (on training data): period 00 : 115.69 period 01 : 115.56 period 02 : 116.82 period 03 : 115.67 period 04 : 115.57 period 05 : 116.72 period 06 : 116.71 period 07 : 119.22 period 08 : 115.56 period 09 : 115.40 Model training finished. Training model... RMSE (on training data): period 00 : 165.32 period 01 : 125.38 period 02 : 116.53 period 03 : 115.99 period 04 : 115.63 period 05 : 114.81 period 06 : 114.06 period 07 : 113.58 period 08 : 114.35 period 09 : 112.88 Model training finished. ËßÇÂØüÂèëÁé∞ ÁªèÂ∫¶ Âíå Áª¥Â∫¶ Ë≤å‰ººÊòØÊ≤°Êúâ‰ªÄ‰πàÁõ∏ÂÖ≥Â∫¶ÁöÑÔºå‰∏™‰∫∫Êî∂ÂÖ•ÁöÑ‰∏≠‰ΩçÊï∞ Âíå Áª¥Â∫¶ ÊòØ‰∏ÄÁªÑÊØîËæÉÂ•ΩÁöÑÁâπÂæÅÁªÑ„ÄÇ Êõ¥Â•ΩÂú∞Âà©Áî®Á∫¨Â∫¶ÁªòÂà∂ latitude ‰∏é median_house_value ÁöÑÂõæÂΩ¢ÂêéÔºåË°®Êòé‰∏§ËÄÖÁ°ÆÂÆû‰∏çÂ≠òÂú®Á∫øÊÄßÂÖ≥Á≥ª„ÄÇ ‰∏çËøáÔºåÊúâÂá†‰∏™Â≥∞ÂÄº‰∏éÊ¥õÊùâÁü∂ÂíåÊóßÈáëÂ±±Â§ßËá¥Áõ∏ÂØπÂ∫î„ÄÇ 1plt.scatter(training_examples["latitude"], training_targets["median_house_value"]) &lt;matplotlib.collections.PathCollection at 0x7fb5a238afd0&gt; Â∞ùËØïÂàõÂª∫‰∏Ä‰∫õËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Á∫¨Â∫¶ÁöÑÂêàÊàêÁâπÂæÅ„ÄÇ ‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•ÂàõÂª∫Êüê‰∏™ÁâπÂæÅÔºåÂ∞Ü latitude Êò†Â∞ÑÂà∞ÂÄº |latitude - 38|ÔºåÂπ∂Â∞ÜËØ•ÁâπÂæÅÂëΩÂêç‰∏∫ distance_from_san_francisco„ÄÇ ÊàñËÄÖÔºåÊÇ®ÂèØ‰ª•Â∞ÜËØ•Á©∫Èó¥ÂàÜÊàê 10 ‰∏™‰∏çÂêåÁöÑÂàÜÊ°∂Ôºà‰æãÂ¶Ç latitude_32_to_33„ÄÅlatitude_33_to_34 Á≠âÔºâÔºöÂ¶ÇÊûú latitude ‰Ωç‰∫éÁõ∏Â∫îÂàÜÊ°∂ËåÉÂõ¥ÂÜÖÔºåÂàôÊòæÁ§∫ÂÄº 1.0ÔºõÂ¶ÇÊûú‰∏çÂú®ËåÉÂõ¥ÂÜÖÔºåÂàôÊòæÁ§∫ÂÄº 0.0„ÄÇ ‰ΩøÁî®Áõ∏ÂÖ≥Áü©ÈòµÊù•ÊåáÂØºÊÇ®ÊûÑÂª∫ÂêàÊàêÁâπÂæÅÔºõÂ¶ÇÊûúÊÇ®ÂèëÁé∞ÊïàÊûúËøò‰∏çÈîôÁöÑÂêàÊàêÁâπÂæÅÔºåÂèØ‰ª•Â∞ÜÂÖ∂Ê∑ªÂä†Âà∞ÊÇ®ÁöÑÊ®°Âûã‰∏≠„ÄÇ Èô§‰∫Ü latitude ‰πãÂ§ñÔºåÊàë‰ª¨Ëøò‰ºö‰øùÁïô median_incomeÔºå‰ª•‰æø‰∏é‰πãÂâçÁöÑÁªìÊûúËøõË°åÊØîËæÉ„ÄÇ Êàë‰ª¨ÂÜ≥ÂÆöÂØπÁ∫¨Â∫¶ËøõË°åÂàÜÊ°∂„ÄÇÂú® Pandas ‰∏≠‰ΩøÁî® Series.apply ÊâßË°åÊ≠§Êìç‰ΩúÁõ∏ÂΩìÁÆÄÂçï„ÄÇ 12345678LATITUDE_RANGES = zip(range(32, 44), range(33, 45))def select_and_transform_features(source_df): selected_examples = pd.DataFrame() selected_examples["median_income"] = source_df["median_income"] for r in LATITUDE_RANGES: selected_examples["latitude_%d_to_%d" % r] = source_df["latitude"].apply( lambda l: 1.0 if l &gt;= r[0] and l &lt; r[1] else 0.0) return selected_examples 12selected_training_examples = select_and_transform_features(training_examples)selected_training_examples.head(2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_income latitude_32_to_33 latitude_33_to_34 latitude_34_to_35 latitude_35_to_36 latitude_36_to_37 latitude_37_to_38 latitude_38_to_39 latitude_39_to_40 latitude_40_to_41 latitude_41_to_42 latitude_42_to_43 latitude_43_to_44 4828 3.4 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 6103 4.7 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 12selected_validation_examples = select_and_transform_features(validation_examples)selected_validation_examples.head(2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_income latitude_32_to_33 latitude_33_to_34 latitude_34_to_35 latitude_35_to_36 latitude_36_to_37 latitude_37_to_38 latitude_38_to_39 latitude_39_to_40 latitude_40_to_41 latitude_41_to_42 latitude_42_to_43 latitude_43_to_44 8959 7.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8330 2.6 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 12345678_ = train_model( learning_rate=0.01, steps=500, batch_size=5, training_examples=selected_training_examples, training_targets=training_targets, validation_examples=selected_validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 227.14 period 01 : 216.98 period 02 : 206.92 period 03 : 196.96 period 04 : 187.10 period 05 : 177.38 period 06 : 167.81 period 07 : 158.44 period 08 : 149.28 period 09 : 140.38 Model training finished.]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 4]]></title>
    <url>%2F2019%2F01%2F08%2FTensorFlow_4%2F</url>
    <content type="text"><![CDATA[È™åËØÅÈÄöÂ∏∏Êàë‰ª¨‰ºöÊääÊï∞ÊçÆÂàÜÈÖç‰∏∫‰∏âÂàÜÔºåËÆ≠ÁªÉÈõÜÔºå‰∫§ÂèâÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜÔºåËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÊòØ‰∏∫‰∫ÜÈÅøÂÖçËøáÊãüÂêàÔºåËÉΩÂ§üÊõ¥Â•ΩÁöÑÊ≥õÂåñ„ÄÇ Ê∑ªÂä†È™åËØÅÈõÜÂêéÔºåÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÂ§ßÊ¶ÇÊòØËøôÊ†∑ÁöÑÔºö Êé•‰∏ãÊù•ÁöÑÁªÉ‰π†ÊòØÂ∞ùËØï‰ΩøÁî®Ëøô‰∏™ÊµÅÁ®ãÊù•ËÆ≠ÁªÉ ‰∏éÂú®‰πãÂâçÁöÑÁªÉ‰π†‰∏≠‰∏ÄÊ†∑ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®Âä†Âà©Á¶èÂ∞º‰∫öÂ∑û‰ΩèÊàøÊï∞ÊçÆÈõÜÔºåÂ∞ùËØïÊ†πÊçÆ 1990 Âπ¥ÁöÑ‰∫∫Âè£ÊôÆÊü•Êï∞ÊçÆÂú®ÂüéÂ∏ÇË°óÂå∫Á∫ßÂà´È¢ÑÊµã median_house_value„ÄÇ ËÆæÁΩÆÈ¶ñÂÖàÂä†ËΩΩÂπ∂ÂáÜÂ§áÊï∞ÊçÆ„ÄÇËøô‰∏ÄÊ¨°‰ΩøÁî®Â§ö‰∏™ÁâπÂæÅÔºåÂõ†Ê≠§ÊääÈÄªËæëÊ®°ÂùóÂåñÔºå‰ª•Êñπ‰æøÂØπÁâπÂæÅËøõË°åÈ¢ÑÂ§ÑÁêÜ 12345678910111213141516171819from __future__ import print_functionimport mathfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10pd.options.display.float_format = '&#123;:.1f&#125;'.formatcalifornia_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",") 12345678910111213141516171819202122232425262728293031323334353637def preprocess_features(california_housing_dataframe): """‰ªéÂä†Â∑û‰ΩèÊàøÊï∞ÊçÆÈõÜËé∑ÂèñËæìÂÖ•Êï∞ÊçÆ ÂèÇÊï∞: california_housing_dataframe:pandaÁöÑ DataFrame Á±ªÂûãÁöÑÊï∞ÊçÆÈõÜ ËøîÂõû: Áî®‰∫éÊ®°ÂûãfeatureÁöÑDataFrame """ selected_features = california_housing_dataframe[ ["latitude", "longitude", "housing_median_age", "total_rooms", "total_bedrooms", "population", "households", "median_income"]] processed_features = selected_features.copy() # Create a synthetic feature. processed_features["rooms_per_person"] = ( california_housing_dataframe["total_rooms"] / california_housing_dataframe["population"]) return processed_featuresdef preprocess_targets(california_housing_dataframe): """ÂáÜÂ§áÁõÆÊ†áÁâπÊÄß(Âç≥Êù•Ëá™Âä†Â∑û‰ΩèÊàøÊï∞ÊçÆÈõÜ„ÄÇ ÂèÇÊï∞: california_housing_dataframe:pandaÁöÑ DataFrame Á±ªÂûãÁöÑÊï∞ÊçÆÈõÜ Êù•Ëá™Âä†Â∑û‰ΩèÊàøÊï∞ÊçÆÈõÜ„ÄÇ ËøîÂõû: Áî®‰∫éÊ®°ÂûãfeatureÁöÑDataFrame """ output_targets = pd.DataFrame() # Â∞ÜtargetsÁöÑÂçï‰ΩçÊâ©Âà∞Âà∞ÂçÉ‰∏∫Âçï‰Ωç output_targets["median_house_value"] = ( california_housing_dataframe["median_house_value"] / 1000.0) return output_targets Êàë‰ª¨‰ªé 17000 ‰∏™Ê†∑Êú¨‰∏≠ÈÄâÂâç 12000 ‰∏™Ê†∑Êú¨ ‰Ωú ËÆ≠ÁªÉÈõÜ 12training_examples = preprocess_features(california_housing_dataframe.head(12000))training_examples.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 12000.0 mean 34.6 -118.5 27.5 2655.7 547.1 1476.0 505.4 3.8 1.9 std 1.6 1.2 12.1 2258.1 434.3 1174.3 391.7 1.9 1.3 min 32.5 -121.4 1.0 2.0 2.0 3.0 2.0 0.5 0.0 25% 33.8 -118.9 17.0 1451.8 299.0 815.0 283.0 2.5 1.4 50% 34.0 -118.2 28.0 2113.5 438.0 1207.0 411.0 3.5 1.9 75% 34.4 -117.8 36.0 3146.0 653.0 1777.0 606.0 4.6 2.3 max 41.8 -114.3 52.0 37937.0 5471.0 35682.0 5189.0 15.0 55.2 12training_targets = preprocess_targets(california_housing_dataframe.head(12000))training_targets.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 12000.0 mean 198.0 std 111.9 min 15.0 25% 117.1 50% 170.5 75% 244.4 max 500.0 Êàë‰ª¨‰ªé 17000 ‰∏™Ê†∑Êú¨‰∏≠ÈÄâÊã©Âêé 5000 ‰∏™‰∏∫ È™åËØÅÈõÜ 12validation_examples = preprocess_features(california_housing_dataframe.tail(5000))validation_examples.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } latitude longitude housing_median_age total_rooms total_bedrooms population households median_income rooms_per_person count 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 5000.0 mean 38.1 -122.2 31.3 2614.8 521.1 1318.1 491.2 4.1 2.1 std 0.9 0.5 13.4 1979.6 388.5 1073.7 366.5 2.0 0.6 min 36.1 -124.3 1.0 8.0 1.0 8.0 1.0 0.5 0.1 25% 37.5 -122.4 20.0 1481.0 292.0 731.0 278.0 2.7 1.7 50% 37.8 -122.1 31.0 2164.0 424.0 1074.0 403.0 3.7 2.1 75% 38.4 -121.9 42.0 3161.2 635.0 1590.2 603.0 5.1 2.4 max 42.0 -121.4 52.0 32627.0 6445.0 28566.0 6082.0 15.0 18.3 12validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))validation_targets.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } median_house_value count 5000.0 mean 229.5 std 122.5 min 15.0 25% 130.4 50% 213.0 75% 303.2 max 500.0 Ê£ÄÊü•Êï∞ÊçÆ Êàë‰ª¨Ê†πÊçÆÂü∫ÂáÜÈ¢ÑÊúüÊÉÖÂÜµÊ£ÄÊü•‰∏Ä‰∏ãÊàë‰ª¨ÁöÑÊï∞ÊçÆÔºö ÂØπ‰∫é‰∏Ä‰∫õÂÄºÔºà‰æãÂ¶Ç median_house_valueÔºâÔºåÊàë‰ª¨ÂèØ‰ª•Ê£ÄÊü•Ëøô‰∫õÂÄºÊòØÂê¶‰Ωç‰∫éÂêàÁêÜÁöÑËåÉÂõ¥ÂÜÖÔºàËØ∑Ê≥®ÊÑèÔºåËøôÊòØ 1990 Âπ¥ÁöÑÊï∞ÊçÆÔºå‰∏çÊòØÁé∞Âú®ÁöÑÔºÅÔºâ„ÄÇ ÂØπ‰∫é latitude Âíå longitude Á≠âÂÖ∂‰ªñÂÄºÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøá Google ËøõË°åÂø´ÈÄüÊêúÁ¥¢ÔºåÂπ∂Âø´ÈÄüÊ£ÄÊü•‰∏Ä‰∏ãÂÆÉ‰ª¨‰∏éÈ¢ÑÊúüÂÄºÊòØÂê¶‰∏ÄËá¥„ÄÇ Â¶ÇÊûúÊÇ®‰ªîÁªÜÁúãÔºåÂèØËÉΩ‰ºöÂèëÁé∞‰∏ãÂàóÂºÇÂ∏∏ÊÉÖÂÜµÔºö median_income ‰Ωç‰∫é 3 Âà∞ 15 ÁöÑËåÉÂõ¥ÂÜÖ„ÄÇÊàë‰ª¨ÂÆåÂÖ®‰∏çÊ∏ÖÊ•öÊ≠§ËåÉÂõ¥Á©∂Á´üÊåáÁöÑÊòØ‰ªÄ‰πàÔºåÁúãËµ∑Êù•ÂèØËÉΩÊòØÊüêÂØπÊï∞Â∞∫Â∫¶ÔºüÊó†Ê≥ïÊâæÂà∞Áõ∏ÂÖ≥ËÆ∞ÂΩïÔºõÊàë‰ª¨ÊâÄËÉΩÂÅáËÆæÁöÑÂè™ÊòØÔºåÂÄºË∂äÈ´òÔºåÁõ∏Â∫îÁöÑÊî∂ÂÖ•Ë∂äÈ´ò„ÄÇ median_house_value ÁöÑÊúÄÂ§ßÂÄºÊòØ 500001„ÄÇËøôÁúãËµ∑Êù•ÂÉèÊòØÊüêÁßç‰∫∫‰∏∫ËÆæÂÆöÁöÑ‰∏äÈôê„ÄÇ rooms_per_person ÁâπÂæÅÈÄöÂ∏∏Âú®Ê≠£Â∏∏ËåÉÂõ¥ÂÜÖÔºåÂÖ∂‰∏≠Á¨¨ 75 ÁôæÂàÜ‰ΩçÊï∞ÁöÑÂÄºÁ∫¶‰∏∫ 2„ÄÇ‰ΩÜ‰πüÊúâ‰∏Ä‰∫õÈùûÂ∏∏Â§ßÁöÑÂÄºÔºà‰æãÂ¶Ç 18 Êàñ 55ÔºâÔºåËøôÂèØËÉΩË°®ÊòéÊï∞ÊçÆÊúâ‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑÊçüÂùè„ÄÇ ÁªòÂà∂Áª¥Â∫¶/ÁªèÂ∫¶‰∏éÊàøÂ±ã‰ª∑ÂÄº‰∏≠‰ΩçÊï∞ÁöÑÊõ≤Á∫øÂõæ Êàë‰ª¨Êù•ËØ¶ÁªÜ‰∫ÜËß£‰∏Ä‰∏ã latitude Âíå longitude Ëøô‰∏§‰∏™ÁâπÂæÅ„ÄÇÂÆÉ‰ª¨ÊòØÁõ∏ÂÖ≥ÂüéÂ∏ÇË°óÂå∫ÁöÑÂú∞ÁêÜÂùêÊ†á„ÄÇ Âà©Áî®Ëøô‰∏§‰∏™ÁâπÂæÅÂèØ‰ª•Êèê‰æõÂá∫Ëâ≤ÁöÑÂèØËßÜÂåñÁªìÊûú - Êàë‰ª¨Êù•ÁªòÂà∂ latitude Âíå longitude ÁöÑÊõ≤Á∫øÂõæÔºåÁÑ∂ÂêéÁî®È¢úËâ≤Ê†áÊ≥® median_house_value„ÄÇ 123456789101112131415161718192021222324252627def plot_scatter(training_examples, training_targets, validation_examples, validation_targets): plt.figure(figsize=(13, 8)) ax = plt.subplot(1, 2, 1) ax.set_title("Validation Data") ax.set_autoscaley_on(False) ax.set_ylim([32, 43]) ax.set_autoscalex_on(False) ax.set_xlim([-126, -112]) plt.scatter(validation_examples["longitude"], validation_examples["latitude"], cmap="coolwarm", c=validation_targets["median_house_value"] / validation_targets["median_house_value"].max()) ax = plt.subplot(1, 2, 2) ax.set_title("Training Date") ax.set_autoscaley_on(False) ax.set_ylim([32, 43]) ax.set_autoscalex_on(False) ax.set_xlim([-126, -112]) plt.scatter(training_examples["longitude"], training_examples["latitude"], cmap="coolwarm", c=training_targets["median_house_value"] / training_targets["median_house_value"].max()) _ = plt.plot() 1plot_scatter(training_examples, training_targets, validation_examples, validation_targets) Áé∞Âú®Â∫îËØ•Â∑≤ÁªèÂëàÁé∞Âá∫‰∏ÄÂπÖ‰∏çÈîôÁöÑÂä†Âà©Á¶èÂ∞º‰∫öÂ∑ûÂú∞Âõæ‰∫ÜÔºåÂÖ∂‰∏≠ÊóßÈáëÂ±±ÂíåÊ¥õÊùâÁü∂Á≠â‰ΩèÊàøÊàêÊú¨È´òÊòÇÁöÑÂú∞Âå∫Áî®Á∫¢Ëâ≤Ë°®Á§∫„ÄÇ Ê†πÊçÆËÆ≠ÁªÉÈõÜÂëàÁé∞ÁöÑÂú∞ÂõæÊúâÂá†ÂàÜÂÉèÁúüÊ≠£ÁöÑÂú∞ÂõæÔºå‰ΩÜÊ†πÊçÆÈ™åËØÅÈõÜÂëàÁé∞ÁöÑÊòéÊòæ‰∏çÂÉè„ÄÇ Êü•Áúã‰∏äÈù¢ÁöÑÊëòË¶ÅÁªüËÆ°‰ø°ÊÅØË°®Ê†ºÊó∂ÔºåÂæàÂÆπÊòì‰∫ßÁîüÊÉ≥Áü•ÈÅìÂ¶Ç‰ΩïËøõË°åÊúâÁî®ÁöÑÊï∞ÊçÆÊ£ÄÊü•ÁöÑÊÉ≥Ê≥ï„ÄÇÊØè‰∏™Ë°óÂå∫ total_rooms ÁöÑÁ¨¨ 75 ÁôæÂàÜ‰ΩçÁöÑÊ≠£Á°ÆÂÄºÊòØ‰ªÄ‰πàÔºü ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÂÖ≥ÈîÆ‰∏ÄÁÇπÊòØÔºåÂØπ‰∫é‰ªª‰ΩïÊåáÂÆöÁâπÂæÅÊàñÂàóÔºåËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ‰πãÈó¥ÁöÑÂÄºÁöÑÂàÜÂ∏ÉÂ∫îËØ•Â§ßËá¥Áõ∏Âêå„ÄÇ Êàë‰ª¨ÁúüÊ≠£ÈúÄË¶ÅÊãÖÂøÉÁöÑÊòØÔºåÁúüÂÆûÊÉÖÂÜµÂπ∂ÈùûËøôÊ†∑ÔºåËøô‰∏Ä‰∫ãÂÆûË°®ÊòéÊàë‰ª¨ÂàõÂª∫ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÁöÑÊãÜÂàÜÊñπÂºèÂæàÂèØËÉΩÂ≠òÂú®ÈóÆÈ¢ò„ÄÇ ÈöèÊú∫ÂåñÂ§ÑÁêÜÊï∞ÊçÆÊàë‰ª¨ÈúÄË¶ÅÂú®ËØªÂÖ•Êï∞ÊçÆÊó∂ÔºåÂØπÊï∞ÊçÆËøõË°åÈöèÊú∫ÂåñÂ§ÑÁêÜÁöÑ„ÄÇ Â¶ÇÊûúÊàë‰ª¨Âú®ÂàõÂª∫ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ‰πãÂâçÔºåÊ≤°ÊúâÂØπÊï∞ÊçÆËøõË°åÊ≠£Á°ÆÁöÑÈöèÊú∫ÂåñÂ§ÑÁêÜÔºåÈÇ£‰πà‰ª•ÊüêÁßçÁâπÂÆöÈ°∫Â∫èÊé•Êî∂Êï∞ÊçÆÂèØËÉΩ‰ºöÂØºËá¥Âá∫Áé∞ÈóÆÈ¢òÔºà‰ºº‰πéÂ∞±ÊòØÊ≠§Êó∂ÁöÑÈóÆÈ¢òÔºâ„ÄÇ ÂèëÁé∞Âπ∂Ëß£ÂÜ≥ÈóÆÈ¢òÂêéÔºåÈáçÊñ∞ËøêË°å‰∏äÈù¢ÁöÑ latitude/longitude ÁªòÂõæÂçïÂÖÉÊ†ºÔºåÂπ∂Á°ÆËÆ§Êàë‰ª¨ÁöÑÂÅ•ÂÖ®ÊÄßÊ£ÄÊü•ÁöÑÁªìÊûúÁúã‰∏äÂéªÊõ¥Â•Ω‰∫Ü„ÄÇ È°∫‰æøÊèê‰∏Ä‰∏ãÔºåÂú®Ëøô‰∏ÄÊ≠•‰∏≠ÔºåÊàë‰ª¨‰ºöÂ≠¶Âà∞‰∏ÄÈ°πÈáçË¶ÅÁªèÈ™å„ÄÇ Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑË∞ÉËØïÈÄöÂ∏∏ÊòØÊï∞ÊçÆË∞ÉËØïËÄå‰∏çÊòØ‰ª£Á†ÅË∞ÉËØï„ÄÇ Â¶ÇÊûúÊï∞ÊçÆÊúâËØØÔºåÂç≥‰ΩøÊúÄÈ´òÁ∫ßÁöÑÊú∫Âô®Â≠¶‰π†‰ª£Á†Å‰πüÊåΩÊïë‰∏ç‰∫ÜÂ±ÄÈù¢„ÄÇ 12345678910california_housing_dataframe = california_housing_dataframe.reindex( np.random.permutation(california_housing_dataframe.index))training_examples = preprocess_features(california_housing_dataframe.head(12000))training_targets = preprocess_targets(california_housing_dataframe.head(12000))validation_examples = preprocess_features(california_housing_dataframe.tail(5000))validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))plot_scatter(training_examples, training_targets, validation_examples, validation_targets) Â•ΩÁöÑÔºåËøôÊ¨°ÁöÑÁªìÊûúÊù•ÁúãËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÈÉΩÊúâÁõ∏‰ººÁöÑÂàÜÂ∏É„ÄÇ ËÆ≠ÁªÉÂíåËØÑ‰º∞Ê®°ÂûãÂ∞ùËØï‰∏çÂêåÁöÑË∂ÖÂèÇÊï∞ÔºåËé∑ÂæóÊúÄ‰Ω≥È™åËØÅÊïàÊûú„ÄÇ È¶ñÂÖàÂÆö‰πâËæìÂÖ•ÂáΩÊï∞ 1234567891011def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): features = &#123;key: np.array(value) for key, value in dict(features).items()&#125; ds = Dataset.from_tensor_slices((features, targets)) ds = ds.batch(batch_size).repeat(num_epochs) if shuffle: ds = ds.shuffle(10000) features, labels = ds.make_one_shot_iterator().get_next() return features, labels Áî±‰∫éÊàë‰ª¨Áé∞Âú®‰ΩøÁî®ÁöÑÊòØÂ§ö‰∏™ËæìÂÖ•ÁâπÂæÅÔºåÂõ†Ê≠§ÈúÄË¶ÅÊääÁî®‰∫éÂ∞ÜÁâπÂæÅÂàóÈÖçÁΩÆ‰∏∫Áã¨Á´ãÂáΩÊï∞ÁöÑ‰ª£Á†ÅÊ®°ÂùóÂåñ„ÄÇÔºàÁõÆÂâçÊ≠§‰ª£Á†ÅÁõ∏ÂΩìÁÆÄÂçïÔºåÂõ†‰∏∫Êàë‰ª¨ÁöÑÊâÄÊúâÁâπÂæÅÈÉΩÊòØÊï∞ÂÄºÔºå‰ΩÜÂΩìÊàë‰ª¨Âú®‰ªäÂêéÁöÑÁªÉ‰π†‰∏≠‰ΩøÁî®ÂÖ∂‰ªñÁ±ªÂûãÁöÑÁâπÂæÅÊó∂Ôºå‰ºöÂü∫‰∫éÊ≠§‰ª£Á†ÅËøõË°åÊûÑÂª∫„ÄÇÔºâ 123456789def construct_feature_columns(input_features): """ÊûÑÈÄ†TensorFlowÁâπÂæÅÂàó ÂèÇÊï∞: input_features:Ë¶Å‰ΩøÁî®ÁöÑÊï∞Â≠óËæìÂÖ•ÁâπÊÄßÁöÑÂêçÁß∞„ÄÇ ËøîÂõû: ‰∏Ä‰∏™ feature columns ÈõÜÂêà """ return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features]) Êé•‰∏ãÊù•ÔºåÁªßÁª≠ÂÆåÊàê train_model() ‰ª£Á†ÅÔºå‰ª•ËÆæÁΩÆËæìÂÖ•ÂáΩÊï∞ÂíåËÆ°ÁÆóÈ¢ÑÊµã„ÄÇ Ê≥®ÊÑèÔºöÂèØ‰ª•ÂèÇËÄÉ‰ª•ÂâçÁöÑÁªÉ‰π†‰∏≠ÁöÑ‰ª£Á†ÅÔºå‰ΩÜË¶ÅÁ°Æ‰øùÈíàÂØπÁõ∏Â∫îÊï∞ÊçÆÈõÜË∞ÉÁî® predict()„ÄÇ ÊØîËæÉËÆ≠ÁªÉÊï∞ÊçÆÂíåÈ™åËØÅÊï∞ÊçÆÁöÑÊçüÂ§±„ÄÇ‰ΩøÁî®‰∏Ä‰∏™ÂéüÂßãÁâπÂæÅÊó∂ÔºåÊàë‰ª¨ÂæóÂà∞ÁöÑÊúÄ‰Ω≥ÂùáÊñπÊ†πËØØÂ∑Æ (RMSE) Á∫¶‰∏∫ 180„ÄÇ Áé∞Âú®Êàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Â§ö‰∏™ÁâπÂæÅÔºå‰∏çÂ¶®Áúã‰∏Ä‰∏ãÂèØ‰ª•Ëé∑ÂæóÂ§öÂ•ΩÁöÑÁªìÊûú„ÄÇ ‰ΩøÁî®Êàë‰ª¨‰πãÂâç‰∫ÜËß£ÁöÑ‰∏Ä‰∫õÊñπÊ≥ïÊ£ÄÊü•Êï∞ÊçÆ„ÄÇËøô‰∫õÊñπÊ≥ïÂèØËÉΩÂåÖÊã¨Ôºö ÊØîËæÉÈ¢ÑÊµãÂÄºÂíåÂÆûÈôÖÁõÆÊ†áÂÄºÁöÑÂàÜÂ∏ÉÊÉÖÂÜµ ÁªòÂà∂È¢ÑÊµãÂÄºÂíåÁõÆÊ†áÂÄºÁöÑÊï£ÁÇπÂõæ ‰ΩøÁî® latitude Âíå longitude ÁªòÂà∂‰∏§‰∏™È™åËØÅÊï∞ÊçÆÊï£ÁÇπÂõæÔºö ‰∏Ä‰∏™Êï£ÁÇπÂõæÂ∞ÜÈ¢úËâ≤Êò†Â∞ÑÂà∞ÂÆûÈôÖÁõÆÊ†á median_house_value Âè¶‰∏Ä‰∏™Êï£ÁÇπÂõæÂ∞ÜÈ¢úËâ≤Êò†Â∞ÑÂà∞È¢ÑÊµãÁöÑ median_house_valueÔºåÂπ∂ÊéíËøõË°åÊØîËæÉ„ÄÇ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798def train_model( learning_rate, strps, batch_size, training_examples, training_targets, validation_examples, validation_targets): """ËÆ≠ÁªÉÂ§öÂÖÉÁâπÂæÅÁöÑÁ∫øÊÄßÂõûÂΩíÊ®°Âûã Èô§ËÆ≠ÁªÉÂ§ñÔºåÊ≠§ÂäüËÉΩËøòÊâìÂç∞ËÆ≠ÁªÉËøõÂ∫¶‰ø°ÊÅØÔºå ‰ª•ÂèäÈöèÁùÄÊó∂Èó¥ÁöÑÊé®ÁßªËÄåÂ§±ÂéªÁöÑËÆ≠ÁªÉÂíåÈ™åËØÅ„ÄÇ ÂèÇÊï∞: learning_rate:‰∏Ä‰∏™floatÔºåË°®Á§∫Â≠¶‰π†Áéá steps:‰∏Ä‰∏™ÈùûÈõ∂ÁöÑintÔºåËÆ≠ÁªÉÊ≠•È™§ÁöÑÊÄªÊï∞„ÄÇËÆ≠ÁªÉÊ≠•È™§ Áî±‰ΩøÁî®Âçï‰∏™ÊâπÂ§ÑÁêÜÁöÑÂêëÂâçÂíåÂêëÂêé‰º†ÈÄíÁªÑÊàê„ÄÇ batch_size:‰∏Ä‰∏™ÈùûÈõ∂ÁöÑint training_example: DataFrame ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™Âàó ' california_housing_dataframe '‰Ωú‰∏∫ËÆ≠ÁªÉÁöÑËæìÂÖ•feature training_targets:‰∏Ä‰∏™' DataFrame 'ÔºåÂÆÉÂè™ÂåÖÂê´‰∏ÄÂàó ' california_housing_dataframe '‰Ωú‰∏∫ËÆ≠ÁªÉÁöÑÁõÆÊ†á„ÄÇ validation_example: ' DataFrame 'ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™Âàó ' california_housing_dataframe '‰Ωú‰∏∫È™åËØÅÁöÑËæìÂÖ•feature validation_targets: ' DataFrame 'Ôºå‰ªÖÂåÖÂê´Êù•Ëá™ÂÖ∂‰∏≠ÁöÑ‰∏ÄÂàó ' california_housing_dataframe '‰Ωú‰∏∫È™åËØÅÁöÑÁõÆÊ†á„ÄÇ ËøîÂõû: Âú®ËÆ≠ÁªÉÊï∞ÊçÆ‰∏äËÆ≠ÁªÉÁöÑ‚ÄúÁ∫øÊÄßÂõûÂΩíÂô®‚ÄùÂØπË±° """ periods = 10 steps_per_period = strps / periods # ÂàõÂª∫‰∏Ä‰∏™Á∫øÊÄßÂõûÂΩíÂØπË±° my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_regressor = tf.estimator.LinearRegressor( feature_columns=construct_feature_columns(training_examples), optimizer=my_optimizer ) # ÂàõÂª∫ËæìÂÖ•ÂáΩÊï∞ training_input_fn = lambda: my_input_fn( training_examples, training_targets["median_house_value"], batch_size=batch_size) predict_training_input_fn = lambda: my_input_fn( training_examples, training_targets["median_house_value"], num_epochs=1, shuffle=False) predict_validation_input_fn = lambda: my_input_fn( validation_examples, validation_targets["median_house_value"], num_epochs=1, shuffle=False) #ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩÜË¶ÅÂú®Âæ™ÁéØ‰∏≠ËøõË°åÔºåËøôÊ†∑Êàë‰ª¨ÊâçËÉΩÂÆöÊúüËØÑ‰º∞ #ÊçüÂ§±ÊåáÊ†á print("Training model...") print("RMSE (on training data):") training_rmse = [] validation_rmse = [] for period in range (0, periods): # Train the model, starting from the prior state. linear_regressor.train( input_fn=training_input_fn, steps=steps_per_period, ) # Take a break and compute predictions. training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn) training_predictions = np.array([item['predictions'][0] for item in training_predictions]) validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn) validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # Compute training and validation loss. training_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(training_predictions, training_targets)) validation_root_mean_squared_error = math.sqrt( metrics.mean_squared_error(validation_predictions, validation_targets)) # Occasionally print the current loss. print(" period %02d : %0.2f" % (period, training_root_mean_squared_error)) # Add the loss metrics from this period to our list. training_rmse.append(training_root_mean_squared_error) validation_rmse.append(validation_root_mean_squared_error) print("Model training finished.") # Output a graph of loss metrics over periods. plt.ylabel("RMSE") plt.xlabel("Periods") plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(training_rmse, label="training") plt.plot(validation_rmse, label="validation") plt.legend() return linear_regressor 12345678linear_regressor = train_model( learning_rate=0.00003, strps=500, batch_size=5, training_examples=training_examples, training_targets=training_targets, validation_examples=validation_examples, validation_targets=validation_targets) Training model... RMSE (on training data): period 00 : 217.57 period 01 : 200.14 period 02 : 185.74 period 03 : 175.52 period 04 : 170.71 period 05 : 167.06 period 06 : 165.72 period 07 : 165.65 period 08 : 166.77 period 09 : 168.40 Model training finished. Âü∫‰∫éÊµãËØïÊï∞ÊçÆËøõË°åËØÑ‰º∞ËΩΩÂÖ•ÊµãËØïÊï∞ÊçÆÈõÜÂπ∂ÊçÆÊ≠§ËØÑ‰º∞Ê®°Âûã„ÄÇ Êàë‰ª¨Â∑≤ÂØπÈ™åËØÅÊï∞ÊçÆËøõË°å‰∫ÜÂ§ßÈáèËø≠‰ª£„ÄÇÊé•‰∏ãÊù•Á°Æ‰øùÊàë‰ª¨Ê≤°ÊúâËøáÊãüÂêàËØ•ÁâπÂÆöÊ†∑Êú¨ÈõÜÁöÑÁâπÊÄß„ÄÇ ÊµãËØïÊï∞ÊçÆÈõÜ‰Ωç‰∫éÊ≠§Â§Ñ„ÄÇ 123456789101112131415161718california_housing_test_data = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_test.csv", sep=",")test_examples = preprocess_features(california_housing_test_data)test_targets = preprocess_targets(california_housing_test_data)predict_test_input_fn = lambda: my_input_fn( test_examples, test_targets["median_house_value"], num_epochs=1, shuffle=False)test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)test_predictions = np.array([item['predictions'][0] for item in test_predictions])root_mean_squared_error = math.sqrt( metrics.mean_squared_error(test_predictions, test_targets))print("Final RMSE (on test data): %0.2f" % root_mean_squared_error) Final RMSE (on test data): 162.99]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 16. 3Sum Closest]]></title>
    <url>%2F2019%2F01%2F07%2FLeetCode%2016.%203Sum%20Closest%2F</url>
    <content type="text"><![CDATA[Â•Ω‰πÖÊ≤°ÂÜôCÁöÑÔºåÂÜô‰∏™CÂ§ç‰π†‰∏Ä‰∏ãÔºåÂÜô‰∏™ÁÆÄÂçïÁöÑleetcodeÂêß 3Sum ClosestGiven an array nums of n integers and an integer target, find three integers in nums such that the sum is closest to target. Return the sum of the three integers. You may assume that each input would have exactly one solution. Example: Given array nums = [-1, 2, 1, -4], and target = 1. The sum that is closest to the target is 2. (-1 + 2 + 1 = 2). Ëøô‰∏™ÈóÆÈ¢òÊØîËæÉÁÆÄÂçïÔºåÊàëÂÖàÂÜô‰∫Ü‰∏™Êö¥ÂäõËß£Ê≥ï1234567891011121314151617181920int threeSumClosest(int* nums, int numsSize, int target) &#123; int result=nums[0] + nums[1] + nums[2]; int i, j, k; int sum; for(i=0; i&lt;numsSize-2; i++) &#123; for(j=i+1; j&lt;numsSize-1; j++) &#123; for(k=j+1; k&lt;numsSize; k++) &#123; sum = nums[i] + nums[j] + nums[k]; if(abs(sum-target) &lt;= abs(result-target)) result = sum; &#125; &#125; &#125; return result;&#125; runtime‰∏∫172 msÂèØÊÉ≥ËÄåÁü•ÊòØÂæà‰ΩéÁöÑ„ÄÇ Áúã‰∫Ü‰∏ãÂà´‰∫∫ÁöÑsolutionÔºåÂÖàÊéíÂ∫èÂÜçÁÆóË¶ÅÂø´Â•ΩÂ§öÔºå‰∫éÊòØÊàëÂÖàÂ∞ùËØï‰∫Ü ÂÜíÊ≥°ÊéíÂ∫è 12345678910void bubble_sort(int arr[], int len) &#123; int i, j, temp; for (i = 0; i &lt; len - 1; i++) for (j = 0; j &lt; len - 1 - i; j++) if (arr[j] &gt; arr[j + 1]) &#123; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125;&#125; Runtime ‰∏∫8 msÔºåËøòÊòØÂ∑ÆÁÇπÔºå‰ªîÁªÜÁúã‰∫Ü‰∏ãÔºåÂõ†ËØ•ÊòØÊàëÁöÑÊéíÂ∫èÁÆóÊ≥ïÊÖ¢‰∫ÜÔºåÁúãÂà∞Âà´‰∫∫ÁöÑsolutionÁî®c‰∏≠ÁöÑÂø´Êéíqsort()ÔºåÂèØÊÉúÊàë‰πãÂâçÊ≤°Â≠¶ËøáËøô‰∏™ÂáΩÊï∞,ÊâÄ‰ª•Ê≤°ÊÉ≥Âà∞ÔºåËµ∂Á¥ßÊÅ∂Ë°•‰∏ã„ÄÇ ÂéüÊñáÂú∞ÂùÄ 1234567891011121314151617181920212223242526272829303132333435void qsort( void *base, size_t nmemb, size_t size, int (*compar)(const void *, const void *) ); ÂáΩÊï∞ÂäüËÉΩÔºöqsort()ÂáΩÊï∞ÁöÑÂäüËÉΩÊòØÂØπÊï∞ÁªÑËøõË°åÊéíÂ∫èÔºåÊï∞ÁªÑÊúânmemb‰∏™ÂÖÉÁ¥†ÔºåÊØè‰∏™ÂÖÉÁ¥†Â§ßÂ∞è‰∏∫size„ÄÇÂèÇÊï∞base - baseÊåáÂêëÊï∞ÁªÑÁöÑËµ∑ÂßãÂú∞ÂùÄÔºåÈÄöÂ∏∏ËØ•‰ΩçÁΩÆ‰º†ÂÖ•ÁöÑÊòØ‰∏Ä‰∏™Êï∞ÁªÑÂêçÂèÇÊï∞nmemb - nmembË°®Á§∫ËØ•Êï∞ÁªÑÁöÑÂÖÉÁ¥†‰∏™Êï∞ÂèÇÊï∞size - sizeË°®Á§∫ËØ•Êï∞ÁªÑ‰∏≠ÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂ§ßÂ∞èÔºàÂ≠óËäÇÊï∞ÔºâÂèÇÊï∞(*compar)(const void *, const void *) - Ê≠§‰∏∫ÊåáÂêëÊØîËæÉÂáΩÊï∞ÁöÑÂáΩÊï∞ÊåáÈíàÔºåÂÜ≥ÂÆö‰∫ÜÊéíÂ∫èÁöÑÈ°∫Â∫è„ÄÇÂáΩÊï∞ËøîÂõûÂÄºÔºöÊó†Ê≥®ÊÑèÔºöÂ¶ÇÊûú‰∏§‰∏™ÂÖÉÁ¥†ÁöÑÂÄºÊòØÁõ∏ÂêåÁöÑÔºåÈÇ£‰πàÂÆÉ‰ª¨ÁöÑÂâçÂêéÈ°∫Â∫èÊòØ‰∏çÁ°ÆÂÆöÁöÑ„ÄÇ‰πüÂ∞±ÊòØËØ¥qsort()ÊòØ‰∏Ä‰∏™‰∏çÁ®≥ÂÆöÁöÑÊéíÂ∫èÁÆóÊ≥ï„ÄÇcomparÂèÇÊï∞comparÂèÇÊï∞ÊåáÂêë‰∏Ä‰∏™ÊØîËæÉ‰∏§‰∏™ÂÖÉÁ¥†ÁöÑÂáΩÊï∞„ÄÇÊØîËæÉÂáΩÊï∞ÁöÑÂéüÂûãÂ∫îËØ•ÂÉè‰∏ãÈù¢ËøôÊ†∑„ÄÇÊ≥®ÊÑè‰∏§‰∏™ÂΩ¢ÂèÇÂøÖÈ°ªÊòØconst void *ÂûãÔºåÂêåÊó∂Âú®Ë∞ÉÁî®compar ÂáΩÊï∞ÔºàcomparÂÆûË¥®‰∏∫ÂáΩÊï∞ÊåáÈíàÔºåËøôÈáåÁß∞ÂÆÉÊâÄÊåáÂêëÁöÑÂáΩÊï∞‰πü‰∏∫comparÔºâÊó∂Ôºå‰º†ÂÖ•ÁöÑÂÆûÂèÇ‰πüÂøÖÈ°ªËΩ¨Êç¢Êàêconst void *Âûã„ÄÇÂú®comparÂáΩÊï∞ÂÜÖÈÉ®‰ºöÂ∞Üconst void *ÂûãËΩ¨Êç¢ÊàêÂÆûÈôÖÁ±ªÂûãÔºåËßÅ‰∏ãÊñá„ÄÇint compar(const void *p1, const void *p2);Â¶ÇÊûúcomparËøîÂõûÂÄºÂ∞è‰∫é0Ôºà&lt; 0ÔºâÔºåÈÇ£‰πàp1ÊâÄÊåáÂêëÂÖÉÁ¥†‰ºöË¢´ÊéíÂú®p2ÊâÄÊåáÂêëÂÖÉÁ¥†ÁöÑÂâçÈù¢Â¶ÇÊûúcomparËøîÂõûÂÄºÁ≠â‰∫é0Ôºà= 0ÔºâÔºåÈÇ£‰πàp1ÊâÄÊåáÂêëÂÖÉÁ¥†‰∏ép2ÊâÄÊåáÂêëÂÖÉÁ¥†ÁöÑÈ°∫Â∫è‰∏çÁ°ÆÂÆöÂ¶ÇÊûúcomparËøîÂõûÂÄºÂ§ß‰∫é0Ôºà&gt; 0ÔºâÔºåÈÇ£‰πàp1ÊâÄÊåáÂêëÂÖÉÁ¥†‰ºöË¢´ÊéíÂú®p2ÊâÄÊåáÂêëÂÖÉÁ¥†ÁöÑÂêéÈù¢Âõ†Ê≠§ÔºåÂ¶ÇÊûúÊÉ≥ËÆ©qsort()ËøõË°å‰ªéÂ∞èÂà∞Â§ßÔºàÂçáÂ∫èÔºâÊéíÂ∫èÔºåÈÇ£‰πà‰∏Ä‰∏™ÈÄöÁî®ÁöÑcomparÂáΩÊï∞ÂèØ‰ª•ÂÜôÊàêËøôÊ†∑Ôºöint compareMyType (const void * a, const void * b)&#123; if ( *(MyType*)a &lt; *(MyType*)b ) return -1; if ( *(MyType*)a == *(MyType*)b ) return 0; if ( *(MyType*)a &gt; *(MyType*)b ) return 1;&#125;Ê≥®ÊÑèÔºö‰Ω†Ë¶ÅÂ∞ÜMyTypeÊç¢ÊàêÂÆûÈôÖÊï∞ÁªÑÂÖÉÁ¥†ÁöÑÁ±ªÂûã„ÄÇ ‰ΩøÁî®Âø´ÊéíÂêé Runtime: 4 ms, faster than 100.00% of C online submissions for 3Sum Closest. 123456789101112131415161718192021222324252627282930313233343536int comp(const void*a,const void*b)&#123; return *(int*)a-*(int*)b;&#125;int threeSumClosest(int* nums, int numsSize, int target) &#123; int result=nums[0] + nums[1] + nums[2]; if(numsSize &lt;= 3) return result; int i, j, k; int sum; qsort(nums, numsSize, sizeof(int), comp); for(i=0; i&lt;numsSize-2; i++) &#123; j = i + 1; k = numsSize - 1; while(j &lt; k) &#123; sum = nums[i] + nums[j] + nums[k]; if(abs(sum-target) &lt;= abs(result-target)) &#123; if(sum == target) return sum; result = sum; &#125; (sum &gt; target)? k--: j++; &#125; &#125; return result;&#125;]]></content>
      <categories>
        <category>ÁÆóÊ≥ïÁªÉ‰π†</category>
      </categories>
      <tags>
        <tag>ÁÆóÊ≥ï</tag>
        <tag>c</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 3]]></title>
    <url>%2F2018%2F12%2F29%2FTensorFlow_3%2F</url>
    <content type="text"><![CDATA[‰ΩøÁî®TensorFlowÁöÑÂü∫Êú¨Ê≠•È™§Ê∑ªÂä†ÂøÖË¶ÅÁöÑÂ∫ì1234567891011121314151617from __future__ import print_functionimport mathfrom IPython import displayfrom matplotlib import cmfrom matplotlib import gridspecfrom matplotlib import pyplot as pltimport numpy as npimport pandas as pdfrom sklearn import metricsimport tensorflow as tffrom tensorflow.python.data import Datasettf.logging.set_verbosity(tf.logging.ERROR)pd.options.display.max_rows = 10 # ÊúÄÂ§ßÊòæÁ§∫Ë°åÊï∞pd.options.display.float_format = '&#123;:.1f&#125;'.format # Á≤æÁ°ÆÂ∫¶ ‰øùÁïô‰∏Ä‰ΩçÂ∞èÊï∞ Âä†ËΩΩÊï∞ÊçÆÈõÜÂä†ËΩΩÁöÑÊï∞ÊçÆÈõÜÔºåÊï∞ÊçÆÂü∫‰∫éÂä†Âà©Á¶èÂ∞º‰∫öÂ∑û1990Âπ¥ÁöÑ‰∫∫Âè£ÊôÆÊü•Êï∞ÊçÆ 1california_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",") ÂàùÂßãÂåñÊï∞ÊçÆÈõÜÔºåÂØπÊï∞ÊçÆÈõÜËøõË°åÈöèÊú∫ÂåñÂ§ÑÁêÜÔºå‰ª•Á°Æ‰øù‰∏ç‰ºöÂá∫Áé∞ÊçüÂÆ≥ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁöÑÊïàÊûú„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨‰ºöÂ∞Ü median_house_value Ë∞ÉÊï¥‰∏∫‰ª•ÂçÉ‰∏∫Âçï‰ΩçÔºåËøôÊ†∑ÔºåÊ®°ÂûãÂ∞±ËÉΩÂ§ü‰ª•Â∏∏Áî®ËåÉÂõ¥ÂÜÖÁöÑÂ≠¶‰π†ÈÄüÁéáËæÉ‰∏∫ËΩªÊùæÂú∞Â≠¶‰π†Ëøô‰∫õÊï∞ÊçÆ„ÄÇ 1234california_housing_dataframe = california_housing_dataframe.reindex( np.random.permutation(california_housing_dataframe.index))california_housing_dataframe["median_house_value"] /= 1000.0california_housing_dataframe .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } longitude latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value 13098 -121.9 37.6 20.0 1309.0 184.0 514.0 172.0 11.0 475.8 6576 -118.3 34.1 52.0 1261.0 616.0 2309.0 581.0 1.6 225.0 12732 -121.8 37.7 17.0 3112.0 872.0 1392.0 680.0 3.0 172.5 6505 -118.3 34.0 34.0 1462.0 394.0 1310.0 351.0 1.2 90.1 339 -116.9 32.7 9.0 2652.0 393.0 1355.0 362.0 6.3 293.1 ... ... ... ... ... ... ... ... ... ... 6741 -118.3 33.9 41.0 896.0 198.0 605.0 168.0 2.3 128.1 496 -117.0 33.7 13.0 16148.0 3474.0 6159.0 3232.0 2.0 97.8 9140 -119.0 35.4 30.0 227.0 75.0 169.0 101.0 1.4 60.0 2610 -117.7 34.1 33.0 2081.0 409.0 1008.0 375.0 2.6 138.1 6827 -118.3 34.0 35.0 1090.0 345.0 1605.0 330.0 2.2 152.8 17000 rows √ó 9 columns Ê£ÄÊü•Êï∞ÊçÆÂª∫ËÆÆÂú®‰ΩøÁî®Êï∞ÊçÆ‰πãÂâçÔºåÂÖàÂØπÂÆÉÊúâ‰∏Ä‰∏™ÂàùÊ≠•ÁöÑ‰∫ÜËß£„ÄÇ ËæìÂá∫ÂÖ≥‰∫éÂêÑÂàóÁöÑ‰∏Ä‰∫õÂÆûÁî®ÁªüËÆ°‰ø°ÊÅØÂø´ÈÄüÊëòË¶ÅÔºöÊ†∑Êú¨Êï∞ÔºåÂùáÂÄºÔºåÊ†áÂáÜÂÅèÂ∑ÆÔºåÊúÄÂ§ßÂÄºÔºåÊúÄÂ∞èÂÄºÂíåÂêÑÁßçÂàÜ‰ΩçÊï∞„ÄÇ 1california_housing_dataframe.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } longitude latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value count 17000.0 17000.0 17000.0 17000.0 17000.0 17000.0 17000.0 17000.0 17000.0 mean -119.6 35.6 28.6 2643.7 539.4 1429.6 501.2 3.9 207.3 std 2.0 2.1 12.6 2179.9 421.5 1147.9 384.5 1.9 116.0 min -124.3 32.5 1.0 2.0 1.0 3.0 1.0 0.5 15.0 25% -121.8 33.9 18.0 1462.0 297.0 790.0 282.0 2.6 119.4 50% -118.5 34.2 29.0 2127.0 434.0 1167.0 409.0 3.5 180.4 75% -118.0 37.7 37.0 3151.2 648.2 1721.0 605.2 4.8 265.0 max -114.3 42.0 52.0 37937.0 6445.0 35682.0 6082.0 15.0 500.0 ÊûÑÂª∫Á¨¨‰∏Ä‰∏™Ê®°ÂûãÂ∞ùËØïÈ¢ÑÊµãmedian_house_valueÔºåÂÆÉÂ∞ÜÊòØÊàë‰ª¨ÁöÑÊ†áÁ≠æÔºå‰πüÁß∞‰∏∫ÁõÆÊ†á„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®total_rooms‰Ωú‰∏∫ËæìÂÖ•ÁâπÂæÅ„ÄÇ Ê≥®ÊÑèÔºöÊàë‰ª¨‰ΩøÁî®ÁöÑÊòØÂüéÂ∏ÇË°óÂå∫Á∫ßÂà´ÁöÑÊï∞ÊçÆÔºåÂõ†Ê≠§ËØ•ÁâπÂæÅË°®Á§∫Áõ∏Â∫îË°óÂå∫ÁöÑÊàøÈó¥ÊÄªÊï∞„ÄÇ ‰∏∫‰∫ÜËÆ≠ÁªÉÊ®°ÂûãÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî® TensorFlow Estimator API Êèê‰æõÁöÑ LinearRegressor Êé•Âè£„ÄÇÊ≠§ API Ë¥üË¥£Â§ÑÁêÜÂ§ßÈáè‰ΩéÁ∫ßÂà´Ê®°ÂûãÊê≠Âª∫Â∑•‰ΩúÔºåÂπ∂‰ºöÊèê‰æõÊâßË°åÊ®°ÂûãËÆ≠ÁªÉ„ÄÅËØÑ‰º∞ÂíåÊé®ÁêÜÁöÑ‰æøÂà©ÊñπÊ≥ï„ÄÇ Á¨¨‰∏ÄÊ≠•ÔºöÂÆö‰πâÁâπÂæÅÂπ∂ÈÖçÁΩÆÁâπÂæÅÂàó‰∏∫‰∫ÜÂ∞ÜÊàë‰ª¨ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂØºÂÖ•TensorFlowÔºåÊàë‰ª¨ÈúÄË¶ÅÊåáÂÆöÊØè‰∏™ÁâπÂæÅÂåÖÂê´ÁöÑÊï∞ÊçÆÁ±ªÂûã„ÄÇÂú®ÁªÉ‰π†‰∏≠Ôºå‰∏ªË¶Å‰ΩøÁî®‰∏Ä‰∏ã‰∏§Á±ªÊï∞ÊçÆÔºö ÂàÜÁ±ªÊï∞ÊçÆÔºö ‰∏ÄÁßçÊñáÂ≠óÊï∞ÊçÆ„ÄÇ Êï∞ÂÄºÊï∞ÊçÆÔºö‰∏ÄÁßçÊï∞Â≠óÔºàÊï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÔºâÊï∞ÊçÆ‰ª•ÂèäÂ∏åÊúõÊòØ‰∏∫Êï∞Â≠óÁöÑÊï∞ÊçÆ„ÄÇ Âú® TenssorFlow‰∏≠Ôºå‰ΩøÁî®‚ÄúÁâπÂæÅÂàó‚ÄùÁöÑÁªìÊûÑÊù•Ë°®Á§∫ÁâπÂæÅÁöÑÊï∞ÊçÆÁ±ªÂûã„ÄÇÁâπÂæÅÂàó‰ªÖÂÇ®Â≠òÂØπÁâπÂæÅÊï∞ÊçÆÁöÑÊèèËø∞Ôºõ‰∏çÂåÖÂê´ÁâπÂæÅÊï∞ÊçÆÊú¨Ë∫´„ÄÇ ‰∏ÄÂºÄÂßãÔºåÂè™‰ΩøÁî®‰∏Ä‰∏™Êï∞ÂÄºËæìÂÖ•ÁâπÂæÅtotal_rooms„ÄÇ‰ª•‰∏ã‰ª£Á†Å‰ºö‰ªé california_housing_dataframe ‰∏≠ÊèêÂèñ total_rooms Êï∞ÊçÆÔºåÂπ∂‰ΩøÁî® numeric_column ÂÆö‰πâÁâπÂæÅÂàóÔºåËøôÊ†∑‰ºöÂ∞ÜÂÖ∂Êï∞ÊçÆÊåáÂÆö‰∏∫Êï∞ÂÄºÔºö 12345# ÂÆö‰πâËæìÂÖ•ÁâπÂæÅ total_rooms.my_feature = california_housing_dataframe[["total_rooms"]]# ‰∏∫total_roomsÈÖçÁΩÆ‰∏Ä‰∏™Áî±Êï∞Â≠óÊûÑÊàêÁöÑfeature columnfeature_columns = [tf.feature_column.numeric_column("total_rooms")] Ê≥®ÊÑèÔºötotal_rooms Êï∞ÊçÆÁöÑÂΩ¢Áä∂ÊòØ‰∏ÄÁª¥Êï∞ÁªÑÔºàÊØè‰∏™Ë°óÂå∫ÁöÑÊàøÈó¥ÊÄªÊï∞ÂàóË°®Ôºâ„ÄÇËøôÊòØ numeric_column ÁöÑÈªòËÆ§ÂΩ¢Áä∂ÔºåÂõ†Ê≠§Êàë‰ª¨‰∏çÂøÖÂ∞ÜÂÖ∂‰Ωú‰∏∫ÂèÇÊï∞‰º†ÈÄí„ÄÇ Á¨¨‰∫åÊ≠•ÔºöÂÆö‰πâÁõÆÊ†áÊé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞ÜÂÆö‰πâÁõÆÊ†áÔºå‰πüÂ∞±ÊòØ median_house_value„ÄÇÂêåÊ†∑ÔºåÊàë‰ª¨ÂèØ‰ª•‰ªé california_housing_dataframe ‰∏≠ÊèêÂèñÂÆÉÔºö 12# ÂÆö‰πâÁõÆÊ†átargets = california_housing_dataframe["median_house_value"] Á¨¨‰∏âÊ≠•ÔºöÈÖçÁΩÆLinearRegressor Êé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî® LinearRegressor ÈÖçÁΩÆÁ∫øÊÄßÂõûÂΩíÊ®°ÂûãÔºåÂπ∂‰ΩøÁî® GradientDescentOptimizerÔºàÂÆÉ‰ºöÂÆûÁé∞Â∞èÊâπÈáèÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï (SGD)ÔºâËÆ≠ÁªÉËØ•Ê®°Âûã„ÄÇlearning_rate ÂèÇÊï∞ÂèØÊéßÂà∂Ê¢ØÂ∫¶Ê≠•ÈïøÁöÑÂ§ßÂ∞è„ÄÇ Ê≥®ÊÑèÔºö‰∏∫‰∫ÜÂÆâÂÖ®Ëµ∑ËßÅÔºåÊàë‰ª¨Ëøò‰ºöÈÄöËøá clip_gradients_by_norm Â∞ÜÊ¢ØÂ∫¶Ë£ÅÂâ™Â∫îÁî®Âà∞Êàë‰ª¨ÁöÑ‰ºòÂåñÂô®„ÄÇÊ¢ØÂ∫¶Ë£ÅÂâ™ÂèØÁ°Æ‰øùÊ¢ØÂ∫¶Â§ßÂ∞èÂú®ËÆ≠ÁªÉÊúüÈó¥‰∏ç‰ºöÂèòÂæóËøáÂ§ßÔºåÊ¢ØÂ∫¶ËøáÂ§ß‰ºöÂØºËá¥Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂ§±Ë¥•„ÄÇ 12345678910# ‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôç‰Ωú‰∏∫ËÆ≠ÁªÉÊ®°ÂûãÁöÑ‰ºòÂåñÂô®my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)# ‰ΩøÁî®Êàë‰ª¨ÁöÑÁâπÊÄßÂàóÂíå‰ºòÂåñÂô®ÈÖçÁΩÆÁ∫øÊÄßÂõûÂΩíÊ®°Âûã# ‰∏∫Ê¢ØÂ∫¶‰∏ãÈôçËÆæÁΩÆ0.0000001ÁöÑÂ≠¶‰π†Áéálinear_regresor = tf.estimator.LinearRegressor( feature_columns=feature_columns, optimizer=my_optimizer) Á¨¨ÂõõÊ≠•ÔºöÂÆö‰πâËæìÂÖ•ÂáΩÊï∞ Ë¶ÅÂ∞ÜÂä†Âà©Á¶èÂ∞º‰∫öÂ∑û‰ΩèÊàøÊï∞ÊçÆÂØºÂÖ• LinearRegressorÔºåÊàë‰ª¨ÈúÄË¶ÅÂÆö‰πâ‰∏Ä‰∏™ËæìÂÖ•ÂáΩÊï∞ÔºåËÆ©ÂÆÉÂëäËØâ TensorFlow Â¶Ç‰ΩïÂØπÊï∞ÊçÆËøõË°åÈ¢ÑÂ§ÑÁêÜÔºå‰ª•ÂèäÂú®Ê®°ÂûãËÆ≠ÁªÉÊúüÈó¥Â¶Ç‰ΩïÊâπÂ§ÑÁêÜ„ÄÅÈöèÊú∫Â§ÑÁêÜÂíåÈáçÂ§çÊï∞ÊçÆ„ÄÇ È¶ñÂÖàÔºåÊàë‰ª¨Â∞Ü Pandas ÁâπÂæÅÊï∞ÊçÆËΩ¨Êç¢Êàê NumPy Êï∞ÁªÑÂ≠óÂÖ∏„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî® TensorFlow Dataset API Ê†πÊçÆÊàë‰ª¨ÁöÑÊï∞ÊçÆÊûÑÂª∫ Dataset ÂØπË±°ÔºåÂπ∂Â∞ÜÊï∞ÊçÆÊãÜÂàÜÊàêÂ§ßÂ∞è‰∏∫ batch_size ÁöÑÂ§öÊâπÊï∞ÊçÆÔºå‰ª•ÊåâÁÖßÊåáÂÆöÂë®ÊúüÊï∞ (num_epochs) ËøõË°åÈáçÂ§ç„ÄÇ Ê≥®ÊÑèÔºöÂ¶ÇÊûúÂ∞ÜÈªòËÆ§ÂÄº num_epochs=None ‰º†ÈÄíÂà∞ repeat()ÔºåËæìÂÖ•Êï∞ÊçÆ‰ºöÊó†ÈôêÊúüÈáçÂ§ç„ÄÇ ÁÑ∂ÂêéÔºåÂ¶ÇÊûú shuffle ËÆæÁΩÆ‰∏∫ TrueÔºåÂàôÊàë‰ª¨‰ºöÂØπÊï∞ÊçÆËøõË°åÈöèÊú∫Â§ÑÁêÜÔºå‰ª•‰æøÊï∞ÊçÆÂú®ËÆ≠ÁªÉÊúüÈó¥‰ª•ÈöèÊú∫ÊñπÂºè‰º†ÈÄíÂà∞Ê®°Âûã„ÄÇbuffer_size ÂèÇÊï∞‰ºöÊåáÂÆö shuffle Â∞Ü‰ªé‰∏≠ÈöèÊú∫ÊäΩÊ†∑ÁöÑÊï∞ÊçÆÈõÜÁöÑÂ§ßÂ∞è„ÄÇ ÊúÄÂêéÔºåËæìÂÖ•ÂáΩÊï∞‰ºö‰∏∫ËØ•Êï∞ÊçÆÈõÜÊûÑÂª∫‰∏Ä‰∏™Ëø≠‰ª£Âô®ÔºåÂπ∂Âêë LinearRegressor ËøîÂõû‰∏ã‰∏ÄÊâπÊï∞ÊçÆ„ÄÇ 123456789101112131415161718192021222324252627def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None): """ËÆ≠ÁªÉ‰∏Ä‰∏™ÁâπÂæÅÁöÑÁ∫øÊÄßÂõûÂΩíÊ®°Âûã ÂèÇÊï∞: features: pandas DataFrame Á±ªÂûãÁöÑ features targets: pandas DataFrame Á±ªÂûãÁöÑ targets batch_size: Size of batches to be passed to the model shuffle: True or False. ÊòØÂê¶ÈöèÊú∫Âåñ data. num_epochs: Êï∞ÊçÆÂ∫îÈáçÂ§çÁöÑÂë®ÊúüÊï∞. None = repeat indefinitely Returns: Tuple of (features, labels) for next data batch ÂÖÉÁªÑÔºö‰∏ã‰∏Ä‰∏™Êï∞ÊçÆÊâπÂ§ÑÁêÜÁöÑ(ÁâπÂæÅ„ÄÅÊ†áÁ≠æ/ÁõÆÊ†á) """ # Â∞ÜpandasÊï∞ÊçÆËΩ¨Êç¢‰∏∫numpyÊï∞ÁªÑÂ≠óÂÖ∏ features = &#123;key: np.array(value) for key, value in dict(features).items()&#125; # ÊûÑÂª∫datasetÔºåÂπ∂‰∏îÊãÜÂàÜ‰∏∫batch_size‰∏™Êï∞ÊçÆ ds = Dataset.from_tensor_slices((features, targets)) # ÈôêÂà∂‰∏∫ÊúÄÂ§ß2GB ds = ds.batch(batch_size).repeat(num_epochs) # shuffle if shuffle: ds = ds.shuffle(buffer_size=10000) # ËøîÂõû‰∏ã‰∏ÄÊâπÊï∞ÊçÆ features, labels = ds.make_one_shot_iterator().get_next() return features, labels Á¨¨‰∫îÊ≠•ÔºöËÆ≠ÁªÉÊï∞ÊçÆ Áé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•Âú® linear_regressor ‰∏äË∞ÉÁî® train() Êù•ËÆ≠ÁªÉÊ®°Âûã„ÄÇÊàë‰ª¨‰ºöÂ∞Ü my_input_fn Â∞ÅË£ÖÂú® lambda ‰∏≠Ôºå‰ª•‰æøÂèØ‰ª•Â∞Ü my_feature Âíå target ‰Ωú‰∏∫ÂèÇÊï∞‰º†ÂÖ•ÔºàÊúâÂÖ≥ËØ¶ÊÉÖÔºåËØ∑ÂèÇÈòÖÊ≠§ TensorFlow ËæìÂÖ•ÂáΩÊï∞ÊïôÁ®ãÔºâÔºåÈ¶ñÂÖàÔºåÊàë‰ª¨‰ºöËÆ≠ÁªÉ 100 Ê≠•„ÄÇ 1234_ = linear_regresor.train( input_fn = lambda: my_input_fn(my_feature, targets), steps=100) Á¨¨ÂÖ≠Ê≠•Ôºö ËØÑ‰º∞Ê®°ÂûãÊàë‰ª¨Âü∫‰∫éËØ•ËÆ≠ÁªÉÊï∞ÊçÆÂÅö‰∏ÄÊ¨°È¢ÑÊµãÔºåÁúãÁúãÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®ËÆ≠ÁªÉÊúüÈó¥‰∏éËøô‰∫õÊï∞ÊçÆÁöÑÊãüÂêàÊÉÖÂÜµ„ÄÇ Ê≥®ÊÑèÔºöËÆ≠ÁªÉËØØÂ∑ÆÂèØ‰ª•Ë°°ÈáèÊÇ®ÁöÑÊ®°Âûã‰∏éËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊãüÂêàÊÉÖÂÜµÔºå‰ΩÜÂπ∂_‰∏çËÉΩ_Ë°°ÈáèÊ®°ÂûãÊ≥õÂåñÂà∞Êñ∞Êï∞ÊçÆÁöÑÊïàÊûú„ÄÇÂú®ÂêéÈù¢ÁöÑÁªÉ‰π†‰∏≠ÔºåÊÇ®Â∞ÜÊé¢Á¥¢Â¶Ç‰ΩïÊãÜÂàÜÊï∞ÊçÆ‰ª•ËØÑ‰º∞Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ 123456789101112131415# ‰∏∫È¢ÑÊµãÂàõÂª∫‰∏Ä‰∏™ËæìÂÖ•ÂáΩÊï∞predication_input_fn = lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)# Âú® linear_regressor ‰∏äË∞ÉÁî®predict()ËøõË°åÈ¢ÑÊµãpredictions = linear_regresor.predict(input_fn=predication_input_fn)# Â∞ÜÈ¢ÑÊµãÊ†ºÂºèÂåñ‰∏∫‰∏Ä‰∏™NumPyÁöÑÊï∞ÁªÑÔºåËøôÊ†∑Êàë‰ª¨Â∞±ÂèØ‰ª•ËÆ°ÁÆóÈîôËØØÂ∫¶Èáèpredictions = np.array([item['predictions'][0] for item in predictions])# ËæìÂá∫ÊñπÂ∑Æmean_squared_error = metrics.mean_squared_error(predictions, targets)root_mean_squared_error = math.sqrt(mean_squared_error)print("Mean Squared Error (on training data): %0.3f" % mean_squared_error)print("Root Mean Squared Error (on training data): %0.3f" % root_mean_squared_error) Mean Squared Error (on training data): 56367.025 Root Mean Squared Error (on training data): 237.417 Â¶Ç‰ΩïÂà§Êñ≠ËØØÂ∑ÆÊúâÂ§öÂ§ßÔºüÁî±‰∫éÂùáÊñπËØØÂ∑Æ (MSE) ÂæàÈöæËß£ËØªÔºåÂõ†Ê≠§Êàë‰ª¨ÁªèÂ∏∏Êü•ÁúãÁöÑÊòØÂùáÊñπÊ†πËØØÂ∑Æ (RMSE)„ÄÇRMSE ÁöÑ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÁâπÊÄßÊòØÔºåÂÆÉÂèØ‰ª•Âú®‰∏éÂéüÁõÆÊ†áÁõ∏ÂêåÁöÑËßÑÊ®°‰∏ãËß£ËØª„ÄÇ Êàë‰ª¨Êù•ÊØîËæÉ‰∏Ä‰∏ã RMSE ‰∏éÁõÆÊ†áÊúÄÂ§ßÂÄºÂíåÊúÄÂ∞èÂÄºÁöÑÂ∑ÆÂÄºÔºö 12345678min_house_value = california_housing_dataframe["median_house_value"].min()max_house_value = california_housing_dataframe["median_house_value"].max()min_max_difference = max_house_value - min_house_valueprint("Min. Median House Value: %0.3f" % min_house_value)print("Max. Median House Value: %0.3f" % max_house_value)print("Difference between Min. and Max.: %0.3f" % min_max_difference)print("Root Mean Squared Error: %0.3f" % root_mean_squared_error) Min. Median House Value: 14.999 Max. Median House Value: 500.001 Difference between Min. and Max.: 485.002 Root Mean Squared Error: 237.417 Êàë‰ª¨ÁöÑËØØÂ∑ÆË∑®Ë∂äÁõÆÊ†áÂÄºËøë‰∏ÄËà¨ËåÉÂõ¥Ôºå‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•Áº©Â∞èËØØÂ∑ÆÔºåÈ¶ñÂÖà‰∫ÜËß£‰∏Ä‰∏ãÊàë‰ª¨ÁöÑÈ¢ÑÊµãpredictionsÂíåtargetsÁöÑÊÄª‰ΩìÁªüËÆ°‰ø°ÊÅØ„ÄÇ 1234calibration_data = pd.DataFrame()calibration_data["predictions"] = pd.Series(predictions)calibration_data["targets"] = pd.Series(targets)calibration_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets count 17000.0 17000.0 mean 0.1 207.3 std 0.1 116.0 min 0.0 15.0 25% 0.1 119.4 50% 0.1 180.4 75% 0.2 265.0 max 1.9 500.0 Ê≠§‰ø°ÊÅØ‰πüËÆ∏Êúâ‰∫õÂ∏ÆÂä©ÔºåÊØîËæÉÁúãÁõ∏Â∑ÆËøòÊòØËõÆÂ§ßÁöÑÔºåÈÄöËøáÊï∞ÊçÆÂèØËßÜÂåñÊù•ËßÇÂØü‰∏ã Êàë‰ª¨Áü•ÈÅìÔºåÂçï‰∏™ÁâπÂæÅÁöÑÁ∫øÊÄßÂõûÂΩíÂèØ‰ª•ÁªòÂà∂‰∏ÄÊù°Â∞ÜËæìÂÖ• x Êò†Â∞ÑÂà∞ËæìÂá∫ y ÁöÑÁ∫ø„ÄÇ È¶ñÂÖàÔºåËé∑ÂæóÂùáÂåÄÂàÜÂ∏ÉÁöÑÈöèÊú∫Êï∞ÊçÆÊ†∑Êú¨Ôºå‰ª•‰æøÁªòÂà∂ÂèØËæ®ËØÜÁöÑÊï£ÁÇπÂõæ„ÄÇ 1sample = california_housing_dataframe.sample(n=300) # ÈöèÊú∫ÊäΩÊ†∑300‰∏™Êù•ËßÇÂØü ÁÑ∂ÂêéÔºåÊ†πÊçÆÊ®°ÂûãÁöÑÂÅèÂ∑ÆÈ°πÂíåÁâπÂæÅÊùÉÈáçÁªòÂà∂Â≠¶‰π†Á∫øÔºåÂπ∂ÁªòÂà∂Êï£ÁÇπÂõæ„ÄÇ 1234567891011121314151617181920212223# Ëé∑Âèñ total_rooms ÊúÄÂ§ß‰∏éÊúÄÂ∞èÂÄºx_0 = sample["total_rooms"].min()x_1 = sample["total_rooms"].max()# Ê£ÄÁ¥¢ËÆ≠ÁªÉËøáÁ®ã‰∏≠‰∫ßÁîüÁöÑÊúÄÁªàÊùÉÈáçÂíåÂÅèÂ∑Æweight = linear_regresor.get_variable_value("linear/linear_model/total_rooms/weights")[0]bias = linear_regresor.get_variable_value("linear/linear_model/bias_weights")# Ëé∑Âèñtotal_roomsÈ¢ÑÊµãÁöÑÊúÄÂ∞èÂíåÊúÄÂ§ßÂÄºy_0 = weight * x_0 + biasy_1 = weight * x_1 + bias# Áé∞Âú®Êàë‰ª¨Êúâ‰∏§‰∏™ÂùêÊ†áÂêé ÁîªÂá∫ÂõûÂΩíÁ∫øplt.plot([x_0, x_1], [y_0, y_1], c='r')# ÂÜô‰∏äÊØè‰∏™ËΩ¥‰ª£Ë°®ÁöÑÂê´‰πâplt.ylabel("median_house_value")plt.xlabel("total_rooms")# ÁîªÂá∫sample Êï∞ÊçÆÁöÑÊï£ÁÇπÂõæplt.scatter(sample["total_rooms"], sample["median_house_value"])plt.show() ËøôÊù°Á∫øÁúãËµ∑Êù•ÊòéÊòæÂíåÁõÆÊ†áÁõ∏Â∑ÆÂæàÂ§ßÔºåÁªº‰∏äÊâÄËø∞ÔºåËøô‰∫õÂàùÁ∫ßÂÅ•ÂÖ®ÊÄßÊ£ÄÊü•ÊèêÁ§∫Êàë‰ª¨‰πüËÆ∏ÂèØ‰ª•ÊâæÂà∞Êõ¥Â•ΩÁöÑÁ∫ø„ÄÇ Ë∞ÉÊï¥Ê®°ÂûãË∂ÖÂèÇÊï∞Êàë‰ª¨Êää‰ª•‰∏äÊâÄÂ≠¶ÁöÑ‰∏úË•øÊï¥ÁêÜÂà∞‰∏Ä‰∏™ÂáΩÊï∞‰∏≠Ôºå‰ª•Êñπ‰æøÊàë‰ª¨Êõ¥ÂÆπÊòìÁöÑË∞ÉÊï¥ÂèÇÊï∞ÂíåËßÇÂØüÂèòÂåñ„ÄÇ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091def train_model(learning_rate, steps, batch_size, input_feature="total_rooms"): """‰∏Ä‰∏™Á∫øÊÄßÂõûÂΩíÁöÑËÆ≠ÁªÉÊ®°Âûã ÂèÇÊï∞Ôºö learning_rate: Â≠¶‰π†ÈÄüÁéá float steps: ËÆ≠ÁªÉÊÄªÊ¨°Êï∞ int batch_size: ÊâπÂ§ÑÁêÜÂ§ßÂ∞è Èùû0 int input_feature: ‰∏Ä‰∏™' string 'ÔºåÊåáÂÆö‰∏Ä‰∏™Êù•Ëá™' california_housing_dataframe 'ÁöÑÂàóÁî®‰ΩúËæìÂÖ•ÁâπÊÄß„ÄÇ """ periods = 10 # Âë®Êúü steps_per_period = steps / periods my_feature = input_feature my_feature_data = california_housing_dataframe[[my_feature]] my_label = "median_house_value" targets = california_housing_dataframe[my_label] # ÂàõÂª∫ feature columns feature_columns = [tf.feature_column.numeric_column(my_feature)] # ÂàõÂª∫ input feature training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size) prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=True) # ÂàõÂª∫ ‰∏Ä‰∏™Á∫øÊÄßÂõûÂΩíÂØπË±° my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0) linear_regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, optimizer=my_optimizer ) # ËÆæÁΩÆÂõûÂΩíÁ∫øÁöÑÁä∂ÊÄÅ plt.figure(figsize=(15, 6)) plt.subplot(1, 2, 1) plt.title("Learned Line by Period") plt.ylabel(my_label) plt.xlabel(my_feature) sample = california_housing_dataframe.sample(n=300) plt.scatter(sample[my_feature], sample[my_label]) colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)] # ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩÜÊòØÂú®Âæ™ÁéØ‰∏≠ËøôÊ†∑ÂÅöÔºåËøôÊ†∑Êàë‰ª¨Â∞±ÂèØ‰ª•Âë®ÊúüÊÄßÂú∞ËØÑ‰º∞ # ÊçüÂ§±ÊåáÊ†á print("Training model...") print("RMSE (on training data):") root_mean_squared_errors = [] for period in range(0, periods): # ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ªé‰πãÂâçÁöÑÁä∂ÊÄÅÂºÄÂßã linear_regressor.train( input_fn=training_input_fn, steps=steps_per_period ) # ËÆ°ÁÆóÈ¢ÑÊµãÂÄº predictions = linear_regressor.predict(input_fn=prediction_input_fn) predictions = np.array([item['predictions'][0] for item in predictions]) # ËÆ°ÁÆóÊçüÂ§± root_mean_squared_error = math.sqrt( metrics.mean_squared_error(predictions, targets)) print(" period %02d : %0.2f" % (period, root_mean_squared_error)) # Ê∑ªÂä†loss Âà∞list root_mean_squared_errors.append(root_mean_squared_error) # Á∫™ÂΩïÊùÉÈáçÂíåÂÅèÂ∑Æ y_extents = np.array([0, sample[my_label].max()]) weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0] bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights') x_extents = (y_extents - bias) / weight x_extents = np.maximum(np.minimum(x_extents, sample[my_feature].max()), sample[my_feature].min()) y_extents = weight * x_extents + bias plt.plot(x_extents, y_extents, color=colors[period]) print("Model training finished.") # ËæìÂá∫‰∏Ä‰∏™Âë®ÊúüÂÜÖÊçüÂ§±ÊåáÊ†áÁöÑÂõæË°®„ÄÇ plt.subplot(1, 2, 2) plt.ylabel('RMSE') plt.xlabel('Periods') plt.title("Root Mean Squared Error vs. Periods") plt.tight_layout() plt.plot(root_mean_squared_errors) # ËæìÂá∫Â∏¶ÊúâÊ†°ÂáÜÊï∞ÊçÆÁöÑË°® calibration_data = pd.DataFrame() calibration_data["predictions"] = pd.Series(predictions) calibration_data["targets"] = pd.Series(targets) display.display(calibration_data.describe()) print("Final RMSE (on training data): %0.2f" % root_mean_squared_error) return calibration_data ËÆæÁΩÆÂèÇÊï∞ÂàùÊ≠•ËÆ≠ÁªÉ‰∏ã‰∏ÄËØïËØï 12345calibration_data = train_model( learning_rate=0.00001, steps=100, batch_size=1) Training model... RMSE (on training data): period 00 : 236.40 period 01 : 235.26 period 02 : 234.10 period 03 : 232.96 period 04 : 231.87 period 05 : 230.78 period 06 : 229.62 period 07 : 228.54 period 08 : 227.36 period 09 : 226.38 Model training finished. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets count 17000.0 17000.0 mean 13.2 207.3 std 10.9 116.0 min 0.0 15.0 25% 7.3 119.4 50% 10.6 180.4 75% 15.8 265.0 max 189.7 500.0 Final RMSE (on training data): 226.38 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets 0 9.7 66.9 1 10.6 80.1 2 7.0 85.7 3 13.6 73.4 4 14.0 65.5 ... ... ... 16995 14.1 111.4 16996 7.5 79.0 16997 20.9 103.6 16998 12.6 85.8 16999 10.9 94.6 17000 rows √ó 2 columns Â∑ÆË∑ùËøòÊòØËõÆÂ§ßÁöÑÔºåÊîπÂèòÂèÇÊï∞ËØïËØï 12345calibration_data = train_model( learning_rate=0.00002, steps=500, batch_size=5) Training model... RMSE (on training data): period 00 : 226.36 period 01 : 216.00 period 02 : 206.55 period 03 : 198.01 period 04 : 191.20 period 05 : 185.74 period 06 : 182.91 period 07 : 179.02 period 08 : 176.59 period 09 : 175.67 Model training finished. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets count 17000.0 17000.0 mean 115.8 207.3 std 95.5 116.0 min 0.1 15.0 25% 64.0 119.4 50% 93.2 180.4 75% 138.0 265.0 max 1661.6 500.0 Final RMSE (on training data): 175.67 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets 0 110.0 66.9 1 51.7 80.1 2 144.4 85.7 3 79.7 73.4 4 77.4 65.5 ... ... ... 16995 47.5 111.4 16996 138.7 79.0 16997 248.7 103.6 16998 117.8 85.8 16999 46.4 94.6 17000 rows √ó 2 columns ÊúâÈÄÇÁî®‰∫éÊ®°ÂûãË∞ÉÊï¥ÁöÑÊ†áÂáÜÂêØÂèëÊ≥ïÂêóÔºüÈôç‰ΩéRMSEÔºåËøôÊòØ‰∏Ä‰∏™Â∏∏ËßÅÁöÑÈóÆÈ¢ò„ÄÇÁÆÄÁü≠ÁöÑÁ≠îÊ°àÊòØÔºå‰∏çÂêåË∂ÖÂèÇÊï∞ÁöÑÊïàÊûúÂèñÂÜ≥‰∫éÊï∞ÊçÆ„ÄÇÂõ†Ê≠§Ôºå‰∏çÂ≠òÂú®ÂøÖÈ°ªÈÅµÂæ™ÁöÑËßÑÂàôÔºåÊÇ®ÈúÄË¶ÅÂØπËá™Â∑±ÁöÑÊï∞ÊçÆËøõË°åÊµãËØï„ÄÇ Âç≥‰æøÂ¶ÇÊ≠§ÔºåÊàë‰ª¨‰ªçÂú®‰∏ãÈù¢ÂàóÂá∫‰∫ÜÂá†Êù°ÂèØ‰∏∫ÊÇ®Êèê‰æõÊåáÂØºÁöÑÁªèÈ™åÊ≥ïÂàôÔºö ËÆ≠ÁªÉËØØÂ∑ÆÂ∫îËØ•Á®≥Ê≠•ÂáèÂ∞èÔºåÂàöÂºÄÂßãÊòØÊÄ•ÂâßÂáèÂ∞èÔºåÊúÄÁªàÂ∫îÈöèÁùÄËÆ≠ÁªÉÊî∂ÊïõËææÂà∞Âπ≥Á®≥Áä∂ÊÄÅ„ÄÇ Â¶ÇÊûúËÆ≠ÁªÉÂ∞öÊú™Êî∂ÊïõÔºåÂ∞ùËØïËøêË°åÊõ¥ÈïøÁöÑÊó∂Èó¥„ÄÇ Â¶ÇÊûúËÆ≠ÁªÉËØØÂ∑ÆÂáèÂ∞èÈÄüÂ∫¶ËøáÊÖ¢ÔºåÂàôÊèêÈ´òÂ≠¶‰π†ÈÄüÁéá‰πüËÆ∏ÊúâÂä©‰∫éÂä†Âø´ÂÖ∂ÂáèÂ∞èÈÄüÂ∫¶„ÄÇ ‰ΩÜÊúâÊó∂Â¶ÇÊûúÂ≠¶‰π†ÈÄüÁéáËøáÈ´òÔºåËÆ≠ÁªÉËØØÂ∑ÆÁöÑÂáèÂ∞èÈÄüÂ∫¶ÂèçËÄå‰ºöÂèòÊÖ¢„ÄÇ Â¶ÇÊûúËÆ≠ÁªÉËØØÂ∑ÆÂèòÂåñÂæàÂ§ßÔºåÂ∞ùËØïÈôç‰ΩéÂ≠¶‰π†ÈÄüÁéá„ÄÇ ËæÉ‰ΩéÁöÑÂ≠¶‰π†ÈÄüÁéáÂíåËæÉÂ§ßÁöÑÊ≠•Êï∞/ËæÉÂ§ßÁöÑÊâπÈáèÂ§ßÂ∞èÈÄöÂ∏∏ÊòØ‰∏çÈîôÁöÑÁªÑÂêà„ÄÇ ÊâπÈáèÂ§ßÂ∞èËøáÂ∞è‰πü‰ºöÂØºËá¥‰∏çÁ®≥ÂÆöÊÉÖÂÜµ„ÄÇ‰∏çÂ¶®ÂÖàÂ∞ùËØï 100 Êàñ 1000 Á≠âËæÉÂ§ßÁöÑÂÄºÔºåÁÑ∂ÂêéÈÄêÊ∏êÂáèÂ∞èÂÄºÁöÑÂ§ßÂ∞èÔºåÁõ¥Âà∞Âá∫Áé∞ÊÄßËÉΩÈôç‰ΩéÁöÑÊÉÖÂÜµ„ÄÇ ÈáçÁî≥‰∏Ä‰∏ãÔºåÂàáÂãø‰∏•Ê†ºÈÅµÂæ™Ëøô‰∫õÁªèÈ™åÊ≥ïÂàôÔºåÂõ†‰∏∫ÊïàÊûúÂèñÂÜ≥‰∫éÊï∞ÊçÆ„ÄÇËØ∑ÂßãÁªàËøõË°åËØïÈ™åÂíåÈ™åËØÅ„ÄÇ Â∞ùËØïÂÖ∂‰ªñÁâπÂæÅ‰ΩøÁî® population ÁâπÂæÅÊõøÊç¢ total_rooms ÁâπÂæÅÔºåÁúãÁúãËÉΩÂê¶ÂèñÂæóÊõ¥Â•ΩÁöÑÊïàÊûú„ÄÇ 123456calibration_data = train_model( learning_rate=0.00002, steps=1000, batch_size=5, input_feature="population") Training model... RMSE (on training data): period 00 : 225.40 period 01 : 214.37 period 02 : 204.42 period 03 : 195.76 period 04 : 188.29 period 05 : 182.98 period 06 : 178.93 period 07 : 175.94 period 08 : 174.97 period 09 : 175.14 Model training finished. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets count 17000.0 17000.0 mean 120.1 207.3 std 96.4 116.0 min 0.3 15.0 25% 66.4 119.4 50% 98.0 180.4 75% 144.6 265.0 max 2997.3 500.0 Final RMSE (on training data): 175.14 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets 0 116.6 66.9 1 829.3 80.1 2 97.7 85.7 3 136.3 73.4 4 41.7 65.5 ... ... ... 16995 56.4 111.4 16996 12.3 79.0 16997 83.9 103.6 16998 84.3 85.8 16999 70.1 94.6 17000 rows √ó 2 columns ÂêàÊàêÁâπÂæÅÂíåÁ¶ªÁæ§ÂÄºÂ∞ùËØïÂêàÊàêÁâπÂæÅtotal_rooms Âíå population ÁâπÂæÅÈÉΩ‰ºöÁªüËÆ°ÊåáÂÆöË°óÂå∫ÁöÑÁõ∏ÂÖ≥ÊÄªËÆ°Êï∞ÊçÆ„ÄÇ ‰ΩÜÊòØÔºåÂ¶ÇÊûú‰∏Ä‰∏™Ë°óÂå∫ÊØîÂè¶‰∏Ä‰∏™Ë°óÂå∫ÁöÑ‰∫∫Âè£Êõ¥ÂØÜÈõÜÔºå‰ºöÊÄé‰πàÊ†∑ÔºüÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫‰∏Ä‰∏™ÂêàÊàêÁâπÂæÅÔºàÂç≥ total_rooms ‰∏é population ÁöÑÊØî‰æãÔºâÊù•Êé¢Á¥¢Ë°óÂå∫‰∫∫Âè£ÂØÜÂ∫¶‰∏éÊàøÂ±ã‰ª∑ÂÄº‰∏≠‰ΩçÊï∞‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇ Âú®‰ª•‰∏ãÂçïÂÖÉÊ†º‰∏≠ÔºåÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ rooms_per_person ÁöÑÁâπÂæÅÔºåÂπ∂Â∞ÜÂÖ∂Áî®‰Ωú train_model() ÁöÑ input_feature„ÄÇ ÈÄöËøáË∞ÉÊï¥Â≠¶‰π†ÈÄüÁéáÔºåÊÇ®‰ΩøÁî®Ëøô‰∏ÄÁâπÂæÅÂèØ‰ª•Ëé∑ÂæóÁöÑÊúÄ‰Ω≥ÊïàÊûúÊòØ‰ªÄ‰πàÔºüÔºàÊïàÊûúË∂äÂ•ΩÔºåÂõûÂΩíÁ∫ø‰∏éÊï∞ÊçÆÁöÑÊãüÂêàÂ∫¶Â∞±Ë∂äÈ´òÔºåÊúÄÁªà RMSE ‰πü‰ºöË∂ä‰Ωé„ÄÇÔºâ 12345678california_housing_dataframe["rooms_per_person"] = ( california_housing_dataframe["total_rooms"] / california_housing_dataframe["population"])calibration_data = train_model( learning_rate=0.05, steps=500, batch_size=5, input_feature="rooms_per_person") Training model... RMSE (on training data): period 00 : 214.75 period 01 : 193.24 period 02 : 176.45 period 03 : 160.89 period 04 : 150.13 period 05 : 146.30 period 06 : 145.44 period 07 : 146.13 period 08 : 147.65 period 09 : 149.22 Model training finished. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets count 17000.0 17000.0 mean 200.9 207.3 std 93.2 116.0 min 44.5 15.0 25% 164.4 119.4 50% 197.8 180.4 75% 226.2 265.0 max 4443.7 500.0 Final RMSE (on training data): 149.22 ËØÜÂà´Á¶ªÁæ§ÂÄºÈÄöËøáÂàõÂª∫È¢ÑÊµãÂÄº‰∏éÁõÆÊ†áÂÄºÁöÑÊï£ÁÇπÂõæÊù•ÂèØËßÜÂåñÊ®°ÂûãÊïàÊûú„ÄÇÁêÜÊÉ≥ÊÉÖÂÜµ‰∏ãÔºåËøô‰∫õÂÄºÂ∞Ü‰Ωç‰∫é‰∏ÄÊù°ÂÆåÂÖ®Áõ∏ÂÖ≥ÁöÑÂØπËßíÁ∫ø‰∏ä„ÄÇ ‰ΩøÁî®ÊÇ®Âú®‰ªªÂä° 1 ‰∏≠ËÆ≠ÁªÉËøáÁöÑ‰∫∫ÂùáÊàøÈó¥Êï∞Ê®°ÂûãÔºåÂπ∂‰ΩøÁî® Pyplot ÁöÑ scatter() ÂàõÂª∫È¢ÑÊµãÂÄº‰∏éÁõÆÊ†áÂÄºÁöÑÊï£ÁÇπÂõæ„ÄÇ ÊÇ®ÊòØÂê¶ÁúãÂà∞‰ªª‰ΩïÂºÇÂ∏∏ÊÉÖÂÜµÔºüÈÄöËøáÊü•Áúã rooms_per_person ‰∏≠ÂÄºÁöÑÂàÜÂ∏ÉÊÉÖÂÜµÔºåÂ∞ÜËøô‰∫õÂºÇÂ∏∏ÊÉÖÂÜµËøΩÊ∫ØÂà∞Ê∫êÊï∞ÊçÆ„ÄÇ 12345plt.figure(figsize=(15, 6))plt.subplot(1, 2, 1)plt.scatter(calibration_data["predictions"], calibration_data["targets"])plt.subplot(1, 2, 2)_ = california_housing_dataframe["rooms_per_person"].hist() Ê†°ÂáÜÊï∞ÊçÆÊòæÁ§∫ÔºåÂ§ßÂ§öÊï∞Êï£ÁÇπ‰∏é‰∏ÄÊù°Á∫øÂØπÈΩê„ÄÇËøôÊù°Á∫øÂá†‰πéÊòØÂûÇÁõ¥ÁöÑÔºåÊàë‰ª¨Á®çÂêéÂÜçËÆ≤Ëß£„ÄÇÁé∞Âú®ÔºåÊàë‰ª¨ÈáçÁÇπÂÖ≥Ê≥®ÂÅèÁ¶ªËøôÊù°Á∫øÁöÑÁÇπ„ÄÇÊàë‰ª¨Ê≥®ÊÑèÂà∞Ëøô‰∫õÁÇπÁöÑÊï∞ÈáèÁõ∏ÂØπËæÉÂ∞ë„ÄÇ ËßÇÂØüÊàë‰ª¨ÁªòÂà∂ rooms_per_person ÁöÑÁõ¥ÊñπÂõæÔºåÂàô‰ºöÂèëÁé∞Êàë‰ª¨ÁöÑËæìÂÖ•Êï∞ÊçÆ‰∏≠ÊúâÂ∞ëÈáèÁ¶ªÁæ§ÂÄº Êà™ÂèñÁ¶ªÁæ§ÂÄºÂ∞Ü rooms_per_person ÁöÑÁ¶ªÁæ§ÂÄºËÆæÁΩÆ‰∏∫Áõ∏ÂØπÂêàÁêÜÁöÑÊúÄÂ∞èÂÄºÊàñÊúÄÂ§ßÂÄºÊù•Ëøõ‰∏ÄÊ≠•ÊîπËøõÊ®°ÂûãÊãüÂêàÊÉÖÂÜµ„ÄÇ ‰ª•‰∏ãÊòØ‰∏Ä‰∏™Â¶Ç‰ΩïÂ∞ÜÂáΩÊï∞Â∫îÁî®‰∫é Pandas Series ÁöÑÁÆÄÂçïÁ§∫‰æãÔºå‰æõÊÇ®ÂèÇËÄÉÔºö clipped_feature = my_dataframe[&quot;my_feature_name&quot;].apply(lambda x: max(x, 0)) ‰∏äËø∞ clipped_feature Ê≤°ÊúâÂ∞è‰∫é 0 ÁöÑÂÄº„ÄÇ ËßÇÂØüÁõ¥ÊñπÂõæÂèëÁé∞Â§ßÂ§öÊï∞Êï∞ÂÄºÈÉΩÂ∞è‰∫é5ÔºåÊàë‰ª¨Â∞Ürooms_per_person ÁöÑÂÄºÊà™Âèñ‰∏∫5ÔºåÁÑ∂ÂêéÁªòÂà∂Áõ¥ÊñπÂõæÂÜçÊ¨°Ê£ÄÊü•ÁªìÊûú„ÄÇ 1234california_housing_dataframe["rooms_per_person"] = ( california_housing_dataframe["rooms_per_person"]).apply(lambda x: min(x, 5))_ = california_housing_dataframe["rooms_per_person"].hist() È™åËØÅÊà™ÂèñÊòØÂê¶ÊúâÊïàÔºåÊàë‰ª¨ÂÜçËÆ≠ÁªÉ‰∏ÄÊ¨°Ê®°ÂûãÔºåÂπ∂ÂÜçÊ¨°ËæìÂá∫Ê†°ÂáÜÊï∞ÊçÆÔºö 12345calibration_data = train_model( learning_rate=0.05, steps=500, batch_size=5, input_feature="rooms_per_person") Training model... RMSE (on training data): period 00 : 214.33 period 01 : 192.43 period 02 : 172.30 period 03 : 155.07 period 04 : 142.01 period 05 : 134.29 period 06 : 129.31 period 07 : 128.99 period 08 : 127.60 period 09 : 126.94 Model training finished. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } predictions targets count 17000.0 17000.0 mean 189.5 207.3 std 49.3 116.0 min 45.1 15.0 25% 158.1 119.4 50% 189.6 180.4 75% 216.4 265.0 max 419.5 500.0 Final RMSE (on training data): 126.94 1_ = plt.scatter(calibration_data["predictions"], calibration_data["targets"])]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 2]]></title>
    <url>%2F2018%2F12%2F28%2FTensorFlow_2%2F</url>
    <content type="text"><![CDATA[ÂàõÂª∫ÂíåÊéßÂà∂Âº†ÈáèÁü¢ÈáèÂä†Ê≥ïÂèØ‰ª•ÂØπÂº†ÈáèÊâßË°åÈáëÂÖ∏ÁöÑÊï∞Â≠¶ËøêÁÆóÔºåËØïÁùÄÂàõÂª∫‰∏Ä‰∫õÁü¢Èáè„ÄÇ 12345678910111213141516171819202122232425from __future__ import print_functionimport tensorflow as tftry: tf.contrib.eager.enable_eager_execution() print("TF imported with eager execution!")except ValueError: print("TF already imported with eager execution!")# ‰∏Ä‰∏™ÂåÖÂê´Ë¥®Êï∞ÁöÑ‚Äòprimes‚ÄôÁü¢Èáèprimes = tf.constant([2, 3, 5, 7, 11 ,13], dtype=tf.int32)print("primes:", primes)# ‰∏Ä‰∏™ÂÄºÂÖ®‰∏∫ 1 ÁöÑ ones Áü¢Èáèones = tf.ones([6], dtype=tf.int32)print(ones)# ‰∏Ä‰∏™ÈÄöËøáÂØπÂâç‰∏§‰∏™Áü¢ÈáèÊâßË°åÂÖÉÁ¥†Á∫ßÂä†Ê≥ïËÄåÂàõÂª∫ÁöÑÁü¢Èáè„ÄÇjust_beyond_primes = tf.add(primes, ones)print(just_beyond_primes)# Êääprimes‰∏≠ÁöÑÂÖÉÁ¥†‰πò‰∫åtwos = tf.constant([2, 2, 2, 2, 2, 2], dtype=tf.int32)primes_doubled = primes * twosprint(primes_doubled) TF imported with eager execution! primes: tf.Tensor([ 2 3 5 7 11 13], shape=(6,), dtype=int32) tf.Tensor([1 1 1 1 1 1], shape=(6,), dtype=int32) tf.Tensor([ 3 4 6 8 12 14], shape=(6,), dtype=int32) tf.Tensor([ 4 6 10 14 22 26], shape=(6,), dtype=int32) ËæìÂá∫ÁöÑÂº†Èáè‰∏ç‰ªÖ‰ºöËøîÂõûÂÄºÔºåËøò‰ºöËøîÂõûÂΩ¢Áä∂shapeÔºå‰ª•ÂèäÂÇ®Â≠òÂú®Âº†Èáè‰∏≠ÁöÑÂÄºÁöÑÁ±ªÂûã„ÄÇË∞ÉÁî®numpyÊñπÊ≥ï‰ºö‰ª•NumPyÊï∞ÁªÑÁöÑÂΩ¢ÂºèËøîÂõû„ÄÇ 123some_matrix = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int32)print(some_matrix)print("\nnumpy matrix:\n", some_matrix.numpy()) tf.Tensor( [[1 2 3] [4 5 6]], shape=(2, 3), dtype=int32) numpy matrix: [[1 2 3] [4 5 6]] Âº†ÈáèÂΩ¢Áä∂shape ÊòØÁî®Êù•ÊèèËø∞Âº†ÈáèÁª¥Â∫¶Â§ßÂ∞èÂíåÊï∞Èáè„ÄÇÂº†ÈáèÁöÑÂΩ¢Áä∂Ë°®Á§∫‰∏∫listÔºåÂÖ∂‰∏≠Á¨¨ i ‰∏™ÂÖÉÁ¥†Ë°®Á§∫Áª¥Â∫¶ i ÁöÑÂ§ßÂ∞è„ÄÇÂàóË°®ÁöÑÈïøÂ∫¶Ë°®Á§∫Âº†ÈáèÁöÑÈò∂ÔºàÂç≥Áª¥Êï∞Ôºâ„ÄÇ Â¶ÇÊûúÊòØ‰∫åÁª¥ÁöÑÂàôshape=(Ë°åÊï∞Ôºå ÂàóÊï∞) ‰æãÂ¶Çshape=(n1, n2, n3, ‚Ä¶, x, y)ÂàôËØ¥Êòé ‰∏ÄÂÖ±Êúâ (n1 x n2 x n3 x ‚Ä¶.)‰∏™xË°åyÂàóÁöÑÊï∞ÁªÑÊûÑÊàê„ÄÇ ‰æãÔºö 123456789101112131415# ‰∏Ä‰∏™Ê†áÈáèscalar = tf.zeros([])# ‰∏Ä‰∏™Êúâ‰∏â‰∏™ÂÖÉÁ¥†ÁöÑÂêëÈáèvector = tf.zeros([3])# ‰∏Ä‰∏™‰∏§Ë°å‰∏âÂàóÁöÑÁü©Èòµmatrix = tf.zeros([2, 3])matrix2 = tf.zeros([2, 3, 4, 5])print('scalar has shape', scalar.get_shape(), 'and value:\n', scalar.numpy())print('vector has shape', vector.get_shape(), 'and value:\n', vector.numpy())print('matrix has shape', matrix.get_shape(), 'and value:\n', matrix.numpy())print('matrix2 has shape', matrix2.get_shape(), 'and value:\n', matrix2.numpy()) scalar has shape () and value: 0.0 vector has shape (3,) and value: [0. 0. 0.] matrix has shape (2, 3) and value: [[0. 0. 0.] [0. 0. 0.]] matrix2 has shape (2, 3, 4, 5) and value: [[[[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]] [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]] [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]]] [[[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]] [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]] [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]]]] ÂπøÊí≠Âú®Êï∞Â≠¶‰∏≠ÔºåÊÇ®Âè™ËÉΩÂØπÂΩ¢Áä∂Áõ∏ÂêåÁöÑÂº†ÈáèÊâßË°åÂÖÉÁ¥†Á∫ßËøêÁÆóÔºà‰æãÂ¶ÇÔºåÁõ∏Âä†ÂíåÁ≠â‰∫éÔºâ„ÄÇ‰∏çËøáÔºåÂú® TensorFlow ‰∏≠ÔºåÊÇ®ÂèØ‰ª•ÂØπÂº†ÈáèÊâßË°å‰º†ÁªüÊÑè‰πâ‰∏ä‰∏çÂèØË°åÁöÑËøêÁÆó„ÄÇTensorFlow ÊîØÊåÅÂπøÊí≠Ôºà‰∏ÄÁßçÂÄüÈâ¥Ëá™ NumPy ÁöÑÊ¶ÇÂøµÔºâ„ÄÇÂà©Áî®ÂπøÊí≠ÔºåÂÖÉÁ¥†Á∫ßËøêÁÆó‰∏≠ÁöÑËæÉÂ∞èÊï∞ÁªÑ‰ºöÂ¢ûÂ§ßÂà∞‰∏éËæÉÂ§ßÊï∞ÁªÑÂÖ∑ÊúâÁõ∏ÂêåÁöÑÂΩ¢Áä∂„ÄÇ‰æãÂ¶ÇÔºåÈÄöËøáÂπøÊí≠Ôºö Â¶ÇÊûúËøêÁÆóÈúÄË¶ÅÂ§ßÂ∞è‰∏∫ [6] ÁöÑÂº†ÈáèÔºåÂàôÂ§ßÂ∞è‰∏∫ [1] Êàñ [] ÁöÑÂº†ÈáèÂèØ‰ª•‰Ωú‰∏∫ËøêÁÆóÊï∞„ÄÇ Â¶ÇÊûúËøêÁÆóÈúÄË¶ÅÂ§ßÂ∞è‰∏∫ [4, 6] ÁöÑÂº†ÈáèÔºåÂàô‰ª•‰∏ã‰ªª‰ΩïÂ§ßÂ∞èÁöÑÂº†ÈáèÈÉΩÂèØ‰ª•‰Ωú‰∏∫ËøêÁÆóÊï∞Ôºö [1, 6] [6] [] Â¶ÇÊûúËøêÁÆóÈúÄË¶ÅÂ§ßÂ∞è‰∏∫ [3, 5, 6] ÁöÑÂº†ÈáèÔºåÂàô‰ª•‰∏ã‰ªª‰ΩïÂ§ßÂ∞èÁöÑÂº†ÈáèÈÉΩÂèØ‰ª•‰Ωú‰∏∫ËøêÁÆóÊï∞Ôºö [1, 5, 6] [3, 1, 6] [3, 5, 1] [1, 1, 1] [5, 6] [1, 6] [6] [1] [] Ê≥®ÊÑèÔºöÂΩìÂº†ÈáèË¢´ÂπøÊí≠Êó∂Ôºå‰ªéÊ¶ÇÂøµ‰∏äÊù•ËØ¥ÔºåÁ≥ªÁªü‰ºöÂ§çÂà∂ÂÖ∂Êù°ÁõÆÔºàÂá∫‰∫éÊÄßËÉΩËÄÉËôëÔºåÂÆûÈôÖÂπ∂‰∏çÂ§çÂà∂„ÄÇÂπøÊí≠‰∏ì‰∏∫ÂÆûÁé∞ÊÄßËÉΩ‰ºòÂåñËÄåËÆæËÆ°Ôºâ„ÄÇ ÊúâÂÖ≥ÂÆåÊï¥ÁöÑÂπøÊí≠ËßÑÂàôÈõÜÔºåËØ∑ÂèÇÈòÖÁÆÄÂçïÊòìÊáÇÁöÑ NumPy ÂπøÊí≠ÊñáÊ°£„ÄÇ ‰ª•‰∏ã‰ª£Á†ÅÊâßË°å‰∫Ü‰∏é‰πãÂâç‰∏ÄÊ†∑ÁöÑÂº†ÈáèËøêÁÆóÔºå‰∏çËøá‰ΩøÁî®ÁöÑÊòØÊ†áÈáèÂÄºÔºàËÄå‰∏çÊòØÂÖ®ÂåÖÂê´ 1 ÊàñÂÖ®ÂåÖÂê´ 2 ÁöÑÁü¢ÈáèÔºâÂíåÂπøÊí≠„ÄÇ 123456789101112primes = tf.constant([2, 3, 5, 7, 11, 13], dtype=tf.int32)print("primes:", primes)one = tf.constant(1, dtype=tf.int32)print("one:", one)just_beyond_primes = tf.add(primes, one)print("just_beyond_primes:", just_beyond_primes)two = tf.constant(2, dtype=tf.int32)primes_doubled = primes * twoprint(primes_doubled) primes: tf.Tensor([ 2 3 5 7 11 13], shape=(6,), dtype=int32) one: tf.Tensor(1, shape=(), dtype=int32) just_beyond_primes: tf.Tensor([ 3 4 6 8 12 14], shape=(6,), dtype=int32) tf.Tensor([ 4 6 10 14 22 26], shape=(6,), dtype=int32) ÁªÉ‰π† 1ÔºöÁü¢ÈáèËøêÁÆó„ÄÇÊâßË°åÁü¢ÈáèËøêÁÆó‰ª•ÂàõÂª∫‰∏Ä‰∏™‚Äújust_under_primes_squared‚ÄùÁü¢ÈáèÔºåÂÖ∂‰∏≠Á¨¨ i ‰∏™ÂÖÉÁ¥†Á≠â‰∫é primes ‰∏≠Á¨¨ i ‰∏™ÂÖÉÁ¥†ÁöÑÂπ≥ÊñπÂáè 1„ÄÇ‰æãÂ¶ÇÔºåÁ¨¨‰∫å‰∏™ÂÖÉÁ¥†‰∏∫ 3 * 3 - 1 = 8„ÄÇ ‰ΩøÁî® tf.multiply Êàñ tf.pow Êìç‰ΩúÂèØÊ±ÇÂæó primes Áü¢Èáè‰∏≠ÊØè‰∏™ÂÖÉÁ¥†ÂÄºÁöÑÂπ≥Êñπ„ÄÇ 123456789def solution(primes): primes_squared = tf.pow(primes, 2) # or tf.multiply(primes, primes) one = tf.constant(1, dtype=tf.int32) just_under_primes_squared = tf.subtract(primes_squared, one) return just_under_primes_squaredprimes = tf.constant([2, 3, 5, 7, 11, 13], dtype=tf.int32)just_under_primes_squared = solution(primes)print(just_under_primes_squared) tf.Tensor([ 3 8 24 48 120 168], shape=(6,), dtype=int32) Áü©Èòµ‰πòÊ≥ïÂú®Á∫øÊÄß‰ª£Êï∞‰∏≠ÔºåÂΩì‰∏§‰∏™Áü©ÈòµÁõ∏‰πòÊó∂ÔºåÁ¨¨‰∏Ä‰∏™Áü©ÈòµÁöÑÂàóÊï∞ÂøÖÈ°ªÁ≠â‰∫éÁ¨¨‰∫å‰∏™Áü©ÈòµÁöÑË°åÊï∞„ÄÇ 3x4 Áü©Èòµ‰πò‰ª• 4x2 Áü©ÈòµÊòØ _ÊúâÊïà_ ÁöÑÔºåÂèØ‰ª•ÂæóÂá∫‰∏Ä‰∏™ 3x2 Áü©Èòµ„ÄÇ 4x2 Áü©Èòµ‰πò‰ª• 3x4 Áü©ÈòµÊòØ _Êó†Êïà_ ÁöÑ„ÄÇ 1234567891011# ‰∏Ä‰∏™3x4ÁöÑÁü©Èòµx = tf.constant([[5, 2, 4, 3], [5, 1, 6, -2], [-1, 3, -1, -2]], dtype=tf.int32)# ‰∏Ä‰∏™4x2ÁöÑÁü©Èòµy = tf.constant([[2, 2], [3, 5], [4, 5], [1, 6]], dtype=tf.int32)# ÁªìÊûúÊòØ‰∏Ä‰∏™3x2ÁöÑÁü©Èòµmatrix_multiply_result = tf.matmul(x, y)print(matrix_multiply_result) tf.Tensor( [[35 58] [35 33] [ 1 -4]], shape=(3, 2), dtype=int32) Âº†ÈáèÂèòÂΩ¢Áî±‰∫éÂº†ÈáèÂä†Ê≥ïÂíåÁü©Èòµ‰πòÊ≥ïÂùáÂØπËøêÁÆóÊï∞ÊñΩÂä†‰∫ÜÈôêÂà∂Êù°‰ª∂ÔºåTensorFlow ÁºñÁ®ãËÄÖÈúÄË¶ÅÈ¢ëÁπÅÊîπÂèòÂº†ÈáèÁöÑÂΩ¢Áä∂„ÄÇ ÊÇ®ÂèØ‰ª•‰ΩøÁî® tf.reshape ÊñπÊ≥ïÊîπÂèòÂº†ÈáèÁöÑÂΩ¢Áä∂„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•Â∞Ü 8x2 Âº†ÈáèÂèòÂΩ¢‰∏∫ 2x8 Âº†ÈáèÊàñ 4x4 Âº†Èáè(ÊîπÂèòÂΩ¢Áä∂ÂΩ¢ÊàêÁöÑÊñ∞Áü©ÈòµÂÖÉÁ¥†Êï∞Âíå‰πãÂâçÂøÖÈ°ª‰∏ÄÊ†∑)Ôºö Ê≠§Â§ñÔºåÊÇ®ËøòÂèØ‰ª•‰ΩøÁî® tf.reshape Êõ¥ÊîπÂº†ÈáèÁöÑÁª¥Êï∞Ôºà‚ÄúÈò∂‚ÄùÔºâ„ÄÇ‰æãÂ¶ÇÔºåÊÇ®ÂèØ‰ª•Â∞Ü 8x2 Âº†ÈáèÂèòÂΩ¢‰∏∫‰∏âÁª¥ 2x2x4 Âº†ÈáèÊàñ‰∏ÄÁª¥ 16 ÂÖÉÁ¥†Âº†Èáè„ÄÇ 123456789101112131415161718192021# ÂàõÂª∫‰∏Ä‰∏™8x2ÁöÑÁü©Èòµmatrix = tf.constant( [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]], dtype=tf.int32)reshaped_2x8_matrix = tf.reshape(matrix, [2, 8])reshaped_4x4_matrix = tf.reshape(matrix, [4, 4])print("Original matrix (8x2):")print(matrix.numpy())print("Reshaped matrix (2x8):")print(reshaped_2x8_matrix.numpy())print("Reshaped matrix (4x4):")print(reshaped_4x4_matrix.numpy())reshaped_2x2x4_tensor = tf.reshape(matrix, [2, 2, 4])one_dimensional_vector = tf.reshape(matrix, [16])print("Reshaped 3-D tensor (2x2x4):")print(reshaped_2x2x4_tensor.numpy())print("1-D vector:")print(one_dimensional_vector.numpy()) Original matrix (8x2): [[ 1 2] [ 3 4] [ 5 6] [ 7 8] [ 9 10] [11 12] [13 14] [15 16]] Reshaped matrix (2x8): [[ 1 2 3 4 5 6 7 8] [ 9 10 11 12 13 14 15 16]] Reshaped matrix (4x4): [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12] [13 14 15 16]] Reshaped 3-D tensor (2x2x4): [[[ 1 2 3 4] [ 5 6 7 8]] [[ 9 10 11 12] [13 14 15 16]]] 1-D vector: [ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16] ÁªÉ‰π† 2ÔºöÊîπÂèò‰∏§‰∏™Âº†ÈáèÁöÑÂΩ¢Áä∂Ôºå‰ΩøÂÖ∂ËÉΩÂ§üÁõ∏‰πò„ÄÇ‰∏ãÈù¢‰∏§‰∏™Áü¢ÈáèÊó†Ê≥ïËøõË°åÁü©Èòµ‰πòÊ≥ïËøêÁÆóÔºö a = tf.constant([5, 3, 2, 7, 1, 4]) b = tf.constant([4, 6, 3]) ËØ∑ÊîπÂèòËøô‰∏§‰∏™Áü¢ÈáèÁöÑÂΩ¢Áä∂Ôºå‰ΩøÂÖ∂Êàê‰∏∫ÂèØ‰ª•ËøõË°åÁü©Èòµ‰πòÊ≥ïËøêÁÆóÁöÑËøêÁÆóÊï∞„ÄÇÁÑ∂ÂêéÔºåÂØπÂèòÂΩ¢ÂêéÁöÑÂº†ÈáèË∞ÉÁî®Áü©Èòµ‰πòÊ≥ïËøêÁÆó„ÄÇ 12345678910111213a = tf.constant([5, 3, 2, 7, 1, 4])b = tf.constant([4, 6, 3])reshaped_a = tf.reshape(a, [2, 3])reshaped_b = tf.reshape(b, [3, 1])c = tf.matmul(reshaped_a, reshaped_b)print("reshaped_a (2x3):")print(reshaped_a.numpy())print("reshaped_b (3x1):")print(reshaped_b.numpy())print("reshaped_a x reshaped_b (2x1):")print(c.numpy()) reshaped_a (2x3): [[5 3 2] [7 1 4]] reshaped_b (3x1): [[4] [6] [3]] reshaped_a x reshaped_b (2x1): [[44] [46]] ÂèòÈáè„ÄÅÂàùÂßãÂåñÂíåËµãÂÄºÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊàë‰ª¨ÊâßË°åÁöÑÊâÄÊúâËøêÁÆóÈÉΩÈíàÂØπÁöÑÊòØÈùôÊÄÅÂÄº (tf.constant)ÔºõË∞ÉÁî® numpy() ÂßãÁªàËøîÂõûÂêå‰∏ÄÁªìÊûú„ÄÇÂú® TensorFlow ‰∏≠ÂèØ‰ª•ÂÆö‰πâ Variable ÂØπË±°ÔºåÂÆÉÁöÑÂÄºÊòØÂèØ‰ª•Êõ¥ÊîπÁöÑ„ÄÇ ÂàõÂª∫ÂèòÈáèÊó∂ÔºåÊÇ®ÂèØ‰ª•ÊòéÁ°ÆËÆæÁΩÆ‰∏Ä‰∏™ÂàùÂßãÂÄºÔºå‰πüÂèØ‰ª•‰ΩøÁî®ÂàùÂßãÂåñÁ®ãÂ∫èÔºà‰æãÂ¶ÇÂàÜÂ∏ÉÔºâÔºö 123456789# ÂàõÂª∫ÂàùÂßãÂÄº‰∏∫3ÁöÑÊ†áÈáèÂèòÈáèv = tf.contrib.eager.Variable([3])# ÂàõÂª∫‰∏Ä‰∏™ÂΩ¢Áä∂‰∏∫[1,4]ÁöÑÁü¢ÈáèÂèòÈáèÔºåÂÖ∂ÂàùÂßãÂÄº‰∏∫ÈöèÊú∫ÁöÑ# ‰ªéÂùáÂÄº‰∏∫1ÔºåÊ†áÂáÜÂ∑Æ‰∏∫0.35ÁöÑÊ≠£ÊÄÅÂàÜÂ∏É‰∏≠ÂèñÊ†∑w = tf.contrib.eager.Variable(tf.random_normal([1, 4], mean=1.0, stddev=0.35))print("v:", v.numpy())print("w:", w.numpy()) v: [3] w: [[0.7752843 1.516361 1.1726708 0.9872638]] Ë¶ÅÊõ¥ÊîπÂèòÈáèÁöÑÂÄºÔºåËØ∑‰ΩøÁî® assign Êìç‰ΩúÔºåÂπ∂‰∏îÂêëÂèòÈáèËµã‰∫àÊñ∞ÂÄºÊó∂ÔºåÂÖ∂ÂΩ¢Áä∂ÂøÖÈ°ªÂíå‰πãÂâçÁöÑÂΩ¢Áä∂‰∏ÄËá¥„ÄÇ 1234567891011121314151617v = tf.contrib.eager.Variable([3])print(v.numpy())tf.assign(v, [7])print(v.numpy())v.assign([5])print(v.numpy())v = tf.contrib.eager.Variable([[1, 2, 3], [4, 5, 6]])print(v.numpy())try: print("Assigning [7, 8, 9] to v") v.assign([7, 8, 9])except ValueError as e: print("Exception:", e) [3] [7] [5] [[1 2 3] [4 5 6]] Assigning [7, 8, 9] to v Exception: Shapes (2, 3) and (3,) are incompatible ÁªÉ‰π† 3ÔºöÊ®°ÊãüÊäïÊé∑‰∏§‰∏™È™∞Â≠ê 10 Ê¨°„ÄÇÂàõÂª∫‰∏Ä‰∏™È™∞Â≠êÊ®°ÊãüÔºåÂú®Ê®°Êãü‰∏≠ÁîüÊàê‰∏Ä‰∏™ 10x3 ‰∫åÁª¥Âº†ÈáèÔºåÂÖ∂‰∏≠Ôºö Âàó 1 Âíå 2 ÂùáÂ≠òÂÇ®‰∏Ä‰∏™ÂÖ≠Èù¢È™∞Â≠êÔºàÂÄº‰∏∫ 1-6ÔºâÁöÑ‰∏ÄÊ¨°ÊäïÊé∑ÂÄº„ÄÇ Âàó 3 Â≠òÂÇ®Âêå‰∏ÄË°å‰∏≠Âàó 1 Âíå 2 ÁöÑÂÄºÁöÑÊÄªÂíå„ÄÇ ‰æãÂ¶ÇÔºåÁ¨¨‰∏ÄË°å‰∏≠ÂèØËÉΩ‰ºöÂåÖÂê´‰ª•‰∏ãÂÄºÔºö Âàó 1 Â≠òÂÇ® 4 Âàó 2 Â≠òÂÇ® 3 Âàó 3 Â≠òÂÇ® 7 Ë¶ÅÂÆåÊàêÊ≠§‰ªªÂä°ÔºåÊÇ®ÈúÄË¶ÅÊµèËßà TensorFlow ÊñáÊ°£„ÄÇ 123456789die1 = tf.contrib.eager.Variable( tf.random_uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))die2 = tf.contrib.eager.Variable( tf.random_uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))dice_sum = tf.add(die1, die2)resulting_matrix = tf.concat(values=[die1, die2, dice_sum], axis=1)print(resulting_matrix) tf.Tensor( [[ 2 3 5] [ 5 6 11] [ 3 3 6] [ 5 6 11] [ 2 1 3] [ 6 5 11] [ 1 4 5] [ 1 1 2] [ 4 6 10] [ 5 4 9]], shape=(10, 3), dtype=int32)]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 1]]></title>
    <url>%2F2018%2F12%2F26%2FTensorFlow_1%2F</url>
    <content type="text"><![CDATA[Hello WorldÂΩìtensorflowÁöÑÁéØÂ¢ÉÊê≠Âª∫Â•ΩÂêéÊàë‰ª¨Â∞±ÂèØ‰ª•Â∞ùËØïrun‰∏ã‰∫ÜÔºåÂÖàÂÜô‰∏™hello worldÁúãÁúãÂêß„ÄÇ 12345678910from __future__ import print_functionimport tensorflow as tftry: tf.contrib.eager.enable_eager_execution()except ValueError: passtensor = tf.constant('Hello, world!')tensor_value = tensor.numpy()print(tensor_value) b&apos;Hello, world!&apos; TensorFlow ÁºñÁ®ãÊ¶ÇÂøµTensorFlowÁöÑÂêçÁß∞Ê∫êËá™Âº†ÈáèÔºåÂº†ÈáèÊòØ‰ªªÊÑèÁª¥Â∫¶ÁöÑÊï∞ÁªÑ„ÄÇÂÄüÂä©TensorFlowÔºåÂèØ‰ª•Êìç‰ΩúÂÖ∑ÊúâÂæàÂ§ßÁª¥Â∫¶ÁöÑÂº†Èáè„ÄÇ Ê†áÈáèÊòØÈõ∂Áª¥Êï∞ÁªÑÔºàÈõ∂Èò∂Âº†ÈáèÔºâ„ÄÇ‰æãÂ¶ÇÔºö&apos;hi&apos; Êàñ 3 Áü¢ÈáèÊòØ‰∏ÄÁª¥Êï∞ÁªÑÔºà‰∏ÄÈò∂Âº†ÈáèÔºâ„ÄÇ‰æãÂ¶ÇÔºö[2, 3, 5, 7, 11] Êàñ [3] Áü©ÈòµÊòØ‰∫åÁª¥Êï∞ÁªÑÔºà‰∫åÈò∂Âº†ÈáèÔºâ„ÄÇ‰æãÂ¶ÇÔºö[[3.1, 8.2, 5.9][4.3, -2.7, 6.5]] TensorFlowÊåá‰ª§‰ºöÂàõÂª∫ÔºåÈîÄÊØÅÂíåÊéßÂà∂Âº†Èáè„ÄÇÂÖ∏ÂûãTensorFlowÁ®ãÂ∫è‰∏≠ÁöÑÂ§ßÂ§öÊï∞‰ª£Á†ÅÈÉΩÊòØÊåá‰ª§„ÄÇTensorFlowÂõæÔºà‰πüÂè´ ËÆ°ÁÆóÂõæ Êàñ Êï∞ÊçÆÊµÅÂõæÔºâÊòØ‰∏ÄÁßçÂõæÊï∞ÊçÆÁªìÊûÑ„ÄÇÂæàÂ§öTensorFlowÁ®ãÂ∫èÁî±Âçï‰∏™ÂõæÊûÑÊàêÔºå‰ΩÜÊòØTensorFlowÁ®ãÂ∫èÂèØ‰ª•ÈÄâÊã©ÂàõÂª∫Â§ö‰∏™Âõæ„ÄÇÂõæÁöÑËäÇÁÇπÊòØÊåá‰ª§ÔºõÂõæÁöÑËæπÊòØÂº†Èáè„ÄÇÂº†ÈáèÊµÅÁªèÂõæÔºåÂú®ÊØè‰∏™ËäÇÁÇπÁî±‰∏Ä‰∏™Êåá‰ª§ÊìçÊéß„ÄÇ‰∏Ä‰∏™Êåá‰ª§ÁöÑËæìÂá∫Âº†ÈáèÈÄöÂ∏∏‰ºöÂèòÊàêÂêéÁª≠Êåá‰ª§ÁöÑËæìÂÖ•Âº†Èáè„ÄÇTensorFlow‰ºöÂÆûÁé∞Âª∂ËøüÊâßË°åÊ®°ÂûãÔºåÊÑèÂë≥ÁùÄÁ≥ªÁªü‰ªÖ‰ºöÊ†πÊçÆÁõ∏ÂÖ≥ËäÇÁÇπÁöÑÈúÄÊ±ÇÂú®ÈúÄË¶ÅÊó∂ËÆ°ÁÆóËäÇÁÇπ„ÄÇ Âº†ÈáèÂèØ‰ª•‰Ωú‰∏∫Â∏∏ÈáèÊàñÂèòÈáèÂÇ®Â≠òÂú®Âõæ‰∏≠„ÄÇÂ∏∏ÈáèÂÇ®Â≠òÁöÑÊòØÂÄºÊòØ‰∏ç‰ºöÂèëÁîüÊõ¥ÊîπÁöÑÂº†ÈáèÔºåËÄåÂèòÈáèÂÇ®Â≠òÁöÑÂÄºÊòØ‰ºöÂèëÁîüÊõ¥ÊîπÁöÑÂº†Èáè„ÄÇÂ∏∏ÈáèÂíåÂèòÈáèÈÉΩÂè™ÊòØÂõæ‰∏≠ÁöÑ‰∏ÄÁßçÊåá‰ª§„ÄÇÂ∏∏ÈáèÊòØÂßãÁªà‰ºöËøîÂõûÂêå‰∏ÄÂº†ÈáèÂÄºÂæóÊåá‰ª§„ÄÇÂèòÈáèÊòØ‰ºöËøîÂõûÂàÜÈÖçÁªôÂæó‰ªª‰ΩïÂº†ÈáèÁöÑÊåá‰ª§„ÄÇ Ë¶ÅÂÆö‰πâÂ∏∏ÈáèÔºå‰ΩøÁî®tf.constantÊåá‰ª§ÔºåÂπ∂‰º†ÂÖ•ÂÆÉÁöÑÂÄº„ÄÇ‰æãÂ¶ÇÔºö x = tf.constant([1.2]) ÂêåÊ†∑ÔºåÂèØ‰ª•ÂàõÂª∫ÂèòÈáèÔºö y = tf.Variable([3]) ÊîπÂèòÂÄºÔºö y = y.assign([1]) ÂàõÂª∫Â•ΩÂèòÈáèÊàñÂ∏∏ÈáèÂêéÔºåÂèØ‰ª•ÂØπÂÆÉ‰ª¨‰ΩøÁî®ÂÖ∂‰ªñÊåá‰ª§ÔºàÂ¶Çtf.addÔºâ„ÄÇ ÂõæÂøÖÈ°ªÂú®TensorFlow‰ºöËØù‰∏≠ËøêË°åÔºå‰ºöËØùÂÇ®Â≠ò‰∫ÜÂÆÉÊâÄËøêË°åÁöÑÂõæÁöÑÁä∂ÊÄÅÔºö Â∞Ü tf.Session()‰Ωú‰∏∫‰ºöËØùÔºö initialization = tf.global_variables_initializer() print(y.eval()) Âú®‰ΩøÁî®tf.VariableÊó∂ÂèØ‰ª•Ë∞ÉÁî®tf.global_variables_initializerÔºå‰ª•ÊòéÁ°ÆÂàùÂßãÂåñËøô‰∫õÂèòÈáè„ÄÇ Ê≥®ÊÑèÔºö‰ºöËØùÂèØ‰ª•Â∞ÜÂõæÂàÜÂèëÂà∞Â§ö‰∏™Êú∫Âô®‰∏äÊâßË°åÔºàÂÅáËÆæÁ®ãÂ∫èÂú®Êüê‰∏™ÂàÜÂ∏ÉÂºèËÆ°ÁÆóÊ°ÜÊû∂‰∏äËøêË°åÔºâ„ÄÇ ÊÄªÁªìTensorFlowÁºñÁ®ãÊúâ‰∏§‰∏™ÊµÅÁ®ãÔºö 1.Â∞ÜÂ∏∏ÈáèÔºåÂèòÈáèÂíåÊåá‰ª§Êï¥ÂêàÂà∞‰∏Ä‰∏™Âõæ‰∏≠„ÄÇ 2.Âú®‰∏Ä‰∏™‰ºöËØù‰∏≠ËØÑ‰º∞Ëøô‰∫õÂ∏∏ÈáèÔºåÂèòÈáèÂíåÊåá‰ª§„ÄÇ ÂàõÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑ TensorFlow Á®ãÂ∫èÊàë‰ª¨Êù•ÁúãÁúãÂ¶Ç‰ΩïÁºñÂÜô‰∏Ä‰∏™Â∞Ü‰∏§‰∏™Â∏∏ÈáèÁõ∏Âä†ÁöÑÁÆÄÂçï TensorFlow Á®ãÂ∫è„ÄÇ Ê∑ªÂä† import ËØ≠Âè•ÊÉ≥Ë¶ÅËøêË°åtensorflowÁ®ãÂ∫èÔºåÂøÖÈ°ªÊ∑ªÂä†ËøôÂè•Ôºö 1import tensorflow as tf ÂÖ∂‰ªñÂ∏∏ËßÅÁöÑimportËØ≠Âè•ÂåÖÊã¨Ôºö import matplotlib.pyplot as plt # Êï∞ÊçÆÂèØËßÜÂåñ import numpy as np # ËæÉ‰ΩéÁ∫ßÁöÑÊï∞Â≠¶pythonÂ∫ì import pandas as pd # ËæÉÈ´òÁ∫ßÁöÑÊï∞Â≠¶pythonÂ∫ì 123456789101112131415from __future__ import print_functionimport tensorflow as tf# ÂàõÂª∫‰∏Ä‰∏™Âõæg = tf.Graph()with g.as_default(): # ÂàõÂª∫‰∏â‰∏™ÈáèÔºå x = tf.constant(8, name="x_const") y = tf.constant(5, name="y_const") sum = tf.add(x, y, name="x_y_sum") python # ÂàõÂª∫‰∏Ä‰∏™‰ºöËØùÔºåÂ∞Ü‰ºöÊâßË°åÈªòËÆ§Âõæ with tf.Session() as sess: print(sum.eval()) TF already imported with eager execution! 13]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlowÂ≠¶‰π†ÂâçÁöÑÂáÜÂ§áÂ∑•‰Ωú]]></title>
    <url>%2F2018%2F12%2F24%2Ftensorflow%E5%AD%A6%E4%B9%A0%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Â∑•Ê¨≤ÂñÑÂÖ∂‰∫ãÂøÖÂÖàÂà©ÂÖ∂Âô®ÔºåÂú®Â≠¶‰π†tensor flow‰πãÂâçÈúÄË¶ÅÂÖàÂ≠¶‰ºö‰ΩøÁî®‰∏Ä‰∫õÂ∑•ÂÖ∑ÔºåÈ¶ñÂÖàÊòØjupyterÔºåËøô‰πãÂêéÂÖ≥‰∫étensor flowÁöÑblog‰πüÈÉΩ‰ºöÂÜôÊàêjupyterÊ†ºÂºèÁöÑ„ÄÇ JupyterJupyter Notebook ÁöÑÊú¨Ë¥®ÊòØ‰∏Ä‰∏™ Web Â∫îÁî®Á®ãÂ∫èÔºå‰æø‰∫éÂàõÂª∫ÂíåÂÖ±‰∫´ÊñáÂ≠¶ÂåñÁ®ãÂ∫èÊñáÊ°£ÔºåÊîØÊåÅÂÆûÊó∂‰ª£Á†ÅÔºåÊï∞Â≠¶ÊñπÁ®ãÔºåÂèØËßÜÂåñÂíå markdown„ÄÇ Áî®ÈÄîÂåÖÊã¨ÔºöÊï∞ÊçÆÊ∏ÖÁêÜÂíåËΩ¨Êç¢ÔºåÊï∞ÂÄºÊ®°ÊãüÔºåÁªüËÆ°Âª∫Ê®°ÔºåÊú∫Âô®Â≠¶‰π†Á≠âÁ≠â„ÄÇ ÂÆòÁΩëÔºöJupyter Installing Jupyter with pip12345678910111213As an existing or experienced Python user, you may wish to install Jupyter using Python‚Äôs package manager, pip, instead of Anaconda.If you have Python 3 installed (which is recommended):python3 -m pip install --upgrade pippython3 -m pip install jupyterIf you have Python 2 installed:python -m pip install --upgrade pippython -m pip install jupyterCongratulations, you have installed Jupyter Notebook! To run the notebook, run the following command at the Terminal (Mac/Linux) or Command Prompt (Windows):run: jupyter notebook ÂÆâË£ÖÊàêÂäüÂêéÊâßË°å jupyter notebook Âêé‰ºöÊâìÂºÄ‰∏Ä‰∏™webÔºåÈÄöËøáÁΩëÈ°µÂ∞±ÂèØ‰ª•ÊâßË°åpythonÁ®ãÂ∫è„ÄÇ ËøòÂèØ‰ª•ÊääipynbÊñá‰ª∂ËΩ¨Êç¢‰∏∫htmlÔºåmdÔºåpdfÁ≠âÊ†ºÂºè 12ipython nbconvert --to markdown filename.ipynbipython nbconvert --to html filename.ipynb ipynbËΩ¨Êç¢‰∏∫html„ÄÅmd„ÄÅpdfÁ≠âÊ†ºÂºèÔºåËøòÊúâÂè¶‰∏ÄÁßçÊõ¥ÁÆÄÂçïÁöÑÊñπÊ≥ïÔºöÂú®jupyter notebook‰∏≠ÔºåÈÄâÊã©File-&gt;Download asÔºåÁõ¥Êé•ÈÄâÊã©ÈúÄË¶ÅËΩ¨Êç¢ÁöÑÊ†ºÂºèÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåËΩ¨Êç¢‰∏∫pdfÊ†ºÂºè‰πãÂâçÔºåÂêåÊ†∑Ë¶Å‰øùËØÅÂ∑≤ÁªèÂÆâË£Ö‰∫Üxelatex„ÄÇ Âü∫Á°ÄÁü•ËØÜÂü∫Á°ÄÊï∞Â≠¶123456789101112131415161718‰ª£Êï∞ÂèòÈáè„ÄÅÁ≥ªÊï∞ÂíåÂáΩÊï∞Á∫øÊÄßÊñπÁ®ãÂºèÔºå‰æãÂ¶Ç ÂØπÊï∞ÂíåÂØπÊï∞ÊñπÁ®ãÂºèÔºå‰æãÂ¶Ç S ÂûãÂáΩÊï∞Á∫øÊÄß‰ª£Êï∞Âº†ÈáèÂíåÂº†ÈáèÁ≠âÁ∫ßÁü©Èòµ‰πòÊ≥ï‰∏âËßíÂ≠¶TanhÔºà‰Ωú‰∏∫ÊøÄÊ¥ªÂáΩÊï∞ËøõË°åËÆ≤Ëß£ÔºåÊó†ÈúÄÊèêÂâçÊéåÊè°Áõ∏ÂÖ≥Áü•ËØÜÔºâÁªüËÆ°‰ø°ÊÅØÂùáÂÄº„ÄÅ‰∏≠Èó¥ÂÄº„ÄÅÁ¶ªÁæ§ÂÄºÂíåÊ†áÂáÜÂÅèÂ∑ÆËÉΩÂ§üËØªÊáÇÁõ¥ÊñπÂõæÂæÆÁßØÂàÜÔºàÂèØÈÄâÔºåÈÄÇÂêàÈ´òÁ∫ß‰∏ªÈ¢òÔºâÂØºÊï∞Ê¶ÇÂøµÔºàÊÇ®‰∏çÂøÖÁúüÊ≠£ËÆ°ÁÆóÂØºÊï∞ÔºâÊ¢ØÂ∫¶ÊàñÊñúÁéáÂÅèÂØºÊï∞Ôºà‰∏éÊ¢ØÂ∫¶Á¥ßÂØÜÁõ∏ÂÖ≥ÔºâÈìæÂºèÊ≥ïÂàôÔºàÂ∏¶ÊÇ®ÂÖ®Èù¢‰∫ÜËß£Áî®‰∫éËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÁöÑÂèçÂêë‰º†Êí≠ÁÆóÊ≥ïÔºâ Âü∫Á°Ä Python123456789101112131415Python ÊïôÁ®ã‰∏≠‰ªãÁªç‰∫Ü‰ª•‰∏ã Python Âü∫Á°ÄÁü•ËØÜÔºöÂÆö‰πâÂíåË∞ÉÁî®ÂáΩÊï∞Ôºö‰ΩøÁî®‰ΩçÁΩÆÂíåÂÖ≥ÈîÆÂ≠óÂèÇÊï∞Â≠óÂÖ∏„ÄÅÂàóË°®„ÄÅÈõÜÂêàÔºàÂàõÂª∫„ÄÅËÆøÈóÆÂíåËø≠‰ª£Ôºâfor Âæ™ÁéØÔºöÂåÖÂê´Â§ö‰∏™Ëø≠‰ª£Âô®ÂèòÈáèÁöÑ for Âæ™ÁéØÔºà‰æãÂ¶Ç for a, b in [(1,2), (3,4)]Ôºâif/else Êù°‰ª∂ÂùóÂíåÊù°‰ª∂Ë°®ËææÂºèÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÔºà‰æãÂ¶Ç '%.2f' % 3.14ÔºâÂèòÈáè„ÄÅËµãÂÄº„ÄÅÂü∫Êú¨Êï∞ÊçÆÁ±ªÂûãÔºàint„ÄÅfloat„ÄÅbool„ÄÅstrÔºâpass ËØ≠Âè• Python Â∫ì1234567891011121314151617Êú∫Âô®Â≠¶‰π†ÈÄüÊàêËØæÁ®ã‰ª£Á†ÅÁ§∫‰æã‰ΩøÁî®‰∫ÜÁ¨¨‰∏âÊñπÂ∫ìÊèê‰æõÁöÑ‰ª•‰∏ãÂäüËÉΩ„ÄÇÊó†ÈúÄÊèêÂâçÁÜüÊÇâËøô‰∫õÂ∫ìÔºõÊÇ®ÂèØ‰ª•Âú®ÈúÄË¶ÅÊó∂Êü•ËØ¢Áõ∏ÂÖ≥ÂÜÖÂÆπ„ÄÇMatplotlibÔºàÈÄÇÂêàÊï∞ÊçÆÂèØËßÜÂåñÔºâpyplot Ê®°Âùócm Ê®°Âùógridspec Ê®°ÂùóSeabornÔºàÈÄÇÂêàÁÉ≠ÂõæÔºâheatmap ÂáΩÊï∞PandasÔºàÈÄÇÂêàÊï∞ÊçÆÂ§ÑÁêÜÔºâDataFrame Á±ªNumPyÔºàÈÄÇÂêà‰ΩéÈò∂Êï∞Â≠¶ËøêÁÆóÔºâlinspace ÂáΩÊï∞random ÂáΩÊï∞array ÂáΩÊï∞arange ÂáΩÊï∞scikit-learnÔºàÈÄÇÂêàËØÑ‰º∞ÊåáÊ†áÔºâmetrics Ê®°Âùó Bash shellÁü•ÈÅìÂëΩ‰ª§Ë°åÔºå‰ºöÊï≤ÂëΩ‰ª§„ÄÇ PandasÊúÄÂêéË¶ÅÁü•ÈÅìPandasÂ∫ì‰∏≠DataFrameÁöÑÊï∞ÊçÆÁªìÊûÑÔºåÁúãÂè¶‰∏ÄÁØáÂçöÂÆ¢ÔºåPandasÁÆÄ‰ªã„ÄÇ ‰ª•‰∏äÈÉΩ‰∏ç‰ºö‰πüÊ≤°ÊúâÂÖ≥Á≥ªÔºåÊØïÁ´ütensor flowÊòØÁªôÂ≠¶ÈæÑÂâçÂÑøÁ´•Áé©ËÄçÁöÑ„ÄÇ TensorFlowÂÆòÁΩëËøôÈáåÊèê‰æõ‰∫ÜÈùûÂ∏∏ËØ¶ÁªÜÁöÑ‰∏≠ÊñáÊïôÁ®ã ÊàëÊ≤°ÊúâÊê≠Âª∫ÂÆû‰ΩìÁéØÂ¢ÉÔºåÊòØÈÄöËøáColaboratoryÊù•ÂÆûÈ™å‰ª£Á†Å„ÄÇ ColaboratoryColaboratoryÊòØGoogleÁöÑ‰∏Ä‰∏™Á†îÁ©∂È°πÁõÆÔºåÊó®Âú®Êèê‰æõÂºÄÂèëËÄÖ‰∏Ä‰∏™‰∫ëÁ´ØËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÁöÑÂ∑•ÂÖ∑„ÄÇÂÆÉÊòØJupyter‰∏Ä‰∏™Á¨îËÆ∞Êú¨ÁéØÂ¢ÉÔºå‰∏çÁî®ÂÅö‰ªª‰ΩïÈÖçÁΩÆÔºåÂÆåÂÖ®ËøêË°åÂú®‰∫ëÁ´Ø„ÄÇColaboratoryÂ≠òÂÇ®Âú®Google Drive‰∏≠ÔºåÂèØ‰ª•ËøõË°åÂÖ±‰∫´„ÄÇColaboratoryÂêëÂºÄÂèëËÄÖÊèê‰æõ‰∫ÜÂÖçË¥πÁöÑTesla K80 GPU‰ΩøÁî®„ÄÇ ÂÆûÁî®ÁöÑÈîÆÁõòÂø´Êç∑ÈîÆ ‚åò/Ctrl+m,bÔºöÂú®ÂΩìÂâçÈÄâÊã©ÁöÑÂçïÂÖÉÊ†º‰∏ãÊñπÂàõÂª∫‰∏Ä‰∏™Á©∫ÁôΩ‰ª£Á†ÅÂçïÂÖÉÊ†º ‚åò/Ctrl+m,iÔºö‰∏≠Êñ≠ÂçïÂÖÉÊ†ºÁöÑËøêË°å ‚åò/Ctrl+m,hÔºöÊòæÁ§∫ÊâÄÊúâÈîÆÁõòÂø´Êç∑ÈîÆÂàóË°® Ë¶ÅÊü•ÁúãÂÖ≥‰∫é‰ªª‰Ωï TensorFlow API ÊñπÊ≥ïÁöÑÊñáÊ°£ÔºåËØ∑Â∞ÜÂÖâÊ†áÊîæÁΩÆÂú®ÂÖ∂Â∑¶Êã¨Âè∑ÁöÑÊ≠£ÂêéÊñπÔºåÁÑ∂ÂêéÊåâ Tab ÈîÆÔºö]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas ÁÆÄ‰ªã]]></title>
    <url>%2F2018%2F12%2F23%2FPandas%20%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Ëøô‰∏™ÊòØÂ≠¶‰π†tensorflowÂâçÁöÑÂáÜÂ§áÔºå pandas ÊòØ‰∏ÄÁßçÂàóÂ≠òÊï∞ÊçÆÂàÜÊûê API„ÄÇÂÆÉÊòØÁî®‰∫éÂ§ÑÁêÜÂíåÂàÜÊûêËæìÂÖ•Êï∞ÊçÆÁöÑÂº∫Â§ßÂ∑•ÂÖ∑ÔºåÂæàÂ§öÊú∫Âô®Â≠¶‰π†Ê°ÜÊû∂ÈÉΩÊîØÊåÅÂ∞Ü pandas Êï∞ÊçÆÁªìÊûÑ‰Ωú‰∏∫ËæìÂÖ•„ÄÇ ËôΩÁÑ∂ÂÖ®Êñπ‰Ωç‰ªãÁªç pandas API ‰ºöÂç†ÊçÆÂæàÈïøÁØáÂπÖÔºå‰ΩÜÂÆÉÁöÑÊ†∏ÂøÉÊ¶ÇÂøµÈùûÂ∏∏ÁÆÄÂçïÔºåÊàë‰ª¨‰ºöÂú®‰∏ãÊñá‰∏≠ËøõË°åËØ¥Êòé„ÄÇÊúâÂÖ≥Êõ¥ÂÆåÊï¥ÁöÑÂèÇËÄÉÔºåËØ∑ËÆøÈóÆ pandas ÊñáÊ°£ÁΩëÁ´ôÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏∞ÂØåÁöÑÊñáÊ°£ÂíåÊïôÁ®ãËµÑÊ∫ê„ÄÇ Âü∫Êú¨Ê¶ÇÂøµÂØºÂÖ•pandas Âπ∂ËæìÂá∫ÁâàÊú¨123from __future__ import print_functionimport pandas as pdprint(pd.__version__) 0.23.4 pandas‰∏≠ÁöÑ‰∏ªË¶ÅÊï∞ÊçÆÁªìÊûÑË¢´Êó∂Èôê‰∏∫‰∏Ä‰∏ã‰∏§Á±ªÔºö DataFrameÔºö ‰∏Ä‰∏™ÂÖ≥Á≥ªÂûãÊï∞ÊçÆË°®Ê†ºÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§öË°åÂíåÂ∑≤ÂëΩÂêçÁöÑÂàóÔºåÂ∞±ÂÉèexcel‰∏ÄÊ†∑ SeriesÔºöÂÆÉÊòØÂçïÁã¨ÁöÑ‰∏ÄÂàóÔºåDataFrame‰∏≠ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™SeriesÔºåÊØè‰∏™SeriesÈÉΩÊúâ‰∏Ä‰∏™ÂêçÁß∞„ÄÇÂ∞±ÂÉèÊàë‰ª¨ÂÜô‰∏™Ë°®Ê†ºÂú®Á¨¨‰∏ÄÂàóÂÜô‰∏äÊØè‰∏ÄË°å‰ª£Ë°®‰ªÄ‰πà‰∏ÄÊ†∑„ÄÇ Êï∞ÊçÆÊ°ÜÊû∂ÊòØÁî®‰∫éÊï∞ÊçÆÊìçÊéßÁöÑ‰∏ÄÁßçÂ∏∏Áî®ÊäΩË±°ÂÆûÁé∞ÂΩ¢ÂºèÔºåspark‰∏≠ÁöÑrddÔºåÊï∞ÊçÆÂ∫ì‰∏≠ÁöÑtable Á±ª‰ºº„ÄÇ ÂàõÂª∫SeriesÁöÑ‰∏ÄÁßçÊñπÊ≥ïÊòØÊûÑÂª∫SeriesÂØπË±°„ÄÇÂàóÂÖ•Ôºö1pd.Series(['Beijing', 'Shanghai', 'Shenzhen']) ‰Ω†ÂèØ‰ª•Â∞ÜÊò†Â∞ÑstringÂàóÂêçÁß∞ÁöÑdict‰º†ÈÄíÂà∞ÂÆÉ‰ª¨ÂêÑËá™ÁöÑSeriesÔºå‰ªéËÄåÂàõÂª∫DataFrameÂØπË±°„ÄÇÂ¶ÇÊûúSeriesÂú®ÈïøÂ∫¶‰∏ä‰∏ç‰∏ÄËá¥ÔºåÁ≥ªÁªü‰ºöÁî®ÁâπÊÆäÁöÑNAÂÄºÂ°´ÂÖÖÁº∫Â§±ÁöÑÂÄº„ÄÇ 12345city_names = pd.Series(['Beijing', 'Shanghai', 'Shenzhen'])population = pd.Series([21534678, 23541023, 120456])data = pd.DataFrame(&#123;'City name': city_names, 'Population': population&#125;)print(data) 1234 City name Population0 Beijing 215346781 Shanghai 235410232 Shenzhen 120456 Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÈúÄË¶ÅÊääÊï¥‰∏™Êñá‰ª∂Âä†ËΩΩÂà∞DataFrame‰∏≠Ôºå‰∏ãÈù¢Êàë‰ª¨Âä†ËΩΩ‰∏Ä‰∏™ÂåÖÂê´Âä†Âà©Á¶èÂ∞º‰∫öÂ∑û‰ΩèÊàøÁöÑÊï∞ÊçÆÊñá‰ª∂„ÄÇÂπ∂ÂàõÂª∫ÁâπÂæÅÂÆö‰πâÔºåÈÄöËøáheadÊñπÊ≥ïÊµèËßàDataFrameÂâçÂá†‰∏™Á∫™ÂΩï 123california_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",")california_housing_dataframe.describe()print(california_housing_dataframe.head()) 12345678 longitude latitude ... median_income median_house_value0 -114.31 34.19 ... 1.4936 66900.01 -114.47 34.40 ... 1.8200 80100.02 -114.56 33.69 ... 1.6509 85700.03 -114.57 33.64 ... 3.1917 73400.04 -114.57 33.57 ... 1.9250 65500.0[5 rows x 9 columns] pandasÁöÑÂè¶‰∏Ä‰∏™Âº∫Â§ßÁöÑÂäüËÉΩÊòØÁªòÂõæÂà∂Ë°®ÔºåÂÄüÂä©DataFrame.histÔºåÂèØ‰ª•Âø´ÈÄü‰∫ÜËß£‰∏Ä‰∏™Âàó‰∏≠ÂÄºÁöÑÂàÜÂ∏É„ÄÇpandas‰ΩøÁî®ÁöÑÁîªÂõæÂ∫ìÊòØmatplotlibÊâÄ‰ª•Êàë‰ª¨‰πüÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™Â∫ì‰∏≠ÁöÑÊñπÊ≥ïÊù•Êìç‰ΩúÂõæË°®„ÄÇ 123import matplotlib.pyplot as plthist = california_housing_dataframe.hist('housing_median_age')plt.show() ËÆøÈóÆÊï∞ÊçÆÂèØ‰ª•‰ΩøÁî® dict Êàñlist ÁöÑÊñπÊ≥ïÊù•ËÆøÈóÆDataFrameÊï∞ÊçÆ123456789cities = pd.DataFrame(&#123;'City name': city_names, 'Population': population&#125;)print(type(cities['City name']))print(cities['City name'])print(type(cities['City name'][1]))print(cities['City name'][1])print(type(cities[0:2]))print(cities[0:2]) 12345678910111213&lt;class 'pandas.core.series.Series'&gt;0 Beijing1 Shanghai2 ShenzhenName: City name, dtype: object&lt;class 'str'&gt;Shanghai&lt;class 'pandas.core.frame.DataFrame'&gt; City name Population0 Beijing 215346781 Shanghai 23541023 ÊìçÊéßÊï∞ÊçÆÂèØ‰ª•ÂêëseriesÂ∫îÁî®PythonÁöÑÂü∫Êú¨Áî®ÁÆóÊåá‰ª§„ÄÇ1234population / 10000 21534.6781 23541.0232 120.456 NumPyÊòØ‰∏Ä‰∏™Áî®‰∫éÁßëÂ≠¶ËÆ°ÁÆóÁöÑÂ∏∏Áî®Â∑•ÂÖ∑ÂåÖ„ÄÇpandas seriesÂèØ‰ΩúÁî®Â§ßÂ§öÊï∞NumPyÂáΩÊï∞ÁöÑÂèÇÊï∞„ÄÇ1234567import numpy as npnp.log(population)0 13.6558921 13.8311722 13.092314dtype: float64 ÂØπ‰∫éÊõ¥Âä†Â§çÊùÇÁöÑÂçïÂàóËΩ¨Êç¢ÔºåÂèØ‰ª•‰ΩøÁî®Series.apply„ÄÇÂÉèPythonÊò†Â∞ÑÂáΩÊï∞‰∏ÄÊ†∑ÔºåSeries.applyÂ∞Ü‰ª•ÂèÇÊï∞ÂΩ¢ÂºèÊé•ÂèólambdaÂáΩÊï∞ÔºåËÄåËØ•ÂáΩÊï∞‰ºöÂ∫îÁî®‰∏éÊØè‰∏™ÂÄºÔºå‰∏ãÈù¢ÁöÑ‰æãÂ≠êÊòØÂàõÂª∫‰∏Ä‰∏™populationÊòØÂê¶Ë∂ÖËøá‰∏ÄÂÆöÊï∞ÂÄºÁöÑseries„ÄÇ 123456print(population.apply(lambda val: val &gt; 1000000))0 True1 True2 Falsedtype: bool DataFramesÁöÑ‰øÆÊîπÊñπÂºè‰πüÈùûÂ∏∏ÁÆÄÂçï„ÄÇ‰æãÂ¶ÇÔºå‰∏Ä‰∏ã‰ª£Á†ÅÂêëÁé∞ÊúâÁöÑDataFrameÊ∑ªÂä†‰∫Ü‰∏§‰∏™Series„ÄÇ12345678cities['Area square miles'] = pd.Series([98.87, 176.53, 46.92]) # Èöè‰æøÂÜôÁöÑÊï∞cities['Population density'] = cities['Population'] / cities['Area square miles']print(cities) City name ... Population density0 Beijing ... 217808.0105191 Shanghai ... 133354.2344082 Shenzhen ... 2567.263427 ÁªÉ‰π†1ÈÄöËøáÊ∑ªÂä†‰∏Ä‰∏™Êñ∞ÁöÑÂ∏ÉÂ∞îÂÄºÂàóÔºå‰øÆÊîπcitiesË°®Ê†º ÂüéÂ∏Ç‰ª•shÂºÄÂ§¥ ÂüéÂ∏ÇÈù¢ÁßØÂ§ß‰∫é50 Ôºà‰∏äÈù¢Êï∞ÈÉΩÊòØÊàëÈöè‰æøÂÜôÁöÑÔºâ Ê≥®ÊÑèÔºöÂ∏ÉÂ∞îÂÄº Series 1 Ëæë‰∏éÊó∂ÔºåÂ∫î‰ΩøÁî® &amp;ÔºåËÄå‰∏çÊòØ and„ÄÇ12345678910cities['Is wide and has Sh name'] = (cities['Area square miles'] &gt; 50) &amp; cities['City name'].apply(lambda name: name.startswith('Sh'))print(cities) City name ... Is wide and has Sh name0 Beijing ... False1 Shanghai ... True2 Shenzhen ... False[3 rows x 5 columns] Á¥¢ÂºïSeriesÂíåDataFrameÂØπË±°‰πüÂÆö‰πâ‰∫ÜindexÂ±ûÊÄßÔºåÊîπÂ±ûÊÄßÂêëÊØè‰∏™SeriesÈ°πÊàñDataFrameË°åËµã‰∏Ä‰∏™Ê†áËØÜÁ¨¶ÂÄº„ÄÇÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåÂú®ÊûÑÈÄ†Êó∂Ôºåpandas‰ºöËµãÂèØÂèçÂ∫îÊï∞ÊçÆÊ∫êÊï∞ÊçÆÈ°∫Â∫èÁöÑÁ¥¢ÂºïÂÄº„ÄÇÁ¥¢ÂºïÂÄºÂú®ÂàõÂª∫ÂêéÊó∂Á®≥ÂÆöÁöÑÔºõ‰πüÂ∞±ÊòØËØ¥Ôºå‰ªñ‰ª¨‰∏ç‰ºöÂõ†‰∏∫Êï∞ÊçÆÈáçÊñ∞ÊéíÂ∫èËÄåÂèëÁîüÊîπÂèò„ÄÇ 123456789101112131415161718192021print(city_names.index)RangeIndex(start=0, stop=3, step=1)print(cities.index)RangeIndex(start=0, stop=3, step=1)print(cities.reindex([2, 0, 1])) City name ... Is wide and has Sh name2 Shenzhen ... False0 Beijing ... False1 Shanghai ... True[3 rows x 5 columns]print(cities.reindex(np.random.permutation(cities.index))) City name ... Is wide and has Sh name0 Beijing ... False2 Shanghai ... True1 Shenzhen ... False[3 rows x 5 columns] ÁªÉ‰π†2reindexÊñπÊ≥ïÂÖÅËÆ∏‰ΩøÁî®Êú™ÂåÖÂê´Âú®ÂéüÂßãDataFrameÁ¥¢ÂºïÂÄº‰∏≠ÁöÑÁ¥¢ÂºïÂÄº„ÄÇËØ∑Á§∫‰∏Ä‰∏ãÔºåÁúãÁúãÂ¶ÇÊûú‰ΩøÁî®Ê≠§Á±ªÂÄº‰ºöÂèëÁîü‰ªÄ‰πà„ÄÇ Â¶ÇÊûúreindexËæìÂÖ•Êï∞ÁªÑÂåÖÂê´ÂéüÂßãDataFrameÁ¥¢ÂºïÂÄº‰∏≠Ê≤°ÊúâÁöÑÂÄºÔºåreindex‰ºö‰∏∫Ê≠§Á±ª‚Äú‰∏¢Â§±ÁöÑ‚ÄùÁ¥¢ÂºïÊ∑ªÂä†Êñ∞Ë°åÔºåÂπ∂Âú®ÊâÄÊúâÂØπÂ∫îÂàó‰∏≠Â°´ÂÖÖNaNÂÄº 12345678cities.reindex([0,4,5,2]) City name ... Is wide and has Sh name0 Beijing ... False4 NaN ... NaN5 NaN ... NaN2 Shenzhen ... False[4 rows x 5 columns] ËøôÁßçË°å‰∏∫ÊòØÂèØÂèñÁöÑÔºåÂõ†‰∏∫Á¥¢ÂºïÈÄöÂ∏∏ÊòØ‰ªéÂÆûÈôÖÊï∞ÊçÆ‰∏≠ÊèêÂèñÁöÑÂ≠óÁ¨¶‰∏≤ÔºåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂ¶ÇÊûúÂÆπËÆ∏Âá∫Áé∞‚Äú‰∏¢Â§±ÁöÑ‚ÄùÁ¥¢ÂºïÔºåÂ∞ÜÂèØ‰ª•ËΩªÊùæÁöÑ‰ΩøÁî®Â§ñÈÉ®ÂàóË°®ÈáçÂª∫Á¥¢ÂºïÔºåÂõ†‰∏∫Êàë‰ª¨‰∏çÂøÖÊãÖÂøÉÂ∞ÜËæìÂÖ•Ê∏ÖÁêÜÊéâ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex8-anomaly detection and recommendation]]></title>
    <url>%2F2018%2F11%2F20%2Fex8-anomaly%20detection%20and%20recommendation%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex6-anomaly detection and recommendation ËøôÊòØÊúÄÂêé‰∏Ä‰∏™ÁªÉ‰π†‰∫ÜÔºåÂÖ±Êúâ‰∏§‰∏™ÁÆóÊ≥ïÔºåÁ¨¨‰∏Ä‰∏™ÊòØÂºÇÂ∏∏Ê£ÄÊµãÔºåÁ¨¨‰∫å‰∏™ÊòØÊé®ËçêÁ≥ªÁªü„ÄÇ ÂºÇÂ∏∏Ê£ÄÊµã‰πãÂâçÂÜôËøá‰∫ÜËøôÈáåÂ∞±‰∏çÂÜçÈáçÂ§ç‰∫ÜÔºöPythonÂÆûÁé∞ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï Êé®ËçêÁ≥ªÁªüÊé®ËçêÁ≥ªÁªü‰ΩøÁî®ÁöÑÁÆóÊ≥ïÂ∞±ÊòØÂçèÂêåËøáÊª§Ôºàcollaborative ltering learning algorithmÔºâ È¶ñÂÖàÊù•ÁúãÊèê‰æõÁöÑÊï∞ÊçÆÈÉΩÊúâ‰∫õ‰ªÄ‰πàÔºåÊõ¥ÂÖ∑PDFÂèØÁü•ÔºåÊúâ5‰∏™Êñá‰ª∂ÊòØÊàë‰ª¨ÈúÄË¶ÅÁöÑÊï∞ÊçÆÈõÜÂêà„ÄÇ Êï∞ÊçÆÈõÜÂêçÁß∞ ÂÜÖÂÆπ movie_ids.txt ÁîµÂΩ±ÁöÑÂàóË°® ex8data1.mat Áî®‰∫éÂºÇÂ∏∏Ê£ÄÊµãÁöÑÁ¨¨‰∏Ä‰∏™Á§∫‰æãÊï∞ÊçÆÈõÜ ex8data2.mat Áî®‰∫éÂºÇÂ∏∏Ê£ÄÊµãÁöÑÁ¨¨‰∫å‰∏™Á§∫‰æãÊï∞ÊçÆÈõÜ ex8_movies.mat ÁîµÂΩ±ËØÑËÆ∫Êï∞ÊçÆÈõÜ ex8_movieParams.mat ‰∏∫Ë∞ÉËØïÊèê‰æõÁöÑÂèÇÊï∞ ÂØºÂÖ•Â∫ìÂíåÊ£ÄÊü•Êï∞ÊçÆÈõÜex8_movies.mat‰∏≠Êúâ‰∏§‰∏™Ê†áÁ≠æÁöÑÊï∞ÊçÆÔºåYÊòØ1682‰∏™ÁîµÂΩ±ÁöÑËØÑÂàÜÔºåÊØè‰∏™ÁîµÂΩ±Êúâ943Êù°‰∫î‰∏™Á∫ßÂà´ÁöÑËØÑÂàÜÔºåRÊòØ‰∏Ä‰∏™ÂíåYÁõ∏ÂêåÁª¥Â∫¶ÁöÑ‰∫åËøõÂà∂Êï∞ÁªÑÔºå0‰ª£Ë°®ËØÑËøáÂàÜÔºå1‰ª£Ë°®Ê≤°ËØÑÂàÜ„ÄÇ % Notes: X - num_movies (1682) x num_features (10) matrix of movie features% Theta - num_users (943) x num_features (10) matrix of user features% Y - num_movies x num_users matrix of user ratings of movies% R - num_movies x num_users matrix, where R(i, j) = 1 if the% i-th movie was rated by the j-th user 1234567891011121314151617181920212223242526#!/usr/bin/python# coding=utf-8import scipy.io as sioimport matplotlib.pyplot as pltimport numpy as npimport seaborn as snsimport pandas as pdsns.set(context="notebook", style="white")# YÊòØÂåÖÂê´‰ªé1Âà∞5ÁöÑÁ≠âÁ∫ßÁöÑÔºàÊï∞ÈáèÁöÑÁîµÂΩ±xÊï∞ÈáèÁöÑÁî®Êà∑ÔºâÊï∞ÁªÑ.RÊòØÂåÖÂê´ÊåáÁ§∫Áî®Êà∑ÊòØÂê¶ÁªôÁîµÂΩ±ËØÑÂàÜÁöÑ‰∫åËøõÂà∂ÂÄºÁöÑ‚ÄúÊåáÁ§∫Á¨¶‚ÄùÊï∞ÁªÑ„ÄÇmovies_mat = sio.loadmat('./data/ex8_movies.mat');Y, R = movies_mat.get('Y'), movies_mat.get('R')print(Y.shape, R.shape)# (1682, 943) (1682, 943)m, u = Y.shape# m: how many movies# u: how many usersn = 10# how many features for a movieparam_mat = sio.loadmat('./data/ex8_movieParams.mat')theta, X = param_mat.get('Theta'), param_mat.get('X')print(theta.shape, X.shape)# (943, 10) (1682, 10) cost function Âú®ÂØπfeatureËøêÁÆóÊó∂ÔºåÊàë‰ª¨ÂÖàÊääparams serialize‰∏∫Âè™Êúâ‰∏Ä‰∏™Áª¥Â∫¶ÁöÑÊï∞ÁªÑÔºåÈÄöËøádeserializeÂáΩÊï∞Êù•ÊÅ¢Â§ç‰∏∫ÂéüÁä∂„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def serialize(X, theta): # serialize 2 matrix # X(move, feature), (1682, 10): movie features # theta (user, feature), (943, 10): user preference # 1682*10 + 943*10 = (26250,) return np.concatenate((X.ravel(), theta.ravel()))def deserialize(param, n_movie, n_user, n_featuers): # into ndarray of X(1682, 10), theta(943, 10) return param[:n_movie * n_featuers].reshape(n_movie, n_featuers),\ param[n_movie * n_featuers:].reshape(n_user, n_featuers)# recomendation fndef cost(param, Y, R, n_features): """compute cost for every r(i, j) = 1 arg: param: serialized X, theta Y (movie, user), (1682, 943): (movie, user) rating R (movie, user), (1682, 943): (movie, user) has rating """ # theta (user, feat) # X(movie, feature), (1682, 10): movie features n_movie, n_user = Y.shape X, theta = deserialize(param, n_movie, n_user, n_features) inner = np.multiply(X @ theta.T - Y, R) return np.power(inner, 2).sum() / 2def gradient(param, Y, R, n_features): # theta (user, feature), (943, 10): user preference # X(movie, feature), (1682, 10): movie features n_movies, n_user = Y.shape X, theta = deserialize(param, n_movies, n_user, n_features) inner = np.multiply(X @ theta.T - Y, R) # (1682, 943) # X_grad (1682, 10) X_grad = inner @ theta # theta_grad (943, 10) theta_grad = inner.T @ X # roll them together and return return serialize(X_grad, theta_grad)def regularized_cost(param, Y, R, n_features, l=1): reg_term = np.power(param, 2).sum() * (1/2) return cost(param, Y, R, n_features) + reg_termdef regularized_gradient(param, Y, R, n_features, l=1): grad = gradient(param, Y, R, n_features) reg_term = l * param return grad + reg_term ÊåâÁÖßÁªÉ‰π†8‰∏≠ÁöÑÂèÇÊï∞costËæìÂá∫‰∏∫22ÔºåÈ™åËØÅÁªìÊûú‚Äú 12345678910111213# ÊåâÁÖßÁªÉ‰π†‰∏≠ÁªôÂá∫ËÆ°ÁÆóÁªìÊûú‰∏∫22users = 4movies = 5features = 3X_sub = X[:movies, :features]theta_sub = theta[:users, :features]Y_sub = Y[:movies, :users]R_sub = R[:movies, :users]param_sub = serialize(X_sub, theta_sub)c = cost(param_sub, Y_sub, R_sub, features)print(c) # 22.224603725685675 ËÆ°ÁÆó‰∏Ä‰∏ãÊÄªÁöÑcost 12345# total readl paramsparam = serialize(X, theta)# total costtotal_cost = cost(param, Y, R, 10)print(total_cost) # 27918.64012454421 gradient function 123456n_movie, n_user = Y.shapeX_grad, theta_grad = deserialize(gradient(param, Y, R, 10), n_movie, n_user, 10)assert X_grad.shape == X.shapeassert theta_grad.shape == theta.shape regularized cost and gradient 123456789101112131415# regularized cost# in the ex8_confi.m, lambda = 1.5, and it's using sub data setreg_cost = regularized_cost(param_sub, Y_sub, R_sub, features, l=1.5)print(reg_cost) # 28.304238738078038# total regularized costtotal_cost = regularized_cost(param, Y, R, 10, l=1)print(total_cost) # 32520.682450229557n_movie, n_user = Y.shapeX_grad, theta_grad = deserialize(regularized_gradient(param, Y, R, 10), n_movie, n_user, 10)assert X_grad.shape == X.shapeassert theta_grad.shape == theta.shape parse movie_id.txt12345678# parse movie_id.txtmovie_list = []with open('./data/movie_ids.txt', encoding='latin-1') as f: for line in f: tokens = line.strip().split(' ') movie_list.append(' '.join(tokens[1:]))movie_list = np.array(movie_list) ÁªôÁîµÂΩ±ÊâìÂàÜ12345678910111213# reproduce my ratingsratings = np.zeros(1682)ratings[0] = 4ratings[6] = 3ratings[11] = 5ratings[53] = 4ratings[63] = 5ratings[65] = 3ratings[68] = 5ratings[97] = 2ratings[182] = 4ratings[225] = 5ratings[354] = 5 Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊääÊàë‰ª¨ÁöÑËØÑ‰ª∑ÊèíÂÖ•Âà∞ÊâÄÊúâÁîµÂΩ±ÁöÑËØÑÂàÜ‰∏≠ÂéªÔºåÊääÂèÇÊï∞thetaÂíåXÂ§ÑÁêÜ‰∏∫Ê≠£ÊÄÅÂàÜÂ∏É„ÄÇ 1234567891011121314151617181920212223# prepare data# now I become user 0Y, R = movies_mat.get('Y'), movies_mat.get('R')Y = np.insert(Y, 0, ratings, axis=1)R = np.insert(R, 0, ratings != 0, axis=1)print(Y.shape) # (1682, 944)print(R.shape) # (1682, 944)n_features = 50n_movie, n_user = Y.shapel = 10# ËΩ¨Êç¢‰∏∫Ê≠£ÊÄÅÂàÜÂ∏ÉX = np.random.standard_normal((n_movie, n_features))theta = np.random.standard_normal((n_user, n_features))print(X.shape, theta.shape) # (1682, 50) (944, 50)param = serialize(X, theta)# normalized ratingsY_norm = Y - Y.mean()print(Y_norm.mean()) # 4.6862111343939375e-17 ËÆ≠ÁªÉ123456789# trainingimport scipy.optimize as optres = opt.minimize(fun=regularized_cost, x0=param, args=(Y_norm, R, n_features, l), method='TNC', jac=regularized_gradient)print(res) Á®çÁ≠â‰∏Ä‰ºöÂÑøÂæóÂà∞‰∏Ä‰∏ãÁªìÊûú12345678910 fun: 24268.448311691616 jac: array([-12.49378802, 14.209063 , -6.75343791, ..., 0.61519582, -1.32599207, 0.58813019])message: 'Converged (|f_n-f_(n-1)| ~= 0)' nfev: 219 nit: 14 status: 1success: True x: array([-0.30795529, 0.88620348, -0.10899471, ..., 0.18986581, -0.28537047, -0.11540767]) Ê£ÄÊü•Êé®ËçêÁªìÊûúy=np.argsort(x)Â∞Üx‰∏≠ÁöÑÂÖÉÁ¥†‰ªéÂ∞èÂà∞Â§ßÊéíÂàóÔºåÊèêÂèñÂÖ∂ÂØπÂ∫îÁöÑindex(Á¥¢Âºï)ÔºåÁÑ∂ÂêéËæìÂá∫Âà∞y1234567891011121314X_trained, theta_trained = deserialize(res.x, n_movie, n_user, n_features)print(X_trained.shape, theta_trained.shape)prediction = X_trained @ theta_trained.Tmy_preds = prediction[:, 0] + Y.mean()idx = np.argsort(my_preds)[::-1] # descending orderprint(idx.shape)# top ten idxmy_preds[idx][:10]for m in movie_list[idx][:10]: print(m) 12345678910Godfather, The (1972)Forrest Gump (1994)Star Wars (1977)Titanic (1997)Shawshank Redemption, The (1994)Raiders of the Lost Ark (1981)Return of the Jedi (1983)Usual Suspects, The (1995)Braveheart (1995)Empire Strikes Back, The (1980) ÊØèÊ¨°ÂæóÂà∞ÁöÑÁªìÊûúÊúâ‰∏™Âà´Â∑ÆÂà´Ôºå‰ΩÜÊòØ‰∏ÉÊàêÊó∂Ê≤°ÊúâÂèòÂåñÁöÑ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex7-k means and PCA]]></title>
    <url>%2F2018%2F11%2F07%2Fex7-k%20means%20and%20PCA%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex7-k means and PCA ÁªÉ‰π†Áî®Êï∞ÊçÆ Âú®Êú¨ÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨Â∞ÜÂÆûÁé∞K-meansËÅöÁ±ªÔºåÂπ∂‰ΩøÁî®ÂÆÉÊù•ÂéãÁº©ÂõæÂÉè„ÄÇ Êàë‰ª¨Â∞Ü‰ªé‰∏Ä‰∏™ÁÆÄÂçïÁöÑ2DÊï∞ÊçÆÈõÜÂºÄÂßãÔºå‰ª•‰∫ÜËß£K-meansÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÔºåÁÑ∂ÂêéÊàë‰ª¨Â∞ÜÂÖ∂Â∫îÁî®‰∫éÂõæÂÉèÂéãÁº©„ÄÇ Êàë‰ª¨ËøòÂ∞ÜÂØπ‰∏ªÊàêÂàÜÂàÜÊûêËøõË°åÂÆûÈ™åÔºåÂπ∂‰∫ÜËß£Â¶Ç‰Ωï‰ΩøÁî®ÂÆÉÊù•ÊâæÂà∞Èù¢ÈÉ®ÂõæÂÉèÁöÑ‰ΩéÁª¥Ë°®Á§∫„ÄÇ Implementing K-meansÊàë‰ª¨Â∞ÜÂÆûÊñΩÂíåÂ∫îÁî®K-meansÂà∞‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰∫åÁª¥Êï∞ÊçÆÈõÜÔºå‰ª•Ëé∑Âæó‰∏Ä‰∫õÁõ¥ËßÇÁöÑÂ∑•‰ΩúÂéüÁêÜ„ÄÇ K-meansÊòØ‰∏Ä‰∏™Ëø≠‰ª£ÁöÑÔºåÊó†ÁõëÁù£ÁöÑËÅöÁ±ªÁÆóÊ≥ïÔºåÂ∞ÜÁ±ª‰ººÁöÑÂÆû‰æãÁªÑÂêàÊàêÁ∞á„ÄÇ ËØ•ÁÆóÊ≥ïÈÄöËøáÁåúÊµãÊØè‰∏™Á∞áÁöÑÂàùÂßãËÅöÁ±ª‰∏≠ÂøÉÂºÄÂßãÔºåÁÑ∂ÂêéÈáçÂ§çÂ∞ÜÂÆû‰æãÂàÜÈÖçÁªôÊúÄËøëÁöÑÁ∞áÔºåÂπ∂ÈáçÊñ∞ËÆ°ÁÆóËØ•Á∞áÁöÑËÅöÁ±ª‰∏≠ÂøÉ„ÄÇ Êàë‰ª¨Ë¶ÅÂÆûÁé∞ÁöÑÁ¨¨‰∏ÄÈÉ®ÂàÜÊòØÊâæÂà∞Êï∞ÊçÆ‰∏≠ÊØè‰∏™ÂÆû‰æãÊúÄÊé•ËøëÁöÑËÅöÁ±ª‰∏≠ÂøÉÁöÑÂáΩÊï∞„ÄÇ ÂèØËßÜÂåñÊï∞ÊçÆ1234567891011121314151617#!/usr/bin/python# coding=utf-8import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sbfrom scipy.io import loadmat# Êï∞ÊçÆÂèØËßÜÂåñdata = loadmat('data/ex7data2.mat')X = data['X']data2 = pd.DataFrame(data.get('X'), columns=['X1', 'X2'])print(data2.head())sb.set(context="notebook", style="white")sb.lmplot('X1', 'X2', data=data2, fit_reg=False)plt.show() Finding closest centroids$c^{(i)} := j\ that\ minimizes\ ||x^i - u_j||^2 $ ËÆ°ÁÆóÊØè‰∏Ä‰∏™ÁâπÂæÅÂÄºÂà∞ÊâÄÈÄâÂèñÁöÑËÅöÁ±ª‰∏≠ÂøÉÁöÑË∑ùÁ¶ªÔºåÁ∫™ÂΩïÊúÄÁü≠Ë∑ùÁ¶ªÁöÑËÅöÁ±ª‰∏≠ÂøÉÁºñÂè∑„ÄÇ 123456789101112131415161718192021def find_closest_centroids(X, centroids): m = X.shape[0] k = centroids.shape[0] idx = np.zeros(m) for i in range(m): min_dist = 1000000 for j in range(k): dist = np.sum((X[i, :] - centroids[j, :]) ** 2) if dist &lt; min_dist: min_dist = dist idx[i] = j return idx initial_centroids = initial_centroids = np.array([[3, 3], [6, 2], [8, 5]])idx = find_closest_centroids(X, initial_centroids)print(idx[: 3]) [0. 2. 1.] ËæìÂá∫‰∏éÊñáÊú¨‰∏≠ÁöÑÈ¢ÑÊúüÂÄºÂåπÈÖçÔºàËÆ∞‰ΩèÊàë‰ª¨ÁöÑÊï∞ÁªÑÊòØ‰ªéÈõ∂ÂºÄÂßãÁ¥¢ÂºïÁöÑÔºåËÄå‰∏çÊòØ‰ªé‰∏ÄÂºÄÂßãÁ¥¢ÂºïÁöÑÔºåÊâÄ‰ª•ÂÄºÊØîÁªÉ‰π†‰∏≠ÁöÑÂÄº‰Ωé‰∏Ä‰∏™Ôºâ„ÄÇ Computing centroid meansÊé•‰∏ãÊù•ÔºåÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™ÂáΩÊï∞Êù•ËÆ°ÁÆóÁ∞áÁöÑËÅöÁ±ª‰∏≠ÂøÉ„ÄÇ ËÅöÁ±ª‰∏≠ÂøÉÂè™ÊòØÂΩìÂâçÂàÜÈÖçÁªôÁ∞áÁöÑÊâÄÊúâÊ†∑Êú¨ÁöÑÂπ≥ÂùáÂÄº„ÄÇ123456789101112def compute_centroids(X, idx, k): m, n = X.shape centroids = np.zeros((k, n)) for i in range(k): indices = np.where(idx == i) centroids[i, :] = (np.sum(X[indices, :], axis=1) / len(indices[0])).ravel() return centroidsprint(compute_centroids(X, idx, 3)) [[2.42830111 3.15792418] [5.81350331 2.63365645] [7.11938687 3.6166844 ]] Ê≠§ËæìÂá∫‰πüÁ¨¶ÂêàÁªÉ‰π†‰∏≠ÁöÑÈ¢ÑÊúüÂÄº„ÄÇ ‰∏ã‰∏ÄÈÉ®ÂàÜÊ∂âÂèäÂÆûÈôÖËøêË°åËØ•ÁÆóÊ≥ïÁöÑ‰∏Ä‰∫õËø≠‰ª£Ê¨°Êï∞ÂíåÂèØËßÜÂåñÁªìÊûú„ÄÇ Ëøô‰∏™Ê≠•È™§ÊòØÁî±‰∫éÂπ∂‰∏çÂ§çÊùÇÔºåÊàëÂ∞Ü‰ªéÂ§¥ÂºÄÂßãÊûÑÂª∫ÂÆÉ„ÄÇ ‰∏∫‰∫ÜËøêË°åÁÆóÊ≥ïÔºåÊàë‰ª¨Âè™ÈúÄË¶ÅÂú®Â∞ÜÊ†∑Êú¨ÂàÜÈÖçÁªôÊúÄËøëÁöÑÁ∞áÂπ∂ÈáçÊñ∞ËÆ°ÁÆóÁ∞áÁöÑËÅöÁ±ª‰∏≠ÂøÉ„ÄÇ K-means on example dataset12345678910111213141516171819202122232425262728293031323334353637383940414243444546centroids_trace = np.empty(shape=[0, 2])def run_k_means(X, initial_centroids, max_iters): m, n = X.shape k = initial_centroids.shape[0] idx = np.zeros(m) centroids = initial_centroids global centroids_trace for i in range(max_iters): idx = find_closest_centroids(X, centroids) centroids = compute_centroids(X, idx, k) centroids_trace = np.append(centroids_trace, centroids, axis=0) return idx, centroidsdef init_centroids(X, k): m, n = X.shape centroids = np.zeros((k, n)) idx = np.random.randint(0, m, k) for i in range(k): centroids[i, :] = X[idx[i], :] return centroidsinitial_centroids = init_centroids(X, 3)idx, centroids = run_k_means(X, initial_centroids, 10)cluster1 = X[np.where(idx == 0)[0], :]cluster2 = X[np.where(idx == 1)[0], :]cluster3 = X[np.where(idx == 2)[0], :]fig, ax = plt.subplots(figsize=(12, 8))ax.scatter(cluster1[:, 0], cluster1[:, 1], s=30, color='r', label='Cluster 1')ax.scatter(cluster2[:, 0], cluster2[:, 1], s=30, color='g', label='Cluster 2')ax.scatter(cluster3[:, 0], cluster3[:, 1], s=30, color='b', label='Cluster 3')ax.legend()x = centroids_trace[:, 0]y = centroids_trace[:, 1]ax.scatter(x, y, color='black', s=50, zorder=2)plt.show() Image compression with K-meansÊàë‰ª¨ÁöÑ‰∏ã‰∏Ä‰∏™‰ªªÂä°ÊòØÂ∞ÜK-meansÂ∫îÁî®‰∫éÂõæÂÉèÂéãÁº©„ÄÇ ‰ªé‰∏ãÈù¢ÁöÑÊºîÁ§∫ÂèØ‰ª•ÁúãÂà∞ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®ËÅöÁ±ªÊù•ÊâæÂà∞ÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑÂ∞ëÊï∞È¢úËâ≤ÔºåÂπ∂‰ΩøÁî®ËÅöÁ±ªÂàÜÈÖçÂ∞ÜÂéüÂßãÁöÑ24‰ΩçÈ¢úËâ≤Êò†Â∞ÑÂà∞ËæÉ‰ΩéÁª¥ÁöÑÈ¢úËâ≤Á©∫Èó¥„ÄÇ ‰∏ãÈù¢ÊòØÊàë‰ª¨Ë¶ÅÂéãÁº©ÁöÑÂõæÂÉè„ÄÇ 1234567891011121314151617181920212223242526272829image_data = loadmat('data/bird_small.mat')print(image_data)A = image_data['A']print(A.shape)# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ# normalize value rangesA = A / 255# reshape the arrayprint((A.shape[0] * A.shape[1], A.shape[2]))X = np.reshape(A, (128*128, 3))print(X.shape)# randomly initalize the centroidsinitial_centroids = init_centroids(X, 16)# run the algorithmidx, centroids = run_k_means(X, initial_centroids, 10)# gor the closet centroids one last timeidx = find_closest_centroids(X, centroids)# map each poxel to the centroid valueX_recovered = centroids[idx.astype(int), :]print(X_recovered.shape)# reshape to the original dimensionsX_recovered = np.reshape(X_recovered, (A.shape[0], A.shape[1], A.shape[2])) Áî®scikit-learnÊù•ÂÆûÁé∞K-means1234567891011121314151617from sklearn.cluster import KMeans # ÂØºÂÖ•kmeansÂ∫ìmodel = KMeans(n_clusters=16, n_init=100, n_jobs=1)model.fit(X)centroids = model.cluster_centers_print(centroids.shape)C = model.predict(X)print(C.shape)print(centroids[C].shape)compressed_pic = centroids[C].reshape((128, 128, 3))fig, ax = plt.subplots(1, 3)ax[0].imshow(A)ax[1].imshow(X_recovered)ax[2].imshow(compressed_pic)plt.show() ÈÄöËøáK-meansÁÆóÊ≥ïÔºåÊàë‰ª¨ËÆ©ÂõæÂÉè‰ª•Êõ¥Â∞ëÁöÑËâ≤ÂΩ©Êù•ÊòæÁ§∫ÂÆûÁé∞ÂéãÁº©Ôºå‰ΩÜÊòØÂõæÂÉèÁöÑ‰∏ªË¶ÅÁâπÂæÅ‰ªçÁÑ∂Â≠òÂú®„ÄÇ Principal component analysisÔºà‰∏ªÊàêÂàÜÂàÜÊûêÔºâPCAÊòØÂú®Êï∞ÊçÆÈõÜ‰∏≠ÊâæÂà∞‚Äú‰∏ªÊàêÂàÜ‚ÄùÊàñÊúÄÂ§ßÊñπÂ∑ÆÊñπÂêëÁöÑÁ∫øÊÄßÂèòÊç¢„ÄÇ ÂÆÉÂèØ‰ª•Áî®‰∫éÈôçÁª¥„ÄÇ Âú®Êú¨ÁªÉ‰π†‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàË¥üË¥£ÂÆûÁé∞PCAÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫é‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰∫åÁª¥Êï∞ÊçÆÈõÜÔºå‰ª•‰∫ÜËß£ÂÆÉÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑ„ÄÇ Êàë‰ª¨‰ªéÂä†ËΩΩÂíåÂèØËßÜÂåñÊï∞ÊçÆÈõÜÂºÄÂßã„ÄÇ 1234567891011121314151617181920212223242526272829303132333435363738394041data = loadmat('data/ex7data1.mat')X = data['X']def pca(X): # normalize the feature X = (X - X.mean()) / X.std() # compute the covariance matrix X = np.matrix(X) cov = (X.T * X) / X.shape[0] # perform SVD U, S, V = np.linalg.svd(cov) return U, S, VU, S, V = pca(X)print(U, S, V)def project_data(X, U, k): U_reduced = U[:, :k] return np.dot(X, U_reduced)Z = project_data(X, U, 1)def recover_data(Z, U, k): U_reduced = U[:, :k] return np.dot(Z, U_reduced.T)X_recovered = recover_data(Z, U, 1)fig, ax = plt.subplots(1, 2)ax[0].scatter(X[:, 0], X[:, 1])ax[1].scatter(list(X_recovered[:, 0]), list(X_recovered[:, 1]))plt.show() ËØ∑Ê≥®ÊÑèÔºåÁ¨¨‰∏Ä‰∏ªÊàêÂàÜÁöÑÊäïÂΩ±ËΩ¥Âü∫Êú¨‰∏äÊòØÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÂØπËßíÁ∫ø„ÄÇ ÂΩìÊàë‰ª¨Â∞ÜÊï∞ÊçÆÂáèÂ∞ëÂà∞‰∏Ä‰∏™Áª¥Â∫¶Êó∂ÔºåÊàë‰ª¨Â§±Âéª‰∫ÜËØ•ÂØπËßíÁ∫øÂë®Âõ¥ÁöÑÂèòÂåñÔºåÊâÄ‰ª•Âú®Êàë‰ª¨ÁöÑÂÜçÁé∞‰∏≠Ôºå‰∏ÄÂàáÈÉΩÊ≤øÁùÄËØ•ÂØπËßíÁ∫ø„ÄÇ Êàë‰ª¨Âú®Ê≠§ÁªÉ‰π†‰∏≠ÁöÑÊúÄÂêé‰∏Ä‰∏™‰ªªÂä°ÊòØÂ∞ÜPCAÂ∫îÁî®‰∫éËÑ∏ÈÉ®ÂõæÂÉè„ÄÇ ÈÄöËøá‰ΩøÁî®Áõ∏ÂêåÁöÑÈôçÁª¥ÊäÄÊúØÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®ÊØîÂéüÂßãÂõæÂÉèÂ∞ëÂæóÂ§öÁöÑÊï∞ÊçÆÊù•ÊçïËé∑ÂõæÂÉèÁöÑ‚ÄúÊú¨Ë¥®‚Äù 1234567891011121314151617181920212223242526272829303132333435def plot_n_image(X, n): """ plot first n images n has to be a square number """ pic_size = int(np.sqrt(X.shape[1])) grid_size = int(np.sqrt(n)) first_n_images = X[:n, :] fig, ax_array = plt.subplots(nrows=grid_size, ncols=grid_size, sharey=True, sharex=True, figsize=(8, 8)) for r in range(grid_size): for c in range(grid_size): ax_array[r, c].imshow(first_n_images[grid_size * r + c].reshape((pic_size, pic_size)).T, cmap=plt.cm.gray) plt.xticks(np.array([])) plt.yticks(np.array([]))faces = loadmat('data/ex7faces.mat')X = faces['X']print(X.shape)plot_n_image(X, 100)face1 = np.reshape(X[1,:], (32, 32)).TU, S, V = pca(X)Z = project_data(X, U, 100)print(Z.shape)X_recovered = recover_data(Z, U, 100)face2 = np.reshape(X_recovered[1,:], (32, 32)).Tfig, ax = plt.subplots(1, 2)ax[0].imshow(face1, cmap=plt.cm.gray)ax[1].imshow(face2, cmap=plt.cm.gray)plt.show()# ËÆ°ÁÆóÂπ≥ÂùáÂùáÊñπÂ∑ÆËØØÂ∑Æ‰∏éËÆ≠ÁªÉÈõÜÊñπÂ∑ÆÁöÑÊØî‰æãprint(np.sum(S[:100]) / np.sum(S)) # 0.9434273519364477 Êàë‰ª¨Êää1024‰∏™ÁâπÂæÅÁº©ÂáèÂà∞100‰∏™Êó∂Ëøò‰øùÁïô‰∫Ü94%ÁöÑÂ∑ÆÂºÇÂÄº„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex6-SVM]]></title>
    <url>%2F2018%2F11%2F01%2Fex6-SVM%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex6-SVM ÁªÉ‰π†Áî®Êï∞ÊçÆ Á∫øÊÄßSVM1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/usr/bin/python# coding=utf-8import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sbfrom scipy.io import loadmatfrom sklearn import svm# Âú®‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰∫å‰ΩçÊï∞ÊçÆÈõÜ‰∏≠ SVM‰∏≠‰∏çÂêåÁöÑCÂ§ÑÁêÜÁªìÊûúraw_data = loadmat('data/ex6data1.mat')print(raw_data)data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])data['y'] = raw_data['y']positive = data[data['y'].isin([1])]negative = data[data['y'].isin([0])]fig, ax = plt.subplots(figsize=(12,8))ax.scatter(positive['X1'], positive['X2'], s=50, marker='x', label='Positive')ax.scatter(negative['X1'], negative['X2'], s=50, marker='o', label='Negative')ax.legend()plt.show()svc = svm.LinearSVC(C=1, loss='hinge', max_iter=1000)print(svc)# È¶ñÂÖàÁúã‰∏ãC=1ÁöÑÁªìÊûúsvc.fit(data[['X1', 'X2']], data['y'])score = svc.score(data[['X1', 'X2']], data['y'])print(score) # 0.9803921568627451# ÂΩìC=100ÁöÑÊó∂ÂÄôsvc2 = svm.LinearSVC(C=100, loss='hinge', max_iter=1000)svc2.fit(data[['X1', 'X2']], data['y'])score2 = svc2.score(data[['X1', 'X2']], data['y'])print(score2) # 0.9411764705882353 ÊØèÊ¨°ÊâßË°åÁöÑÁªìÊûúÂèØËÉΩ‰∏çÂêå data['SVM 1 Confidence'] = svc.decision_function(data[['X1', 'X2']])fig, ax = plt.subplots(figsize=(12, 8))ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM 1 Confidence'], cmap='seismic')ax.set_title('SVM (C=1) Decision Confidence')plt.show()data['SVM 2 Confidence'] = svc2.decision_function(data[['X1', 'X2']])fig, ax = plt.subplots(figsize=(12,8))ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM 2 Confidence'], cmap='seismic')ax.set_title('SVM (C=100) Decision Confidence')plt.show() È´òÊñØÊ†∏ÂáΩÊï∞123456789101112# Ê†∏ÂáΩÊï∞def gaussian_kernel(x1, x2, sigma): return np.exp(-(np.sum((x1 - x2) ** 2) / (2 * (sigma ** 2))))x1 = np.array([1.0, 2.0, 1.0])x2 = np.array([0.0, 4.0, -1.0])sigma = 2gaussian_kernel(x1, x2, sigma)# 0.32465246735834974 ÈùûÁ∫øÊÄßÂÜ≥Á≠ñËæπÁïå123456789101112raw_data = loadmat('data/ex6data2.mat')data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])data['y'] = raw_data['y']positive = data[data['y'].isin([1])]negative = data[data['y'].isin([0])]fig, ax = plt.subplots(figsize=(12, 8))ax.scatter(positive['X1'], positive['X2'], s=30, marker='x', label='Positive')ax.scatter(negative['X1'], negative['X2'], s=30, marker='o', label='Negative')ax.legend()plt.show() ÂØπ‰∫éËØ•Êï∞ÊçÆÈõÜÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®ÂÜÖÁΩÆÁöÑRBFÂÜÖÊ†∏ÊûÑÂª∫ÊîØÊåÅÂêëÈáèÊú∫ÂàÜÁ±ªÂô®ÔºåÂπ∂Ê£ÄÊü•ÂÖ∂ÂØπËÆ≠ÁªÉÊï∞ÊçÆÁöÑÂáÜÁ°ÆÊÄß„ÄÇ ‰∏∫‰∫ÜÂèØËßÜÂåñÂÜ≥Á≠ñËæπÁïåÔºåËøô‰∏ÄÊ¨°Êàë‰ª¨Â∞ÜÊ†πÊçÆÂÆû‰æãÂÖ∑ÊúâË¥üÁ±ªÊ†áÁ≠æÁöÑÈ¢ÑÊµãÊ¶ÇÁéáÊù•ÂØπÁÇπÂÅöÈò¥ÂΩ±„ÄÇ ‰ªéÁªìÊûúÂèØ‰ª•ÁúãÂá∫ÔºåÂÆÉ‰ª¨Â§ßÈÉ®ÂàÜÊòØÊ≠£Á°ÆÁöÑ„ÄÇ 123456789svc = svm.SVC(C=100, gamma=10, probability=True)print(svc)svc.fit(data[['X1', 'X2']], data['y'])svc.score(data[['X1', 'X2']], data['y'])data['Probability'] = svc.predict_proba(data[['X1', 'X2']])[:,0]fig, ax = plt.subplots(figsize=(12,8))ax.scatter(data['X1'], data['X2'], s=30, c=data['Probability'], cmap='Reds')plt.show() ÊêúÁ¥¢ÊúÄ‰Ω≥ÂèÇÊï∞12345678910111213141516171819202122232425# ÊêúÁ¥¢ÊúÄ‰Ω≥ÂèÇÊï∞raw_data = loadmat('data/ex6data3.mat')X = raw_data['X']Xval = raw_data['Xval']y = raw_data['y'].ravel()yval = raw_data['yval']. ravel()C_values = [0.001, 0.003, 0.1, 0.3, 1, 3, 10, 30, 100]gamma_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]best_score = 0best_params = &#123;'C': None, 'gamma':None&#125;for C in C_values: for gamma in gamma_values: svc = svm.SVC(C=C, gamma=gamma) svc.fit(X, y) score = svc.score(Xval, yval) if score &gt; best_score: best_score = score best_params['C'] = C best_params['gamma'] = gammaprint(best_params, best_score) {‚ÄòC‚Äô: 0.3, ‚Äògamma‚Äô: 100} 0.965 ÂûÉÂúæÈÇÆ‰ª∂ËøáÊª§Áé∞Âú®ÔºåÊàë‰ª¨Â∞ÜËøõË°åÁ¨¨‰∫åÈÉ®ÂàÜÁöÑÁªÉ‰π†„ÄÇ Âú®Ëøô‰∏ÄÈÉ®ÂàÜ‰∏≠ÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÊòØ‰ΩøÁî®SVMÊù•ÊûÑÂª∫ÂûÉÂúæÈÇÆ‰ª∂ËøáÊª§Âô®„ÄÇ Âú®ÁªÉ‰π†ÊñáÊú¨‰∏≠ÔºåÊúâ‰∏Ä‰∏™‰ªªÂä°Ê∂âÂèä‰∏Ä‰∫õÊñáÊú¨È¢ÑÂ§ÑÁêÜÔºå‰ª•Ëé∑ÂæóÈÄÇÂêàSVMÂ§ÑÁêÜÁöÑÊ†ºÂºèÁöÑÊï∞ÊçÆ„ÄÇ ÁÑ∂ËÄåÔºåËøô‰∏™‰ªªÂä°ÂæàÁÆÄÂçïÔºàÂ∞ÜÂ≠óËØçÊò†Â∞ÑÂà∞‰∏∫ÁªÉ‰π†Êèê‰æõÁöÑÂ≠óÂÖ∏‰∏≠ÁöÑIDÔºâÔºåËÄåÂÖ∂‰ΩôÁöÑÈ¢ÑÂ§ÑÁêÜÊ≠•È™§ÔºàÂ¶ÇHTMLÂà†Èô§ÔºåËØçÂπ≤ÔºåÊ†áÂáÜÂåñÁ≠âÔºâÂ∑≤ÁªèÂÆåÊàê„ÄÇ ÊàëÂ∞ÜË∑≥ËøáÊú∫Âô®Â≠¶‰π†‰ªªÂä°ÔºåËÄå‰∏çÊòØÈáçÁé∞Ëøô‰∫õÈ¢ÑÂ§ÑÁêÜÊ≠•È™§ÔºåÂÖ∂‰∏≠ÂåÖÊã¨‰ªéÈ¢ÑÂ§ÑÁêÜËøáÁöÑËÆ≠ÁªÉÈõÜÊûÑÂª∫ÂàÜÁ±ªÂô®Ôºå‰ª•ÂèäÂ∞ÜÂûÉÂúæÈÇÆ‰ª∂ÂíåÈùûÂûÉÂúæÈÇÆ‰ª∂ËΩ¨Êç¢‰∏∫ÂçïËØçÂá∫Áé∞Ê¨°Êï∞ÁöÑÂêëÈáèÁöÑÊµãËØïÊï∞ÊçÆÈõÜ„ÄÇ12345678910111213# ÂûÉÂúæÈÇÆ‰ª∂ËøáÊª§mat_tr = loadmat('data/spamTrain.mat')X, y = mat_tr.get('X'), mat_tr.get('y').ravel()print(X.shape, y.shape) # ((4000, 1899), (4000,))mat_test = loadmat('data/spamTest.mat')test_X, test_y = mat_test.get('Xtest'), mat_test.get('ytest').ravel()print(test_X.shape, test_y.shape) # ((1000, 1899), (1000,))svc = svm.SVC()svc.fit(X, y)pred = svc.predict(test_X)print(metrics.classification_report(test_y, pred)) 123456 precision recall f1-score support 0 0.94 0.99 0.97 692 1 0.98 0.87 0.92 308avg / total 0.95 0.95 0.95 1000 Ëøô‰∏™ÁªìÊûúÊòØ‰ΩøÁî®‰ΩøÁî®ÈªòËÆ§ÂèÇÊï∞ÁöÑ„ÄÇ „ÄÇ ÁÑ∂ÂêéÁî®ÈÄªËæëÂõûÂΩíÊù•ËÆ°ÁÆóÂêéÁ≤æÁ°ÆÁöÑËææÂà∞‰∫Ü99%12345# Â¶ÇÊûúÊòØÈÄªËæëÂõûÂΩíÂë¢Ôºülogit = LogisticRegression()logit.fit(X, y)pred = logit.predict(test_X)print(metrics.classification_report(test_y, pred)) 123456 precision recall f1-score support 0 1.00 0.99 0.99 692 1 0.97 0.99 0.98 308avg / total 0.99 0.99 0.99 1000 Ë∞ÉÊï¥ÂèÇÊï∞Âêé‰πüÂèØ‰ª•ËææÂà∞ÂíåÈÄªËæëÂõûÂΩí‰∏ÄÊ†∑ÁöÑÁ≤æÁ°ÆÂ∫¶1234svc = svm.SVC(C=100)svc.fit(X, y)pred = svc.predict(test_X)print(metrics.classification_report(test_y, pred)) 123456 precision recall f1-score support 0 1.00 0.99 0.99 692 1 0.97 0.99 0.98 308avg / total 0.99 0.99 0.99 1000]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex2-logistic regression]]></title>
    <url>%2F2018%2F10%2F09%2Fex2-logistic%20regression%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex2-logistic regression ÁªÉ‰π†Áî®Êï∞ÊçÆ ÁªÉ‰π†Êï∞ÊçÆex2data1.txtÂíåex2data2.txtÈÉΩÊòØÁî±‰∏âÂàóÊï∞Â≠óÁªÑÊàêÁöÑÊñáÊú¨Êñá‰ª∂ÔºåÂâç‰∏§ÂàóÊòØÁâπÂæÅÔºåÁ¨¨‰∏âÂàóÊòØÁªìÊûúÔºåÁªìÊûúÂè™Êúâ0Âíå1‰∏§Áßç„ÄÇ ÊµèËßàÊï∞ÊçÆÁîªÂá∫Êï£ÁÇπÂõæÔºåËßÇÂØü‰∏§‰∏™‰∏çÂêåÁªìÊûúÁöÑÂàÜÁ±ªÊÉÖÂÜµÔºåÊúâÊòéÊòæÁöÑÂÜ≥Á≠ñËæπÁïå„ÄÇ12345678910111213141516171819202122232425262728import numpy as npimport pandas as pdimport matplotlib.pyplot as pltpath = './data/ex2data1.txt'names=['exam 1', 'exam 2', 'admitted']data = pd.read_csv(path, header=None, names=names)print(data.head())# ÂèØËßÜÂåñdef data_visual(data, names, theta=None): positive = data[data[names[2]].isin([1])] negative = data[data[names[2]].isin([0])] fig, ax = plt.subplots(figsize=(12, 8)) ax.scatter(positive[names[0]], positive[names[1]], s=50, c='b', marker='o', label='1') ax.scatter(negative[names[0]], negative[names[1]], s=50, c='r', marker='x', label='0') ax.legend() if theta is not None: x1 = np.arange(20, 100, 5) x2 = (- theta[0] - theta[1] * x1) / theta[2] plt.plot(x1, x2, color='black') plt.show()data_visual(data, names) ÊøÄÊ¥ªÂáΩÊï∞ ÈÄªËæëÂõûÂΩíÊ®°ÂûãÁöÑÂÅáËÆæÊòØÔºö$h_\theta \left( x \right)=g\left(\theta^{T}X \right)$ÂÖ∂‰∏≠Ôºö $X$ ‰ª£Ë°®ÁâπÂæÅÂêëÈáè $g$ ‰ª£Ë°®ÈÄªËæëÂáΩÊï∞Ôºàlogistic function)ÊòØ‰∏Ä‰∏™Â∏∏Áî®ÁöÑÈÄªËæëÂáΩÊï∞‰∏∫SÂΩ¢ÂáΩÊï∞ÔºàSigmoid functionÔºâÔºåÂÖ¨Âºè‰∏∫Ôºö $g\left( z \right)=\frac{1}{1+{{e}^{-z}}}$„ÄÇ 12345678910111213# sigmoidÂáΩÊï∞def sigmoid(z): return 1 / (1 + np.exp(-z))# Ê£ÄÊü•ÊøÄÊ¥ªÂáΩÊï∞def sigmoid_visual(): nums = np.arange(-10, 10, step=1) plt.plot(nums, sigmoid(nums)) plt.show()sigmoid_visual() ‰ª£‰ª∑ÂáΩÊï∞‰∏éÈ¢ÑÂ§ÑÁêÜ‰ª£‰ª∑ÂáΩÊï∞Ôºö $J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{{h}_{\theta }}\left( {{x}^{(i)}} \right) \right)]}$ 123456789101112131415161718192021222324252627# ‰ª£‰ª∑ÂáΩÊï∞def cost(theta, X, Y): theta = np.matrix(theta) X = np.matrix(X) Y = np.matrix(Y) first = np.multiply(-Y, np.log(sigmoid(X * theta.T))) second = np.multiply((1 - Y), np.log(1 - sigmoid(X * theta.T))) return np.sum(first - second) / len(X)# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ# add a ones column - this makes the matrix multiplication work out easierdata.insert(0, 'Ones', 1)# set X (training data) and y (target variable)cols = data.shape[1]X = data.iloc[:, 0: cols - 1]Y = data.iloc[:, cols - 1: cols]# convert to numpy arrays and initalize the parameter array thetaX = np.array(X.values)Y = np.array(Y.values)theta = np.zeros(3)# Ê£ÄÊü•Áª¥Â∫¶print(X.shape, theta.shape, Y.shape) # (100, 3) (3,) (100, 1)print(cost(theta, X, Y)) # ÂàùÂßãÂÄºÁöÑ‰ª£‰ª∑ ÂàùÂßãÂåñÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÂÄº‰∏∫Ôºö0.6931471805599453 Ê¢ØÂ∫¶‰∏ãÈôç $\frac{\partial J\left( \theta \right)}{\partial {{\theta }_{j}}}=\frac{1}{m}\sum\limits_{i=1}^{m}{({{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}})x_{_{j}}^{(i)}}$ 1234567891011121314151617# Ê¢ØÂ∫¶‰∏ãÈôçdef gradient(theta, X, Y): theta = np.matrix(theta) X = np.matrix(X) y = np.matrix(Y) parameters = int(theta.ravel().shape[1]) grad = np.zeros(parameters) error = sigmoid(X * theta.T) - Y for i in range(parameters): term = np.multiply(error, X[:, i]) grad[i] = np.sum(term) / len(X) return grad ËÆ≠ÁªÉÊï∞ÊçÆ‰∏éÂÜ≥Á≠ñËæπÁïå123456789101112131415161718192021# Áî®SciPy's truncated newtonÔºàTNCÔºâÂÆûÁé∞ÂØªÊâæÊúÄ‰ºòÂèÇÊï∞result = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, Y))print(result)print(cost(result[0], X, Y))theta = result[0]# ÁîªÂá∫ÂÜ≥Á≠ñËæπÁïådata_visual(data, names, theta)# ËÆ°ÁÆóÈ¢ÑÊµãÊïàÊûúdef predict(theta, X): probability = sigmoid(X * theta.T) return [1 if x &gt;= 0.5 else 0 for x in probability]theta_min = np.matrix(result[0])predictions = predict(theta_min, X)correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, Y)]accuracy = (sum(map(int, correct)) % len(correct))print('accuracy = &#123;&#125;%'.format(accuracy)) accuracy = 89% ÈÄªËæëÂõûÂΩíÊ≠£ÂàôÂåñ123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778path2 = './data/ex2data2.txt'names = ['test1', 'test2', 'accepted']data2 = pd.read_csv(path2, header=None, names=names)print(data2.head())#data_visual(data2, names)degree = 5x1 = data2['test1']x2 = data2['test2']data2.insert(3, 'Ones', 1)for i in range(1, degree): for j in range(0, i): data2['F' + str(i) + str(j)] = np.power(x1, i-j) * np.power(x2, j)data2.drop('test1', axis=1, inplace=True)data2.drop('test2', axis=1, inplace=True)print(data2.head())# Ê≠£ÂàôÂåñ‰ª£‰ª∑ÂáΩÊï∞ learng_rate = Œª lambdadef cost_reg(theta, X, Y, learng_rate): theta = np.matrix(theta) X = np.matrix(X) Y = np.matrix(Y) first = np.multiply(-Y, np.log(sigmoid(X * theta.T))) second = np.multiply((1 - Y), np.log(1 - sigmoid(X * theta.T))) reg = (learng_rate / (2 * len(X))) * np.sum(np.power(theta[:, 1: theta.shape[1]], 2)) return np.sum(first - second) / len(X) + regdef gradient_reg(theta, X, Y, learng_rate): theta = np.matrix(theta) X = np.matrix(X) Y = np.matrix(Y) parameters = int(theta.ravel().shape[1]) grad = np.zeros(parameters) error = sigmoid(X * theta.T) - Y for i in range(parameters): term = np.multiply(error, X[:, i]) if(i == 0): grad[i] = np.sum(term) / len(X) else: grad[i] = (np.sum(term) / len(X)) + ((learng_rate / len(X)) * theta[:, i]) return grad# set X and y (remember from above that we moved the label to column 0)cols = data2.shape[1]X2 = data2.iloc[:,1:cols]Y2 = data2.iloc[:, :1]# convert to numpy arrays and initalize the parameter array thetaX2 = np.array(X2.values)Y2 = np.array(Y2.values)theta2 = np.zeros(11)learng_rate = 1print(cost_reg(theta2, X2, Y2, learng_rate))print(gradient_reg(theta2, X2, Y2, learng_rate))result2 = opt.fmin_tnc(func=cost_reg, x0=theta2, fprime=gradient_reg, args=(X2, Y2, learng_rate))print(result2)theta_min = np.matrix(result2[0])predictions = predict(theta_min, X2)correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, Y2)]accuracy = (sum(map(int, correct)) % len(correct))print('accuracy = &#123;0&#125;%'.format(accuracy)) accuracy = 78% Ê≠£ÂàôÂåñÁîªÂá∫ÂÜ≥Á≠ñËæπÁïå123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport scipy.optimize as optimport seaborn as snsdef get_y(df): # ËØªÂèñÊ†áÁ≠æ# '''assume the last column is the target''' return np.array(df.iloc[:, -1]) # df.iloc[:, -1]ÊòØÊåádfÁöÑÊúÄÂêé‰∏ÄÂàódef sigmoid(z): return 1 / (1 + np.exp(-z))def gradient(theta, X, y):# '''just 1 batch gradient''' return (1 / len(X)) * X.T @ (sigmoid(X @ theta) - y)def cost(theta, X, y): ''' cost fn is -l(theta) for you to minimize''' return np.mean(-y * np.log(sigmoid(X @ theta)) - (1 - y) * np.log(1 - sigmoid(X @ theta)))df = pd.read_csv('./data/ex2data2.txt', names=['test1', 'test2', 'accepted'])df.head()def feature_mapping(x, y, power, as_ndarray=False):# """return mapped features as ndarray or dataframe""" # data = &#123;&#125; # # inclusive # for i in np.arange(power + 1): # for p in np.arange(i + 1): # data["f&#123;&#125;&#123;&#125;".format(i - p, p)] = np.power(x, i - p) * np.power(y, p) data = &#123;"f&#123;&#125;&#123;&#125;".format(i - p, p): np.power(x, i - p) * np.power(y, p) for i in np.arange(power + 1) for p in np.arange(i + 1) &#125; if as_ndarray: return pd.DataFrame(data).as_matrix() else: return pd.DataFrame(data)x1 = np.array(df.test1)x2 = np.array(df.test2)data = feature_mapping(x1, x2, power=6)print(data.shape)print(data.head())theta = np.zeros(data.shape[1])X = feature_mapping(x1, x2, power=6, as_ndarray=True)print(X.shape)y = get_y(df)print(y.shape)def regularized_cost(theta, X, y, l=1):# '''you don't penalize theta_0''' theta_j1_to_n = theta[1:] regularized_term = (l / (2 * len(X))) * np.power(theta_j1_to_n, 2).sum() return cost(theta, X, y) + regularized_term# Ê≠£ÂàôÂåñ‰ª£‰ª∑ÂáΩÊï∞regularized_cost(theta, X, y, l=1)def regularized_gradient(theta, X, y, l=1):# '''still, leave theta_0 alone''' theta_j1_to_n = theta[1:] regularized_theta = (l / len(X)) * theta_j1_to_n # by doing this, no offset is on theta_0 regularized_term = np.concatenate([np.array([0]), regularized_theta]) return gradient(theta, X, y) + regularized_termprint('init cost = &#123;&#125;'.format(regularized_cost(theta, X, y)))res = opt.minimize(fun=regularized_cost, x0=theta, args=(X, y), method='Newton-CG', jac=regularized_gradient)def draw_boundary(power, l):# """# power: polynomial power for mapped feature# l: lambda constant# """ density = 1000 threshhold = 2 * 10**-3 final_theta = feature_mapped_logistic_regression(power, l) x, y = find_decision_boundary(density, power, final_theta, threshhold) df = pd.read_csv('./data/ex2data2.txt', names=['test1', 'test2', 'accepted']) sns.lmplot('test1', 'test2', hue='accepted', data=df, size=6, fit_reg=False, scatter_kws=&#123;"s": 100&#125;) plt.scatter(x, y, c='R', s=10) plt.title('Decision boundary') plt.show()def feature_mapped_logistic_regression(power, l):# """for drawing purpose only.. not a well generealize logistic regression# power: int# raise x1, x2 to polynomial power# l: int# lambda constant for regularization term# """ df = pd.read_csv('./data/ex2data2.txt', names=['test1', 'test2', 'accepted']) x1 = np.array(df.test1) x2 = np.array(df.test2) y = get_y(df) X = feature_mapping(x1, x2, power, as_ndarray=True) theta = np.zeros(X.shape[1]) res = opt.minimize(fun=regularized_cost, x0=theta, args=(X, y, l), method='TNC', jac=regularized_gradient) final_theta = res.x return final_thetadef find_decision_boundary(density, power, theta, threshhold): t1 = np.linspace(-1, 1.5, density) t2 = np.linspace(-1, 1.5, density) cordinates = [(x, y) for x in t1 for y in t2] x_cord, y_cord = zip(*cordinates) mapped_cord = feature_mapping(x_cord, y_cord, power) # this is a dataframe inner_product = mapped_cord.as_matrix() @ theta decision = mapped_cord[np.abs(inner_product) &lt; threshhold] return decision.f10, decision.f01# ÂØªÊâæÂÜ≥Á≠ñËæπÁïåÂáΩÊï∞draw_boundary(power=6, l=1) # lambda=1draw_boundary(power=6, l=0) # lambda=1 ËøáÊãüÂêàdraw_boundary(power=6, l=100) # lambda=1 Ê¨†ÊãüÂêà]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex1-linear regression]]></title>
    <url>%2F2018%2F10%2F08%2Fex1-linear%20regression%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex1-linear regressionÁªÉ‰π†Áî®Êï∞ÊçÆ ÁªÉ‰π†Êï∞ÊçÆex1data1.txtÂíåex2data2.txtÈÉΩÊòØ‰ª•ÈÄóÂè∑‰∏∫ÂàÜÂâ≤Á¨¶ÁöÑÊñáÊú¨Êñá‰ª∂ÔºåÊâÄ‰ª•Êàë‰ª¨‰πüÂèØ‰ª•ÊääÂÆÉ‰ª¨Áúã‰ΩúcsvÊñá‰ª∂Â§ÑÁêÜ„ÄÇ ex1data1‰∏≠ÁöÑÁ¨¨‰∏ÄÂàóÊòØ‰∏Ä‰∏™ÂüéÂ∏ÇÁöÑ‰∫∫Âè£ÔºåÁ¨¨‰∫åÂàóÊòØËøô‰∏™ÂüéÂ∏Ç‰∏≠Âç°ËΩ¶Âè∏Êú∫ÁöÑÂà©Ê∂¶„ÄÇ ex2data2‰∏âÂàóÂàÜÂà´ÊòØÔºå‰∏Ä‰∏™ÊàøÂ≠êÁöÑÂ§ßÂ∞èÔºåÊàøÈó¥Êï∞ÔºåÂîÆ‰ª∑„ÄÇ ÊµèËßàÊï∞ÊçÆ12345678910111213import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# Âä†ËΩΩÊï∞ÊçÆpath = './data/ex1data1.txt'data = pd.read_csv(path, header=None, names=['Population', 'Profit'])# Áúã‰∏Ä‰∏ãÊï∞ÊçÆÁöÑÂÜÖÂÆπprint(data.head())print(data.describe())# ÁîªÂá∫Êï£ÁÇπÂõædata.plot(kind='scatter', x='Population', y='Profit', figsize=(12, 8))plt.show() - Population Profit 0 6.1101 17.5920 1 5.5277 9.1302 2 8.5186 13.6620 3 7.0032 11.8540 4 5.8598 6.8233 - Population Profit count 97.000000 97.000000 mean 8.159800 5.839135 std 3.869884 5.510262 min 5.026900 -2.680700 25% 5.707700 1.986900 50% 6.589400 4.562300 75% 8.578100 7.046700 max 22.203000 24.147000 ‰ª£‰ª∑ÂáΩÊï∞Êàë‰ª¨Â∞ÜÂàõÂª∫‰∏Ä‰∏™‰ª•ÂèÇÊï∞Œ∏‰∏∫ÁâπÂæÅÂáΩÊï∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{{{\left( {{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}}$ ÂÖ∂‰∏≠Ôºö ${{h}{\theta }}\left( x \right)={{\theta }^{T}}X={{\theta }{0}}{{x}{0}}+{{\theta }{1}}{{x}{1}}+{{\theta }{2}}{{x}{2}}+...+{{\theta }{n}}{{x}_{n}}$ 123def compute_cost(X, y, theta): inner = np.power(((X * theta.T) - y), 2) return np.sum(inner) / (2 * len(X)) È¢ÑÂ§ÑÁêÜ1234567891011121314151617# È¢ÑÂ§ÑÁêÜdata.insert(0, 'Ones', 1) # Ê∑ªÂä†‰∏ÄÂàó1cols = data.shape[1]X = data.iloc[:, :cols - 1] # ÂéªÊéâÊúÄÂêé‰∏ÄÂàóY = data.iloc[:, cols - 1: cols] # ÊúÄÂêé‰∏ÄÂàó# Ê£ÄÊü•XÂíåY ÊòØÂê¶Ê≠£Á°Æprint(X.head())print(Y.head())# ÊääXÂíåYËΩ¨Êç¢‰∏∫numpyÁöÑÁü©ÈòµX = np.matrix(X.values)Y = np.matrix(Y.values)# ÂàùÂßãÂåñthetatheta = np.matrix(np.array([0, 0]))# Ê£ÄÊü•Áª¥Â∫¶print(X.shape, Y.shape, theta.shape) # (97, 2) (97, 1) (1, 2) ÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÊàë‰ª¨Ë¶ÅËøô‰∏™ÂÖ¨ÂºèÊù•Êõ¥Êñ∞Œ∏„ÄÇ ${\theta_{j}}:={\theta_{j}}-\alpha \frac{\partial }{\partial {\theta_{j}}}J\left(\theta \right)$ 12345678910111213141516171819202122232425# Ê¢ØÂ∫¶‰∏ãÈôç# XÁü©ÈòµÔºåYÁü©ÈòµÔºåÂàùÂßãÁöÑŒ∏ÔºåÂ≠¶‰π†ÈÄüÁéáÔºåËø≠‰ª£Ê¨°Êï∞def gradient_descent(X, Y, theta, alpha, iters): temp = np.matrix(np.zeros(theta.shape)) parameters = int(theta.ravel().shape[1]) cost = np.zeros(iters) for i in range(iters): error = (X * theta.T) - Y for j in range(parameters): term = np.multiply(error, X[:, j]) temp[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term)) theta = temp cost[i] = compute_cost(X, Y, theta) return theta, cost# ÂàùÂßãÂåñËø≠‰ª£Ê¨°Êï∞ÂíåÂ≠¶‰π†ÈÄüÁéáalpha = 0.01iters = 1000g, cost = gradient_descent(X, Y, theta, alpha, iters)# Áî®Êàë‰ª¨ÂæóÂà∞ÁöÑÂèÇÊï∞gËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞ÔºåÊü•ÁúãËØØÂ∑Æprint(g, compute_cost(X, Y, theta)) ÂèØËßÜÂåñ1234567891011121314# ÁªòÂà∂Á∫øÊÄßÊ®°Âûã‰ª•ÂèäÊï∞ÊçÆÔºåÊü•ÁúãÊãüÂêàÊïàÊûúdef data_visual(data, g): x = np.linspace(data.Population.min(), data.Population.max(), 100) f = g[0, 0] + (g[0, 1] * x) fig, ax = plt.subplots(figsize=(12, 8)) ax.plot(x, f, 'g', label='Prediction') ax.scatter(data.Population, data.Profit, label='Traning Data') ax.legend(loc=2) ax.set_xlabel('Population') ax.set_ylabel('Profit') plt.show()data_visual(data, g) 123456789# ÁªòÂà∂‰ª£‰ª∑ÂêëÈáèdef cost_visual(cost): fig, ax = plt.subplots(figsize=(12, 8)) ax.plot(np.arange(iters), cost, 'r') ax.set_xlabel('Iterations') ax.set_ylabel('Cost') plt.show()cost_visual(cost) Â§öÂèòÈáèÁöÑÁ∫øÊÄßÂõûÂΩíÁªÉ‰π†1ËøòÂåÖÊã¨‰∏Ä‰∏™ÊàøÂ±ã‰ª∑Ê†ºÊï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠Êúâ2‰∏™ÂèòÈáèÔºàÊàøÂ≠êÁöÑÂ§ßÂ∞èÔºåÂçßÂÆ§ÁöÑÊï∞ÈáèÔºâÂíåÁõÆÊ†áÔºàÊàøÂ≠êÁöÑ‰ª∑Ê†ºÔºâ„ÄÇ Êàë‰ª¨‰ΩøÁî®Êàë‰ª¨Â∑≤ÁªèÂ∫îÁî®ÁöÑÊäÄÊúØÊù•ÂàÜÊûêÊï∞ÊçÆÈõÜ„ÄÇ 1234567891011121314151617181920212223path = './data/ex1data2.txt'data2 = pd.read_csv(path, header=None, names =['Size', 'Bedrooms', 'Price'])print(data2.head())# ÁâπÂæÅÂΩí‰∏ÄÂåñdata2 = (data2 - data2.mean()) / data2.std()# È¢ÑÂ§ÑÁêÜ# add ones columndata2.insert(0, 'Ones', 1)# set X (training data) and y (target variable)cols = data2.shape[1]X2 = data2.iloc[:, : cols - 1]Y2 = data2.iloc[:, cols - 1: cols]# convert to matrices and initialize thetaX2 = np.matrix(X2.values)Y2 = np.matrix(Y2.values)theta2 = np.matrix(np.array([0, 0, 0]))g2, cost2 = gradient_descent(X2, Y2, theta2, alpha, iters)cost_visual(cost2) - Size Bedrooms Price 0 2104 3 399900 1 1600 3 329900 2 2400 3 369000 3 1416 2 232000 4 3000 4 539900 Ê≠£ËßÑÊñπÁ®ã $\theta ={{\left( {X^T}X \right)}^{-1}}{X^{T}}y$ 1234567# Ê≠£ËßÑÊñπÁ®ãdef normal_func(X ,Y): theta = np.linalg.inv(X.T@X)@X.T@Y return thetag = normal_func(X, Y)data_visual(data, g.T)]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex4-NN back propagation]]></title>
    <url>%2F2018%2F09%2F29%2Fex4-NN%20back%20propagation%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex4-NN back propagation ÁªÉ‰π†Áî®Êï∞ÊçÆ ÈúÄË¶ÅÁöÑÂ§¥Ôºö123456import matplotlib.pyplot as pltimport numpy as npimport scipy.io as sioimport matplotlibimport scipy.optimize as optfrom sklearn.metrics import classification_report # Ëøô‰∏™ÂåÖÊòØËØÑ‰ª∑Êä•Âëä Visualizing the dataËΩΩÂÖ•Êï∞ÊçÆÔºö12345678910111213141516171819202122232425262728def load_data(path, transpose=True): data = sio.loadmat(path) y = data.get('y') y = y.reshape(y.shape[0]) X = data.get('X') if transpose: X = np.array([im.reshape((20, 20)).T for im in X]) X = np.array([im.reshape(400) for im in X]) return X, yX, y = load_data('./data/ex4data1.mat')def plot_100_image(X): size = int(np.sqrt(X.shape[1])) sample_idx = np.random.choice(np.array(X.shape[0]), 100) sample_images = X[sample_idx, :] fig, ax_array = plt.subplots(nrows=10, ncols=10, sharey=True, sharex=True, figsize=(8, 8)) for r in range(10): for c in range(10): ax_array[r, c].matshow(sample_images[10 * r + c].reshape((size, size)), cmap=matplotlib.cm.binary) plt.xticks(np.array([])) plt.yticks(np.array([])) plt.show()plot_100_image(X) ÂáÜÂ§áÊï∞ÊçÆÁâπÂæÅÈõÜÂêàXÊ∑ªÂä†‰∏ÄÂàóÂÖ®‰∏∫1ÁöÑÂÅèÂ∑ÆÂêëÈáèÔºåÊääÁõÆÊ†áÂêëÈáèyËøõË°åOneHotÁºñÁ†Å„ÄÇ12345678X_raw, y_raw = load_data('./data/ex4data1.mat', transpose=False) # ËøôÈáåËΩ¨ÁΩÆX = np.insert(X_raw, 0, np.ones(X_raw.shape[0]), axis=1) # Â¢ûÂä†ÂÖ®‰∏∫1ÁöÑ‰∏ÄÂàóprint(y.shape) # (5000,)y = np.array([y_raw]).Tfrom sklearn.preprocessing import OneHotEncoderencoder = OneHotEncoder(sparse=False)y_onehot = encoder.fit_transform(y)print(y_onehot.shape) # (5000, 10) ËØªÂèñÊùÉÈáçÂÖàËØªÂèñÂá∫ex4weights.mat‰∏≠ÁöÑtheta1Âíåtheta2ÔºåÊääthetaÂ±ïÂºÄÂêéËøõË°åÊâÅÂπ≥ÂåñÂ§ÑÁêÜ„ÄÇ12345678910111213141516171819202122def load_weight(path): data = sio.loadmat(path) return data['Theta1'], data['Theta2']t1, t2 = load_weight('./data/ex4weights.mat')print(t1.shape, t2.shape) # (25, 401) (10, 26)def serialize(a, b): # np.ravel() ÈôçÁª¥ # np.concatenate() ÊãºÊé• return np.concatenate((np.ravel(a), np.ravel(b)))def deserialize(seq): # Ëß£ÂºÄ‰∏∫‰∏§‰∏™theta return seq[:25 * 401].reshape(25, 401), seq[25 * 401:].reshape(10, 26)theta = serialize(t1, t2)print(theta.shape) # (25 * 401) + (10 * 26) = 10285 ÂâçÂêë‰º†Êí≠ feed forwardÔºà400 + 1Ôºâ -&gt; (25 + 1) -&gt; (1)12345678910111213141516171819def sigmoid(z): return 1 / (1 + np.exp(-z)) def feed_forward(theta, X): t1, t2 = deserialize(theta) m = X.shape[0] a1 = X # 5000 * 401 z2 = a1 @ t1.T a2 = np.insert(sigmoid(z2), 0, np.ones(m), axis=1) # 5000*26 Á¨¨‰∏ÄÂàóÂä†‰∏ÄÂàó‰∏Ä z3 = a2 @ t2.T # 5000 * 100 h = sigmoid(z3) # 5000 * 10 ËøôÊòØ h_theta(X) return a1, z2, a2, z3, h # ÊääÊØè‰∏ÄÂ±ÇÁöÑËÆ°ÁÆóÈÉΩËøîÂõû#_, _, _, _, h = feed_forward(theta, X)#print(h.shape) # (5000, 10) ‰ª£‰ª∑ÂáΩÊï∞‰∏éÊ≠£ÂàôÂåñ 123456789101112131415161718192021222324def cost(theta, X, y): m = X.shape[0] _, _, _, _, h = feed_forward(theta, X) pair_computation = -np.multiply(y, np.log(h)) - np.multiply((1 - y), np.log(1 - h)) return pair_computation.sum() / mcost_res = cost(theta, X, y)print("cost:",cost_res)def regularized_cost(theta, X, y, l=1): t1, t2 = deserialize(theta) # t1: (25,401) t2: (10,26) m = X.shape[0] reg_t1 = np.power(t1[:, 1:], 2).sum() reg_t2 = np.power(t2[:, 1:], 2).sum() reg = (1 / (2 * m)) * (reg_t1 + reg_t2) return cost(theta, X, y) + regregularized_cost_res = regularized_cost(theta, X, y)print("reg cost:",regularized_cost_res) ÂèçÂêë‰º†Êí≠12345678910111213141516171819202122232425262728293031323334353637383940def sigmoid_gradient(z): return np.multiply(sigmoid(z), 1 - sigmoid(z))print(sigmoid_gradient(0)) #0.25 def gradient(theta, X, y): t1, t2 = deserialize(theta) m = X.shape[0] deltal = np.zeros(t1.shape) delta2 = np.zeros(t2.shape) a1, z2, a2, z3, h = feed_forward(theta, X) for i in range(m): a1i = a1[i, :] z2i = z2[i, :] a2i = a2[i, :] hi = h[i, :] yi = y[i, :] d3i = hi - yi z2i = np.insert(z2i, 0, np.ones(1)) d2i = np.multiply(t2.T @ d3i, sigmoid_gradient(z2i)) delta2 += np.matrix(d3i).T @ np.matrix(a2i) deltal += np.matrix(d2i[1:]).T @ np.matrix(a1i) delta1 = deltal / m delta2 = delta2 / m return serialize(delta1, delta2)d1, d2 = deserialize(gradient(theta, X, y))print(d1.shape, d2.shape) # (25, 401) (10, 26) Ê¢ØÂ∫¶Ê†°È™å Ê¢ØÂ∫¶Ê≠£ÂàôÂåñÔºö 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def regularized_gradient(theta, X, y, l=1): """don't regularize theta of bias terms""" m = X.shape[0] delta1, delta2 = deserialize(gradient(theta, X, y)) t1, t2 = deserialize(theta) t1[:, 0] = 0 reg_term_d1 = (l / m) * t1 delta1 = delta1 + reg_term_d1 t2[:, 0] = 0 reg_term_d2 = (l / m) * t2 delta2 = delta2 + reg_term_d2 return serialize(delta1, delta2)def expand_array(arr): """replicate array into matrix [1, 2, 3] [[1, 2, 3], [1, 2, 3], [1, 2, 3]] """ # turn matrix back to ndarray return np.array(np.matrix(np.ones(arr.shape[0])).T @ np.matrix(arr))def gradient_checking(theta, X, y, epsilon, regularized=False): def a_numeric_grad(plus, minus, regularized=False): """calculate a partial gradient with respect to 1 theta""" if regularized: return (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (epsilon * 2) else: return (cost(plus, X, y) - cost(minus, X, y)) / (epsilon * 2) theta_matrix = expand_array(theta) # expand to (10285, 10285) epsilon_matrix = np.identity(len(theta)) * epsilon plus_matrix = theta_matrix + epsilon_matrix minus_matrix = theta_matrix - epsilon_matrix # calculate numerical gradient with respect to all theta numeric_grad = np.array([a_numeric_grad(plus_matrix[i], minus_matrix[i], regularized) for i in range(len(theta))]) # analytical grad will depend on if you want it to be regularized or not analytic_grad = regularized_gradient(theta, X, y) if regularized else gradient(theta, X, y) # If you have a correct implementation, and assuming you used EPSILON = 0.0001 # the diff below should be less than 1e-9 # this is how original matlab code do gradient checking diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad) print('If your backpropagation implementation is correct,\nthe relative difference will be smaller than 10e-9 (assume epsilon=0.0001).\nRelative Difference: &#123;&#125;\n'.format(diff))# gradient_checking(theta, X, y, epsilon= 0.0001)#Ëøô‰∏™ËøêË°åÂæàÊÖ¢ÔºåË∞®ÊÖéËøêË°å If your backpropagation implementation is correct,the relative difference will be smaller than 10e-9 (assume epsilon=0.0001).Relative Difference: 2.1466000818218673e-09 ÂáÜÂ§áËÆ≠ÁªÉÊ®°Âûã12345678910111213141516def random_init(size): return np.random.uniform(-0.12, 0.12, size)def nn_training(X, y): init_theta = random_init(10285) # 25 * 401 + 10 * 26 res = opt.minimize(fun=regularized_cost, x0=init_theta, args=(X ,y, 1), method='TNC', jac=regularized_gradient, options=&#123;'maxiter': 400&#125;) return resres = nn_training(X, y) # ÊÖ¢print(res) Out putÔºö12345678910 fun: 0.32211992072588747 jac: array([ 2.15004329e-04, 3.88985627e-08, -3.33174201e-08, ..., 3.15328424e-05, 2.82831419e-05, -1.68082404e-05])message: 'Max. number of function evaluations reached' nfev: 400 nit: 26 status: 3success: False x: array([ 0.00000000e+00, 1.94492814e-04, -1.66587101e-04, ..., -7.15493763e-01, -1.36561388e+00, -2.90127262e+00]) ÊòæÁ§∫ÂáÜÁ°ÆÁéá123456789101112_, y_answer = load_data('./data/ex4data1.mat')final_theta = res.xdef show_accuracy(theta, X, y): _, _, _, _, h = feed_forward(theta, X) y_pred = np.argmax(h, axis=1) + 1 print(classification_report(y, y_pred))show_accuracy(final_theta, X, y_answer) Out Put:1234567891011121314 precision recall f1-score support 1 1.00 0.79 0.88 500 2 0.73 1.00 0.85 500 3 0.82 0.99 0.89 500 4 1.00 0.89 0.94 500 5 1.00 0.86 0.92 500 6 0.94 0.99 0.97 500 7 0.99 0.81 0.89 500 8 0.94 0.95 0.95 500 9 0.96 0.95 0.95 500 10 0.96 0.98 0.97 500avg / total 0.93 0.92 0.92 5000 ÊòæÁ§∫ÈöêËóèÂ±Ç123456789101112131415161718def plot_hidden_layer(theta): """ theta: (10285, ) """ final_theta1, _ = deserialize(theta) hidden_layer = final_theta1[:, 1:] # ger rid of bias term theta fig, ax_array = plt.subplots(nrows=5, ncols=5, sharey=True, sharex=True, figsize=(5, 5)) for r in range(5): for c in range(5): ax_array[r, c].matshow(hidden_layer[5 * r + c].reshape((20, 20)), cmap=matplotlib.cm.binary) plt.xticks(np.array([])) plt.yticks(np.array([]))plot_hidden_layer(final_theta)plt.show()]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex5-bias vs variance]]></title>
    <url>%2F2018%2F09%2F29%2Fex5-bias%20vs%20variance%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex5-bias vs variance ÁªÉ‰π†Áî®Êï∞ÊçÆ ex5data1.matÊñá‰ª∂ÂÇ®Â≠ò‰∫ÜÂ§ßÂùùÂá∫Ê∞¥ÈáèÁöÑÊï∞ÊçÆÔºåÁî±‰∏âÈÉ®ÂàÜÁªÑÊàêÔºö ËÆ≠ÁªÉÈõÜÔºöXÔºåy ‰∫§ÂèâÈ™åËØÅÈõÜÔºöXvalÔºåyval ÊµãËØïÈõÜÔºöXtestÔºåytest ÈúÄË¶ÅÁöÑÂ§¥Ôºö123456import numpy as npimport scipy.io as sioimport scipy.optimize as optimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁîªÂá∫ËÆ≠ÁªÉÈõÜÁöÑÊï£ÁÇπÂõæÔºåÁªôÁâπÂæÅÈõÜÂä†‰∏ÄÂàó1.12345678910111213def load_data(): d = sio.loadmat('./data/ex5data1.mat') return map(np.ravel, [d['X'], d['y'], d['Xval'], d['yval'], d['Xtest'], d['ytest']])X, y, Xval, yval, Xtest, ytest = load_data()df = pd.DataFrame(&#123;'water_level': X, 'flow': y&#125;)print(df.shape)sns.lmplot('water_level', 'flow', data=df, fit_reg=False)plt.show()X, Xval, Xtest = [np.insert(x.reshape(x.shape[0], 1), 0, np.ones(x.shape[0]), axis=1) for x in (X, Xval, Xtest)]# print(X, Xval, Xtest ) Ê≠£ÂàôÂåñ‰ª£‰ª∑ÂáΩÊï∞ÊòØÔºö Ê¢ØÂ∫¶‰∏ãÈôçÔºö ${\theta_{j}}:={\theta_{j}}-\alpha \frac{\partial }{\partial {\theta_{j}}}J\left(\theta \right)$ Ê≠£ÂàôÂåñÁ∫øÊÄßÂõûÂΩíÁöÑ‰ª£‰ª∑ÂáΩÊï∞‰∏∫Ôºö $J\left( \theta \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[({{({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})}^{2}}+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2}})]}$ Â¶ÇÊûúÊàë‰ª¨Ë¶Å‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï‰ª§Ëøô‰∏™‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÂåñÔºåÂõ†‰∏∫Êàë‰ª¨Êú™ÂØπ$\theta_0$ËøõË°åÊ≠£ÂàôÂåñÔºåÊâÄ‰ª•Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÂ∞ÜÂàÜ‰∏§ÁßçÊÉÖÂΩ¢Ôºö $Repeat$ $until$ $convergence${ ${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{0}^{(i)}})$ ${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{j}^{\left( i \right)}}+\frac{\lambda }{m}{\theta_j}]$ $for$ $j=1,2,...n$ } 12345678910111213141516171819202122232425262728293031323334353637# ‰ª£‰ª∑ÂáΩÊï∞def cost(theta, X, y): m = X.shape[0] inner = X @ theta - y # R(m+1) # 1*m @ m*1 = 1*1 Áü©Èòµ‰πòÊ≥ï # ‰∏ÄÁª¥Áü©ÈòµÁöÑËΩ¨ÁΩÆ‰πò‰ª•ÂÆÉËá™Â∑±Á≠â‰∫éÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂπ≥ÊñπÂíå return inner.T @ inner / (2 * m)print(cost(theta, X, y,))# 303.9515255535976# Ê¢ØÂ∫¶def gradient(theta, X, y): m = X.shape[0] return X.T @ (X @ theta - y) / m # (m, n).T @ (m, 1) -&gt; (n, 1)print(gradient(theta, X, y,))# [-15.30301567 598.16741084]# Ê≠£ÂàôÂåñdef regularized_cost(theta, X, y, l=1): return cost(theta, X, y) + (l / (2 * X.shape[0])) * np.power(theta[1:], 2).sum()def regularized_gradient(theta, X, y, l=1): m = X.shape[0] regularized_term = theta.copy() regularized_term[0] = 0 regularized_term = (l / m) * regularized_term return gradient(theta, X, y) + regularized_termprint(regularized_gradient(theta, X, y, l=1))# [-15.30301567 598.25074417] ËÆ≠ÁªÉÊï∞ÊçÆÊ≠£ÂàôÂåñÈ°π $\lambda=0$12345678910111213def linear_regression_np(theta, X, y, l=1): res = opt.fmin_tnc(func=regularized_cost, x0=theta, fprime=regularized_gradient, args=(X, y)) return resfinal_theta = linear_regression_np(theta, X, y)[0]b = final_theta[0]m = final_theta[1]plt.scatter(X[:, 1], y, label="Training data")plt.plot(X[:, 1], X[:, 1]*m + b, label='Prediction')plt.legend(loc=2)plt.show() Â≠¶‰π†Êõ≤Á∫ø12345678910111213141516171819def plot_learning_curve(X, y, Xval, yval, l=0): training_cost, cv_cost = [], [] # ËÆ°ÁÆóËÆ≠ÁªÉÈõÜÁöÑ‰ª£‰ª∑Âíå‰∫§ÂèâÈ™åËØÅÔºàcross validationÔºâÈõÜÁöÑ‰ª£‰ª∑ m = X.shape[0] for i in range(1, m + 1): res = linear_regression_np(theta, X[:i, :], y[:i], l=0) tc = regularized_cost(res[0], X[:i, :], y[:i], l=0) cv = regularized_cost(res[0], Xval, yval, l=0) training_cost.append(tc) cv_cost.append(cv) plt.plot(np.arange(1, m + 1), training_cost, label='training cost') plt.plot(np.arange(1, m + 1), cv_cost, label='cv cost') plt.legend(loc=1)plot_learning_curve(X, y, Xval, yval, l=0)plt.show() ËßÇÂØüÂ≠¶‰π†Êõ≤Á∫øÂèëÁé∞ÊãüÂêàÁöÑ‰∏çÂ§™Â•ΩÔºåÊ¨†ÊãüÂêà„ÄÇÂæàÊòæÁÑ∂Êàë‰ª¨ÁöÑÊ®°Âûã‰∏ç‰ºòÁßÄÔºåÊîπ‰∏∫Â§öÈ°πÂºèÁâπÂæÅÂ∞ùËØï„ÄÇ Â§öÈ°πÂºèÁâπÂæÅÊääÁâπÂæÅÊâ©Â±ïÂà∞8Èò∂ÔºåÁÑ∂ÂêéÂΩí‰∏ÄÂåñÁâπÂæÅÂÄº„ÄÇ12345678910111213141516171819202122232425262728def poly_features(x, power, as_ndarray=False): data = &#123;'f&#123;&#125;'.format(i): np.power(x, i) for i in range(1, power + 1)&#125; df = pd.DataFrame(data) return df.as_matrix() if as_ndarray else df# ÂΩí‰∏ÄÂåñÁâπÂæÅÂÄºÔºåÂáèÂéªÂπ≥ÂùáÊï∞Èô§‰ª•Ê†áÂáÜÂ∑Ædef normalize_feature(df): """Applies function along input axis(default 0) of DataFrame.""" return df.apply(lambda column: (column - column.mean()) / column.std())def prepare_poly_data(*args, power): """ args: keep feeding in X, Xval, or Xtest will return in the same order """ def prepare(x): # expand feature df = poly_features(x, power=power) # normalization ndarr = normalize_feature(df).as_matrix() # add intercept term return np.insert(ndarr, 0, np.ones(ndarr.shape[0]), axis=1) return [prepare(x) for x in args] Â∞ùËØï‰∏çÂêåÁöÑŒªÊù•ËßÇÂØüÂ≠¶‰π†Êõ≤Á∫ø123456789X, y, Xval, yval, Xtest, ytest = load_data()X_poly, Xval_poly, Xtest_poly= prepare_poly_data(X, Xval, Xtest, power=8)plot_learning_curve(X_poly, y, Xval_poly, yval, l=0)plt.show()plot_learning_curve(X_poly, y, Xval_poly, yval, l=1)plt.show()plot_learning_curve(X_poly, y, Xval_poly, yval, l=100)plt.show() ÂΩìŒªÂèñ0Êó∂Ôºå‰πüÂ∞±ÊòØÊ≤°ÊúâÊ≠£ÂàôÈ°πÊó∂ÔºåÂèØ‰ª•ÁúãÂà∞ËÆ≠ÁªÉÁöÑ‰ª£‰ª∑Â§™‰Ωé‰∫ÜÔºå‰∏çÁúüÂÆû. ËøôÊòØ ËøáÊãüÂêà‰∫Ü ÂΩìËÆ≠ÁªÉ‰ª£‰ª∑Â¢ûÂä†‰∫Ü‰∫õÔºå‰∏çÂÜçÊòØ0‰∫Ü„ÄÇ Á®çÂáèËΩª‰∫ÜËøáÊãüÂêà ÂΩìŒªÂèñ100Êó∂ÔºåÊ≠£ÂàôÂåñËøáÂ§öÔºåÂèòÊàê‰∫ÜÊ¨†ÊãüÂêà„ÄÇ ÊúÄ‰ºòŒª12345678910111213141516171819202122232425262728# ÊâæÂà∞ÊúÄ‰Ω≥ÊãüÂêàl_candidate = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]training_cost, cv_cost = [], []for l in l_candidate: theta = np.ones(X_poly.shape[1]) theta = linear_regression_np(theta, X_poly, y, l)[0] tc = cost(theta, X_poly, y) cv = cost(theta, Xval_poly, yval) training_cost.append(tc) cv_cost.append(cv)plt.plot(l_candidate, training_cost, label='training')plt.plot(l_candidate, cv_cost, label='cross validation')plt.legend(loc=2)plt.xlabel('lambda')plt.ylabel('cost')plt.show()# best cv I got from all those candidatesl_candidate[np.argmin(cv_cost)]# use test data to compute the costfor l in l_candidate: theta = np.ones(X_poly.shape[1]) theta = linear_regression_np(theta, X_poly, y, l)[0] print('test cost(l=&#123;&#125;) = &#123;&#125;'.format(l, cost(theta, Xtest_poly, ytest))) 12345678910test cost(l=0) = 9.799399498688892test cost(l=0.001) = 11.054987989655938test cost(l=0.003) = 11.249198861537238test cost(l=0.01) = 10.879605199670008test cost(l=0.03) = 10.022734920552129test cost(l=0.1) = 8.632060998872074test cost(l=0.3) = 7.336602384055533test cost(l=1) = 7.46630349664086test cost(l=3) = 11.643928200535115test cost(l=10) = 27.715080216719304 Ë∞ÉÂèÇÂêéÔºå lambda = 0.3 ÊòØÊúÄ‰ºòÈÄâÊã©ÔºåËøô‰∏™Êó∂ÂÄôÊµãËØï‰ª£‰ª∑ÊúÄÂ∞è]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Áã¨ÁÉ≠ÁºñÁ†ÅOne Hot Encoder]]></title>
    <url>%2F2018%2F09%2F29%2F%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81One%20Hot%20Encoder%2F</url>
    <content type="text"><![CDATA[Âú®Êú∫Âô®Â≠¶‰π†Êó∂Êàë‰ª¨ÈÄöÂ∏∏Ë¶ÅËøõË°åÂΩí‰∏ÄÂåñÊï∞ÊçÆÂêéÂÜçËøõË°åËÆ≠ÁªÉÔºåËøòÊúâ‰∏Ä‰∫õÂÖ∂‰ªñÂ§ÑÁêÜÊñπÊ≥ïÊØîÂ¶Ç‰ΩøÁî®Áã¨ÁÉ≠ÁºñÁ†Å„ÄÇ ‰ªÄ‰πàÊòØÁã¨ÁÉ≠Á†ÅÁã¨ÁÉ≠ÁºñÁ†ÅÂç≥ One-Hot ÁºñÁ†ÅÔºåÂèàÁß∞‰∏Ä‰ΩçÊúâÊïàÁºñÁ†ÅÔºåÂÖ∂ÊñπÊ≥ïÊòØ‰ΩøÁî®N‰ΩçÁä∂ÊÄÅÂØÑÂ≠òÂô®Êù•ÂØπN‰∏™Áä∂ÊÄÅËøõË°åÁºñÁ†ÅÔºåÊØè‰∏™Áä∂ÊÄÅÈÉΩÊúâÂÆÉÁã¨Á´ãÁöÑÂØÑÂ≠òÂô®‰ΩçÔºåÂπ∂‰∏îÂú®‰ªªÊÑèÊó∂ÂÄôÔºåÂÖ∂‰∏≠Âè™Êúâ‰∏Ä‰ΩçÊúâÊïà„ÄÇ ÂèØ‰ª•ËøôÊ†∑ÁêÜËß£ÔºåÂØπ‰∫éÊØè‰∏Ä‰∏™ÁâπÂæÅÔºåÂ¶ÇÊûúÂÆÉÊúâm‰∏™ÂèØËÉΩÂÄºÔºåÈÇ£‰πàÁªèËøáÁã¨ÁÉ≠ÁºñÁ†ÅÂêéÔºåÂ∞±ÂèòÊàê‰∫Üm‰∏™‰∫åÂÖÉÁâπÂæÅ„ÄÇÂπ∂‰∏îÔºåËøô‰∫õÁâπÂæÅ‰∫íÊñ•ÔºåÊØèÊ¨°Âè™Êúâ‰∏Ä‰∏™ÊøÄÊ¥ª„ÄÇÂõ†Ê≠§ÔºåÊï∞ÊçÆ‰ºöÂèòÊàêÁ®ÄÁñèÁöÑ„ÄÇ ‰æãÂ¶ÇÂØπÂÖ≠‰∏™Áä∂ÊÄÅËøõË°åÁºñÁ†ÅÔºö Ëá™ÁÑ∂È°∫Â∫èÁ†Å‰∏∫ 000,001,010,011,100,101 Áã¨ÁÉ≠ÁºñÁ†ÅÂàôÊòØ 000001,000010,000100,001000,010000,100000 Áã¨ÁÉ≠Á†ÅÁöÑ‰ºòÁÇπÊúâ‰∏Ä‰∫õÁâπÂæÅÊó†Ê≥ïÁõ¥Êé•Â∫îÁî®Âú®ÈúÄË¶ÅÊï∞ÂÄºËÆ°ÁÆóÁöÑÁÆóÊ≥ï‰∏≠Ôºå‰æãÂ¶ÇÔºåÁî®Êà∑ÁöÑÊÄßÂà´ÔºåÁà±Â•ΩÔºå‰ΩèÂùÄÁ≠âÔºå‰∏ÄËà¨ÁÆÄÂçïÁ≤óÊö¥ÁöÑÂ§ÑÁêÜÊñπÂºèÊó∂Áõ¥Êé•Â∞Ü‰∏çÂêåÁöÑÁ±ªÂà´Êò†Â∞Ñ‰∏∫‰∏Ä‰∏™Êï¥Êï∞ÔºåÊØîÂ¶ÇÁî∑ÊÄß‰∏∫0ÔºåÂ•≥ÊÄß‰∏∫1ÔºåÂÖ∂‰ªñ‰∏∫2ÔºåËøôÁßçÁÆÄÂçïÁöÑÂÆûÁé∞ÊúÄÂ§ßÁöÑÈóÆÈ¢òÂ∞±Âú®‰∫éÂêÑÁßçÁ±ªÂà´ÁöÑÁâπÂæÅÈÉΩË¢´ÁúãÊàêÊòØÊúâÂ∫èÁöÑÔºåËøôÊòæÁÑ∂‰∏çÁ¨¶ÂêàÂÆûÈôÖÂú∫ÊôØ„ÄÇ ‰ΩøÁî®Áã¨ÁÉ≠Á†ÅÂèØ‰ª•Â§ÑÁêÜÈùûËøûÁª≠ÂûãÊï∞ÂÄºÁâπÂæÅÔºåÂπ∂‰∏îÂú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÊâ©ÂÖÖ‰∫ÜÁâπÂæÅ„ÄÇ 1.‰ΩøÁî®one-hotÁºñÁ†ÅÔºåÂ∞ÜÁ¶ªÊï£ÁâπÂæÅÁöÑÂèñÂÄºÊâ©Â±ïÂà∞‰∫ÜÊ¨ßÂºèÁ©∫Èó¥ÔºåÁ¶ªÊï£ÁâπÂæÅÁöÑÊüê‰∏™ÂèñÂÄºÂ∞±ÂØπÂ∫îÊ¨ßÂºèÁ©∫Èó¥ÁöÑÊüê‰∏™ÁÇπ„ÄÇ 2.Â∞ÜÁ¶ªÊï£ÁâπÂæÅÈÄöËøáone-hotÁºñÁ†ÅÊò†Â∞ÑÂà∞Ê¨ßÂºèÁ©∫Èó¥ÔºåÊòØÂõ†‰∏∫ÔºåÂú®ÂõûÂΩíÔºåÂàÜÁ±ªÔºåËÅöÁ±ªÁ≠âÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ï‰∏≠ÔºåÁâπÂæÅ‰πãÈó¥Ë∑ùÁ¶ªÁöÑËÆ°ÁÆóÊàñÁõ∏‰ººÂ∫¶ÁöÑËÆ°ÁÆóÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑÔºåËÄåÊàë‰ª¨Â∏∏Áî®ÁöÑË∑ùÁ¶ªÊàñÁõ∏‰ººÂ∫¶ÁöÑËÆ°ÁÆóÈÉΩÊòØÂú®Ê¨ßÂºèÁ©∫Èó¥ÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÔºåËÆ°ÁÆó‰ΩôÂº¶Áõ∏‰ººÊÄßÔºåÂü∫‰∫éÁöÑÂ∞±ÊòØÊ¨ßÂºèÁ©∫Èó¥„ÄÇ 3.Â∞ÜÁ¶ªÊï£ÂûãÁâπÂæÅ‰ΩøÁî®one-hotÁºñÁ†ÅÔºåÂèØ‰ª•‰ºöËÆ©ÁâπÂæÅ‰πãÈó¥ÁöÑË∑ùÁ¶ªËÆ°ÁÆóÊõ¥Âä†ÂêàÁêÜ„ÄÇÊØîÂ¶ÇÔºåÊúâ‰∏Ä‰∏™Á¶ªÊï£ÂûãÁâπÂæÅÔºå‰ª£Ë°®Â∑•‰ΩúÁ±ªÂûãÔºåËØ•Á¶ªÊï£ÂûãÁâπÂæÅÔºåÂÖ±Êúâ‰∏â‰∏™ÂèñÂÄºÔºå‰∏ç‰ΩøÁî®one-hotÁºñÁ†ÅÔºåÂÖ∂Ë°®Á§∫ÂàÜÂà´ÊòØx_1 = (1), x_2 = (2), x_3 = (3)„ÄÇ‰∏§‰∏™Â∑•‰Ωú‰πãÈó¥ÁöÑË∑ùÁ¶ªÊòØÔºå(x_1, x_2) = 1, d(x_2, x_3) = 1, d(x_1, x_3) = 2„ÄÇÈÇ£‰πàx_1Âíåx_3Â∑•‰Ωú‰πãÈó¥Â∞±Ë∂ä‰∏çÁõ∏‰ººÂêóÔºüÊòæÁÑ∂ËøôÊ†∑ÁöÑË°®Á§∫ÔºåËÆ°ÁÆóÂá∫Êù•ÁöÑÁâπÂæÅÁöÑË∑ùÁ¶ªÊòØ‰∏çÂêàÁêÜ„ÄÇÈÇ£Â¶ÇÊûú‰ΩøÁî®one-hotÁºñÁ†ÅÔºåÂàôÂæóÂà∞x_1 = (1, 0, 0), x_2 = (0, 1, 0), x_3 = (0, 0, 1)ÔºåÈÇ£‰πà‰∏§‰∏™Â∑•‰Ωú‰πãÈó¥ÁöÑË∑ùÁ¶ªÂ∞±ÈÉΩÊòØsqrt(2).Âç≥ÊØè‰∏§‰∏™Â∑•‰Ωú‰πãÈó¥ÁöÑË∑ùÁ¶ªÊòØ‰∏ÄÊ†∑ÁöÑÔºåÊòæÂæóÊõ¥ÂêàÁêÜ„ÄÇ ÁºñÁ†ÅËøáÁ®ã ÂÅáÂ¶ÇÂè™Êúâ‰∏Ä‰∏™ÁâπÂæÅÊòØÁ¶ªÊï£ÂÄºÔºö {sexÔºö{maleÔºå femaleÔºåother}} ËØ•ÁâπÂæÅÊÄªÂÖ±Êúâ3‰∏™‰∏çÂêåÁöÑÂàÜÁ±ªÂÄºÔºåÊ≠§Êó∂ÈúÄË¶Å3‰∏™bit‰ΩçË°®Á§∫ËØ•ÁâπÂæÅÊòØ‰ªÄ‰πàÂÄºÔºåÂØπÂ∫îbit‰Ωç‰∏∫1ÁöÑ‰ΩçÁΩÆÂØπÂ∫îÂéüÊù•ÁöÑÁâπÂæÅÁöÑÂÄºÔºà‰∏ÄËà¨ÊÉÖÂÜµ‰∏ãÂèØ‰ª•Â∞ÜÂéüÂßãÁöÑÁâπÂæÅÁöÑÂèñÂÄºËøõË°åÊéíÂ∫èÔºå‰ª•‰æø‰∫éÂêéÊúü‰ΩøÁî®ÔºâÔºåÊ≠§Êó∂ÂæóÂà∞Áã¨ÁÉ≠Á†Å‰∏∫{100}Áî∑ÊÄß Ôºå{010}Â•≥ÊÄßÔºå{001}ÂÖ∂‰ªñ ÂÅáÂ¶ÇÂ§ö‰∏™ÁâπÂæÅÈúÄË¶ÅÁã¨ÁÉ≠Á†ÅÁºñÁ†ÅÔºåÈÇ£‰πà‰πÖÊåâÁÖß‰∏äÈù¢ÁöÑÊñπÊ≥ï‰æùÊ¨°Â∞ÜÊØè‰∏™ÁâπÂæÅÁöÑÁã¨ÁÉ≠Á†ÅÊãºÊé•Ëµ∑Êù•Ôºö {sexÔºö{maleÔºå femaleÔºåother}} {gradeÔºö{‰∏ÄÂπ¥Á∫ßÔºå ‰∫åÂπ¥Á∫ßÔºå‰∏âÂπ¥Á∫ßÔºå ÂõõÂπ¥Á∫ß}} Ê≠§Êó∂ÂØπ‰∫éËæìÂÖ•‰∏∫{sexÔºömaleÔºõ gradeÔºö ÂõõÂπ¥Á∫ß}ËøõË°åÁã¨ÁÉ≠ÁºñÁ†ÅÔºåÂèØ‰ª•È¶ñÂÖàÂ∞ÜsexÊåâÁÖß‰∏äÈù¢ÁöÑËøõË°åÁºñÁ†ÅÂæóÂà∞{100}ÔºåÁÑ∂ÂêéÊåâÁÖßgradeËøõË°åÁºñÁ†Å‰∏∫{0001}ÔºåÈÇ£‰πà‰∏§ËÄÖËøûÊé•Ëµ∑Êù•ÂæóÂà∞ÊúÄÂêéÁöÑÁã¨ÁÉ≠Á†Å{1000001}Ôºõ sklearn‰∏≠ÁöÑOne Hot EncoderÂÆòÊñπÊñáÊ°£ 12345from sklearn.preprocessing import OneHotEncodery = np.array([[1, 2, 3]]).Tencoder = OneHotEncoder(sparse=False)y_onehot = encoder.fit_transform(y)print(y_onehot) 123[[1. 0. 0.] [0. 1. 0.] [0. 0. 1.]]]]></content>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>OneHotEncoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ex3-neural network]]></title>
    <url>%2F2018%2F09%2F28%2Fex3-neural%20network%2F</url>
    <content type="text"><![CDATA[AndrewNg Êú∫Âô®Â≠¶‰π†‰π†È¢òex3-neural network ÁªÉ‰π†Áî®Êï∞ÊçÆ ex3data1.matÊòØ‰∏Ä‰∏™matlabÊñá‰ª∂ÔºåÂÇ®Â≠ò‰∫Ü5000‰∏™ÂõæÂÉèÁöÑÊï∞ÊçÆÔºåÊØè‰∏™ÂõæÂÉèÊòØ‰∏Ä‰∏™20ÂÉèÁ¥†√ó20ÂÉèÁ¥†ÁöÑÁÅ∞Â∫¶ÂõæÔºåÂ±ïÂºÄÂêé‰∏∫‰∏Ä‰∏™400Áª¥ÁöÑÂêëÈáèÔºåÊØè‰∏Ä‰∏™ÂêëÈáèÈÉΩÂÇ®Â≠ò‰∏∫Áü©ÈòµXÁöÑË°åÔºåÊâÄ‰ª•XÁöÑÁª¥Â∫¶ÊòØÔºà5000Ôºå400ÔºâyÁöÑÊØè‰∏ÄË°å‰ª£Ë°®XÊâÄÂØπÂ∫îÁöÑÊâãÂÜôÊï∞Â≠óÔºåyÁöÑÁª¥Â∫¶ÊòØÔºà5000Ôºå1Ôºâ ÈúÄË¶ÅÁöÑÂ§¥Ôºö123456import matplotlib.pyplot as pltimport numpy as npimport scipy.io as sioimport matplotlibimport scipy.optimize as optfrom sklearn.metrics import classification_report # Ëøô‰∏™ÂåÖÊòØËØÑ‰ª∑Êä•Âëä Visualizing the dataËΩΩÂÖ•Êï∞ÊçÆÔºö1234567891011def load_data(path, transpose=True): data = sio.loadmat(path) y = data.get('y') y = y.reshape(y.shape[0]) X = data.get('X') if transpose: X = np.array([im.reshape((20, 20)).T for im in X]) X = np.array([im.reshape(400) for im in X]) return X, yX, y = load_data('./data/ex3data1.mat') Áîª‰∏Ä‰∏™Âõæ12345678910def plot_an_image(image): fig, ax = plt.subplots(figsize=(1, 1)) ax.matshow(image.reshape((20, 20)), cmap=matplotlib.cm.binary) plt.xticks(np.array([])) plt.yticks(np.array([])) plt.show()pick_one = np.random.randint(0, 5000)plot_an_image(X[pick_one, :])print('this should be &#123;&#125;'.format(y[pick_one])) Áîª‰∏ÄÁôæ‰∏™Âõæ123456789101112131415def plot_100_image(X): size = int(np.sqrt(X.shape[1])) sample_idx = np.random.choice(np.array(X.shape[0]), 100) sample_images = X[sample_idx, :] fig, ax_array = plt.subplots(nrows=10, ncols=10, sharey=True, sharex=True, figsize=(8, 8)) for r in range(10): for c in range(10): ax_array[r, c].matshow(sample_images[10 * r + c].reshape((size, size)), cmap=matplotlib.cm.binary) plt.xticks(np.array([])) plt.yticks(np.array([])) plt.show() plot_100_image(X) ÂáÜÂ§áÊï∞ÊçÆÂä†ËΩΩÂ•Ωex3data1.matÊñá‰ª∂ÂêéÊàë‰ª¨ÈúÄË¶ÅÂ§ÑÁêÜ‰∏Ä‰∏ãÔºåÈ¶ñÂÖàXÊòØ‰∏Ä‰∏™(5000,400)ÁöÑÁü©ÈòµÔºåÊàë‰ª¨Âú®Á¨¨‰∏ÄÂàóÂä†‰∏ä‰∏ÄÂàóÂÖ®‰∏∫1ÁöÑÁü©Èòµ‰∏∫ÂÅèÂ∑ÆÈáèÔºåyÊòØ‰∏Ä‰∏™(5000,)ÁöÑÁü©ÈòµÔºåÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºå‰∏∫‰∫ÜÂÖºÂÆπOxtaveÂíåmatlabÔºåy‰∏≠0ÁöÑË¢´Ê†áËÆ∞‰∏∫‰∫Ü10„ÄÇÊàë‰ª¨ÊääyÂàÜÊàê10Á±ªÊï¥ÁêÜyÊï∞ÊçÆ‰∏∫(10,5000)ÁöÑ‰∏Ä‰∏™Áü©Èòµ„ÄÇ 123Êâ©Â±ï 5000*1 Âà∞ 5000*10 ÊØîÂ¶Ç y=10 -&gt; [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]: ndarray ÊØîÂ¶Ç y=1 -&gt; [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]: ndarray 1234567raw_X, raw_y = load_data('./data/ex3data1.mat')X = np.insert(raw_X, 0, values=np.ones(raw_X.shape[0]), axis = 1) # ÊèíÂÖ•‰∫ÜÁ¨¨‰∏ÄÂàó ÂÖ®‰∏∫1y_matrix = []for k in range(1, 11): y_matrix.append((raw_y == k).astype(int))y_matrix = [y_matrix[-1]] + y_matrix[:-1]y = np.array(y_matrix) ËÆ≠ÁªÉ‰∏ÄÁª¥Ê®°ÂûãÂ§ÑÁêÜÂ•ΩÊï∞ÊçÆÂêéÊé•ÁùÄÂÜôÔºåÊøÄÊ¥ªÂáΩÊï∞Âíå‰ª£‰ª∑ÂáΩÊï∞Ôºå‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÅèÂØºÊï∞Â∞±ÊòØÊ¢ØÂ∫¶ÂáΩÊï∞ÔºåÊàë‰ª¨ÊúüÊúõËøô‰∏™ÂáΩÊï∞ÊúÄÂ∞è„ÄÇÁªôÊ¢ØÂ∫¶ÂáΩÊï∞Âíå‰ª£‰ª∑ÂáΩÊï∞Âä†ÂÖ•Ê≠£ÂàôÈ°π„ÄÇ 12345678910111213141516171819202122def sigmoid(z): return 1 / (1 + np.exp(-z))def cost(theta, X, y): return np.mean(-y * np.log(sigmoid(X @ theta)) - (1 - y) * np.log(1 - sigmoid(X @ theta)))# Ê¢ØÂ∫¶Â∞±ÊòØjŒ∏ÁöÑÂú®Œ∏ÂÅèÂØºdef gradient(theta, X, y): # @ ÂØπÂ∫îÂÖÉÁ¥†Áõ∏‰πòÊ±ÇÂíå return (1 / len(X)) * X.T @ (sigmoid(X @ theta) - y)def regularized_cost(theta, X, y, l=1): theta_j1_to_n = theta[1:] regularized_term = (1 / (2 * len(X))) * np.power(theta_j1_to_n, 2).sum() return cost(theta, X, y) + regularized_termdef regularized_gradient(theta, X, y, l=1): theta_j1_to_n = theta[1:] regularized_theta = (l / len(X)) * theta_j1_to_n regularized_term = np.concatenate([np.array([0]), regularized_theta]) # Âú®thetaÁü©ÈòµÂâçÊé•‰∏Ä‰∏™[0] return gradient(theta, X, y) + regularized_term ËøêÁî®minimize()ÂáΩÊï∞ÂºÄÂßãËø≠‰ª£ÔºåËÆ°ÁÆóÂá∫thetaÔºåÁÑ∂ÂêéÈ™åËØÅthetaÁöÑÂáÜÁ°ÆÊÄß„ÄÇ 12345678910111213def logistic_regression(X, y, l=1): theta = np.zeros(X.shape[1]) res = opt.minimize(fun=regularized_cost, x0=theta, args=(X, y, l), method='TNC', jac=regularized_gradient, options=&#123;'disp': True&#125;) final_theta = res.x return final_thetadef predict(x, theta): prob = sigmoid(x @ theta) return (prob &gt;= 0.5).astype(int)t0 = logistic_regression(X, y[0])y_pred = predict(X, t0)print('Accuracy=&#123;&#125;'.format(np.mean(y[0] == y_pred))) ÊúÄÁªàÊ±ÇÂæóÁªìÊûú‰∏∫ Accuracy=0.9974 ËÆ≠ÁªÉKÁª¥Ê®°Âûã1234567891011121314k_theta = np.array([logistic_regression(X, y[k]) for k in range(10)])print(k_theta.shape) # (10, 401)prob_matrix = sigmoid(X @ k_theta.T)np.set_printoptions(suppress=True) # ÁßëÂ≠¶ËÆ°Êï∞Ê≥ïË°®Á§∫print(prob_matrix.shape) # (5000, 10)y_pred = np.argmax(prob_matrix, axis=1)print(y_pred.shape) # (5000,)y_answer = raw_y.copy()y_answer[y_answer==10] = 0print(classification_report(y_answer, y_pred)) 1234567891011121314 precision recall f1-score support 0 0.97 0.99 0.98 500 1 0.95 0.99 0.97 500 2 0.95 0.92 0.93 500 3 0.95 0.91 0.93 500 4 0.95 0.95 0.95 500 5 0.92 0.92 0.92 500 6 0.97 0.98 0.97 500 7 0.95 0.95 0.95 500 8 0.93 0.92 0.92 500 9 0.92 0.92 0.92 500avg / total 0.94 0.94 0.94 5000 Â¶Çex3.pdf‰∏≠ÊâÄËØ¥ÔºåÊàë‰ª¨ÊàêÂäüÁöÑÂàÜÁ±ªÂá∫94%ÁöÑ‰æãÂ≠ê„ÄÇ Feedforward Propagation and Prediction Êàë‰ª¨ÁöÑÁ•ûÁªèÁΩëË∑ØÂ¶Ç‰∏äÂõæÊâÄÁ§∫ÔºåÂÆÉÊúâ3Â±ÇÊûÑÊàêÔºà‰∏Ä‰∏™ËæìÂÖ•Â±ÇÔºå‰∏Ä‰∏™ÈöêËóèÂ±ÇaÔºå‰∏Ä‰∏™ËæìÂá∫Â±Ç„ÄÇÔºâÂ∑≤ÁªèÊèê‰æõ‰∫Ü‰∏ÄÁªÑËÆ≠ÁªÉÂèÇÊï∞ÔºàŒò1ÔºåŒò2ÔºâÂÇ®Â≠òÂú®ex3weights.mat‰∏≠ 123456% Load saved matrices from fileload('ex3weights.mat');% The matrices Theta1 and Theta2 will now be in your Octave% environment% Theta1 has size 25 x 401% Theta2 has size 10 x 26 1234567891011121314151617181920212223242526def load_weight(path): data = sio.loadmat(path) return data['Theta1'], data['Theta2']theta1, theta2 = load_weight('./data/ex3weights.mat')X, y = load_data('./data/ex3data1.mat',transpose=False)X = np.insert(X, 0, values=np.ones(X.shape[0]), axis=1) # intercepta1 = Xz2 = a1 @ theta1.T # (5000, 401) @ (25,401).T = (5000, 25)print(z2.shape)z2 = np.insert(z2, 0, values=np.ones(z2.shape[0]), axis=1)a2 = sigmoid(z2)z3 = a2 @ theta2.Ta3 = sigmoid(z3)y_pred = np.argmax(a3, axis=1) + 1 # numpy is 0 base index, +1 for matlab conventionÔºåËøîÂõûÊ≤øËΩ¥axisÊúÄÂ§ßÂÄºÁöÑÁ¥¢ÂºïÔºåaxis=1‰ª£Ë°®Ë°åprint(classification_report(y, y_pred)) 1234567891011121314 precision recall f1-score support 1 0.97 0.98 0.97 500 2 0.98 0.97 0.97 500 3 0.98 0.96 0.97 500 4 0.97 0.97 0.97 500 5 0.98 0.98 0.98 500 6 0.97 0.99 0.98 500 7 0.98 0.97 0.97 500 8 0.98 0.98 0.98 500 9 0.97 0.96 0.96 500 10 0.98 0.99 0.99 500avg / total 0.98 0.98 0.98 5000]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰π†È¢ò</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 28.Implement strStr().]]></title>
    <url>%2F2018%2F09%2F14%2FLeetCode%2028.Implement%20strStr().%2F</url>
    <content type="text"><![CDATA[28.Implement strStr(). Return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. Example 1: Input: haystack = ‚Äúhello‚Äù, needle = ‚Äúll‚Äù Output: 2 Example 2: Input: haystack = ‚Äúaaaaa‚Äù, needle = ‚Äúbba‚Äù Output: -1Clarification: What should we return when needle is an empty string? This is a great question to ask during an interview. For the purpose of this problem, we will return 0 when needle is an empty string. This is consistent to C‚Äôs strstr() and Java‚Äôs indexOf(). ‰∏âÁßçËß£Ê≥ïÔºåÈ¶ñÂÖàÊòØÊö¥ÂäõËß£Ê≥ïÔºåÊú¨Êù•ÊàëÂÖàÂÜô‰∫ÜËøô‰∏™Ëß£Ê≥ïËØïËØïÁúãÔºåÁªìÊûúleetcodeÊ≤°ÈÄöËøáÔºåÂú®ÂÄíÊï∞Á¨¨‰∫å‰∏™caseÊó∂Ë∂ÖÊó∂‰∫ÜÔºåÂú®Â§ÑÁêÜaaaa‚Ä¶ab, aa‚Ä¶ab(ÈùûÂ∏∏Â§ö‰∏™a)ËøôÁßçÊÉÖÂÜµÊó∂ÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶Êó∂n*mÔºåÊòæÁÑ∂‰∏çÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÁÆóÊ≥ïÔºå‰ΩøÁî®KMPÁÆóÊ≥ïÂè™ÊúâO(n+m)„ÄÇ ÊÑüË∞¢UP‰∏ª [KMPÁÆóÊ≥ï]NEXTÊï∞ÂàóÊâãÁÆóÊºîÁ§∫ 12345678910111213141516171819Êö¥ÂäõÁ†¥Ëß£Ê≥ïÔºöint strStr(char* haystack, char* needle) &#123; int i = 0, j = 0, n = 0; if(strlen(haystack) &lt; strlen(needle)) return -1; if(strlen(needle) == 0) return 0; while(i &lt;= strlen(haystack)) &#123; if(haystack[i] == needle[j]) for(j = 0, n = i; j &lt; strlen(needle) &amp;&amp; haystack[n] == needle[j]; j++, n++) ; if(j == strlen(needle)) return i; i++; j = 0; &#125; return -1;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546KMPÁÆóÊ≥ïÔºöint* next_arr(char* ptr)&#123; int ptr_num = strlen(ptr); int* next; int i = 0, j = 1; next = calloc(ptr_num, sizeof(int)); for(i = 1, j = 0; i &lt; ptr_num;) &#123; if(ptr[i] == ptr[j]) next[i++] = ++j; else if(j) j = next[j - 1]; else next[i++] = 0; &#125; return next;&#125;int strStr_kmp(char* haystack, char* needle) &#123; int m = strlen(haystack), n = strlen(needle); int i, j; int* next = next_arr(needle); if (!n) return 0; for (i = 0, j = 0; i &lt; m;) &#123; if (haystack[i] == needle[j]) &#123; i++; j++; &#125; if(j == n) return i - j; if (i &lt; m &amp;&amp; haystack[i] != needle[j]) &#123; if (j) j = next[j - 1]; else i++; &#125; &#125; free(next); return -1; &#125; ‰ΩøÁî®KMPÁÆóÊ≥ïËøêÁÆóÈÄüÁéáÊàêÂäüÁöÑÊâìË¥•‰∫Ü100%ÁöÑ‰∫∫ÔºåÁÑ∂ÂêéÁÇπ‰∫Üsample 0 ms submissionÔºåÁúãÂà∞‰∫ÜÂà´‰∫∫ÁöÑÁÆóÊ≥ï„ÄÇ„ÄÇ„ÄÇ1234567891011121314151617int strStr(char* haystack, char* needle) &#123; int a = strlen(needle); int b = strlen(haystack); if(a==0) return 0; for(int i=0;i&lt;b-a+1;i++)&#123; for(int j = 0; j&lt;b; j++)&#123; if(haystack[i+j] == needle[j])&#123; if(j == a-1) return i; &#125; else break; &#125; &#125; return -1;&#125;]]></content>
      <categories>
        <category>ÁÆóÊ≥ïÁªÉ‰π†</category>
      </categories>
      <tags>
        <tag>ÁÆóÊ≥ï</tag>
        <tag>c</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÊÄªÁªì]]></title>
    <url>%2F2018%2F09%2F14%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Andrew NgÁöÑÊú∫Âô®Â≠¶‰π†ÂÖ•Èó®ËØæÁ®ãÂ∑≤ÁªèÂÖ®ÈÉ®ÁúãÂÆå‰∫ÜÔºåÁ¨îËÆ∞‰πüÂÜô‰∫Ü‰∏Ä‰∫õÔºåËøôÈáåÊÄªÁªìÊâÄÊúâÊâÄÂ≠¶ÁöÑÂÜÖÂÆπÔºåËØ¥ÂÆûËØùÔºåÁé∞Âú®ÂÆåÂÖ®ÂøòËÆ∞‰∫ÜÂºÄÂßãÊâÄÂ≠¶ÁöÑÂÜÖÂÆπ‰∫Ü„ÄÇ ‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π†Arthur Samuel„ÄÇ‰ªñÂÆö‰πâÊú∫Âô®Â≠¶‰π†‰∏∫ÔºåÂú®ËøõË°åÁâπÂÆöÁºñÁ®ãÁöÑÊÉÖÂÜµ‰∏ãÁªô‰∫àËÆ°ÁÆóÂ≠¶‰π†ËÉΩÂäõÁöÑÈ¢ÜÂüü„ÄÇ Tom Mitchell„ÄÇ‰ªñÂÆö‰πâÁöÑÁöÑÊú∫Âô®Â≠¶‰π†ÊòØÔºå‰∏Ä‰∏™Á®ãÂ∫èË¢´ËÆ§‰∏∫ËÉΩ‰ªéÁªèÈ™åE‰∏≠Â≠¶‰π†ÔºåËß£ÂÜ≥‰ªªÂä°TÔºåËææÂà∞ÊÄßËÉΩÂ∫¶ÈáèÂÄºPÔºåÂΩì‰∏î‰ªÖÂΩìÔºåÊúâ‰∫ÜÁªèÈ™åEÂêéÔºåÁªèËøáPËØÑÂà§ÔºåÁ®ãÂ∫èÂÜçÂ§ÑÁêÜTÊó∂ÁöÑÊÄßËÉΩÊúâÊâÄÊèêÂçá„ÄÇ Âë®ÂøóÂçé„ÄÇ‰ªñÂÜçÊú∫Âô®Â≠¶‰π†‰∏Ä‰π¶‰∏≠ÁöÑÊÑèÊÄùÊòØÔºåËÆ©Êú∫Âô®‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†ÔºåËøõËÄåÂæóÂà∞‰∏Ä‰∏™Êõ¥Âä†Á¨¶ÂêàÁé∞ÂÆûËßÑÂæãÁöÑÊ®°ÂûãÔºåÈÄöËøáÂØπÊ®°ÂûãÁöÑ‰ΩøÁî®‰ΩøÂæóÊú∫Âô®ÊØî‰ª•ÂæÄË°®Áé∞ÁöÑÊõ¥Â•ΩÔºåËøôÂ∞±ÊòØÊú∫Âô®Â≠¶‰π†„ÄÇ ÊàëÁöÑÊÑöËßÅ„ÄÇÊú∫Âô®Â≠¶‰π†Â∞±ÊòØÂú®Â∑≤ÊúâÁöÑÊï∞ÊçÆ‰∏≠ÂèëÁé∞ËßÑÂæãÂÜçÂØªÊâæÁ¨¶ÂêàËøô‰∏™ËßÑÂæãÁöÑÊï∞ÊçÆ„ÄÇ ÁõëÁù£Â≠¶‰π†ÂõûÂΩíÔºàÊàø‰ª∑È¢ÑÊµãÔºâÔºåÂàÜÁ±ªÔºàËÇøÁò§È¢ÑÊµãÔºâÔºåÁªôÂá∫ÁâπÂæÅÂÄº‰∏éÂÖ∂ÂØπÂ∫îÁöÑÁªìÊûú„ÄÇ Êó†ÁõëÁù£Â≠¶‰π†ËÅöÁ±ªÔºàÊñ∞Èóª„ÄÅÈÇÆ‰ª∂ÁöÑÂàÜÁ±ªÔºâÔºåÂè™Ê†πÊçÆÁâπÂæÅÂÄºÂØªÊâæÂÖ∂‰∏≠ÁöÑËßÑÂæã„ÄÇ Á∫øÊÄßÂõûÂΩíÊ®°ÂûãË°®Á§∫mÔºöËÆ≠ÁªÉÈõÜ‰∏≠ÂÆû‰æãÁöÑÊï∞Èáè xÔºöÁâπÂæÅÂÄº/ËæìÂÖ•ÂèòÈáè yÔºöÁõÆÊ†áÂÄº/ËæìÂá∫ÂèòÈáè ÔºàxÔºåyÔºâÔºöËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑÂÆû‰æã Á¨¨i‰∏™ÂÆû‰æãÔºö$(x^i, y^i)$ hÔºöÂ≠¶‰π†ÁÆóÊ≥ï‰∏≠ÁöÑËß£ÂÜ≥ÊñπÊ°àÊàñÂáΩÊï∞Ôºå‰πüÁß∞‰∏∫ÂÅáËÆæÔºàhypothesisÔºâ $h_\theta(x)=\theta_0+\theta_1x$ Á∫øÊÄßÂõûÂΩí‰ª£‰ª∑ÂáΩÊï∞È¢ÑÊµãÂáΩÊï∞$h_\theta(x)$ÊòØÂÖ≥‰∫é$x$ÁöÑÂáΩÊï∞,ËÄå‰ª£‰ª∑ÂáΩÊï∞ÊòØ‰∏Ä‰∏™ÂÖ≥‰∫é$(\theta_0,\theta_1)$ÁöÑÂáΩÊï∞ $J(\theta_0,\theta_1) = \frac{1}{2m} \sum^m_{i=1}(h_\theta(x^i)-y^i)^2$ ‰ºòÂåñÁõÆÊ†áÔºö$minimize J(\theta_0,\theta_1)$ Ê¢ØÂ∫¶‰∏ãÈôç Ê¢ØÂ∫¶‰∏ãÈôçÊòØ‰∏Ä‰∏™Áî®Êù•Ê±ÇÂáΩÊï∞ÊúÄÂ∞èÂÄºÁöÑÁÆóÊ≥ïÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊù•Ê±ÇÂá∫‰ª£‰ª∑ÂáΩÊï∞$J(\theta_0,\theta_1)$ÁöÑÊúÄÂ∞èÂÄº„ÄÇ Ê¢ØÂ∫¶‰∏ãÈôçËÉåÂêéÁöÑÊÄùÊÉ≥ÊòØÔºöÂºÄÂßãÊó∂Êàë‰ª¨ÈöèÊú∫ÈÄâÊã©‰∏Ä‰∏™ÂèÇÊï∞ÁªÑÂêà$(\theta_0, \theta_1, ......,\theta_n)$ÔºåËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞ÔºåÁÑ∂ÂêéÊàë‰ª¨ÂØªÊâæ‰∏ã‰∏Ä‰∏™ËÉΩËÆ©‰ª£‰ª∑ÂáΩÊï∞ÂÄº‰∏ãÈôçÊúÄÂ§öÁöÑÂèÇÊï∞ÁªÑÂêà„ÄÇÊàë‰ª¨ÊåÅÁª≠Ëøô‰πàÂÅöÁõ¥Âà∞Âà∞‰∏Ä‰∏™Â±ÄÈÉ®ÊúÄÂ∞èÂÄºÔºåÂõ†‰∏∫Êàë‰ª¨Ê≤°ÊúâÂ∞ùËØïÂÆåÊâÄÊúâÁöÑÂèÇÊï∞ÁªÑÂêàÔºåÊâÄ‰ª•‰∏çËÉΩÁ°ÆÂÆöÊàë‰ª¨ÂæóÂà∞ÁöÑÂ±ÄÈÉ®ÊúÄÂ∞èÂÄºÊòØÂê¶ÊòØÂÖ®Â±ÄÊúÄÂ∞èÂÄºÔºåÈÄâÊã©‰∏çÂêåÁöÑÂàùÂßãÂèÇÊï∞ÁªÑÂêàÔºåÂèØËÉΩÂõûÊâæÂà∞‰∏çÂêåÁöÑÂ±ÄÈÉ®ÊúÄÂ∞èÂÄº„ÄÇ Á∫øÊÄßÂõûÂΩíÈóÆÈ¢òËøêÁî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºåÂÖ≥ÈîÆÂú®‰∫éÊ±ÇÂá∫‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂØºÊï∞ÔºåÂç≥Ôºö $\frac{\partial }{\partial {{\theta }{j}}}J({{\theta }{0}},{{\theta }{1}})=\frac{\partial }{\partial {{\theta }{j}}}\frac{1}{2m}{{\sum\limits_{i=1}^{m}{\left( {{h}_{\theta }}({{x}^{(i)}})-{{y}^{(i)}} \right)}}^{2}}$ $j=0$ Êó∂Ôºö$\frac{\partial }{\partial {{\theta }{0}}}J({{\theta }{0}},{{\theta }{1}})=\frac{1}{m}{{\sum\limits{i=1}^{m}{\left( {{h}_{\theta }}({{x}^{(i)}})-{{y}^{(i)}} \right)}}}$ $j=1$ Êó∂Ôºö$\frac{\partial }{\partial {{\theta }{1}}}J({{\theta }{0}},{{\theta }{1}})=\frac{1}{m}\sum\limits{i=1}^{m}{\left( \left( {{h}_{\theta }}({{x}^{(i)}})-{{y}^{(i)}} \right)\cdot {{x}^{(i)}} \right)}$ ÂàôÁÆóÊ≥ïÂÜôÊàêÔºö Repeat { ‚Äã ${\theta_{0}}:={\theta_{0}}-a\frac{1}{m}\sum\limits_{i=1}^{m}{ \left({{h}_{\theta }}({{x}^{(i)}})-{{y}^{(i)}} \right)}$ ‚Äã ${\theta_{1}}:={\theta_{1}}-a\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left({{h}_{\theta }}({{x}^{(i)}})-{{y}^{(i)}} \right)\cdot {{x}^{(i)}} \right)}$ ‚Äã } ÁâπÂæÅÁº©Êîæ Â∞ùËØïÂ∞ÜÊâÄÊúâÁâπÂæÅÁöÑÂ∞∫Â∫¶ÈÉΩÂ∞ΩÈáèÁº©ÊîæÂà∞-1Âà∞1‰πãÈó¥Ôºå ÊúÄÁÆÄÂçïÁöÑÊñπÊ≥ïÊòØ‰ª§Ôºö${{x}{n}}=\frac{{{x}{n}}-{{\mu}{n}}}{{{s}{n}}}$ÔºåÂÖ∂‰∏≠ ${\mu_{n}}$ÊòØÂπ≥ÂùáÂÄºÔºå${s_{n}}$ÊòØÊ†áÂáÜÂ∑Æ„ÄÇ Â≠¶‰π†ÈÄüÁéáÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÁöÑÊØèÊ¨°Ëø≠‰ª£ÂèóÂà∞Â≠¶‰π†ÁéáÁöÑÂΩ±ÂìçÔºåÂ¶ÇÊûúÂ≠¶‰π†Áéá$a$ËøáÂ∞èÔºåÂàôËææÂà∞Êî∂ÊïõÊâÄÈúÄÁöÑËø≠‰ª£Ê¨°Êï∞‰ºöÈùûÂ∏∏È´òÔºõÂ¶ÇÊûúÂ≠¶‰π†Áéá$a$ËøáÂ§ßÔºåÊØèÊ¨°Ëø≠‰ª£ÂèØËÉΩ‰∏ç‰ºöÂáèÂ∞è‰ª£‰ª∑ÂáΩÊï∞ÔºåÂèØËÉΩ‰ºöË∂äËøáÂ±ÄÈÉ®ÊúÄÂ∞èÂÄºÂØºËá¥Êó†Ê≥ïÊî∂Êïõ„ÄÇ ÈÄöÂ∏∏ÂèØ‰ª•ËÄÉËôëÂ∞ùËØï‰∫õÂ≠¶‰π†ÁéáÔºö $\alpha=0.01Ôºå0.03Ôºå0.1Ôºå0.3Ôºå1Ôºå3Ôºå10$ Ê≠£ËßÑÊñπÁ®ãÊ≠£ËßÑÊñπÁ®ãÊòØÈÄöËøáÊ±ÇËß£‰∏ãÈù¢ÁöÑÊñπÁ®ãÊù•ÊâæÂá∫‰ΩøÂæó‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÁöÑÂèÇÊï∞ÁöÑÔºö$\frac{\partial}{\partial{\theta_{j}}}J\left( {\theta_{j}} \right)=0$ „ÄÇ ÂÅáËÆæÊàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜÁâπÂæÅÁü©Èòµ‰∏∫ $X$ÔºàÂåÖÂê´‰∫Ü ${{x}_{0}}=1$ÔºâÂπ∂‰∏îÊàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜÁªìÊûú‰∏∫ÂêëÈáè $y$ÔºåÂàôÂà©Áî®Ê≠£ËßÑÊñπÁ®ãËß£Âá∫ÂêëÈáè $\theta ={{\left( {X^T}X \right)}^{-1}}{X^{T}}y$ „ÄÇ Ê¢ØÂ∫¶‰∏ãÈôç‰∏éÊ≠£ËßÑÊñπÁ®ãÁöÑÊØîËæÉ Ê¢ØÂ∫¶‰∏ãÈôç Ê≠£ËßÑÊñπÁ®ã ÈúÄË¶ÅÈÄâÊã©Â≠¶‰π†ÈÄüÁéá ‰∏çÈúÄË¶Å ÈúÄË¶ÅÂ§öÊ¨°Ëø≠‰ª£ ÈúÄË¶ÅËÆ°ÁÆó${{\left( {X^T}X \right)}^{-1}}{X^{T}}$Â¶ÇÊûúÁâπÂæÅÊï∞ÈáènËæÉÂ§ßÂàôËøêÁÆó‰ª£‰ª∑Â§ßÔºåÂõ†‰∏∫Áü©ÈòµÈÄÜÁöÑËÆ°ÁÆóÊó∂Èó¥Â§çÊùÇËØª‰∏∫$O(n^3)$ÔºåÈÄöÂ∏∏Êù•ËØ¥nÂ∞è‰∫é‰∏Ä‰∏áÊó∂ËøòÂèØ‰ª•Êé•Âèó ÈÄÇÁî®‰∫éÂêÑÁßçÁ±ªÂûãÁöÑÊ®°Âûã Âè™ÈÄÇÁî®‰∫éÁ∫øÊÄßÊ®°ÂûãÔºå‰∏çÈÄÇÂêàÈÄªËæëÂõûÂΩíÁ≠âÂÖ∂‰ªñÊ®°Âûã ÊÄªÁªì‰∏Ä‰∏ãÔºåÂè™Ë¶ÅÁâπÂæÅÂèòÈáèÁöÑÊï∞ÁõÆÂπ∂‰∏çÂ§ßÔºåÊ†áÂáÜÊñπÁ®ãÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑËÆ°ÁÆóÂèÇÊï∞$\theta $ÁöÑÊõø‰ª£ÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÂú∞ËØ¥ÔºåÂè™Ë¶ÅÁâπÂæÅÂèòÈáèÊï∞ÈáèÂ∞è‰∫é‰∏Ä‰∏áÔºåÈÄöÂ∏∏‰ΩøÁî®Ê†áÂáÜÊñπÁ®ãÊ≥ïÔºåËÄå‰∏ç‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï„ÄÇ ÈÄªËæëÂõûÂΩíÈÄªËæëÂõûÂΩí(Logistic Regression)‰∏ÄËà¨Áî®Âú®ÂàÜÁ±ªÈóÆÈ¢ò‰∏≠„ÄÇ ÂÅáËÆæÂáΩÊï∞ $h_\theta(x) = g(\theta^TX)$ $g\left( z \right)=\frac{1}{1+{{e}^{-z}}}$ X‰ª£Ë°®ÁâπÂæÅÂêëÈáèÔºåg‰ª£Ë°®ÈÄªËæëÂáΩÊï∞(Logistic function)ÔºåÂ∏∏Áî®ÁöÑÈÄªËæëÂáΩÊï∞‰∏∫SÂΩ¢ÂáΩÊï∞(Sigmoid function) Âà§ÂÆöËæπÁïåÂú®ÈÄªËæëÂõûÂΩí‰∏≠ÔºåÊàë‰ª¨È¢ÑÊµãÔºö ÂΩì${h_\theta}\left( x \right)&gt;=0.5$Êó∂ÔºåÈ¢ÑÊµã $y=1$„ÄÇ ÂΩì${h_\theta}\left( x \right)&lt;0.5$Êó∂ÔºåÈ¢ÑÊµã $y=0$„ÄÇ Ê†πÊçÆ S ÂΩ¢ÂáΩÊï∞ÂõæÂÉèÔºåÊàë‰ª¨Áü•ÈÅìÂΩì $z=0$ Êó∂ $g(z)=0.5$ $z&gt;0$ Êó∂ $g(z)&gt;0.5$ $z&lt;0$ Êó∂ $g(z)&lt;0.5$ Âèà $z={\theta^{T}}x$ÔºåÂç≥Ôºö ${\theta^{T}}x&gt;=0$ Êó∂ÔºåÈ¢ÑÊµã $y=1$. ${\theta^{T}}x&lt;0$ Êó∂ÔºåÈ¢ÑÊµã $y=0$ Êé•‰∏ãÊù•Áúã‰ª∑ÂáΩÊï∞ ÈÄªËæëÂõûÂΩí‰ª£‰ª∑ÂáΩÊï∞ÈÄªËæëÂõûÂΩíÁöÑ‰ª£‰ª∑ÂáΩÊï∞‰∏∫Ôºö$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{{Cost}\left( {h_\theta}\left( {x}^{\left( i \right)} \right),{y}^{\left( i \right)} \right)}$. ${h_\theta}\left( x \right)$‰∏é $Cost\left( {h_\theta}\left( x \right),y \right)$‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö.ËøôÊ†∑ÊûÑÂª∫ÁöÑ$Cost\left( {h_\theta}\left( x \right),y \right)$ÂáΩÊï∞ÁöÑÁâπÁÇπÊòØÔºöÂΩìÂÆûÈôÖÁöÑ $y=1$ ‰∏î${h_\theta}\left( x \right)$‰πü‰∏∫ 1 Êó∂ËØØÂ∑Æ‰∏∫ 0ÔºåÂΩì $y=1$ ‰ΩÜ${h_\theta}\left( x \right)$‰∏ç‰∏∫1Êó∂ËØØÂ∑ÆÈöèÁùÄ${h_\theta}\left( x \right)$ÂèòÂ∞èËÄåÂèòÂ§ßÔºõÂΩìÂÆûÈôÖÁöÑ $y=0$ ‰∏î${h_\theta}\left( x \right)$‰πü‰∏∫ 0 Êó∂‰ª£‰ª∑‰∏∫ 0ÔºåÂΩì$y=0$ ‰ΩÜ${h_\theta}\left( x \right)$‰∏ç‰∏∫ 0Êó∂ËØØÂ∑ÆÈöèÁùÄ ${h_\theta}\left( x \right)$ÁöÑÂèòÂ§ßËÄåÂèòÂ§ß„ÄÇ Â∞ÜÊûÑÂª∫ÁöÑ $Cost\left( {h_\theta}\left( x \right),y \right)$ÁÆÄÂåñÂ¶Ç‰∏ãÔºö $Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$ Â∏¶ÂÖ•‰ª£‰ª∑ÂáΩÊï∞ÂæóÂà∞Ôºö$J\left( \theta \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {h_\theta}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{h_\theta}\left( {{x}^{(i)}} \right) \right)]}$.Âç≥Ôºö$J\left( \theta \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{{y}^{(i)}}\log \left( {h_\theta}\left( {{x}^{(i)}} \right) \right)+\left( 1-{{y}^{(i)}} \right)\log \left( 1-{h_\theta}\left( {{x}^{(i)}} \right) \right)]}$.Âú®ÂæóÂà∞ËøôÊ†∑‰∏Ä‰∏™‰ª£‰ª∑ÂáΩÊï∞‰ª•ÂêéÔºåÊàë‰ª¨‰æøÂèØ‰ª•Áî®Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊù•Ê±ÇÂæóËÉΩ‰Ωø‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÁöÑÂèÇÊï∞‰∫Ü„ÄÇÁÆóÊ≥ï‰∏∫ÔºöRepeat { $\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$ (simultaneously update all ) } Ê±ÇÂØºÂêéÂæóÂà∞Ôºö Repeat { $\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{{\left( {h_\theta}\left( \mathop{x}^{\left( i \right)} \right)-\mathop{y}^{\left( i \right)} \right)}}\mathop{x}_{j}^{(i)}$ (simultaneously update all ) } È´òÁ∫ß‰ºòÂåñÂÖ±ËΩ≠Ê¢ØÂ∫¶Ê≥ï BFGS (ÂèòÂ∞∫Â∫¶Ê≥ï) L-BFGS (ÈôêÂà∂ÂèòÂ∞∫Â∫¶Ê≥ï) Á∫øÊÄßÊêúÁ¥¢(line search) Ê≠£ÂàôÂåñÊ≠£ÂàôÂåñÂèØ‰ª•ÊîπÂñÑÊàñËÄÖÂáèÂ∞ëËøáÊãüÂêàÈóÆÈ¢ò„ÄÇ $...+\frac{\lambda}{2m}\sum\limits_{j=1}^{n}\theta_j^2$ Á•ûÁªèÁΩëÁªúÂΩìÁâπÂæÅ‰ªñÂ§öÊó∂ÔºåÈúÄË¶ÅÁ•ûÁªèÁΩëÁªú„ÄÇ Ê†áËÆ∞ÊñπÊ≥ïËÆ≠ÁªÉÊ†∑Êú¨Êï∞Ôºö$m$ ËæìÂÖ•‰ø°Âè∑Ôºö$x$ ËæìÂá∫‰ø°Âè∑Ôºö$y$ Á•ûÁªèÁΩëÁªúÂ±ÇÊï∞Ôºö$L$ ÊØèÂ±ÇÁöÑneuron‰∏™Êï∞Ôºö$S_1$ - $S_L$ Á•ûÁªèÁΩëÁªúÁöÑÂàÜÁ±ª‰∫åÁ±ªÂàÜÁ±ªÔºö$S_L = 0, y = 0 or 1$ KÁ±ªÂàÜÁ±ªÔºö$S_L = k, y_i = 1 (k &gt; 2)$ ‰ª£‰ª∑ÂáΩÊï∞$\newcommand{\subk}[1]{ #1_k }$ $$h_\theta\left(x\right)\in \mathbb{R}^{K}$$ $${\left({h_\theta}\left(x\right)\right)}_{i}={i}^{th} \text{output}$$ $J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_l+1} \left( \Theta_{ji}^{(l)} \right)^2$ ÂèçÂêë‰º†Êí≠ÂêëÂâç‰º†Êí≠ÁöÑÁÆóÊ≥ïÊòØ: ÂèçÂêë‰º†Êí≠ÁöÑÁÆóÊ≥ïÂ∞±ÊòØÂÖàÊ≠£Âêë‰º†Êí≠ËÆ°ÁÆóÂá∫ÊØè‰∏ÄÂ±ÇÁöÑÊøÄÊ¥ªÂçïÂÖÉÔºåÁÑ∂ÂêéÂà©Áî®ËÆ≠ÁªÉÈõÜÁöÑÁªìÊûú‰∏éÁ•ûÁªèÁΩëÁªúÈ¢ÑÊµãÁöÑÁªìÊûúÊ±ÇÂá∫ÊúÄÂêé‰∏ÄÂ±ÇÁöÑËØØÂ∑ÆÔºåÁÑ∂ÂêéÂà©Áî®ËØ•ËØØÂ∑ÆËøêÁî®ÂèçÂêë‰º†Êí≠ËÆ°ÁÆóÂá∫Áõ¥Ëá≥Á¨¨‰∫åÂ±ÇÁöÑÊâÄÊúâËØØÂ∑Æ„ÄÇ Âú®Ê±ÇÂá∫‰∫Ü$\Delta_{ij}^{(l)}$‰πãÂêéÔºåÊàë‰ª¨‰æøÂèØ‰ª•ËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÅèÂØºÊï∞‰∫ÜÔºåËÆ°ÁÆóÊñπÊ≥ïÂ¶Ç‰∏ãÔºö $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}$ ${if}; j \neq 0$ $ D_{ij}^{(l)} :=\frac{1}{m}\Delta_{ij}^{(l)}$ ${if}; j = 0$ Á•ûÁªèÁΩëÁªúÁöÑÊÄªÁªìÁΩëÁªúÁªìÊûÑÔºöÁ¨¨‰∏Ä‰ª∂Ë¶ÅÂÅöÁöÑ‰∫ãÊòØÈÄâÊã©ÁΩëÁªúÁªìÊûÑÔºåÂç≥ÂÜ≥ÂÆöÈÄâÊã©Â§öÂ∞ëÂ±Ç‰ª•ÂèäÂÜ≥ÂÆöÊØèÂ±ÇÂàÜÂà´ÊúâÂ§öÂ∞ë‰∏™ÂçïÂÖÉ„ÄÇ Á¨¨‰∏ÄÂ±ÇÁöÑÂçïÂÖÉÊï∞Âç≥Êàë‰ª¨ËÆ≠ÁªÉÈõÜÁöÑÁâπÂæÅÊï∞Èáè„ÄÇ ÊúÄÂêé‰∏ÄÂ±ÇÁöÑÂçïÂÖÉÊï∞ÊòØÊàë‰ª¨ËÆ≠ÁªÉÈõÜÁöÑÁªìÊûúÁöÑÁ±ªÁöÑÊï∞Èáè„ÄÇ Â¶ÇÊûúÈöêËóèÂ±ÇÊï∞Â§ß‰∫é1ÔºåÁ°Æ‰øùÊØè‰∏™ÈöêËóèÂ±ÇÁöÑÂçïÂÖÉ‰∏™Êï∞Áõ∏ÂêåÔºåÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÈöêËóèÂ±ÇÂçïÂÖÉÁöÑ‰∏™Êï∞Ë∂äÂ§öË∂äÂ•Ω„ÄÇ Êàë‰ª¨ÁúüÊ≠£Ë¶ÅÂÜ≥ÂÆöÁöÑÊòØÈöêËóèÂ±ÇÁöÑÂ±ÇÊï∞ÂíåÊØè‰∏™‰∏≠Èó¥Â±ÇÁöÑÂçïÂÖÉÊï∞„ÄÇ ËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÔºö ÂèÇÊï∞ÁöÑÈöèÊú∫ÂàùÂßãÂåñ Âà©Áî®Ê≠£Âêë‰º†Êí≠ÊñπÊ≥ïËÆ°ÁÆóÊâÄÊúâÁöÑ$h_{\theta}(x)$ ÁºñÂÜôËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞ $J$ ÁöÑ‰ª£Á†Å Âà©Áî®ÂèçÂêë‰º†Êí≠ÊñπÊ≥ïËÆ°ÁÆóÊâÄÊúâÂÅèÂØºÊï∞ Âà©Áî®Êï∞ÂÄºÊ£ÄÈ™åÊñπÊ≥ïÊ£ÄÈ™åËøô‰∫õÂÅèÂØºÊï∞ ‰ΩøÁî®‰ºòÂåñÁÆóÊ≥ïÊù•ÊúÄÂ∞èÂåñ‰ª£‰ª∑ÂáΩÊï∞]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÂÆûÁé∞ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï]]></title>
    <url>%2F2018%2F08%2F27%2FPython%E5%AE%9E%E7%8E%B0%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Â∫îÁî®È´òÊñØÂàÜÂ∏ÉÂºÄÂèëÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÔºåËøô‰∏™ÊØîËæÉÁÆÄÂçïÔºåÈ´òÊñØÂàÜÂ∏É‰πüÂè´ÂÅöÊ≠£ÊÄÅÂàÜÂ∏ÉÔºåÈ´ò‰∏≠Â∞±Â≠¶ËøáÔºåÂ¶ÇÊûúÊàë‰ª¨ÁöÑÊï∞ÊçÆÁ¨¶ÂêàÈ´òÊñØÂàÜÂ∏ÉÊàñËÄÖÊØîËæÉÂÉèÈ´òÊñØÂàÜÂ∏ÉÁöÑÊó∂ÂÄôÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÁÆóÊ≥ïÔºåÈÄöËøáËÆ≠ÁªÉÈõÜËÆ°ÁÆóÈ´òÊñØÂàÜÂ∏ÉÂáΩÊï∞Ôºå‰∏é‰∫§ÂèâÈ™åËØÅÈõÜÊØîËæÉËÆæÁΩÆÂêàÈÄÇÁöÑŒ£ÔºåÂΩìÊµãËØïÊï∞ÊçÆÂ∞è‰∫éŒ£Êó∂Âàô‰∏∫ÂºÇÂ∏∏ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#!/usr/bin/python# coding=utf-8import numpy as npimport matplotlib.pyplot as pltimport scipy.io as siodata = sio.loadmat('./data/ex8data1.mat');X = data['X'] # ËÆ≠ÁªÉÈõÜXval = data['Xval'] # ‰∫§ÂèâÈ™åËØÅÈõÜYval = data['yval']X1 = X[:, [0]]X2 = X[:, [1]]fig, ax = plt.subplots(figsize=(12,8))ax.scatter(X1, X2)# plt.plot(Xval[:, [0]], Xval[:, [1]], '.', markerfacecolor='g', markeredgecolor="k", markersize=14)plt.show()# ËÆ°ÁÆóÂπ≥ÂùáÊï∞ ùúá Âíå ÊñπÂ∑Æ ùúé2def aveandvar(x): sum = np.array([0]) for i in x: sum = sum + i ave = sum/len(x) sum = 0 for i in x: sum += (i - ave)*(i - ave) var = sum/len(x) return ave, var# ËÆ°ÁÆóÊ¶ÇÁéáÂØÜÂ∫¶p(x); ÁâπÂæÅÈõÜ, Âπ≥ÂùáÂÄº, Âπ≥ÊñπÂ∑Ædef gaussian_distribution(x, u, s): px = [] for i in x: p = 1/(np.sqrt((2 * np.pi * s))) * np.exp(-((i - u) * (i - u))/(2 * s)) px.append(p) px = np.array(px) return px# ÈÄâÊã©ÈòàÂÄºdef select_threshold(pval, yval): best_epsilon = 0 best_f1 = 0 f1 = 0 step = (pval.max() - pval.min()) / 10000 for epsilon in np.arange(pval.min(), pval.max(), step): preds = pval &lt; epsilon tp = np.sum(np.logical_and(preds == 1, yval == 1)).astype(float) fp = np.sum(np.logical_and(preds == 1, yval == 0)).astype(float) fn = np.sum(np.logical_and(preds == 0, yval == 1)).astype(float) precision = tp / (tp + fp) recall = tp / (tp + fn) f1 = (2 * precision * recall) / (precision + recall) if f1 &gt; best_f1: best_f1 = f1 best_epsilon = epsilon return best_epsilon, best_f1# Áîª‰∏Ä‰∏ãËøô‰∏§‰∏™ÁâπÂæÅÂÄºÁöÑÈ´òÊñØÊõ≤Á∫ø È¶ñÂÖàË¶ÅÊéí‰∏ãÂ∫èX1.T.sort()X2.T.sort()u,s = aveandvar(X1)px1 = gaussian_distribution(X1, u, s)u,s = aveandvar(X2)px2 = gaussian_distribution(X2, u, s)plt.subplot(211)plt.title('X1')plt.plot(X1, px1 )plt.subplot(212)plt.title('X2')plt.plot(X2, px2 )plt.show()# ËÆ°ÁÆóËÆ≠ÁªÉÈõÜu,s = aveandvar(X)px = gaussian_distribution(X, u, s)# ËÆ°ÁÆóÊµãËØïÈõÜu,s = aveandvar(Xval)tpx = gaussian_distribution(X, u, s)epsilon, f1 = select_threshold(tpx, Yval)print(epsilon, f1)# Ê†áËÆ∞Âá∫ÂºÇÂ∏∏Êï∞ÊçÆoutliers = np.where(px &lt; epsilon)fig, ax = plt.subplots(figsize=(12,8))ax.scatter(X[:,0], X[:,1])ax.scatter(X[outliers[0],0], X[outliers[0],1], s=50, color='r', marker='o')plt.show()# Ë∞ÉÂ∫ìÈ™åËØÅfrom scipy import statspx = np.zeros((X.shape[0], X.shape[1]))px[:,0] = stats.norm(u[0], s[0]).pdf(X[:,0])px[:,1] = stats.norm(u[1], s[1]).pdf(X[:,1])outliers = np.where(px &lt; epsilon)fig, ax = plt.subplots(figsize=(12,8))ax.scatter(X[:,0], X[:,1])ax.scatter(X[outliers[0],0], X[outliers[0],1], s=50, color='r', marker='o')plt.show() ËøôÊòØÊàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜÂêàÔºåÊòéÊòæÊúâÂÖ≠‰∏™ÊòØÂºÇÂ∏∏Êï∞ÊçÆ ÁîªÂá∫Ëøû‰∏™ÁâπÂæÅÁöÑÈ´òÊñØÂáΩÊï∞ÔºåÊØîËæÉÂÉèÈ´òÊñØÂàÜÂ∏É ÈÄöËøáÊàëËá™Â∑±ÂÜôÁöÑÈ´òÊñØÂØÜÂ∫¶ÂáΩÊï∞ËÆ°ÁÆóÔºåÊúâ‰∫õËøáÊãüÂêàÔºåÂ§öÊãüÂêàÂà∞‰∫Ü‰∏§‰∏™ÁÇπÔºå‰∏çÁü•ÈÅì‰∏∫‰ªÄ‰πà„ÄÇ Ë∞ÉÁî®scipyÁöÑÈ´òÊñØÂáΩÊï∞Â∫ìËÆ°ÁÆóÂêéÂÆåÁæéÁöÑÊ£ÄÊµãÂà∞‰∫ÜÂºÇÂ∏∏Êï∞ÊçÆ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰ª£Á†ÅÂÆûÁé∞</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÂÆûÁé∞PCAÈôçÁª¥ÁÆóÊ≥ï]]></title>
    <url>%2F2018%2F08%2F21%2FPython%E5%AE%9E%E7%8E%B0PCA%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[ËøôÊòØÁ¨¨‰∫å‰∏™Êó†ÁõëÁù£Â≠¶‰π†ÁöÑÁÆóÊ≥ïÔºåÊòØ‰∏Ä‰∏™ÈôçÁª¥ÁÆóÊ≥ïÔºåÂèØ‰ª•ÊääÂ§ö‰∏™ÁâπÂæÅËøõË°åÂéãÁº©ÔºåÊàëÂú®ÂéãÁº©ÂêéËÆ°ÁÆó‰∫Ü‰∏éÂéüÊï∞ÊçÆÁöÑÂÅèÂ∑ÆÔºåÂΩìÊàëÊääÂõõ‰∏™ÁâπÂæÅÂéãÁº©‰∏∫‰∏â‰∏™Êó∂ÂÅèÂ∑ÆÂè™Êúâ0.5%ÔºåÂéãÁº©‰∏∫‰∏Ä‰∏™ÁâπÂæÅÊó∂ÂÅèÂ∑Æ‰πüÂè™Êúâ7%ÔºåÂΩìÂè™Êúâ‰∏Ä‰∏™ÁâπÂæÅÊó∂ÊääÊï∞ÊçÆÂ±ïÂºÄ‰πüÂèØ‰ª•ËΩªÊòìÁöÑÂàÜ‰∏∫‰∏âÁ±ªÔºåÊâÄ‰ª•ËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏‰ºòÁßÄÁöÑÁÆóÊ≥ï„ÄÇ ÂÄºÂæóÊ≥®ÊÑèÁöÑÁÇπÊòØÂú®ËÆ°ÁÆóÂ•áÂºÇÁü©ÈòµÊó∂ÈÅáÂà∞ÁöÑÈóÆÈ¢òÔºåÈ¶ñÂÖàÊàë‰ª¨Êúâ‰∏Ä‰∏™m√ónÔºàm‰∏™Êï∞ÊçÆÔºån‰∏™ÁâπÂæÅÔºâÁöÑÁü©ÈòµXÔºåÊàë‰ª¨Â∏åÊúõÂæóÂà∞‰∏Ä‰∏™m√ókÁöÑÁü©ÈòµZÔºåÂÖ∑‰ΩìÈôçÁª¥ËøáÁ®ãÂàÜ‰∏âÊ≠•Ôºö ¬∑Á¨¨‰∏ÄÊ≠•ÔºöÂùáÂÄºÂΩí‰∏ÄÂåñÔºåÂ∞±ÊòØÊääÊØè‰∏Ä‰∏™Êï∞ÈÉΩÂáèÂéªÊÄªÊï∞ÁöÑÂπ≥ÂùáÂÄºÔºåÂæóÂà∞ÁöÑ‰∏Ä‰∏™ÂíåÂπ≥ÂùáÊï∞Â∑ÆË∑ùÁöÑÊñ∞Áü©ÈòµXj„ÄÇ ¬∑Á¨¨‰∫åÈÉ®ÔºöËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÂú®ËøôÈáåË¶ÅÊ≥®ÊÑèÁöÑÊó∂ÔºåXj(i)ÊòØ‰∏Ä‰∏™n√ó1ÁöÑÁü©ÈòµÔºåXj(i)ÁöÑËΩ¨ÁΩÆÊòØ‰∏Ä‰∏™1√ónÁöÑÁü©ÈòµÔºåÊâÄ‰ª•‰ªñ‰ø©Áõ∏‰πòÂæóÂà∞‰∏Ä‰∏™n√ónÁöÑÁü©ÈòµŒ£ÔºåÂÖ∂ÂÆûÂ∞±ÊòØÁöÑÂà∞‰∏Ä‰∏™Â•áÂºÇÁü©ÈòµÔºåÂõ†‰∏∫Âè™ÊúâÂ•áÂºÇÁü©ÈòµÊâçÂèØËÉΩÊúâÁâπÂæÅÂÄº„ÄÇ ¬∑Á¨¨‰∏âÈÉ®ÔºöÂ•áÂºÇÂÄºÂàÜËß£ÔºåËÆ°ÁÆó‚àëÁöÑÁâπÂæÅÂÄºÔºå‰ΩøÁî®svd()ÂáΩÊï∞ÂàÜËß£Âá∫U,S,V‰∏â‰∏™ÂêëÈáèÔºåU‰πüÊòØ‰∏Ä‰∏™n√ónÁöÑÁü©ÈòµÔºåÂú®U‰∏≠ÈÄâÂèñk‰∏™ÂêëÈáèÔºåËé∑Âæó‰∏Ä‰∏™n√ókÁöÑÁü©ÈòµUreduceÔºåÊñ∞ÁöÑÁâπÂæÅÁü©ÈòµzÂ∞±Á≠â‰∫éUreduceÁöÑËΩ¨ÁΩÆ(k√ón)‰πò‰ª•X(n√óm)ÁªìÊûúÂæóÂà∞‰∏Ä‰∏™k√ómÁöÑÊñ∞Áü©Èòµ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#!/usr/bin/python# coding=utf-8from sklearn.datasets import load_irisimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dimport numpy as npfrom sklearn.cluster import KMeansclass MYPCA: def __init__(self, data, k): self.m = len(data) # ËÆ≠ÁªÉÊï∞ÊçÆ‰∏™Êï∞ self.n = len(data[0]) # Áé∞Âú®ÁöÑÁâπÂæÅÊï∞ self.k = k # ‰ºòÂåñÂêéÁöÑÁâπÂæÅÊï∞ self.X = data # Á¨¨‰∏ÄÊ≠•ÊòØÂùáÂÄºÂΩí‰∏ÄÂåñ„ÄÇÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÂá∫ÊâÄÊúâÁâπÂæÅÁöÑÂùáÂÄº def data_preprocess(self): sum = 0 for i in self.X: sum += i u = sum/self.m self.newX = np.empty([0, self.n]) for i in self.X: self.newX = np.row_stack((self.newX, i - u)) return self.newX # Á¨¨‰∫åÊ≠•ËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©Èòµ ‰º†ÂÖ•ÂùáÂÄºÂΩí‰∏ÄÂåñÂêéÁöÑÁü©Èòµ Œ£=1ùëöŒ£(ùë•(ùëñ))ùëõùëñ=1(ùë•(ùëñ))ùëá def covariance_matrix(self, X): sum = 0 for i in X: i = i[np.newaxis, :] sum += np.dot(i.T, i) sigma = sum/self.m return sigma # ËÆ°ÁÆóÊñ∞ÁöÑÁâπÂæÅÂêëÈáèZ def get_z(self, U, X): z = np.empty([self.k, 0]) Ureduce = U[...,0:self.k] for i in X: i = i[np.newaxis, :] t = np.dot(Ureduce.T, i.T) z = np.column_stack((z, t)) return z # ËÆ°ÁÆóËÆ≠ÁªÉÈõÜËØØÂ∑Æ def error_analysis(self): S = self.S sigmaK = 0 sigmaN = 0 for i in range(self.n): if i &lt; self.k: sigmaK += S[i] if i &lt; self.n: sigmaN += S[i] return 1 - sigmaK/sigmaN # ÊÅ¢Â§çÂà∞‰πãÂâçÁª¥Â∫¶ def rovecor_dimensional(self): Ureduce = self.U[..., 0:self.k] Xappox = np.dot(Ureduce, self.z) return Xappox def train(self): newX = self.data_preprocess() sigma = self.covariance_matrix(newX) self.U, self.S, self.V = np.linalg.svd(sigma) # ËøôÈáå‰ΩøÁî®ÂùáÂÄºÂΩí‰∏ÄÂåñÂêéÁöÑXÂíåÂéüXÂØπÁªìÊûúÊ≤°ÊúâÂΩ±Âìç #self.z = self.get_z(self.U, self.X) self.z = self.get_z(self.U, newX) return self.z.T# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜÔºöÂºïÂÖ•È∏¢Â∞æËä±Êï∞ÊçÆÈõÜÊù•‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜ, ÂÖ∑ÊúâÂõõ‰∏™ÁâπÂæÅ,ÂàÜ‰∏âÁ±ªiris = load_iris()data = iris.datadata = np.array(data[:])m = len(data)#np.random.shuffle(data)# ÊääÂõõ‰∏™ÁâπÂæÅÂéãÁº©‰∏∫‰∏â‰∏™irispca = MYPCA(data, 3)z = irispca.train()error = irispca.error_analysis()print(error)x1 = z[:, [0]]x2 = z[:, [1]]x3 = z[:, [2]]fig = plt.figure()ax = fig.add_subplot(111, projection='3d')ax.scatter(x1, x2, x3, c='r', marker='*')ax.set_xlabel('x1 Label')ax.set_ylabel('x2 Label')ax.set_zlabel('x3 Label')plt.show()# ÊääÂõõ‰∏™ÁâπÂæÅÂéãÁº©‰∏∫‰∏Ä‰∏™irispca = MYPCA(data, 1)z = irispca.train()plt.plot(z, '.')error = irispca.error_analysis()print(error)# ‰ΩøÁî®KmeansÁöÑÁÆóÊ≥ïÈ™åËØÅ‰∏Ä‰∏ãÊòØÂê¶ËøòÂèØ‰ª•Ê≠£Á°ÆÂàÜÁ±ªkmeans = KMeans(n_clusters=3, random_state=0).fit(z)kmeans_u = kmeans.cluster_centers_u = np.transpose(kmeans_u)plt.plot([m/6, m/2, 5*m/6], u[0], '*', markerfacecolor='g', markeredgecolor="k", markersize=14)plt.show()]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰ª£Á†ÅÂÆûÁé∞</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitÂ≠¶‰π†Á¨îËÆ∞]]></title>
    <url>%2F2018%2F08%2F20%2FGit%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[GitÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÂàÜÂ∏ÉÂºèÁâàÊú¨ÊéßÂà∂Á≥ªÁªüÔºåÁî®‰∫éÊïèÊç∑È´òÊïàÂú∞Â§ÑÁêÜ‰ªª‰ΩïÊàñÂ∞èÊàñÂ§ßÁöÑÈ°πÁõÆ„ÄÇGit ÊòØ Linus Torvalds ‰∏∫‰∫ÜÂ∏ÆÂä©ÁÆ°ÁêÜ Linux ÂÜÖÊ†∏ÂºÄÂèëËÄåÂºÄÂèëÁöÑ‰∏Ä‰∏™ÂºÄÊîæÊ∫êÁ†ÅÁöÑÁâàÊú¨ÊéßÂà∂ËΩØ‰ª∂„ÄÇGit ‰∏éÂ∏∏Áî®ÁöÑÁâàÊú¨ÊéßÂà∂Â∑•ÂÖ∑ CVS, Subversion Á≠â‰∏çÂêåÔºåÂÆÉÈááÁî®‰∫ÜÂàÜÂ∏ÉÂºèÁâàÊú¨Â∫ìÁöÑÊñπÂºèÔºå‰∏çÂøÖÊúçÂä°Âô®Á´ØËΩØ‰ª∂ÊîØÊåÅ„ÄÇGit‰∏çÂêå‰∫éSVN‰πãÂâçÂÜôËøá SVN‰ΩøÁî®ÊâãÂÜå ÔºåÊê≠Âª∫ËøáSVNÊúçÂä°ÔºåÁé∞Âú®Â§ç‰π†‰∏Ä‰∏ãGit ÈÖçÁΩÆGitÈ¶ñÂÖàÂàõÂª∫SSH keyÔºö 1ssh-keygen -t rsa -C "email@email.com" Âú®~/ÁõÆÂΩï‰∏ãÁîüÊàê.sshÊñá‰ª∂Â§πÔºåÊâìÂºÄid_rsa.pubÔºåÂ§çÂà∂ÈáåÈù¢ÁöÑkey„ÄÇÂú®github‰∏äÔºåËøõÂÖ• Account SettingsÔºàË¥¶Êà∑ÈÖçÁΩÆÔºâÔºåÂ∑¶ËæπÈÄâÊã©SSH KeysÔºåAdd SSHKey,titleÈöè‰æøÂ°´ÔºåÁ≤òË¥¥Âú®ÁîµËÑë‰∏äÁîüÊàêÁöÑkey„ÄÇÈ™åËØÅÊòØÂê¶ÊàêÂäü1ssh -T git@github.com Â¶ÇÊûúÊòØÁ¨¨‰∏ÄÊ¨°ÁöÑ‰ºöÊèêÁ§∫ÊòØÂê¶continueÔºåËæìÂÖ•yesÂ∞±‰ºöÁúãÂà∞ÔºöYou‚Äôve successfully authenticated, but GitHub does not provide shell access „ÄÇËøôÂ∞±Ë°®Á§∫Â∑≤ÊàêÂäüËøû‰∏ägithub„ÄÇÊé•‰∏ãÊù•Êàë‰ª¨Ë¶ÅÂÅöÁöÑÂ∞±ÊòØÊääÊú¨Âú∞‰ªìÂ∫ì‰º†Âà∞github‰∏äÂéªÔºåÂú®Ê≠§‰πãÂâçËøòÈúÄË¶ÅËÆæÁΩÆusernameÂíåemailÔºåÂõ†‰∏∫githubÊØèÊ¨°commitÈÉΩ‰ºöËÆ∞ÂΩï‰ªñ‰ª¨„ÄÇ12git config --global user.name "your name"git config --global user.eamil "your_eamail@email.com" ‰∏ä‰º†ËøúÁ®ã‰ªìÂ∫ìÔºåÈúÄË¶ÅÊ∑ªÂä†ËøúÁ®ãÂú∞ÂùÄÔºå‰ªìÂ∫ìÈúÄË¶ÅÂú®github‰∏äÂÖàÂª∫Á´ãÂ•Ω1git remote add origin git@github.com:yourName/yourRepo.git Ê£ÄÂá∫‰ªìÂ∫ìÂÖãÈöÜÊú¨Âú∞‰ªìÂ∫ìÔºö git clone /path/to/repository ÂÖãÈöÜËøúÁ®ã‰ªìÂ∫ìÔºö git clone username@host:/path/to/repository Êé®ÈÄÅÊµÅÁ®ã123456789101112131415$mkdir test #ÂàõÂª∫‰∏Ä‰∏™ÊµãËØïÁõÆÂΩï$cd test/ #ËøõÂÖ•testÁõÆÂΩï$echo "#git test file" &gt;&gt; README.md #ÁªôreadmeÊñá‰ª∂ÂÜôÂÖ•ÂÜÖÂÆπ$lsREADME.md$git init #ÂàùÂßãÂåñinit$git add README.md #Ê∑ªÂä†Êñá‰ª∂[master (root-commit) 0205aab] Ê∑ªÂä† README.md Êñá‰ª∂ 1 file changed, 1 insertion(+) create mode 100644 README.md$git commit -m "add readme.md file" #Êèê‰∫§Â§áÊ≥®‰ø°ÊÅØ#Êèê‰∫§Âà∞github$ git remote add origin git@github.com:usename/Repositoryname.git$ git push -u origin master Â∏∏Áî®ÂëΩ‰ª§1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#ÂàùÂßãÂåñgit$git init#Êã∑Ë¥ù‰∏Ä‰∏™‰ªìÂ∫ìÂà∞Êú¨Âú∞$git clone [url]#Ê∑ªÂä†Êñá‰ª∂Âà∞ÁºìÂ≠ò$git add#Êü•ÁúãÂΩìÂâçÈ°πÁõÆÁä∂ÊÄÅ$git status -s#A Âä†ÂÖ•ÁºìÂ≠ò MÊúâÊîπÂä® #Êü•Áúã‰øÆÊîπÊâßË°å git diff Êù•Êü•ÁúãÊâßË°å git status ÁöÑÁªìÊûúÁöÑËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇgit diff ÂëΩ‰ª§ÊòæÁ§∫Â∑≤ÂÜôÂÖ•ÁºìÂ≠ò‰∏éÂ∑≤‰øÆÊîπ‰ΩÜÂ∞öÊú™ÂÜôÂÖ•ÁºìÂ≠òÁöÑÊîπÂä®ÁöÑÂå∫Âà´„ÄÇgit diff Êúâ‰∏§‰∏™‰∏ªË¶ÅÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇÂ∞öÊú™ÁºìÂ≠òÁöÑÊîπÂä®Ôºögit diffÊü•ÁúãÂ∑≤ÁºìÂ≠òÁöÑÊîπÂä®Ôºö git diff --cachedÊü•ÁúãÂ∑≤ÁºìÂ≠òÁöÑ‰∏éÊú™ÁºìÂ≠òÁöÑÊâÄÊúâÊîπÂä®Ôºögit diff HEADÊòæÁ§∫ÊëòË¶ÅËÄåÈùûÊï¥‰∏™ diffÔºögit diff --stat#Ê∑ªÂä†Âà∞‰ªìÂ∫ì$git commit -m "ÊèèËø∞"#ÂèñÊ∂àÁºìÂ≠òÂÜÖÂÆπ$git reset HEAD#Âà†Èô§Êñá‰ª∂Â¶ÇÊûúÂè™ÊòØÁÆÄÂçïÂú∞‰ªéÂ∑•‰ΩúÁõÆÂΩï‰∏≠ÊâãÂ∑•Âà†Èô§Êñá‰ª∂ÔºåËøêË°å git status Êó∂Â∞±‰ºöÂú® Changes not staged for commit ÁöÑÊèêÁ§∫„ÄÇË¶Å‰ªé Git ‰∏≠ÁßªÈô§Êüê‰∏™Êñá‰ª∂ÔºåÂ∞±ÂøÖÈ°ªË¶Å‰ªéÂ∑≤Ë∑üË∏™Êñá‰ª∂Ê∏ÖÂçï‰∏≠ÁßªÈô§ÔºåÁÑ∂ÂêéÊèê‰∫§„ÄÇÂèØ‰ª•Áî®‰ª•‰∏ãÂëΩ‰ª§ÂÆåÊàêÊ≠§È°πÂ∑•‰Ωú$git rm &lt;file&gt;Â¶ÇÊûúÂà†Èô§‰πãÂâç‰øÆÊîπËøáÂπ∂‰∏îÂ∑≤ÁªèÊîæÂà∞ÊöÇÂ≠òÂå∫ÂüüÁöÑËØùÔºåÂàôÂøÖÈ°ªË¶ÅÁî®Âº∫Âà∂Âà†Èô§ÈÄâÈ°π -f$git rm -f &lt;file&gt;Â¶ÇÊûúÊääÊñá‰ª∂‰ªéÊöÇÂ≠òÂå∫ÂüüÁßªÈô§Ôºå‰ΩÜ‰ªçÁÑ∂Â∏åÊúõ‰øùÁïôÂú®ÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩï‰∏≠ÔºåÊç¢Âè•ËØùËØ¥Ôºå‰ªÖÊòØ‰ªéË∑üË∏™Ê∏ÖÂçï‰∏≠Âà†Èô§Ôºå‰ΩøÁî® --cached ÈÄâÈ°πÂç≥ÂèØ$git rm --cached &lt;file&gt;#ÈáçÂëΩÂêç$git mv oldname newname#pushÂà∞ËøúÁ®ãÂàÜÊîØgit push origin Êú¨Âú∞ÂàÜÊîØÂêçÂ≠ó:ËøúÁ®ãÂàÜÊîØÂêç#Êü•ÁúãÊâÄÊúâÂàÜÊîØgit branch -a * master remotes/origin/HEAD -&gt; origin/master #ÂàõÂª∫Âπ∂ÂàáÊç¢ÂàÜÊîØ git checkout -b Êú¨Âú∞ÂàÜÊîØÂêç origin/ËøúÁ®ãÂàÜÊîØÂêç Êü•ÁúãÂΩìÂâçËøúÁ®ã‰ªìÂ∫ìÔºö12345$ git remoteorigin$ git remote -vorigin git@github.com:Voidmort/blogs.git (fetch)origin git@github.com:Voidmort/blogs.git (push) Git Êúâ‰∏§‰∏™ÂëΩ‰ª§Áî®Êù•ÊèêÂèñËøúÁ®ã‰ªìÂ∫ìÁöÑÊõ¥Êñ∞„ÄÇ1„ÄÅ‰ªéËøúÁ®ã‰ªìÂ∫ì‰∏ãËΩΩÊñ∞ÂàÜÊîØ‰∏éÊï∞ÊçÆÔºö git fetch ËØ•ÂëΩ‰ª§ÊâßË°åÂÆåÂêéÈúÄË¶ÅÊâßË°ågit merge ËøúÁ®ãÂàÜÊîØÂà∞‰Ω†ÊâÄÂú®ÁöÑÂàÜÊîØ„ÄÇ2„ÄÅ‰ªéËøúÁ´Ø‰ªìÂ∫ìÊèêÂèñÊï∞ÊçÆÂπ∂Â∞ùËØïÂêàÂπ∂Âà∞ÂΩìÂâçÂàÜÊîØÔºö git merge ËØ•ÂëΩ‰ª§Â∞±ÊòØÂú®ÊâßË°å git fetch ‰πãÂêéÁ¥ßÊé•ÁùÄÊâßË°å git merge ËøúÁ®ãÂàÜÊîØÂà∞‰Ω†ÊâÄÂú®ÁöÑ‰ªªÊÑèÂàÜÊîØ„ÄÇ Âà†Èô§1234567891011121314151617181920$ git remote -vorigin git@github.com:Voidmort/blogs.git (fetch)origin git@github.com:Voidmort/blogs.git (push)#Ê∑ªÂä†‰ªìÂ∫ì2$ git remote add origin2 git@github.com:Voidmort/blogs.git$ git remote -vorigin git@github.com:Voidmort/blogs.git (fetch)origin git@github.com:Voidmort/blogs.git (push)origin2 git@github.com:Voidmort/blogs.git (fetch)origin2 git@github.com:Voidmort/blogs.git (push)#Âà†Èô§‰ªìÂ∫ì2$ git remote rm origin2$ git remote -vorigin git@github.com:Voidmort/blogs.git (fetch)origin git@github.com:Voidmort/blogs.git (push) gitÂú®ÁªàÁ´Ø‰∏çËÉΩËØÜÂà´‰∏≠Êñá 123456789$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: "\346\234\272\345\231\250\345\255\246\344\271\240\345\256\236\346\210\230\357\274\210\345\215\201\357\274\211.ipynb" core.quotepathËÆæ‰∏∫falseÁöÑËØùÔºåÂ∞±‰∏ç‰ºöÂØπ0x80‰ª•‰∏äÁöÑÂ≠óÁ¨¶ËøõË°åquote„ÄÇ‰∏≠ÊñáÊòæÁ§∫Ê≠£Â∏∏„ÄÇ 1git config --global core.quotepath false]]></content>
      <categories>
        <category>Â≠¶‰π†Á¨îËÆ∞</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÂÆûÁé∞K-ÂùáÂÄºÁÆóÊ≥ï]]></title>
    <url>%2F2018%2F08%2F16%2FPython%E5%AE%9E%E7%8E%B0K-%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Á¨¨‰∏Ä‰∏™Êó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåK-ÂùáÂÄºÔºåËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÊôÆÂèäÁöÑËÅöÁ±ªÁÆóÊ≥ïÔºåÂÆûÁé∞Ëµ∑Êù•‰πüÊØîËæÉÁÆÄÂçïÔºåÂ≠¶‰π†‰∫ÜAndrew NgÁöÑËßÜÈ¢ëËÆ≤Ëß£ÔºåÁõ¥Êé•Á∫™ÂΩï‰∏Ä‰∏ãÈáçÁÇπÂêß„ÄÇ È¶ñÂÖàËÆ≠ÁªÉÈõÜÂêàÈÄâÂèñ‰∫ÜsklearnËá™Â∏¶ÁöÑÂ§öÁ±ªÂçïÊ†áÁ≠æÊï∞ÊçÆÈõÜmake_blobs ÂàùÂßãÂåñÂèòÈáèÊúâm:ËÆ≠ÁªÉÈõÜÁöÑ‰∏™Êï∞ÔºåFeature:ËÆ≠ÁªÉÈõÜÁöÑÁª¥Â∫¶ÔºåKÔºöË¶ÅÂàÜÊàêÂá†Á±ªÔºåuÔºö‰∏Ä‰∏™K*FeatureÁª¥Â∫¶ÁöÑÊï∞ÁªÑÔºåÂÇ®Â≠òËÅöÁ±ª‰∏≠ÂøÉÔºåc:ÂÇ®Â≠òÊØèÊ¨°Ëø≠‰ª£ÁöÑÂàÜÁ±ªÁªìÊûúÔºåuDict:ÂÇ®Â≠òÂàÜÁ±ªÁªìÊûúÁöÑÂ≠óÂÖ∏ ÊÄªÁªìÔºöÂõ†‰∏∫Êï∞ÊçÆÈáèÊØîËæÉÂ∞ëÔºåÊ†πÊçÆËßÇÂØüÁï∏ÂèòÂáΩÁöÑÁªìÊûúÊï∞ÔºåÂü∫Êú¨Ëø≠‰ª£‰∏âÊ¨°Â∞±ÂàÜÁ±ªÊàêÂäü‰∫ÜÔºåËØ¥ÊòéËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏‰ºòÁßÄÁöÑÁÆóÊ≥ï„ÄÇ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets.samples_generator import make_blobsfrom sklearn.cluster import KMeansimport random# ÊûÑÂª∫ÂçïÊ†áÁ≠æÊï∞ÊçÆÈõÜcenter = [[1,1],[-1,-1],[1,-1]]cluster_std = 0.3X,labels = make_blobs(n_samples=200, centers=center, n_features=2, cluster_std=cluster_std, random_state=0)unique_lables = set(labels)colors=plt.cm.Spectral(np.linspace(0, 1, len(unique_lables)))for k,col in zip(unique_lables, colors): x_k=X[labels==k] plt.plot(x_k[:,0], x_k[:,1], 'o', markerfacecolor=col, markeredgecolor="k", markersize=14)##########Feature = 2 # ÁâπÂæÅÊï∞m = 200 # ËÆ≠ÁªÉÊï∞ÊçÆ‰∏™Êï∞# ÂàùÂßãÂåñK Âíå ËÅöÁ±ª‰∏≠ÂøÉuK = 3u = np.empty([K, Feature])for i in range(K): u[i] = random.choice(X)# c ÂÇ®Â≠òÂàÜÁ±ªÁªìÊûúÂíåË∑ùÁ¶ªc = np.zeros([m,2])# ÁîªÂá∫ÂàùÂßãËÅöÁ±ª‰∏≠ÂøÉt = np.transpose(u)plt.plot(t[0], t[1], '+', markerfacecolor='g', markeredgecolor="k", markersize=14)# ÂÇ®Â≠òÂàÜÁ±ªÁªìÊûúÁöÑÂ≠óÂÖ∏uDict = &#123;&#125;# ÁßªÂä®ËÅöÁ±ª‰∏≠ÂøÉdef MoveK(c): u = np.empty([K, Feature]) for i in range(K): uDict[i] = [] for i in range(m): for j in range(K): if(c[i][0] == j): uDict[j].append(X[i]) for i in range(K): sum = np.zeros([1, Feature]) for j in uDict[i]: sum = np.add(sum, j) u[i] = sum/len(uDict[i]) return u# Áï∏ÂèòÂáΩÊï∞ Distortion functiondef Distortion(u): sum = 0 for i in uDict.keys(): for j in uDict[i]: dis = np.linalg.norm(j - u[i]) sum += dis * dis return sum/m# ÂºÄÂßãËø≠‰ª£for t in range(5): # ÊàëÂ∏åÊúõÊâæÂà∞ c[i](‰ª£Ë°®Á¨¨i‰∏™Êï∞ÊçÆ) Ë∑ùÁ¶ª u[k]ÔºàËÅöÁ±ª‰∏≠ÂøÉÔºâ ÊúÄÂ∞è for i in range(m): flag = True for j in range(K): dis = np.linalg.norm(X[i]-u[j]) if(flag or dis &lt; c[i][1]): flag = False c[i][0] = j c[i][1] = dis u = MoveK(c) print(Distortion(u))# È™åËØÅÁªìÊûúprint("my kemans cluster enters:", u)kmeans = KMeans(n_clusters=3, random_state=0).fit(X)kmeans_u = kmeans.cluster_centers_print("sklearn kemans cluster enters:", kmeans_u)t = np.transpose(u)plt.plot(t[0], t[1], '*', markerfacecolor='blue', markeredgecolor="k", markersize=14)plt.show() ÊâßË°åÁªìÊûúÔºö 0.80930644677085140.27707959685843420.172880244245511540.172880244245511540.17288024424551154 my kemans cluster enters: [[ 0.95712283 -1.02057236] [ 1.01281413 1.06595402] [-1.03507066 -1.03233287]] sklearn kemans cluster enters: [[ 0.95712283 -1.02057236] [ 1.01281413 1.06595402] [-1.03507066 -1.03233287]] ÁÆóÊ≥ïÊàêÂäüÁöÑ‰ªé+Âè∑ÁöÑ‰ΩçÁΩÆÁßªÂä®Âà∞‰∫îËßíÊòüÁöÑ‰ΩçÁΩÆ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰ª£Á†ÅÂÆûÁé∞</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÔºàÂçÅ‰∫åÔºâ]]></title>
    <url>%2F2018%2F08%2F12%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÂçÅ‰∏É„ÄÅÂ§ßËßÑÊ®°Êú∫Âô®Â≠¶‰π†(Large Scale Machine Learning) 17.1 Â§ßÂûãÊï∞ÊçÆÈõÜÁöÑÂ≠¶‰π†ÂèÇËÄÉËßÜÈ¢ë: 17 - 1 - Learning With Large Datasets (6 min).mkv Â¶ÇÊûúÊàë‰ª¨Êúâ‰∏Ä‰∏™‰ΩéÊñπÂ∑ÆÁöÑÊ®°ÂûãÔºåÂ¢ûÂä†Êï∞ÊçÆÈõÜÁöÑËßÑÊ®°ÂèØ‰ª•Â∏ÆÂä©‰Ω†Ëé∑ÂæóÊõ¥Â•ΩÁöÑÁªìÊûú„ÄÇÊàë‰ª¨Â∫îËØ•ÊÄéÊ†∑Â∫îÂØπ‰∏Ä‰∏™Êúâ100‰∏áÊù°ËÆ∞ÂΩïÁöÑËÆ≠ÁªÉÈõÜÔºü ‰ª•Á∫øÊÄßÂõûÂΩíÊ®°Âûã‰∏∫‰æãÔºåÊØè‰∏ÄÊ¨°Ê¢ØÂ∫¶‰∏ãÈôçËø≠‰ª£ÔºåÊàë‰ª¨ÈÉΩÈúÄË¶ÅËÆ°ÁÆóËÆ≠ÁªÉÈõÜÁöÑËØØÂ∑ÆÁöÑÂπ≥ÊñπÂíåÔºåÂ¶ÇÊûúÊàë‰ª¨ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÈúÄË¶ÅÊúâ20Ê¨°Ëø≠‰ª£ÔºåËøô‰æøÂ∑≤ÁªèÊòØÈùûÂ∏∏Â§ßÁöÑËÆ°ÁÆó‰ª£‰ª∑„ÄÇ È¶ñÂÖàÂ∫îËØ•ÂÅöÁöÑ‰∫ãÊòØÂéªÊ£ÄÊü•‰∏Ä‰∏™Ëøô‰πàÂ§ßËßÑÊ®°ÁöÑËÆ≠ÁªÉÈõÜÊòØÂê¶ÁúüÁöÑÂøÖË¶ÅÔºå‰πüËÆ∏Êàë‰ª¨Âè™Áî®1000‰∏™ËÆ≠ÁªÉÈõÜ‰πüËÉΩËé∑ÂæóËæÉÂ•ΩÁöÑÊïàÊûúÔºåÊàë‰ª¨ÂèØ‰ª•ÁªòÂà∂Â≠¶‰π†Êõ≤Á∫øÊù•Â∏ÆÂä©Âà§Êñ≠„ÄÇ 17.2 ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂèÇËÄÉËßÜÈ¢ë: 17 - 2 - Stochastic Gradient Descent (13 min).mkv Â¶ÇÊûúÊàë‰ª¨‰∏ÄÂÆöÈúÄË¶Å‰∏Ä‰∏™Â§ßËßÑÊ®°ÁöÑËÆ≠ÁªÉÈõÜÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ùËØï‰ΩøÁî®ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÊù•‰ª£ÊõøÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ï„ÄÇ Âú®ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï‰∏≠ÔºåÊàë‰ª¨ÂÆö‰πâ‰ª£‰ª∑ÂáΩÊï∞‰∏∫‰∏Ä‰∏™Âçï‰∏ÄËÆ≠ÁªÉÂÆû‰æãÁöÑ‰ª£‰ª∑Ôºö ‚Äã $$cost\left( \theta, \left( {x}^{(i)} , {y}^{(i)} \right) \right) = \frac{1}{2}\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{{(i)}} \right)^{2}$$ **ÈöèÊú∫**Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰∏∫ÔºöÈ¶ñÂÖàÂØπËÆ≠ÁªÉÈõÜÈöèÊú∫‚ÄúÊ¥óÁâå‚ÄùÔºåÁÑ∂ÂêéÔºö Repeat (usually anywhere between1-10){ **for** $i = 1:m${ ‚Äã $\theta:={\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{(i)} \right){{x}_{j}}^{(i)}$ ‚Äã (**for** $j=0:n$) ‚Äã } } ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÂú®ÊØè‰∏ÄÊ¨°ËÆ°ÁÆó‰πãÂêé‰æøÊõ¥Êñ∞ÂèÇÊï∞ ${{\theta }}$ ÔºåËÄå‰∏çÈúÄË¶ÅÈ¶ñÂÖàÂ∞ÜÊâÄÊúâÁöÑËÆ≠ÁªÉÈõÜÊ±ÇÂíåÔºåÂú®Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïËøòÊ≤°ÊúâÂÆåÊàê‰∏ÄÊ¨°Ëø≠‰ª£Êó∂ÔºåÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰æøÂ∑≤ÁªèËµ∞Âá∫‰∫ÜÂæàËøú„ÄÇ‰ΩÜÊòØËøôÊ†∑ÁöÑÁÆóÊ≥ïÂ≠òÂú®ÁöÑÈóÆÈ¢òÊòØÔºå‰∏çÊòØÊØè‰∏ÄÊ≠•ÈÉΩÊòØÊúùÁùÄ‚ÄùÊ≠£Á°Æ‚ÄùÁöÑÊñπÂêëËøàÂá∫ÁöÑ„ÄÇÂõ†Ê≠§ÁÆóÊ≥ïËôΩÁÑ∂‰ºöÈÄêÊ∏êËµ∞ÂêëÂÖ®Â±ÄÊúÄÂ∞èÂÄºÁöÑ‰ΩçÁΩÆÔºå‰ΩÜÊòØÂèØËÉΩÊó†Ê≥ïÁ´ôÂà∞ÈÇ£‰∏™ÊúÄÂ∞èÂÄºÁöÑÈÇ£‰∏ÄÁÇπÔºåËÄåÊòØÂú®ÊúÄÂ∞èÂÄºÁÇπÈôÑËøëÂæòÂæä„ÄÇ 17.3 Â∞èÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÂèÇËÄÉËßÜÈ¢ë: 17 - 3 - Mini-Batch Gradient Descent (6 min).mkv Â∞èÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊòØ‰ªã‰∫éÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÂíåÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰πãÈó¥ÁöÑÁÆóÊ≥ïÔºåÊØèËÆ°ÁÆóÂ∏∏Êï∞$b$Ê¨°ËÆ≠ÁªÉÂÆû‰æãÔºå‰æøÊõ¥Êñ∞‰∏ÄÊ¨°ÂèÇÊï∞ ${{\theta }}$ „ÄÇ **Repeat** { **for** $i = 1:m${ ‚Äã $\theta:={\theta}_{j}-\alpha\frac{1}{b}\sum_\limits{k=i}^{i+b-1}\left( {h}_{\theta}\left({x}^{(k)}\right)-{y}^{(k)} \right){{x}_{j}}^{(k)}$ ‚Äã (**for** $j=0:n$) ‚Äã $ i +=10 $ ‚Äã } } ÈÄöÂ∏∏Êàë‰ª¨‰ºö‰ª§ $b$ Âú® 2-100 ‰πãÈó¥„ÄÇËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÂú®‰∫éÔºåÊàë‰ª¨ÂèØ‰ª•Áî®ÂêëÈáèÂåñÁöÑÊñπÂºèÊù•Âæ™ÁéØ $b$‰∏™ËÆ≠ÁªÉÂÆû‰æãÔºåÂ¶ÇÊûúÊàë‰ª¨Áî®ÁöÑÁ∫øÊÄß‰ª£Êï∞ÂáΩÊï∞Â∫ìÊØîËæÉÂ•ΩÔºåËÉΩÂ§üÊîØÊåÅÂπ≥Ë°åÂ§ÑÁêÜÔºåÈÇ£‰πàÁÆóÊ≥ïÁöÑÊÄª‰ΩìË°®Áé∞Â∞Ü‰∏çÂèóÂΩ±ÂìçÔºà‰∏éÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁõ∏ÂêåÔºâ„ÄÇ 17.4 ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊî∂ÊïõÂèÇËÄÉËßÜÈ¢ë: 17 - 4 - Stochastic Gradient Descent Convergence (12 min). mkv Áé∞Âú®Êàë‰ª¨‰ªãÁªçÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÁöÑË∞ÉËØïÔºå‰ª•ÂèäÂ≠¶‰π†Áéá $Œ±$ ÁöÑÈÄâÂèñ„ÄÇ Âú®ÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôç‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•‰ª§‰ª£‰ª∑ÂáΩÊï∞$J$‰∏∫Ëø≠‰ª£Ê¨°Êï∞ÁöÑÂáΩÊï∞ÔºåÁªòÂà∂ÂõæË°®ÔºåÊ†πÊçÆÂõæË°®Êù•Âà§Êñ≠Ê¢ØÂ∫¶‰∏ãÈôçÊòØÂê¶Êî∂Êïõ„ÄÇ‰ΩÜÊòØÔºåÂú®Â§ßËßÑÊ®°ÁöÑËÆ≠ÁªÉÈõÜÁöÑÊÉÖÂÜµ‰∏ãÔºåËøôÊòØ‰∏çÁé∞ÂÆûÁöÑÔºåÂõ†‰∏∫ËÆ°ÁÆó‰ª£‰ª∑Â§™Â§ß‰∫Ü„ÄÇ Âú®ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôç‰∏≠ÔºåÊàë‰ª¨Âú®ÊØè‰∏ÄÊ¨°Êõ¥Êñ∞ ${{\theta }}$ ‰πãÂâçÈÉΩËÆ°ÁÆó‰∏ÄÊ¨°‰ª£‰ª∑ÔºåÁÑ∂ÂêéÊØè$x$Ê¨°Ëø≠‰ª£ÂêéÔºåÊ±ÇÂá∫Ëøô$x$Ê¨°ÂØπËÆ≠ÁªÉÂÆû‰æãËÆ°ÁÆó‰ª£‰ª∑ÁöÑÂπ≥ÂùáÂÄºÔºåÁÑ∂ÂêéÁªòÂà∂Ëøô‰∫õÂπ≥ÂùáÂÄº‰∏é$x$Ê¨°Ëø≠‰ª£ÁöÑÊ¨°Êï∞‰πãÈó¥ÁöÑÂáΩÊï∞ÂõæË°®„ÄÇ ÂΩìÊàë‰ª¨ÁªòÂà∂ËøôÊ†∑ÁöÑÂõæË°®Êó∂ÔºåÂèØËÉΩ‰ºöÂæóÂà∞‰∏Ä‰∏™È¢†Á∞∏‰∏çÂπ≥‰ΩÜÊòØ‰∏ç‰ºöÊòéÊòæÂáèÂ∞ëÁöÑÂáΩÊï∞ÂõæÂÉèÔºàÂ¶Ç‰∏äÈù¢Â∑¶‰∏ãÂõæ‰∏≠ËìùÁ∫øÊâÄÁ§∫Ôºâ„ÄÇÊàë‰ª¨ÂèØ‰ª•Â¢ûÂä†$Œ±$Êù•‰ΩøÂæóÂáΩÊï∞Êõ¥Âä†Âπ≥ÁºìÔºå‰πüËÆ∏‰æøËÉΩÁúãÂá∫‰∏ãÈôçÁöÑË∂ãÂäø‰∫ÜÔºàÂ¶Ç‰∏äÈù¢Â∑¶‰∏ãÂõæ‰∏≠Á∫¢Á∫øÊâÄÁ§∫ÔºâÔºõÊàñËÄÖÂèØËÉΩÂáΩÊï∞ÂõæË°®‰ªçÁÑ∂ÊòØÈ¢†Á∞∏‰∏çÂπ≥‰∏î‰∏ç‰∏ãÈôçÁöÑÔºàÂ¶ÇÊ¥ãÁ∫¢Ëâ≤Á∫øÊâÄÁ§∫ÔºâÔºåÈÇ£‰πàÊàë‰ª¨ÁöÑÊ®°ÂûãÊú¨Ë∫´ÂèØËÉΩÂ≠òÂú®‰∏Ä‰∫õÈîôËØØ„ÄÇ Â¶ÇÊûúÊàë‰ª¨ÂæóÂà∞ÁöÑÊõ≤Á∫øÂ¶Ç‰∏äÈù¢Âè≥‰∏ãÊñπÊâÄÁ§∫Ôºå‰∏çÊñ≠Âú∞‰∏äÂçáÔºåÈÇ£‰πàÊàë‰ª¨ÂèØËÉΩ‰ºöÈúÄË¶ÅÈÄâÊã©‰∏Ä‰∏™ËæÉÂ∞èÁöÑÂ≠¶‰π†Áéá$Œ±$„ÄÇ Êàë‰ª¨‰πüÂèØ‰ª•‰ª§Â≠¶‰π†ÁéáÈöèÁùÄËø≠‰ª£Ê¨°Êï∞ÁöÑÂ¢ûÂä†ËÄåÂáèÂ∞èÔºå‰æãÂ¶Ç‰ª§Ôºö ‚Äã $$\alpha = \frac{const1}{iterationNumber + const2}$$ ÈöèÁùÄÊàë‰ª¨‰∏çÊñ≠Âú∞Èù†ËøëÂÖ®Â±ÄÊúÄÂ∞èÂÄºÔºåÈÄöËøáÂáèÂ∞èÂ≠¶‰π†ÁéáÔºåÊàë‰ª¨Ëø´‰ΩøÁÆóÊ≥ïÊî∂ÊïõËÄåÈùûÂú®ÊúÄÂ∞èÂÄºÈôÑËøëÂæòÂæä„ÄÇ‰ΩÜÊòØÈÄöÂ∏∏Êàë‰ª¨‰∏çÈúÄË¶ÅËøôÊ†∑ÂÅö‰æøËÉΩÊúâÈùûÂ∏∏Â•ΩÁöÑÊïàÊûú‰∫ÜÔºåÂØπ$Œ±$ËøõË°åË∞ÉÊï¥ÊâÄËÄóË¥πÁöÑËÆ°ÁÆóÈÄöÂ∏∏‰∏çÂÄºÂæó ÊÄªÁªì‰∏ãÔºåËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñπÊ≥ïÔºåËøë‰ººÂú∞ÁõëÊµãÂá∫ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÂú®ÊúÄ‰ºòÂåñ‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÁöÑË°®Áé∞ÔºåËøôÁßçÊñπÊ≥ï‰∏çÈúÄË¶ÅÂÆöÊó∂Âú∞Êâ´ÊèèÊï¥‰∏™ËÆ≠ÁªÉÈõÜÔºåÊù•ÁÆóÂá∫Êï¥‰∏™Ê†∑Êú¨ÈõÜÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåËÄåÊòØÂè™ÈúÄË¶ÅÊØèÊ¨°ÂØπÊúÄÂêé1000‰∏™ÔºåÊàñËÄÖÂ§öÂ∞ë‰∏™Ê†∑Êú¨ÔºåÊ±Ç‰∏Ä‰∏ãÂπ≥ÂùáÂÄº„ÄÇÂ∫îÁî®ËøôÁßçÊñπÊ≥ïÔºå‰Ω†Êó¢ÂèØ‰ª•‰øùËØÅÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÊ≠£Âú®Ê≠£Â∏∏ËøêËΩ¨ÂíåÊî∂ÊïõÔºå‰πüÂèØ‰ª•Áî®ÂÆÉÊù•Ë∞ÉÊï¥Â≠¶‰π†ÈÄüÁéá$Œ±$ÁöÑÂ§ßÂ∞è„ÄÇ 17.5 Âú®Á∫øÂ≠¶‰π†ÂèÇËÄÉËßÜÈ¢ë: 17 - 5 - Online Learning (13 min).mkv Âú®Ëøô‰∏™ËßÜÈ¢ë‰∏≠ÔºåËÆ®ËÆ∫‰∏ÄÁßçÊñ∞ÁöÑÂ§ßËßÑÊ®°ÁöÑÊú∫Âô®Â≠¶‰π†Êú∫Âà∂ÔºåÂè´ÂÅöÂú®Á∫øÂ≠¶‰π†Êú∫Âà∂„ÄÇÂú®Á∫øÂ≠¶‰π†Êú∫Âà∂ËÆ©Êàë‰ª¨ÂèØ‰ª•Ê®°ÂûãÂåñÈóÆÈ¢ò„ÄÇ ‰ªäÂ§©ÔºåËÆ∏Â§öÂ§ßÂûãÁΩëÁ´ôÊàñËÄÖËÆ∏Â§öÂ§ßÂûãÁΩëÁªúÂÖ¨Âè∏Ôºå‰ΩøÁî®‰∏çÂêåÁâàÊú¨ÁöÑÂú®Á∫øÂ≠¶‰π†Êú∫Âà∂ÁÆóÊ≥ïÔºå‰ªéÂ§ßÊâπÁöÑÊ∂åÂÖ•ÂèàÁ¶ªÂºÄÁΩëÁ´ôÁöÑÁî®Êà∑Ë∫´‰∏äËøõË°åÂ≠¶‰π†„ÄÇÁâπÂà´Ë¶ÅÊèêÂèäÁöÑÊòØÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™Áî±ËøûÁª≠ÁöÑÁî®Êà∑ÊµÅÂºïÂèëÁöÑËøûÁª≠ÁöÑÊï∞ÊçÆÊµÅÔºåËøõÂÖ•‰Ω†ÁöÑÁΩëÁ´ôÔºå‰Ω†ËÉΩÂÅöÁöÑÊòØ‰ΩøÁî®‰∏Ä‰∏™Âú®Á∫øÂ≠¶‰π†Êú∫Âà∂Ôºå‰ªéÊï∞ÊçÆÊµÅ‰∏≠Â≠¶‰π†Áî®Êà∑ÁöÑÂÅèÂ•ΩÔºåÁÑ∂Âêé‰ΩøÁî®Ëøô‰∫õ‰ø°ÊÅØÊù•‰ºòÂåñ‰∏Ä‰∫õÂÖ≥‰∫éÁΩëÁ´ôÁöÑÂÜ≥Á≠ñ„ÄÇ ÂÅáÂÆö‰Ω†Êúâ‰∏Ä‰∏™Êèê‰æõËøêËæìÊúçÂä°ÁöÑÂÖ¨Âè∏ÔºåÁî®Êà∑‰ª¨Êù•Âêë‰Ω†ËØ¢ÈóÆÊääÂåÖË£π‰ªéAÂú∞ËøêÂà∞BÂú∞ÁöÑÊúçÂä°ÔºåÂêåÊó∂ÂÅáÂÆö‰Ω†Êúâ‰∏Ä‰∏™ÁΩëÁ´ôÔºåËÆ©Áî®Êà∑‰ª¨ÂèØÂ§öÊ¨°ÁôªÈôÜÔºåÁÑ∂Âêé‰ªñ‰ª¨ÂëäËØâ‰Ω†Ôºå‰ªñ‰ª¨ÊÉ≥‰ªéÂì™ÈáåÂØÑÂá∫ÂåÖË£πÔºå‰ª•ÂèäÂåÖË£πË¶ÅÂØÑÂà∞Âì™ÈáåÂéªÔºå‰πüÂ∞±ÊòØÂá∫ÂèëÂú∞‰∏éÁõÆÁöÑÂú∞ÔºåÁÑ∂Âêé‰Ω†ÁöÑÁΩëÁ´ôÂºÄÂá∫ËøêËæìÂåÖË£πÁöÑÁöÑÊúçÂä°‰ª∑Ê†º„ÄÇÊØîÂ¶ÇÔºåÊàë‰ºöÊî∂Âèñ\$50Êù•ËøêËæì‰Ω†ÁöÑÂåÖË£πÔºåÊàë‰ºöÊî∂Âèñ\$20‰πãÁ±ªÁöÑÔºåÁÑ∂ÂêéÊ†πÊçÆ‰Ω†ÂºÄÁªôÁî®Êà∑ÁöÑËøô‰∏™‰ª∑Ê†ºÔºåÁî®Êà∑ÊúâÊó∂‰ºöÊé•ÂèóËøô‰∏™ËøêËæìÊúçÂä°ÔºåÈÇ£‰πàËøôÂ∞±ÊòØ‰∏™Ê≠£Ê†∑Êú¨ÔºåÊúâÊó∂‰ªñ‰ª¨‰ºöËµ∞ÊéâÔºåÁÑ∂Âêé‰ªñ‰ª¨ÊãíÁªùË¥≠‰π∞‰Ω†ÁöÑËøêËæìÊúçÂä°ÔºåÊâÄ‰ª•ÔºåËÆ©Êàë‰ª¨ÂÅáÂÆöÊàë‰ª¨ÊÉ≥Ë¶Å‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÊù•Â∏ÆÂä©Êàë‰ª¨Ôºå‰ºòÂåñÊàë‰ª¨ÊÉ≥ÁªôÁî®Êà∑ÂºÄÂá∫ÁöÑ‰ª∑Ê†º„ÄÇ ‰∏Ä‰∏™ÁÆóÊ≥ïÊù•‰ªé‰∏≠Â≠¶‰π†ÁöÑÊó∂ÂÄôÊù•Ê®°ÂûãÂåñÈóÆÈ¢òÂú®Á∫øÂ≠¶‰π†ÁÆóÊ≥ïÊåáÁöÑÊòØÂØπÊï∞ÊçÆÊµÅËÄåÈùûÁ¶ªÁ∫øÁöÑÈùôÊÄÅÊï∞ÊçÆÈõÜÁöÑÂ≠¶‰π†„ÄÇËÆ∏Â§öÂú®Á∫øÁΩëÁ´ôÈÉΩÊúâÊåÅÁª≠‰∏çÊñ≠ÁöÑÁî®Êà∑ÊµÅÔºåÂØπ‰∫éÊØè‰∏Ä‰∏™Áî®Êà∑ÔºåÁΩëÁ´ôÂ∏åÊúõËÉΩÂú®‰∏çÂ∞ÜÊï∞ÊçÆÂ≠òÂÇ®Âà∞Êï∞ÊçÆÂ∫ì‰∏≠‰æøÈ°∫Âà©Âú∞ËøõË°åÁÆóÊ≥ïÂ≠¶‰π†„ÄÇ ÂÅá‰ΩøÊàë‰ª¨Ê≠£Âú®ÁªèËê•‰∏ÄÂÆ∂Áâ©ÊµÅÂÖ¨Âè∏ÔºåÊØèÂΩì‰∏Ä‰∏™Áî®Êà∑ËØ¢ÈóÆ‰ªéÂú∞ÁÇπAËá≥Âú∞ÁÇπBÁöÑÂø´ÈÄíË¥πÁî®Êó∂ÔºåÊàë‰ª¨ÁªôÁî®Êà∑‰∏Ä‰∏™Êä•‰ª∑ÔºåËØ•Áî®Êà∑ÂèØËÉΩÈÄâÊã©Êé•ÂèóÔºà$y=1$ÔºâÊàñ‰∏çÊé•ÂèóÔºà$y=0$Ôºâ„ÄÇ Áé∞Âú®ÔºåÊàë‰ª¨Â∏åÊúõÊûÑÂª∫‰∏Ä‰∏™Ê®°ÂûãÔºåÊù•È¢ÑÊµãÁî®Êà∑Êé•ÂèóÊä•‰ª∑‰ΩøÁî®Êàë‰ª¨ÁöÑÁâ©ÊµÅÊúçÂä°ÁöÑÂèØËÉΩÊÄß„ÄÇÂõ†Ê≠§Êä•‰ª∑ÊòØÊàë‰ª¨ÁöÑ‰∏Ä‰∏™ÁâπÂæÅÔºåÂÖ∂‰ªñÁâπÂæÅ‰∏∫Ë∑ùÁ¶ªÔºåËµ∑ÂßãÂú∞ÁÇπÔºåÁõÆÊ†áÂú∞ÁÇπ‰ª•ÂèäÁâπÂÆöÁöÑÁî®Êà∑Êï∞ÊçÆ„ÄÇÊ®°ÂûãÁöÑËæìÂá∫ÊòØ:$p(y=1)$„ÄÇ Âú®Á∫øÂ≠¶‰π†ÁöÑÁÆóÊ≥ï‰∏éÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊúâ‰∫õÁ±ª‰ººÔºåÊàë‰ª¨ÂØπÂçï‰∏ÄÁöÑÂÆû‰æãËøõË°åÂ≠¶‰π†ÔºåËÄåÈùûÂØπ‰∏Ä‰∏™ÊèêÂâçÂÆö‰πâÁöÑËÆ≠ÁªÉÈõÜËøõË°åÂæ™ÁéØ„ÄÇ Repeat forever (as long as the website is running) { Get $\left(x,y\right)$ corresponding to the current user ‚Äã $\theta:={\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}\right)-{y} \right){{x}_{j}}$ ‚Äã (**for** $j=0:n$) } ‰∏ÄÊó¶ÂØπ‰∏Ä‰∏™Êï∞ÊçÆÁöÑÂ≠¶‰π†ÂÆåÊàê‰∫ÜÔºåÊàë‰ª¨‰æøÂèØ‰ª•‰∏¢ÂºÉËØ•Êï∞ÊçÆÔºå‰∏çÈúÄË¶ÅÂÜçÂ≠òÂÇ®ÂÆÉ‰∫Ü„ÄÇËøôÁßçÊñπÂºèÁöÑÂ•ΩÂ§ÑÂú®‰∫éÔºåÊàë‰ª¨ÁöÑÁÆóÊ≥ïÂèØ‰ª•ÂæàÂ•ΩÁöÑÈÄÇÂ∫îÁî®Êà∑ÁöÑÂÄæÂêëÊÄßÔºåÁÆóÊ≥ïÂèØ‰ª•ÈíàÂØπÁî®Êà∑ÁöÑÂΩìÂâçË°å‰∏∫‰∏çÊñ≠Âú∞Êõ¥Êñ∞Ê®°Âûã‰ª•ÈÄÇÂ∫îËØ•Áî®Êà∑„ÄÇ ÊØèÊ¨°‰∫§‰∫í‰∫ã‰ª∂Âπ∂‰∏çÂè™‰∫ßÁîü‰∏Ä‰∏™Êï∞ÊçÆÈõÜÔºå‰æãÂ¶ÇÔºåÊàë‰ª¨‰∏ÄÊ¨°ÁªôÁî®Êà∑Êèê‰æõ3‰∏™Áâ©ÊµÅÈÄâÈ°πÔºåÁî®Êà∑ÈÄâÊã©2È°πÔºåÊàë‰ª¨ÂÆûÈôÖ‰∏äÂèØ‰ª•Ëé∑Âæó3‰∏™Êñ∞ÁöÑËÆ≠ÁªÉÂÆû‰æãÔºåÂõ†ËÄåÊàë‰ª¨ÁöÑÁÆóÊ≥ïÂèØ‰ª•‰∏ÄÊ¨°‰ªé3‰∏™ÂÆû‰æã‰∏≠Â≠¶‰π†Âπ∂Êõ¥Êñ∞Ê®°Âûã„ÄÇ Ëøô‰∫õÈóÆÈ¢ò‰∏≠ÁöÑ‰ªª‰Ωï‰∏Ä‰∏™ÈÉΩÂèØ‰ª•Ë¢´ÂΩíÁ±ªÂà∞Ê†áÂáÜÁöÑÔºåÊã•Êúâ‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÊ†∑Êú¨ÈõÜÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢ò‰∏≠„ÄÇÊàñËÆ∏Ôºå‰Ω†ÂèØ‰ª•ËøêË°å‰∏Ä‰∏™‰Ω†Ëá™Â∑±ÁöÑÁΩëÁ´ôÔºåÂ∞ùËØïËøêË°åÂá†Â§©ÔºåÁÑ∂Âêé‰øùÂ≠ò‰∏Ä‰∏™Êï∞ÊçÆÈõÜÔºå‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÊï∞ÊçÆÈõÜÔºåÁÑ∂ÂêéÂØπÂÖ∂ËøêË°å‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ï„ÄÇ‰ΩÜÊòØËøô‰∫õÊòØÂÆûÈôÖÁöÑÈóÆÈ¢òÔºåÂú®Ëøô‰∫õÈóÆÈ¢òÈáåÔºå‰Ω†‰ºöÁúãÂà∞Â§ßÂÖ¨Âè∏‰ºöËé∑ÂèñÂ¶ÇÊ≠§Â§öÁöÑÊï∞ÊçÆÔºåÁúüÁöÑÊ≤°ÊúâÂøÖË¶ÅÊù•‰øùÂ≠ò‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÊï∞ÊçÆÈõÜÔºåÂèñËÄå‰ª£‰πãÁöÑÊòØ‰Ω†ÂèØ‰ª•‰ΩøÁî®‰∏Ä‰∏™Âú®Á∫øÂ≠¶‰π†ÁÆóÊ≥ïÊù•ËøûÁª≠ÁöÑÂ≠¶‰π†Ôºå‰ªéËøô‰∫õÁî®Êà∑‰∏çÊñ≠‰∫ßÁîüÁöÑÊï∞ÊçÆ‰∏≠Êù•Â≠¶‰π†„ÄÇËøôÂ∞±ÊòØÂú®Á∫øÂ≠¶‰π†Êú∫Âà∂ÔºåÁÑ∂ÂêéÂ∞±ÂÉèÊàë‰ª¨ÊâÄÁúãÂà∞ÁöÑÔºåÊàë‰ª¨ÊâÄ‰ΩøÁî®ÁöÑËøô‰∏™ÁÆóÊ≥ï‰∏éÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÈùûÂ∏∏Á±ª‰ººÔºåÂîØ‰∏ÄÁöÑÂå∫Âà´ÁöÑÊòØÔºåÊàë‰ª¨‰∏ç‰ºö‰ΩøÁî®‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÊï∞ÊçÆÈõÜÔºåÊàë‰ª¨‰ºöÂÅöÁöÑÊòØËé∑Âèñ‰∏Ä‰∏™Áî®Êà∑Ê†∑Êú¨Ôºå‰ªéÈÇ£‰∏™Ê†∑Êú¨‰∏≠Â≠¶‰π†ÔºåÁÑ∂Âêé‰∏¢ÂºÉÈÇ£‰∏™Ê†∑Êú¨Âπ∂ÁªßÁª≠‰∏ãÂéªÔºåËÄå‰∏îÂ¶ÇÊûú‰Ω†ÂØπÊüê‰∏ÄÁßçÂ∫îÁî®Êúâ‰∏Ä‰∏™ËøûÁª≠ÁöÑÊï∞ÊçÆÊµÅÔºåËøôÊ†∑ÁöÑÁÆóÊ≥ïÂèØËÉΩ‰ºöÈùûÂ∏∏ÂÄºÂæóËÄÉËôë„ÄÇÂΩìÁÑ∂ÔºåÂú®Á∫øÂ≠¶‰π†ÁöÑ‰∏Ä‰∏™‰ºòÁÇπÂ∞±ÊòØÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™ÂèòÂåñÁöÑÁî®Êà∑Áæ§ÔºåÂèàÊàñËÄÖ‰Ω†Âú®Â∞ùËØïÈ¢ÑÊµãÁöÑ‰∫ãÊÉÖÔºåÂú®ÁºìÊÖ¢ÂèòÂåñÔºåÂ∞±ÂÉè‰Ω†ÁöÑÁî®Êà∑ÁöÑÂìÅÂë≥Âú®ÁºìÊÖ¢ÂèòÂåñÔºåËøô‰∏™Âú®Á∫øÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂèØ‰ª•ÊÖ¢ÊÖ¢Âú∞Ë∞ÉËØï‰Ω†ÊâÄÂ≠¶‰π†Âà∞ÁöÑÂÅáËÆæÔºåÂ∞ÜÂÖ∂Ë∞ÉËäÇÊõ¥Êñ∞Âà∞ÊúÄÊñ∞ÁöÑÁî®Êà∑Ë°å‰∏∫„ÄÇ 17.6 Êò†Â∞ÑÂåñÁÆÄÂíåÊï∞ÊçÆÂπ∂Ë°åÂèÇËÄÉËßÜÈ¢ë: 17 - 6 - Map Reduce and Data Parallelism (14 min).mkv Êò†Â∞ÑÂåñÁÆÄÂíåÊï∞ÊçÆÂπ∂Ë°åÂØπ‰∫éÂ§ßËßÑÊ®°Êú∫Âô®Â≠¶‰π†ÈóÆÈ¢òËÄåË®ÄÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑÊ¶ÇÂøµ„ÄÇ‰πãÂâçÊèêÂà∞ÔºåÂ¶ÇÊûúÊàë‰ª¨Áî®ÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊù•Ê±ÇËß£Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜÁöÑÊúÄ‰ºòËß£ÔºåÊàë‰ª¨ÈúÄË¶ÅÂØπÊï¥‰∏™ËÆ≠ÁªÉÈõÜËøõË°åÂæ™ÁéØÔºåËÆ°ÁÆóÂÅèÂØºÊï∞Âíå‰ª£‰ª∑ÔºåÂÜçÊ±ÇÂíåÔºåËÆ°ÁÆó‰ª£‰ª∑ÈùûÂ∏∏Â§ß„ÄÇÂ¶ÇÊûúÊàë‰ª¨ËÉΩÂ§üÂ∞ÜÊàë‰ª¨ÁöÑÊï∞ÊçÆÈõÜÂàÜÈÖçÁªô‰∏çÂ§öÂè∞ËÆ°ÁÆóÊú∫ÔºåËÆ©ÊØè‰∏ÄÂè∞ËÆ°ÁÆóÊú∫Â§ÑÁêÜÊï∞ÊçÆÈõÜÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºåÁÑ∂ÂêéÊàë‰ª¨Â∞ÜËÆ°ÊâÄÁöÑÁªìÊûúÊ±áÊÄªÂú®Ê±ÇÂíå„ÄÇËøôÊ†∑ÁöÑÊñπÊ≥ïÂè´ÂÅöÊò†Â∞ÑÁÆÄÂåñ„ÄÇ ÂÖ∑‰ΩìËÄåË®ÄÔºåÂ¶ÇÊûú‰ªª‰ΩïÂ≠¶‰π†ÁÆóÊ≥ïËÉΩÂ§üË°®Ëææ‰∏∫ÔºåÂØπËÆ≠ÁªÉÈõÜÁöÑÂáΩÊï∞ÁöÑÊ±ÇÂíåÔºåÈÇ£‰πà‰æøËÉΩÂ∞ÜËøô‰∏™‰ªªÂä°ÂàÜÈÖçÁªôÂ§öÂè∞ËÆ°ÁÆóÊú∫ÔºàÊàñËÄÖÂêå‰∏ÄÂè∞ËÆ°ÁÆóÊú∫ÁöÑ‰∏çÂêåCPU Ê†∏ÂøÉÔºâÔºå‰ª•ËææÂà∞Âä†ÈÄüÂ§ÑÁêÜÁöÑÁõÆÁöÑ„ÄÇ ‰æãÂ¶ÇÔºåÊàë‰ª¨Êúâ400‰∏™ËÆ≠ÁªÉÂÆû‰æãÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÁöÑÊ±ÇÂíå‰ªªÂä°ÂàÜÈÖçÁªô4Âè∞ËÆ°ÁÆóÊú∫ËøõË°åÂ§ÑÁêÜÔºö ÂæàÂ§öÈ´òÁ∫ßÁöÑÁ∫øÊÄß‰ª£Êï∞ÂáΩÊï∞Â∫ìÂ∑≤ÁªèËÉΩÂ§üÂà©Áî®Â§öÊ†∏CPUÁöÑÂ§ö‰∏™Ê†∏ÂøÉÊù•Âπ∂Ë°åÂú∞Â§ÑÁêÜÁü©ÈòµËøêÁÆóÔºåËøô‰πüÊòØÁÆóÊ≥ïÁöÑÂêëÈáèÂåñÂÆûÁé∞Â¶ÇÊ≠§ÈáçË¶ÅÁöÑÁºòÊïÖÔºàÊØîË∞ÉÁî®Âæ™ÁéØÂø´Ôºâ„ÄÇ ÂçÅÂÖ´„ÄÅÂ∫îÁî®ÂÆû‰æãÔºöÂõæÁâáÊñáÂ≠óËØÜÂà´(Application Example: Photo OCR)18.1 ÈóÆÈ¢òÊèèËø∞ÂíåÊµÅÁ®ãÂõæÂèÇËÄÉËßÜÈ¢ë: 18 - 1 - Problem Description and Pipeline (7 min).mkv ÂõæÂÉèÊñáÂ≠óËØÜÂà´Â∫îÁî®ÊâÄ‰ΩúÁöÑ‰∫ãÊòØÔºå‰ªé‰∏ÄÂº†ÁªôÂÆöÁöÑÂõæÁâá‰∏≠ËØÜÂà´ÊñáÂ≠ó„ÄÇËøôÊØî‰ªé‰∏Ä‰ªΩÊâ´ÊèèÊñáÊ°£‰∏≠ËØÜÂà´ÊñáÂ≠óË¶ÅÂ§çÊùÇÁöÑÂ§ö„ÄÇ ‰∏∫‰∫ÜÂÆåÊàêËøôÊ†∑ÁöÑÂ∑•‰ΩúÔºåÈúÄË¶ÅÈááÂèñÂ¶Ç‰∏ãÊ≠•È™§Ôºö ÊñáÂ≠ó‰æ¶ÊµãÔºàText detectionÔºâ‚Äî‚ÄîÂ∞ÜÂõæÁâá‰∏äÁöÑÊñáÂ≠ó‰∏éÂÖ∂‰ªñÁéØÂ¢ÉÂØπË±°ÂàÜÁ¶ªÂºÄÊù• Â≠óÁ¨¶ÂàáÂàÜÔºàCharacter segmentationÔºâ‚Äî‚ÄîÂ∞ÜÊñáÂ≠óÂàÜÂâ≤Êàê‰∏Ä‰∏™‰∏™Âçï‰∏ÄÁöÑÂ≠óÁ¨¶ Â≠óÁ¨¶ÂàÜÁ±ªÔºàCharacter classificationÔºâ‚Äî‚ÄîÁ°ÆÂÆöÊØè‰∏Ä‰∏™Â≠óÁ¨¶ÊòØ‰ªÄ‰πàÂèØ‰ª•Áî®‰ªªÂä°ÊµÅÁ®ãÂõæÊù•Ë°®ËææËøô‰∏™ÈóÆÈ¢òÔºåÊØè‰∏ÄÈ°π‰ªªÂä°ÂèØ‰ª•Áî±‰∏Ä‰∏™ÂçïÁã¨ÁöÑÂ∞èÈòüÊù•Ë¥üË¥£Ëß£ÂÜ≥Ôºö 18.2 ÊªëÂä®Á™óÂè£ÂèÇËÄÉËßÜÈ¢ë: 18 - 2 - Sliding Windows (15 min).mkv ÊªëÂä®Á™óÂè£ÊòØ‰∏ÄÈ°πÁî®Êù•‰ªéÂõæÂÉè‰∏≠ÊäΩÂèñÂØπË±°ÁöÑÊäÄÊúØ„ÄÇÂÅá‰ΩøÊàë‰ª¨ÈúÄË¶ÅÂú®‰∏ÄÂº†ÂõæÁâá‰∏≠ËØÜÂà´Ë°å‰∫∫ÔºåÈ¶ñÂÖàË¶ÅÂÅöÁöÑÊòØÁî®ËÆ∏Â§öÂõ∫ÂÆöÂ∞∫ÂØ∏ÁöÑÂõæÁâáÊù•ËÆ≠ÁªÉ‰∏Ä‰∏™ËÉΩÂ§üÂáÜÁ°ÆËØÜÂà´Ë°å‰∫∫ÁöÑÊ®°Âûã„ÄÇÁÑ∂ÂêéÊàë‰ª¨Áî®‰πãÂâçËÆ≠ÁªÉËØÜÂà´Ë°å‰∫∫ÁöÑÊ®°ÂûãÊó∂ÊâÄÈááÁî®ÁöÑÂõæÁâáÂ∞∫ÂØ∏Âú®Êàë‰ª¨Ë¶ÅËøõË°åË°å‰∫∫ËØÜÂà´ÁöÑÂõæÁâá‰∏äËøõË°åÂâ™Ë£ÅÔºåÁÑ∂ÂêéÂ∞ÜÂâ™Ë£ÅÂæóÂà∞ÁöÑÂàáÁâá‰∫§ÁªôÊ®°ÂûãÔºåËÆ©Ê®°ÂûãÂà§Êñ≠ÊòØÂê¶‰∏∫Ë°å‰∫∫ÔºåÁÑ∂ÂêéÂú®ÂõæÁâá‰∏äÊªëÂä®Ââ™Ë£ÅÂå∫ÂüüÈáçÊñ∞ËøõË°åÂâ™Ë£ÅÔºåÂ∞ÜÊñ∞Ââ™Ë£ÅÁöÑÂàáÁâá‰πü‰∫§ÁªôÊ®°ÂûãËøõË°åÂà§Êñ≠ÔºåÂ¶ÇÊ≠§Âæ™ÁéØÁõ¥Ëá≥Â∞ÜÂõæÁâáÂÖ®ÈÉ®Ê£ÄÊµãÂÆå„ÄÇ ‰∏ÄÊó¶ÂÆåÊàêÂêéÔºåÊàë‰ª¨ÊåâÊØî‰æãÊîæÂ§ßÂâ™Ë£ÅÁöÑÂå∫ÂüüÔºåÂÜç‰ª•Êñ∞ÁöÑÂ∞∫ÂØ∏ÂØπÂõæÁâáËøõË°åÂâ™Ë£ÅÔºåÂ∞ÜÊñ∞Ââ™Ë£ÅÁöÑÂàáÁâáÊåâÊØî‰æãÁº©Â∞èËá≥Ê®°ÂûãÊâÄÈááÁ∫≥ÁöÑÂ∞∫ÂØ∏Ôºå‰∫§ÁªôÊ®°ÂûãËøõË°åÂà§Êñ≠ÔºåÂ¶ÇÊ≠§Âæ™ÁéØ„ÄÇ ÊªëÂä®Á™óÂè£ÊäÄÊúØ‰πüË¢´Áî®‰∫éÊñáÂ≠óËØÜÂà´ÔºåÈ¶ñÂÖàËÆ≠ÁªÉÊ®°ÂûãËÉΩÂ§üÂå∫ÂàÜÂ≠óÁ¨¶‰∏éÈùûÂ≠óÁ¨¶ÔºåÁÑ∂ÂêéÔºåËøêÁî®ÊªëÂä®Á™óÂè£ÊäÄÊúØËØÜÂà´Â≠óÁ¨¶Ôºå‰∏ÄÊó¶ÂÆåÊàê‰∫ÜÂ≠óÁ¨¶ÁöÑËØÜÂà´ÔºåÊàë‰ª¨Â∞ÜËØÜÂà´ÂæóÂá∫ÁöÑÂå∫ÂüüËøõË°å‰∏Ä‰∫õÊâ©Â±ïÔºåÁÑ∂ÂêéÂ∞ÜÈáçÂè†ÁöÑÂå∫ÂüüËøõË°åÂêàÂπ∂„ÄÇÊé•ÁùÄÊàë‰ª¨‰ª•ÂÆΩÈ´òÊØî‰Ωú‰∏∫ËøáÊª§Êù°‰ª∂ÔºåËøáÊª§ÊéâÈ´òÂ∫¶ÊØîÂÆΩÂ∫¶Êõ¥Â§ßÁöÑÂå∫ÂüüÔºàËÆ§‰∏∫ÂçïËØçÁöÑÈïøÂ∫¶ÈÄöÂ∏∏ÊØîÈ´òÂ∫¶Ë¶ÅÂ§ßÔºâ„ÄÇ‰∏ãÂõæ‰∏≠ÁªøËâ≤ÁöÑÂå∫ÂüüÊòØÁªèËøáËøô‰∫õÊ≠•È™§ÂêéË¢´ËÆ§‰∏∫ÊòØÊñáÂ≠óÁöÑÂå∫ÂüüÔºåËÄåÁ∫¢Ëâ≤ÁöÑÂå∫ÂüüÊòØË¢´ÂøΩÁï•ÁöÑ„ÄÇ ‰ª•‰∏ä‰æøÊòØÊñáÂ≠ó‰æ¶ÊµãÈò∂ÊÆµ„ÄÇ‰∏ã‰∏ÄÊ≠•ÊòØËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÊù•ÂÆåÊàêÂ∞ÜÊñáÂ≠óÂàÜÂâ≤Êàê‰∏Ä‰∏™‰∏™Â≠óÁ¨¶ÁöÑ‰ªªÂä°ÔºåÈúÄË¶ÅÁöÑËÆ≠ÁªÉÈõÜÁî±Âçï‰∏™Â≠óÁ¨¶ÁöÑÂõæÁâáÂíå‰∏§‰∏™Áõ∏ËøûÂ≠óÁ¨¶‰πãÈó¥ÁöÑÂõæÁâáÊù•ËÆ≠ÁªÉÊ®°Âûã„ÄÇ Ê®°ÂûãËÆ≠ÁªÉÂÆåÂêéÔºåÊàë‰ª¨‰ªçÁÑ∂ÊòØ‰ΩøÁî®ÊªëÂä®Á™óÂè£ÊäÄÊúØÊù•ËøõË°åÂ≠óÁ¨¶ËØÜÂà´„ÄÇ ‰ª•‰∏ä‰æøÊòØÂ≠óÁ¨¶ÂàáÂàÜÈò∂ÊÆµ„ÄÇÊúÄÂêé‰∏Ä‰∏™Èò∂ÊÆµÊòØÂ≠óÁ¨¶ÂàÜÁ±ªÈò∂ÊÆµÔºåÂà©Áî®Á•ûÁªèÁΩëÁªú„ÄÅÊîØÊåÅÂêëÈáèÊú∫ÊàñËÄÖÈÄªËæëÂõûÂΩíÁÆóÊ≥ïËÆ≠ÁªÉ‰∏Ä‰∏™ÂàÜÁ±ªÂô®Âç≥ÂèØ„ÄÇ 18.3 Ëé∑ÂèñÂ§ßÈáèÊï∞ÊçÆÂíå‰∫∫Â∑•Êï∞ÊçÆÂèÇËÄÉËßÜÈ¢ë: 18 - 3 - Getting Lots of Data and Artificial Data (16 min).mkv Â¶ÇÊûúÊàë‰ª¨ÁöÑÊ®°ÂûãÊòØ‰ΩéÊñπÂ∑ÆÁöÑÔºåÈÇ£‰πàËé∑ÂæóÊõ¥Â§öÁöÑÊï∞ÊçÆÁî®‰∫éËÆ≠ÁªÉÊ®°ÂûãÔºåÊòØËÉΩÂ§üÊúâÊõ¥Â•ΩÁöÑÊïàÊûúÁöÑ„ÄÇÈóÆÈ¢òÂú®‰∫éÔºåÊàë‰ª¨ÊÄéÊ†∑Ëé∑ÂæóÊï∞ÊçÆÔºåÊï∞ÊçÆ‰∏çÊÄªÊòØÂèØ‰ª•Áõ¥Êé•Ëé∑ÂæóÁöÑÔºåÊàë‰ª¨ÊúâÂèØËÉΩÈúÄË¶Å‰∫∫Â∑•Âú∞ÂàõÈÄ†‰∏Ä‰∫õÊï∞ÊçÆ„ÄÇ ‰ª•Êàë‰ª¨ÁöÑÊñáÂ≠óËØÜÂà´Â∫îÁî®‰∏∫‰æãÔºåÊàë‰ª¨ÂèØ‰ª•Â≠ó‰ΩìÁΩëÁ´ô‰∏ãËΩΩÂêÑÁßçÂ≠ó‰ΩìÔºåÁÑ∂ÂêéÂà©Áî®Ëøô‰∫õ‰∏çÂêåÁöÑÂ≠ó‰ΩìÈÖç‰∏äÂêÑÁßç‰∏çÂêåÁöÑÈöèÊú∫ËÉåÊôØÂõæÁâáÂàõÈÄ†Âá∫‰∏Ä‰∫õÁî®‰∫éËÆ≠ÁªÉÁöÑÂÆû‰æãÔºåËøôËÆ©Êàë‰ª¨ËÉΩÂ§üËé∑Âæó‰∏Ä‰∏™Êó†ÈôêÂ§ßÁöÑËÆ≠ÁªÉÈõÜ„ÄÇËøôÊòØ‰ªéÈõ∂ÂºÄÂßãÂàõÈÄ†ÂÆû‰æã„ÄÇ Âè¶‰∏ÄÁßçÊñπÊ≥ïÊòØÔºåÂà©Áî®Â∑≤ÊúâÁöÑÊï∞ÊçÆÔºåÁÑ∂ÂêéÂØπÂÖ∂ËøõË°å‰øÆÊîπÔºå‰æãÂ¶ÇÂ∞ÜÂ∑≤ÊúâÁöÑÂ≠óÁ¨¶ÂõæÁâáËøõË°å‰∏Ä‰∫õÊâ≠Êõ≤„ÄÅÊóãËΩ¨„ÄÅÊ®°Á≥äÂ§ÑÁêÜ„ÄÇÂè™Ë¶ÅÊàë‰ª¨ËÆ§‰∏∫ÂÆûÈôÖÊï∞ÊçÆÊúâÂèØËÉΩÂíåÁªèËøáËøôÊ†∑Â§ÑÁêÜÂêéÁöÑÊï∞ÊçÆÁ±ª‰ººÔºåÊàë‰ª¨‰æøÂèØ‰ª•Áî®ËøôÊ†∑ÁöÑÊñπÊ≥ïÊù•ÂàõÈÄ†Â§ßÈáèÁöÑÊï∞ÊçÆ„ÄÇ ÊúâÂÖ≥Ëé∑ÂæóÊõ¥Â§öÊï∞ÊçÆÁöÑÂá†ÁßçÊñπÊ≥ïÔºö ‰∫∫Â∑•Êï∞ÊçÆÂêàÊàê ÊâãÂä®Êî∂ÈõÜ„ÄÅÊ†áËÆ∞Êï∞ÊçÆ ‰ºóÂåÖ 18.4 ‰∏äÈôêÂàÜÊûêÔºöÂì™ÈÉ®ÂàÜÁÆ°ÈÅìÁöÑÊé•‰∏ãÂéªÂÅöÂèÇËÄÉËßÜÈ¢ë: 18 - 4 - Ceiling Analysis_ What Part of the Pipeline to Work on Next(14 min).mkv Âú®Êú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®‰∏≠ÔºåÊàë‰ª¨ÈÄöÂ∏∏ÈúÄË¶ÅÈÄöËøáÂá†‰∏™Ê≠•È™§ÊâçËÉΩËøõË°åÊúÄÁªàÁöÑÈ¢ÑÊµãÔºåÊàë‰ª¨Â¶Ç‰ΩïËÉΩÂ§üÁü•ÈÅìÂì™‰∏ÄÈÉ®ÂàÜÊúÄÂÄºÂæóÊàë‰ª¨Ëä±Êó∂Èó¥ÂíåÁ≤æÂäõÂéªÊîπÂñÑÂë¢ÔºüËøô‰∏™ÈóÆÈ¢òÂèØ‰ª•ÈÄöËøá‰∏äÈôêÂàÜÊûêÊù•ÂõûÁ≠î„ÄÇ ÂõûÂà∞Êàë‰ª¨ÁöÑÊñáÂ≠óËØÜÂà´Â∫îÁî®‰∏≠ÔºåÊàë‰ª¨ÁöÑÊµÅÁ®ãÂõæÂ¶Ç‰∏ãÔºö ÊµÅÁ®ãÂõæ‰∏≠ÊØè‰∏ÄÈÉ®ÂàÜÁöÑËæìÂá∫ÈÉΩÊòØ‰∏ã‰∏ÄÈÉ®ÂàÜÁöÑËæìÂÖ•Ôºå‰∏äÈôêÂàÜÊûê‰∏≠ÔºåÊàë‰ª¨ÈÄâÂèñ‰∏ÄÈÉ®ÂàÜÔºåÊâãÂ∑•Êèê‰æõ100%Ê≠£Á°ÆÁöÑËæìÂá∫ÁªìÊûúÔºåÁÑ∂ÂêéÁúãÂ∫îÁî®ÁöÑÊï¥‰ΩìÊïàÊûúÊèêÂçá‰∫ÜÂ§öÂ∞ë„ÄÇÂÅá‰ΩøÊàë‰ª¨ÁöÑ‰æãÂ≠ê‰∏≠ÊÄª‰ΩìÊïàÊûú‰∏∫72%ÁöÑÊ≠£Á°ÆÁéá„ÄÇ Â¶ÇÊûúÊàë‰ª¨‰ª§ÊñáÂ≠ó‰æ¶ÊµãÈÉ®ÂàÜËæìÂá∫ÁöÑÁªìÊûú100%Ê≠£Á°ÆÔºåÂèëÁé∞Á≥ªÁªüÁöÑÊÄª‰ΩìÊïàÊûú‰ªé72%ÊèêÈ´òÂà∞‰∫Ü89%„ÄÇËøôÊÑèÂë≥ÁùÄÊàë‰ª¨ÂæàÂèØËÉΩ‰ºöÂ∏åÊúõÊäïÂÖ•Êó∂Èó¥Á≤æÂäõÊù•ÊèêÈ´òÊàë‰ª¨ÁöÑÊñáÂ≠ó‰æ¶ÊµãÈÉ®ÂàÜ„ÄÇ Êé•ÁùÄÊàë‰ª¨ÊâãÂä®ÈÄâÊã©Êï∞ÊçÆÔºåËÆ©Â≠óÁ¨¶ÂàáÂàÜËæìÂá∫ÁöÑÁªìÊûú100%Ê≠£Á°ÆÔºåÂèëÁé∞Á≥ªÁªüÁöÑÊÄª‰ΩìÊïàÊûúÂè™ÊèêÂçá‰∫Ü1%ÔºåËøôÊÑèÂë≥ÁùÄÔºåÊàë‰ª¨ÁöÑÂ≠óÁ¨¶ÂàáÂàÜÈÉ®ÂàÜÂèØËÉΩÂ∑≤ÁªèË∂≥Â§üÂ•Ω‰∫Ü„ÄÇ ÊúÄÂêéÊàë‰ª¨ÊâãÂ∑•ÈÄâÊã©Êï∞ÊçÆÔºåËÆ©Â≠óÁ¨¶ÂàÜÁ±ªËæìÂá∫ÁöÑÁªìÊûú100%Ê≠£Á°ÆÔºåÁ≥ªÁªüÁöÑÊÄª‰ΩìÊïàÊûúÂèàÊèêÂçá‰∫Ü10%ÔºåËøôÊÑèÂë≥ÁùÄÊàë‰ª¨ÂèØËÉΩ‰πü‰ºöÂ∫îËØ•ÊäïÂÖ•Êõ¥Â§öÁöÑÊó∂Èó¥ÂíåÁ≤æÂäõÊù•ÊèêÈ´òÂ∫îÁî®ÁöÑÊÄª‰ΩìË°®Áé∞„ÄÇ ÂçÅ‰πù„ÄÅÊÄªÁªì(Conclusion)19.1 ÊÄªÁªìÂíåËá¥Ë∞¢ÂèÇËÄÉËßÜÈ¢ë: 19 - 1 - Summary and Thank You (5 min).mkv Ê¨¢ËøéÊù•Âà∞„ÄäÊú∫Âô®Â≠¶‰π†„ÄãËØæÁöÑÊúÄÂêé‰∏ÄÊÆµËßÜÈ¢ë„ÄÇÊàë‰ª¨Â∑≤Áªè‰∏ÄËµ∑Â≠¶‰π†ÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥‰∫Ü„ÄÇÂú®ÊúÄÂêéËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàëÊÉ≥Âø´ÈÄüÂú∞ÂõûÈ°æ‰∏Ä‰∏ãËøôÈó®ËØæÁöÑ‰∏ªË¶ÅÂÜÖÂÆπÔºåÁÑ∂ÂêéÁÆÄÂçïËØ¥Âá†Âè•ÊÉ≥ËØ¥ÁöÑËØù„ÄÇ ‰Ωú‰∏∫ËøôÈó®ËØæÁöÑÁªìÊùüÊó∂Èó¥ÔºåÈÇ£‰πàÊàë‰ª¨Â≠¶Âà∞‰∫Ü‰∫õ‰ªÄ‰πàÂë¢ÔºüÂú®ËøôÈó®ËØæ‰∏≠ÔºåÊàë‰ª¨Ëä±‰∫ÜÂ§ßÈáèÁöÑÊó∂Èó¥‰ªãÁªç‰∫ÜËØ∏Â¶ÇÁ∫øÊÄßÂõûÂΩí„ÄÅÈÄªËæëÂõûÂΩí„ÄÅÁ•ûÁªèÁΩëÁªú„ÄÅÊîØÊåÅÂêëÈáèÊú∫Á≠âÁ≠â‰∏Ä‰∫õÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåËøôÁ±ªÁÆóÊ≥ïÂÖ∑ÊúâÂ∏¶Ê†áÁ≠æÁöÑÊï∞ÊçÆÂíåÊ†∑Êú¨ÔºåÊØîÂ¶Ç${{x}^{\left( i \right)}}$„ÄÅ${{y}^{\left( i \right)}}$„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨‰πüËä±‰∫ÜÂæàÂ§öÊó∂Èó¥‰ªãÁªçÊó†ÁõëÁù£Â≠¶‰π†„ÄÇ‰æãÂ¶Ç **K-ÂùáÂÄº**ËÅöÁ±ª„ÄÅÁî®‰∫éÈôçÁª¥ÁöÑ‰∏ªÊàêÂàÜÂàÜÊûêÔºå‰ª•ÂèäÂΩì‰Ω†Âè™Êúâ‰∏ÄÁ≥ªÂàóÊó†Ê†áÁ≠æÊï∞ÊçÆ ${{x}^{\left( i \right)}}$ Êó∂ÁöÑÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇ ÂΩìÁÑ∂ÔºåÊúâÊó∂Â∏¶Ê†áÁ≠æÁöÑÊï∞ÊçÆÔºå‰πüÂèØ‰ª•Áî®‰∫éÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÁöÑËØÑ‰º∞„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨‰πüËä±Êó∂Èó¥ËÆ®ËÆ∫‰∫Ü‰∏Ä‰∫õÁâπÂà´ÁöÑÂ∫îÁî®ÊàñËÄÖÁâπÂà´ÁöÑËØùÈ¢òÔºåÊØîÂ¶ÇËØ¥Êé®ËçêÁ≥ªÁªü„ÄÇ‰ª•ÂèäÂ§ßËßÑÊ®°Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÔºåÂåÖÊã¨Âπ∂Ë°åÁ≥ªÁªüÂíåÊò†Â∞ÑÂåñÁÆÄÊñπÊ≥ïÔºåËøòÊúâÂÖ∂‰ªñ‰∏Ä‰∫õÁâπÂà´ÁöÑÂ∫îÁî®„ÄÇÊØîÂ¶ÇÔºåÁî®‰∫éËÆ°ÁÆóÊú∫ËßÜËßâÊäÄÊúØÁöÑÊªëÂä®Á™óÂè£ÂàÜÁ±ªÁÆóÊ≥ï„ÄÇ ÊúÄÂêéÔºåÊàë‰ª¨ËøòÊèêÂà∞‰∫ÜÂæàÂ§öÂÖ≥‰∫éÊûÑÂª∫Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑÂÆûÁî®Âª∫ËÆÆ„ÄÇËøôÂåÖÊã¨‰∫ÜÊÄéÊ†∑ÁêÜËß£Êüê‰∏™Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊòØÂê¶Ê≠£Â∏∏Â∑•‰ΩúÁöÑÂéüÂõ†ÔºåÊâÄ‰ª•Êàë‰ª¨Ë∞àÂà∞‰∫ÜÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÁöÑÈóÆÈ¢òÔºå‰πüË∞àÂà∞‰∫ÜËß£ÂÜ≥ÊñπÂ∑ÆÈóÆÈ¢òÁöÑÊ≠£ÂàôÂåñÔºåÂêåÊó∂Êàë‰ª¨‰πüËÆ®ËÆ∫‰∫ÜÊÄéÊ†∑ÂÜ≥ÂÆöÊé•‰∏ãÊù•ÊÄé‰πàÂÅöÁöÑÈóÆÈ¢òÔºå‰πüÂ∞±ÊòØËØ¥ÂΩì‰Ω†Âú®ÂºÄÂèë‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÊó∂Ôºå‰ªÄ‰πàÂ∑•‰ΩúÊâçÊòØÊé•‰∏ãÊù•Â∫îËØ•‰ºòÂÖàËÄÉËôëÁöÑÈóÆÈ¢ò„ÄÇÂõ†Ê≠§Êàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂ≠¶‰π†ÁÆóÊ≥ïÁöÑËØÑ‰ª∑Ê≥ï„ÄÇ‰ªãÁªç‰∫ÜËØÑ‰ª∑Áü©ÈòµÔºåÊØîÂ¶ÇÔºöÊü•ÂáÜÁéá„ÄÅÂè¨ÂõûÁéá‰ª•ÂèäF1ÂàÜÊï∞ÔºåËøòÊúâËØÑ‰ª∑Â≠¶‰π†ÁÆóÊ≥ïÊØîËæÉÂÆûÁî®ÁöÑËÆ≠ÁªÉÈõÜ„ÄÅ‰∫§ÂèâÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜ„ÄÇÊàë‰ª¨‰πü‰ªãÁªç‰∫ÜÂ≠¶‰π†ÁÆóÊ≥ïÁöÑË∞ÉËØïÔºå‰ª•ÂèäÂ¶Ç‰ΩïÁ°Æ‰øùÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÊ≠£Â∏∏ËøêË°åÔºå‰∫éÊòØÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏Ä‰∫õËØäÊñ≠Ê≥ïÔºåÊØîÂ¶ÇÂ≠¶‰π†Êõ≤Á∫øÔºåÂêåÊó∂‰πüËÆ®ËÆ∫‰∫ÜËØØÂ∑ÆÂàÜÊûê„ÄÅ‰∏äÈôêÂàÜÊûêÁ≠âÁ≠âÂÜÖÂÆπ„ÄÇ ÊâÄÊúâËøô‰∫õÂ∑•ÂÖ∑ÈÉΩËÉΩÊúâÊïàÂú∞ÊåáÂºï‰Ω†ÂÜ≥ÂÆöÊé•‰∏ãÊù•Â∫îËØ•ÊÄéÊ†∑ÂÅöÔºåËÆ©‰Ω†ÊääÂÆùË¥µÁöÑÊó∂Èó¥Áî®Âú®ÂàÄÂàÉ‰∏ä„ÄÇÁé∞Âú®‰Ω†Â∑≤ÁªèÊéåÊè°‰∫ÜÂæàÂ§öÊú∫Âô®Â≠¶‰π†ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÂíåÊó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÁ≠âÁ≠â„ÄÇ ‰ΩÜÈô§‰∫ÜËøô‰∫õ‰ª•Â§ñÔºåÊàëÊõ¥Â∏åÊúõ‰Ω†Áé∞Âú®‰∏ç‰ªÖ‰ªÖÂè™ÊòØËÆ§ËØÜËøô‰∫õÂ∑•ÂÖ∑ÔºåÊõ¥ÈáçË¶ÅÁöÑÊòØÊéåÊè°ÊÄéÊ†∑ÊúâÊïàÂú∞Âà©Áî®Ëøô‰∫õÂ∑•ÂÖ∑Êù•Âª∫Á´ãÂº∫Â§ßÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªü„ÄÇÊâÄ‰ª•Ôºå‰ª•‰∏äÂ∞±ÊòØËøôÈó®ËØæÁöÑÂÖ®ÈÉ®ÂÜÖÂÆπ„ÄÇÂ¶ÇÊûú‰Ω†Ë∑üÁùÄÊàë‰ª¨ÁöÑËØæÁ®ã‰∏ÄË∑ØËµ∞Êù•ÔºåÂà∞Áé∞Âú®Ôºå‰Ω†Â∫îËØ•Â∑≤ÁªèÊÑüËßâÂà∞Ëá™Â∑±Â∑≤ÁªèÊàê‰∏∫Êú∫Âô®Â≠¶‰π†ÊñπÈù¢ÁöÑ‰∏ìÂÆ∂‰∫ÜÂêßÔºü Êàë‰ª¨ÈÉΩÁü•ÈÅìÔºåÊú∫Âô®Â≠¶‰π†ÊòØ‰∏ÄÈó®ÂØπÁßëÊäÄ„ÄÅÂ∑•‰∏ö‰∫ßÁîüÊ∑±ËøúÂΩ±ÂìçÁöÑÈáçË¶ÅÂ≠¶ÁßëÔºåËÄåÁé∞Âú®Ôºå‰Ω†Â∑≤ÁªèÂÆåÂÖ®ÂÖ∑Â§á‰∫ÜÂ∫îÁî®Ëøô‰∫õÊú∫Âô®Â≠¶‰π†Â∑•ÂÖ∑Êù•ÂàõÈÄ†‰ºüÂ§ßÊàêÂ∞±ÁöÑËÉΩÂäõ„ÄÇÊàëÂ∏åÊúõ‰Ω†‰ª¨‰∏≠ÁöÑÂæàÂ§ö‰∫∫ÈÉΩËÉΩÂú®Áõ∏Â∫îÁöÑÈ¢ÜÂüüÔºåÂ∫îÁî®ÊâÄÂ≠¶ÁöÑÊú∫Âô®Â≠¶‰π†Â∑•ÂÖ∑ÔºåÊûÑÂª∫Âá∫ÂÆåÁæéÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÔºåÂºÄÂèëÂá∫Êó†‰∏é‰º¶ÊØîÁöÑ‰∫ßÂìÅÂíåÂ∫îÁî®„ÄÇÂπ∂‰∏îÊàë‰πüÂ∏åÊúõ‰Ω†‰ª¨ÈÄöËøáÂ∫îÁî®Êú∫Âô®Â≠¶‰π†Ôºå‰∏ç‰ªÖ‰ªÖÊîπÂèòËá™Â∑±ÁöÑÁîüÊ¥ªÔºåÊúâÊúù‰∏ÄÊó•ÔºåËøòË¶ÅËÆ©Êõ¥Â§öÁöÑ‰∫∫ÁîüÊ¥ªÂæóÊõ¥Âä†ÁæéÂ•ΩÔºÅ Êàë‰πüÊÉ≥ÂëäËØâÂ§ßÂÆ∂ÔºåÊïôËøôÈó®ËØæÂØπÊàëÊù•ËÆ≤ÊòØ‰∏ÄÁßç‰∫´Âèó„ÄÇÊâÄ‰ª•ÔºåË∞¢Ë∞¢Â§ßÂÆ∂ÔºÅ ÊúÄÂêéÔºåÂú®ÁªìÊùü‰πãÂâçÔºåÊàëËøòÊÉ≥ÂÜçÂ§öËØ¥‰∏ÄÁÇπÔºöÈÇ£Â∞±ÊòØÔºå‰πüËÆ∏‰∏ç‰πÖ‰ª•ÂâçÊàë‰πüÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåÂç≥‰ΩøÊòØÁé∞Âú®ÔºåÊàë‰πüÂ∞ΩÂèØËÉΩÊå§Âá∫Êó∂Èó¥Âê¨‰∏Ä‰∫õËØæÔºåÂ≠¶‰∏Ä‰∫õÊñ∞ÁöÑ‰∏úË•ø„ÄÇÊâÄ‰ª•ÔºåÊàëÊ∑±Áü•Ë¶ÅÂùöÊåÅÂ≠¶ÂÆåËøôÈó®ËØæÊòØÂæàÈúÄË¶ÅËä±‰∏Ä‰∫õÊó∂Èó¥ÁöÑÔºåÊàëÁü•ÈÅìÔºå‰πüËÆ∏‰Ω†ÊòØ‰∏Ä‰∏™ÂæàÂøôÁöÑ‰∫∫ÔºåÁîüÊ¥ª‰∏≠ÊúâÂæàÂ§öÂæàÂ§ö‰∫ãÊÉÖË¶ÅÂ§ÑÁêÜ„ÄÇÊ≠£Âõ†Â¶ÇÊ≠§Ôºå‰Ω†‰æùÁÑ∂Êå§Âá∫Êó∂Èó¥Êù•ËßÇÁúãËøô‰∫õËØæÁ®ãËßÜÈ¢ë„ÄÇÊàëÁü•ÈÅìÔºåÂæàÂ§öËßÜÈ¢ëÁöÑÊó∂Èó¥ÈÉΩÈïøËææÊï∞Â∞èÊó∂Ôºå‰Ω†‰æùÁÑ∂Ëä±‰∫ÜÂ•ΩÂ§öÊó∂Èó¥Êù•ÂÅöËøô‰∫õÂ§ç‰π†È¢ò„ÄÇ‰Ω†‰ª¨‰∏≠Â•ΩÂ§ö‰∫∫ÔºåËøòÊÑøÊÑèËä±Êó∂Èó¥Êù•Á†îÁ©∂ÈÇ£‰∫õÁºñÁ®ãÁªÉ‰π†ÔºåÈÇ£‰∫õÂèàÈïøÂèàÂ§çÊùÇÁöÑÁºñÁ®ãÁªÉ‰π†„ÄÇÊàëÂØπ‰Ω†‰ª¨Ë°®Á§∫Ë°∑ÂøÉÁöÑÊÑüË∞¢ÔºÅÊàëÁü•ÈÅì‰Ω†‰ª¨ÂæàÂ§ö‰∫∫Âú®ËøôÈó®ËØæ‰∏≠ÈÉΩÈùûÂ∏∏Âä™ÂäõÔºåÂæàÂ§ö‰∫∫ÈÉΩÂú®ËøôÈó®ËØæ‰∏äËä±‰∫ÜÂæàÂ§öÊó∂Èó¥ÔºåÂæàÂ§ö‰∫∫ÈÉΩ‰∏∫ËøôÈó®ËØæË¥°ÁåÆ‰∫ÜËá™Â∑±ÁöÑÂæàÂ§öÁ≤æÂäõ„ÄÇÊâÄ‰ª•ÔºåÊàëË°∑ÂøÉÂú∞Â∏åÊúõ‰Ω†‰ª¨ËÉΩ‰ªéËøôÈó®ËØæ‰∏≠ÊúâÊâÄÊî∂Ëé∑ÔºÅ ÊúÄÂêéÊàëÊÉ≥ËØ¥ÔºÅÂÜçÊ¨°ÊÑüË∞¢‰Ω†‰ª¨ÈÄâ‰øÆËøôÈó®ËØæÁ®ãÔºÅ Andew Ng]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÔºàÂçÅ‰∏ÄÔºâ]]></title>
    <url>%2F2018%2F08%2F12%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÂçÅ‰∫î„ÄÅÂºÇÂ∏∏Ê£ÄÊµã(Anomaly Detection) 15.1 ÈóÆÈ¢òÁöÑÂä®Êú∫ÂèÇËÄÉÊñáÊ°£: 15 - 1 - Problem Motivation (8 min).mkv Âú®Êé•‰∏ãÊù•ÁöÑ‰∏ÄÁ≥ªÂàóËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜÂêëÂ§ßÂÆ∂‰ªãÁªçÂºÇÂ∏∏Ê£ÄÊµã(Anomaly detection)ÈóÆÈ¢ò„ÄÇËøôÊòØÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑ‰∏Ä‰∏™Â∏∏ËßÅÂ∫îÁî®„ÄÇËøôÁßçÁÆóÊ≥ïÁöÑ‰∏Ä‰∏™ÊúâË∂£‰πãÂ§ÑÂú®‰∫éÔºöÂÆÉËôΩÁÑ∂‰∏ªË¶ÅÁî®‰∫éÈùûÁõëÁù£Â≠¶‰π†ÈóÆÈ¢òÔºå‰ΩÜ‰ªéÊüê‰∫õËßíÂ∫¶ÁúãÔºåÂÆÉÂèàÁ±ª‰ºº‰∫é‰∏Ä‰∫õÁõëÁù£Â≠¶‰π†ÈóÆÈ¢ò„ÄÇ ‰ªÄ‰πàÊòØÂºÇÂ∏∏Ê£ÄÊµãÂë¢Ôºü‰∏∫‰∫ÜËß£ÈáäËøô‰∏™Ê¶ÇÂøµÔºåËÆ©Êàë‰∏æ‰∏Ä‰∏™‰æãÂ≠êÂêßÔºö ÂÅáÊÉ≥‰Ω†ÊòØ‰∏Ä‰∏™È£ûÊú∫ÂºïÊìéÂà∂ÈÄ†ÂïÜÔºåÂΩì‰Ω†Áîü‰∫ßÁöÑÈ£ûÊú∫ÂºïÊìé‰ªéÁîü‰∫ßÁ∫ø‰∏äÊµÅÂá∫Êó∂Ôºå‰Ω†ÈúÄË¶ÅËøõË°åQA(Ë¥®ÈáèÊéßÂà∂ÊµãËØï)ÔºåËÄå‰Ωú‰∏∫Ëøô‰∏™ÊµãËØïÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÊµãÈáè‰∫ÜÈ£ûÊú∫ÂºïÊìéÁöÑ‰∏Ä‰∫õÁâπÂæÅÂèòÈáèÔºåÊØîÂ¶ÇÂºïÊìéËøêËΩ¨Êó∂‰∫ßÁîüÁöÑÁÉ≠ÈáèÔºåÊàñËÄÖÂºïÊìéÁöÑÊåØÂä®Á≠âÁ≠â„ÄÇ ËøôÊ†∑‰∏ÄÊù•Ôºå‰Ω†Â∞±Êúâ‰∫Ü‰∏Ä‰∏™Êï∞ÊçÆÈõÜÔºå‰ªé$x^{(1)}$Âà∞$x^{(m)}$ÔºåÂ¶ÇÊûú‰Ω†Áîü‰∫ß‰∫Ü$m$‰∏™ÂºïÊìéÁöÑËØùÔºå‰Ω†Â∞ÜËøô‰∫õÊï∞ÊçÆÁªòÂà∂ÊàêÂõæË°®ÔºåÁúãËµ∑Êù•Â∞±ÊòØËøô‰∏™Ê†∑Â≠êÔºö ËøôÈáåÁöÑÊØè‰∏™ÁÇπ„ÄÅÊØè‰∏™ÂèâÔºåÈÉΩÊòØ‰Ω†ÁöÑÊó†Ê†áÁ≠æÊï∞ÊçÆ„ÄÇËøôÊ†∑ÔºåÂºÇÂ∏∏Ê£ÄÊµãÈóÆÈ¢òÂèØ‰ª•ÂÆö‰πâÂ¶Ç‰∏ãÔºöÊàë‰ª¨ÂÅáËÆæÂêéÊù•Êúâ‰∏ÄÂ§©Ôºå‰Ω†Êúâ‰∏Ä‰∏™Êñ∞ÁöÑÈ£ûÊú∫ÂºïÊìé‰ªéÁîü‰∫ßÁ∫ø‰∏äÊµÅÂá∫ÔºåËÄå‰Ω†ÁöÑÊñ∞È£ûÊú∫ÂºïÊìéÊúâÁâπÂæÅÂèòÈáè$x_{test}$„ÄÇÊâÄË∞ìÁöÑÂºÇÂ∏∏Ê£ÄÊµãÈóÆÈ¢òÂ∞±ÊòØÔºöÊàë‰ª¨Â∏åÊúõÁü•ÈÅìËøô‰∏™Êñ∞ÁöÑÈ£ûÊú∫ÂºïÊìéÊòØÂê¶ÊúâÊüêÁßçÂºÇÂ∏∏ÔºåÊàñËÄÖËØ¥ÔºåÊàë‰ª¨Â∏åÊúõÂà§Êñ≠Ëøô‰∏™ÂºïÊìéÊòØÂê¶ÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÊµãËØï„ÄÇÂõ†‰∏∫ÔºåÂ¶ÇÊûúÂÆÉÁúãËµ∑Êù•ÂÉè‰∏Ä‰∏™Ê≠£Â∏∏ÁöÑÂºïÊìéÔºåÈÇ£‰πàÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•Â∞ÜÂÆÉËøêÈÄÅÂà∞ÂÆ¢Êà∑ÈÇ£ÈáåÔºåËÄå‰∏çÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÁöÑÊµãËØï„ÄÇ ÁªôÂÆöÊï∞ÊçÆÈõÜ $x^{(1)},x^{(2)},..,x^{(m)}$ÔºåÊàë‰ª¨ÂÅá‰ΩøÊï∞ÊçÆÈõÜÊòØÊ≠£Â∏∏ÁöÑÔºåÊàë‰ª¨Â∏åÊúõÁü•ÈÅìÊñ∞ÁöÑÊï∞ÊçÆ $x_{test}$ ÊòØ‰∏çÊòØÂºÇÂ∏∏ÁöÑÔºåÂç≥Ëøô‰∏™ÊµãËØïÊï∞ÊçÆ‰∏çÂ±û‰∫éËØ•ÁªÑÊï∞ÊçÆÁöÑÂá†ÁéáÂ¶Ç‰Ωï„ÄÇÊàë‰ª¨ÊâÄÊûÑÂª∫ÁöÑÊ®°ÂûãÂ∫îËØ•ËÉΩÊ†πÊçÆËØ•ÊµãËØïÊï∞ÊçÆÁöÑ‰ΩçÁΩÆÂëäËØâÊàë‰ª¨ÂÖ∂Â±û‰∫é‰∏ÄÁªÑÊï∞ÊçÆÁöÑÂèØËÉΩÊÄß $p(x)$„ÄÇ ‰∏äÂõæ‰∏≠ÔºåÂú®ËìùËâ≤ÂúàÂÜÖÁöÑÊï∞ÊçÆÂ±û‰∫éËØ•ÁªÑÊï∞ÊçÆÁöÑÂèØËÉΩÊÄßËæÉÈ´òÔºåËÄåË∂äÊòØÂÅèËøúÁöÑÊï∞ÊçÆÔºåÂÖ∂Â±û‰∫éËØ•ÁªÑÊï∞ÊçÆÁöÑÂèØËÉΩÊÄßÂ∞±Ë∂ä‰Ωé„ÄÇ ËøôÁßçÊñπÊ≥ïÁß∞‰∏∫ÂØÜÂ∫¶‰º∞ËÆ°ÔºåË°®ËææÂ¶Ç‰∏ãÔºö $$ if \quad p(x) \begin{cases} < \varepsilon & anomaly \\ > =\varepsilon & normal \end{cases} $$ Ê¨∫ËØàÊ£ÄÊµãÔºö $x^{(i)} = {Áî®Êà∑ÁöÑÁ¨¨i‰∏™Ê¥ªÂä®ÁâπÂæÅ}$ Ê®°Âûã$p(x)$ ‰∏∫Êàë‰ª¨ÂÖ∂Â±û‰∫é‰∏ÄÁªÑÊï∞ÊçÆÁöÑÂèØËÉΩÊÄßÔºåÈÄöËøá$p(x) &lt; \varepsilon$Ê£ÄÊµãÈùûÊ≠£Â∏∏Áî®Êà∑„ÄÇ ÂºÇÂ∏∏Ê£ÄÊµã‰∏ªË¶ÅÁî®Êù•ËØÜÂà´Ê¨∫È™ó„ÄÇ‰æãÂ¶ÇÂú®Á∫øÈááÈõÜËÄåÊù•ÁöÑÊúâÂÖ≥Áî®Êà∑ÁöÑÊï∞ÊçÆÔºå‰∏Ä‰∏™ÁâπÂæÅÂêëÈáè‰∏≠ÂèØËÉΩ‰ºöÂåÖÂê´Â¶ÇÔºöÁî®Êà∑Â§ö‰πÖÁôªÂΩï‰∏ÄÊ¨°ÔºåËÆøÈóÆËøáÁöÑÈ°µÈù¢ÔºåÂú®ËÆ∫ÂùõÂèëÂ∏ÉÁöÑÂ∏ñÂ≠êÊï∞ÈáèÔºåÁîöËá≥ÊòØÊâìÂ≠óÈÄüÂ∫¶Á≠â„ÄÇÂ∞ùËØïÊ†πÊçÆËøô‰∫õÁâπÂæÅÊûÑÂª∫‰∏Ä‰∏™Ê®°ÂûãÔºåÂèØ‰ª•Áî®Ëøô‰∏™Ê®°ÂûãÊù•ËØÜÂà´ÈÇ£‰∫õ‰∏çÁ¨¶ÂêàËØ•Ê®°ÂºèÁöÑÁî®Êà∑„ÄÇ ÂÜç‰∏Ä‰∏™‰æãÂ≠êÊòØÊ£ÄÊµã‰∏Ä‰∏™Êï∞ÊçÆ‰∏≠ÂøÉÔºåÁâπÂæÅÂèØËÉΩÂåÖÂê´ÔºöÂÜÖÂ≠ò‰ΩøÁî®ÊÉÖÂÜµÔºåË¢´ËÆøÈóÆÁöÑÁ£ÅÁõòÊï∞ÈáèÔºåCPUÁöÑË¥üËΩΩÔºåÁΩëÁªúÁöÑÈÄö‰ø°ÈáèÁ≠â„ÄÇÊ†πÊçÆËøô‰∫õÁâπÂæÅÂèØ‰ª•ÊûÑÂª∫‰∏Ä‰∏™Ê®°ÂûãÔºåÁî®Êù•Âà§Êñ≠Êüê‰∫õËÆ°ÁÆóÊú∫ÊòØ‰∏çÊòØÊúâÂèØËÉΩÂá∫Èîô‰∫Ü„ÄÇ 15.2 È´òÊñØÂàÜÂ∏ÉÂèÇËÄÉËßÜÈ¢ë: 15 - 2 - Gaussian Distribution (10 min).mkv Âú®Ëøô‰∏™ËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞Ü‰ªãÁªçÈ´òÊñØÂàÜÂ∏ÉÔºå‰πüÁß∞‰∏∫Ê≠£ÊÄÅÂàÜÂ∏É„ÄÇÂõûÈ°æÈ´òÊñØÂàÜÂ∏ÉÁöÑÂü∫Êú¨Áü•ËØÜ„ÄÇ ÈÄöÂ∏∏Â¶ÇÊûúÊàë‰ª¨ËÆ§‰∏∫ÂèòÈáè $x$ Á¨¶ÂêàÈ´òÊñØÂàÜÂ∏É $x \sim N(\mu, \sigma^2)$ÂàôÂÖ∂Ê¶ÇÁéáÂØÜÂ∫¶ÂáΩÊï∞‰∏∫Ôºö$p(x,\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$Êàë‰ª¨ÂèØ‰ª•Âà©Áî®Â∑≤ÊúâÁöÑÊï∞ÊçÆÊù•È¢ÑÊµãÊÄª‰Ωì‰∏≠ÁöÑ$Œº$Âíå$œÉ^2$ÁöÑËÆ°ÁÆóÊñπÊ≥ïÂ¶Ç‰∏ãÔºö$\mu=\frac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}$ $\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2$ È´òÊñØÂàÜÂ∏ÉÊ†∑‰æãÔºö Ê≥®ÔºöÊú∫Âô®Â≠¶‰π†‰∏≠ÂØπ‰∫éÊñπÂ∑ÆÊàë‰ª¨ÈÄöÂ∏∏Âè™Èô§‰ª•$m$ËÄåÈùûÁªüËÆ°Â≠¶‰∏≠ÁöÑ$(m-1)$„ÄÇËøôÈáåÈ°∫‰æøÊèê‰∏Ä‰∏ãÔºåÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠ÔºåÂà∞Â∫ïÊòØÈÄâÊã©‰ΩøÁî®$1/m$ËøòÊòØ$1/(m-1)$ÂÖ∂ÂÆûÂå∫Âà´ÂæàÂ∞èÔºåÂè™Ë¶Å‰Ω†Êúâ‰∏Ä‰∏™ËøòÁÆóÂ§ßÁöÑËÆ≠ÁªÉÈõÜÔºåÂú®Êú∫Âô®Â≠¶‰π†È¢ÜÂüüÂ§ßÈÉ®ÂàÜ‰∫∫Êõ¥‰π†ÊÉØ‰ΩøÁî®$1/m$Ëøô‰∏™ÁâàÊú¨ÁöÑÂÖ¨Âºè„ÄÇËøô‰∏§‰∏™ÁâàÊú¨ÁöÑÂÖ¨ÂºèÂú®ÁêÜËÆ∫ÁâπÊÄßÂíåÊï∞Â≠¶ÁâπÊÄß‰∏äÁ®çÊúâ‰∏çÂêåÔºå‰ΩÜÊòØÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠Ôºå‰ªñ‰ª¨ÁöÑÂå∫Âà´ÁîöÂ∞èÔºåÂá†‰πéÂèØ‰ª•ÂøΩÁï•‰∏çËÆ°„ÄÇ 15.3 ÁÆóÊ≥ïÂèÇËÄÉËßÜÈ¢ë: 15 - 3 - Algorithm (12 min).mkv Âú®Êú¨ËäÇËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜÂ∫îÁî®È´òÊñØÂàÜÂ∏ÉÂºÄÂèëÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇ ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÔºö ÂØπ‰∫éÁªôÂÆöÁöÑÊï∞ÊçÆÈõÜ $x^{(1)},x^{(2)},‚Ä¶,x^{(m)}$ÔºåÊàë‰ª¨Ë¶ÅÈíàÂØπÊØè‰∏Ä‰∏™ÁâπÂæÅËÆ°ÁÆó $\mu$ Âíå $\sigma^2$ ÁöÑ‰º∞ËÆ°ÂÄº„ÄÇ $\mu_j=\frac{1}{m}\sum\limits_{i=1}^{m}x_j^{(i)}$ $\sigma_j^2=\frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2$ ‰∏ÄÊó¶Êàë‰ª¨Ëé∑Âæó‰∫ÜÂπ≥ÂùáÂÄºÂíåÊñπÂ∑ÆÁöÑ‰º∞ËÆ°ÂÄºÔºåÁªôÂÆöÊñ∞ÁöÑ‰∏Ä‰∏™ËÆ≠ÁªÉÂÆû‰æãÔºåÊ†πÊçÆÊ®°ÂûãËÆ°ÁÆó $p(x)$Ôºö $p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod\limits_{j=1}^1\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$ ÂΩì$p(x) &lt; \varepsilon$Êó∂Ôºå‰∏∫ÂºÇÂ∏∏„ÄÇ ‰∏ãÂõæÊòØ‰∏Ä‰∏™Áî±‰∏§‰∏™ÁâπÂæÅÁöÑËÆ≠ÁªÉÈõÜÔºå‰ª•ÂèäÁâπÂæÅÁöÑÂàÜÂ∏ÉÊÉÖÂÜµÔºö ‰∏ãÈù¢ÁöÑ‰∏âÁª¥ÂõæË°®Ë°®Á§∫ÁöÑÊòØÂØÜÂ∫¶‰º∞ËÆ°ÂáΩÊï∞Ôºå$z$ËΩ¥‰∏∫Ê†πÊçÆ‰∏§‰∏™ÁâπÂæÅÁöÑÂÄºÊâÄ‰º∞ËÆ°$p(x)$ÂÄºÔºö Êàë‰ª¨ÈÄâÊã©‰∏Ä‰∏™$\varepsilon$ÔºåÂ∞Ü$p(x) = \varepsilon$‰Ωú‰∏∫Êàë‰ª¨ÁöÑÂà§ÂÆöËæπÁïåÔºåÂΩì$p(x) &gt; \varepsilon$Êó∂È¢ÑÊµãÊï∞ÊçÆ‰∏∫Ê≠£Â∏∏Êï∞ÊçÆÔºåÂê¶Âàô‰∏∫ÂºÇÂ∏∏„ÄÇ Âú®ËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÊãüÂêà$p(x)$Ôºå‰πüÂ∞±ÊòØ $x$ÁöÑÊ¶ÇÁéáÂÄºÔºå‰ª•ÂºÄÂèëÂá∫‰∏ÄÁßçÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇÂêåÊó∂ÔºåÂú®ËøôËäÇËØæ‰∏≠ÔºåÊàë‰ª¨‰πüÁªôÂá∫‰∫ÜÈÄöËøáÁªôÂá∫ÁöÑÊï∞ÊçÆÈõÜÊãüÂêàÂèÇÊï∞ÔºåËøõË°åÂèÇÊï∞‰º∞ËÆ°ÔºåÂæóÂà∞ÂèÇÊï∞ $\mu$ Âíå $\sigma$ÔºåÁÑ∂ÂêéÊ£ÄÊµãÊñ∞ÁöÑÊ†∑Êú¨ÔºåÁ°ÆÂÆöÊñ∞Ê†∑Êú¨ÊòØÂê¶ÊòØÂºÇÂ∏∏„ÄÇ Âú®Êé•‰∏ãÊù•ÁöÑËØæÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊ∑±ÂÖ•Á†îÁ©∂Ëøô‰∏ÄÁÆóÊ≥ïÔºåÂêåÊó∂Êõ¥Ê∑±ÂÖ•Âú∞‰ªãÁªçÔºåÊÄéÊ†∑ËÆ©ÁÆóÊ≥ïÂ∑•‰ΩúÂú∞Êõ¥Âä†ÊúâÊïà„ÄÇ 15.4 ÂºÄÂèëÂíåËØÑ‰ª∑‰∏Ä‰∏™ÂºÇÂ∏∏Ê£ÄÊµãÁ≥ªÁªüÂèÇËÄÉËßÜÈ¢ë: 15 - 4 - Developing and Evaluating an Anomaly Detection System (13 min). mkv ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÊòØ‰∏Ä‰∏™ÈùûÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåÊÑèÂë≥ÁùÄÊàë‰ª¨Êó†Ê≥ïÊ†πÊçÆÁªìÊûúÂèòÈáè $ y$ ÁöÑÂÄºÊù•ÂëäËØâÊàë‰ª¨Êï∞ÊçÆÊòØÂê¶ÁúüÁöÑÊòØÂºÇÂ∏∏ÁöÑ„ÄÇÊàë‰ª¨ÈúÄË¶ÅÂè¶‰∏ÄÁßçÊñπÊ≥ïÊù•Â∏ÆÂä©Ê£ÄÈ™åÁÆóÊ≥ïÊòØÂê¶ÊúâÊïà„ÄÇÂΩìÊàë‰ª¨ÂºÄÂèë‰∏Ä‰∏™ÂºÇÂ∏∏Ê£ÄÊµãÁ≥ªÁªüÊó∂ÔºåÊàë‰ª¨‰ªéÂ∏¶Ê†áËÆ∞ÔºàÂºÇÂ∏∏ÊàñÊ≠£Â∏∏ÔºâÁöÑÊï∞ÊçÆÁùÄÊâãÔºåÊàë‰ª¨‰ªéÂÖ∂‰∏≠ÈÄâÊã©‰∏ÄÈÉ®ÂàÜÊ≠£Â∏∏Êï∞ÊçÆÁî®‰∫éÊûÑÂª∫ËÆ≠ÁªÉÈõÜÔºåÁÑ∂ÂêéÁî®Ââ©‰∏ãÁöÑÊ≠£Â∏∏Êï∞ÊçÆÂíåÂºÇÂ∏∏Êï∞ÊçÆÊ∑∑ÂêàÁöÑÊï∞ÊçÆÊûÑÊàê‰∫§ÂèâÊ£ÄÈ™åÈõÜÂíåÊµãËØïÈõÜ„ÄÇ ‰æãÂ¶ÇÔºöÊàë‰ª¨Êúâ10000Âè∞Ê≠£Â∏∏ÂºïÊìéÁöÑÊï∞ÊçÆÔºåÊúâ20Âè∞ÂºÇÂ∏∏ÂºïÊìéÁöÑÊï∞ÊçÆ„ÄÇ Êàë‰ª¨ËøôÊ†∑ÂàÜÈÖçÊï∞ÊçÆÔºö 6000Âè∞Ê≠£Â∏∏ÂºïÊìéÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜ 2000Âè∞Ê≠£Â∏∏ÂºïÊìéÂíå10Âè∞ÂºÇÂ∏∏ÂºïÊìéÁöÑÊï∞ÊçÆ‰Ωú‰∏∫‰∫§ÂèâÊ£ÄÈ™åÈõÜ 2000Âè∞Ê≠£Â∏∏ÂºïÊìéÂíå10Âè∞ÂºÇÂ∏∏ÂºïÊìéÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ÊµãËØïÈõÜ ÂÖ∑‰ΩìÁöÑËØÑ‰ª∑ÊñπÊ≥ïÂ¶Ç‰∏ãÔºö Ê†πÊçÆÊµãËØïÈõÜÊï∞ÊçÆÔºåÊàë‰ª¨‰º∞ËÆ°ÁâπÂæÅÁöÑÂπ≥ÂùáÂÄºÂíåÊñπÂ∑ÆÂπ∂ÊûÑÂª∫$p(x)$ÂáΩÊï∞ ÂØπ‰∫§ÂèâÊ£ÄÈ™åÈõÜÔºåÊàë‰ª¨Â∞ùËØï‰ΩøÁî®‰∏çÂêåÁöÑ$\varepsilon$ÂÄº‰Ωú‰∏∫ÈòÄÂÄºÔºåÂπ∂È¢ÑÊµãÊï∞ÊçÆÊòØÂê¶ÂºÇÂ∏∏ÔºåÊ†πÊçÆF1ÂÄºÊàñËÄÖÊü•ÂáÜÁéá‰∏éÊü•ÂÖ®ÁéáÁöÑÊØî‰æãÊù•ÈÄâÊã© $\varepsilon$ ÈÄâÂá∫ $\varepsilon$ ÂêéÔºåÈíàÂØπÊµãËØïÈõÜËøõË°åÈ¢ÑÊµãÔºåËÆ°ÁÆóÂºÇÂ∏∏Ê£ÄÈ™åÁ≥ªÁªüÁöÑ$F1$ÂÄºÔºåÊàñËÄÖÊü•ÂáÜÁéá‰∏éÊü•ÂÖ®Áéá‰πãÊØî 15.5 ÂºÇÂ∏∏Ê£ÄÊµã‰∏éÁõëÁù£Â≠¶‰π†ÂØπÊØîÂèÇËÄÉËßÜÈ¢ë: 15 - 5 - Anomaly Detection vs. Supervised Learning (8 min).mkv ‰πãÂâçÊàë‰ª¨ÊûÑÂª∫ÁöÑÂºÇÂ∏∏Ê£ÄÊµãÁ≥ªÁªü‰πü‰ΩøÁî®‰∫ÜÂ∏¶Ê†áËÆ∞ÁöÑÊï∞ÊçÆÔºå‰∏éÁõëÁù£Â≠¶‰π†Êúâ‰∫õÁõ∏‰ººÔºå‰∏ãÈù¢ÁöÑÂØπÊØîÊúâÂä©‰∫éÈÄâÊã©ÈááÁî®ÁõëÁù£Â≠¶‰π†ËøòÊòØÂºÇÂ∏∏Ê£ÄÊµãÔºö ‰∏§ËÄÖÊØîËæÉÔºö ÂºÇÂ∏∏Ê£ÄÊµã ÁõëÁù£Â≠¶‰π† ÈùûÂ∏∏Â∞ëÈáèÁöÑÊ≠£ÂêëÁ±ªÔºàÂºÇÂ∏∏Êï∞ÊçÆ $y=1$Ôºâ, Â§ßÈáèÁöÑË¥üÂêëÁ±ªÔºà$y=0$Ôºâ ÂêåÊó∂ÊúâÂ§ßÈáèÁöÑÊ≠£ÂêëÁ±ªÂíåË¥üÂêëÁ±ª ËÆ∏Â§ö‰∏çÂêåÁßçÁ±ªÁöÑÂºÇÂ∏∏ÔºåÈùûÂ∏∏Èöæ„ÄÇÊ†πÊçÆÈùûÂ∏∏ Â∞ëÈáèÁöÑÊ≠£ÂêëÁ±ªÊï∞ÊçÆÊù•ËÆ≠ÁªÉÁÆóÊ≥ï„ÄÇ ÊúâË∂≥Â§üÂ§öÁöÑÊ≠£ÂêëÁ±ªÂÆû‰æãÔºåË∂≥Â§üÁî®‰∫éËÆ≠ÁªÉ ÁÆóÊ≥ïÔºåÊú™Êù•ÈÅáÂà∞ÁöÑÊ≠£ÂêëÁ±ªÂÆû‰æãÂèØËÉΩ‰∏éËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑÈùûÂ∏∏Ëøë‰ºº„ÄÇ Êú™Êù•ÈÅáÂà∞ÁöÑÂºÇÂ∏∏ÂèØËÉΩ‰∏éÂ∑≤ÊéåÊè°ÁöÑÂºÇÂ∏∏„ÄÅÈùûÂ∏∏ÁöÑ‰∏çÂêå„ÄÇ ‰æãÂ¶ÇÔºö Ê¨∫ËØàË°å‰∏∫Ê£ÄÊµã Áîü‰∫ßÔºà‰æãÂ¶ÇÈ£ûÊú∫ÂºïÊìéÔºâÊ£ÄÊµãÊï∞ÊçÆ‰∏≠ÂøÉÁöÑËÆ°ÁÆóÊú∫ËøêË°åÁä∂ÂÜµ ‰æãÂ¶ÇÔºöÈÇÆ‰ª∂ËøáÊª§Âô® Â§©Ê∞îÈ¢ÑÊä• ËÇøÁò§ÂàÜÁ±ª Â∏åÊúõËøôËäÇËØæËÉΩËÆ©‰Ω†ÊòéÁôΩ‰∏Ä‰∏™Â≠¶‰π†ÈóÆÈ¢òÁöÑ‰ªÄ‰πàÊ†∑ÁöÑÁâπÂæÅÔºåËÉΩËÆ©‰Ω†ÊääËøô‰∏™ÈóÆÈ¢òÂΩìÂÅöÊòØ‰∏Ä‰∏™ÂºÇÂ∏∏Ê£ÄÊµãÔºåÊàñËÄÖÊòØ‰∏Ä‰∏™ÁõëÁù£Â≠¶‰π†ÁöÑÈóÆÈ¢ò„ÄÇÂè¶Â§ñÔºåÂØπ‰∫éÂæàÂ§öÊäÄÊúØÂÖ¨Âè∏ÂèØËÉΩ‰ºöÈÅáÂà∞ÁöÑ‰∏Ä‰∫õÈóÆÈ¢òÔºåÈÄöÂ∏∏Êù•ËØ¥ÔºåÊ≠£Ê†∑Êú¨ÁöÑÊï∞ÈáèÂæàÂ∞ëÔºåÁîöËá≥ÊúâÊó∂ÂÄôÊòØ0Ôºå‰πüÂ∞±ÊòØËØ¥ÔºåÂá∫Áé∞‰∫ÜÂ§™Â§öÊ≤°ËßÅËøáÁöÑ‰∏çÂêåÁöÑÂºÇÂ∏∏Á±ªÂûãÔºåÈÇ£‰πàÂØπ‰∫éËøô‰∫õÈóÆÈ¢òÔºåÈÄöÂ∏∏Â∫îËØ•‰ΩøÁî®ÁöÑÁÆóÊ≥ïÂ∞±ÊòØÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇ 15.6 ÈÄâÊã©ÁâπÂæÅÂèÇËÄÉËßÜÈ¢ë: 15 - 6 - Choosing What Features to Use (12 min).mkv ÂØπ‰∫éÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÔºåÊàë‰ª¨‰ΩøÁî®ÁöÑÁâπÂæÅÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑÔºå‰∏ãÈù¢Ë∞àË∞àÂ¶Ç‰ΩïÈÄâÊã©ÁâπÂæÅÔºö ÂºÇÂ∏∏Ê£ÄÊµãÂÅáËÆæÁâπÂæÅÁ¨¶ÂêàÈ´òÊñØÂàÜÂ∏ÉÔºåÂ¶ÇÊûúÊï∞ÊçÆÁöÑÂàÜÂ∏É‰∏çÊòØÈ´òÊñØÂàÜÂ∏ÉÔºåÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï‰πüËÉΩÂ§üÂ∑•‰ΩúÔºå‰ΩÜÊòØÊúÄÂ•ΩËøòÊòØÂ∞ÜÊï∞ÊçÆËΩ¨Êç¢ÊàêÈ´òÊñØÂàÜÂ∏ÉÔºå‰æãÂ¶Ç‰ΩøÁî®ÂØπÊï∞ÂáΩÊï∞Ôºö$x= log(x+c)$ÔºåÂÖ∂‰∏≠ $c$ ‰∏∫ÈùûË¥üÂ∏∏Êï∞Ôºõ ÊàñËÄÖ $x=x^c$Ôºå$c$‰∏∫ 0-1 ‰πãÈó¥ÁöÑ‰∏Ä‰∏™ÂàÜÊï∞ÔºåÁ≠âÊñπÊ≥ï„ÄÇ(ÁºñËÄÖÊ≥®ÔºöÂú®python‰∏≠ÔºåÈÄöÂ∏∏Áî®np.log1p()ÂáΩÊï∞Ôºå$log1p$Â∞±ÊòØ $log(x+1)$ÔºåÂèØ‰ª•ÈÅøÂÖçÂá∫Áé∞Ë¥üÊï∞ÁªìÊûúÔºåÂèçÂêëÂáΩÊï∞Â∞±ÊòØnp.expm1()) ËØØÂ∑ÆÂàÜÊûêÔºö ‰∏Ä‰∏™Â∏∏ËßÅÁöÑÈóÆÈ¢òÊòØ‰∏Ä‰∫õÂºÇÂ∏∏ÁöÑÊï∞ÊçÆÂèØËÉΩ‰πü‰ºöÊúâËæÉÈ´òÁöÑ$p(x)$ÂÄºÔºåÂõ†ËÄåË¢´ÁÆóÊ≥ïËÆ§‰∏∫ÊòØÊ≠£Â∏∏ÁöÑ„ÄÇËøôÁßçÊÉÖÂÜµ‰∏ãËØØÂ∑ÆÂàÜÊûêËÉΩÂ§üÂ∏ÆÂä©Êàë‰ª¨ÔºåÊàë‰ª¨ÂèØ‰ª•ÂàÜÊûêÈÇ£‰∫õË¢´ÁÆóÊ≥ïÈîôËØØÈ¢ÑÊµã‰∏∫Ê≠£Â∏∏ÁöÑÊï∞ÊçÆÔºåËßÇÂØüËÉΩÂê¶ÊâæÂá∫‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÂèØËÉΩËÉΩ‰ªéÈóÆÈ¢ò‰∏≠ÂèëÁé∞Êàë‰ª¨ÈúÄË¶ÅÂ¢ûÂä†‰∏Ä‰∫õÊñ∞ÁöÑÁâπÂæÅÔºåÂ¢ûÂä†Ëøô‰∫õÊñ∞ÁâπÂæÅÂêéËé∑ÂæóÁöÑÊñ∞ÁÆóÊ≥ïËÉΩÂ§üÂ∏ÆÂä©Êàë‰ª¨Êõ¥Â•ΩÂú∞ËøõË°åÂºÇÂ∏∏Ê£ÄÊµã„ÄÇ ÂºÇÂ∏∏Ê£ÄÊµãËØØÂ∑ÆÂàÜÊûêÔºö Êàë‰ª¨ÈÄöÂ∏∏ÂèØ‰ª•ÈÄöËøáÂ∞Ü‰∏Ä‰∫õÁõ∏ÂÖ≥ÁöÑÁâπÂæÅËøõË°åÁªÑÂêàÔºåÊù•Ëé∑Âæó‰∏Ä‰∫õÊñ∞ÁöÑÊõ¥Â•ΩÁöÑÁâπÂæÅÔºàÂºÇÂ∏∏Êï∞ÊçÆÁöÑËØ•ÁâπÂæÅÂÄºÂºÇÂ∏∏Âú∞Â§ßÊàñÂ∞èÔºâÔºå‰æãÂ¶ÇÔºåÂú®Ê£ÄÊµãÊï∞ÊçÆ‰∏≠ÂøÉÁöÑËÆ°ÁÆóÊú∫Áä∂ÂÜµÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•Áî®CPUË¥üËΩΩ‰∏éÁΩëÁªúÈÄö‰ø°ÈáèÁöÑÊØî‰æã‰Ωú‰∏∫‰∏Ä‰∏™Êñ∞ÁöÑÁâπÂæÅÔºåÂ¶ÇÊûúËØ•ÂÄºÂºÇÂ∏∏Âú∞Â§ßÔºå‰æøÊúâÂèØËÉΩÊÑèÂë≥ÁùÄËØ•ÊúçÂä°Âô®ÊòØÈô∑ÂÖ•‰∫Ü‰∏Ä‰∫õÈóÆÈ¢ò‰∏≠„ÄÇ Âú®ËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÈÄâÊã©ÁâπÂæÅÔºå‰ª•ÂèäÂØπÁâπÂæÅËøõË°å‰∏Ä‰∫õÂ∞èÂ∞èÁöÑËΩ¨Êç¢ÔºåËÆ©Êï∞ÊçÆÊõ¥ÂÉèÊ≠£ÊÄÅÂàÜÂ∏ÉÔºåÁÑ∂ÂêéÂÜçÊääÊï∞ÊçÆËæìÂÖ•ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇÂêåÊó∂‰πü‰ªãÁªç‰∫ÜÂª∫Á´ãÁâπÂæÅÊó∂ÔºåËøõË°åÁöÑËØØÂ∑ÆÂàÜÊûêÊñπÊ≥ïÔºåÊù•ÊçïÊçâÂêÑÁßçÂºÇÂ∏∏ÁöÑÂèØËÉΩ„ÄÇÂ∏åÊúõ‰Ω†ÈÄöËøáËøô‰∫õÊñπÊ≥ïÔºåËÉΩÂ§ü‰∫ÜËß£Â¶Ç‰ΩïÈÄâÊã©Â•ΩÁöÑÁâπÂæÅÂèòÈáèÔºå‰ªéËÄåÂ∏ÆÂä©‰Ω†ÁöÑÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÔºåÊçïÊçâÂà∞ÂêÑÁßç‰∏çÂêåÁöÑÂºÇÂ∏∏ÊÉÖÂÜµ„ÄÇ 15.7 Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÔºàÈÄâ‰øÆÔºâÂèÇËÄÉËßÜÈ¢ë: 15 - 7 - Multivariate Gaussian Distribution (Optional) (14 min).mkv ÂÅá‰ΩøÊàë‰ª¨Êúâ‰∏§‰∏™Áõ∏ÂÖ≥ÁöÑÁâπÂæÅÔºåËÄå‰∏îËøô‰∏§‰∏™ÁâπÂæÅÁöÑÂÄºÂüüËåÉÂõ¥ÊØîËæÉÂÆΩÔºåËøôÁßçÊÉÖÂÜµ‰∏ãÔºå‰∏ÄËà¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÂèØËÉΩ‰∏çËÉΩÂæàÂ•ΩÂú∞ËØÜÂà´ÂºÇÂ∏∏Êï∞ÊçÆ„ÄÇÂÖ∂ÂéüÂõ†Âú®‰∫éÔºå‰∏ÄËà¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÂ∞ùËØïÁöÑÊòØÂéªÂêåÊó∂Êäì‰Ωè‰∏§‰∏™ÁâπÂæÅÁöÑÂÅèÂ∑ÆÔºåÂõ†Ê≠§ÂàõÈÄ†Âá∫‰∏Ä‰∏™ÊØîËæÉÂ§ßÁöÑÂà§ÂÆöËæπÁïå„ÄÇ ‰∏ãÂõæ‰∏≠ÊòØ‰∏§‰∏™Áõ∏ÂÖ≥ÁâπÂæÅÔºåÊ¥ãÁ∫¢Ëâ≤ÁöÑÁ∫øÔºàÊ†πÊçÆŒµÁöÑ‰∏çÂêåÂÖ∂ËåÉÂõ¥ÂèØÂ§ßÂèØÂ∞èÔºâÊòØ‰∏ÄËà¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãËé∑ÂæóÁöÑÂà§ÂÆöËæπÁïåÔºåÂæàÊòéÊòæÁªøËâ≤ÁöÑXÊâÄ‰ª£Ë°®ÁöÑÊï∞ÊçÆÁÇπÂæàÂèØËÉΩÊòØÂºÇÂ∏∏ÂÄºÔºå‰ΩÜÊòØÂÖ∂$p(x)$ÂÄºÂç¥‰ªçÁÑ∂Âú®Ê≠£Â∏∏ËåÉÂõ¥ÂÜÖ„ÄÇÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÂ∞ÜÂàõÂª∫ÂÉèÂõæ‰∏≠ËìùËâ≤Êõ≤Á∫øÊâÄÁ§∫ÁöÑÂà§ÂÆöËæπÁïå„ÄÇ Âú®‰∏ÄËà¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã‰∏≠ÔºåÊàë‰ª¨ËÆ°ÁÆó $p(x)$ ÁöÑÊñπÊ≥ïÊòØÔºöÈÄöËøáÂàÜÂà´ËÆ°ÁÆóÊØè‰∏™ÁâπÂæÅÂØπÂ∫îÁöÑÂá†ÁéáÁÑ∂ÂêéÂ∞ÜÂÖ∂Á¥Ø‰πòËµ∑Êù•ÔºåÂú®Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊûÑÂª∫ÁâπÂæÅÁöÑÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÁî®ÊâÄÊúâÁöÑÁâπÂæÅ‰∏ÄËµ∑Êù•ËÆ°ÁÆó $p(x)$„ÄÇ Êàë‰ª¨È¶ñÂÖàËÆ°ÁÆóÊâÄÊúâÁâπÂæÅÁöÑÂπ≥ÂùáÂÄºÔºåÁÑ∂ÂêéÂÜçËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©ÈòµÔºö$p(x)=\prod_{j=1}^np(x_j;\mu,\sigma_j^2)=\prod_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$ $\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}$ $\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)$ Ê≥®:ÂÖ∂‰∏≠$\mu $ ÊòØ‰∏Ä‰∏™ÂêëÈáèÔºåÂÖ∂ÊØè‰∏Ä‰∏™ÂçïÂÖÉÈÉΩÊòØÂéüÁâπÂæÅÁü©Èòµ‰∏≠‰∏ÄË°åÊï∞ÊçÆÁöÑÂùáÂÄº„ÄÇÊúÄÂêéÊàë‰ª¨ËÆ°ÁÆóÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÁöÑ$p\left( x \right)$: $p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)$ ÂÖ∂‰∏≠Ôºö $|\Sigma|$ÊòØÂÆöÁü©ÈòµÔºåÂú® Octave ‰∏≠Áî® det(sigma)ËÆ°ÁÆó $\Sigma1$ ÊòØÈÄÜÁü©ÈòµÔºå‰∏ãÈù¢Êàë‰ª¨Êù•ÁúãÁúãÂçèÊñπÂ∑ÆÁü©ÈòµÊòØÂ¶Ç‰ΩïÂΩ±ÂìçÊ®°ÂûãÁöÑÔºö ‰∏äÂõæÊòØ5‰∏™‰∏çÂêåÁöÑÊ®°ÂûãÔºå‰ªéÂ∑¶ÂæÄÂè≥‰æùÊ¨°ÂàÜÊûêÔºö ÊòØ‰∏Ä‰∏™‰∏ÄËà¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã ÈÄöËøáÂçèÊñπÂ∑ÆÁü©ÈòµÔºå‰ª§ÁâπÂæÅ1Êã•ÊúâËæÉÂ∞èÁöÑÂÅèÂ∑ÆÔºåÂêåÊó∂‰øùÊåÅÁâπÂæÅ2ÁöÑÂÅèÂ∑Æ ÈÄöËøáÂçèÊñπÂ∑ÆÁü©ÈòµÔºå‰ª§ÁâπÂæÅ2Êã•ÊúâËæÉÂ§ßÁöÑÂÅèÂ∑ÆÔºåÂêåÊó∂‰øùÊåÅÁâπÂæÅ1ÁöÑÂÅèÂ∑Æ ÈÄöËøáÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÂú®‰∏çÊîπÂèò‰∏§‰∏™ÁâπÂæÅÁöÑÂéüÊúâÂÅèÂ∑ÆÁöÑÂü∫Á°Ä‰∏äÔºåÂ¢ûÂä†‰∏§ËÄÖ‰πãÈó¥ÁöÑÊ≠£Áõ∏ÂÖ≥ÊÄß ÈÄöËøáÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÂú®‰∏çÊîπÂèò‰∏§‰∏™ÁâπÂæÅÁöÑÂéüÊúâÂÅèÂ∑ÆÁöÑÂü∫Á°Ä‰∏äÔºåÂ¢ûÂä†‰∏§ËÄÖ‰πãÈó¥ÁöÑË¥üÁõ∏ÂÖ≥ÊÄß Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã‰∏éÂéüÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÁöÑÂÖ≥Á≥ªÔºö ÂèØ‰ª•ËØÅÊòéÁöÑÊòØÔºåÂéüÊú¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÊòØÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºåÂç≥ÂÉè‰∏äÂõæ‰∏≠ÁöÑÁ¨¨1„ÄÅ2„ÄÅ3Ôºå3‰∏™‰æãÂ≠êÊâÄÁ§∫ÔºåÂ¶ÇÊûúÂçèÊñπÂ∑ÆÁü©ÈòµÂè™Âú®ÂØπËßíÁ∫øÁöÑÂçï‰Ωç‰∏äÊúâÈùûÈõ∂ÁöÑÂÄºÊó∂ÔºåÂç≥‰∏∫ÂéüÊú¨ÁöÑÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã‰∫Ü„ÄÇ ÂéüÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÂíåÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãÁöÑÊØîËæÉÔºö ÂéüÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã ‰∏çËÉΩÊçïÊçâÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß ‰ΩÜÂèØ‰ª•ÈÄöËøáÂ∞ÜÁâπÂæÅËøõË°åÁªÑÂêàÁöÑÊñπÊ≥ïÊù•Ëß£ÂÜ≥ Ëá™Âä®ÊçïÊçâÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß ËÆ°ÁÆó‰ª£‰ª∑‰ΩéÔºåËÉΩÈÄÇÂ∫îÂ§ßËßÑÊ®°ÁöÑÁâπÂæÅ ËÆ°ÁÆó‰ª£‰ª∑ËæÉÈ´ò ËÆ≠ÁªÉÈõÜËæÉÂ∞èÊó∂‰πüÂêåÊ†∑ÈÄÇÁî® ÂøÖÈ°ªË¶ÅÊúâ $m&gt;n$Ôºå‰∏çÁÑ∂ÁöÑËØùÂçèÊñπÂ∑ÆÁü©Èòµ ‰∏çÂèØÈÄÜÁöÑÔºåÈÄöÂ∏∏ÈúÄË¶Å $m&gt;10n$ Âè¶Â§ñÁâπÂæÅÂÜó‰Ωô‰πü‰ºöÂØºËá¥ÂçèÊñπÂ∑ÆÁü©Èòµ‰∏çÂèØÈÄÜ ÂéüÈ´òÊñØÂàÜÂ∏ÉÊ®°ÂûãË¢´ÂπøÊ≥õ‰ΩøÁî®ÁùÄÔºåÂ¶ÇÊûúÁâπÂæÅ‰πãÈó¥Âú®ÊüêÁßçÁ®ãÂ∫¶‰∏äÂ≠òÂú®Áõ∏‰∫íÂÖ≥ËÅîÁöÑÊÉÖÂÜµÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÊûÑÈÄ†Êñ∞Êñ∞ÁâπÂæÅÁöÑÊñπÊ≥ïÊù•ÊçïÊçâËøô‰∫õÁõ∏ÂÖ≥ÊÄß„ÄÇ Â¶ÇÊûúËÆ≠ÁªÉÈõÜ‰∏çÊòØÂ§™Â§ßÔºåÂπ∂‰∏îÊ≤°ÊúâÂ§™Â§öÁöÑÁâπÂæÅÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊ®°Âûã„ÄÇ 15.8 ‰ΩøÁî®Â§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉËøõË°åÂºÇÂ∏∏Ê£ÄÊµãÔºàÂèØÈÄâÔºâÂèÇËÄÉËßÜÈ¢ë: 15 - 8 - Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min).mkv Âú®Êàë‰ª¨Ë∞àÂà∞ÁöÑÊúÄÂêé‰∏Ä‰∏™ËßÜÈ¢ëÔºåÂÖ≥‰∫éÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÔºåÁúãÂà∞ÁöÑ‰∏Ä‰∫õÂª∫Á´ãÁöÑÂêÑÁßçÂàÜÂ∏ÉÊ®°ÂûãÔºåÂΩì‰Ω†ÊîπÂèòÂèÇÊï∞Ôºå$\mu$ Âíå $\Sigma$„ÄÇÂú®ËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåËÆ©Êàë‰ª¨Áî®Ëøô‰∫õÊÉ≥Ê≥ïÔºåÂπ∂Â∫îÁî®ÂÆÉ‰ª¨Âà∂ÂÆö‰∏Ä‰∏™‰∏çÂêåÁöÑÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇ Ë¶ÅÂõûÈ°æ‰∏Ä‰∏ãÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÂíåÂ§öÂÖÉÊ≠£ÊÄÅÂàÜÂ∏ÉÔºö ÂàÜÂ∏ÉÊúâ‰∏§‰∏™ÂèÇÊï∞Ôºå $\mu$ Âíå $\Sigma$„ÄÇÂÖ∂‰∏≠$\mu$Ëøô‰∏Ä‰∏™$n$Áª¥ÂêëÈáèÂíå $\Sigma$ ÁöÑÂçèÊñπÂ∑ÆÁü©ÈòµÔºåÊòØ‰∏ÄÁßç$n\times n$ÁöÑÁü©Èòµ„ÄÇËÄåËøôÈáåÁöÑÂÖ¨Âºè$x$ÁöÑÊ¶ÇÁéáÔºåÂ¶ÇÊåâ $\mu$ ÂíåÂèÇÊï∞Âåñ $\Sigma$ÔºåÂíå‰Ω†ÁöÑÂèòÈáè $\mu$ Âíå $\Sigma$Ôºå‰Ω†ÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™ËåÉÂõ¥ÁöÑ‰∏çÂêåÂàÜÂ∏É‰∏ÄÊ†∑Ôºå‰Ω†Áü•ÈÅìÁöÑÔºåËøô‰∫õÈÉΩÊòØ‰∏â‰∏™Ê†∑Êú¨ÔºåÈÇ£‰∫õÊàë‰ª¨Âú®‰ª•ÂâçÁöÑËßÜÈ¢ëÁúãËøá‰∫Ü„ÄÇ Âõ†Ê≠§ÔºåËÆ©Êàë‰ª¨Ë∞àË∞àÂèÇÊï∞ÊãüÂêàÊàñÂèÇÊï∞‰º∞ËÆ°ÈóÆÈ¢òÔºö ÊàëÊúâ‰∏ÄÁªÑÊ†∑Êú¨${{{ x^{(1)},x^{(2)},...,x^{(m)}} }}$ÊòØ‰∏Ä‰∏™$n$Áª¥ÂêëÈáèÔºåÊàëÊÉ≥ÊàëÁöÑÊ†∑Êú¨Êù•Ëá™‰∏Ä‰∏™Â§öÂÖÉÈ´òÊñØÂàÜÂ∏É„ÄÇÊàëÂ¶Ç‰ΩïÂ∞ùËØï‰º∞ËÆ°ÊàëÁöÑÂèÇÊï∞ $\mu$ Âíå $\Sigma$ ‰ª•ÂèäÊ†áÂáÜÂÖ¨ÂºèÔºü ‰º∞ËÆ°‰ªñ‰ª¨ÊòØ‰Ω†ËÆæÁΩÆ $\mu$ ÊòØ‰Ω†ÁöÑËÆ≠ÁªÉÊ†∑Êú¨ÁöÑÂπ≥ÂùáÂÄº„ÄÇ $\mu=\frac{1}{m}\sum_{i=1}^{m}x^{(i)}$Âπ∂ËÆæÁΩÆ$\Sigma$Ôºö$\Sigma=\frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu)(x^{(i)}-\mu)^T$ËøôÂÖ∂ÂÆûÂè™ÊòØÂΩìÊàë‰ª¨‰ΩøÁî®PCAÁÆóÊ≥ïÊó∂ÂÄôÔºåÊúâ $\Sigma$ Êó∂ÂÜôÂá∫Êù•„ÄÇÊâÄ‰ª•‰Ω†Âè™ÈúÄÊèíÂÖ•‰∏äËø∞‰∏§‰∏™ÂÖ¨ÂºèÔºåËøô‰ºöÁªô‰Ω†‰Ω†‰º∞ËÆ°ÁöÑÂèÇÊï∞ $\mu$ Âíå‰Ω†‰º∞ËÆ°ÁöÑÂèÇÊï∞ $\Sigma$„ÄÇÊâÄ‰ª•ÔºåËøôÈáåÁªôÂá∫ÁöÑÊï∞ÊçÆÈõÜÊòØ‰Ω†Â¶Ç‰Ωï‰º∞ËÆ° $\mu$ Âíå $\Sigma$„ÄÇËÆ©Êàë‰ª¨‰ª•ËøôÁßçÊñπÊ≥ïËÄåÂè™ÈúÄÂ∞ÜÂÖ∂ÊèíÂÖ•Âà∞ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ï„ÄÇÈÇ£‰πàÔºåÊàë‰ª¨Â¶Ç‰ΩïÊääÊâÄÊúâËøô‰∏ÄÂàáÂÖ±ÂêåÂºÄÂèë‰∏Ä‰∏™ÂºÇÂ∏∏Ê£ÄÊµãÁÆóÊ≥ïÔºü È¶ñÂÖàÔºåÊàë‰ª¨ÊääÊàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜÔºåÂíåÊàë‰ª¨ÁöÑÊãüÂêàÊ®°ÂûãÔºåÊàë‰ª¨ËÆ°ÁÆó$p(x)$ÔºåË¶ÅÁü•ÈÅìÔºåËÆæÂÆö$\mu$ÂíåÊèèËø∞ÁöÑ‰∏ÄÊ†∑$\Sigma$„ÄÇ Â¶ÇÂõæÔºåËØ•ÂàÜÂ∏ÉÂú®‰∏≠Â§ÆÊúÄÂ§öÔºåË∂äÂà∞Â§ñÈù¢ÁöÑÂúàÁöÑËåÉÂõ¥Ë∂äÂ∞è„ÄÇ Âπ∂Âú®ËØ•ÁÇπÊòØÂá∫Ë∑ØËøôÈáåÁöÑÊ¶ÇÁéáÈùûÂ∏∏‰Ωé„ÄÇ ÂéüÂßãÊ®°Âûã‰∏éÂ§öÂÖÉÈ´òÊñØÊ®°ÂûãÁöÑÂÖ≥Á≥ªÂ¶ÇÂõæÔºö ÂÖ∂‰∏≠ÔºöÂçèÊñπÂ∑ÆÁü©Èòµ$\Sigma$‰∏∫Ôºö ÂéüÂßãÊ®°ÂûãÂíåÂ§öÂÖÉÈ´òÊñØÂàÜÂ∏ÉÊØîËæÉÂ¶ÇÂõæÔºö ÂçÅÂÖ≠„ÄÅÊé®ËçêÁ≥ªÁªü(Recommender Systems)16.1 ÈóÆÈ¢òÂΩ¢ÂºèÂåñÂèÇËÄÉËßÜÈ¢ë: 16 - 1 - Problem Formulation (8 min).mkv Âú®Êé•‰∏ãÊù•ÁöÑËßÜÈ¢ë‰∏≠ÔºåÊàëÊÉ≥ËÆ≤‰∏Ä‰∏ãÊé®ËçêÁ≥ªÁªü„ÄÇÊàëÊÉ≥ËÆ≤Êé®ËçêÁ≥ªÁªüÊúâ‰∏§‰∏™ÂéüÂõ†Ôºö Á¨¨‰∏Ä„ÄÅ‰ªÖ‰ªÖÂõ†‰∏∫ÂÆÉÊòØÊú∫Âô®Â≠¶‰π†‰∏≠ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÂ∫îÁî®„ÄÇÂú®ËøáÂéªÂá†Âπ¥ÔºåÊàëÂÅ∂Â∞îËÆøÈóÆÁ°ÖË∞∑‰∏çÂêåÁöÑÊäÄÊúØÂÖ¨Âè∏ÔºåÊàëÂ∏∏ÂíåÂ∑•‰ΩúÂú®ËøôÂÑøËá¥Âäõ‰∫éÊú∫Âô®Â≠¶‰π†Â∫îÁî®ÁöÑ‰∫∫‰ª¨ËÅäÂ§©ÔºåÊàëÂ∏∏ÈóÆ‰ªñ‰ª¨ÔºåÊúÄÈáçË¶ÅÁöÑÊú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®ÊòØ‰ªÄ‰πàÔºåÊàñËÄÖÔºå‰Ω†ÊúÄÊÉ≥ÊîπËøõÁöÑÊú∫Âô®Â≠¶‰π†Â∫îÁî®ÊúâÂì™‰∫õ„ÄÇÊàëÊúÄÂ∏∏Âê¨Âà∞ÁöÑÁ≠îÊ°àÊòØÊé®ËçêÁ≥ªÁªü„ÄÇÁé∞Âú®ÔºåÂú®Á°ÖË∞∑ÊúâÂæàÂ§öÂõ¢‰ΩìËØïÂõæÂª∫Á´ãÂæàÂ•ΩÁöÑÊé®ËçêÁ≥ªÁªü„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûú‰Ω†ËÄÉËôëÁΩëÁ´ôÂÉè‰∫öÈ©¨ÈÄäÔºåÊàñÁΩëÈ£ûÂÖ¨Âè∏ÊàñÊòìË∂£ÔºåÊàñiTunes GeniusÔºåÊúâÂæàÂ§öÁöÑÁΩëÁ´ôÊàñÁ≥ªÁªüËØïÂõæÊé®ËçêÊñ∞‰∫ßÂìÅÁªôÁî®Êà∑„ÄÇÂ¶ÇÔºå‰∫öÈ©¨ÈÄäÊé®ËçêÊñ∞‰π¶Áªô‰Ω†ÔºåÁΩëÈ£ûÂÖ¨Âè∏ËØïÂõæÊé®ËçêÊñ∞ÁîµÂΩ±Áªô‰Ω†ÔºåÁ≠âÁ≠â„ÄÇËøô‰∫õÊé®ËçêÁ≥ªÁªüÔºåÊ†πÊçÆÊµèËßà‰Ω†ËøáÂéª‰π∞Ëøá‰ªÄ‰πà‰π¶ÔºåÊàñËøáÂéªËØÑ‰ª∑Ëøá‰ªÄ‰πàÁîµÂΩ±Êù•Âà§Êñ≠„ÄÇËøô‰∫õÁ≥ªÁªü‰ºöÂ∏¶Êù•ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜÊî∂ÂÖ•ÔºåÊØîÂ¶Ç‰∏∫‰∫öÈ©¨ÈÄäÂíåÂÉèÁΩëÈ£ûËøôÊ†∑ÁöÑÂÖ¨Âè∏„ÄÇÂõ†Ê≠§ÔºåÂØπÊé®ËçêÁ≥ªÁªüÊÄßËÉΩÁöÑÊîπÂñÑÔºåÂ∞ÜÂØπËøô‰∫õ‰ºÅ‰∏öÁöÑÊúâÂÆûË¥®ÊÄßÂíåÁõ¥Êé•ÁöÑÂΩ±Âìç„ÄÇ Êé®ËçêÁ≥ªÁªüÊòØ‰∏™ÊúâË∂£ÁöÑÈóÆÈ¢òÔºåÂú®Â≠¶ÊúØÊú∫Âô®Â≠¶‰π†‰∏≠Âõ†Ê≠§ÔºåÊàë‰ª¨ÂèØ‰ª•ÂéªÂèÇÂä†‰∏Ä‰∏™Â≠¶ÊúØÊú∫Âô®Â≠¶‰π†‰ºöËÆÆÔºåÊé®ËçêÁ≥ªÁªüÈóÆÈ¢òÂÆûÈôÖ‰∏äÂèóÂà∞ÂæàÂ∞ëÁöÑÂÖ≥Ê≥®ÔºåÊàñËÄÖÔºåËá≥Â∞ëÂú®Â≠¶ÊúØÁïåÂÆÉÂç†‰∫ÜÂæàÂ∞èÁöÑ‰ªΩÈ¢ù„ÄÇ‰ΩÜÊòØÔºåÂ¶ÇÊûú‰Ω†ÁúãÊ≠£Âú®ÂèëÁîüÁöÑ‰∫ãÊÉÖÔºåËÆ∏Â§öÊúâËÉΩÂäõÊûÑÂª∫Ëøô‰∫õÁ≥ªÁªüÁöÑÁßëÊäÄ‰ºÅ‰∏öÔºå‰ªñ‰ª¨‰ºº‰πéÂú®ÂæàÂ§ö‰ºÅ‰∏ö‰∏≠Âç†ÊçÆÂæàÈ´òÁöÑ‰ºòÂÖàÁ∫ß„ÄÇËøôÊòØÊàë‰∏∫‰ªÄ‰πàÂú®ËøôËäÇËØæËÆ®ËÆ∫ÂÆÉÁöÑÂéüÂõ†‰πã‰∏Ä„ÄÇ ÊàëÊÉ≥ËÆ®ËÆ∫Êé®ËçêÁ≥ªÁªüÂú∞Á¨¨‰∫å‰∏™ÂéüÂõ†ÊòØÔºöËøô‰∏™Áè≠ËßÜÈ¢ëÁöÑÊúÄÂêéÂá†ÈõÜÊàëÊÉ≥ËÆ®ËÆ∫Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑ‰∏Ä‰∫õÂ§ßÊÄùÊÉ≥ÔºåÂπ∂ÂíåÂ§ßÂÆ∂ÂàÜ‰∫´„ÄÇËøôËäÇËØæÊàë‰ª¨‰πüÁúãÂà∞‰∫ÜÔºåÂØπÊú∫Âô®Â≠¶‰π†Êù•ËØ¥ÔºåÁâπÂæÅÊòØÂæàÈáçË¶ÅÁöÑÔºå‰Ω†ÊâÄÈÄâÊã©ÁöÑÁâπÂæÅÔºåÂ∞ÜÂØπ‰Ω†Â≠¶‰π†ÁÆóÊ≥ïÁöÑÊÄßËÉΩÊúâÂæàÂ§ßÁöÑÂΩ±Âìç„ÄÇÂõ†Ê≠§ÔºåÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Êúâ‰∏ÄÁßçÂ§ßÊÄùÊÉ≥ÔºåÂÆÉÈíàÂØπ‰∏Ä‰∫õÈóÆÈ¢òÔºåÂèØËÉΩÂπ∂‰∏çÊòØÊâÄÊúâÁöÑÈóÆÈ¢òÔºåËÄåÊòØ‰∏Ä‰∫õÈóÆÈ¢òÔºåÊúâÁÆóÊ≥ïÂèØ‰ª•‰∏∫‰Ω†Ëá™Âä®Â≠¶‰π†‰∏ÄÂ•óÂ•ΩÁöÑÁâπÂæÅ„ÄÇÂõ†Ê≠§Ôºå‰∏çË¶ÅËØïÂõæÊâãÂä®ËÆæËÆ°ÔºåËÄåÊâãÂÜô‰ª£Á†ÅËøôÊòØÁõÆÂâç‰∏∫Ê≠¢Êàë‰ª¨Â∏∏Âπ≤ÁöÑ„ÄÇÊúâ‰∏Ä‰∫õËÆæÁΩÆÔºå‰Ω†ÂèØ‰ª•Êúâ‰∏Ä‰∏™ÁÆóÊ≥ïÔºå‰ªÖ‰ªÖÂ≠¶‰π†ÂÖ∂‰ΩøÁî®ÁöÑÁâπÂæÅÔºåÊé®ËçêÁ≥ªÁªüÂ∞±ÊòØÁ±ªÂûãËÆæÁΩÆÁöÑ‰∏Ä‰∏™‰æãÂ≠ê„ÄÇËøòÊúâÂæàÂ§öÂÖ∂ÂÆÉÁöÑÔºå‰ΩÜÊòØÈÄöËøáÊé®ËçêÁ≥ªÁªüÔºåÊàë‰ª¨Â∞ÜÈ¢ÜÁï•‰∏ÄÂ∞èÈÉ®ÂàÜÁâπÂæÅÂ≠¶‰π†ÁöÑÊÄùÊÉ≥ÔºåËá≥Â∞ëÔºå‰Ω†Â∞ÜËÉΩÂ§ü‰∫ÜËß£Âà∞ËøôÊñπÈù¢ÁöÑ‰∏Ä‰∏™‰æãÂ≠êÔºåÊàëËÆ§‰∏∫ÔºåÊú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÂ§ßÊÄùÊÉ≥‰πüÊòØËøôÊ†∑„ÄÇÂõ†Ê≠§ÔºåËÆ©Êàë‰ª¨ÂºÄÂßãËÆ®ËÆ∫Êé®ËçêÁ≥ªÁªüÈóÆÈ¢òÂΩ¢ÂºèÂåñ„ÄÇ Êàë‰ª¨‰ªé‰∏Ä‰∏™‰æãÂ≠êÂºÄÂßãÂÆö‰πâÊé®ËçêÁ≥ªÁªüÁöÑÈóÆÈ¢ò„ÄÇ ÂÅá‰ΩøÊàë‰ª¨ÊòØ‰∏Ä‰∏™ÁîµÂΩ±‰æõÂ∫îÂïÜÔºåÊàë‰ª¨Êúâ 5 ÈÉ®ÁîµÂΩ±Âíå 4 ‰∏™Áî®Êà∑ÔºåÊàë‰ª¨Ë¶ÅÊ±ÇÁî®Êà∑‰∏∫ÁîµÂΩ±ÊâìÂàÜ„ÄÇ Ââç‰∏âÈÉ®ÁîµÂΩ±ÊòØÁà±ÊÉÖÁâáÔºåÂêé‰∏§ÈÉ®ÂàôÊòØÂä®‰ΩúÁâáÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂá∫AliceÂíåBob‰ºº‰πéÊõ¥ÂÄæÂêë‰∏éÁà±ÊÉÖÁâáÔºå ËÄå Carol Âíå Dave ‰ºº‰πéÊõ¥ÂÄæÂêë‰∏éÂä®‰ΩúÁâá„ÄÇÂπ∂‰∏îÊ≤°Êúâ‰∏Ä‰∏™Áî®Êà∑ÁªôÊâÄÊúâÁöÑÁîµÂΩ±ÈÉΩÊâìËøáÂàÜ„ÄÇÊàë‰ª¨Â∏åÊúõÊûÑÂª∫‰∏Ä‰∏™ÁÆóÊ≥ïÊù•È¢ÑÊµã‰ªñ‰ª¨ÊØè‰∏™‰∫∫ÂèØËÉΩ‰ºöÁªô‰ªñ‰ª¨Ê≤°ÁúãËøáÁöÑÁîµÂΩ±ÊâìÂ§öÂ∞ëÂàÜÔºåÂπ∂‰ª•Ê≠§‰Ωú‰∏∫Êé®ËçêÁöÑ‰æùÊçÆ„ÄÇ ‰∏ãÈù¢ÂºïÂÖ•‰∏Ä‰∫õÊ†áËÆ∞Ôºö $n_u$ ‰ª£Ë°®Áî®Êà∑ÁöÑÊï∞Èáè $n_m$ ‰ª£Ë°®ÁîµÂΩ±ÁöÑÊï∞Èáè $r(i, j)$ Â¶ÇÊûúÁî®Êà∑jÁªôÁîµÂΩ± $i$ ËØÑËøáÂàÜÂàô $r(i,j)=1$ $y^{(i, j)}$ ‰ª£Ë°®Áî®Êà∑ $j$ ÁªôÁîµÂΩ±iÁöÑËØÑÂàÜ $m_j$‰ª£Ë°®Áî®Êà∑ $j$ ËØÑËøáÂàÜÁöÑÁîµÂΩ±ÁöÑÊÄªÊï∞ 16.2 Âü∫‰∫éÂÜÖÂÆπÁöÑÊé®ËçêÁ≥ªÁªüÂèÇËÄÉËßÜÈ¢ë: 16 - 2 - Content Based Recommendations (15 min).mkv Âú®‰∏Ä‰∏™Âü∫‰∫éÂÜÖÂÆπÁöÑÊé®ËçêÁ≥ªÁªüÁÆóÊ≥ï‰∏≠ÔºåÊàë‰ª¨ÂÅáËÆæÂØπ‰∫éÊàë‰ª¨Â∏åÊúõÊé®ËçêÁöÑ‰∏úË•øÊúâ‰∏Ä‰∫õÊï∞ÊçÆÔºåËøô‰∫õÊï∞ÊçÆÊòØÊúâÂÖ≥Ëøô‰∫õ‰∏úË•øÁöÑÁâπÂæÅ„ÄÇ Âú®Êàë‰ª¨ÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨ÂèØ‰ª•ÂÅáËÆæÊØèÈÉ®ÁîµÂΩ±ÈÉΩÊúâ‰∏§‰∏™ÁâπÂæÅÔºåÂ¶Ç$x_1$‰ª£Ë°®ÁîµÂΩ±ÁöÑÊµ™Êº´Á®ãÂ∫¶Ôºå$x_2$ ‰ª£Ë°®ÁîµÂΩ±ÁöÑÂä®‰ΩúÁ®ãÂ∫¶„ÄÇ ÂàôÊØèÈÉ®ÁîµÂΩ±ÈÉΩÊúâ‰∏Ä‰∏™ÁâπÂæÅÂêëÈáèÔºåÂ¶Ç$x^{(1)}$ÊòØÁ¨¨‰∏ÄÈÉ®ÁîµÂΩ±ÁöÑÁâπÂæÅÂêëÈáè‰∏∫[0.9 0]„ÄÇ ‰∏ãÈù¢Êàë‰ª¨Ë¶ÅÂü∫‰∫éËøô‰∫õÁâπÂæÅÊù•ÊûÑÂª∫‰∏Ä‰∏™Êé®ËçêÁ≥ªÁªüÁÆóÊ≥ï„ÄÇ ÂÅáËÆæÊàë‰ª¨ÈááÁî®Á∫øÊÄßÂõûÂΩíÊ®°ÂûãÔºåÊàë‰ª¨ÂèØ‰ª•ÈíàÂØπÊØè‰∏Ä‰∏™Áî®Êà∑ÈÉΩËÆ≠ÁªÉ‰∏Ä‰∏™Á∫øÊÄßÂõûÂΩíÊ®°ÂûãÔºåÂ¶Ç${{\theta }^{(1)}}$ÊòØÁ¨¨‰∏Ä‰∏™Áî®Êà∑ÁöÑÊ®°ÂûãÁöÑÂèÇÊï∞„ÄÇ ‰∫éÊòØÔºåÊàë‰ª¨ÊúâÔºö $\theta^{(j)}$Áî®Êà∑ $j$ ÁöÑÂèÇÊï∞ÂêëÈáè $x^{(i)}$ÁîµÂΩ± $i$ ÁöÑÁâπÂæÅÂêëÈáè ÂØπ‰∫éÁî®Êà∑ $j$ ÂíåÁîµÂΩ± $i$ÔºåÊàë‰ª¨È¢ÑÊµãËØÑÂàÜ‰∏∫Ôºö$(\theta^{(j)})^T x^{(i)}$ ‰ª£‰ª∑ÂáΩÊï∞ ÈíàÂØπÁî®Êà∑ $j$ÔºåËØ•Á∫øÊÄßÂõûÂΩíÊ®°ÂûãÁöÑ‰ª£‰ª∑‰∏∫È¢ÑÊµãËØØÂ∑ÆÁöÑÂπ≥ÊñπÂíåÔºåÂä†‰∏äÊ≠£ÂàôÂåñÈ°πÔºö$$\min_{\theta (j)}\frac{1}{2}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\left(\theta_{k}^{(j)}\right)^2$$ ÂÖ∂‰∏≠ $i:r(i,j)$Ë°®Á§∫Êàë‰ª¨Âè™ËÆ°ÁÆóÈÇ£‰∫õÁî®Êà∑ $j$ ËØÑËøáÂàÜÁöÑÁîµÂΩ±„ÄÇÂú®‰∏ÄËà¨ÁöÑÁ∫øÊÄßÂõûÂΩíÊ®°Âûã‰∏≠ÔºåËØØÂ∑ÆÈ°πÂíåÊ≠£ÂàôÈ°πÂ∫îËØ•ÈÉΩÊòØ‰πò‰ª•$1/2m$ÔºåÂú®ËøôÈáåÊàë‰ª¨Â∞Ü$m$ÂéªÊéâ„ÄÇÂπ∂‰∏îÊàë‰ª¨‰∏çÂØπÊñπÂ∑ÆÈ°π$\theta_0$ËøõË°åÊ≠£ÂàôÂåñÂ§ÑÁêÜ„ÄÇ ‰∏äÈù¢ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Âè™ÊòØÈíàÂØπ‰∏Ä‰∏™Áî®Êà∑ÁöÑÔºå‰∏∫‰∫ÜÂ≠¶‰π†ÊâÄÊúâÁî®Êà∑ÔºåÊàë‰ª¨Â∞ÜÊâÄÊúâÁî®Êà∑ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Ê±ÇÂíåÔºö $$ \min_{\theta^{(1)},...,\theta^{(n_u)}} \frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2 $$ Â¶ÇÊûúÊàë‰ª¨Ë¶ÅÁî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÊù•Ê±ÇËß£ÊúÄ‰ºòËß£ÔºåÊàë‰ª¨ËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÅèÂØºÊï∞ÂêéÂæóÂà∞Ê¢ØÂ∫¶‰∏ãÈôçÁöÑÊõ¥Êñ∞ÂÖ¨Âºè‰∏∫Ôºö $$\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)} \quad (\text{for} \, k = 0)$$ $$\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)}+\lambda\theta_k^{(j)}\right) \quad (\text{for} \, k\neq 0)$$ 16.3 ÂçèÂêåËøáÊª§ÂèÇËÄÉËßÜÈ¢ë: 16 - 3 - Collaborative Filtering (10 min).mkv Âú®‰πãÂâçÁöÑÂü∫‰∫éÂÜÖÂÆπÁöÑÊé®ËçêÁ≥ªÁªü‰∏≠ÔºåÂØπ‰∫éÊØè‰∏ÄÈÉ®ÁîµÂΩ±ÔºåÊàë‰ª¨ÈÉΩÊéåÊè°‰∫ÜÂèØÁî®ÁöÑÁâπÂæÅÔºå‰ΩøÁî®Ëøô‰∫õÁâπÂæÅËÆ≠ÁªÉÂá∫‰∫ÜÊØè‰∏Ä‰∏™Áî®Êà∑ÁöÑÂèÇÊï∞„ÄÇÁõ∏ÂèçÂú∞ÔºåÂ¶ÇÊûúÊàë‰ª¨Êã•ÊúâÁî®Êà∑ÁöÑÂèÇÊï∞ÔºåÊàë‰ª¨ÂèØ‰ª•Â≠¶‰π†ÂæóÂá∫ÁîµÂΩ±ÁöÑÁâπÂæÅ„ÄÇ $$ \mathop{min}\limits_{x^{(1)},...,x^{(n_m)}}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j{r(i,j)=1}}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2 $$ ‰ΩÜÊòØÂ¶ÇÊûúÊàë‰ª¨Êó¢Ê≤°ÊúâÁî®Êà∑ÁöÑÂèÇÊï∞Ôºå‰πüÊ≤°ÊúâÁîµÂΩ±ÁöÑÁâπÂæÅÔºåËøô‰∏§ÁßçÊñπÊ≥ïÈÉΩ‰∏çÂèØË°å‰∫Ü„ÄÇÂçèÂêåËøáÊª§ÁÆóÊ≥ïÂèØ‰ª•ÂêåÊó∂Â≠¶‰π†Ëøô‰∏§ËÄÖ„ÄÇ Êàë‰ª¨ÁöÑ‰ºòÂåñÁõÆÊ†á‰æøÊîπ‰∏∫ÂêåÊó∂ÈíàÂØπ$x$Âíå$\theta$ËøõË°å„ÄÇ$$J(x^{(1)},‚Ä¶x^{(n_m)},\theta^{(1)},‚Ä¶,\theta^{(n_u)})=\frac{1}{2}\sum_{(i:j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$ ÂØπ‰ª£‰ª∑ÂáΩÊï∞Ê±ÇÂÅèÂØºÊï∞ÁöÑÁªìÊûúÂ¶Ç‰∏ãÔºö $$x_k^{(i)}:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\theta_k^{j}+\lambda x_k^{(i)}\right)$$ $$\theta_k^{(i)}:=\theta_k^{(i)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}x_k^{(i)}+\lambda \theta_k^{(j)}\right)$$ Ê≥®ÔºöÂú®ÂçèÂêåËøáÊª§‰ªéÁÆóÊ≥ï‰∏≠ÔºåÊàë‰ª¨ÈÄöÂ∏∏‰∏ç‰ΩøÁî®ÊñπÂ∑ÆÈ°πÔºåÂ¶ÇÊûúÈúÄË¶ÅÁöÑËØùÔºåÁÆóÊ≥ï‰ºöËá™Âä®Â≠¶Âæó„ÄÇÂçèÂêåËøáÊª§ÁÆóÊ≥ï‰ΩøÁî®Ê≠•È™§Â¶Ç‰∏ãÔºö ÂàùÂßã $x^{(1)},x^{(1)},‚Ä¶x^{(nm)},\ \theta^{(1)},\theta^{(2)},‚Ä¶,\theta^{(n_u)}$‰∏∫‰∏Ä‰∫õÈöèÊú∫Â∞èÂÄº ‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊúÄÂ∞èÂåñ‰ª£‰ª∑ÂáΩÊï∞ Âú®ËÆ≠ÁªÉÂÆåÁÆóÊ≥ïÂêéÔºåÊàë‰ª¨È¢ÑÊµã$(\theta^{(j)})^Tx^{(i)}$‰∏∫Áî®Êà∑ $j$ ÁªôÁîµÂΩ± $i$ ÁöÑËØÑÂàÜ ÈÄöËøáËøô‰∏™Â≠¶‰π†ËøáÁ®ãËé∑ÂæóÁöÑÁâπÂæÅÁü©ÈòµÂåÖÂê´‰∫ÜÊúâÂÖ≥ÁîµÂΩ±ÁöÑÈáçË¶ÅÊï∞ÊçÆÔºåËøô‰∫õÊï∞ÊçÆ‰∏çÊÄªÊòØ‰∫∫ËÉΩËØªÊáÇÁöÑÔºå‰ΩÜÊòØÊàë‰ª¨ÂèØ‰ª•Áî®Ëøô‰∫õÊï∞ÊçÆ‰Ωú‰∏∫ÁªôÁî®Êà∑Êé®ËçêÁîµÂΩ±ÁöÑ‰æùÊçÆ„ÄÇ ‰æãÂ¶ÇÔºåÂ¶ÇÊûú‰∏Ä‰ΩçÁî®Êà∑Ê≠£Âú®ËßÇÁúãÁîµÂΩ± $x^{(i)}$ÔºåÊàë‰ª¨ÂèØ‰ª•ÂØªÊâæÂè¶‰∏ÄÈÉ®ÁîµÂΩ±$x^{(j)}$Ôºå‰æùÊçÆ‰∏§ÈÉ®ÁîµÂΩ±ÁöÑÁâπÂæÅÂêëÈáè‰πãÈó¥ÁöÑË∑ùÁ¶ª$\left\| {{x}^{(i)}}-{{x}^{(j)}} \right\|$ÁöÑÂ§ßÂ∞è„ÄÇ 16.4 ÂçèÂêåËøáÊª§ÁÆóÊ≥ïÂèÇËÄÉËßÜÈ¢ë: 16 - 4 - Collaborative Filtering Algorithm (9 min).mkv ÂçèÂêåËøáÊª§‰ºòÂåñÁõÆÊ†áÔºö ÁªôÂÆö$x^{(1)},...,x^{(n_m)}$Ôºå‰º∞ËÆ°$\theta^{(1)},...,\theta^{(n_u)}$Ôºö $$ \min_{\theta^{(1)},...,\theta^{(n_u)}}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2 $$ ÁªôÂÆö$\theta^{(1)},‚Ä¶,\theta^{(n_u)}$Ôºå‰º∞ËÆ°$x^{(1)},‚Ä¶,x^{(n_m)}$Ôºö ÂêåÊó∂ÊúÄÂ∞èÂåñ$x^{(1)},‚Ä¶,x^{(n_m)}$Âíå$\theta^{(1)},‚Ä¶,\theta^{(n_u)}$Ôºö$$J(x^{(1)},‚Ä¶,x^{(n_m)},\theta^{(1)},‚Ä¶,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2$$ $$ \min_{x^{(1)},...,x^{(n_m)} \\\ \theta^{(1)},...,\theta^{(n_u)}}J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)}) $$ 16.5 ÂêëÈáèÂåñÔºö‰ΩéÁß©Áü©ÈòµÂàÜËß£ÂèÇËÄÉËßÜÈ¢ë: 16 - 5 - Vectorization_ Low Rank Matrix Factorization (8 min).mkv Âú®‰∏äÂá†ËäÇËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨Ë∞àÂà∞‰∫ÜÂçèÂêåËøáÊª§ÁÆóÊ≥ïÔºåÊú¨ËäÇËßÜÈ¢ë‰∏≠ÊàëÂ∞Ü‰ºöËÆ≤Âà∞ÊúâÂÖ≥ËØ•ÁÆóÊ≥ïÁöÑÂêëÈáèÂåñÂÆûÁé∞Ôºå‰ª•ÂèäËØ¥ËØ¥ÊúâÂÖ≥ËØ•ÁÆóÊ≥ï‰Ω†ÂèØ‰ª•ÂÅöÁöÑÂÖ∂‰ªñ‰∫ãÊÉÖ„ÄÇ ‰∏æ‰æãÂ≠êÔºö ÂΩìÁªôÂá∫‰∏Ä‰ª∂‰∫ßÂìÅÊó∂Ôºå‰Ω†ËÉΩÂê¶ÊâæÂà∞‰∏é‰πãÁõ∏ÂÖ≥ÁöÑÂÖ∂ÂÆÉ‰∫ßÂìÅ„ÄÇ ‰∏Ä‰ΩçÁî®Êà∑ÊúÄËøëÁúã‰∏ä‰∏Ä‰ª∂‰∫ßÂìÅÔºåÊúâÊ≤°ÊúâÂÖ∂ÂÆÉÁõ∏ÂÖ≥ÁöÑ‰∫ßÂìÅÔºå‰Ω†ÂèØ‰ª•Êé®ËçêÁªô‰ªñ„ÄÇ ÊàëÂ∞ÜË¶ÅÂÅöÁöÑÊòØÔºöÂÆûÁé∞‰∏ÄÁßçÈÄâÊã©ÁöÑÊñπÊ≥ïÔºåÂÜôÂá∫ÂçèÂêåËøáÊª§ÁÆóÊ≥ïÁöÑÈ¢ÑÊµãÊÉÖÂÜµ„ÄÇ Êàë‰ª¨ÊúâÂÖ≥‰∫é‰∫îÈÉ®ÁîµÂΩ±ÁöÑÊï∞ÊçÆÈõÜÔºåÊàëÂ∞ÜË¶ÅÂÅöÁöÑÊòØÔºåÂ∞ÜËøô‰∫õÁî®Êà∑ÁöÑÁîµÂΩ±ËØÑÂàÜÔºåËøõË°åÂàÜÁªÑÂπ∂Â≠òÂà∞‰∏Ä‰∏™Áü©Èòµ‰∏≠„ÄÇ Êàë‰ª¨Êúâ‰∫îÈÉ®ÁîµÂΩ±Ôºå‰ª•ÂèäÂõõ‰ΩçÁî®Êà∑ÔºåÈÇ£‰πà Ëøô‰∏™Áü©Èòµ $Y$ Â∞±ÊòØ‰∏Ä‰∏™5Ë°å4ÂàóÁöÑÁü©ÈòµÔºåÂÆÉÂ∞ÜËøô‰∫õÁîµÂΩ±ÁöÑÁî®Êà∑ËØÑÂàÜÊï∞ÊçÆÈÉΩÂ≠òÂú®Áü©ÈòµÈáåÔºö Movie Alice (1) Bob (2) Carol (3) Dave (4) Love at last 5 5 0 0 Romance forever 5 ? ? 0 Cute puppies of love ? 4 0 ? Nonstop car chases 0 0 5 4 Swords vs. karate 0 0 5 ? Êé®Âá∫ËØÑÂàÜÔºö ÊâæÂà∞Áõ∏ÂÖ≥ÂΩ±ÁâáÔºö Áé∞Âú®Êó¢ÁÑ∂‰Ω†Â∑≤ÁªèÂØπÁâπÂæÅÂèÇÊï∞ÂêëÈáèËøõË°å‰∫ÜÂ≠¶‰π†ÔºåÈÇ£‰πàÊàë‰ª¨Â∞±‰ºöÊúâ‰∏Ä‰∏™ÂæàÊñπ‰æøÁöÑÊñπÊ≥ïÊù•Â∫¶Èáè‰∏§ÈÉ®ÁîµÂΩ±‰πãÈó¥ÁöÑÁõ∏‰ººÊÄß„ÄÇ‰æãÂ¶ÇËØ¥ÔºöÁîµÂΩ± $i$ Êúâ‰∏Ä‰∏™ÁâπÂæÅÂêëÈáè$x^{(i)}$Ôºå‰Ω†ÊòØÂê¶ËÉΩÊâæÂà∞‰∏ÄÈÉ®‰∏çÂêåÁöÑÁîµÂΩ± $j$Ôºå‰øùËØÅ‰∏§ÈÉ®ÁîµÂΩ±ÁöÑÁâπÂæÅÂêëÈáè‰πãÈó¥ÁöÑË∑ùÁ¶ª$x^{(i)}$Âíå$x^{(j)}$ÂæàÂ∞èÔºåÈÇ£Â∞±ËÉΩÂæàÊúâÂäõÂú∞Ë°®ÊòéÁîµÂΩ±$i$ÂíåÁîµÂΩ± $j$ Âú®ÊüêÁßçÁ®ãÂ∫¶‰∏äÊúâÁõ∏‰ººÔºåËá≥Â∞ëÂú®ÊüêÁßçÊÑè‰πâ‰∏äÔºåÊüê‰∫õ‰∫∫ÂñúÊ¨¢ÁîµÂΩ± $i$ÔºåÊàñËÆ∏Êõ¥ÊúâÂèØËÉΩ‰πüÂØπÁîµÂΩ± $j$ ÊÑüÂÖ¥Ë∂£„ÄÇÊÄªÁªì‰∏Ä‰∏ãÔºåÂΩìÁî®Êà∑Âú®ÁúãÊüêÈÉ®ÁîµÂΩ± $i$ ÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûú‰Ω†ÊÉ≥Êâæ5ÈÉ®‰∏éÁîµÂΩ±ÈùûÂ∏∏Áõ∏‰ººÁöÑÁîµÂΩ±Ôºå‰∏∫‰∫ÜËÉΩÁªôÁî®Êà∑Êé®Ëçê5ÈÉ®Êñ∞ÁîµÂΩ±Ôºå‰Ω†ÈúÄË¶ÅÂÅöÁöÑÊòØÊâæÂá∫ÁîµÂΩ± $j$ÔºåÂú®Ëøô‰∫õ‰∏çÂêåÁöÑÁîµÂΩ±‰∏≠‰∏éÊàë‰ª¨Ë¶ÅÊâæÁöÑÁîµÂΩ± $i$ ÁöÑË∑ùÁ¶ªÊúÄÂ∞èÔºåËøôÊ†∑‰Ω†Â∞±ËÉΩÁªô‰Ω†ÁöÑÁî®Êà∑Êé®ËçêÂá†ÈÉ®‰∏çÂêåÁöÑÁîµÂΩ±‰∫Ü„ÄÇ ÈÄöËøáËøô‰∏™ÊñπÊ≥ïÔºåÂ∏åÊúõ‰Ω†ËÉΩÁü•ÈÅìÔºåÂ¶Ç‰ΩïËøõË°å‰∏Ä‰∏™ÂêëÈáèÂåñÁöÑËÆ°ÁÆóÊù•ÂØπÊâÄÊúâÁöÑÁî®Êà∑ÂíåÊâÄÊúâÁöÑÁîµÂΩ±ËøõË°åËØÑÂàÜËÆ°ÁÆó„ÄÇÂêåÊó∂Â∏åÊúõ‰Ω†‰πüËÉΩÊéåÊè°ÔºåÈÄöËøáÂ≠¶‰π†ÁâπÂæÅÂèÇÊï∞ÔºåÊù•ÊâæÂà∞Áõ∏ÂÖ≥ÁîµÂΩ±Âíå‰∫ßÂìÅÁöÑÊñπÊ≥ï„ÄÇ 16.6 Êé®Ë°åÂ∑•‰Ωú‰∏äÁöÑÁªÜËäÇÔºöÂùáÂÄºÂΩí‰∏ÄÂåñÂèÇËÄÉËßÜÈ¢ë: 16 - 6 - Implementational Detail_ Mean Normalization (9 min).mkv ËÆ©Êàë‰ª¨Êù•Áúã‰∏ãÈù¢ÁöÑÁî®Êà∑ËØÑÂàÜÊï∞ÊçÆÔºö Â¶ÇÊûúÊàë‰ª¨Êñ∞Â¢û‰∏Ä‰∏™Áî®Êà∑ EveÔºåÂπ∂‰∏î Eve Ê≤°Êúâ‰∏∫‰ªª‰ΩïÁîµÂΩ±ËØÑÂàÜÔºåÈÇ£‰πàÊàë‰ª¨‰ª•‰ªÄ‰πà‰∏∫‰æùÊçÆ‰∏∫EveÊé®ËçêÁîµÂΩ±Âë¢Ôºü Êàë‰ª¨È¶ñÂÖàÈúÄË¶ÅÂØπÁªìÊûú $Y $Áü©ÈòµËøõË°åÂùáÂÄºÂΩí‰∏ÄÂåñÂ§ÑÁêÜÔºåÂ∞ÜÊØè‰∏Ä‰∏™Áî®Êà∑ÂØπÊüê‰∏ÄÈÉ®ÁîµÂΩ±ÁöÑËØÑÂàÜÂáèÂéªÊâÄÊúâÁî®Êà∑ÂØπËØ•ÁîµÂΩ±ËØÑÂàÜÁöÑÂπ≥ÂùáÂÄºÔºö ÁÑ∂ÂêéÊàë‰ª¨Âà©Áî®Ëøô‰∏™Êñ∞ÁöÑ $Y$ Áü©ÈòµÊù•ËÆ≠ÁªÉÁÆóÊ≥ï„ÄÇÂ¶ÇÊûúÊàë‰ª¨Ë¶ÅÁî®Êñ∞ËÆ≠ÁªÉÂá∫ÁöÑÁÆóÊ≥ïÊù•È¢ÑÊµãËØÑÂàÜÔºåÂàôÈúÄË¶ÅÂ∞ÜÂπ≥ÂùáÂÄºÈáçÊñ∞Âä†ÂõûÂéªÔºåÈ¢ÑÊµã$(\theta^{(j)})^T x^{(i)}+\mu_i$ÔºåÂØπ‰∫éEveÔºåÊàë‰ª¨ÁöÑÊñ∞Ê®°Âûã‰ºöËÆ§‰∏∫Â•πÁªôÊØèÈÉ®ÁîµÂΩ±ÁöÑËØÑÂàÜÈÉΩÊòØËØ•ÁîµÂΩ±ÁöÑÂπ≥ÂùáÂàÜ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÔºàÂçÅÔºâ]]></title>
    <url>%2F2018%2F08%2F12%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÂçÅ‰∏â„ÄÅËÅöÁ±ª(Clustering)Êó†ÁõëÁù£Â≠¶‰π†ÔºöÁÆÄ‰ªãÂèÇËÄÉËßÜÈ¢ë: 13 - 1 - Unsupervised Learning_ Introduction (3 min).mkv Âú®Ëøô‰∏™ËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜÂºÄÂßã‰ªãÁªçËÅöÁ±ªÁÆóÊ≥ï„ÄÇËøôÂ∞ÜÊòØ‰∏Ä‰∏™ÊøÄÂä®‰∫∫ÂøÉÁöÑÊó∂ÂàªÔºåÂõ†‰∏∫ËøôÊòØÊàë‰ª¨Â≠¶‰π†ÁöÑÁ¨¨‰∏Ä‰∏™ÈùûÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï„ÄÇÊàë‰ª¨Â∞ÜË¶ÅËÆ©ËÆ°ÁÆóÊú∫Â≠¶‰π†Êó†Ê†áÁ≠æÊï∞ÊçÆÔºåËÄå‰∏çÊòØÊ≠§ÂâçÁöÑÊ†áÁ≠æÊï∞ÊçÆ„ÄÇ ÈÇ£‰πàÔºå‰ªÄ‰πàÊòØÈùûÁõëÁù£Â≠¶‰π†Âë¢ÔºüÂú®ËØæÁ®ãÁöÑ‰∏ÄÂºÄÂßãÔºåÊàëÊõæÁÆÄÂçïÁöÑ‰ªãÁªçËøáÈùûÁõëÁù£Â≠¶‰π†ÔºåÁÑ∂ËÄåÔºåÊàë‰ª¨ËøòÊòØÊúâÂøÖË¶ÅÂ∞ÜÂÖ∂‰∏éÁõëÁù£Â≠¶‰π†ÂÅö‰∏Ä‰∏ãÊØîËæÉ„ÄÇ Âú®‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑÁõëÁù£Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨Êúâ‰∏Ä‰∏™ÊúâÊ†áÁ≠æÁöÑËÆ≠ÁªÉÈõÜÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÊòØÊâæÂà∞ËÉΩÂ§üÂå∫ÂàÜÊ≠£Ê†∑Êú¨ÂíåË¥üÊ†∑Êú¨ÁöÑÂÜ≥Á≠ñËæπÁïåÔºåÂú®ËøôÈáåÁöÑÁõëÁù£Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨Êúâ‰∏ÄÁ≥ªÂàóÊ†áÁ≠æÔºåÊàë‰ª¨ÈúÄË¶ÅÊçÆÊ≠§ÊãüÂêà‰∏Ä‰∏™ÂÅáËÆæÂáΩÊï∞„ÄÇ‰∏éÊ≠§‰∏çÂêåÁöÑÊòØÔºåÂú®ÈùûÁõëÁù£Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨ÁöÑÊï∞ÊçÆÊ≤°ÊúâÈôÑÂ∏¶‰ªª‰ΩïÊ†áÁ≠æÔºåÊàë‰ª¨ÊãøÂà∞ÁöÑÊï∞ÊçÆÂ∞±ÊòØËøôÊ†∑ÁöÑÔºö Âú®ËøôÈáåÊàë‰ª¨Êúâ‰∏ÄÁ≥ªÂàóÁÇπÔºåÂç¥Ê≤°ÊúâÊ†áÁ≠æ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜÂèØ‰ª•ÂÜôÊàêÂè™Êúâ$x^{(1)}$,$x^{(2)}$‚Ä¶..‰∏ÄÁõ¥Âà∞$x^{(m)}$„ÄÇÊàë‰ª¨Ê≤°Êúâ‰ªª‰ΩïÊ†áÁ≠æ$y$„ÄÇÂõ†Ê≠§ÔºåÂõæ‰∏äÁîªÁöÑËøô‰∫õÁÇπÊ≤°ÊúâÊ†áÁ≠æ‰ø°ÊÅØ„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÂú®ÈùûÁõëÁù£Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨ÈúÄË¶ÅÂ∞Ü‰∏ÄÁ≥ªÂàóÊó†Ê†áÁ≠æÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåËæìÂÖ•Âà∞‰∏Ä‰∏™ÁÆóÊ≥ï‰∏≠ÔºåÁÑ∂ÂêéÊàë‰ª¨ÂëäËØâËøô‰∏™ÁÆóÊ≥ïÔºåÂø´Âéª‰∏∫Êàë‰ª¨ÊâæÊâæËøô‰∏™Êï∞ÊçÆÁöÑÂÜÖÂú®ÁªìÊûÑÁªôÂÆöÊï∞ÊçÆ„ÄÇÊàë‰ª¨ÂèØËÉΩÈúÄË¶ÅÊüêÁßçÁÆóÊ≥ïÂ∏ÆÂä©Êàë‰ª¨ÂØªÊâæ‰∏ÄÁßçÁªìÊûÑ„ÄÇÂõæ‰∏äÁöÑÊï∞ÊçÆÁúãËµ∑Êù•ÂèØ‰ª•ÂàÜÊàê‰∏§‰∏™ÂàÜÂºÄÁöÑÁÇπÈõÜÔºàÁß∞‰∏∫Á∞áÔºâÔºå‰∏Ä‰∏™ËÉΩÂ§üÊâæÂà∞ÊàëÂúàÂá∫ÁöÑËøô‰∫õÁÇπÈõÜÁöÑÁÆóÊ≥ïÔºåÂ∞±Ë¢´Áß∞‰∏∫ËÅöÁ±ªÁÆóÊ≥ï„ÄÇ ËøôÂ∞ÜÊòØÊàë‰ª¨‰ªãÁªçÁöÑÁ¨¨‰∏Ä‰∏™ÈùûÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï„ÄÇÂΩìÁÑ∂ÔºåÊ≠§ÂêéÊàë‰ª¨ËøòÂ∞ÜÊèêÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑÈùûÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåÂÆÉ‰ª¨ÂèØ‰ª•‰∏∫Êàë‰ª¨ÊâæÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑÁªìÊûÑÊàñËÄÖÂÖ∂‰ªñÁöÑ‰∏Ä‰∫õÊ®°ÂºèÔºåËÄå‰∏çÂè™ÊòØÁ∞á„ÄÇ Êàë‰ª¨Â∞ÜÂÖà‰ªãÁªçËÅöÁ±ªÁÆóÊ≥ï„ÄÇÊ≠§ÂêéÔºåÊàë‰ª¨Â∞ÜÈôÜÁª≠‰ªãÁªçÂÖ∂‰ªñÁÆóÊ≥ï„ÄÇÈÇ£‰πàËÅöÁ±ªÁÆóÊ≥ï‰∏ÄËà¨Áî®Êù•ÂÅö‰ªÄ‰πàÂë¢Ôºü Âú®ËøôÈó®ËØæÁ®ãÁöÑÊó©‰∫õÊó∂ÂÄôÔºåÊàëÊõæÁªèÂàó‰∏æËøá‰∏Ä‰∫õÂ∫îÁî®ÔºöÊØîÂ¶ÇÂ∏ÇÂú∫ÂàÜÂâ≤„ÄÇ‰πüËÆ∏‰Ω†Âú®Êï∞ÊçÆÂ∫ì‰∏≠Â≠òÂÇ®‰∫ÜËÆ∏Â§öÂÆ¢Êà∑ÁöÑ‰ø°ÊÅØÔºåËÄå‰Ω†Â∏åÊúõÂ∞Ü‰ªñ‰ª¨ÂàÜÊàê‰∏çÂêåÁöÑÂÆ¢Êà∑Áæ§ÔºåËøôÊ†∑‰Ω†ÂèØ‰ª•ÂØπ‰∏çÂêåÁ±ªÂûãÁöÑÂÆ¢Êà∑ÂàÜÂà´ÈîÄÂîÆ‰∫ßÂìÅÊàñËÄÖÂàÜÂà´Êèê‰æõÊõ¥ÈÄÇÂêàÁöÑÊúçÂä°„ÄÇÁ§æ‰∫§ÁΩëÁªúÂàÜÊûêÔºö‰∫ãÂÆû‰∏äÊúâËÆ∏Â§öÁ†îÁ©∂‰∫∫ÂëòÊ≠£Âú®Á†îÁ©∂ËøôÊ†∑‰∏Ä‰∫õÂÜÖÂÆπÔºå‰ªñ‰ª¨ÂÖ≥Ê≥®‰∏ÄÁæ§‰∫∫ÔºåÂÖ≥Ê≥®Á§æ‰∫§ÁΩëÁªúÔºå‰æãÂ¶ÇFacebookÔºåGoogle+ÔºåÊàñËÄÖÊòØÂÖ∂‰ªñÁöÑ‰∏Ä‰∫õ‰ø°ÊÅØÔºåÊØîÂ¶ÇËØ¥Ôºö‰Ω†ÁªèÂ∏∏Ë∑üÂì™‰∫õ‰∫∫ËÅîÁ≥ªÔºåËÄåËøô‰∫õ‰∫∫ÂèàÁªèÂ∏∏ÁªôÂì™‰∫õ‰∫∫ÂèëÈÇÆ‰ª∂ÔºåÁî±Ê≠§ÊâæÂà∞ÂÖ≥Á≥ªÂØÜÂàáÁöÑ‰∫∫Áæ§„ÄÇÂõ†Ê≠§ÔºåËøôÂèØËÉΩÈúÄË¶ÅÂè¶‰∏Ä‰∏™ËÅöÁ±ªÁÆóÊ≥ïÔºå‰Ω†Â∏åÊúõÁî®ÂÆÉÂèëÁé∞Á§æ‰∫§ÁΩëÁªú‰∏≠ÂÖ≥Á≥ªÂØÜÂàáÁöÑÊúãÂèã„ÄÇÊàëÊúâ‰∏Ä‰∏™ÊúãÂèãÊ≠£Âú®Á†îÁ©∂Ëøô‰∏™ÈóÆÈ¢òÔºå‰ªñÂ∏åÊúõ‰ΩøÁî®ËÅöÁ±ªÁÆóÊ≥ïÊù•Êõ¥Â•ΩÁöÑÁªÑÁªáËÆ°ÁÆóÊú∫ÈõÜÁæ§ÔºåÊàñËÄÖÊõ¥Â•ΩÁöÑÁÆ°ÁêÜÊï∞ÊçÆ‰∏≠ÂøÉ„ÄÇÂõ†‰∏∫Â¶ÇÊûú‰Ω†Áü•ÈÅìÊï∞ÊçÆ‰∏≠ÂøÉ‰∏≠ÔºåÈÇ£‰∫õËÆ°ÁÆóÊú∫ÁªèÂ∏∏Âçè‰ΩúÂ∑•‰Ωú„ÄÇÈÇ£‰πàÔºå‰Ω†ÂèØ‰ª•ÈáçÊñ∞ÂàÜÈÖçËµÑÊ∫êÔºåÈáçÊñ∞Â∏ÉÂ±ÄÁΩëÁªú„ÄÇÁî±Ê≠§‰ºòÂåñÊï∞ÊçÆ‰∏≠ÂøÉÔºå‰ºòÂåñÊï∞ÊçÆÈÄö‰ø°„ÄÇ ÊúÄÂêéÔºåÊàëÂÆûÈôÖ‰∏äËøòÂú®Á†îÁ©∂Â¶Ç‰ΩïÂà©Áî®ËÅöÁ±ªÁÆóÊ≥ï‰∫ÜËß£ÊòüÁ≥ªÁöÑÂΩ¢Êàê„ÄÇÁÑ∂ÂêéÁî®Ëøô‰∏™Áü•ËØÜÔºå‰∫ÜËß£‰∏Ä‰∫õÂ§©ÊñáÂ≠¶‰∏äÁöÑÁªÜËäÇÈóÆÈ¢ò„ÄÇÂ•ΩÁöÑÔºåËøôÂ∞±ÊòØËÅöÁ±ªÁÆóÊ≥ï„ÄÇËøôÂ∞ÜÊòØÊàë‰ª¨‰ªãÁªçÁöÑÁ¨¨‰∏Ä‰∏™ÈùûÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï„ÄÇÂú®‰∏ã‰∏Ä‰∏™ËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨Â∞ÜÂºÄÂßã‰ªãÁªç‰∏Ä‰∏™ÂÖ∑‰ΩìÁöÑËÅöÁ±ªÁÆóÊ≥ï„ÄÇ K-ÂùáÂÄºÁÆóÊ≥ïÂèÇËÄÉËßÜÈ¢ë: 13 - 2 - K-Means Algorithm (13 min).mkv K-ÂùáÂÄºÊòØÊúÄÊôÆÂèäÁöÑËÅöÁ±ªÁÆóÊ≥ïÔºåÁÆóÊ≥ïÊé•Âèó‰∏Ä‰∏™Êú™Ê†áËÆ∞ÁöÑÊï∞ÊçÆÈõÜÔºåÁÑ∂ÂêéÂ∞ÜÊï∞ÊçÆËÅöÁ±ªÊàê‰∏çÂêåÁöÑÁªÑ„ÄÇ K-ÂùáÂÄºÊòØ‰∏Ä‰∏™Ëø≠‰ª£ÁÆóÊ≥ïÔºåÂÅáËÆæÊàë‰ª¨ÊÉ≥Ë¶ÅÂ∞ÜÊï∞ÊçÆËÅöÁ±ªÊàên‰∏™ÁªÑÔºåÂÖ∂ÊñπÊ≥ï‰∏∫: È¶ñÂÖàÈÄâÊã©$K$‰∏™ÈöèÊú∫ÁöÑÁÇπÔºåÁß∞‰∏∫ËÅöÁ±ª‰∏≠ÂøÉÔºàcluster centroidsÔºâÔºõ ÂØπ‰∫éÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÊØè‰∏Ä‰∏™Êï∞ÊçÆÔºåÊåâÁÖßË∑ùÁ¶ª$K$‰∏™‰∏≠ÂøÉÁÇπÁöÑË∑ùÁ¶ªÔºåÂ∞ÜÂÖ∂‰∏éË∑ùÁ¶ªÊúÄËøëÁöÑ‰∏≠ÂøÉÁÇπÂÖ≥ËÅîËµ∑Êù•Ôºå‰∏éÂêå‰∏Ä‰∏™‰∏≠ÂøÉÁÇπÂÖ≥ËÅîÁöÑÊâÄÊúâÁÇπËÅöÊàê‰∏ÄÁ±ª„ÄÇ ËÆ°ÁÆóÊØè‰∏Ä‰∏™ÁªÑÁöÑÂπ≥ÂùáÂÄºÔºåÂ∞ÜËØ•ÁªÑÊâÄÂÖ≥ËÅîÁöÑ‰∏≠ÂøÉÁÇπÁßªÂä®Âà∞Âπ≥ÂùáÂÄºÁöÑ‰ΩçÁΩÆ„ÄÇ ÈáçÂ§çÊ≠•È™§2-4Áõ¥Ëá≥‰∏≠ÂøÉÁÇπ‰∏çÂÜçÂèòÂåñ„ÄÇ ‰∏ãÈù¢ÊòØ‰∏Ä‰∏™ËÅöÁ±ªÁ§∫‰æãÔºö Ëø≠‰ª£ 1 Ê¨° Ëø≠‰ª£ 3 Ê¨° Ëø≠‰ª£ 10 Ê¨° Áî®$Œº^1$,$Œº^2$,‚Ä¶,$Œº^k$ Êù•Ë°®Á§∫ËÅöÁ±ª‰∏≠ÂøÉÔºåÁî®$c^{(1)}$,$c^{(2)}$,‚Ä¶,$c^{(m)}$Êù•Â≠òÂÇ®‰∏éÁ¨¨$i$‰∏™ÂÆû‰æãÊï∞ÊçÆÊúÄËøëÁöÑËÅöÁ±ª‰∏≠ÂøÉÁöÑÁ¥¢ÂºïÔºåK-ÂùáÂÄºÁÆóÊ≥ïÁöÑ‰º™‰ª£Á†ÅÂ¶Ç‰∏ãÔºö 1234567891011Repeat &#123;for i = 1 to mc(i) := index (form 1 to K) of cluster centroid closest to x(i)for k = 1 to KŒºk := average (mean) of points assigned to cluster k&#125; ÁÆóÊ≥ïÂàÜ‰∏∫‰∏§‰∏™Ê≠•È™§ÔºåÁ¨¨‰∏Ä‰∏™forÂæ™ÁéØÊòØËµãÂÄºÊ≠•È™§ÔºåÂç≥ÔºöÂØπ‰∫éÊØè‰∏Ä‰∏™Ê†∑‰æã$i$ÔºåËÆ°ÁÆóÂÖ∂Â∫îËØ•Â±û‰∫éÁöÑÁ±ª„ÄÇÁ¨¨‰∫å‰∏™forÂæ™ÁéØÊòØËÅöÁ±ª‰∏≠ÂøÉÁöÑÁßªÂä®ÔºåÂç≥ÔºöÂØπ‰∫éÊØè‰∏Ä‰∏™Á±ª$K$ÔºåÈáçÊñ∞ËÆ°ÁÆóËØ•Á±ªÁöÑË¥®ÂøÉ„ÄÇ K-ÂùáÂÄºÁÆóÊ≥ï‰πüÂèØ‰ª•Âæà‰æøÂà©Âú∞Áî®‰∫éÂ∞ÜÊï∞ÊçÆÂàÜ‰∏∫ËÆ∏Â§ö‰∏çÂêåÁªÑÔºåÂç≥‰ΩøÂú®Ê≤°ÊúâÈùûÂ∏∏ÊòéÊòæÂå∫ÂàÜÁöÑÁªÑÁæ§ÁöÑÊÉÖÂÜµ‰∏ã‰πüÂèØ‰ª•„ÄÇ‰∏ãÂõæÊâÄÁ§∫ÁöÑÊï∞ÊçÆÈõÜÂåÖÂê´Ë∫´È´òÂíå‰ΩìÈáç‰∏§È°πÁâπÂæÅÊûÑÊàêÁöÑÔºåÂà©Áî®K-ÂùáÂÄºÁÆóÊ≥ïÂ∞ÜÊï∞ÊçÆÂàÜ‰∏∫‰∏âÁ±ªÔºåÁî®‰∫éÂ∏ÆÂä©Á°ÆÂÆöÂ∞ÜË¶ÅÁîü‰∫ßÁöÑT-ÊÅ§Ë°´ÁöÑ‰∏âÁßçÂ∞∫ÂØ∏„ÄÇ ‰ºòÂåñÁõÆÊ†áÂèÇËÄÉËßÜÈ¢ë: 13 - 3 - Optimization Objective (7 min).mkv K-ÂùáÂÄºÊúÄÂ∞èÂåñÈóÆÈ¢òÔºåÊòØË¶ÅÊúÄÂ∞èÂåñÊâÄÊúâÁöÑÊï∞ÊçÆÁÇπ‰∏éÂÖ∂ÊâÄÂÖ≥ËÅîÁöÑËÅöÁ±ª‰∏≠ÂøÉÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ª‰πãÂíåÔºåÂõ†Ê≠§K-ÂùáÂÄºÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºàÂèàÁß∞Áï∏ÂèòÂáΩÊï∞ Distortion functionÔºâ‰∏∫ $$J(c^{(1)},...,c^{(m)},Œº_1,...,Œº_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{\left( i\right) }-\mu_{c^{(i)}}\right\| ^{2}$$ ÂÖ∂‰∏≠${{\mu }_{{{c}^{(i)}}}}$‰ª£Ë°®‰∏é${{x}^{(i)}}$ÊúÄËøëÁöÑËÅöÁ±ª‰∏≠ÂøÉÁÇπ„ÄÇÊàë‰ª¨ÁöÑÁöÑ‰ºòÂåñÁõÆÊ†á‰æøÊòØÊâæÂá∫‰ΩøÂæó‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÁöÑ $c^{(1)}$,$c^{(2)}$,...,$c^{(m)}$Âíå$Œº^1$,$Œº^2$,...,$Œº^k$ ÂõûÈ°æÂàöÊâçÁªôÂá∫ÁöÑ:K-ÂùáÂÄºËø≠‰ª£ÁÆóÊ≥ïÔºåÊàë‰ª¨Áü•ÈÅìÔºåÁ¨¨‰∏Ä‰∏™Âæ™ÁéØÊòØÁî®‰∫éÂáèÂ∞è$c^{(i)}$ÂºïËµ∑ÁöÑ‰ª£‰ª∑ÔºåËÄåÁ¨¨‰∫å‰∏™Âæ™ÁéØÂàôÊòØÁî®‰∫éÂáèÂ∞è${{\mu }_{i}}$ÂºïËµ∑ÁöÑ‰ª£‰ª∑„ÄÇËø≠‰ª£ÁöÑËøáÁ®ã‰∏ÄÂÆö‰ºöÊòØÊØè‰∏ÄÊ¨°Ëø≠‰ª£ÈÉΩÂú®ÂáèÂ∞è‰ª£‰ª∑ÂáΩÊï∞Ôºå‰∏çÁÑ∂‰æøÊòØÂá∫Áé∞‰∫ÜÈîôËØØ„ÄÇ ÈöèÊú∫ÂàùÂßãÂåñÂèÇËÄÉËßÜÈ¢ë: 13 - 4 - Random Initialization (8 min).mkv Âú®ËøêË°åK-ÂùáÂÄºÁÆóÊ≥ïÁöÑ‰πãÂâçÔºåÊàë‰ª¨È¶ñÂÖàË¶ÅÈöèÊú∫ÂàùÂßãÂåñÊâÄÊúâÁöÑËÅöÁ±ª‰∏≠ÂøÉÁÇπÔºå‰∏ãÈù¢‰ªãÁªçÊÄéÊ†∑ÂÅöÔºö Êàë‰ª¨Â∫îËØ•ÈÄâÊã©$K&lt;m$ÔºåÂç≥ËÅöÁ±ª‰∏≠ÂøÉÁÇπÁöÑ‰∏™Êï∞Ë¶ÅÂ∞è‰∫éÊâÄÊúâËÆ≠ÁªÉÈõÜÂÆû‰æãÁöÑÊï∞Èáè ÈöèÊú∫ÈÄâÊã©$K$‰∏™ËÆ≠ÁªÉÂÆû‰æãÔºåÁÑ∂Âêé‰ª§$K$‰∏™ËÅöÁ±ª‰∏≠ÂøÉÂàÜÂà´‰∏éËøô$K$‰∏™ËÆ≠ÁªÉÂÆû‰æãÁõ∏Á≠â K-ÂùáÂÄºÁöÑ‰∏Ä‰∏™ÈóÆÈ¢òÂú®‰∫éÔºåÂÆÉÊúâÂèØËÉΩ‰ºöÂÅúÁïôÂú®‰∏Ä‰∏™Â±ÄÈÉ®ÊúÄÂ∞èÂÄºÂ§ÑÔºåËÄåËøôÂèñÂÜ≥‰∫éÂàùÂßãÂåñÁöÑÊÉÖÂÜµ„ÄÇ ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÈÄöÂ∏∏ÈúÄË¶ÅÂ§öÊ¨°ËøêË°åK-ÂùáÂÄºÁÆóÊ≥ïÔºåÊØè‰∏ÄÊ¨°ÈÉΩÈáçÊñ∞ËøõË°åÈöèÊú∫ÂàùÂßãÂåñÔºåÊúÄÂêéÂÜçÊØîËæÉÂ§öÊ¨°ËøêË°åK-ÂùáÂÄºÁöÑÁªìÊûúÔºåÈÄâÊã©‰ª£‰ª∑ÂáΩÊï∞ÊúÄÂ∞èÁöÑÁªìÊûú„ÄÇËøôÁßçÊñπÊ≥ïÂú®$K$ËæÉÂ∞èÁöÑÊó∂ÂÄôÔºà2‚Äì10ÔºâËøòÊòØÂèØË°åÁöÑÔºå‰ΩÜÊòØÂ¶ÇÊûú$K$ËæÉÂ§ßÔºåËøô‰πàÂÅö‰πüÂèØËÉΩ‰∏ç‰ºöÊúâÊòéÊòæÂú∞ÊîπÂñÑ„ÄÇ ÈÄâÊã©ËÅöÁ±ªÊï∞ÂèÇËÄÉËßÜÈ¢ë: 13 - 5 - Choosing the Number of Clusters (8 min).mkv Ê≤°ÊúâÊâÄË∞ìÊúÄÂ•ΩÁöÑÈÄâÊã©ËÅöÁ±ªÊï∞ÁöÑÊñπÊ≥ïÔºåÈÄöÂ∏∏ÊòØÈúÄË¶ÅÊ†πÊçÆ‰∏çÂêåÁöÑÈóÆÈ¢òÔºå‰∫∫Â∑•ËøõË°åÈÄâÊã©ÁöÑ„ÄÇÈÄâÊã©ÁöÑÊó∂ÂÄôÊÄùËÄÉÊàë‰ª¨ËøêÁî®K-ÂùáÂÄºÁÆóÊ≥ïËÅöÁ±ªÁöÑÂä®Êú∫ÊòØ‰ªÄ‰πàÔºåÁÑ∂ÂêéÈÄâÊã©ËÉΩÊúÄÂ•ΩÊúçÂä°‰∫éËØ•ÁõÆÁöÑÊ†áËÅöÁ±ªÊï∞„ÄÇ ÂΩì‰∫∫‰ª¨Âú®ËÆ®ËÆ∫ÔºåÈÄâÊã©ËÅöÁ±ªÊï∞ÁõÆÁöÑÊñπÊ≥ïÊó∂ÔºåÊúâ‰∏Ä‰∏™ÂèØËÉΩ‰ºöË∞àÂèäÁöÑÊñπÊ≥ïÂè´‰Ωú‚ÄúËÇòÈÉ®Ê≥ïÂàô‚Äù„ÄÇÂÖ≥‰∫é‚ÄúËÇòÈÉ®Ê≥ïÂàô‚ÄùÔºåÊàë‰ª¨ÊâÄÈúÄË¶ÅÂÅöÁöÑÊòØÊîπÂèò$K$ÂÄºÔºå‰πüÂ∞±ÊòØËÅöÁ±ªÁ±ªÂà´Êï∞ÁõÆÁöÑÊÄªÊï∞„ÄÇÊàë‰ª¨Áî®‰∏Ä‰∏™ËÅöÁ±ªÊù•ËøêË°åKÂùáÂÄºËÅöÁ±ªÊñπÊ≥ï„ÄÇËøôÂ∞±ÊÑèÂë≥ÁùÄÔºåÊâÄÊúâÁöÑÊï∞ÊçÆÈÉΩ‰ºöÂàÜÂà∞‰∏Ä‰∏™ËÅöÁ±ªÈáåÔºåÁÑ∂ÂêéËÆ°ÁÆóÊàêÊú¨ÂáΩÊï∞ÊàñËÄÖËÆ°ÁÆóÁï∏ÂèòÂáΩÊï∞$J$„ÄÇ$K$‰ª£Ë°®ËÅöÁ±ªÊï∞Â≠ó„ÄÇ Êàë‰ª¨ÂèØËÉΩ‰ºöÂæóÂà∞‰∏ÄÊù°Á±ª‰ºº‰∫éËøôÊ†∑ÁöÑÊõ≤Á∫ø„ÄÇÂÉè‰∏Ä‰∏™‰∫∫ÁöÑËÇòÈÉ®„ÄÇËøôÂ∞±ÊòØ‚ÄúËÇòÈÉ®Ê≥ïÂàô‚ÄùÊâÄÂÅöÁöÑÔºåËÆ©Êàë‰ª¨Êù•ÁúãËøôÊ†∑‰∏Ä‰∏™ÂõæÔºåÁúãËµ∑Êù•Â∞±Â•ΩÂÉèÊúâ‰∏Ä‰∏™ÂæàÊ∏ÖÊ•öÁöÑËÇòÂú®ÈÇ£ÂÑø„ÄÇÂ•ΩÂÉè‰∫∫ÁöÑÊâãËáÇÔºåÂ¶ÇÊûú‰Ω†‰º∏Âá∫‰Ω†ÁöÑËÉ≥ËÜäÔºåÈÇ£‰πàËøôÂ∞±ÊòØ‰Ω†ÁöÑËÇ©ÂÖ≥ËäÇ„ÄÅËÇòÂÖ≥ËäÇ„ÄÅÊâã„ÄÇËøôÂ∞±ÊòØ‚ÄúËÇòÈÉ®Ê≥ïÂàô‚Äù„ÄÇ‰Ω†‰ºöÂèëÁé∞ËøôÁßçÊ®°ÂºèÔºåÂÆÉÁöÑÁï∏ÂèòÂÄº‰ºöËøÖÈÄü‰∏ãÈôçÔºå‰ªé1Âà∞2Ôºå‰ªé2Âà∞3‰πãÂêéÔºå‰Ω†‰ºöÂú®3ÁöÑÊó∂ÂÄôËææÂà∞‰∏Ä‰∏™ËÇòÁÇπ„ÄÇÂú®Ê≠§‰πãÂêéÔºåÁï∏ÂèòÂÄºÂ∞±‰∏ãÈôçÁöÑÈùûÂ∏∏ÊÖ¢ÔºåÁúãËµ∑Êù•Â∞±ÂÉè‰ΩøÁî®3‰∏™ËÅöÁ±ªÊù•ËøõË°åËÅöÁ±ªÊòØÊ≠£Á°ÆÁöÑÔºåËøôÊòØÂõ†‰∏∫ÈÇ£‰∏™ÁÇπÊòØÊõ≤Á∫øÁöÑËÇòÁÇπÔºåÁï∏ÂèòÂÄº‰∏ãÈôçÂæóÂæàÂø´Ôºå$K=3$‰πãÂêéÂ∞±‰∏ãÈôçÂæóÂæàÊÖ¢ÔºåÈÇ£‰πàÊàë‰ª¨Â∞±ÈÄâ$K=3$„ÄÇÂΩì‰Ω†Â∫îÁî®‚ÄúËÇòÈÉ®Ê≥ïÂàô‚ÄùÁöÑÊó∂ÂÄôÔºåÂ¶ÇÊûú‰Ω†ÂæóÂà∞‰∫Ü‰∏Ä‰∏™ÂÉè‰∏äÈù¢ËøôÊ†∑ÁöÑÂõæÔºåÈÇ£‰πàËøôÂ∞ÜÊòØ‰∏ÄÁßçÁî®Êù•ÈÄâÊã©ËÅöÁ±ª‰∏™Êï∞ÁöÑÂêàÁêÜÊñπÊ≥ï„ÄÇ ‰æãÂ¶ÇÔºåÊàë‰ª¨ÁöÑ T-ÊÅ§Âà∂ÈÄ†‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨Ë¶ÅÂ∞ÜÁî®Êà∑ÊåâÁÖßË∫´ÊùêËÅöÁ±ªÔºåÊàë‰ª¨ÂèØ‰ª•ÂàÜÊàê3‰∏™Â∞∫ÂØ∏:$S,M,L$Ôºå‰πüÂèØ‰ª•ÂàÜÊàê5‰∏™Â∞∫ÂØ∏$XS,S,M,L,XL$ÔºåËøôÊ†∑ÁöÑÈÄâÊã©ÊòØÂª∫Á´ãÂú®ÂõûÁ≠î‚ÄúËÅöÁ±ªÂêéÊàë‰ª¨Âà∂ÈÄ†ÁöÑT-ÊÅ§ÊòØÂê¶ËÉΩËæÉÂ•ΩÂú∞ÈÄÇÂêàÊàë‰ª¨ÁöÑÂÆ¢Êà∑‚ÄùËøô‰∏™ÈóÆÈ¢òÁöÑÂü∫Á°Ä‰∏ä‰ΩúÂá∫ÁöÑ„ÄÇËÅöÁ±ªÂèÇËÄÉËµÑÊñôÔºö1.Áõ∏‰ººÂ∫¶/Ë∑ùÁ¶ªËÆ°ÁÆóÊñπÊ≥ïÊÄªÁªì(1). ÈóµÂèØÂ§´ÊñØÂü∫Ë∑ùÁ¶ªMinkowskiÔºàÂÖ∂‰∏≠Ê¨ßÂºèË∑ùÁ¶ªÔºö$p=2$)$dist(X,Y)={{\left( {{\sum\limits_{i=1}^{n}{\left| {{x}_{i}}-{{y}_{i}} \right|}}^{p}} \right)}^{\frac{1}{p}}}$ (2). Êù∞Âç°Âæ∑Áõ∏‰ººÁ≥ªÊï∞(Jaccard)Ôºö $J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}$ (3). ‰ΩôÂº¶Áõ∏‰ººÂ∫¶(cosine similarity)Ôºö $n$Áª¥ÂêëÈáè$x$Âíå$y$ÁöÑÂ§πËßíËÆ∞ÂÅö$\theta$ÔºåÊ†πÊçÆ‰ΩôÂº¶ÂÆöÁêÜÔºåÂÖ∂‰ΩôÂº¶ÂÄº‰∏∫Ôºö $cos (\theta )=\frac{{{x}^{T}}y}{\left|x \right|\cdot \left| y \right|}=\frac{\sum\limits_{i=1}^{n}{{{x}_{i}}{{y}_{i}}}}{\sqrt{\sum\limits_{i=1}^{n}{{{x}_{i}}^{2}}}\sqrt{\sum\limits_{i=1}^{n}{{{y}_{i}}^{2}}}}$ (4). PearsonÁöÆÂ∞îÈÄäÁõ∏ÂÖ≥Á≥ªÊï∞Ôºö${{\rho }_{XY}}=\frac{\operatorname{cov}(X,Y)}{{{\sigma }_{X}}{{\sigma }_{Y}}}=\frac{E[(X-{{\mu }_{X}})(Y-{{\mu }_{Y}})]}{{{\sigma }_{X}}{{\sigma }_{Y}}}=\frac{\sum\limits_{i=1}^{n}{(x-{{\mu }_{X}})(y-{{\mu }_{Y}})}}{\sqrt{\sum\limits_{i=1}^{n}{{{(x-{{\mu }_{X}})}^{2}}}}\sqrt{\sum\limits_{i=1}^{n}{{{(y-{{\mu }_{Y}})}^{2}}}}}$ PearsonÁõ∏ÂÖ≥Á≥ªÊï∞Âç≥Â∞Ü$x$„ÄÅ$y$ÂùêÊ†áÂêëÈáèÂêÑËá™Âπ≥ÁßªÂà∞ÂéüÁÇπÂêéÁöÑÂ§πËßí‰ΩôÂº¶„ÄÇ 2.ËÅöÁ±ªÁöÑË°°ÈáèÊåáÊ†á (1). Âùá‰∏ÄÊÄßÔºö$p$ Á±ª‰ºº‰∫éÁ≤æÁ°ÆÁéáÔºå‰∏Ä‰∏™Á∞á‰∏≠Âè™ÂåÖÂê´‰∏Ä‰∏™Á±ªÂà´ÁöÑÊ†∑Êú¨ÔºåÂàôÊª°Ë∂≥Âùá‰∏ÄÊÄß„ÄÇÂÖ∂ÂÆû‰πüÂèØ‰ª•ËÆ§‰∏∫Â∞±ÊòØÊ≠£Á°ÆÁéá(ÊØè‰∏™ ËÅöÁ∞á‰∏≠Ê≠£Á°ÆÂàÜÁ±ªÁöÑÊ†∑Êú¨Êï∞Âç†ËØ•ËÅöÁ∞áÊÄªÊ†∑Êú¨Êï∞ÁöÑÊØî‰æãÂíå) (2). ÂÆåÊï¥ÊÄßÔºö$r$ Á±ª‰ºº‰∫éÂè¨ÂõûÁéáÔºåÂêåÁ±ªÂà´Ê†∑Êú¨Ë¢´ÂΩíÁ±ªÂà∞Áõ∏ÂêåÁ∞á‰∏≠ÔºåÂàôÊª°Ë∂≥ÂÆåÊï¥ÊÄß;ÊØè‰∏™ËÅöÁ∞á‰∏≠Ê≠£Á°ÆÂàÜÁ±ªÁöÑÊ†∑Êú¨Êï∞Âç†ËØ•Á±ªÂûãÁöÑÊÄªÊ†∑Êú¨Êï∞ÊØî‰æãÁöÑÂíå (3). V-measure: Âùá‰∏ÄÊÄßÂíåÂÆåÊï¥ÊÄßÁöÑÂä†ÊùÉÂπ≥Âùá $V = \frac{(1+\beta^2)*pr}{\beta^2*p+r}$ (4). ËΩÆÂªìÁ≥ªÊï∞ Ê†∑Êú¨$i$ÁöÑËΩÆÂªìÁ≥ªÊï∞Ôºö$s(i)$ Á∞áÂÜÖ‰∏çÁõ∏‰ººÂ∫¶:ËÆ°ÁÆóÊ†∑Êú¨$i$Âà∞ÂêåÁ∞áÂÖ∂ÂÆÉÊ†∑Êú¨ÁöÑÂπ≥ÂùáË∑ùÁ¶ª‰∏∫$a(i)$ÔºåÂ∫îÂ∞ΩÂèØËÉΩÂ∞è„ÄÇ Á∞áÈó¥‰∏çÁõ∏‰ººÂ∫¶:ËÆ°ÁÆóÊ†∑Êú¨$i$Âà∞ÂÖ∂ÂÆÉÁ∞á$C_j$ÁöÑÊâÄÊúâÊ†∑Êú¨ÁöÑÂπ≥ÂùáË∑ùÁ¶ª$b_{ij}$ÔºåÂ∫îÂ∞ΩÂèØËÉΩÂ§ß„ÄÇ ËΩÆÂªìÁ≥ªÊï∞Ôºö$s(i)$ÂÄºË∂äÊé•Ëøë1Ë°®Á§∫Ê†∑Êú¨$i$ËÅöÁ±ªË∂äÂêàÁêÜÔºåË∂äÊé•Ëøë-1ÔºåË°®Á§∫Ê†∑Êú¨$i$Â∫îËØ•ÂàÜÁ±ªÂà∞ Âè¶Â§ñÁöÑÁ∞á‰∏≠ÔºåËøë‰ºº‰∏∫0ÔºåË°®Á§∫Ê†∑Êú¨$i$Â∫îËØ•Âú®ËæπÁïå‰∏ä;ÊâÄÊúâÊ†∑Êú¨ÁöÑ$s(i)$ÁöÑÂùáÂÄºË¢´Êàê‰∏∫ËÅöÁ±ªÁªìÊûúÁöÑËΩÆÂªìÁ≥ªÊï∞„ÄÇ$s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\}}$ (5). ARI Êï∞ÊçÆÈõÜ$S$ÂÖ±Êúâ$N$‰∏™ÂÖÉÁ¥†Ôºå ‰∏§‰∏™ËÅöÁ±ªÁªìÊûúÂàÜÂà´ÊòØÔºö $X=\{{{X}_{1}},{{X}_{2}},...,{{X}_{r}}\},Y=\{{{Y}_{1}},{{Y}_{2}},...,{{Y}_{s}}\}$ $X$Âíå$Y$ÁöÑÂÖÉÁ¥†‰∏™Êï∞‰∏∫Ôºö $a=\{{{a}_{1}},{{a}_{2}},...,{{a}_{r}}\},b=\{{{b}_{1}},{{b}_{2}},...,{{b}_{s}}\}$ ËÆ∞Ôºö${{n}_{ij}}=\left| {{X}_{i}}\cap {{Y}_{i}} \right|$ $ARI=\frac{\sum\limits_{i,j}{C_{{{n}_{ij}}}^{2}}-\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}{\frac{1}{2}\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)+\left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]-\left[ \left( \sum\limits_{i}{C_{{{a}_{i}}}^{2}} \right)\cdot \left( \sum\limits_{i}{C_{{{b}_{i}}}^{2}} \right) \right]/C_{n}^{2}}$ ÂçÅÂõõ„ÄÅÈôçÁª¥(Dimensionality Reduction)Âä®Êú∫‰∏ÄÔºöÊï∞ÊçÆÂéãÁº©ÂèÇËÄÉËßÜÈ¢ë: 14 - 1 - Motivation I_ Data Compression (10 min).mkv Ëøô‰∏™ËßÜÈ¢ëÔºåÊàëÊÉ≥ÂºÄÂßãË∞àËÆ∫Á¨¨‰∫åÁßçÁ±ªÂûãÁöÑÊó†ÁõëÁù£Â≠¶‰π†ÈóÆÈ¢òÔºåÁß∞‰∏∫ÈôçÁª¥„ÄÇÊúâÂá†‰∏™‰∏çÂêåÁöÑÁöÑÂéüÂõ†‰Ωø‰Ω†ÂèØËÉΩÊÉ≥Ë¶ÅÂÅöÈôçÁª¥„ÄÇ‰∏ÄÊòØÊï∞ÊçÆÂéãÁº©ÔºåÂêéÈù¢Êàë‰ª¨‰ºöÁúã‰∫Ü‰∏Ä‰∫õËßÜÈ¢ëÂêéÔºåÊï∞ÊçÆÂéãÁº©‰∏ç‰ªÖÂÖÅËÆ∏Êàë‰ª¨ÂéãÁº©Êï∞ÊçÆÔºåÂõ†ËÄå‰ΩøÁî®ËæÉÂ∞ëÁöÑËÆ°ÁÆóÊú∫ÂÜÖÂ≠òÊàñÁ£ÅÁõòÁ©∫Èó¥Ôºå‰ΩÜÂÆÉ‰πüËÆ©Êàë‰ª¨Âä†Âø´Êàë‰ª¨ÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇ ‰ΩÜÈ¶ñÂÖàÔºåËÆ©Êàë‰ª¨Ë∞àËÆ∫ÈôçÁª¥ÊòØ‰ªÄ‰πà„ÄÇ‰Ωú‰∏∫‰∏ÄÁßçÁîüÂä®ÁöÑ‰æãÂ≠êÔºåÊàë‰ª¨Êî∂ÈõÜÁöÑÊï∞ÊçÆÈõÜÔºåÊúâËÆ∏Â§öÔºåËÆ∏Â§öÁâπÂæÅÔºåÊàëÁªòÂà∂‰∏§‰∏™Âú®ËøôÈáå„ÄÇ ÂÅáËÆæÊàë‰ª¨Êú™Áü•‰∏§‰∏™ÁöÑÁâπÂæÅÔºö$x_1$:ÈïøÂ∫¶ÔºöÁî®ÂéòÁ±≥Ë°®Á§∫Ôºõ$x_2$ÔºöÊòØÁî®Ëã±ÂØ∏Ë°®Á§∫Âêå‰∏ÄÁâ©‰ΩìÁöÑÈïøÂ∫¶„ÄÇ ÊâÄ‰ª•ÔºåËøôÁªô‰∫ÜÊàë‰ª¨È´òÂ∫¶ÂÜó‰ΩôË°®Á§∫Ôºå‰πüËÆ∏‰∏çÊòØ‰∏§‰∏™ÂàÜÂºÄÁöÑÁâπÂæÅ$x_1$Âíå$x_2$ÔºåËøô‰∏§‰∏™Âü∫Êú¨ÁöÑÈïøÂ∫¶Â∫¶ÈáèÔºå‰πüËÆ∏Êàë‰ª¨ÊÉ≥Ë¶ÅÂÅöÁöÑÊòØÂáèÂ∞ëÊï∞ÊçÆÂà∞‰∏ÄÁª¥ÔºåÂè™Êúâ‰∏Ä‰∏™Êï∞ÊµãÈáèËøô‰∏™ÈïøÂ∫¶„ÄÇËøô‰∏™‰æãÂ≠ê‰ºº‰πéÊúâÁÇπÂÅö‰ΩúÔºåËøôÈáåÂéòÁ±≥Ëã±ÂØ∏ÁöÑ‰æãÂ≠êÂÆûÈôÖ‰∏ä‰∏çÊòØÈÇ£‰πà‰∏çÂàáÂÆûÈôÖÁöÑÔºå‰∏§ËÄÖÂπ∂Ê≤°Êúâ‰ªÄ‰πà‰∏çÂêå„ÄÇ Â∞ÜÊï∞ÊçÆ‰ªé‰∫åÁª¥ÈôçËá≥‰∏ÄÁª¥ÔºöÂÅá‰ΩøÊàë‰ª¨Ë¶ÅÈááÁî®‰∏§Áßç‰∏çÂêåÁöÑ‰ª™Âô®Êù•ÊµãÈáè‰∏Ä‰∫õ‰∏úË•øÁöÑÂ∞∫ÂØ∏ÔºåÂÖ∂‰∏≠‰∏Ä‰∏™‰ª™Âô®ÊµãÈáèÁªìÊûúÁöÑÂçï‰ΩçÊòØËã±ÂØ∏ÔºåÂè¶‰∏Ä‰∏™‰ª™Âô®ÊµãÈáèÁöÑÁªìÊûúÊòØÂéòÁ±≥ÔºåÊàë‰ª¨Â∏åÊúõÂ∞ÜÊµãÈáèÁöÑÁªìÊûú‰Ωú‰∏∫Êàë‰ª¨Êú∫Âô®Â≠¶‰π†ÁöÑÁâπÂæÅ„ÄÇÁé∞Âú®ÁöÑÈóÆÈ¢òÁöÑÊòØÔºå‰∏§Áßç‰ª™Âô®ÂØπÂêå‰∏Ä‰∏™‰∏úË•øÊµãÈáèÁöÑÁªìÊûú‰∏çÂÆåÂÖ®Áõ∏Á≠âÔºàÁî±‰∫éËØØÂ∑Æ„ÄÅÁ≤æÂ∫¶Á≠âÔºâÔºåËÄåÂ∞Ü‰∏§ËÄÖÈÉΩ‰Ωú‰∏∫ÁâπÂæÅÊúâ‰∫õÈáçÂ§çÔºåÂõ†ËÄåÔºåÊàë‰ª¨Â∏åÊúõÂ∞ÜËøô‰∏™‰∫åÁª¥ÁöÑÊï∞ÊçÆÈôçËá≥‰∏ÄÁª¥„ÄÇ ‰ªéËøô‰ª∂‰∫ãÊÉÖÊàëÁúãÂà∞ÁöÑ‰∏úË•øÂèëÁîüÂú®Â∑•‰∏ö‰∏äÁöÑ‰∫ã„ÄÇÂ¶ÇÊûú‰Ω†ÊúâÂá†Áôæ‰∏™ÊàñÊàêÂçÉ‰∏ä‰∏áÁöÑÁâπÂæÅÔºåÂÆÉÊòØÂÆÉËøôÂæÄÂæÄÂÆπÊòìÂ§±Âéª‰Ω†ÈúÄË¶ÅÁöÑÁâπÂæÅ„ÄÇÊúâÊó∂ÂèØËÉΩÊúâÂá†‰∏™‰∏çÂêåÁöÑÂ∑•Á®ãÂõ¢ÈòüÔºå‰πüËÆ∏‰∏Ä‰∏™Â∑•Á®ãÈòüÁªô‰Ω†‰∫åÁôæ‰∏™ÁâπÂæÅÔºåÁ¨¨‰∫åÂ∑•Á®ãÈòüÁªô‰Ω†Âè¶Â§ñ‰∏âÁôæ‰∏™ÁöÑÁâπÂæÅÔºåÁ¨¨‰∏âÂ∑•Á®ãÈòüÁªô‰Ω†‰∫îÁôæ‰∏™ÁâπÂæÅÔºå‰∏ÄÂçÉÂ§ö‰∏™ÁâπÂæÅÈÉΩÂú®‰∏ÄËµ∑ÔºåÂÆÉÂÆûÈôÖ‰∏ä‰ºöÂèòÂæóÈùûÂ∏∏Âõ∞ÈöæÔºåÂéªË∑üË∏™‰Ω†Áü•ÈÅìÁöÑÈÇ£‰∫õÁâπÂæÅÔºå‰Ω†‰ªéÈÇ£‰∫õÂ∑•Á®ãÈòüÂæóÂà∞ÁöÑ„ÄÇÂÖ∂ÂÆû‰∏çÊÉ≥ÊúâÈ´òÂ∫¶ÂÜó‰ΩôÁöÑÁâπÂæÅ‰∏ÄÊ†∑„ÄÇ Â§öÂπ¥Êàë‰∏ÄÁõ¥Âú®Á†îÁ©∂Áõ¥ÂçáÈ£ûÊú∫Ëá™Âä®È©æÈ©∂„ÄÇËØ∏Â¶ÇÊ≠§Á±ª„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥ÊµãÈáè‚Äî‚ÄîÂ¶ÇÊûú‰Ω†ÊÉ≥ÂÅöÔºå‰Ω†Áü•ÈÅìÔºåÂÅö‰∏Ä‰∏™Ë∞ÉÊü•ÊàñÂÅöËøô‰∫õ‰∏çÂêåÈ£ûË°åÂëòÁöÑÊµãËØï‚Äî‚Äî‰Ω†ÂèØËÉΩÊúâ‰∏Ä‰∏™ÁâπÂæÅÔºö$x_1$ÔºåËøô‰πüËÆ∏ÊòØ‰ªñ‰ª¨ÁöÑÊäÄËÉΩÔºàÁõ¥ÂçáÊú∫È£ûË°åÂëòÔºâÔºå‰πüËÆ∏$x_2$ÂèØËÉΩÊòØÈ£ûË°åÂëòÁöÑÁà±Â•Ω„ÄÇËøôÊòØË°®Á§∫‰ªñ‰ª¨ÊòØÂê¶ÂñúÊ¨¢È£ûË°åÔºå‰πüËÆ∏Ëøô‰∏§‰∏™ÁâπÂæÅÂ∞ÜÈ´òÂ∫¶Áõ∏ÂÖ≥„ÄÇ‰Ω†ÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÂèØËÉΩÊòØËøôÊù°Á∫¢Á∫øÁöÑÊñπÂêëÔºå‰∏çÂêåÁöÑÁâπÂæÅÔºåÂÜ≥ÂÆöÈ£ûË°åÂëòÁöÑËÉΩÂäõ„ÄÇ Â∞ÜÊï∞ÊçÆ‰ªé‰∏âÁª¥ÈôçËá≥‰∫åÁª¥ÔºöËøô‰∏™‰æãÂ≠ê‰∏≠Êàë‰ª¨Ë¶ÅÂ∞Ü‰∏Ä‰∏™‰∏âÁª¥ÁöÑÁâπÂæÅÂêëÈáèÈôçËá≥‰∏Ä‰∏™‰∫åÁª¥ÁöÑÁâπÂæÅÂêëÈáè„ÄÇËøáÁ®ãÊòØ‰∏é‰∏äÈù¢Á±ª‰ººÁöÑÔºåÊàë‰ª¨Â∞Ü‰∏âÁª¥ÂêëÈáèÊäïÂ∞ÑÂà∞‰∏Ä‰∏™‰∫åÁª¥ÁöÑÂπ≥Èù¢‰∏äÔºåÂº∫Ëø´‰ΩøÂæóÊâÄÊúâÁöÑÊï∞ÊçÆÈÉΩÂú®Âêå‰∏Ä‰∏™Âπ≥Èù¢‰∏äÔºåÈôçËá≥‰∫åÁª¥ÁöÑÁâπÂæÅÂêëÈáè„ÄÇ ËøôÊ†∑ÁöÑÂ§ÑÁêÜËøáÁ®ãÂèØ‰ª•Ë¢´Áî®‰∫éÊää‰ªª‰ΩïÁª¥Â∫¶ÁöÑÊï∞ÊçÆÈôçÂà∞‰ªª‰ΩïÊÉ≥Ë¶ÅÁöÑÁª¥Â∫¶Ôºå‰æãÂ¶ÇÂ∞Ü1000Áª¥ÁöÑÁâπÂæÅÈôçËá≥100Áª¥„ÄÇ Ê≠£Â¶ÇÊàë‰ª¨ÊâÄÁúãÂà∞ÁöÑÔºåÊúÄÂêéÔºåËøôÂ∞Ü‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰ΩøÊàë‰ª¨ÁöÑ‰∏Ä‰∫õÂ≠¶‰π†ÁÆóÊ≥ïËøêË°å‰πüËæÉÊôöÔºå‰ΩÜÊàë‰ª¨‰ºöÂú®‰ª•ÂêéÁöÑËßÜÈ¢ëÊèêÂà∞ÂÆÉ„ÄÇ Âä®Êú∫‰∫åÔºöÊï∞ÊçÆÂèØËßÜÂåñÂèÇËÄÉËßÜÈ¢ë: 14 - 2 - Motivation II_ Visualization (6 min).mkv Âú®ËÆ∏Â§öÂèäÂÖ∂Â≠¶‰π†ÈóÆÈ¢ò‰∏≠ÔºåÂ¶ÇÊûúÊàë‰ª¨ËÉΩÂ∞ÜÊï∞ÊçÆÂèØËßÜÂåñÔºåÊàë‰ª¨‰æøËÉΩÂØªÊâæÂà∞‰∏Ä‰∏™Êõ¥Â•ΩÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÈôçÁª¥ÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨„ÄÇ ÂÅá‰ΩøÊàë‰ª¨ÊúâÊúâÂÖ≥‰∫éËÆ∏Â§ö‰∏çÂêåÂõΩÂÆ∂ÁöÑÊï∞ÊçÆÔºåÊØè‰∏Ä‰∏™ÁâπÂæÅÂêëÈáèÈÉΩÊúâ50‰∏™ÁâπÂæÅÔºàÂ¶ÇGDPÔºå‰∫∫ÂùáGDPÔºåÂπ≥ÂùáÂØøÂëΩÁ≠âÔºâ„ÄÇÂ¶ÇÊûúË¶ÅÂ∞ÜËøô‰∏™50Áª¥ÁöÑÊï∞ÊçÆÂèØËßÜÂåñÊòØ‰∏çÂèØËÉΩÁöÑ„ÄÇ‰ΩøÁî®ÈôçÁª¥ÁöÑÊñπÊ≥ïÂ∞ÜÂÖ∂ÈôçËá≥2Áª¥ÔºåÊàë‰ª¨‰æøÂèØ‰ª•Â∞ÜÂÖ∂ÂèØËßÜÂåñ‰∫Ü„ÄÇ ËøôÊ†∑ÂÅöÁöÑÈóÆÈ¢òÂú®‰∫éÔºåÈôçÁª¥ÁöÑÁÆóÊ≥ïÂè™Ë¥üË¥£ÂáèÂ∞ëÁª¥Êï∞ÔºåÊñ∞‰∫ßÁîüÁöÑÁâπÂæÅÁöÑÊÑè‰πâÂ∞±ÂøÖÈ°ªÁî±Êàë‰ª¨Ëá™Â∑±ÂéªÂèëÁé∞‰∫Ü„ÄÇ ‰∏ªÊàêÂàÜÂàÜÊûêÈóÆÈ¢òÂèÇËÄÉËßÜÈ¢ë: 14 - 3 - Principal Component Analysis Problem Formulation (9 min). mkv ‰∏ªÊàêÂàÜÂàÜÊûê(PCA)ÊòØÊúÄÂ∏∏ËßÅÁöÑÈôçÁª¥ÁÆóÊ≥ï„ÄÇ Âú®PCA‰∏≠ÔºåÊàë‰ª¨Ë¶ÅÂÅöÁöÑÊòØÊâæÂà∞‰∏Ä‰∏™ÊñπÂêëÂêëÈáèÔºàVector directionÔºâÔºåÂΩìÊàë‰ª¨ÊääÊâÄÊúâÁöÑÊï∞ÊçÆÈÉΩÊäïÂ∞ÑÂà∞ËØ•ÂêëÈáè‰∏äÊó∂ÔºåÊàë‰ª¨Â∏åÊúõÊäïÂ∞ÑÂπ≥ÂùáÂùáÊñπËØØÂ∑ÆËÉΩÂ∞ΩÂèØËÉΩÂú∞Â∞è„ÄÇÊñπÂêëÂêëÈáèÊòØ‰∏Ä‰∏™ÁªèËøáÂéüÁÇπÁöÑÂêëÈáèÔºåËÄåÊäïÂ∞ÑËØØÂ∑ÆÊòØ‰ªéÁâπÂæÅÂêëÈáèÂêëËØ•ÊñπÂêëÂêëÈáè‰ΩúÂûÇÁ∫øÁöÑÈïøÂ∫¶„ÄÇ ‰∏ãÈù¢ÁªôÂá∫‰∏ªÊàêÂàÜÂàÜÊûêÈóÆÈ¢òÁöÑÊèèËø∞Ôºö ÈóÆÈ¢òÊòØË¶ÅÂ∞Ü$n$Áª¥Êï∞ÊçÆÈôçËá≥$k$Áª¥ÔºåÁõÆÊ†áÊòØÊâæÂà∞ÂêëÈáè$u^{(1)}$,$u^{(2)}$,‚Ä¶,$u^{(k)}$‰ΩøÂæóÊÄªÁöÑÊäïÂ∞ÑËØØÂ∑ÆÊúÄÂ∞è„ÄÇ‰∏ªÊàêÂàÜÂàÜÊûê‰∏éÁ∫øÊÄßÂõûÈ°æÁöÑÊØîËæÉÔºö ‰∏ªÊàêÂàÜÂàÜÊûê‰∏éÁ∫øÊÄßÂõûÂΩíÊòØ‰∏§Áßç‰∏çÂêåÁöÑÁÆóÊ≥ï„ÄÇ‰∏ªÊàêÂàÜÂàÜÊûêÊúÄÂ∞èÂåñÁöÑÊòØÊäïÂ∞ÑËØØÂ∑ÆÔºàProjected ErrorÔºâÔºåËÄåÁ∫øÊÄßÂõûÂΩíÂ∞ùËØïÁöÑÊòØÊúÄÂ∞èÂåñÈ¢ÑÊµãËØØÂ∑Æ„ÄÇÁ∫øÊÄßÂõûÂΩíÁöÑÁõÆÁöÑÊòØÈ¢ÑÊµãÁªìÊûúÔºåËÄå‰∏ªÊàêÂàÜÂàÜÊûê‰∏ç‰Ωú‰ªª‰ΩïÈ¢ÑÊµã„ÄÇ ‰∏äÂõæ‰∏≠ÔºåÂ∑¶ËæπÁöÑÊòØÁ∫øÊÄßÂõûÂΩíÁöÑËØØÂ∑ÆÔºàÂûÇÁõ¥‰∫éÊ®™ËΩ¥ÊäïÂΩ±ÔºâÔºåÂè≥ËæπÂàôÊòØ‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÁöÑËØØÂ∑ÆÔºàÂûÇÁõ¥‰∫éÁ∫¢Á∫øÊäïÂΩ±Ôºâ„ÄÇ PCAÂ∞Ü$n$‰∏™ÁâπÂæÅÈôçÁª¥Âà∞$k$‰∏™ÔºåÂèØ‰ª•Áî®Êù•ËøõË°åÊï∞ÊçÆÂéãÁº©ÔºåÂ¶ÇÊûú100Áª¥ÁöÑÂêëÈáèÊúÄÂêéÂèØ‰ª•Áî®10Áª¥Êù•Ë°®Á§∫ÔºåÈÇ£‰πàÂéãÁº©Áéá‰∏∫90%„ÄÇÂêåÊ†∑ÂõæÂÉèÂ§ÑÁêÜÈ¢ÜÂüüÁöÑKLÂèòÊç¢‰ΩøÁî®PCAÂÅöÂõæÂÉèÂéãÁº©„ÄÇ‰ΩÜPCA Ë¶Å‰øùËØÅÈôçÁª¥ÂêéÔºåËøòË¶Å‰øùËØÅÊï∞ÊçÆÁöÑÁâπÊÄßÊçüÂ§±ÊúÄÂ∞è„ÄÇ PCAÊäÄÊúØÁöÑ‰∏ÄÂ§ßÂ•ΩÂ§ÑÊòØÂØπÊï∞ÊçÆËøõË°åÈôçÁª¥ÁöÑÂ§ÑÁêÜ„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂØπÊñ∞Ê±ÇÂá∫ÁöÑ‚Äú‰∏ªÂÖÉ‚ÄùÂêëÈáèÁöÑÈáçË¶ÅÊÄßËøõË°åÊéíÂ∫èÔºåÊ†πÊçÆÈúÄË¶ÅÂèñÂâçÈù¢ÊúÄÈáçË¶ÅÁöÑÈÉ®ÂàÜÔºåÂ∞ÜÂêéÈù¢ÁöÑÁª¥Êï∞ÁúÅÂéªÔºåÂèØ‰ª•ËææÂà∞ÈôçÁª¥‰ªéËÄåÁÆÄÂåñÊ®°ÂûãÊàñÊòØÂØπÊï∞ÊçÆËøõË°åÂéãÁº©ÁöÑÊïàÊûú„ÄÇÂêåÊó∂ÊúÄÂ§ßÁ®ãÂ∫¶ÁöÑ‰øùÊåÅ‰∫ÜÂéüÊúâÊï∞ÊçÆÁöÑ‰ø°ÊÅØ„ÄÇ PCAÊäÄÊúØÁöÑ‰∏Ä‰∏™ÂæàÂ§ßÁöÑ‰ºòÁÇπÊòØÔºåÂÆÉÊòØÂÆåÂÖ®Êó†ÂèÇÊï∞ÈôêÂà∂ÁöÑ„ÄÇÂú®PCAÁöÑËÆ°ÁÆóËøáÁ®ã‰∏≠ÂÆåÂÖ®‰∏çÈúÄË¶Å‰∫∫‰∏∫ÁöÑËÆæÂÆöÂèÇÊï∞ÊàñÊòØÊ†πÊçÆ‰ªª‰ΩïÁªèÈ™åÊ®°ÂûãÂØπËÆ°ÁÆóËøõË°åÂπ≤È¢ÑÔºåÊúÄÂêéÁöÑÁªìÊûúÂè™‰∏éÊï∞ÊçÆÁõ∏ÂÖ≥Ôºå‰∏éÁî®Êà∑ÊòØÁã¨Á´ãÁöÑ„ÄÇ ‰ΩÜÊòØÔºåËøô‰∏ÄÁÇπÂêåÊó∂‰πüÂèØ‰ª•Áúã‰ΩúÊòØÁº∫ÁÇπ„ÄÇÂ¶ÇÊûúÁî®Êà∑ÂØπËßÇÊµãÂØπË±°Êúâ‰∏ÄÂÆöÁöÑÂÖàÈ™åÁü•ËØÜÔºåÊéåÊè°‰∫ÜÊï∞ÊçÆÁöÑ‰∏Ä‰∫õÁâπÂæÅÔºåÂç¥Êó†Ê≥ïÈÄöËøáÂèÇÊï∞ÂåñÁ≠âÊñπÊ≥ïÂØπÂ§ÑÁêÜËøáÁ®ãËøõË°åÂπ≤È¢ÑÔºåÂèØËÉΩ‰ºöÂæó‰∏çÂà∞È¢ÑÊúüÁöÑÊïàÊûúÔºåÊïàÁéá‰πü‰∏çÈ´ò„ÄÇ ‰∏ªÊàêÂàÜÂàÜÊûêÁÆóÊ≥ïÂèÇËÄÉËßÜÈ¢ë: 14 - 4 - Principal Component Analysis Algorithm (15 min).mkv PCA ÂáèÂ∞ë$n$Áª¥Âà∞$k$Áª¥Ôºö Á¨¨‰∏ÄÊ≠•ÊòØÂùáÂÄºÂΩí‰∏ÄÂåñ„ÄÇÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÂá∫ÊâÄÊúâÁâπÂæÅÁöÑÂùáÂÄºÔºåÁÑ∂Âêé‰ª§ $x_j= x_j-Œº_j$„ÄÇÂ¶ÇÊûúÁâπÂæÅÊòØÂú®‰∏çÂêåÁöÑÊï∞ÈáèÁ∫ß‰∏äÔºåÊàë‰ª¨ËøòÈúÄË¶ÅÂ∞ÜÂÖ∂Èô§‰ª•Ê†áÂáÜÂ∑Æ $œÉ^2$„ÄÇÁ¨¨‰∫åÊ≠•ÊòØËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©ÈòµÔºàcovariance matrixÔºâ$Œ£$Ôºö$\sum=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$ Á¨¨‰∏âÊ≠•ÊòØËÆ°ÁÆóÂçèÊñπÂ∑ÆÁü©Èòµ$Œ£$ÁöÑÁâπÂæÅÂêëÈáèÔºàeigenvectorsÔºâ: Âú® Octave ÈáåÊàë‰ª¨ÂèØ‰ª•Âà©Áî®Â•áÂºÇÂÄºÂàÜËß£Ôºàsingular value decompositionÔºâÊù•Ê±ÇËß£Ôºå[U, S, V]= svd(sigma)„ÄÇ $$Sigma=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$$ ÂØπ‰∫é‰∏Ä‰∏™ $n√ón$Áª¥Â∫¶ÁöÑÁü©ÈòµÔºå‰∏äÂºè‰∏≠ÁöÑ$U$ÊòØ‰∏Ä‰∏™ÂÖ∑Êúâ‰∏éÊï∞ÊçÆ‰πãÈó¥ÊúÄÂ∞èÊäïÂ∞ÑËØØÂ∑ÆÁöÑÊñπÂêëÂêëÈáèÊûÑÊàêÁöÑÁü©Èòµ„ÄÇÂ¶ÇÊûúÊàë‰ª¨Â∏åÊúõÂ∞ÜÊï∞ÊçÆ‰ªé$n$Áª¥ÈôçËá≥$k$Áª¥ÔºåÊàë‰ª¨Âè™ÈúÄË¶Å‰ªé$U$‰∏≠ÈÄâÂèñÂâç$k$‰∏™ÂêëÈáèÔºåËé∑Âæó‰∏Ä‰∏™$n√ók$Áª¥Â∫¶ÁöÑÁü©ÈòµÔºåÊàë‰ª¨Áî®$U_{reduce}$Ë°®Á§∫ÔºåÁÑ∂ÂêéÈÄöËøáÂ¶Ç‰∏ãËÆ°ÁÆóËé∑ÂæóË¶ÅÊ±ÇÁöÑÊñ∞ÁâπÂæÅÂêëÈáè$z^{(i)}$:$$z^{(i)}=U^{T}_{reduce}*x^{(i)}$$ ÂÖ∂‰∏≠$x$ÊòØ$n√ó1$Áª¥ÁöÑÔºåÂõ†Ê≠§ÁªìÊûú‰∏∫$k√ó1$Áª¥Â∫¶„ÄÇÊ≥®ÔºåÊàë‰ª¨‰∏çÂØπÊñπÂ∑ÆÁâπÂæÅËøõË°åÂ§ÑÁêÜ„ÄÇ ÈÄâÊã©‰∏ªÊàêÂàÜÁöÑÊï∞ÈáèÂèÇËÄÉËßÜÈ¢ë: 14 - 5 - Choosing The Number Of Principal Components (13 min).mkv ‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÊòØÂáèÂ∞ëÊäïÂ∞ÑÁöÑÂπ≥ÂùáÂùáÊñπËØØÂ∑ÆÔºö ËÆ≠ÁªÉÈõÜÁöÑÊñπÂ∑Æ‰∏∫Ôºö$\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }\right\| ^{2}$ Êàë‰ª¨Â∏åÊúõÂú®Âπ≥ÂùáÂùáÊñπËØØÂ∑Æ‰∏éËÆ≠ÁªÉÈõÜÊñπÂ∑ÆÁöÑÊØî‰æãÂ∞ΩÂèØËÉΩÂ∞èÁöÑÊÉÖÂÜµ‰∏ãÈÄâÊã©Â∞ΩÂèØËÉΩÂ∞èÁöÑ$k$ÂÄº„ÄÇ Â¶ÇÊûúÊàë‰ª¨Â∏åÊúõËøô‰∏™ÊØî‰æãÂ∞è‰∫é1%ÔºåÂ∞±ÊÑèÂë≥ÁùÄÂéüÊú¨Êï∞ÊçÆÁöÑÂÅèÂ∑ÆÊúâ99%ÈÉΩ‰øùÁïô‰∏ãÊù•‰∫ÜÔºåÂ¶ÇÊûúÊàë‰ª¨ÈÄâÊã©‰øùÁïô95%ÁöÑÂÅèÂ∑ÆÔºå‰æøËÉΩÈùûÂ∏∏ÊòæËëóÂú∞Èôç‰ΩéÊ®°Âûã‰∏≠ÁâπÂæÅÁöÑÁª¥Â∫¶‰∫Ü„ÄÇ Êàë‰ª¨ÂèØ‰ª•ÂÖà‰ª§$k=1$ÔºåÁÑ∂ÂêéËøõË°å‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÔºåËé∑Âæó$U_{reduce}$Âíå$z$ÔºåÁÑ∂ÂêéËÆ°ÁÆóÊØî‰æãÊòØÂê¶Â∞è‰∫é1%„ÄÇÂ¶ÇÊûú‰∏çÊòØÁöÑËØùÂÜç‰ª§$k=2$ÔºåÂ¶ÇÊ≠§Á±ªÊé®ÔºåÁõ¥Âà∞ÊâæÂà∞ÂèØ‰ª•‰ΩøÂæóÊØî‰æãÂ∞è‰∫é1%ÁöÑÊúÄÂ∞è$k$ ÂÄºÔºàÂéüÂõ†ÊòØÂêÑ‰∏™ÁâπÂæÅ‰πãÈó¥ÈÄöÂ∏∏ÊÉÖÂÜµÂ≠òÂú®ÊüêÁßçÁõ∏ÂÖ≥ÊÄßÔºâ„ÄÇ ËøòÊúâ‰∏Ä‰∫õÊõ¥Â•ΩÁöÑÊñπÂºèÊù•ÈÄâÊã©$k$ÔºåÂΩìÊàë‰ª¨Âú®Octave‰∏≠Ë∞ÉÁî®‚Äúsvd‚ÄùÂáΩÊï∞ÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Ëé∑Âæó‰∏â‰∏™ÂèÇÊï∞Ôºö[U, S, V] = svd(sigma)„ÄÇ ÂÖ∂‰∏≠ÁöÑ$S$ÊòØ‰∏Ä‰∏™$n√ón$ÁöÑÁü©ÈòµÔºåÂè™ÊúâÂØπËßíÁ∫ø‰∏äÊúâÂÄºÔºåËÄåÂÖ∂ÂÆÉÂçïÂÖÉÈÉΩÊòØ0ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™Áü©ÈòµÊù•ËÆ°ÁÆóÂπ≥ÂùáÂùáÊñπËØØÂ∑Æ‰∏éËÆ≠ÁªÉÈõÜÊñπÂ∑ÆÁöÑÊØî‰æãÔºö$$\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2}}{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2}}=1-\dfrac {\Sigma^{k}_{i=1}S_{ii}}{\Sigma^{m}_{i=1}S_{ii}}\leq 1\%$$ ‰πüÂ∞±ÊòØÔºö$$\frac {\Sigma^{k}_{i=1}s_{ii}}{\Sigma^{n}_{i=1}s_{ii}}\geq0.99$$ Âú®ÂéãÁº©ËøáÊï∞ÊçÆÂêéÔºåÊàë‰ª¨ÂèØ‰ª•ÈááÁî®Â¶Ç‰∏ãÊñπÊ≥ïÊù•Ëøë‰ººÂú∞Ëé∑ÂæóÂéüÊúâÁöÑÁâπÂæÅÔºö$$x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}$$ ÈáçÂª∫ÁöÑÂéãÁº©Ë°®Á§∫ÂèÇËÄÉËßÜÈ¢ë: 14 - 6 - Reconstruction from Compressed Representation (4 min).mkv Âú®‰ª•ÂâçÁöÑËßÜÈ¢ë‰∏≠ÔºåÊàëË∞àËÆ∫PCA‰Ωú‰∏∫ÂéãÁº©ÁÆóÊ≥ï„ÄÇÂú®ÈÇ£Èáå‰Ω†ÂèØËÉΩÈúÄË¶ÅÊää1000Áª¥ÁöÑÊï∞ÊçÆÂéãÁº©100Áª¥ÁâπÂæÅÔºåÊàñÂÖ∑Êúâ‰∏âÁª¥Êï∞ÊçÆÂéãÁº©Âà∞‰∏Ä‰∫åÁª¥Ë°®Á§∫„ÄÇÊâÄ‰ª•ÔºåÂ¶ÇÊûúËøôÊòØ‰∏Ä‰∏™ÂéãÁº©ÁÆóÊ≥ïÔºåÂ∫îËØ•ËÉΩÂõûÂà∞Ëøô‰∏™ÂéãÁº©Ë°®Á§∫ÔºåÂõûÂà∞‰Ω†ÂéüÊúâÁöÑÈ´òÁª¥Êï∞ÊçÆÁöÑ‰∏ÄÁßçËøë‰ºº„ÄÇ ÊâÄ‰ª•ÔºåÁªôÂÆöÁöÑ$z^{(i)}$ÔºåËøôÂèØËÉΩ100Áª¥ÔºåÊÄé‰πàÂõûÂà∞‰Ω†ÂéüÊù•ÁöÑË°®Á§∫$x^{(i)}$ÔºåËøôÂèØËÉΩÊòØ1000Áª¥ÁöÑÊï∞ÁªÑÔºü PCAÁÆóÊ≥ïÔºåÊàë‰ª¨ÂèØËÉΩÊúâ‰∏Ä‰∏™ËøôÊ†∑ÁöÑÊ†∑Êú¨„ÄÇÂ¶ÇÂõæ‰∏≠Ê†∑Êú¨$x^{(1)}$,$x^{(2)}$„ÄÇÊàë‰ª¨ÂÅöÁöÑÊòØÔºåÊàë‰ª¨ÊääËøô‰∫õÊ†∑Êú¨ÊäïÂ∞ÑÂà∞Âõæ‰∏≠Ëøô‰∏™‰∏ÄÁª¥Âπ≥Èù¢„ÄÇÁÑ∂ÂêéÁé∞Âú®Êàë‰ª¨ÈúÄË¶ÅÂè™‰ΩøÁî®‰∏Ä‰∏™ÂÆûÊï∞ÔºåÊØîÂ¶Ç$z^{(1)}$ÔºåÊåáÂÆöËøô‰∫õÁÇπÁöÑ‰ΩçÁΩÆÂêé‰ªñ‰ª¨Ë¢´ÊäïÂ∞ÑÂà∞Ëøô‰∏Ä‰∏™‰∏âÁª¥Êõ≤Èù¢„ÄÇÁªôÂÆö‰∏Ä‰∏™ÁÇπ$z^{(1)}$ÔºåÊàë‰ª¨ÊÄé‰πàËÉΩÂõûÂéªËøô‰∏™ÂéüÂßãÁöÑ‰∫åÁª¥Á©∫Èó¥Âë¢Ôºü$x$‰∏∫2Áª¥Ôºåz‰∏∫1Áª¥Ôºå$z=U^{T}_{reduce}x$ÔºåÁõ∏ÂèçÁöÑÊñπÁ®ã‰∏∫Ôºö$x_{appox}=U_{reduce}\cdot z$,$x_{appox}\approx x$„ÄÇÂ¶ÇÂõæÔºö Â¶Ç‰Ω†ÊâÄÁü•ÔºåËøôÊòØ‰∏Ä‰∏™ÊºÇ‰∫ÆÁöÑ‰∏éÂéüÂßãÊï∞ÊçÆÁõ∏ÂΩìÁõ∏‰ºº„ÄÇÊâÄ‰ª•ÔºåËøôÂ∞±ÊòØ‰Ω†‰ªé‰ΩéÁª¥Ë°®Á§∫$z$ÂõûÂà∞Êú™ÂéãÁº©ÁöÑË°®Á§∫„ÄÇÊàë‰ª¨ÂæóÂà∞ÁöÑÊï∞ÊçÆÁöÑ‰∏Ä‰∏™‰πãÈó¥‰Ω†ÁöÑÂéüÂßãÊï∞ÊçÆ $x$ÔºåÊàë‰ª¨‰πüÊääËøô‰∏™ËøáÁ®ãÁß∞‰∏∫ÈáçÂª∫ÂéüÂßãÊï∞ÊçÆ„ÄÇ ÂΩìÊàë‰ª¨ËÆ§‰∏∫ËØïÂõæÈáçÂª∫‰ªéÂéãÁº©Ë°®Á§∫ $x$ ÁöÑÂàùÂßãÂÄº„ÄÇÊâÄ‰ª•ÔºåÁªôÂÆöÊú™Ê†áËÆ∞ÁöÑÊï∞ÊçÆÈõÜÔºåÊÇ®Áé∞Âú®Áü•ÈÅìÂ¶Ç‰ΩïÂ∫îÁî®PCAÔºå‰Ω†ÁöÑÂ∏¶È´òÁª¥ÁâπÂæÅ$x$ÂíåÊò†Â∞ÑÂà∞ËøôÁöÑ‰ΩéÁª¥Ë°®Á§∫$z$„ÄÇËøô‰∏™ËßÜÈ¢ëÔºåÂ∏åÊúõ‰Ω†Áé∞Âú®‰πüÁü•ÈÅìÂ¶Ç‰ΩïÈááÂèñËøô‰∫õ‰ΩéÁª¥Ë°®Á§∫$z$ÔºåÊò†Â∞ÑÂà∞Â§á‰ªΩÂà∞‰∏Ä‰∏™Ëøë‰ºº‰Ω†ÂéüÊúâÁöÑÈ´òÁª¥Êï∞ÊçÆ„ÄÇ Áé∞Âú®‰Ω†Áü•ÈÅìÂ¶Ç‰ΩïÂÆûÊñΩÂ∫îÁî®PCAÔºåÊàë‰ª¨Â∞ÜË¶ÅÂÅöÁöÑ‰∫ãÊòØË∞àËÆ∫‰∏Ä‰∫õÊäÄÊúØÂú®ÂÆûÈôÖ‰ΩøÁî®PCAÂæàÂ•ΩÔºåÁâπÂà´ÊòØÔºåÂú®Êé•‰∏ãÊù•ÁöÑËßÜÈ¢ë‰∏≠ÔºåÊàëÊÉ≥Ë∞à‰∏ÄË∞àÂÖ≥‰∫éÂ¶Ç‰ΩïÈÄâÊã©$k$„ÄÇ ‰∏ªÊàêÂàÜÂàÜÊûêÊ≥ïÁöÑÂ∫îÁî®Âª∫ËÆÆÂèÇËÄÉËßÜÈ¢ë: 14 - 7 - Advice for Applying PCA (13 min).mkv ÂÅá‰ΩøÊàë‰ª¨Ê≠£Âú®ÈíàÂØπ‰∏ÄÂº† 100√ó100ÂÉèÁ¥†ÁöÑÂõæÁâáËøõË°åÊüê‰∏™ËÆ°ÁÆóÊú∫ËßÜËßâÁöÑÊú∫Âô®Â≠¶‰π†ÔºåÂç≥ÊÄªÂÖ±Êúâ10000 ‰∏™ÁâπÂæÅ„ÄÇ Á¨¨‰∏ÄÊ≠•ÊòØËøêÁî®‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÂ∞ÜÊï∞ÊçÆÂéãÁº©Ëá≥1000‰∏™ÁâπÂæÅ ÁÑ∂ÂêéÂØπËÆ≠ÁªÉÈõÜËøêË°åÂ≠¶‰π†ÁÆóÊ≥ï Âú®È¢ÑÊµãÊó∂ÔºåÈááÁî®‰πãÂâçÂ≠¶‰π†ËÄåÊù•ÁöÑ$U_{reduce}$Â∞ÜËæìÂÖ•ÁöÑÁâπÂæÅ$x$ËΩ¨Êç¢ÊàêÁâπÂæÅÂêëÈáè$z$ÔºåÁÑ∂ÂêéÂÜçËøõË°åÈ¢ÑÊµã Ê≥®ÔºöÂ¶ÇÊûúÊàë‰ª¨Êúâ‰∫§ÂèâÈ™åËØÅÈõÜÂêàÊµãËØïÈõÜÔºå‰πüÈááÁî®ÂØπËÆ≠ÁªÉÈõÜÂ≠¶‰π†ËÄåÊù•ÁöÑ$U_{reduce}$„ÄÇ ÈîôËØØÁöÑ‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÊÉÖÂÜµÔºö‰∏Ä‰∏™Â∏∏ËßÅÈîôËØØ‰ΩøÁî®‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÁöÑÊÉÖÂÜµÊòØÔºåÂ∞ÜÂÖ∂Áî®‰∫éÂáèÂ∞ëËøáÊãüÂêàÔºàÂáèÂ∞ë‰∫ÜÁâπÂæÅÁöÑÊï∞ÈáèÔºâ„ÄÇËøôÊ†∑ÂÅöÈùûÂ∏∏‰∏çÂ•ΩÔºå‰∏çÂ¶ÇÂ∞ùËØïÊ≠£ÂàôÂåñÂ§ÑÁêÜ„ÄÇÂéüÂõ†Âú®‰∫é‰∏ªË¶ÅÊàêÂàÜÂàÜÊûêÂè™ÊòØËøë‰ººÂú∞‰∏¢ÂºÉÊéâ‰∏Ä‰∫õÁâπÂæÅÔºåÂÆÉÂπ∂‰∏çËÄÉËôë‰ªª‰Ωï‰∏éÁªìÊûúÂèòÈáèÊúâÂÖ≥ÁöÑ‰ø°ÊÅØÔºåÂõ†Ê≠§ÂèØËÉΩ‰ºö‰∏¢Â§±ÈùûÂ∏∏ÈáçË¶ÅÁöÑÁâπÂæÅ„ÄÇÁÑ∂ËÄåÂΩìÊàë‰ª¨ËøõË°åÊ≠£ÂàôÂåñÂ§ÑÁêÜÊó∂Ôºå‰ºöËÄÉËôëÂà∞ÁªìÊûúÂèòÈáèÔºå‰∏ç‰ºö‰∏¢ÊéâÈáçË¶ÅÁöÑÊï∞ÊçÆ„ÄÇ Âè¶‰∏Ä‰∏™Â∏∏ËßÅÁöÑÈîôËØØÊòØÔºåÈªòËÆ§Âú∞Â∞Ü‰∏ªË¶ÅÊàêÂàÜÂàÜÊûê‰Ωú‰∏∫Â≠¶‰π†ËøáÁ®ã‰∏≠ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåËøôËôΩÁÑ∂ÂæàÂ§öÊó∂ÂÄôÊúâÊïàÊûúÔºåÊúÄÂ•ΩËøòÊòØ‰ªéÊâÄÊúâÂéüÂßãÁâπÂæÅÂºÄÂßãÔºåÂè™Âú®ÊúâÂøÖË¶ÅÁöÑÊó∂ÂÄôÔºàÁÆóÊ≥ïËøêË°åÂ§™ÊÖ¢ÊàñËÄÖÂç†Áî®Â§™Â§öÂÜÖÂ≠òÔºâÊâçËÄÉËôëÈááÁî®‰∏ªË¶ÅÊàêÂàÜÂàÜÊûê„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Ôºà‰πùÔºâ]]></title>
    <url>%2F2018%2F08%2F12%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B9%9D%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÂçÅ‰∫å„ÄÅÊîØÊåÅÂêëÈáèÊú∫(Support Vector Machines) 12.1 ‰ºòÂåñÁõÆÊ†áÂèÇËÄÉËßÜÈ¢ë: 12 - 1 - Optimization Objective (15 min).mkv Âà∞ÁõÆÂâç‰∏∫Ê≠¢,‰Ω†Â∑≤ÁªèËßÅËøá‰∏ÄÁ≥ªÂàó‰∏çÂêåÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇÂú®ÁõëÁù£Â≠¶‰π†‰∏≠ÔºåËÆ∏Â§öÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÊÄßËÉΩÈÉΩÈùûÂ∏∏Á±ª‰ººÔºåÂõ†Ê≠§ÔºåÈáçË¶ÅÁöÑ‰∏çÊòØ‰Ω†ËØ•ÈÄâÊã©‰ΩøÁî®Â≠¶‰π†ÁÆóÊ≥ïAËøòÊòØÂ≠¶‰π†ÁÆóÊ≥ïBÔºåËÄåÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÂ∫îÁî®Ëøô‰∫õÁÆóÊ≥ïÊó∂ÔºåÊâÄÂàõÂª∫ÁöÑÂ§ßÈáèÊï∞ÊçÆÂú®Â∫îÁî®Ëøô‰∫õÁÆóÊ≥ïÊó∂ÔºåË°®Áé∞ÊÉÖÂÜµÈÄöÂ∏∏‰æùËµñ‰∫é‰Ω†ÁöÑÊ∞¥Âπ≥„ÄÇÊØîÂ¶ÇÔºö‰Ω†‰∏∫Â≠¶‰π†ÁÆóÊ≥ïÊâÄËÆæËÆ°ÁöÑÁâπÂæÅÈáèÁöÑÈÄâÊã©Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄâÊã©Ê≠£ÂàôÂåñÂèÇÊï∞ÔºåËØ∏Â¶ÇÊ≠§Á±ªÁöÑ‰∫ã„ÄÇËøòÊúâ‰∏Ä‰∏™Êõ¥Âä†Âº∫Â§ßÁöÑÁÆóÊ≥ïÂπøÊ≥õÁöÑÂ∫îÁî®‰∫éÂ∑•‰∏öÁïåÂíåÂ≠¶ÊúØÁïåÔºåÂÆÉË¢´Áß∞‰∏∫ÊîØÊåÅÂêëÈáèÊú∫(Support Vector Machine)„ÄÇ‰∏éÈÄªËæëÂõûÂΩíÂíåÁ•ûÁªèÁΩëÁªúÁõ∏ÊØîÔºåÊîØÊåÅÂêëÈáèÊú∫ÔºåÊàñËÄÖÁÆÄÁß∞SVMÔºåÂú®Â≠¶‰π†Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÊñπÁ®ãÊó∂Êèê‰æõ‰∫Ü‰∏ÄÁßçÊõ¥‰∏∫Ê∏ÖÊô∞ÔºåÊõ¥Âä†Âº∫Â§ßÁöÑÊñπÂºè„ÄÇÂõ†Ê≠§ÔºåÂú®Êé•‰∏ãÊù•ÁöÑËßÜÈ¢ë‰∏≠ÔºåÊàë‰ºöÊé¢ËÆ®Ëøô‰∏ÄÁÆóÊ≥ï„ÄÇÂú®Á®çÂêéÁöÑËØæÁ®ã‰∏≠ÔºåÊàë‰πü‰ºöÂØπÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïËøõË°åÁÆÄË¶ÅÁöÑÊÄªÁªì„ÄÇÂΩìÁÑ∂Ôºå‰ªÖ‰ªÖÊòØ‰ΩúÁÆÄË¶ÅÊèèËø∞„ÄÇ‰ΩÜÂØπ‰∫éÊîØÊåÅÂêëÈáèÊú∫ÔºåÈâ¥‰∫éËØ•ÁÆóÊ≥ïÁöÑÂº∫Â§ßÂíåÂèóÊ¨¢ËøéÂ∫¶ÔºåÂú®Êú¨ËØæ‰∏≠ÔºåÊàë‰ºöËä±ËÆ∏Â§öÊó∂Èó¥Êù•ËÆ≤Ëß£ÂÆÉ„ÄÇÂÆÉ‰πüÊòØÊàë‰ª¨ÊâÄ‰ªãÁªçÁöÑÊúÄÂêé‰∏Ä‰∏™ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï„ÄÇ Ê≠£Â¶ÇÊàë‰ª¨‰πãÂâçÂºÄÂèëÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊàë‰ª¨‰ªé‰ºòÂåñÁõÆÊ†áÂºÄÂßã„ÄÇÈÇ£‰πàÔºåÊàë‰ª¨ÂºÄÂßãÂ≠¶‰π†Ëøô‰∏™ÁÆóÊ≥ï„ÄÇ‰∏∫‰∫ÜÊèèËø∞ÊîØÊåÅÂêëÈáèÊú∫Ôºå‰∫ãÂÆû‰∏äÔºåÊàëÂ∞Ü‰ºö‰ªéÈÄªËæëÂõûÂΩíÂºÄÂßãÂ±ïÁ§∫Êàë‰ª¨Â¶Ç‰Ωï‰∏ÄÁÇπ‰∏ÄÁÇπ‰øÆÊîπÊù•ÂæóÂà∞Êú¨Ë¥®‰∏äÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇ ÈÇ£‰πàÔºåÂú®ÈÄªËæëÂõûÂΩí‰∏≠Êàë‰ª¨Â∑≤ÁªèÁÜüÊÇâ‰∫ÜËøôÈáåÁöÑÂÅáËÆæÂáΩÊï∞ÂΩ¢ÂºèÔºåÂíåÂè≥ËæπÁöÑSÂûãÊøÄÂä±ÂáΩÊï∞„ÄÇÁÑ∂ËÄåÔºå‰∏∫‰∫ÜËß£Èáä‰∏Ä‰∫õÊï∞Â≠¶Áü•ËØÜ.ÊàëÂ∞ÜÁî®$z$ Ë°®Á§∫$\theta^Tx$„ÄÇ Áé∞Âú®ËÄÉËôë‰∏ãÊàë‰ª¨ÊÉ≥Ë¶ÅÈÄªËæëÂõûÂΩíÂÅö‰ªÄ‰πàÔºöÂ¶ÇÊûúÊúâ‰∏Ä‰∏™ $y=1$ÁöÑÊ†∑Êú¨ÔºåÊàëÁöÑÊÑèÊÄùÊòØ‰∏çÁÆ°ÊòØÂú®ËÆ≠ÁªÉÈõÜ‰∏≠ÊàñÊòØÂú®ÊµãËØïÈõÜ‰∏≠ÔºåÂèàÊàñËÄÖÂú®‰∫§ÂèâÈ™åËØÅÈõÜ‰∏≠ÔºåÊÄª‰πãÊòØ $y=1$ÔºåÁé∞Âú®Êàë‰ª¨Â∏åÊúõ${{h}_{\theta }}\left( x \right)$ Ë∂ãËøë1„ÄÇÂõ†‰∏∫Êàë‰ª¨ÊÉ≥Ë¶ÅÊ≠£Á°ÆÂú∞Â∞ÜÊ≠§Ê†∑Êú¨ÂàÜÁ±ªÔºåËøôÂ∞±ÊÑèÂë≥ÁùÄÂΩì ${{h}_{\theta }}\left( x \right)$Ë∂ãËøë‰∫é1Êó∂Ôºå$\theta^Tx$ Â∫îÂΩìËøúÂ§ß‰∫é0ÔºåËøôÈáåÁöÑ$>>$ÊÑèÊÄùÊòØËøúËøúÂ§ß‰∫é0„ÄÇËøôÊòØÂõ†‰∏∫Áî±‰∫é $z$ Ë°®Á§∫ $\theta^Tx$ÔºåÂΩì $z$ËøúÂ§ß‰∫é0Êó∂ÔºåÂç≥Âà∞‰∫ÜËØ•ÂõæÁöÑÂè≥ËæπÔºå‰Ω†‰∏çÈöæÂèëÁé∞Ê≠§Êó∂ÈÄªËæëÂõûÂΩíÁöÑËæìÂá∫Â∞ÜË∂ãËøë‰∫é1„ÄÇÁõ∏ÂèçÂú∞ÔºåÂ¶ÇÊûúÊàë‰ª¨ÊúâÂè¶‰∏Ä‰∏™Ê†∑Êú¨ÔºåÂç≥$y=0$„ÄÇÊàë‰ª¨Â∏åÊúõÂÅáËÆæÂáΩÊï∞ÁöÑËæìÂá∫ÂÄºÂ∞ÜË∂ãËøë‰∫é0ÔºåËøôÂØπÂ∫î‰∫é$\theta^Tx$ÔºåÊàñËÄÖÂ∞±ÊòØ $z$ ‰ºöËøúÂ∞è‰∫é0ÔºåÂõ†‰∏∫ÂØπÂ∫îÁöÑÂÅáËÆæÂáΩÊï∞ÁöÑËæìÂá∫ÂÄºË∂ãËøë0„ÄÇ Â¶ÇÊûú‰Ω†Ëøõ‰∏ÄÊ≠•ËßÇÂØüÈÄªËæëÂõûÂΩíÁöÑ‰ª£‰ª∑ÂáΩÊï∞Ôºå‰Ω†‰ºöÂèëÁé∞ÊØè‰∏™Ê†∑Êú¨ $(x,y)$ÈÉΩ‰ºö‰∏∫ÊÄª‰ª£‰ª∑ÂáΩÊï∞ÔºåÂ¢ûÂä†ËøôÈáåÁöÑ‰∏ÄÈ°πÔºåÂõ†Ê≠§ÔºåÂØπ‰∫éÊÄª‰ª£‰ª∑ÂáΩÊï∞ÈÄöÂ∏∏‰ºöÊúâÂØπÊâÄÊúâÁöÑËÆ≠ÁªÉÊ†∑Êú¨Ê±ÇÂíåÔºåÂπ∂‰∏îËøôÈáåËøòÊúâ‰∏Ä‰∏™$1/m$È°πÔºå‰ΩÜÊòØÔºåÂú®ÈÄªËæëÂõûÂΩí‰∏≠ÔºåËøôÈáåÁöÑËøô‰∏ÄÈ°πÂ∞±ÊòØË°®Á§∫‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÊâÄÂØπÂ∫îÁöÑË°®ËææÂºè„ÄÇÁé∞Âú®ÔºåÂ¶ÇÊûúÊàëÂ∞ÜÂÆåÊï¥ÂÆö‰πâÁöÑÂÅáËÆæÂáΩÊï∞‰ª£ÂÖ•ËøôÈáå„ÄÇÈÇ£‰πàÔºåÊàë‰ª¨Â∞±‰ºöÂæóÂà∞ÊØè‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÈÉΩÂΩ±ÂìçËøô‰∏ÄÈ°π„ÄÇ Áé∞Âú®ÔºåÂÖàÂøΩÁï• $1/m$ Ëøô‰∏ÄÈ°πÔºå‰ΩÜÊòØËøô‰∏ÄÈ°πÊòØÂΩ±ÂìçÊï¥‰∏™ÊÄª‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÁöÑËøô‰∏ÄÈ°πÁöÑ„ÄÇ Áé∞Âú®Ôºå‰∏ÄËµ∑Êù•ËÄÉËôë‰∏§ÁßçÊÉÖÂÜµÔºö ‰∏ÄÁßçÊòØ$y$Á≠â‰∫é1ÁöÑÊÉÖÂÜµÔºõÂè¶‰∏ÄÁßçÊòØ $y$ Á≠â‰∫é0ÁöÑÊÉÖÂÜµ„ÄÇ Âú®Á¨¨‰∏ÄÁßçÊÉÖÂÜµ‰∏≠ÔºåÂÅáËÆæ $y=1$ ÔºåÊ≠§Êó∂Âú®ÁõÆÊ†áÂáΩÊï∞‰∏≠Âè™ÈúÄÊúâÁ¨¨‰∏ÄÈ°πËµ∑‰ΩúÁî®ÔºåÂõ†‰∏∫$y=1$Êó∂Ôºå$(1-y)$È°πÂ∞ÜÁ≠â‰∫é0„ÄÇÂõ†Ê≠§ÔºåÂΩìÂú® $y=1$ ÁöÑÊ†∑Êú¨‰∏≠Êó∂ÔºåÂç≥Âú® $(x, y) $‰∏≠ ÔºåÊàë‰ª¨ÂæóÂà∞ $y=1$ $-\log(1-\frac{1}{1+e^{-z}})$ËøôÊ†∑‰∏ÄÈ°πÔºåËøôÈáåÂêå‰∏ä‰∏ÄÂº†ÂπªÁÅØÁâá‰∏ÄËá¥„ÄÇ ÊàëÁî® $z$ Ë°®Á§∫$\theta^Tx$ÔºåÂç≥Ôºö $z= \theta^Tx$„ÄÇÂΩìÁÑ∂ÔºåÂú®‰ª£‰ª∑ÂáΩÊï∞‰∏≠Ôºå$y$ ÂâçÈù¢ÊúâË¥üÂè∑„ÄÇÊàë‰ª¨Âè™ÊòØËøôÊ†∑Ë°®Á§∫ÔºåÂ¶ÇÊûú $y=1$ ‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÔºåËøô‰∏ÄÈ°π‰πüÁ≠â‰∫é1„ÄÇËøôÊ†∑ÂÅöÊòØ‰∏∫‰∫ÜÁÆÄÂåñÊ≠§Â§ÑÁöÑË°®ËææÂºè„ÄÇÂ¶ÇÊûúÁîªÂá∫ÂÖ≥‰∫é$z$ ÁöÑÂáΩÊï∞Ôºå‰Ω†‰ºöÁúãÂà∞Â∑¶‰∏ãËßíÁöÑËøôÊù°Êõ≤Á∫øÔºåÊàë‰ª¨ÂêåÊ†∑ÂèØ‰ª•ÁúãÂà∞ÔºåÂΩì$z$ Â¢ûÂ§ßÊó∂Ôºå‰πüÂ∞±ÊòØÁõ∏ÂΩì‰∫é$\theta^Tx$Â¢ûÂ§ßÊó∂Ôºå$z$ ÂØπÂ∫îÁöÑÂÄº‰ºöÂèòÁöÑÈùûÂ∏∏Â∞è„ÄÇÂØπÊï¥‰∏™‰ª£‰ª∑ÂáΩÊï∞ËÄåË®ÄÔºåÂΩ±Âìç‰πüÈùûÂ∏∏Â∞è„ÄÇËøô‰πüÂ∞±Ëß£Èáä‰∫ÜÔºå‰∏∫‰ªÄ‰πàÈÄªËæëÂõûÂΩíÂú®ËßÇÂØüÂà∞Ê≠£Ê†∑Êú¨$y=1$Êó∂ÔºåËØïÂõæÂ∞Ü$\theta^Tx$ËÆæÁΩÆÂæóÈùûÂ∏∏Â§ß„ÄÇÂõ†‰∏∫ÔºåÂú®‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÁöÑËøô‰∏ÄÈ°π‰ºöÂèòÁöÑÈùûÂ∏∏Â∞è„ÄÇ Áé∞Âú®ÂºÄÂßãÂª∫Á´ãÊîØÊåÅÂêëÈáèÊú∫ÔºåÊàë‰ª¨‰ªéËøôÈáåÂºÄÂßãÔºö Êàë‰ª¨‰ºö‰ªéËøô‰∏™‰ª£‰ª∑ÂáΩÊï∞ÂºÄÂßãÔºå‰πüÂ∞±ÊòØ$-\log(1-\frac{1}{1+e^{-z}})$‰∏ÄÁÇπ‰∏ÄÁÇπ‰øÆÊîπÔºåËÆ©ÊàëÂèñËøôÈáåÁöÑ$z=1$ ÁÇπÔºåÊàëÂÖàÁîªÂá∫Â∞ÜË¶ÅÁî®ÁöÑ‰ª£‰ª∑ÂáΩÊï∞„ÄÇ Êñ∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Â∞Ü‰ºöÊ∞¥Âπ≥ÁöÑ‰ªéËøôÈáåÂà∞Âè≥Ëæπ(ÂõæÂ§ñ)ÔºåÁÑ∂ÂêéÊàëÂÜçÁîª‰∏ÄÊù°ÂêåÈÄªËæëÂõûÂΩíÈùûÂ∏∏Áõ∏‰ººÁöÑÁõ¥Á∫øÔºå‰ΩÜÊòØÔºåÂú®ËøôÈáåÊòØ‰∏ÄÊù°Áõ¥Á∫øÔºå‰πüÂ∞±ÊòØÊàëÁî®Á¥´Á∫¢Ëâ≤ÁîªÁöÑÊõ≤Á∫øÔºåÂ∞±ÊòØËøôÊù°Á¥´Á∫¢Ëâ≤ÁöÑÊõ≤Á∫ø„ÄÇÈÇ£‰πàÔºåÂà∞‰∫ÜËøôÈáåÂ∑≤ÁªèÈùûÂ∏∏Êé•ËøëÈÄªËæëÂõûÂΩí‰∏≠‰ΩøÁî®ÁöÑ‰ª£‰ª∑ÂáΩÊï∞‰∫Ü„ÄÇÂè™ÊòØËøôÈáåÊòØÁî±‰∏§Êù°Á∫øÊÆµÁªÑÊàêÔºåÂç≥‰Ωç‰∫éÂè≥ËæπÁöÑÊ∞¥Âπ≥ÈÉ®ÂàÜÂíå‰Ωç‰∫éÂ∑¶ËæπÁöÑÁõ¥Á∫øÈÉ®ÂàÜÔºåÂÖàÂà´ËøáÂ§öÁöÑËÄÉËôëÂ∑¶ËæπÁõ¥Á∫øÈÉ®ÂàÜÁöÑÊñúÁéáÔºåËøôÂπ∂‰∏çÊòØÂæàÈáçË¶Å„ÄÇ‰ΩÜÊòØÔºåËøôÈáåÊàë‰ª¨Â∞Ü‰ΩøÁî®ÁöÑÊñ∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåÊòØÂú®$y=1$ÁöÑÂâçÊèê‰∏ãÁöÑ„ÄÇ‰Ω†‰πüËÆ∏ËÉΩÊÉ≥Âà∞ÔºåËøôÂ∫îËØ•ËÉΩÂÅöÂêåÈÄªËæëÂõûÂΩí‰∏≠Á±ª‰ººÁöÑ‰∫ãÊÉÖÔºå‰ΩÜ‰∫ãÂÆû‰∏äÔºåÂú®‰πãÂêéÁöÑ‰ºòÂåñÈóÆÈ¢ò‰∏≠ÔºåËøô‰ºöÂèòÂæóÊõ¥ÂùöÂÆöÔºåÂπ∂‰∏î‰∏∫ÊîØÊåÅÂêëÈáèÊú∫ÔºåÂ∏¶Êù•ËÆ°ÁÆó‰∏äÁöÑ‰ºòÂäø„ÄÇ‰æãÂ¶ÇÔºåÊõ¥ÂÆπÊòìËÆ°ÁÆóËÇ°Á•®‰∫§ÊòìÁöÑÈóÆÈ¢òÁ≠âÁ≠â„ÄÇ ÁõÆÂâçÔºåÊàë‰ª¨Âè™ÊòØËÆ®ËÆ∫‰∫Ü$y=1$ÁöÑÊÉÖÂÜµÔºåÂè¶Â§ñ‰∏ÄÁßçÊÉÖÂÜµÊòØÂΩì$y=0$Êó∂ÔºåÊ≠§Êó∂Â¶ÇÊûú‰Ω†‰ªîÁªÜËßÇÂØü‰ª£‰ª∑ÂáΩÊï∞Âè™Áïô‰∏ã‰∫ÜÁ¨¨‰∫åÈ°πÔºåÂõ†‰∏∫Á¨¨‰∏ÄÈ°πË¢´Ê∂àÈô§‰∫Ü„ÄÇÂ¶ÇÊûúÂΩì$y=0$Êó∂ÔºåÈÇ£‰πàËøô‰∏ÄÈ°π‰πüÂ∞±ÊòØ0‰∫Ü„ÄÇÊâÄ‰ª•‰∏äËø∞Ë°®ËææÂºèÂè™Áïô‰∏ã‰∫ÜÁ¨¨‰∫åÈ°π„ÄÇÂõ†Ê≠§ÔºåËøô‰∏™Ê†∑Êú¨ÁöÑ‰ª£‰ª∑ÊàñÊòØ‰ª£‰ª∑ÂáΩÊï∞ÁöÑË¥°ÁåÆ„ÄÇÂ∞Ü‰ºöÁî±Ëøô‰∏ÄÈ°πË°®Á§∫„ÄÇÂπ∂‰∏îÔºåÂ¶ÇÊûú‰Ω†Â∞ÜËøô‰∏ÄÈ°π‰Ωú‰∏∫$z$ÁöÑÂáΩÊï∞ÔºåÈÇ£‰πàÔºåËøôÈáåÂ∞±‰ºöÂæóÂà∞Ê®™ËΩ¥$z$„ÄÇÁé∞Âú®Ôºå‰Ω†ÂÆåÊàê‰∫ÜÊîØÊåÅÂêëÈáèÊú∫‰∏≠ÁöÑÈÉ®ÂàÜÂÜÖÂÆπÔºåÂêåÊ†∑Âú∞ÔºåÊàë‰ª¨Ë¶ÅÊõø‰ª£Ëøô‰∏ÄÊù°ËìùËâ≤ÁöÑÁ∫øÔºåÁî®Áõ∏‰ººÁöÑÊñπÊ≥ï„ÄÇ Â¶ÇÊûúÊàë‰ª¨Áî®‰∏Ä‰∏™Êñ∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Êù•‰ª£ÊõøÔºåÂç≥ËøôÊù°‰ªé0ÁÇπÂºÄÂßãÁöÑÊ∞¥Âπ≥Áõ¥Á∫øÔºåÁÑ∂ÂêéÊòØ‰∏ÄÊù°ÊñúÁ∫øÔºåÂÉè‰∏äÂõæ„ÄÇÈÇ£‰πàÔºåÁé∞Âú®ËÆ©ÊàëÁªôËøô‰∏§‰∏™ÊñπÁ®ãÂëΩÂêçÔºåÂ∑¶ËæπÁöÑÂáΩÊï∞ÔºåÊàëÁß∞‰πã‰∏∫${\cos}t_1{(z)}$ÔºåÂêåÊó∂ÔºåÂè≥ËæπÂáΩÊï∞ÊàëÁß∞ÂÆÉ‰∏∫${\cos}t_0{(z)}$„ÄÇËøôÈáåÁöÑ‰∏ãÊ†áÊòØÊåáÂú®‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÔºåÂØπÂ∫îÁöÑ $y=1$ Âíå $y=0$ ÁöÑÊÉÖÂÜµÔºåÊã•Êúâ‰∫ÜËøô‰∫õÂÆö‰πâÂêéÔºåÁé∞Âú®ÔºåÊàë‰ª¨Â∞±ÂºÄÂßãÊûÑÂª∫ÊîØÊåÅÂêëÈáèÊú∫„ÄÇ ËøôÊòØÊàë‰ª¨Âú®ÈÄªËæëÂõûÂΩí‰∏≠‰ΩøÁî®‰ª£‰ª∑ÂáΩÊï∞$J(\theta)$„ÄÇ‰πüËÆ∏Ëøô‰∏™ÊñπÁ®ãÁúãËµ∑Êù•‰∏çÊòØÈùûÂ∏∏ÁÜüÊÇâ„ÄÇËøôÊòØÂõ†‰∏∫‰πãÂâçÊúâ‰∏™Ë¥üÂè∑Âú®ÊñπÁ®ãÂ§ñÈù¢Ôºå‰ΩÜÊòØÔºåËøôÈáåÊàëÊâÄÂÅöÁöÑÊòØÔºåÂ∞ÜË¥üÂè∑ÁßªÂà∞‰∫ÜË°®ËææÂºèÁöÑÈáåÈù¢ÔºåËøôÊ†∑ÂÅö‰ΩøÂæóÊñπÁ®ãÁúãËµ∑Êù•Êúâ‰∫õ‰∏çÂêå„ÄÇÂØπ‰∫éÊîØÊåÅÂêëÈáèÊú∫ËÄåË®ÄÔºåÂÆûË¥®‰∏äÊàë‰ª¨Ë¶ÅÂ∞ÜËøôÊõøÊç¢‰∏∫${\cos}t_1{(z)}$Ôºå‰πüÂ∞±ÊòØ${\cos}t_1{(\theta^Tx)}$ÔºåÂêåÊ†∑Âú∞ÔºåÊàë‰πüÂ∞ÜËøô‰∏ÄÈ°πÊõøÊç¢‰∏∫${\cos}t_0{(z)}$Ôºå‰πüÂ∞±ÊòØ‰ª£‰ª∑${\cos}t_0{(\theta^Tx)}$„ÄÇËøôÈáåÁöÑ‰ª£‰ª∑ÂáΩÊï∞${\cos}t_1$ÔºåÂ∞±ÊòØ‰πãÂâçÊâÄÊèêÂà∞ÁöÑÈÇ£Êù°Á∫ø„ÄÇÊ≠§Â§ñÔºå‰ª£‰ª∑ÂáΩÊï∞${\cos}t_0$Ôºå‰πüÊòØ‰∏äÈù¢ÊâÄ‰ªãÁªçËøáÁöÑÈÇ£Êù°Á∫ø„ÄÇÂõ†Ê≠§ÔºåÂØπ‰∫éÊîØÊåÅÂêëÈáèÊú∫ÔºåÊàë‰ª¨ÂæóÂà∞‰∫ÜËøôÈáåÁöÑÊúÄÂ∞èÂåñÈóÆÈ¢òÔºåÂç≥: ÁÑ∂ÂêéÔºåÂÜçÂä†‰∏äÊ≠£ÂàôÂåñÂèÇÊï∞„ÄÇÁé∞Âú®ÔºåÊåâÁÖßÊîØÊåÅÂêëÈáèÊú∫ÁöÑÊÉØ‰æãÔºå‰∫ãÂÆû‰∏äÔºåÊàë‰ª¨ÁöÑ‰π¶ÂÜô‰ºöÁ®çÂæÆÊúâ‰∫õ‰∏çÂêåÔºå‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂèÇÊï∞Ë°®Á§∫‰πü‰ºöÁ®çÂæÆÊúâ‰∫õ‰∏çÂêå„ÄÇ È¶ñÂÖàÔºåÊàë‰ª¨Ë¶ÅÈô§Âéª$1/m$Ëøô‰∏ÄÈ°πÔºåÂΩìÁÑ∂ÔºåËøô‰ªÖ‰ªÖÊòØÁî±‰∫é‰∫∫‰ª¨‰ΩøÁî®ÊîØÊåÅÂêëÈáèÊú∫Êó∂ÔºåÂØπÊØî‰∫éÈÄªËæëÂõûÂΩíËÄåË®ÄÔºå‰∏çÂêåÁöÑ‰π†ÊÉØÊâÄËá¥Ôºå‰ΩÜËøôÈáåÊàëÊâÄËØ¥ÁöÑÊÑèÊÄùÊòØÔºö‰Ω†Áü•ÈÅìÔºåÊàëÂ∞ÜË¶ÅÂÅöÁöÑÊòØ‰ªÖ‰ªÖÈô§Âéª$1/m$Ëøô‰∏ÄÈ°πÔºå‰ΩÜÊòØÔºåËøô‰πü‰ºöÂæóÂá∫ÂêåÊ†∑ÁöÑ $\theta$ ÊúÄ‰ºòÂÄºÔºåÂ•ΩÁöÑÔºåÂõ†‰∏∫$1/m$ ‰ªÖÊòØ‰∏™Â∏∏ÈáèÔºåÂõ†Ê≠§Ôºå‰Ω†Áü•ÈÅìÂú®Ëøô‰∏™ÊúÄÂ∞èÂåñÈóÆÈ¢ò‰∏≠ÔºåÊó†ËÆ∫ÂâçÈù¢ÊòØÂê¶Êúâ$1/m$ Ëøô‰∏ÄÈ°πÔºåÊúÄÁªàÊàëÊâÄÂæóÂà∞ÁöÑÊúÄ‰ºòÂÄº$\theta$ÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇËøôÈáåÊàëÁöÑÊÑèÊÄùÊòØÔºåÂÖàÁªô‰Ω†‰∏æ‰∏Ä‰∏™ÂÆû‰æãÔºåÂÅáÂÆöÊúâ‰∏ÄÊúÄÂ∞èÂåñÈóÆÈ¢òÔºöÂç≥Ë¶ÅÊ±ÇÂΩì$(u-5)^2+1$ÂèñÂæóÊúÄÂ∞èÂÄºÊó∂ÁöÑ$u$ÂÄºÔºåËøôÊó∂ÊúÄÂ∞èÂÄº‰∏∫ÔºöÂΩì$u=5$Êó∂ÂèñÂæóÊúÄÂ∞èÂÄº„ÄÇ Áé∞Âú®ÔºåÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥Ë¶ÅÂ∞ÜËøô‰∏™ÁõÆÊ†áÂáΩÊï∞‰πò‰∏äÂ∏∏Êï∞10ÔºåËøôÈáåÊàëÁöÑÊúÄÂ∞èÂåñÈóÆÈ¢òÂ∞±ÂèòÊàê‰∫ÜÔºöÊ±Ç‰ΩøÂæó$10√ó(u-5)^2+10$ÊúÄÂ∞èÁöÑÂÄº$u$ÔºåÁÑ∂ËÄåÔºå‰ΩøÂæóËøôÈáåÊúÄÂ∞èÁöÑ$u$ÂÄº‰ªç‰∏∫5„ÄÇÂõ†Ê≠§Â∞Ü‰∏Ä‰∫õÂ∏∏Êï∞‰πò‰ª•‰Ω†ÁöÑÊúÄÂ∞èÂåñÈ°πÔºåËøôÂπ∂‰∏ç‰ºöÊîπÂèòÊúÄÂ∞èÂåñËØ•ÊñπÁ®ãÊó∂ÂæóÂà∞$u$ÂÄº„ÄÇÂõ†Ê≠§ÔºåËøôÈáåÊàëÊâÄÂÅöÁöÑÊòØÂà†ÂéªÂ∏∏Èáè$m$„ÄÇ‰πüÁõ∏ÂêåÁöÑÔºåÊàëÂ∞ÜÁõÆÊ†áÂáΩÊï∞‰πò‰∏ä‰∏Ä‰∏™Â∏∏Èáè$m$ÔºåÂπ∂‰∏ç‰ºöÊîπÂèòÂèñÂæóÊúÄÂ∞èÂÄºÊó∂ÁöÑ$\theta$ÂÄº„ÄÇ Á¨¨‰∫åÁÇπÊ¶ÇÂøµ‰∏äÁöÑÂèòÂåñÔºåÊàë‰ª¨Âè™ÊòØÊåáÂú®‰ΩøÁî®ÊîØÊåÅÂêëÈáèÊú∫Êó∂Ôºå‰∏Ä‰∫õÂ¶Ç‰∏ãÁöÑÊ†áÂáÜÊÉØ‰æãÔºåËÄå‰∏çÊòØÈÄªËæëÂõûÂΩí„ÄÇÂõ†Ê≠§ÔºåÂØπ‰∫éÈÄªËæëÂõûÂΩíÔºåÂú®ÁõÆÊ†áÂáΩÊï∞‰∏≠ÔºåÊàë‰ª¨Êúâ‰∏§È°πÔºöÁ¨¨‰∏Ä‰∏™ÊòØËÆ≠ÁªÉÊ†∑Êú¨ÁöÑ‰ª£‰ª∑ÔºåÁ¨¨‰∫å‰∏™ÊòØÊàë‰ª¨ÁöÑÊ≠£ÂàôÂåñÈ°πÔºåÊàë‰ª¨‰∏çÂæó‰∏çÂéªÁî®Ëøô‰∏ÄÈ°πÊù•Âπ≥Ë°°„ÄÇËøôÂ∞±Áõ∏ÂΩì‰∫éÊàë‰ª¨ÊÉ≥Ë¶ÅÊúÄÂ∞èÂåñ$A$Âä†‰∏äÊ≠£ÂàôÂåñÂèÇÊï∞$\lambda$ÔºåÁÑ∂Âêé‰πò‰ª•ÂÖ∂‰ªñÈ°π$B$ÂØπÂêßÔºüËøôÈáåÁöÑ$A$Ë°®Á§∫ËøôÈáåÁöÑÁ¨¨‰∏ÄÈ°πÔºåÂêåÊó∂ÊàëÁî®BË°®Á§∫Á¨¨‰∫åÈ°πÔºå‰ΩÜ‰∏çÂåÖÊã¨$\lambda$ÔºåÊàë‰ª¨‰∏çÊòØ‰ºòÂåñËøôÈáåÁöÑ$A+\lambda\times B$„ÄÇÊàë‰ª¨ÊâÄÂÅöÁöÑÊòØÈÄöËøáËÆæÁΩÆ‰∏çÂêåÊ≠£ÂàôÂèÇÊï∞$\lambda$ËææÂà∞‰ºòÂåñÁõÆÁöÑ„ÄÇËøôÊ†∑ÔºåÊàë‰ª¨Â∞±ËÉΩÂ§üÊùÉË°°ÂØπÂ∫îÁöÑÈ°πÔºåÊòØ‰ΩøÂæóËÆ≠ÁªÉÊ†∑Êú¨ÊãüÂêàÁöÑÊõ¥Â•Ω„ÄÇÂç≥ÊúÄÂ∞èÂåñ$A$„ÄÇËøòÊòØ‰øùËØÅÊ≠£ÂàôÂèÇÊï∞Ë∂≥Â§üÂ∞èÔºå‰πüÂç≥ÊòØÂØπ‰∫éBÈ°πËÄåË®ÄÔºå‰ΩÜÂØπ‰∫éÊîØÊåÅÂêëÈáèÊú∫ÔºåÊåâÁÖßÊÉØ‰æãÔºåÊàë‰ª¨Â∞Ü‰ΩøÁî®‰∏Ä‰∏™‰∏çÂêåÁöÑÂèÇÊï∞ÊõøÊç¢ËøôÈáå‰ΩøÁî®ÁöÑ$\lambda$Êù•ÊùÉË°°Ëøô‰∏§È°π„ÄÇ‰Ω†Áü•ÈÅìÔºåÂ∞±ÊòØÁ¨¨‰∏ÄÈ°πÂíåÁ¨¨‰∫åÈ°πÊàë‰ª¨‰æùÁÖßÊÉØ‰æã‰ΩøÁî®‰∏Ä‰∏™‰∏çÂêåÁöÑÂèÇÊï∞Áß∞‰∏∫$C$ÔºåÂêåÊó∂Êîπ‰∏∫‰ºòÂåñÁõÆÊ†áÔºå$C√óA+B$Âõ†Ê≠§ÔºåÂú®ÈÄªËæëÂõûÂΩí‰∏≠ÔºåÂ¶ÇÊûúÁªôÂÆö$\lambda$Ôºå‰∏Ä‰∏™ÈùûÂ∏∏Â§ßÁöÑÂÄºÔºåÊÑèÂë≥ÁùÄÁªô‰∫àBÊõ¥Â§ßÁöÑÊùÉÈáç„ÄÇËÄåËøôÈáåÔºåÂ∞±ÂØπÂ∫î‰∫éÂ∞Ü$C$ ËÆæÂÆö‰∏∫ÈùûÂ∏∏Â∞èÁöÑÂÄºÔºåÈÇ£‰πàÔºåÁõ∏Â∫îÁöÑÂ∞Ü‰ºöÁªô$B$ÊØîÁªô$A$Êõ¥Â§ßÁöÑÊùÉÈáç„ÄÇÂõ†Ê≠§ÔºåËøôÂè™ÊòØ‰∏ÄÁßç‰∏çÂêåÁöÑÊñπÂºèÊù•ÊéßÂà∂ËøôÁßçÊùÉË°°ÊàñËÄÖ‰∏ÄÁßç‰∏çÂêåÁöÑÊñπÊ≥ïÔºåÂç≥Áî®ÂèÇÊï∞Êù•ÂÜ≥ÂÆöÊòØÊõ¥ÂÖ≥ÂøÉÁ¨¨‰∏ÄÈ°πÁöÑ‰ºòÂåñÔºåËøòÊòØÊõ¥ÂÖ≥ÂøÉÁ¨¨‰∫åÈ°πÁöÑ‰ºòÂåñ„ÄÇÂΩìÁÑ∂‰Ω†‰πüÂèØ‰ª•ÊääËøôÈáåÁöÑÂèÇÊï∞$C$ ËÄÉËôëÊàê$1/\lambda$ÔºåÂêå $1/\lambda$ÊâÄÊâÆÊºîÁöÑËßíËâ≤Áõ∏ÂêåÔºåÂπ∂‰∏îËøô‰∏§‰∏™ÊñπÁ®ãÊàñËøô‰∏§‰∏™Ë°®ËææÂºèÂπ∂‰∏çÁõ∏ÂêåÔºåÂõ†‰∏∫$C=1/\lambda$Ôºå‰ΩÜÊòØ‰πüÂπ∂‰∏çÂÖ®ÊòØËøôÊ†∑ÔºåÂ¶ÇÊûúÂΩì$C=1/\lambda$Êó∂ÔºåËøô‰∏§‰∏™‰ºòÂåñÁõÆÊ†áÂ∫îÂΩìÂæóÂà∞Áõ∏ÂêåÁöÑÂÄºÔºåÁõ∏ÂêåÁöÑÊúÄ‰ºòÂÄº $\theta$„ÄÇÂõ†Ê≠§ÔºåÂ∞±Áî®ÂÆÉ‰ª¨Êù•‰ª£Êõø„ÄÇÈÇ£‰πàÔºåÊàëÁé∞Âú®Âà†ÊéâËøôÈáåÁöÑ$\lambda$ÔºåÂπ∂‰∏îÁî®Â∏∏Êï∞$C$Êù•‰ª£Êõø„ÄÇÂõ†Ê≠§ÔºåËøôÂ∞±ÂæóÂà∞‰∫ÜÂú®ÊîØÊåÅÂêëÈáèÊú∫‰∏≠Êàë‰ª¨ÁöÑÊï¥‰∏™‰ºòÂåñÁõÆÊ†áÂáΩÊï∞„ÄÇÁÑ∂ÂêéÊúÄÂ∞èÂåñËøô‰∏™ÁõÆÊ†áÂáΩÊï∞ÔºåÂæóÂà∞SVM Â≠¶‰π†Âà∞ÁöÑÂèÇÊï∞$C$„ÄÇ ÊúÄÂêéÊúâÂà´‰∫éÈÄªËæëÂõûÂΩíËæìÂá∫ÁöÑÊ¶ÇÁéá„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåÂΩìÊúÄÂ∞èÂåñ‰ª£‰ª∑ÂáΩÊï∞ÔºåËé∑ÂæóÂèÇÊï∞$\theta$Êó∂ÔºåÊîØÊåÅÂêëÈáèÊú∫ÊâÄÂÅöÁöÑÊòØÂÆÉÊù•Áõ¥Êé•È¢ÑÊµã$y$ÁöÑÂÄºÁ≠â‰∫é1ÔºåËøòÊòØÁ≠â‰∫é0„ÄÇÂõ†Ê≠§ÔºåËøô‰∏™ÂÅáËÆæÂáΩÊï∞‰ºöÈ¢ÑÊµã1„ÄÇÂΩì$\theta^Tx$Â§ß‰∫éÊàñËÄÖÁ≠â‰∫é0Êó∂ÔºåÊàñËÄÖÁ≠â‰∫é0Êó∂ÔºåÊâÄ‰ª•Â≠¶‰π†ÂèÇÊï∞$\theta$Â∞±ÊòØÊîØÊåÅÂêëÈáèÊú∫ÂÅáËÆæÂáΩÊï∞ÁöÑÂΩ¢Âºè„ÄÇÈÇ£‰πàÔºåËøôÂ∞±ÊòØÊîØÊåÅÂêëÈáèÊú∫Êï∞Â≠¶‰∏äÁöÑÂÆö‰πâ„ÄÇ Âú®Êé•‰∏ãÊù•ÁöÑËßÜÈ¢ë‰∏≠ÔºåËÆ©Êàë‰ª¨ÂÜçÂõûÂéª‰ªéÁõ¥ËßÇÁöÑËßíÂ∫¶ÁúãÁúã‰ºòÂåñÁõÆÊ†áÔºåÂÆûÈôÖ‰∏äÊòØÂú®ÂÅö‰ªÄ‰πàÔºå‰ª•ÂèäSVMÁöÑÂÅáËÆæÂáΩÊï∞Â∞Ü‰ºöÂ≠¶‰π†‰ªÄ‰πàÔºåÂêåÊó∂‰πü‰ºöË∞àË∞àÂ¶Ç‰ΩïÂÅö‰∫õËÆ∏‰øÆÊîπÔºåÂ≠¶‰π†Êõ¥Âä†Â§çÊùÇ„ÄÅÈùûÁ∫øÊÄßÁöÑÂáΩÊï∞„ÄÇ 12.2 Â§ßËæπÁïåÁöÑÁõ¥ËßÇÁêÜËß£ÂèÇËÄÉËßÜÈ¢ë: 12 - 2 - Large Margin Intuition (11 min).mkv ‰∫∫‰ª¨ÊúâÊó∂Â∞ÜÊîØÊåÅÂêëÈáèÊú∫Áúã‰ΩúÊòØÂ§ßÈó¥Ë∑ùÂàÜÁ±ªÂô®„ÄÇÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºåÊàëÂ∞Ü‰ªãÁªçÂÖ∂‰∏≠ÁöÑÂê´‰πâÔºåËøôÊúâÂä©‰∫éÊàë‰ª¨Áõ¥ËßÇÁêÜËß£SVMÊ®°ÂûãÁöÑÂÅáËÆæÊòØ‰ªÄ‰πàÊ†∑ÁöÑ„ÄÇ ËøôÊòØÊàëÁöÑÊîØÊåÅÂêëÈáèÊú∫Ê®°ÂûãÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåÂú®Â∑¶ËæπËøôÈáåÊàëÁîªÂá∫‰∫ÜÂÖ≥‰∫ézÁöÑ‰ª£‰ª∑ÂáΩÊï∞${\cos}t_1{(z)}$ÔºåÊ≠§ÂáΩÊï∞Áî®‰∫éÊ≠£Ê†∑Êú¨ÔºåËÄåÂú®Âè≥ËæπËøôÈáåÊàëÁîªÂá∫‰∫ÜÂÖ≥‰∫é$z$ÁöÑ‰ª£‰ª∑ÂáΩÊï∞${\cos}t_0{(z)}$ÔºåÊ®™ËΩ¥Ë°®Á§∫$z$ÔºåÁé∞Âú®ËÆ©Êàë‰ª¨ËÄÉËôë‰∏Ä‰∏ãÔºåÊúÄÂ∞èÂåñËøô‰∫õ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂøÖË¶ÅÊù°‰ª∂ÊòØ‰ªÄ‰πà„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™Ê≠£Ê†∑Êú¨Ôºå$y=1$ÔºåÂàôÂè™ÊúâÂú®$z>=1$Êó∂Ôºå‰ª£‰ª∑ÂáΩÊï∞${\cos}t_1{(z)}$ÊâçÁ≠â‰∫é0„ÄÇ Êç¢Âè•ËØùËØ¥ÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™Ê≠£Ê†∑Êú¨ÔºåÊàë‰ª¨‰ºöÂ∏åÊúõ$\theta^Tx$>=1ÔºåÂèç‰πãÔºåÂ¶ÇÊûú$y=0$ÔºåÊàë‰ª¨ËßÇÂØü‰∏Ä‰∏ãÔºåÂáΩÊï∞${\cos}t_0{(z)}$ÔºåÂÆÉÂè™ÊúâÂú®$z0Â§ßÁöÑËØùÔºåÊàë‰ª¨ÁöÑÊ®°Âûã‰ª£‰ª∑ÂáΩÊï∞ÂÄº‰∏∫0ÔºåÁ±ª‰ººÂú∞ÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™Ë¥üÊ†∑Êú¨ÔºåÂàô‰ªÖÈúÄË¶Å$\theta^Tx$\0ÔºåÊàë‰ª¨ÈúÄË¶ÅÁöÑÊòØÊØî0ÂÄºÂ§ßÂæàÂ§öÔºåÊØîÂ¶ÇÂ§ß‰∫éÁ≠â‰∫é1ÔºåÊàë‰πüÊÉ≥Ëøô‰∏™ÊØî0Â∞èÂæàÂ§öÔºåÊØîÂ¶ÇÊàëÂ∏åÊúõÂÆÉÂ∞è‰∫éÁ≠â‰∫é-1ÔºåËøôÂ∞±Áõ∏ÂΩì‰∫éÂú®ÊîØÊåÅÂêëÈáèÊú∫‰∏≠ÂµåÂÖ•‰∫Ü‰∏Ä‰∏™È¢ùÂ§ñÁöÑÂÆâÂÖ®Âõ†Â≠êÔºåÊàñËÄÖËØ¥ÂÆâÂÖ®ÁöÑÈó¥Ë∑ùÂõ†Â≠ê„ÄÇ ÂΩìÁÑ∂ÔºåÈÄªËæëÂõûÂΩíÂÅö‰∫ÜÁ±ª‰ººÁöÑ‰∫ãÊÉÖ„ÄÇ‰ΩÜÊòØËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏ãÔºåÂú®ÊîØÊåÅÂêëÈáèÊú∫‰∏≠ÔºåËøô‰∏™Âõ†Â≠ê‰ºöÂØºËá¥‰ªÄ‰πàÁªìÊûú„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàëÊé•‰∏ãÊù•‰ºöËÄÉËôë‰∏Ä‰∏™Áâπ‰æã„ÄÇÊàë‰ª¨Â∞ÜËøô‰∏™Â∏∏Êï∞$C$ËÆæÁΩÆÊàê‰∏Ä‰∏™ÈùûÂ∏∏Â§ßÁöÑÂÄº„ÄÇÊØîÂ¶ÇÊàë‰ª¨ÂÅáËÆæ$C$ÁöÑÂÄº‰∏∫100000ÊàñËÄÖÂÖ∂ÂÆÉÈùûÂ∏∏Â§ßÁöÑÊï∞ÔºåÁÑ∂ÂêéÊù•ËßÇÂØüÊîØÊåÅÂêëÈáèÊú∫‰ºöÁªôÂá∫‰ªÄ‰πàÁªìÊûúÔºü Â¶ÇÊûú $C$ÈùûÂ∏∏Â§ßÔºåÂàôÊúÄÂ∞èÂåñ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Â∞Ü‰ºöÂæàÂ∏åÊúõÊâæÂà∞‰∏Ä‰∏™‰ΩøÁ¨¨‰∏ÄÈ°π‰∏∫0ÁöÑÊúÄ‰ºòËß£„ÄÇÂõ†Ê≠§ÔºåËÆ©Êàë‰ª¨Â∞ùËØïÂú®‰ª£‰ª∑È°πÁöÑÁ¨¨‰∏ÄÈ°π‰∏∫0ÁöÑÊÉÖÂΩ¢‰∏ãÁêÜËß£ËØ•‰ºòÂåñÈóÆÈ¢ò„ÄÇÊØîÂ¶ÇÊàë‰ª¨ÂèØ‰ª•Êää$C$ËÆæÁΩÆÊàê‰∫ÜÈùûÂ∏∏Â§ßÁöÑÂ∏∏Êï∞ÔºåËøôÂ∞ÜÁªôÊàë‰ª¨‰∏Ä‰∫õÂÖ≥‰∫éÊîØÊåÅÂêëÈáèÊú∫Ê®°ÂûãÁöÑÁõ¥ËßÇÊÑüÂèó„ÄÇ ‚Äã $$\min_\limits{\theta}C\sum_\limits{i=1}^{m}\left[y^{(i)}{\cos}t_{1}\left(\theta^{T}x^{(i)}\right)+\left(1-y^{(i)}\right){\cos}t\left(\theta^{T}x^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{i=1}^{n}\theta^{2}_{j}$$ Êàë‰ª¨Â∑≤ÁªèÁúãÂà∞ËæìÂÖ•‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑Êú¨Ê†áÁ≠æ‰∏∫$y=1$Ôºå‰Ω†ÊÉ≥‰ª§Á¨¨‰∏ÄÈ°π‰∏∫0Ôºå‰Ω†ÈúÄË¶ÅÂÅöÁöÑÊòØÊâæÂà∞‰∏Ä‰∏™$\theta$Ôºå‰ΩøÂæó$\theta^Tx>=1$ÔºåÁ±ª‰ººÂú∞ÔºåÂØπ‰∫é‰∏Ä‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÔºåÊ†áÁ≠æ‰∏∫$y=0$Ôºå‰∏∫‰∫Ü‰Ωø${\cos}t_0{(z)}$ ÂáΩÊï∞ÁöÑÂÄº‰∏∫0ÔºåÊàë‰ª¨ÈúÄË¶Å$\theta^Tx=1$ÔºåÂ¶ÇÊûú $y^{(i)}$ÊòØÁ≠â‰∫é1 ÁöÑÔºå$\theta^Tx^{(i)}=1$ ÊàñËÄÖ$Œ∏^Tx^{(i)}=1$Ëøô‰∏™Á∫¶ÊùüÊâÄ‰ª£ÊõøÁöÑ„ÄÇÂõ†‰∏∫$Œ∏^Tx^{(i)}=p^{(i)}\cdot{\left\| \theta \right\|}$ ÔºåÂ∞ÜÂÖ∂ÂÜôÂÖ•Êàë‰ª¨ÁöÑ‰ºòÂåñÁõÆÊ†á„ÄÇÊàë‰ª¨Â∞Ü‰ºöÂæóÂà∞Ê≤°Êúâ‰∫ÜÁ∫¶ÊùüÔºå$Œ∏^Tx^{(i)}$ËÄåÂèòÊàê‰∫Ü$p^{(i)}\cdot{\left\| \theta \right\|}$„ÄÇ ÈúÄË¶ÅÊèêÈÜí‰∏ÄÁÇπÔºåÊàë‰ª¨‰πãÂâçÊõæËÆ≤ËøáËøô‰∏™‰ºòÂåñÁõÆÊ†áÂáΩÊï∞ÂèØ‰ª•Ë¢´ÂÜôÊàêÁ≠â‰∫é$\frac{1}{2}\left\| \theta \right\|^2$„ÄÇ Áé∞Âú®ËÆ©Êàë‰ª¨ËÄÉËôë‰∏ãÈù¢ËøôÈáåÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇÁé∞Âú®ÔºåÁªßÁª≠‰ΩøÁî®‰πãÂâçÁöÑÁÆÄÂåñÔºåÂç≥${{\theta }_{0}}=0$ÔºåÊàë‰ª¨Êù•Áúã‰∏Ä‰∏ãÊîØÊåÅÂêëÈáèÊú∫‰ºöÈÄâÊã©‰ªÄ‰πàÊ†∑ÁöÑÂÜ≥Á≠ñÁïå„ÄÇËøôÊòØ‰∏ÄÁßçÈÄâÊã©ÔºåÊàë‰ª¨ÂÅáËÆæÊîØÊåÅÂêëÈáèÊú∫‰ºöÈÄâÊã©Ëøô‰∏™ÂÜ≥Á≠ñËæπÁïå„ÄÇËøô‰∏çÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Â•ΩÁöÑÈÄâÊã©ÔºåÂõ†‰∏∫ÂÆÉÁöÑÈó¥Ë∑ùÂæàÂ∞è„ÄÇËøô‰∏™ÂÜ≥Á≠ñÁïåÁ¶ªËÆ≠ÁªÉÊ†∑Êú¨ÁöÑË∑ùÁ¶ªÂæàËøë„ÄÇÊàë‰ª¨Êù•Áúã‰∏Ä‰∏ã‰∏∫‰ªÄ‰πàÊîØÊåÅÂêëÈáèÊú∫‰∏ç‰ºöÈÄâÊã©ÂÆÉ„ÄÇ ÂØπ‰∫éËøôÊ†∑ÈÄâÊã©ÁöÑÂèÇÊï∞$\theta$ÔºåÂèØ‰ª•ÁúãÂà∞ÂèÇÊï∞ÂêëÈáè$\theta$‰∫ãÂÆû‰∏äÊòØÂíåÂÜ≥Á≠ñÁïåÊòØ90Â∫¶Ê≠£‰∫§ÁöÑÔºåÂõ†Ê≠§Ëøô‰∏™ÁªøËâ≤ÁöÑÂÜ≥Á≠ñÁïåÂØπÂ∫îÁùÄ‰∏Ä‰∏™ÂèÇÊï∞ÂêëÈáè$\theta$Ëøô‰∏™ÊñπÂêë,È°∫‰æøÊèê‰∏ÄÂè•${{\theta }_{0}}=0$ÁöÑÁÆÄÂåñ‰ªÖ‰ªÖÊÑèÂë≥ÁùÄÂÜ≥Á≠ñÁïåÂøÖÈ°ªÈÄöËøáÂéüÁÇπ$(0,0)$„ÄÇÁé∞Âú®ËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏ãËøôÂØπ‰∫é‰ºòÂåñÁõÆÊ†áÂáΩÊï∞ÊÑèÂë≥ÁùÄ‰ªÄ‰πà„ÄÇ ÊØîÂ¶ÇËøô‰∏™Ê†∑Êú¨ÔºåÊàë‰ª¨ÂÅáËÆæÂÆÉÊòØÊàëÁöÑÁ¨¨‰∏Ä‰∏™Ê†∑Êú¨$x^{(1)}$ÔºåÂ¶ÇÊûúÊàëËÄÉÂØüËøô‰∏™Ê†∑Êú¨Âà∞ÂèÇÊï∞$\theta$ÁöÑÊäïÂΩ±ÔºåÊäïÂΩ±ÊòØËøô‰∏™Áü≠ÁöÑÁ∫¢Á∫øÊÆµÔºåÂ∞±Á≠â‰∫é$p^{(1)}$ÔºåÂÆÉÈùûÂ∏∏Áü≠„ÄÇÁ±ª‰ººÂú∞ÔºåËøô‰∏™Ê†∑Êú¨Â¶ÇÊûúÂÆÉÊÅ∞Â•ΩÊòØ$x^{(2)}$ÔºåÊàëÁöÑÁ¨¨‰∫å‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÔºåÂàôÂÆÉÂà∞$\theta$ÁöÑÊäïÂΩ±Âú®ËøôÈáå„ÄÇÊàëÂ∞ÜÂÆÉÁîªÊàêÁ≤âËâ≤ÔºåËøô‰∏™Áü≠ÁöÑÁ≤âËâ≤Á∫øÊÆµÊòØ$p^{(2)}$ÔºåÂç≥Á¨¨‰∫å‰∏™Ê†∑Êú¨Âà∞ÊàëÁöÑÂèÇÊï∞ÂêëÈáè$\theta$ÁöÑÊäïÂΩ±„ÄÇÂõ†Ê≠§ÔºåËøô‰∏™ÊäïÂΩ±ÈùûÂ∏∏Áü≠„ÄÇ$p^{(2)}$‰∫ãÂÆû‰∏äÊòØ‰∏Ä‰∏™Ë¥üÂÄºÔºå$p^{(2)}$ÊòØÂú®Áõ∏ÂèçÁöÑÊñπÂêëÔºåËøô‰∏™ÂêëÈáèÂíåÂèÇÊï∞ÂêëÈáè$\theta$ÁöÑÂ§πËßíÂ§ß‰∫é90Â∫¶Ôºå$p^{(2)}$ÁöÑÂÄºÂ∞è‰∫é0„ÄÇ Êàë‰ª¨‰ºöÂèëÁé∞Ëøô‰∫õ$p^{(i)}$Â∞Ü‰ºöÊòØÈùûÂ∏∏Â∞èÁöÑÊï∞ÔºåÂõ†Ê≠§ÂΩìÊàë‰ª¨ËÄÉÂØü‰ºòÂåñÁõÆÊ†áÂáΩÊï∞ÁöÑÊó∂ÂÄôÔºåÂØπ‰∫éÊ≠£Ê†∑Êú¨ËÄåË®ÄÔºåÊàë‰ª¨ÈúÄË¶Å$p^{(i)}\cdot{\left\| \theta \right\|}>=1$,‰ΩÜÊòØÂ¶ÇÊûú $p^{(i)}$Âú®ËøôÈáåÈùûÂ∏∏Â∞è,ÈÇ£Â∞±ÊÑèÂë≥ÁùÄÊàë‰ª¨ÈúÄË¶Å$\theta$ÁöÑËåÉÊï∞ÈùûÂ∏∏Â§ß.Âõ†‰∏∫Â¶ÇÊûú $p^{(1)}$ ÂæàÂ∞è,ËÄåÊàë‰ª¨Â∏åÊúõ$p^{(1)}\cdot{\left\| \theta \right\|}>=1$,‰ª§ÂÖ∂ÂÆûÁé∞ÁöÑÂîØ‰∏ÄÁöÑÂäûÊ≥ïÂ∞±ÊòØËøô‰∏§‰∏™Êï∞ËæÉÂ§ß„ÄÇÂ¶ÇÊûú $p^{(1)}$ Â∞èÔºåÊàë‰ª¨Â∞±Â∏åÊúõ$\theta$ÁöÑËåÉÊï∞Â§ß„ÄÇÁ±ª‰ººÂú∞ÔºåÂØπ‰∫éË¥üÊ†∑Êú¨ËÄåË®ÄÊàë‰ª¨ÈúÄË¶Å$p^{(2)}\cdot{\left\|\theta \right\|}1ÔºåÂàôÂõ†‰∏∫$p^{(1)}$ÂèòÂ§ß‰∫ÜÔºå$\theta$ÁöÑËåÉÊï∞Â∞±ÂèØ‰ª•ÂèòÂ∞è‰∫Ü„ÄÇÂõ†Ê≠§ËøôÊÑèÂë≥ÁùÄÈÄöËøáÈÄâÊã©Âè≥ËæπÁöÑÂÜ≥Á≠ñÁïåÔºåËÄå‰∏çÊòØÂ∑¶ËæπÁöÑÈÇ£‰∏™ÔºåÊîØÊåÅÂêëÈáèÊú∫ÂèØ‰ª•‰ΩøÂèÇÊï∞$\theta$ÁöÑËåÉÊï∞ÂèòÂ∞èÂæàÂ§ö„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥‰ª§$\theta$ÁöÑËåÉÊï∞ÂèòÂ∞èÔºå‰ªéËÄå‰ª§$\theta$ËåÉÊï∞ÁöÑÂπ≥ÊñπÂèòÂ∞èÔºåÂ∞±ËÉΩËÆ©ÊîØÊåÅÂêëÈáèÊú∫ÈÄâÊã©Âè≥ËæπÁöÑÂÜ≥Á≠ñÁïå„ÄÇËøôÂ∞±ÊòØÊîØÊåÅÂêëÈáèÊú∫Â¶Ç‰ΩïËÉΩÊúâÊïàÂú∞‰∫ßÁîüÂ§ßÈó¥Ë∑ùÂàÜÁ±ªÁöÑÂéüÂõ†„ÄÇÁúãËøôÊù°ÁªøÁ∫øÔºåËøô‰∏™ÁªøËâ≤ÁöÑÂÜ≥Á≠ñÁïå„ÄÇÊàë‰ª¨Â∏åÊúõÊ≠£Ê†∑Êú¨ÂíåË¥üÊ†∑Êú¨ÊäïÂΩ±Âà∞$\theta$ÁöÑÂÄºÂ§ß„ÄÇË¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπÁöÑÂîØ‰∏ÄÊñπÂºèÂ∞±ÊòØÈÄâÊã©ËøôÊù°ÁªøÁ∫øÂÅöÂÜ≥Á≠ñÁïå„ÄÇËøôÊòØÂ§ßÈó¥Ë∑ùÂÜ≥Á≠ñÁïåÊù•Âå∫ÂàÜÂºÄÊ≠£Ê†∑Êú¨ÂíåË¥üÊ†∑Êú¨Ëøô‰∏™Èó¥Ë∑ùÁöÑÂÄº„ÄÇËøô‰∏™Èó¥Ë∑ùÁöÑÂÄºÂ∞±ÊòØ$p^{(1)},p^{(2)},p^{(3)}$Á≠âÁ≠âÁöÑÂÄº„ÄÇÈÄöËøáËÆ©Èó¥Ë∑ùÂèòÂ§ßÔºåÂç≥ÈÄöËøáËøô‰∫õ$p^{(1)},p^{(2)},p^{(3)}$Á≠âÁ≠âÁöÑÂÄºÔºåÊîØÊåÅÂêëÈáèÊú∫ÊúÄÁªàÂèØ‰ª•ÊâæÂà∞‰∏Ä‰∏™ËæÉÂ∞èÁöÑ$\theta$ËåÉÊï∞„ÄÇËøôÊ≠£ÊòØÊîØÊåÅÂêëÈáèÊú∫‰∏≠ÊúÄÂ∞èÂåñÁõÆÊ†áÂáΩÊï∞ÁöÑÁõÆÁöÑ„ÄÇ‰ª•‰∏äÂ∞±ÊòØ‰∏∫‰ªÄ‰πàÊîØÊåÅÂêëÈáèÊú∫ÊúÄÁªà‰ºöÊâæÂà∞Â§ßÈó¥Ë∑ùÂàÜÁ±ªÂô®ÁöÑÂéüÂõ†„ÄÇÂõ†‰∏∫ÂÆÉËØïÂõæÊûÅÂ§ßÂåñËøô‰∫õ$p^{(i)}$ÁöÑËåÉÊï∞ÔºåÂÆÉ‰ª¨ÊòØËÆ≠ÁªÉÊ†∑Êú¨Âà∞ÂÜ≥Á≠ñËæπÁïåÁöÑË∑ùÁ¶ª„ÄÇÊúÄÂêé‰∏ÄÁÇπÔºåÊàë‰ª¨ÁöÑÊé®ÂØºËá™ÂßãËá≥Áªà‰ΩøÁî®‰∫ÜËøô‰∏™ÁÆÄÂåñÂÅáËÆæÔºåÂ∞±ÊòØÂèÇÊï∞$Œ∏_0=0$„ÄÇÂ∞±ÂÉèÊàë‰πãÂâçÊèêÂà∞ÁöÑ„ÄÇËøô‰∏™ÁöÑ‰ΩúÁî®ÊòØÔºö$Œ∏_0=0$ÁöÑÊÑèÊÄùÊòØÊàë‰ª¨ËÆ©ÂÜ≥Á≠ñÁïåÈÄöËøáÂéüÁÇπ„ÄÇÂ¶ÇÊûú‰Ω†‰ª§$Œ∏_0$‰∏çÊòØ0ÁöÑËØùÔºåÂê´‰πâÂ∞±ÊòØ‰Ω†Â∏åÊúõÂÜ≥Á≠ñÁïå‰∏çÈÄöËøáÂéüÁÇπ„ÄÇÊàëÂ∞Ü‰∏ç‰ºöÂÅöÂÖ®ÈÉ®ÁöÑÊé®ÂØº„ÄÇÂÆûÈôÖ‰∏äÔºåÊîØÊåÅÂêëÈáèÊú∫‰∫ßÁîüÂ§ßÈó¥Ë∑ùÂàÜÁ±ªÂô®ÁöÑÁªìËÆ∫Ôºå‰ºöË¢´ËØÅÊòéÂêåÊ†∑ÊàêÁ´ãÔºåËØÅÊòéÊñπÂºèÊòØÈùûÂ∏∏Á±ª‰ººÁöÑÔºåÊòØÊàë‰ª¨ÂàöÂàöÂÅöÁöÑËØÅÊòéÁöÑÊé®Âπø„ÄÇ‰πãÂâçËßÜÈ¢ë‰∏≠ËØ¥ËøáÔºåÂç≥‰æø$Œ∏_0$‰∏çÁ≠â‰∫é0ÔºåÊîØÊåÅÂêëÈáèÊú∫Ë¶ÅÂÅöÁöÑ‰∫ãÊÉÖÈÉΩÊòØ‰ºòÂåñËøô‰∏™ÁõÆÊ†áÂáΩÊï∞ÂØπÂ∫îÁùÄ$C$ÂÄºÈùûÂ∏∏Â§ßÁöÑÊÉÖÂÜµÔºå‰ΩÜÊòØÂèØ‰ª•ËØ¥ÊòéÁöÑÊòØÔºåÂç≥‰æø$Œ∏_0$‰∏çÁ≠â‰∫é0ÔºåÊîØÊåÅÂêëÈáèÊú∫‰ªçÁÑ∂‰ºöÊâæÂà∞Ê≠£Ê†∑Êú¨ÂíåË¥üÊ†∑Êú¨‰πãÈó¥ÁöÑÂ§ßÈó¥Ë∑ùÂàÜÈöî„ÄÇÊÄª‰πãÔºåÊàë‰ª¨Ëß£Èáä‰∫Ü‰∏∫‰ªÄ‰πàÊîØÊåÅÂêëÈáèÊú∫ÊòØ‰∏Ä‰∏™Â§ßÈó¥Ë∑ùÂàÜÁ±ªÂô®„ÄÇÂú®‰∏ã‰∏ÄËäÇÊàë‰ª¨ÔºåÂ∞ÜÂºÄÂßãËÆ®ËÆ∫Â¶Ç‰ΩïÂà©Áî®ÊîØÊåÅÂêëÈáèÊú∫ÁöÑÂéüÁêÜÔºåÂ∫îÁî®ÂÆÉ‰ª¨Âª∫Á´ã‰∏Ä‰∏™Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ªÂô®„ÄÇ### 12.4 Ê†∏ÂáΩÊï∞1ÂèÇËÄÉËßÜÈ¢ë: 12 - 4 - Kernels I (16 min).mkvÂõûÈ°æÊàë‰ª¨‰πãÂâçËÆ®ËÆ∫ËøáÂèØ‰ª•‰ΩøÁî®È´òÁ∫ßÊï∞ÁöÑÂ§öÈ°πÂºèÊ®°ÂûãÊù•Ëß£ÂÜ≥Êó†Ê≥ïÁî®Áõ¥Á∫øËøõË°åÂàÜÈöîÁöÑÂàÜÁ±ªÈóÆÈ¢òÔºö‰∏∫‰∫ÜËé∑Âæó‰∏äÂõæÊâÄÁ§∫ÁöÑÂà§ÂÆöËæπÁïåÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂèØËÉΩÊòØ${{\theta }_{0}}+{{\theta }_{1}}{{x}_{1}}+{{\theta }_{2}}{{x}_{2}}+{{\theta }_{3}}{{x}_{1}}{{x}_{2}}+{{\theta }_{4}}x_{1}^{2}+{{\theta }_{5}}x_{2}^{2}+\cdots $ÁöÑÂΩ¢Âºè„ÄÇÊàë‰ª¨ÂèØ‰ª•Áî®‰∏ÄÁ≥ªÂàóÁöÑÊñ∞ÁöÑÁâπÂæÅfÊù•ÊõøÊç¢Ê®°Âûã‰∏≠ÁöÑÊØè‰∏ÄÈ°π„ÄÇ‰æãÂ¶Ç‰ª§Ôºö${{f}_{1}}={{x}_{1}},{{f}_{2}}={{x}_{2}},{{f}_{3}}={{x}_{1}}{{x}_{2}},{{f}_{4}}=x_{1}^{2},{{f}_{5}}=x_{2}^{2}$ ‚Ä¶ÂæóÂà∞$h_Œ∏(x)=f_1+f_2+‚Ä¶+f_n$„ÄÇÁÑ∂ËÄåÔºåÈô§‰∫ÜÂØπÂéüÊúâÁöÑÁâπÂæÅËøõË°åÁªÑÂêà‰ª•Â§ñÔºåÊúâÊ≤°ÊúâÊõ¥Â•ΩÁöÑÊñπÊ≥ïÊù•ÊûÑÈÄ†$f_1,f_2,f_3$ÔºüÊàë‰ª¨ÂèØ‰ª•Âà©Áî®Ê†∏ÂáΩÊï∞Êù•ËÆ°ÁÆóÂá∫Êñ∞ÁöÑÁâπÂæÅ„ÄÇ ÁªôÂÆö‰∏Ä‰∏™ËÆ≠ÁªÉÂÆû‰æã$x$ÔºåÊàë‰ª¨Âà©Áî®$x$ÁöÑÂêÑ‰∏™ÁâπÂæÅ‰∏éÊàë‰ª¨È¢ÑÂÖàÈÄâÂÆöÁöÑÂú∞Ê†á(landmarks)$l^{(1)},l^{(2)},l^{(3)}$ÁöÑËøë‰ººÁ®ãÂ∫¶Êù•ÈÄâÂèñÊñ∞ÁöÑÁâπÂæÅ$f_1,f_2,f_3$„ÄÇ ‰æãÂ¶ÇÔºö${{f}_{1}}=similarity(x,{{l}^{(1)}})=e(-\frac{{{\left\| x-{{l}^{(1)}} \right\|}^{2}}}{2{{\sigma }^{2}}})$ ÂÖ∂‰∏≠Ôºö${{\left\| x-{{l}^{(1)}} \right\|}^{2}}=\sum{_{j=1}^{n}}{{({{x}_{j}}-l_{j}^{(1)})}^{2}}$Ôºå‰∏∫ÂÆû‰æã$x$‰∏≠ÊâÄÊúâÁâπÂæÅ‰∏éÂú∞Ê†á$l^{(1)}$‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂíå„ÄÇ‰∏ä‰æã‰∏≠ÁöÑ$similarity(x,{{l}^{(1)}})$Â∞±ÊòØÊ†∏ÂáΩÊï∞ÔºåÂÖ∑‰ΩìËÄåË®ÄÔºåËøôÈáåÊòØ‰∏Ä‰∏™È´òÊñØÊ†∏ÂáΩÊï∞(Gaussian Kernel)„ÄÇ Ê≥®ÔºöËøô‰∏™ÂáΩÊï∞‰∏éÊ≠£ÊÄÅÂàÜÂ∏ÉÊ≤°‰ªÄ‰πàÂÆûÈôÖ‰∏äÁöÑÂÖ≥Á≥ªÔºåÂè™ÊòØÁúã‰∏äÂéªÂÉèËÄåÂ∑≤„ÄÇ Ëøô‰∫õÂú∞Ê†áÁöÑ‰ΩúÁî®ÊòØ‰ªÄ‰πàÔºüÂ¶ÇÊûú‰∏Ä‰∏™ËÆ≠ÁªÉÂÆû‰æã$x$‰∏éÂú∞Ê†á$L$‰πãÈó¥ÁöÑË∑ùÁ¶ªËøë‰ºº‰∫é0ÔºåÂàôÊñ∞ÁâπÂæÅ $f$Ëøë‰ºº‰∫é$e^{-0}=1$ÔºåÂ¶ÇÊûúËÆ≠ÁªÉÂÆû‰æã$x$‰∏éÂú∞Ê†á$L$‰πãÈó¥Ë∑ùÁ¶ªËæÉËøúÔºåÂàô$f$Ëøë‰ºº‰∫é$e^{-(‰∏Ä‰∏™ËæÉÂ§ßÁöÑÊï∞)}=0$„ÄÇ ÂÅáËÆæÊàë‰ª¨ÁöÑËÆ≠ÁªÉÂÆû‰æãÂê´Êúâ‰∏§‰∏™ÁâπÂæÅ[$x_{1}$ $x{_2}$]ÔºåÁªôÂÆöÂú∞Ê†á$l^{(1)}$‰∏é‰∏çÂêåÁöÑ$\sigma$ÂÄºÔºåËßÅ‰∏ãÂõæÔºö Âõæ‰∏≠Ê∞¥Âπ≥Èù¢ÁöÑÂùêÊ†á‰∏∫ $x_{1}$Ôºå$x_{2}$ËÄåÂûÇÁõ¥ÂùêÊ†áËΩ¥‰ª£Ë°®$f$„ÄÇÂèØ‰ª•ÁúãÂá∫ÔºåÂè™ÊúâÂΩì$x$‰∏é$l^{(1)}$ÈáçÂêàÊó∂$f$ÊâçÂÖ∑ÊúâÊúÄÂ§ßÂÄº„ÄÇÈöèÁùÄ$x$ÁöÑÊîπÂèò$f$ÂÄºÊîπÂèòÁöÑÈÄüÁéáÂèóÂà∞$\sigma^2$ÁöÑÊéßÂà∂„ÄÇ Âú®‰∏ãÂõæ‰∏≠ÔºåÂΩìÂÆû‰æãÂ§Ñ‰∫éÊ¥ãÁ∫¢Ëâ≤ÁöÑÁÇπ‰ΩçÁΩÆÂ§ÑÔºåÂõ†‰∏∫ÂÖ∂Á¶ª$l^{(1)}$Êõ¥ËøëÔºå‰ΩÜÊòØÁ¶ª$l^{(2)}$Âíå$l^{(3)}$ËæÉËøúÔºåÂõ†Ê≠§$f_1$Êé•Ëøë1ÔºåËÄå$f_2$,$f_3$Êé•Ëøë0„ÄÇÂõ†Ê≠§$h_Œ∏(x)=Œ∏_0+Œ∏_1f_1+Œ∏_2f_2+Œ∏_1f_3>0$ÔºåÂõ†Ê≠§È¢ÑÊµã$y=1$„ÄÇÂêåÁêÜÂèØ‰ª•Ê±ÇÂá∫ÔºåÂØπ‰∫éÁ¶ª$l^{(2)}$ËæÉËøëÁöÑÁªøËâ≤ÁÇπÔºå‰πüÈ¢ÑÊµã$y=1$Ôºå‰ΩÜÊòØÂØπ‰∫éËìùÁªøËâ≤ÁöÑÁÇπÔºåÂõ†‰∏∫ÂÖ∂Á¶ª‰∏â‰∏™Âú∞Ê†áÈÉΩËæÉËøúÔºåÈ¢ÑÊµã$y=0$„ÄÇ ËøôÊ†∑ÔºåÂõæ‰∏≠Á∫¢Ëâ≤ÁöÑÂ∞ÅÈó≠Êõ≤Á∫øÊâÄË°®Á§∫ÁöÑËåÉÂõ¥Ôºå‰æøÊòØÊàë‰ª¨‰æùÊçÆ‰∏Ä‰∏™Âçï‰∏ÄÁöÑËÆ≠ÁªÉÂÆû‰æãÂíåÊàë‰ª¨ÈÄâÂèñÁöÑÂú∞Ê†áÊâÄÂæóÂá∫ÁöÑÂà§ÂÆöËæπÁïåÔºåÂú®È¢ÑÊµãÊó∂ÔºåÊàë‰ª¨ÈááÁî®ÁöÑÁâπÂæÅ‰∏çÊòØËÆ≠ÁªÉÂÆû‰æãÊú¨Ë∫´ÁöÑÁâπÂæÅÔºåËÄåÊòØÈÄöËøáÊ†∏ÂáΩÊï∞ËÆ°ÁÆóÂá∫ÁöÑÊñ∞ÁâπÂæÅ$f_1,f_2,f_3$„ÄÇ 12.5 Ê†∏ÂáΩÊï∞2ÂèÇËÄÉËßÜÈ¢ë: 12 - 5 - Kernels II (16 min).mkv Âú®‰∏ä‰∏ÄËäÇËßÜÈ¢ëÈáåÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜÊ†∏ÂáΩÊï∞Ëøô‰∏™ÊÉ≥Ê≥ïÔºå‰ª•ÂèäÊÄéÊ†∑Âà©Áî®ÂÆÉÂéªÂÆûÁé∞ÊîØÊåÅÂêëÈáèÊú∫ÁöÑ‰∏Ä‰∫õÊñ∞ÁâπÊÄß„ÄÇÂú®Ëøô‰∏ÄËäÇËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜË°•ÂÖÖ‰∏Ä‰∫õÁº∫Â§±ÁöÑÁªÜËäÇÔºåÂπ∂ÁÆÄÂçïÁöÑ‰ªãÁªç‰∏Ä‰∏ãÊÄé‰πàÂú®ÂÆûÈôÖ‰∏≠‰ΩøÁî®Â∫îÁî®Ëøô‰∫õÊÉ≥Ê≥ï„ÄÇ Â¶Ç‰ΩïÈÄâÊã©Âú∞Ê†áÔºü Êàë‰ª¨ÈÄöÂ∏∏ÊòØÊ†πÊçÆËÆ≠ÁªÉÈõÜÁöÑÊï∞ÈáèÈÄâÊã©Âú∞Ê†áÁöÑÊï∞ÈáèÔºåÂç≥Â¶ÇÊûúËÆ≠ÁªÉÈõÜ‰∏≠Êúâ$m$‰∏™ÂÆû‰æãÔºåÂàôÊàë‰ª¨ÈÄâÂèñ$m$‰∏™Âú∞Ê†áÔºåÂπ∂‰∏î‰ª§:$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},.....,l^{(m)}=x^{(m)}$„ÄÇËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÂú®‰∫éÔºöÁé∞Âú®Êàë‰ª¨ÂæóÂà∞ÁöÑÊñ∞ÁâπÂæÅÊòØÂª∫Á´ãÂú®ÂéüÊúâÁâπÂæÅ‰∏éËÆ≠ÁªÉÈõÜ‰∏≠ÊâÄÊúâÂÖ∂‰ªñÁâπÂæÅ‰πãÈó¥Ë∑ùÁ¶ªÁöÑÂü∫Á°Ä‰πã‰∏äÁöÑÔºåÂç≥Ôºö ‰∏ãÈù¢Êàë‰ª¨Â∞ÜÊ†∏ÂáΩÊï∞ËøêÁî®Âà∞ÊîØÊåÅÂêëÈáèÊú∫‰∏≠Ôºå‰øÆÊîπÊàë‰ª¨ÁöÑÊîØÊåÅÂêëÈáèÊú∫ÂÅáËÆæ‰∏∫Ôºö ‚Ä¢ ÁªôÂÆö$x$ÔºåËÆ°ÁÆóÊñ∞ÁâπÂæÅ$f$ÔºåÂΩì$Œ∏^Tf&gt;=0$ Êó∂ÔºåÈ¢ÑÊµã $y=1$ÔºåÂê¶ÂàôÂèç‰πã„ÄÇ Áõ∏Â∫îÂú∞‰øÆÊîπ‰ª£‰ª∑ÂáΩÊï∞‰∏∫Ôºö$\sum{_{j=1}^{n=m}}\theta _{j}^{2}={{\theta}^{T}}\theta $Ôºå $min C\sum\limits_{i=1}^{m}{[{{y}^{(i)}}cos {{t}_{1}}}( {{\theta }^{T}}{{f}^{(i)}})+(1-{{y}^{(i)}})cos {{t}_{0}}( {{\theta }^{T}}{{f}^{(i)}})]+\frac{1}{2}\sum\limits_{j=1}^{n=m}{\theta _{j}^{2}}$. Âú®ÂÖ∑‰ΩìÂÆûÊñΩËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨ËøòÈúÄË¶ÅÂØπÊúÄÂêéÁöÑÊ≠£ÂàôÂåñÈ°πËøõË°å‰∫õÂæÆË∞ÉÊï¥ÔºåÂú®ËÆ°ÁÆó$\sum{_{j=1}^{n=m}}\theta _{j}^{2}={{\theta}^{T}}\theta $Êó∂ÔºåÊàë‰ª¨Áî®$Œ∏^TMŒ∏$‰ª£Êõø$Œ∏^TŒ∏$ÔºåÂÖ∂‰∏≠$M$ÊòØÊ†πÊçÆÊàë‰ª¨ÈÄâÊã©ÁöÑÊ†∏ÂáΩÊï∞ËÄå‰∏çÂêåÁöÑ‰∏Ä‰∏™Áü©Èòµ„ÄÇËøôÊ†∑ÂÅöÁöÑÂéüÂõ†ÊòØ‰∏∫‰∫ÜÁÆÄÂåñËÆ°ÁÆó„ÄÇ ÁêÜËÆ∫‰∏äËÆ≤ÔºåÊàë‰ª¨‰πüÂèØ‰ª•Âú®ÈÄªËæëÂõûÂΩí‰∏≠‰ΩøÁî®Ê†∏ÂáΩÊï∞Ôºå‰ΩÜÊòØ‰∏äÈù¢‰ΩøÁî® $M$Êù•ÁÆÄÂåñËÆ°ÁÆóÁöÑÊñπÊ≥ï‰∏çÈÄÇÁî®‰∏éÈÄªËæëÂõûÂΩíÔºåÂõ†Ê≠§ËÆ°ÁÆóÂ∞ÜÈùûÂ∏∏ËÄóË¥πÊó∂Èó¥„ÄÇ Âú®Ê≠§ÔºåÊàë‰ª¨‰∏ç‰ªãÁªçÊúÄÂ∞èÂåñÊîØÊåÅÂêëÈáèÊú∫ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÊñπÊ≥ïÔºå‰Ω†ÂèØ‰ª•‰ΩøÁî®Áé∞ÊúâÁöÑËΩØ‰ª∂ÂåÖÔºàÂ¶Çliblinear,libsvmÁ≠âÔºâ„ÄÇÂú®‰ΩøÁî®Ëøô‰∫õËΩØ‰ª∂ÂåÖÊúÄÂ∞èÂåñÊàë‰ª¨ÁöÑ‰ª£‰ª∑ÂáΩÊï∞‰πãÂâçÔºåÊàë‰ª¨ÈÄöÂ∏∏ÈúÄË¶ÅÁºñÂÜôÊ†∏ÂáΩÊï∞ÔºåÂπ∂‰∏îÂ¶ÇÊûúÊàë‰ª¨‰ΩøÁî®È´òÊñØÊ†∏ÂáΩÊï∞ÔºåÈÇ£‰πàÂú®‰ΩøÁî®‰πãÂâçËøõË°åÁâπÂæÅÁº©ÊîæÊòØÈùûÂ∏∏ÂøÖË¶ÅÁöÑ„ÄÇ Âè¶Â§ñÔºåÊîØÊåÅÂêëÈáèÊú∫‰πüÂèØ‰ª•‰∏ç‰ΩøÁî®Ê†∏ÂáΩÊï∞Ôºå‰∏ç‰ΩøÁî®Ê†∏ÂáΩÊï∞ÂèàÁß∞‰∏∫Á∫øÊÄßÊ†∏ÂáΩÊï∞(linear kernel)ÔºåÂΩìÊàë‰ª¨‰∏çÈááÁî®ÈùûÂ∏∏Â§çÊùÇÁöÑÂáΩÊï∞ÔºåÊàñËÄÖÊàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜÁâπÂæÅÈùûÂ∏∏Â§öËÄåÂÆû‰æãÈùûÂ∏∏Â∞ëÁöÑÊó∂ÂÄôÔºåÂèØ‰ª•ÈááÁî®ËøôÁßç‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇ ‰∏ãÈù¢ÊòØÊîØÊåÅÂêëÈáèÊú∫ÁöÑ‰∏§‰∏™ÂèÇÊï∞$C$Âíå$\sigma$ÁöÑÂΩ±ÂìçÔºö $C=1/\lambda$ $C$ ËæÉÂ§ßÊó∂ÔºåÁõ∏ÂΩì‰∫é$\lambda$ËæÉÂ∞èÔºåÂèØËÉΩ‰ºöÂØºËá¥ËøáÊãüÂêàÔºåÈ´òÊñπÂ∑ÆÔºõ $C$ ËæÉÂ∞èÊó∂ÔºåÁõ∏ÂΩì‰∫é$Œª$ËæÉÂ§ßÔºåÂèØËÉΩ‰ºöÂØºËá¥‰ΩéÊãüÂêàÔºåÈ´òÂÅèÂ∑ÆÔºõ $\sigma$ËæÉÂ§ßÊó∂ÔºåÂèØËÉΩ‰ºöÂØºËá¥‰ΩéÊñπÂ∑ÆÔºåÈ´òÂÅèÂ∑ÆÔºõ $\sigma$ËæÉÂ∞èÊó∂ÔºåÂèØËÉΩ‰ºöÂØºËá¥‰ΩéÂÅèÂ∑ÆÔºåÈ´òÊñπÂ∑Æ„ÄÇ Â¶ÇÊûú‰Ω†Áúã‰∫ÜÊú¨Âë®ÁöÑÁºñÁ®ã‰Ωú‰∏öÔºå‰Ω†Â∞±ËÉΩ‰∫≤Ëá™ÂÆûÁé∞Ëøô‰∫õÊÉ≥Ê≥ïÔºåÂπ∂‰∫≤ÁúºÁúãÂà∞Ëøô‰∫õÊïàÊûú„ÄÇËøôÂ∞±ÊòØÂà©Áî®Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÔºåÂ∏åÊúõËøô‰∫õÂÖ≥‰∫éÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÁöÑËÆ®ËÆ∫ÔºåËÉΩÁªô‰Ω†‰∏Ä‰∫õÂØπ‰∫éÁÆóÊ≥ïÁªìÊûúÈ¢ÑÊúüÁöÑÁõ¥ËßÇÂç∞Ë±°„ÄÇ 12.6 ‰ΩøÁî®ÊîØÊåÅÂêëÈáèÊú∫ÂèÇËÄÉËßÜÈ¢ë: 12 - 6 - Using An SVM (21 min).mkv ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊàë‰ª¨Â∑≤ÁªèËÆ®ËÆ∫‰∫ÜSVMÊØîËæÉÊäΩË±°ÁöÑÂ±ÇÈù¢ÔºåÂú®Ëøô‰∏™ËßÜÈ¢ë‰∏≠ÊàëÂ∞ÜË¶ÅËÆ®ËÆ∫Âà∞‰∏∫‰∫ÜËøêË°åÊàñËÄÖËøêÁî®SVM„ÄÇ‰Ω†ÂÆûÈôÖ‰∏äÊâÄÈúÄË¶ÅÁöÑ‰∏Ä‰∫õ‰∏úË•øÔºöÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÔºåÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁâπÂà´‰ºòÂåñÁöÑÈóÆÈ¢ò„ÄÇ‰ΩÜÊòØÂ∞±Â¶ÇÂú®‰πãÂâçÁöÑËßÜÈ¢ë‰∏≠ÊàëÁÆÄÂçïÊèêÂà∞ÁöÑÔºåÊàëÁúüÁöÑ‰∏çÂª∫ËÆÆ‰Ω†Ëá™Â∑±ÂÜôËΩØ‰ª∂Êù•Ê±ÇËß£ÂèÇÊï∞$\theta$ÔºåÂõ†Ê≠§Áî±‰∫é‰ªäÂ§©Êàë‰ª¨‰∏≠ÁöÑÂæàÂ∞ë‰∫∫ÔºåÊàñËÄÖÂÖ∂ÂÆûÊ≤°Êúâ‰∫∫ËÄÉËôëËøáËá™Â∑±ÂÜô‰ª£Á†ÅÊù•ËΩ¨Êç¢Áü©ÈòµÔºåÊàñÊ±Ç‰∏Ä‰∏™Êï∞ÁöÑÂπ≥ÊñπÊ†πÁ≠âÊàë‰ª¨Âè™ÊòØÁü•ÈÅìÂ¶Ç‰ΩïÂéªË∞ÉÁî®Â∫ìÂáΩÊï∞Êù•ÂÆûÁé∞Ëøô‰∫õÂäüËÉΩ„ÄÇÂêåÊ†∑ÁöÑÔºåÁî®‰ª•Ëß£ÂÜ≥SVMÊúÄ‰ºòÂåñÈóÆÈ¢òÁöÑËΩØ‰ª∂ÂæàÂ§çÊùÇÔºå‰∏îÂ∑≤ÁªèÊúâÁ†îÁ©∂ËÄÖÂÅö‰∫ÜÂæàÂ§öÂπ¥Êï∞ÂÄº‰ºòÂåñ‰∫Ü„ÄÇÂõ†Ê≠§‰Ω†ÊèêÂá∫Â•ΩÁöÑËΩØ‰ª∂Â∫ìÂíåÂ•ΩÁöÑËΩØ‰ª∂ÂåÖÊù•ÂÅöËøôÊ†∑‰∏Ä‰∫õ‰∫ãÂÑø„ÄÇÁÑ∂ÂêéÂº∫ÁÉàÂª∫ËÆÆ‰ΩøÁî®È´ò‰ºòÂåñËΩØ‰ª∂Â∫ì‰∏≠ÁöÑ‰∏Ä‰∏™ÔºåËÄå‰∏çÊòØÂ∞ùËØïËá™Â∑±ËêΩÂÆû‰∏Ä‰∫õÊï∞ÊçÆ„ÄÇÊúâËÆ∏Â§öÂ•ΩÁöÑËΩØ‰ª∂Â∫ìÔºåÊàëÊ≠£Â•ΩÁî®ÂæóÊúÄÂ§öÁöÑ‰∏§‰∏™ÊòØliblinearÂíålibsvmÔºå‰ΩÜÊòØÁúüÁöÑÊúâÂæàÂ§öËΩØ‰ª∂Â∫ìÂèØ‰ª•Áî®Êù•ÂÅöËøô‰ª∂‰∫ãÂÑø„ÄÇ‰Ω†ÂèØ‰ª•ËøûÊé•ËÆ∏Â§ö‰Ω†ÂèØËÉΩ‰ºöÁî®Êù•ÁºñÂÜôÂ≠¶‰π†ÁÆóÊ≥ïÁöÑ‰∏ªË¶ÅÁºñÁ®ãËØ≠Ë®Ä„ÄÇ Âú®È´òÊñØÊ†∏ÂáΩÊï∞‰πãÂ§ñÊàë‰ª¨ËøòÊúâÂÖ∂‰ªñ‰∏Ä‰∫õÈÄâÊã©ÔºåÂ¶ÇÔºö Â§öÈ°πÂºèÊ†∏ÂáΩÊï∞ÔºàPolynomial KernelÔºâ Â≠óÁ¨¶‰∏≤Ê†∏ÂáΩÊï∞ÔºàString kernelÔºâ Âç°ÊñπÊ†∏ÂáΩÊï∞Ôºà chi-square kernelÔºâ Áõ¥ÊñπÂõæ‰∫§ÈõÜÊ†∏ÂáΩÊï∞Ôºàhistogram intersection kernelÔºâ Á≠âÁ≠â‚Ä¶ Ëøô‰∫õÊ†∏ÂáΩÊï∞ÁöÑÁõÆÊ†á‰πüÈÉΩÊòØÊ†πÊçÆËÆ≠ÁªÉÈõÜÂíåÂú∞Ê†á‰πãÈó¥ÁöÑË∑ùÁ¶ªÊù•ÊûÑÂª∫Êñ∞ÁâπÂæÅÔºåËøô‰∫õÊ†∏ÂáΩÊï∞ÈúÄË¶ÅÊª°Ë∂≥Mercer‚ÄôsÂÆöÁêÜÔºåÊâçËÉΩË¢´ÊîØÊåÅÂêëÈáèÊú∫ÁöÑ‰ºòÂåñËΩØ‰ª∂Ê≠£Á°ÆÂ§ÑÁêÜ„ÄÇ Â§öÁ±ªÂàÜÁ±ªÈóÆÈ¢ò ÂÅáËÆæÊàë‰ª¨Âà©Áî®‰πãÂâç‰ªãÁªçÁöÑ‰∏ÄÂØπÂ§öÊñπÊ≥ïÊù•Ëß£ÂÜ≥‰∏Ä‰∏™Â§öÁ±ªÂàÜÁ±ªÈóÆÈ¢ò„ÄÇÂ¶ÇÊûú‰∏ÄÂÖ±Êúâ$k$‰∏™Á±ªÔºåÂàôÊàë‰ª¨ÈúÄË¶Å$k$‰∏™Ê®°ÂûãÔºå‰ª•Âèä$k$‰∏™ÂèÇÊï∞ÂêëÈáè$\theta $„ÄÇÊàë‰ª¨ÂêåÊ†∑‰πüÂèØ‰ª•ËÆ≠ÁªÉk‰∏™ÊîØÊåÅÂêëÈáèÊú∫Êù•Ëß£ÂÜ≥Â§öÁ±ªÂàÜÁ±ªÈóÆÈ¢ò„ÄÇ‰ΩÜÊòØÂ§ßÂ§öÊï∞ÊîØÊåÅÂêëÈáèÊú∫ËΩØ‰ª∂ÂåÖÈÉΩÊúâÂÜÖÁΩÆÁöÑÂ§öÁ±ªÂàÜÁ±ªÂäüËÉΩÔºåÊàë‰ª¨Âè™Ë¶ÅÁõ¥Êé•‰ΩøÁî®Âç≥ÂèØ„ÄÇ Â∞ΩÁÆ°‰Ω†‰∏çÂéªÂÜô‰Ω†Ëá™Â∑±ÁöÑSVMÁöÑ‰ºòÂåñËΩØ‰ª∂Ôºå‰ΩÜÊòØ‰Ω†‰πüÈúÄË¶ÅÂÅöÂá†‰ª∂‰∫ãÔºö 1„ÄÅÊòØÊèêÂá∫ÂèÇÊï∞$C$ÁöÑÈÄâÊã©„ÄÇÊàë‰ª¨Âú®‰πãÂâçÁöÑËßÜÈ¢ë‰∏≠ËÆ®ËÆ∫ËøáËØØÂ∑Æ/ÊñπÂ∑ÆÂú®ËøôÊñπÈù¢ÁöÑÊÄßË¥®„ÄÇ 2„ÄÅ‰Ω†‰πüÈúÄË¶ÅÈÄâÊã©ÂÜÖÊ†∏ÂèÇÊï∞Êàñ‰Ω†ÊÉ≥Ë¶Å‰ΩøÁî®ÁöÑÁõ∏‰ººÂáΩÊï∞ÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÈÄâÊã©ÊòØÔºöÊàë‰ª¨ÈÄâÊã©‰∏çÈúÄË¶Å‰ªª‰ΩïÂÜÖÊ†∏ÂèÇÊï∞ÔºåÊ≤°ÊúâÂÜÖÊ†∏ÂèÇÊï∞ÁöÑÁêÜÂøµÔºå‰πüÂè´Á∫øÊÄßÊ†∏ÂáΩÊï∞„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÊúâ‰∫∫ËØ¥‰ªñ‰ΩøÁî®‰∫ÜÁ∫øÊÄßÊ†∏ÁöÑSVMÔºàÊîØÊåÅÂêëÈáèÊú∫ÔºâÔºåËøôÂ∞±ÊÑèÂë≥Ëøô‰ªñ‰ΩøÁî®‰∫Ü‰∏çÂ∏¶ÊúâÊ†∏ÂáΩÊï∞ÁöÑSVMÔºàÊîØÊåÅÂêëÈáèÊú∫Ôºâ„ÄÇ ‰ªéÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºåÊàë‰ª¨ÂæóÂà∞‰∫ÜÊîØÊåÅÂêëÈáèÊú∫Ê®°ÂûãÔºåÂú®‰∏§ËÄÖ‰πãÈó¥ÔºåÊàë‰ª¨Â∫îËØ•Â¶Ç‰ΩïÈÄâÊã©Âë¢Ôºü ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÊôÆÈÅç‰ΩøÁî®ÁöÑÂáÜÂàôÔºö $n$‰∏∫ÁâπÂæÅÊï∞Ôºå$m$‰∏∫ËÆ≠ÁªÉÊ†∑Êú¨Êï∞„ÄÇ (1)Â¶ÇÊûúÁõ∏ËæÉ‰∫é$m$ËÄåË®ÄÔºå$n$Ë¶ÅÂ§ßËÆ∏Â§öÔºåÂç≥ËÆ≠ÁªÉÈõÜÊï∞ÊçÆÈáè‰∏çÂ§üÊîØÊåÅÊàë‰ª¨ËÆ≠ÁªÉ‰∏Ä‰∏™Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÊ®°ÂûãÔºåÊàë‰ª¨ÈÄâÁî®ÈÄªËæëÂõûÂΩíÊ®°ÂûãÊàñËÄÖ‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇ (2)Â¶ÇÊûú$n$ËæÉÂ∞èÔºåËÄå‰∏î$m$Â§ßÂ∞è‰∏≠Á≠âÔºå‰æãÂ¶Ç$n$Âú® 1-1000 ‰πãÈó¥ÔºåËÄå$m$Âú®10-10000‰πãÈó¥Ôºå‰ΩøÁî®È´òÊñØÊ†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇ (3)Â¶ÇÊûú$n$ËæÉÂ∞èÔºåËÄå$m$ËæÉÂ§ßÔºå‰æãÂ¶Ç$n$Âú®1-1000‰πãÈó¥ÔºåËÄå$m$Â§ß‰∫é50000ÔºåÂàô‰ΩøÁî®ÊîØÊåÅÂêëÈáèÊú∫‰ºöÈùûÂ∏∏ÊÖ¢ÔºåËß£ÂÜ≥ÊñπÊ°àÊòØÂàõÈÄ†„ÄÅÂ¢ûÂä†Êõ¥Â§öÁöÑÁâπÂæÅÔºåÁÑ∂Âêé‰ΩøÁî®ÈÄªËæëÂõûÂΩíÊàñ‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇ ÂÄºÂæó‰∏ÄÊèêÁöÑÊòØÔºåÁ•ûÁªèÁΩëÁªúÂú®‰ª•‰∏ä‰∏âÁßçÊÉÖÂÜµ‰∏ãÈÉΩÂèØËÉΩ‰ºöÊúâËæÉÂ•ΩÁöÑË°®Áé∞Ôºå‰ΩÜÊòØËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÂèØËÉΩÈùûÂ∏∏ÊÖ¢ÔºåÈÄâÊã©ÊîØÊåÅÂêëÈáèÊú∫ÁöÑÂéüÂõ†‰∏ªË¶ÅÂú®‰∫éÂÆÉÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÊòØÂá∏ÂáΩÊï∞Ôºå‰∏çÂ≠òÂú®Â±ÄÈÉ®ÊúÄÂ∞èÂÄº„ÄÇ ‰ªäÂ§©ÁöÑSVMÂåÖ‰ºöÂ∑•‰ΩúÂæóÂæàÂ•ΩÔºå‰ΩÜÊòØÂÆÉ‰ª¨‰ªçÁÑ∂‰ºöÊúâ‰∏Ä‰∫õÊÖ¢„ÄÇÂΩì‰Ω†ÊúâÈùûÂ∏∏ÈùûÂ∏∏Â§ßÁöÑËÆ≠ÁªÉÈõÜÔºå‰∏îÁî®È´òÊñØÊ†∏ÂáΩÊï∞ÊòØÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÊàëÁªèÂ∏∏‰ºöÂÅöÁöÑÊòØÂ∞ùËØïÊâãÂä®Âú∞ÂàõÂª∫ÔºåÊã•ÊúâÊõ¥Â§öÁöÑÁâπÂæÅÂèòÈáèÔºåÁÑ∂ÂêéÁî®ÈÄªËæëÂõûÂΩíÊàñËÄÖ‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇÂ¶ÇÊûú‰Ω†ÁúãÂà∞Ëøô‰∏™ÂπªÁÅØÁâáÔºåÁúãÂà∞‰∫ÜÈÄªËæëÂõûÂΩíÔºåÊàñËÄÖ‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫„ÄÇÂú®Ëøô‰∏™‰∏§‰∏™Âú∞ÊñπÔºåÊàëÊääÂÆÉ‰ª¨ÊîæÂú®‰∏ÄËµ∑ÊòØÊúâÂéüÂõ†ÁöÑ„ÄÇÂéüÂõ†ÊòØÔºöÈÄªËæëÂõûÂΩíÂíå‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫ÂÆÉ‰ª¨ÈÉΩÊòØÈùûÂ∏∏Áõ∏‰ººÁöÑÁÆóÊ≥ïÔºå‰∏çÁÆ°ÊòØÈÄªËæëÂõûÂΩíËøòÊòØ‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑSVMÔºåÈÄöÂ∏∏ÈÉΩ‰ºöÂÅöÁõ∏‰ººÁöÑ‰∫ãÊÉÖÔºåÂπ∂ÁªôÂá∫Áõ∏‰ººÁöÑÁªìÊûú„ÄÇ‰ΩÜÊòØÊ†πÊçÆ‰Ω†ÂÆûÁé∞ÁöÑÊÉÖÂÜµÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÂèØËÉΩ‰ºöÊØîÂè¶‰∏Ä‰∏™Êõ¥Âä†ÊúâÊïà„ÄÇ‰ΩÜÊòØÂú®ÂÖ∂‰∏≠‰∏Ä‰∏™ÁÆóÊ≥ïÂ∫îÁî®ÁöÑÂú∞ÊñπÔºåÈÄªËæëÂõûÂΩíÊàñ‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑSVMÂè¶‰∏Ä‰∏™‰πüÂæàÊúâÂèØËÉΩÂæàÊúâÊïà„ÄÇ‰ΩÜÊòØÈöèÁùÄSVMÁöÑÂ§çÊùÇÂ∫¶Â¢ûÂä†ÔºåÂΩì‰Ω†‰ΩøÁî®‰∏çÂêåÁöÑÂÜÖÊ†∏ÂáΩÊï∞Êù•Â≠¶‰π†Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞Êó∂ÔºåËøô‰∏™‰ΩìÁ≥ªÔºå‰Ω†Áü•ÈÅìÁöÑÔºåÂΩì‰Ω†ÊúâÂ§öËææ1‰∏áÔºà10,000ÔºâÁöÑÊ†∑Êú¨Êó∂Ôºå‰πüÂèØËÉΩÊòØ5‰∏áÔºà50,000ÔºâÔºå‰Ω†ÁöÑÁâπÂæÅÂèòÈáèÁöÑÊï∞ÈáèËøôÊòØÁõ∏ÂΩìÂ§ßÁöÑ„ÄÇÈÇ£ÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Â∏∏ËßÅÁöÑ‰ΩìÁ≥ªÔºå‰πüËÆ∏Âú®Ëøô‰∏™‰ΩìÁ≥ªÈáåÔºå‰∏çÂ∏¶Ê†∏ÂáΩÊï∞ÁöÑÊîØÊåÅÂêëÈáèÊú∫Â∞±‰ºöË°®Áé∞ÂæóÁõ∏ÂΩìÁ™ÅÂá∫„ÄÇ‰Ω†ÂèØ‰ª•ÂÅöÊØîËøôÂõ∞ÈöæÂæóÂ§öÈúÄË¶ÅÈÄªËæëÂõûÂΩíÁöÑ‰∫ãÊÉÖ„ÄÇ ÊúÄÂêéÔºåÁ•ûÁªèÁΩëÁªú‰ΩøÁî®‰∫é‰ªÄ‰πàÊó∂ÂÄôÂë¢Ôºü ÂØπ‰∫éÊâÄÊúâÁöÑËøô‰∫õÈóÆÈ¢òÔºåÂØπ‰∫éÊâÄÊúâÁöÑËøô‰∫õ‰∏çÂêå‰ΩìÁ≥ª‰∏Ä‰∏™ËÆæËÆ°ÂæóÂæàÂ•ΩÁöÑÁ•ûÁªèÁΩëÁªú‰πüÂæàÊúâÂèØËÉΩ‰ºöÈùûÂ∏∏ÊúâÊïà„ÄÇÊúâ‰∏Ä‰∏™Áº∫ÁÇπÊòØÔºåÊàñËÄÖËØ¥ÊòØÊúâÊó∂ÂèØËÉΩ‰∏ç‰ºö‰ΩøÁî®Á•ûÁªèÁΩëÁªúÁöÑÂéüÂõ†ÊòØÔºöÂØπ‰∫éËÆ∏Â§öËøôÊ†∑ÁöÑÈóÆÈ¢òÔºåÁ•ûÁªèÁΩëÁªúËÆ≠ÁªÉËµ∑Êù•ÂèØËÉΩ‰ºöÁâπÂà´ÊÖ¢Ôºå‰ΩÜÊòØÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∏™ÈùûÂ∏∏Â•ΩÁöÑSVMÂÆûÁé∞ÂåÖÔºåÂÆÉÂèØËÉΩ‰ºöËøêË°åÂæóÊØîËæÉÂø´ÊØîÁ•ûÁªèÁΩëÁªúÂø´ÂæàÂ§öÔºåÂ∞ΩÁÆ°Êàë‰ª¨Âú®Ê≠§‰πãÂâçÊ≤°ÊúâÂ±ïÁ§∫Ôºå‰ΩÜÊòØ‰∫ãÂÆûËØÅÊòéÔºåSVMÂÖ∑ÊúâÁöÑ‰ºòÂåñÈóÆÈ¢òÔºåÊòØ‰∏ÄÁßçÂá∏‰ºòÂåñÈóÆÈ¢ò„ÄÇÂõ†Ê≠§ÔºåÂ•ΩÁöÑSVM‰ºòÂåñËΩØ‰ª∂ÂåÖÊÄªÊòØ‰ºöÊâæÂà∞ÂÖ®Â±ÄÊúÄÂ∞èÂÄºÔºåÊàñËÄÖÊé•ËøëÂÆÉÁöÑÂÄº„ÄÇÂØπ‰∫éSVM‰Ω†‰∏çÈúÄË¶ÅÊãÖÂøÉÂ±ÄÈÉ®ÊúÄ‰ºò„ÄÇÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÔºåÂ±ÄÈÉ®ÊúÄ‰ºò‰∏çÊòØÁ•ûÁªèÁΩëÁªúÊâÄÈúÄË¶ÅËß£ÂÜ≥ÁöÑ‰∏Ä‰∏™ÈáçÂ§ßÈóÆÈ¢òÔºåÊâÄ‰ª•ËøôÊòØ‰Ω†Âú®‰ΩøÁî®SVMÁöÑÊó∂ÂÄô‰∏çÈúÄË¶ÅÂ§™ÂéªÊãÖÂøÉÁöÑ‰∏Ä‰∏™ÈóÆÈ¢ò„ÄÇÊ†πÊçÆ‰Ω†ÁöÑÈóÆÈ¢òÔºåÁ•ûÁªèÁΩëÁªúÂèØËÉΩ‰ºöÊØîSVMÊÖ¢ÔºåÂ∞§ÂÖ∂ÊòØÂú®ËøôÊ†∑‰∏Ä‰∏™‰ΩìÁ≥ª‰∏≠ÔºåËá≥‰∫éËøôÈáåÁªôÂá∫ÁöÑÂèÇËÄÉÔºåÁúã‰∏äÂéªÊúâ‰∫õÊ®°Á≥äÔºåÂ¶ÇÊûú‰Ω†Âú®ËÄÉËôë‰∏Ä‰∫õÈóÆÈ¢òÔºåËøô‰∫õÂèÇËÄÉ‰ºöÊúâ‰∏Ä‰∫õÊ®°Á≥äÔºå‰ΩÜÊòØÊàë‰ªçÁÑ∂‰∏çËÉΩÂÆåÂÖ®Á°ÆÂÆöÔºåÊàëÊòØËØ•Áî®Ëøô‰∏™ÁÆóÊ≥ïËøòÊòØÊîπÁî®ÈÇ£‰∏™ÁÆóÊ≥ïÔºåËøô‰∏™Ê≤°ÊúâÂ§™Â§ßÂÖ≥Á≥ªÔºåÂΩìÊàëÈÅáÂà∞Êú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÁöÑÊó∂ÂÄôÔºåÊúâÊó∂ÂÆÉÁ°ÆÂÆû‰∏çÊ∏ÖÊ•öËøôÊòØÂê¶ÊòØÊúÄÂ•ΩÁöÑÁÆóÊ≥ïÔºå‰ΩÜÊòØÂ∞±Â¶ÇÂú®‰πãÂâçÁöÑËßÜÈ¢ë‰∏≠ÁúãÂà∞ÁöÑÁÆóÊ≥ïÁ°ÆÂÆûÂæàÈáçË¶Å„ÄÇ‰ΩÜÊòØÈÄöÂ∏∏Êõ¥Âä†ÈáçË¶ÅÁöÑÊòØÔºö‰Ω†ÊúâÂ§öÂ∞ëÊï∞ÊçÆÔºå‰Ω†ÊúâÂ§öÁÜüÁªÉÊòØÂê¶ÊìÖÈïøÂÅöËØØÂ∑ÆÂàÜÊûêÂíåÊéíÈô§Â≠¶‰π†ÁÆóÊ≥ïÔºåÊåáÂá∫Â¶Ç‰ΩïËÆæÂÆöÊñ∞ÁöÑÁâπÂæÅÂèòÈáèÂíåÊâæÂá∫ÂÖ∂‰ªñËÉΩÂÜ≥ÂÆö‰Ω†Â≠¶‰π†ÁÆóÊ≥ïÁöÑÂèòÈáèÁ≠âÊñπÈù¢ÔºåÈÄöÂ∏∏Ëøô‰∫õÊñπÈù¢‰ºöÊØî‰Ω†‰ΩøÁî®ÈÄªËæëÂõûÂΩíËøòÊòØSVMËøôÊñπÈù¢Êõ¥Âä†ÈáçË¶Å„ÄÇ‰ΩÜÊòØÔºåÂ∑≤ÁªèËØ¥Ëøá‰∫ÜÔºåSVM‰ªçÁÑ∂Ë¢´ÂπøÊ≥õËÆ§‰∏∫ÊòØ‰∏ÄÁßçÊúÄÂº∫Â§ßÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåËøôÊòØ‰∏Ä‰∏™‰ΩìÁ≥ªÔºåÂåÖÂê´‰∫Ü‰ªÄ‰πàÊó∂ÂÄô‰∏Ä‰∏™ÊúâÊïàÁöÑÊñπÊ≥ïÂéªÂ≠¶‰π†Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞„ÄÇÂõ†Ê≠§ÔºåÂÆûÈôÖ‰∏ä‰∏éÈÄªËæëÂõûÂΩí„ÄÅÁ•ûÁªèÁΩëÁªú„ÄÅSVM‰∏ÄËµ∑‰ΩøÁî®Ëøô‰∫õÊñπÊ≥ïÊù•ÊèêÈ´òÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊàëËÆ§‰∏∫‰Ω†‰ºöÂæàÂ•ΩÂú∞Âª∫Á´ãÂæàÊúâÊäÄÊúØÁöÑÁä∂ÊÄÅ„ÄÇÔºàÁºñËÄÖÊ≥®ÔºöÂΩìÊó∂GPUËÆ°ÁÆóÊØîËæÉÊÖ¢ÔºåÁ•ûÁªèÁΩëÁªúËøò‰∏çÊµÅË°å„ÄÇÔºâ Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÂØπ‰∫é‰∏Ä‰∏™ÂÆΩÊ≥õÁöÑÂ∫îÁî®È¢ÜÂüüÊù•ËØ¥ÔºåËøôÊòØÂè¶‰∏Ä‰∏™Âú®‰Ω†ÂÜõÊ¢∞Â∫ìÈáåÈùûÂ∏∏Âº∫Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰Ω†ÂèØ‰ª•ÊääÂÆÉÂ∫îÁî®Âà∞ÂæàÂ§öÂú∞ÊñπÔºåÂ¶ÇÁ°ÖË∞∑„ÄÅÂú®Â∑•‰∏ö„ÄÅÂ≠¶ÊúØÁ≠âÈ¢ÜÂüüÂª∫Á´ãËÆ∏Â§öÈ´òÊÄßËÉΩÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªü„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÔºàÂÖ´Ôºâ]]></title>
    <url>%2F2018%2F08%2F12%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%85%AB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Â•ΩÂêßÔºå‰ªéËøôÈáåÂºÄÂßãÂçöÂÆ¢Â∞±‰∏çÊòØÊàëËá™Â∑±ÊâãÊï≤ÁöÑ‰∫ÜÔºåÂõ†‰∏∫‰∏Ä‰∫õÂéüÂõ†ÔºåÊ≤°ÊúâÊó∂Èó¥ÂÜçÂÜô‰∏ãÂéª‰∫ÜÔºå‰ΩÜÂèà‰∏çÊÉ≥ÊîæÂºÉÔºåÂè™ËÉΩÊäÑ‰∏Ä‰ªΩËøáÊù•‰∫ÜÔºåÊÑüË∞¢Huang HaiguangËÄÅÂ∏àÁöÑÁ¨îËÆ∞„ÄÇhttps://github.com/fengdu78 ÂçÅ„ÄÅÂ∫îÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÂª∫ËÆÆ(Advice for Applying Machine Learning) 10.1 ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•ÂÅö‰ªÄ‰πàÂèÇËÄÉËßÜÈ¢ë: 10 - 1 - Deciding What to Try Next (6 min).mkv ‚Äã Âà∞ÁõÆÂâç‰∏∫Ê≠¢ÔºåÊàë‰ª¨Â∑≤Áªè‰ªãÁªç‰∫ÜËÆ∏Â§ö‰∏çÂêåÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂ¶ÇÊûú‰Ω†‰∏ÄÁõ¥Ë∑üÁùÄËøô‰∫õËßÜÈ¢ëÁöÑËøõÂ∫¶Â≠¶‰π†Ôºå‰Ω†‰ºöÂèëÁé∞Ëá™Â∑±Â∑≤Áªè‰∏çÁü•‰∏çËßâÂú∞Êàê‰∏∫‰∏Ä‰∏™‰∫ÜËß£ËÆ∏Â§öÂÖàËøõÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁöÑ‰∏ìÂÆ∂‰∫Ü„ÄÇ ‚Äã ÁÑ∂ËÄåÔºåÂú®ÊáÇÊú∫Âô®Â≠¶‰π†ÁöÑ‰∫∫ÂΩì‰∏≠‰æùÁÑ∂Â≠òÂú®ÁùÄÂæàÂ§ßÁöÑÂ∑ÆË∑ùÔºå‰∏ÄÈÉ®ÂàÜ‰∫∫Á°ÆÂÆûÊéåÊè°‰∫ÜÊÄéÊ†∑È´òÊïàÊúâÂäõÂú∞ËøêÁî®Ëøô‰∫õÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇËÄåÂè¶‰∏Ä‰∫õ‰∫∫‰ªñ‰ª¨ÂèØËÉΩÂØπÊàëÈ©¨‰∏äË¶ÅËÆ≤ÁöÑ‰∏úË•øÔºåÂ∞±‰∏çÊòØÈÇ£‰πàÁÜüÊÇâ‰∫Ü„ÄÇ‰ªñ‰ª¨ÂèØËÉΩÊ≤°ÊúâÂÆåÂÖ®ÁêÜËß£ÊÄéÊ†∑ËøêÁî®Ëøô‰∫õÁÆóÊ≥ï„ÄÇÂõ†Ê≠§ÊÄªÊòØÊääÊó∂Èó¥Êµ™Ë¥πÂú®ÊØ´Êó†ÊÑè‰πâÁöÑÂ∞ùËØï‰∏ä„ÄÇÊàëÊÉ≥ÂÅöÁöÑÊòØÁ°Æ‰øù‰Ω†Âú®ËÆæËÆ°Êú∫Âô®Â≠¶‰π†ÁöÑÁ≥ªÁªüÊó∂Ôºå‰Ω†ËÉΩÂ§üÊòéÁôΩÊÄéÊ†∑ÈÄâÊã©‰∏ÄÊù°ÊúÄÂêàÈÄÇ„ÄÅÊúÄÊ≠£Á°ÆÁöÑÈÅìË∑Ø„ÄÇÂõ†Ê≠§ÔºåÂú®ËøôËäÇËßÜÈ¢ëÂíå‰πãÂêéÁöÑÂá†ÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜÂêë‰Ω†‰ªãÁªç‰∏Ä‰∫õÂÆûÁî®ÁöÑÂª∫ËÆÆÂíåÊåáÂØºÔºåÂ∏ÆÂä©‰Ω†ÊòéÁôΩÊÄéÊ†∑ËøõË°åÈÄâÊã©„ÄÇÂÖ∑‰ΩìÊù•ËÆ≤ÔºåÊàëÂ∞ÜÈáçÁÇπÂÖ≥Ê≥®ÁöÑÈóÆÈ¢òÊòØÂÅáÂ¶Ç‰Ω†Âú®ÂºÄÂèë‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÔºåÊàñËÄÖÊÉ≥ËØïÁùÄÊîπËøõ‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑÊÄßËÉΩÔºå‰Ω†Â∫îÂ¶Ç‰ΩïÂÜ≥ÂÆöÊé•‰∏ãÊù•Â∫îËØ•ÈÄâÊã©Âì™Êù°ÈÅìË∑ØÔºü‰∏∫‰∫ÜËß£ÈáäËøô‰∏ÄÈóÆÈ¢òÔºåÊàëÊÉ≥‰ªçÁÑ∂‰ΩøÁî®È¢ÑÊµãÊàø‰ª∑ÁöÑÂ≠¶‰π†‰æãÂ≠êÔºåÂÅáÂ¶Ç‰Ω†Â∑≤ÁªèÂÆåÊàê‰∫ÜÊ≠£ÂàôÂåñÁ∫øÊÄßÂõûÂΩíÔºå‰πüÂ∞±ÊòØÊúÄÂ∞èÂåñ‰ª£‰ª∑ÂáΩÊï∞$J$ÁöÑÂÄºÔºåÂÅáÂ¶ÇÔºåÂú®‰Ω†ÂæóÂà∞‰Ω†ÁöÑÂ≠¶‰π†ÂèÇÊï∞‰ª•ÂêéÔºåÂ¶ÇÊûú‰Ω†Ë¶ÅÂ∞Ü‰Ω†ÁöÑÂÅáËÆæÂáΩÊï∞ÊîæÂà∞‰∏ÄÁªÑÊñ∞ÁöÑÊàøÂ±ãÊ†∑Êú¨‰∏äËøõË°åÊµãËØïÔºåÂÅáÂ¶ÇËØ¥‰Ω†ÂèëÁé∞Âú®È¢ÑÊµãÊàø‰ª∑Êó∂‰∫ßÁîü‰∫ÜÂ∑®Â§ßÁöÑËØØÂ∑ÆÔºåÁé∞Âú®‰Ω†ÁöÑÈóÆÈ¢òÊòØË¶ÅÊÉ≥ÊîπËøõËøô‰∏™ÁÆóÊ≥ïÔºåÊé•‰∏ãÊù•Â∫îËØ•ÊÄé‰πàÂäûÔºü ‚Äã ÂÆûÈôÖ‰∏ä‰Ω†ÂèØ‰ª•ÊÉ≥Âá∫ÂæàÂ§öÁßçÊñπÊ≥ïÊù•ÊîπËøõËøô‰∏™ÁÆóÊ≥ïÁöÑÊÄßËÉΩÔºåÂÖ∂‰∏≠‰∏ÄÁßçÂäûÊ≥ïÊòØ‰ΩøÁî®Êõ¥Â§öÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇÂÖ∑‰ΩìÊù•ËÆ≤Ôºå‰πüËÆ∏‰Ω†ËÉΩÊÉ≥Âà∞ÈÄöËøáÁîµËØùË∞ÉÊü•Êàñ‰∏äÈó®Ë∞ÉÊü•Êù•Ëé∑ÂèñÊõ¥Â§öÁöÑ‰∏çÂêåÁöÑÊàøÂ±ãÂá∫ÂîÆÊï∞ÊçÆ„ÄÇÈÅóÊÜæÁöÑÊòØÔºåÊàëÁúãÂà∞Â•ΩÂ§ö‰∫∫Ëä±Ë¥π‰∫ÜÂ•ΩÂ§öÊó∂Èó¥ÊÉ≥Êî∂ÈõÜÊõ¥Â§öÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇ‰ªñ‰ª¨ÊÄªËÆ§‰∏∫ÔºåË¶ÅÊòØÊàëÊúâ‰∏§ÂÄçÁîöËá≥ÂçÅÂÄçÊï∞ÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÈÇ£Â∞±‰∏ÄÂÆö‰ºöËß£ÂÜ≥ÈóÆÈ¢òÁöÑÊòØÂêßÔºü‰ΩÜÊúâÊó∂ÂÄôËé∑ÂæóÊõ¥Â§öÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂÆûÈôÖ‰∏äÂπ∂Ê≤°Êúâ‰ΩúÁî®„ÄÇÂú®Êé•‰∏ãÊù•ÁöÑÂá†ÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨Â∞ÜËß£ÈáäÂéüÂõ†„ÄÇ ‚Äã Êàë‰ª¨‰πüÂ∞ÜÁü•ÈÅìÊÄéÊ†∑ÈÅøÂÖçÊääËøáÂ§öÁöÑÊó∂Èó¥Êµ™Ë¥πÂú®Êî∂ÈõÜÊõ¥Â§öÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏äÔºåËøôÂÆûÈôÖ‰∏äÊòØ‰∫é‰∫ãÊó†Ë°•ÁöÑ„ÄÇÂè¶‰∏Ä‰∏™ÊñπÊ≥ïÔºå‰Ω†‰πüËÆ∏ËÉΩÊÉ≥Âà∞ÁöÑÊòØÂ∞ùËØïÈÄâÁî®Êõ¥Â∞ëÁöÑÁâπÂæÅÈõÜ„ÄÇÂõ†Ê≠§Â¶ÇÊûú‰Ω†Êúâ‰∏ÄÁ≥ªÂàóÁâπÂæÅÊØîÂ¶Ç$x_1,x_2,x_3$Á≠âÁ≠â„ÄÇ‰πüËÆ∏ÊúâÂæàÂ§öÁâπÂæÅÔºå‰πüËÆ∏‰Ω†ÂèØ‰ª•Ëä±‰∏ÄÁÇπÊó∂Èó¥‰ªéËøô‰∫õÁâπÂæÅ‰∏≠‰ªîÁªÜÊåëÈÄâ‰∏ÄÂ∞èÈÉ®ÂàÜÊù•Èò≤Ê≠¢ËøáÊãüÂêà„ÄÇÊàñËÄÖ‰πüËÆ∏‰Ω†ÈúÄË¶ÅÁî®Êõ¥Â§öÁöÑÁâπÂæÅÔºå‰πüËÆ∏ÁõÆÂâçÁöÑÁâπÂæÅÈõÜÔºåÂØπ‰Ω†Êù•ËÆ≤Âπ∂‰∏çÊòØÂæàÊúâÂ∏ÆÂä©„ÄÇ‰Ω†Â∏åÊúõ‰ªéËé∑ÂèñÊõ¥Â§öÁâπÂæÅÁöÑËßíÂ∫¶Êù•Êî∂ÈõÜÊõ¥Â§öÁöÑÊï∞ÊçÆÔºåÂêåÊ†∑Âú∞Ôºå‰Ω†ÂèØ‰ª•ÊääËøô‰∏™ÈóÆÈ¢òÊâ©Â±ï‰∏∫‰∏Ä‰∏™ÂæàÂ§ßÁöÑÈ°πÁõÆÔºåÊØîÂ¶Ç‰ΩøÁî®ÁîµËØùË∞ÉÊü•Êù•ÂæóÂà∞Êõ¥Â§öÁöÑÊàøÂ±ãÊ°à‰æãÔºåÊàñËÄÖÂÜçËøõË°åÂúüÂú∞ÊµãÈáèÊù•Ëé∑ÂæóÊõ¥Â§öÊúâÂÖ≥ÔºåËøôÂùóÂúüÂú∞ÁöÑ‰ø°ÊÅØÁ≠âÁ≠âÔºåÂõ†Ê≠§ËøôÊòØ‰∏Ä‰∏™Â§çÊùÇÁöÑÈóÆÈ¢ò„ÄÇÂêåÊ†∑ÁöÑÈÅìÁêÜÔºåÊàë‰ª¨ÈùûÂ∏∏Â∏åÊúõÂú®Ëä±Ë¥πÂ§ßÈáèÊó∂Èó¥ÂÆåÊàêËøô‰∫õÂ∑•‰Ωú‰πãÂâçÔºåÊàë‰ª¨Â∞±ËÉΩÁü•ÈÅìÂÖ∂ÊïàÊûúÂ¶Ç‰Ωï„ÄÇÊàë‰ª¨‰πüÂèØ‰ª•Â∞ùËØïÂ¢ûÂä†Â§öÈ°πÂºèÁâπÂæÅÁöÑÊñπÊ≥ïÔºåÊØîÂ¶Ç$x_1$ÁöÑÂπ≥ÊñπÔºå$x_2$ÁöÑÂπ≥ÊñπÔºå$x_1,x_2$ÁöÑ‰πòÁßØÔºåÊàë‰ª¨ÂèØ‰ª•Ëä±ÂæàÂ§öÊó∂Èó¥Êù•ËÄÉËôëËøô‰∏ÄÊñπÊ≥ïÔºåÊàë‰ª¨‰πüÂèØ‰ª•ËÄÉËôëÂÖ∂‰ªñÊñπÊ≥ïÂáèÂ∞èÊàñÂ¢ûÂ§ßÊ≠£ÂàôÂåñÂèÇÊï∞$\lambda$ÁöÑÂÄº„ÄÇÊàë‰ª¨ÂàóÂá∫ÁöÑËøô‰∏™ÂçïÂ≠êÔºå‰∏äÈù¢ÁöÑÂæàÂ§öÊñπÊ≥ïÈÉΩÂèØ‰ª•Êâ©Â±ïÂºÄÊù•Êâ©Â±ïÊàê‰∏Ä‰∏™ÂÖ≠‰∏™ÊúàÊàñÊõ¥ÈïøÊó∂Èó¥ÁöÑÈ°πÁõÆ„ÄÇÈÅóÊÜæÁöÑÊòØÔºåÂ§ßÂ§öÊï∞‰∫∫Áî®Êù•ÈÄâÊã©Ëøô‰∫õÊñπÊ≥ïÁöÑÊ†áÂáÜÊòØÂá≠ÊÑüËßâÁöÑÔºå‰πüÂ∞±ÊòØËØ¥ÔºåÂ§ßÂ§öÊï∞‰∫∫ÁöÑÈÄâÊã©ÊñπÊ≥ïÊòØÈöè‰æø‰ªéËøô‰∫õÊñπÊ≥ï‰∏≠ÈÄâÊã©‰∏ÄÁßçÔºåÊØîÂ¶Ç‰ªñ‰ª¨‰ºöËØ¥‚ÄúÂô¢ÔºåÊàë‰ª¨Êù•Â§öÊâæÁÇπÊï∞ÊçÆÂêß‚ÄùÔºåÁÑ∂ÂêéËä±‰∏äÂÖ≠‰∏™ÊúàÁöÑÊó∂Èó¥Êî∂ÈõÜ‰∫Ü‰∏ÄÂ§ßÂ†ÜÊï∞ÊçÆÔºåÁÑ∂Âêé‰πüËÆ∏Âè¶‰∏Ä‰∏™‰∫∫ËØ¥Ôºö‚ÄúÂ•ΩÂêßÔºåËÆ©Êàë‰ª¨Êù•‰ªéËøô‰∫õÊàøÂ≠êÁöÑÊï∞ÊçÆ‰∏≠Â§öÊâæÁÇπÁâπÂæÅÂêß‚Äù„ÄÇÊàëÂæàÈÅóÊÜæ‰∏çÊ≠¢‰∏ÄÊ¨°Âú∞ÁúãÂà∞ÂæàÂ§ö‰∫∫Ëä±‰∫ÜËá≥Â∞ëÂÖ≠‰∏™ÊúàÊó∂Èó¥Êù•ÂÆåÊàê‰ªñ‰ª¨Èöè‰æøÈÄâÊã©ÁöÑ‰∏ÄÁßçÊñπÊ≥ïÔºåËÄåÂú®ÂÖ≠‰∏™ÊúàÊàñËÄÖÊõ¥ÈïøÊó∂Èó¥ÂêéÔºå‰ªñ‰ª¨ÂæàÈÅóÊÜæÂú∞ÂèëÁé∞Ëá™Â∑±ÈÄâÊã©ÁöÑÊòØ‰∏ÄÊù°‰∏çÂΩíË∑Ø„ÄÇÂπ∏ËøêÁöÑÊòØÔºåÊúâ‰∏ÄÁ≥ªÂàóÁÆÄÂçïÁöÑÊñπÊ≥ïËÉΩËÆ©‰Ω†‰∫ãÂçäÂäüÂÄçÔºåÊéíÈô§ÊéâÂçïÂ≠ê‰∏äÁöÑËá≥Â∞ë‰∏ÄÂçäÁöÑÊñπÊ≥ïÔºåÁïô‰∏ãÈÇ£‰∫õÁ°ÆÂÆûÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂêåÊó∂‰πüÊúâ‰∏ÄÁßçÂæàÁÆÄÂçïÁöÑÊñπÊ≥ïÔºåÂè™Ë¶Å‰Ω†‰ΩøÁî®ÔºåÂ∞±ËÉΩÂæàËΩªÊùæÂú∞ÊéíÈô§ÊéâÂæàÂ§öÈÄâÊã©Ôºå‰ªéËÄå‰∏∫‰Ω†ËäÇÁúÅÂ§ßÈáè‰∏çÂøÖË¶ÅËä±Ë¥πÁöÑÊó∂Èó¥„ÄÇÊúÄÁªàËææÂà∞ÊîπËøõÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÊÄßËÉΩÁöÑÁõÆÁöÑÂÅáËÆæÊàë‰ª¨ÈúÄË¶ÅÁî®‰∏Ä‰∏™Á∫øÊÄßÂõûÂΩíÊ®°ÂûãÊù•È¢ÑÊµãÊàø‰ª∑ÔºåÂΩìÊàë‰ª¨ËøêÁî®ËÆ≠ÁªÉÂ•Ω‰∫ÜÁöÑÊ®°ÂûãÊù•È¢ÑÊµãÊú™Áü•Êï∞ÊçÆÁöÑÊó∂ÂÄôÂèëÁé∞ÊúâËæÉÂ§ßÁöÑËØØÂ∑ÆÔºåÊàë‰ª¨‰∏ã‰∏ÄÊ≠•ÂèØ‰ª•ÂÅö‰ªÄ‰πàÔºü Ëé∑ÂæóÊõ¥Â§öÁöÑËÆ≠ÁªÉÂÆû‰æã‚Äî‚ÄîÈÄöÂ∏∏ÊòØÊúâÊïàÁöÑÔºå‰ΩÜ‰ª£‰ª∑ËæÉÂ§ßÔºå‰∏ãÈù¢ÁöÑÊñπÊ≥ï‰πüÂèØËÉΩÊúâÊïàÔºåÂèØËÄÉËôëÂÖàÈááÁî®‰∏ãÈù¢ÁöÑÂá†ÁßçÊñπÊ≥ï„ÄÇ Â∞ùËØïÂáèÂ∞ëÁâπÂæÅÁöÑÊï∞Èáè Â∞ùËØïËé∑ÂæóÊõ¥Â§öÁöÑÁâπÂæÅ Â∞ùËØïÂ¢ûÂä†Â§öÈ°πÂºèÁâπÂæÅ Â∞ùËØïÂáèÂ∞ëÊ≠£ÂàôÂåñÁ®ãÂ∫¶$\lambda$ Â∞ùËØïÂ¢ûÂä†Ê≠£ÂàôÂåñÁ®ãÂ∫¶$\lambda$ ‚Äã Êàë‰ª¨‰∏çÂ∫îËØ•ÈöèÊú∫ÈÄâÊã©‰∏äÈù¢ÁöÑÊüêÁßçÊñπÊ≥ïÊù•ÊîπËøõÊàë‰ª¨ÁöÑÁÆóÊ≥ïÔºåËÄåÊòØËøêÁî®‰∏Ä‰∫õÊú∫Âô®Â≠¶‰π†ËØäÊñ≠Ê≥ïÊù•Â∏ÆÂä©Êàë‰ª¨Áü•ÈÅì‰∏äÈù¢Âì™‰∫õÊñπÊ≥ïÂØπÊàë‰ª¨ÁöÑÁÆóÊ≥ïÊòØÊúâÊïàÁöÑ„ÄÇ ‚Äã Âú®Êé•‰∏ãÊù•ÁöÑ‰∏§ÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàëÈ¶ñÂÖà‰ªãÁªçÊÄéÊ†∑ËØÑ‰º∞Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÊÄßËÉΩÔºåÁÑ∂ÂêéÂú®‰πãÂêéÁöÑÂá†ÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜÂºÄÂßãËÆ®ËÆ∫Ëøô‰∫õÊñπÊ≥ïÔºåÂÆÉ‰ª¨‰πüË¢´Áß∞‰∏∫‚ÄùÊú∫Âô®Â≠¶‰π†ËØäÊñ≠Ê≥ï‚Äù„ÄÇ‚ÄúËØäÊñ≠Ê≥ï‚ÄùÁöÑÊÑèÊÄùÊòØÔºöËøôÊòØ‰∏ÄÁßçÊµãËØïÊ≥ïÔºå‰Ω†ÈÄöËøáÊâßË°åËøôÁßçÊµãËØïÔºåËÉΩÂ§üÊ∑±ÂÖ•‰∫ÜËß£ÊüêÁßçÁÆóÊ≥ïÂà∞Â∫ïÊòØÂê¶ÊúâÁî®„ÄÇËøôÈÄöÂ∏∏‰πüËÉΩÂ§üÂëäËØâ‰Ω†ÔºåË¶ÅÊÉ≥ÊîπËøõ‰∏ÄÁßçÁÆóÊ≥ïÁöÑÊïàÊûúÔºå‰ªÄ‰πàÊ†∑ÁöÑÂ∞ùËØïÔºåÊâçÊòØÊúâÊÑè‰πâÁöÑ„ÄÇÂú®Ëøô‰∏ÄÁ≥ªÂàóÁöÑËßÜÈ¢ë‰∏≠Êàë‰ª¨Â∞Ü‰ªãÁªçÂÖ∑‰ΩìÁöÑËØäÊñ≠Ê≥ïÔºå‰ΩÜÊàëË¶ÅÊèêÂâçËØ¥Êòé‰∏ÄÁÇπÁöÑÊòØÔºåËøô‰∫õËØäÊñ≠Ê≥ïÁöÑÊâßË°åÂíåÂÆûÁé∞ÔºåÊòØÈúÄË¶ÅËä±‰∫õÊó∂Èó¥ÁöÑÔºåÊúâÊó∂ÂÄôÁ°ÆÂÆûÈúÄË¶ÅËä±ÂæàÂ§öÊó∂Èó¥Êù•ÁêÜËß£ÂíåÂÆûÁé∞Ôºå‰ΩÜËøôÊ†∑ÂÅöÁöÑÁ°ÆÊòØÊääÊó∂Èó¥Áî®Âú®‰∫ÜÂàÄÂàÉ‰∏äÔºåÂõ†‰∏∫Ëøô‰∫õÊñπÊ≥ïËÆ©‰Ω†Âú®ÂºÄÂèëÂ≠¶‰π†ÁÆóÊ≥ïÊó∂ÔºåËäÇÁúÅ‰∫ÜÂá†‰∏™ÊúàÁöÑÊó∂Èó¥ÔºåÂõ†Ê≠§ÔºåÂú®Êé•‰∏ãÊù•Âá†ËäÇËØæ‰∏≠ÔºåÊàëÂ∞ÜÂÖàÊù•‰ªãÁªçÂ¶Ç‰ΩïËØÑ‰ª∑‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇÂú®Ê≠§‰πãÂêéÔºåÊàëÂ∞Ü‰ªãÁªç‰∏Ä‰∫õËØäÊñ≠Ê≥ïÔºåÂ∏åÊúõËÉΩËÆ©‰Ω†Êõ¥Ê∏ÖÊ•ö„ÄÇÂú®Êé•‰∏ãÊù•ÁöÑÂ∞ùËØï‰∏≠ÔºåÂ¶Ç‰ΩïÈÄâÊã©Êõ¥ÊúâÊÑè‰πâÁöÑÊñπÊ≥ï„ÄÇ 10.2 ËØÑ‰º∞‰∏Ä‰∏™ÂÅáËÆæÂèÇËÄÉËßÜÈ¢ë: 10 - 2 - Evaluating a Hypothesis (8 min).mkv ‚Äã Âú®Êú¨ËäÇËßÜÈ¢ë‰∏≠ÊàëÊÉ≥‰ªãÁªç‰∏Ä‰∏ãÊÄéÊ†∑Áî®‰Ω†Â≠¶ËøáÁöÑÁÆóÊ≥ïÊù•ËØÑ‰º∞ÂÅáËÆæÂáΩÊï∞„ÄÇÂú®‰πãÂêéÁöÑËØæÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ª•Ê≠§‰∏∫Âü∫Á°ÄÊù•ËÆ®ËÆ∫Â¶Ç‰ΩïÈÅøÂÖçËøáÊãüÂêàÂíåÊ¨†ÊãüÂêàÁöÑÈóÆÈ¢ò„ÄÇ ‚Äã ÂΩìÊàë‰ª¨Á°ÆÂÆöÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÂèÇÊï∞ÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨ËÄÉËôëÁöÑÊòØÈÄâÊã©ÂèÇÈáèÊù•‰ΩøËÆ≠ÁªÉËØØÂ∑ÆÊúÄÂ∞èÂåñÔºåÊúâ‰∫∫ËÆ§‰∏∫ÂæóÂà∞‰∏Ä‰∏™ÈùûÂ∏∏Â∞èÁöÑËÆ≠ÁªÉËØØÂ∑Æ‰∏ÄÂÆöÊòØ‰∏Ä‰ª∂Â•Ω‰∫ãÔºå‰ΩÜÊàë‰ª¨Â∑≤ÁªèÁü•ÈÅìÔºå‰ªÖ‰ªÖÊòØÂõ†‰∏∫Ëøô‰∏™ÂÅáËÆæÂÖ∑ÊúâÂæàÂ∞èÁöÑËÆ≠ÁªÉËØØÂ∑ÆÔºåÂπ∂‰∏çËÉΩËØ¥ÊòéÂÆÉÂ∞±‰∏ÄÂÆöÊòØ‰∏Ä‰∏™Â•ΩÁöÑÂÅáËÆæÂáΩÊï∞„ÄÇËÄå‰∏îÊàë‰ª¨‰πüÂ≠¶‰π†‰∫ÜËøáÊãüÂêàÂÅáËÆæÂáΩÊï∞ÁöÑ‰æãÂ≠êÔºåÊâÄ‰ª•ËøôÊé®ÂπøÂà∞Êñ∞ÁöÑËÆ≠ÁªÉÈõÜ‰∏äÊòØ‰∏çÈÄÇÁî®ÁöÑ„ÄÇ ‚Äã ÈÇ£‰πàÔºå‰Ω†ËØ•Â¶Ç‰ΩïÂà§Êñ≠‰∏Ä‰∏™ÂÅáËÆæÂáΩÊï∞ÊòØËøáÊãüÂêàÁöÑÂë¢ÔºüÂØπ‰∫éËøô‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºåÊàë‰ª¨ÂèØ‰ª•ÂØπÂÅáËÆæÂáΩÊï∞$h(x)$ËøõË°åÁîªÂõæÔºåÁÑ∂ÂêéËßÇÂØüÂõæÂΩ¢Ë∂ãÂäøÔºå‰ΩÜÂØπ‰∫éÁâπÂæÅÂèòÈáè‰∏çÊ≠¢‰∏Ä‰∏™ÁöÑËøôÁßç‰∏ÄËà¨ÊÉÖÂÜµÔºåËøòÊúâÂÉèÊúâÂæàÂ§öÁâπÂæÅÂèòÈáèÁöÑÈóÆÈ¢òÔºåÊÉ≥Ë¶ÅÈÄöËøáÁîªÂá∫ÂÅáËÆæÂáΩÊï∞Êù•ËøõË°åËßÇÂØüÔºåÂ∞±‰ºöÂèòÂæóÂæàÈöæÁîöËá≥ÊòØ‰∏çÂèØËÉΩÂÆûÁé∞„ÄÇ ‚Äã Âõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶ÅÂè¶‰∏ÄÁßçÊñπÊ≥ïÊù•ËØÑ‰º∞Êàë‰ª¨ÁöÑÂÅáËÆæÂáΩÊï∞ËøáÊãüÂêàÊ£ÄÈ™å„ÄÇ ‚Äã ‰∏∫‰∫ÜÊ£ÄÈ™åÁÆóÊ≥ïÊòØÂê¶ËøáÊãüÂêàÔºåÊàë‰ª¨Â∞ÜÊï∞ÊçÆÂàÜÊàêËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÔºåÈÄöÂ∏∏Áî®70%ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜÔºåÁî®Ââ©‰∏ã30%ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ÊµãËØïÈõÜ„ÄÇÂæàÈáçË¶ÅÁöÑ‰∏ÄÁÇπÊòØËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÂùáË¶ÅÂê´ÊúâÂêÑÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÈÄöÂ∏∏Êàë‰ª¨Ë¶ÅÂØπÊï∞ÊçÆËøõË°å‚ÄúÊ¥óÁâå‚ÄùÔºåÁÑ∂ÂêéÂÜçÂàÜÊàêËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ„ÄÇ ‚Äã ÊµãËØïÈõÜËØÑ‰º∞Âú®ÈÄöËøáËÆ≠ÁªÉÈõÜËÆ©Êàë‰ª¨ÁöÑÊ®°ÂûãÂ≠¶‰π†ÂæóÂá∫ÂÖ∂ÂèÇÊï∞ÂêéÔºåÂØπÊµãËØïÈõÜËøêÁî®ËØ•Ê®°ÂûãÔºåÊàë‰ª¨Êúâ‰∏§ÁßçÊñπÂºèËÆ°ÁÆóËØØÂ∑ÆÔºö ÂØπ‰∫éÁ∫øÊÄßÂõûÂΩíÊ®°ÂûãÔºåÊàë‰ª¨Âà©Áî®ÊµãËØïÈõÜÊï∞ÊçÆËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞$J$ ÂØπ‰∫éÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºåÊàë‰ª¨Èô§‰∫ÜÂèØ‰ª•Âà©Áî®ÊµãËØïÊï∞ÊçÆÈõÜÊù•ËÆ°ÁÆó‰ª£‰ª∑ÂáΩÊï∞Â§ñÔºö $$ J_{test}{(\theta)} = -\frac{1}{{m}_{test}}\sum_\limits{i=1}^{m_{test}}\log{h_{\theta}(x^{(i)}_{test})}+(1-{y^{(i)}_{test}})\log{h_{\theta}(x^{(i)}_{test})}$$ ËØØÂàÜÁ±ªÁöÑÊØîÁéáÔºåÂØπ‰∫éÊØè‰∏Ä‰∏™ÊµãËØïÈõÜÂÆû‰æãÔºåËÆ°ÁÆóÔºö ÁÑ∂ÂêéÂØπËÆ°ÁÆóÁªìÊûúÊ±ÇÂπ≥Âùá„ÄÇ 10.3 Ê®°ÂûãÈÄâÊã©Âíå‰∫§ÂèâÈ™åËØÅÈõÜÂèÇËÄÉËßÜÈ¢ë: 10 - 3 - Model Selection and Train_Validation_Test Sets (12 min).mkv ‚Äã ÂÅáËÆæÊàë‰ª¨Ë¶ÅÂú®10‰∏™‰∏çÂêåÊ¨°Êï∞ÁöÑ‰∫åÈ°πÂºèÊ®°Âûã‰πãÈó¥ËøõË°åÈÄâÊã©Ôºö ‚Äã ÊòæÁÑ∂Ë∂äÈ´òÊ¨°Êï∞ÁöÑÂ§öÈ°πÂºèÊ®°ÂûãË∂äËÉΩÂ§üÈÄÇÂ∫îÊàë‰ª¨ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºå‰ΩÜÊòØÈÄÇÂ∫îËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂπ∂‰∏ç‰ª£Ë°®ÁùÄËÉΩÊé®ÂπøËá≥‰∏ÄËà¨ÊÉÖÂÜµÔºåÊàë‰ª¨Â∫îËØ•ÈÄâÊã©‰∏Ä‰∏™Êõ¥ËÉΩÈÄÇÂ∫î‰∏ÄËà¨ÊÉÖÂÜµÁöÑÊ®°Âûã„ÄÇÊàë‰ª¨ÈúÄË¶Å‰ΩøÁî®‰∫§ÂèâÈ™åËØÅÈõÜÊù•Â∏ÆÂä©ÈÄâÊã©Ê®°Âûã„ÄÇ ‚Äã Âç≥Ôºö‰ΩøÁî®60%ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜÔºå‰ΩøÁî® 20%ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫‰∫§ÂèâÈ™åËØÅÈõÜÔºå‰ΩøÁî®20%ÁöÑÊï∞ÊçÆ‰Ωú‰∏∫ÊµãËØïÈõÜ Ê®°ÂûãÈÄâÊã©ÁöÑÊñπÊ≥ï‰∏∫Ôºö ‰ΩøÁî®ËÆ≠ÁªÉÈõÜËÆ≠ÁªÉÂá∫10‰∏™Ê®°Âûã Áî®10‰∏™Ê®°ÂûãÂàÜÂà´ÂØπ‰∫§ÂèâÈ™åËØÅÈõÜËÆ°ÁÆóÂæóÂá∫‰∫§ÂèâÈ™åËØÅËØØÂ∑ÆÔºà‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÄºÔºâ ÈÄâÂèñ‰ª£‰ª∑ÂáΩÊï∞ÂÄºÊúÄÂ∞èÁöÑÊ®°Âûã Áî®Ê≠•È™§3‰∏≠ÈÄâÂá∫ÁöÑÊ®°ÂûãÂØπÊµãËØïÈõÜËÆ°ÁÆóÂæóÂá∫Êé®ÂπøËØØÂ∑ÆÔºà‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÄºÔºâ Train/validation/test error Training error: ‚Äã $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$ Cross Validation error: ‚Äã $J_{cv}(\theta) = \frac{1}{2m_{cv}}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}{cv})-y^{(i)}{cv})^2‚Äã$ Test error: ‚Äã $J_{test}(\theta)=\frac{1}{2m_{test}}\sum_\limits{i=1}^{m_{test}}(h_{\theta}(x^{(i)}{cv})-y^{(i)}{cv})^2$ 10.4 ËØäÊñ≠ÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÂèÇËÄÉËßÜÈ¢ë: 10 - 4 - Diagnosing Bias vs. Variance (8 min).mkv ‚Äã ÂΩì‰Ω†ËøêË°å‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÊó∂ÔºåÂ¶ÇÊûúËøô‰∏™ÁÆóÊ≥ïÁöÑË°®Áé∞‰∏çÁêÜÊÉ≥ÔºåÈÇ£‰πàÂ§öÂçäÊòØÂá∫Áé∞‰∏§ÁßçÊÉÖÂÜµÔºöË¶Å‰πàÊòØÂÅèÂ∑ÆÊØîËæÉÂ§ßÔºåË¶Å‰πàÊòØÊñπÂ∑ÆÊØîËæÉÂ§ß„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂá∫Áé∞ÁöÑÊÉÖÂÜµË¶Å‰πàÊòØÊ¨†ÊãüÂêàÔºåË¶Å‰πàÊòØËøáÊãüÂêàÈóÆÈ¢ò„ÄÇÈÇ£‰πàËøô‰∏§ÁßçÊÉÖÂÜµÔºåÂì™‰∏™ÂíåÂÅèÂ∑ÆÊúâÂÖ≥ÔºåÂì™‰∏™ÂíåÊñπÂ∑ÆÊúâÂÖ≥ÔºåÊàñËÄÖÊòØ‰∏çÊòØÂíå‰∏§‰∏™ÈÉΩÊúâÂÖ≥ÔºüÊêûÊ∏ÖÊ•öËøô‰∏ÄÁÇπÈùûÂ∏∏ÈáçË¶ÅÔºåÂõ†‰∏∫ËÉΩÂà§Êñ≠Âá∫Áé∞ÁöÑÊÉÖÂÜµÊòØËøô‰∏§ÁßçÊÉÖÂÜµ‰∏≠ÁöÑÂì™‰∏ÄÁßç„ÄÇÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™ÂæàÊúâÊïàÁöÑÊåáÁ§∫Âô®ÔºåÊåáÂºïÁùÄÂèØ‰ª•ÊîπËøõÁÆóÊ≥ïÁöÑÊúÄÊúâÊïàÁöÑÊñπÊ≥ïÂíåÈÄîÂæÑ„ÄÇÂú®ËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåÊàëÊÉ≥Êõ¥Ê∑±ÂÖ•Âú∞Êé¢ËÆ®‰∏Ä‰∏ãÊúâÂÖ≥ÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÁöÑÈóÆÈ¢òÔºåÂ∏åÊúõ‰Ω†ËÉΩÂØπÂÆÉ‰ª¨Êúâ‰∏Ä‰∏™Êõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£ÔºåÂπ∂‰∏î‰πüËÉΩÂºÑÊ∏ÖÊ•öÊÄéÊ†∑ËØÑ‰ª∑‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÔºåËÉΩÂ§üÂà§Êñ≠‰∏Ä‰∏™ÁÆóÊ≥ïÊòØÂÅèÂ∑ÆËøòÊòØÊñπÂ∑ÆÊúâÈóÆÈ¢òÔºåÂõ†‰∏∫Ëøô‰∏™ÈóÆÈ¢òÂØπ‰∫éÂºÑÊ∏ÖÂ¶Ç‰ΩïÊîπËøõÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÊïàÊûúÈùûÂ∏∏ÈáçË¶ÅÔºåÈ´òÂÅèÂ∑ÆÂíåÈ´òÊñπÂ∑ÆÁöÑÈóÆÈ¢òÂü∫Êú¨‰∏äÊù•ËØ¥ÊòØÊ¨†ÊãüÂêàÂíåËøáÊãüÂêàÁöÑÈóÆÈ¢ò„ÄÇ ‚Äã Êàë‰ª¨ÈÄöÂ∏∏‰ºöÈÄöËøáÂ∞ÜËÆ≠ÁªÉÈõÜÂíå‰∫§ÂèâÈ™åËØÅÈõÜÁöÑ‰ª£‰ª∑ÂáΩÊï∞ËØØÂ∑Æ‰∏éÂ§öÈ°πÂºèÁöÑÊ¨°Êï∞ÁªòÂà∂Âú®Âêå‰∏ÄÂº†ÂõæË°®‰∏äÊù•Â∏ÆÂä©ÂàÜÊûêÔºö Bias/variance Training error: $J_{train}(\theta) = \frac{1}{2m}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$ Cross Validation error: $J_{cv}(\theta) = \frac{1}{2m_{cv}}\sum_\limits{i=1}^{m}(h_{\theta}(x^{(i)}{cv})-y^{(i)}{cv})^2$ ‚Äã ÂØπ‰∫éËÆ≠ÁªÉÈõÜÔºåÂΩì $d$ ËæÉÂ∞èÊó∂ÔºåÊ®°ÂûãÊãüÂêàÁ®ãÂ∫¶Êõ¥‰ΩéÔºåËØØÂ∑ÆËæÉÂ§ßÔºõÈöèÁùÄ $d$ ÁöÑÂ¢ûÈïøÔºåÊãüÂêàÁ®ãÂ∫¶ÊèêÈ´òÔºåËØØÂ∑ÆÂáèÂ∞è„ÄÇ ‚Äã ÂØπ‰∫é‰∫§ÂèâÈ™åËØÅÈõÜÔºåÂΩì $d$ ËæÉÂ∞èÊó∂ÔºåÊ®°ÂûãÊãüÂêàÁ®ãÂ∫¶‰ΩéÔºåËØØÂ∑ÆËæÉÂ§ßÔºõ‰ΩÜÊòØÈöèÁùÄ $d$ ÁöÑÂ¢ûÈïøÔºåËØØÂ∑ÆÂëàÁé∞ÂÖàÂáèÂ∞èÂêéÂ¢ûÂ§ßÁöÑË∂ãÂäøÔºåËΩ¨ÊäòÁÇπÊòØÊàë‰ª¨ÁöÑÊ®°ÂûãÂºÄÂßãËøáÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆÈõÜÁöÑÊó∂ÂÄô„ÄÇ ‚Äã Â¶ÇÊûúÊàë‰ª¨ÁöÑ‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑ÆËæÉÂ§ßÔºåÊàë‰ª¨Â¶Ç‰ΩïÂà§Êñ≠ÊòØÊñπÂ∑ÆËøòÊòØÂÅèÂ∑ÆÂë¢ÔºüÊ†πÊçÆ‰∏äÈù¢ÁöÑÂõæË°®ÔºåÊàë‰ª¨Áü•ÈÅì: ‚Äã ËÆ≠ÁªÉÈõÜËØØÂ∑ÆÂíå‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑ÆËøë‰ººÊó∂ÔºöÂÅèÂ∑Æ/Ê¨†ÊãüÂêà ‚Äã ‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑ÆËøúÂ§ß‰∫éËÆ≠ÁªÉÈõÜËØØÂ∑ÆÊó∂ÔºöÊñπÂ∑Æ/ËøáÊãüÂêà 10.5 Ê≠£ÂàôÂåñÂíåÂÅèÂ∑Æ/ÊñπÂ∑ÆÂèÇËÄÉËßÜÈ¢ë: 10 - 5 - Regularization and Bias_Variance (11 min).mkv ‚Äã Âú®Êàë‰ª¨Âú®ËÆ≠ÁªÉÊ®°ÂûãÁöÑËøáÁ®ã‰∏≠Ôºå‰∏ÄËà¨‰ºö‰ΩøÁî®‰∏Ä‰∫õÊ≠£ÂàôÂåñÊñπÊ≥ïÊù•Èò≤Ê≠¢ËøáÊãüÂêà„ÄÇ‰ΩÜÊòØÊàë‰ª¨ÂèØËÉΩ‰ºöÊ≠£ÂàôÂåñÁöÑÁ®ãÂ∫¶Â§™È´òÊàñÂ§™Â∞è‰∫ÜÔºåÂç≥Êàë‰ª¨Âú®ÈÄâÊã©ŒªÁöÑÂÄºÊó∂‰πüÈúÄË¶ÅÊÄùËÄÉ‰∏éÂàöÊâçÈÄâÊã©Â§öÈ°πÂºèÊ®°ÂûãÊ¨°Êï∞Á±ª‰ººÁöÑÈóÆÈ¢ò„ÄÇ ‚Äã Êàë‰ª¨ÈÄâÊã©‰∏ÄÁ≥ªÂàóÁöÑÊÉ≥Ë¶ÅÊµãËØïÁöÑ $\lambda$ ÂÄºÔºåÈÄöÂ∏∏ÊòØ 0-10‰πãÈó¥ÁöÑÂëàÁé∞2ÂÄçÂÖ≥Á≥ªÁöÑÂÄºÔºàÂ¶ÇÔºö$0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10$ÂÖ±12‰∏™Ôºâ„ÄÇ Êàë‰ª¨ÂêåÊ†∑ÊääÊï∞ÊçÆÂàÜ‰∏∫ËÆ≠ÁªÉÈõÜ„ÄÅ‰∫§ÂèâÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜ„ÄÇ ÈÄâÊã©$\lambda$ÁöÑÊñπÊ≥ï‰∏∫Ôºö ‰ΩøÁî®ËÆ≠ÁªÉÈõÜËÆ≠ÁªÉÂá∫12‰∏™‰∏çÂêåÁ®ãÂ∫¶Ê≠£ÂàôÂåñÁöÑÊ®°Âûã Áî®12‰∏™Ê®°ÂûãÂàÜÂà´ÂØπ‰∫§ÂèâÈ™åËØÅÈõÜËÆ°ÁÆóÁöÑÂá∫‰∫§ÂèâÈ™åËØÅËØØÂ∑Æ ÈÄâÊã©ÂæóÂá∫‰∫§ÂèâÈ™åËØÅËØØÂ∑ÆÊúÄÂ∞èÁöÑÊ®°Âûã ËøêÁî®Ê≠•È™§3‰∏≠ÈÄâÂá∫Ê®°ÂûãÂØπÊµãËØïÈõÜËÆ°ÁÆóÂæóÂá∫Êé®ÂπøËØØÂ∑ÆÔºåÊàë‰ª¨‰πüÂèØ‰ª•ÂêåÊó∂Â∞ÜËÆ≠ÁªÉÈõÜÂíå‰∫§ÂèâÈ™åËØÅÈõÜÊ®°ÂûãÁöÑ‰ª£‰ª∑ÂáΩÊï∞ËØØÂ∑Æ‰∏éŒªÁöÑÂÄºÁªòÂà∂Âú®‰∏ÄÂº†ÂõæË°®‰∏äÔºö ‚Äã ‚Ä¢ ÂΩì $\lambda$ ËæÉÂ∞èÊó∂ÔºåËÆ≠ÁªÉÈõÜËØØÂ∑ÆËæÉÂ∞èÔºàËøáÊãüÂêàÔºâËÄå‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑ÆËæÉÂ§ß ‚Äã ‚Ä¢ ÈöèÁùÄ $\lambda$ ÁöÑÂ¢ûÂä†ÔºåËÆ≠ÁªÉÈõÜËØØÂ∑Æ‰∏çÊñ≠Â¢ûÂä†ÔºàÊ¨†ÊãüÂêàÔºâÔºåËÄå‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑ÆÂàôÊòØÂÖàÂáèÂ∞èÂêéÂ¢ûÂä† 10.6 Â≠¶‰π†Êõ≤Á∫øÂèÇËÄÉËßÜÈ¢ë: 10 - 6 - Learning Curves (12 min).mkv ‚Äã Â≠¶‰π†Êõ≤Á∫øÂ∞±ÊòØ‰∏ÄÁßçÂæàÂ•ΩÁöÑÂ∑•ÂÖ∑ÔºåÊàëÁªèÂ∏∏‰ΩøÁî®Â≠¶‰π†Êõ≤Á∫øÊù•Âà§Êñ≠Êüê‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÊòØÂê¶Â§Ñ‰∫éÂÅèÂ∑Æ„ÄÅÊñπÂ∑ÆÈóÆÈ¢ò„ÄÇÂ≠¶‰π†Êõ≤Á∫øÊòØÂ≠¶‰π†ÁÆóÊ≥ïÁöÑ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÂêàÁêÜÊ£ÄÈ™åÔºàsanity checkÔºâ„ÄÇÂ≠¶‰π†Êõ≤Á∫øÊòØÂ∞ÜËÆ≠ÁªÉÈõÜËØØÂ∑ÆÂíå‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑Æ‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜÂÆû‰æãÊï∞ÈáèÔºà$m$ÔºâÁöÑÂáΩÊï∞ÁªòÂà∂ÁöÑÂõæË°®„ÄÇ ‚Äã Âç≥ÔºåÂ¶ÇÊûúÊàë‰ª¨Êúâ100Ë°åÊï∞ÊçÆÔºåÊàë‰ª¨‰ªé1Ë°åÊï∞ÊçÆÂºÄÂßãÔºåÈÄêÊ∏êÂ≠¶‰π†Êõ¥Â§öË°åÁöÑÊï∞ÊçÆ„ÄÇÊÄùÊÉ≥ÊòØÔºöÂΩìËÆ≠ÁªÉËæÉÂ∞ëË°åÊï∞ÊçÆÁöÑÊó∂ÂÄôÔºåËÆ≠ÁªÉÁöÑÊ®°ÂûãÂ∞ÜËÉΩÂ§üÈùûÂ∏∏ÂÆåÁæéÂú∞ÈÄÇÂ∫îËæÉÂ∞ëÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ΩÜÊòØËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂç¥‰∏çËÉΩÂæàÂ•ΩÂú∞ÈÄÇÂ∫î‰∫§ÂèâÈ™åËØÅÈõÜÊï∞ÊçÆÊàñÊµãËØïÈõÜÊï∞ÊçÆ„ÄÇ ‚Äã Â¶Ç‰ΩïÂà©Áî®Â≠¶‰π†Êõ≤Á∫øËØÜÂà´È´òÂÅèÂ∑Æ/Ê¨†ÊãüÂêàÔºö‰Ωú‰∏∫‰æãÂ≠êÔºåÊàë‰ª¨Â∞ùËØïÁî®‰∏ÄÊù°Áõ¥Á∫øÊù•ÈÄÇÂ∫î‰∏ãÈù¢ÁöÑÊï∞ÊçÆÔºåÂèØ‰ª•ÁúãÂá∫ÔºåÊó†ËÆ∫ËÆ≠ÁªÉÈõÜÊúâÂ§ö‰πàÂ§ßËØØÂ∑ÆÈÉΩ‰∏ç‰ºöÊúâÂ§™Â§ßÊîπËßÇÔºö ‚Äã ‰πüÂ∞±ÊòØËØ¥Âú®È´òÂÅèÂ∑Æ/Ê¨†ÊãüÂêàÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ¢ûÂä†Êï∞ÊçÆÂà∞ËÆ≠ÁªÉÈõÜ‰∏ç‰∏ÄÂÆöËÉΩÊúâÂ∏ÆÂä©„ÄÇ ‚Äã Â¶Ç‰ΩïÂà©Áî®Â≠¶‰π†Êõ≤Á∫øËØÜÂà´È´òÊñπÂ∑Æ/ËøáÊãüÂêàÔºöÂÅáËÆæÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™ÈùûÂ∏∏È´òÊ¨°ÁöÑÂ§öÈ°πÂºèÊ®°ÂûãÔºåÂπ∂‰∏îÊ≠£ÂàôÂåñÈùûÂ∏∏Â∞èÔºåÂèØ‰ª•ÁúãÂá∫ÔºåÂΩì‰∫§ÂèâÈ™åËØÅÈõÜËØØÂ∑ÆËøúÂ§ß‰∫éËÆ≠ÁªÉÈõÜËØØÂ∑ÆÊó∂ÔºåÂæÄËÆ≠ÁªÉÈõÜÂ¢ûÂä†Êõ¥Â§öÊï∞ÊçÆÂèØ‰ª•ÊèêÈ´òÊ®°ÂûãÁöÑÊïàÊûú„ÄÇ ‚Äã ‰πüÂ∞±ÊòØËØ¥Âú®È´òÊñπÂ∑Æ/ËøáÊãüÂêàÁöÑÊÉÖÂÜµ‰∏ãÔºåÂ¢ûÂä†Êõ¥Â§öÊï∞ÊçÆÂà∞ËÆ≠ÁªÉÈõÜÂèØËÉΩÂèØ‰ª•ÊèêÈ´òÁÆóÊ≥ïÊïàÊûú„ÄÇ 10.7 ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•ÂÅö‰ªÄ‰πàÂèÇËÄÉËßÜÈ¢ë: 10 - 7 - Deciding What to Do Next Revisited (7 min).mkv ‚Äã Êàë‰ª¨Â∑≤Áªè‰ªãÁªç‰∫ÜÊÄéÊ†∑ËØÑ‰ª∑‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜÊ®°ÂûãÈÄâÊã©ÈóÆÈ¢òÔºåÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇÈÇ£‰πàËøô‰∫õËØäÊñ≠Ê≥ïÂàôÊÄéÊ†∑Â∏ÆÂä©Êàë‰ª¨Âà§Êñ≠ÔºåÂì™‰∫õÊñπÊ≥ïÂèØËÉΩÊúâÂä©‰∫éÊîπËøõÂ≠¶‰π†ÁÆóÊ≥ïÁöÑÊïàÊûúÔºåËÄåÂì™‰∫õÂèØËÉΩÊòØÂæíÂä≥ÁöÑÂë¢Ôºü ‚Äã ËÆ©Êàë‰ª¨ÂÜçÊ¨°ÂõûÂà∞ÊúÄÂºÄÂßãÁöÑ‰æãÂ≠êÔºåÂú®ÈÇ£ÈáåÂØªÊâæÁ≠îÊ°àÔºåËøôÂ∞±ÊòØÊàë‰ª¨‰πãÂâçÁöÑ‰æãÂ≠ê„ÄÇÂõûÈ°æ 1.1 ‰∏≠ÊèêÂá∫ÁöÑÂÖ≠ÁßçÂèØÈÄâÁöÑ‰∏ã‰∏ÄÊ≠•ÔºåËÆ©Êàë‰ª¨Êù•Áúã‰∏ÄÁúãÊàë‰ª¨Âú®‰ªÄ‰πàÊÉÖÂÜµ‰∏ãÂ∫îËØ•ÊÄéÊ†∑ÈÄâÊã©Ôºö Ëé∑ÂæóÊõ¥Â§öÁöÑËÆ≠ÁªÉÂÆû‰æã‚Äî‚ÄîËß£ÂÜ≥È´òÊñπÂ∑Æ Â∞ùËØïÂáèÂ∞ëÁâπÂæÅÁöÑÊï∞Èáè‚Äî‚ÄîËß£ÂÜ≥È´òÊñπÂ∑Æ Â∞ùËØïËé∑ÂæóÊõ¥Â§öÁöÑÁâπÂæÅ‚Äî‚ÄîËß£ÂÜ≥È´òÂÅèÂ∑Æ Â∞ùËØïÂ¢ûÂä†Â§öÈ°πÂºèÁâπÂæÅ‚Äî‚ÄîËß£ÂÜ≥È´òÂÅèÂ∑Æ Â∞ùËØïÂáèÂ∞ëÊ≠£ÂàôÂåñÁ®ãÂ∫¶Œª‚Äî‚ÄîËß£ÂÜ≥È´òÂÅèÂ∑Æ Â∞ùËØïÂ¢ûÂä†Ê≠£ÂàôÂåñÁ®ãÂ∫¶Œª‚Äî‚ÄîËß£ÂÜ≥È´òÊñπÂ∑Æ Á•ûÁªèÁΩëÁªúÁöÑÊñπÂ∑ÆÂíåÂÅèÂ∑ÆÔºö ‚Äã ‰ΩøÁî®ËæÉÂ∞èÁöÑÁ•ûÁªèÁΩëÁªúÔºåÁ±ª‰ºº‰∫éÂèÇÊï∞ËæÉÂ∞ëÁöÑÊÉÖÂÜµÔºåÂÆπÊòìÂØºËá¥È´òÂÅèÂ∑ÆÂíåÊ¨†ÊãüÂêàÔºå‰ΩÜËÆ°ÁÆó‰ª£‰ª∑ËæÉÂ∞è‰ΩøÁî®ËæÉÂ§ßÁöÑÁ•ûÁªèÁΩëÁªúÔºåÁ±ª‰ºº‰∫éÂèÇÊï∞ËæÉÂ§öÁöÑÊÉÖÂÜµÔºåÂÆπÊòìÂØºËá¥È´òÊñπÂ∑ÆÂíåËøáÊãüÂêàÔºåËôΩÁÑ∂ËÆ°ÁÆó‰ª£‰ª∑ÊØîËæÉÂ§ßÔºå‰ΩÜÊòØÂèØ‰ª•ÈÄöËøáÊ≠£ÂàôÂåñÊâãÊÆµÊù•Ë∞ÉÊï¥ËÄåÊõ¥Âä†ÈÄÇÂ∫îÊï∞ÊçÆ„ÄÇ ‚Äã ÈÄöÂ∏∏ÈÄâÊã©ËæÉÂ§ßÁöÑÁ•ûÁªèÁΩëÁªúÂπ∂ÈááÁî®Ê≠£ÂàôÂåñÂ§ÑÁêÜ‰ºöÊØîÈááÁî®ËæÉÂ∞èÁöÑÁ•ûÁªèÁΩëÁªúÊïàÊûúË¶ÅÂ•Ω„ÄÇ ‚Äã ÂØπ‰∫éÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÈöêËóèÂ±ÇÁöÑÂ±ÇÊï∞ÁöÑÈÄâÊã©ÔºåÈÄöÂ∏∏‰ªé‰∏ÄÂ±ÇÂºÄÂßãÈÄêÊ∏êÂ¢ûÂä†Â±ÇÊï∞Ôºå‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞‰ΩúÈÄâÊã©ÔºåÂèØ‰ª•ÊääÊï∞ÊçÆÂàÜ‰∏∫ËÆ≠ÁªÉÈõÜ„ÄÅ‰∫§ÂèâÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜÔºåÈíàÂØπ‰∏çÂêåÈöêËóèÂ±ÇÂ±ÇÊï∞ÁöÑÁ•ûÁªèÁΩëÁªúËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÔºåÁÑ∂ÂêéÈÄâÊã©‰∫§ÂèâÈ™åËØÅÈõÜ‰ª£‰ª∑ÊúÄÂ∞èÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇ ‚Äã Â•ΩÁöÑÔºå‰ª•‰∏äÂ∞±ÊòØÊàë‰ª¨‰ªãÁªçÁöÑÂÅèÂ∑ÆÂíåÊñπÂ∑ÆÈóÆÈ¢òÔºå‰ª•ÂèäËØäÊñ≠ËØ•ÈóÆÈ¢òÁöÑÂ≠¶‰π†Êõ≤Á∫øÊñπÊ≥ï„ÄÇÂú®ÊîπËøõÂ≠¶‰π†ÁÆóÊ≥ïÁöÑË°®Áé∞Êó∂Ôºå‰Ω†ÂèØ‰ª•ÂÖÖÂàÜËøêÁî®‰ª•‰∏äËøô‰∫õÂÜÖÂÆπÊù•Âà§Êñ≠Âì™‰∫õÈÄîÂæÑÂèØËÉΩÊòØÊúâÂ∏ÆÂä©ÁöÑ„ÄÇËÄåÂì™‰∫õÊñπÊ≥ïÂèØËÉΩÊòØÊó†ÊÑè‰πâÁöÑ„ÄÇÂ¶ÇÊûú‰Ω†ÁêÜËß£‰∫Ü‰ª•‰∏äÂá†ËäÇËßÜÈ¢ë‰∏≠‰ªãÁªçÁöÑÂÜÖÂÆπÔºåÂπ∂‰∏îÊáÇÂæóÂ¶Ç‰ΩïËøêÁî®„ÄÇÈÇ£‰πà‰Ω†Â∑≤ÁªèÂèØ‰ª•‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÊúâÊïàÁöÑËß£ÂÜ≥ÂÆûÈôÖÈóÆÈ¢ò‰∫Ü„ÄÇ‰Ω†‰πüËÉΩÂÉèÁ°ÖË∞∑ÁöÑÂ§ßÈÉ®ÂàÜÊú∫Âô®Â≠¶‰π†‰ªé‰∏öËÄÖ‰∏ÄÊ†∑Ôºå‰ªñ‰ª¨ÊØèÂ§©ÁöÑÂ∑•‰ΩúÂ∞±ÊòØ‰ΩøÁî®Ëøô‰∫õÂ≠¶‰π†ÁÆóÊ≥ïÊù•Ëß£ÂÜ≥‰ºóÂ§öÂÆûÈôÖÈóÆÈ¢ò„ÄÇÊàëÂ∏åÊúõËøôÂá†ËäÇ‰∏≠ÊèêÂà∞ÁöÑ‰∏Ä‰∫õÊäÄÂ∑ßÔºåÂÖ≥‰∫éÊñπÂ∑Æ„ÄÅÂÅèÂ∑ÆÔºå‰ª•ÂèäÂ≠¶‰π†Êõ≤Á∫ø‰∏∫‰ª£Ë°®ÁöÑËØäÊñ≠Ê≥ïËÉΩÂ§üÁúüÊ≠£Â∏ÆÂä©‰Ω†Êõ¥ÊúâÊïàÁéáÂú∞Â∫îÁî®Êú∫Âô®Â≠¶‰π†ÔºåËÆ©ÂÆÉ‰ª¨È´òÊïàÂú∞Â∑•‰Ωú„ÄÇ ÂçÅ‰∏Ä„ÄÅÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑËÆæËÆ°(Machine Learning System Design)11.1 È¶ñÂÖàË¶ÅÂÅö‰ªÄ‰πàÂèÇËÄÉËßÜÈ¢ë: 11 - 1 - Prioritizing What to Work On (10 min).mkv ‚Äã Âú®Êé•‰∏ãÊù•ÁöÑËßÜÈ¢ë‰∏≠ÔºåÊàëÂ∞ÜË∞àÂà∞Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑËÆæËÆ°„ÄÇËøô‰∫õËßÜÈ¢ëÂ∞ÜË∞àÂèäÂú®ËÆæËÆ°Â§çÊùÇÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÊó∂Ôºå‰Ω†Â∞ÜÈÅáÂà∞ÁöÑ‰∏ªË¶ÅÈóÆÈ¢ò„ÄÇÂêåÊó∂Êàë‰ª¨‰ºöËØïÁùÄÁªôÂá∫‰∏Ä‰∫õÂÖ≥‰∫éÂ¶Ç‰ΩïÂ∑ßÂ¶ôÊûÑÂª∫‰∏Ä‰∏™Â§çÊùÇÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑÂª∫ËÆÆ„ÄÇ‰∏ãÈù¢ÁöÑËØæÁ®ãÁöÑÁöÑÊï∞Â≠¶ÊÄßÂèØËÉΩ‰∏çÊòØÈÇ£‰πàÂº∫Ôºå‰ΩÜÊòØÊàëËÆ§‰∏∫Êàë‰ª¨Â∞ÜË¶ÅËÆ≤Âà∞ÁöÑËøô‰∫õ‰∏úË•øÊòØÈùûÂ∏∏ÊúâÁî®ÁöÑÔºåÂèØËÉΩÂú®ÊûÑÂª∫Â§ßÂûãÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÊó∂ÔºåËäÇÁúÅÂ§ßÈáèÁöÑÊó∂Èó¥„ÄÇ ‚Äã Êú¨Âë®‰ª•‰∏Ä‰∏™ÂûÉÂúæÈÇÆ‰ª∂ÂàÜÁ±ªÂô®ÁÆóÊ≥ï‰∏∫‰æãËøõË°åËÆ®ËÆ∫„ÄÇ ‚Äã ‰∏∫‰∫ÜËß£ÂÜ≥ËøôÊ†∑‰∏Ä‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨È¶ñÂÖàË¶ÅÂÅöÁöÑÂÜ≥ÂÆöÊòØÂ¶Ç‰ΩïÈÄâÊã©Âπ∂Ë°®ËææÁâπÂæÅÂêëÈáè$x$„ÄÇÊàë‰ª¨ÂèØ‰ª•ÈÄâÊã©‰∏Ä‰∏™Áî±100‰∏™ÊúÄÂ∏∏Âá∫Áé∞Âú®ÂûÉÂúæÈÇÆ‰ª∂‰∏≠ÁöÑËØçÊâÄÊûÑÊàêÁöÑÂàóË°®ÔºåÊ†πÊçÆËøô‰∫õËØçÊòØÂê¶ÊúâÂú®ÈÇÆ‰ª∂‰∏≠Âá∫Áé∞ÔºåÊù•Ëé∑ÂæóÊàë‰ª¨ÁöÑÁâπÂæÅÂêëÈáèÔºàÂá∫Áé∞‰∏∫1Ôºå‰∏çÂá∫Áé∞‰∏∫0ÔºâÔºåÂ∞∫ÂØ∏‰∏∫100√ó1„ÄÇ ‰∏∫‰∫ÜÊûÑÂª∫Ëøô‰∏™ÂàÜÁ±ªÂô®ÁÆóÊ≥ïÔºåÊàë‰ª¨ÂèØ‰ª•ÂÅöÂæàÂ§ö‰∫ãÔºå‰æãÂ¶ÇÔºö Êî∂ÈõÜÊõ¥Â§öÁöÑÊï∞ÊçÆÔºåËÆ©Êàë‰ª¨ÊúâÊõ¥Â§öÁöÑÂûÉÂúæÈÇÆ‰ª∂ÂíåÈùûÂûÉÂúæÈÇÆ‰ª∂ÁöÑÊ†∑Êú¨ Âü∫‰∫éÈÇÆ‰ª∂ÁöÑË∑ØÁî±‰ø°ÊÅØÂºÄÂèë‰∏ÄÁ≥ªÂàóÂ§çÊùÇÁöÑÁâπÂæÅ Âü∫‰∫éÈÇÆ‰ª∂ÁöÑÊ≠£Êñá‰ø°ÊÅØÂºÄÂèë‰∏ÄÁ≥ªÂàóÂ§çÊùÇÁöÑÁâπÂæÅÔºåÂåÖÊã¨ËÄÉËôëÊà™ËØçÁöÑÂ§ÑÁêÜ ‰∏∫Êé¢ÊµãÂàªÊÑèÁöÑÊãºÂÜôÈîôËØØÔºàÊääwatch ÂÜôÊàêw4tchÔºâÂºÄÂèëÂ§çÊùÇÁöÑÁÆóÊ≥ï ‚Äã Âú®‰∏äÈù¢Ëøô‰∫õÈÄâÈ°π‰∏≠ÔºåÈùûÂ∏∏ÈöæÂÜ≥ÂÆöÂ∫îËØ•Âú®Âì™‰∏ÄÈ°π‰∏äËä±Ë¥πÊó∂Èó¥ÂíåÁ≤æÂäõÔºå‰ΩúÂá∫ÊòéÊô∫ÁöÑÈÄâÊã©ÔºåÊØîÈöèÁùÄÊÑüËßâËµ∞Ë¶ÅÊõ¥Â•Ω„ÄÇÂΩìÊàë‰ª¨‰ΩøÁî®Êú∫Âô®Â≠¶‰π†Êó∂ÔºåÊÄªÊòØÂèØ‰ª•‚ÄúÂ§¥ËÑëÈ£éÊö¥‚Äù‰∏Ä‰∏ãÔºåÊÉ≥Âá∫‰∏ÄÂ†ÜÊñπÊ≥ïÊù•ËØïËØï„ÄÇÂÆûÈôÖ‰∏äÔºåÂΩì‰Ω†ÈúÄË¶ÅÈÄöËøáÂ§¥ËÑëÈ£éÊö¥Êù•ÊÉ≥Âá∫‰∏çÂêåÊñπÊ≥ïÊù•Â∞ùËØïÂéªÊèêÈ´òÁ≤æÂ∫¶ÁöÑÊó∂ÂÄôÔºå‰Ω†ÂèØËÉΩÂ∑≤ÁªèË∂ÖË∂ä‰∫ÜÂæàÂ§ö‰∫∫‰∫Ü„ÄÇÂ§ßÈÉ®ÂàÜ‰∫∫Âπ∂‰∏çÂ∞ùËØïÁùÄÂàóÂá∫ÂèØËÉΩÁöÑÊñπÊ≥ïÔºå‰ªñ‰ª¨ÂÅöÁöÑÂè™ÊòØÊüêÂ§©Êó©‰∏äÈÜíÊù•ÔºåÂõ†‰∏∫Êüê‰∫õÂéüÂõ†Êúâ‰∫Ü‰∏Ä‰∏™Á™ÅÂèëÂ•áÊÉ≥Ôºö‚ÄùËÆ©Êàë‰ª¨Êù•ËØïËØïÁî®Honey PotÈ°πÁõÆÊî∂ÈõÜÂ§ßÈáèÁöÑÊï∞ÊçÆÂêß„ÄÇ‚Äù ‚Äã Êàë‰ª¨Â∞ÜÂú®ÈöèÂêéÁöÑËØæÁ®ã‰∏≠ËÆ≤ËØØÂ∑ÆÂàÜÊûêÔºåÊàë‰ºöÂëäËØâ‰Ω†ÊÄéÊ†∑Áî®‰∏Ä‰∏™Êõ¥Âä†Á≥ªÁªüÊÄßÁöÑÊñπÊ≥ïÔºå‰ªé‰∏ÄÂ†Ü‰∏çÂêåÁöÑÊñπÊ≥ï‰∏≠ÔºåÈÄâÂèñÂêàÈÄÇÁöÑÈÇ£‰∏Ä‰∏™„ÄÇÂõ†Ê≠§Ôºå‰Ω†Êõ¥ÊúâÂèØËÉΩÈÄâÊã©‰∏Ä‰∏™ÁúüÊ≠£ÁöÑÂ•ΩÊñπÊ≥ïÔºåËÉΩËÆ©‰Ω†Ëä±‰∏äÂá†Â§©Âá†Âë®ÔºåÁîöËá≥ÊòØÂá†‰∏™ÊúàÂéªËøõË°åÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂„ÄÇ 11.2 ËØØÂ∑ÆÂàÜÊûêÂèÇËÄÉËßÜÈ¢ë: 11 - 2 - Error Analysis (13 min).mkv ‚Äã Âú®Êú¨Ê¨°ËØæÁ®ã‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ºöËÆ≤Âà∞ËØØÂ∑ÆÂàÜÊûêÔºàError AnalysisÔºâÁöÑÊ¶ÇÂøµ„ÄÇËøô‰ºöÂ∏ÆÂä©‰Ω†Êõ¥Á≥ªÁªüÂú∞ÂÅöÂá∫ÂÜ≥ÂÆö„ÄÇÂ¶ÇÊûú‰Ω†ÂáÜÂ§áÁ†îÁ©∂Êú∫Âô®Â≠¶‰π†ÁöÑ‰∏úË•øÔºåÊàñËÄÖÊûÑÈÄ†Êú∫Âô®Â≠¶‰π†Â∫îÁî®Á®ãÂ∫èÔºåÊúÄÂ•ΩÁöÑÂÆûË∑µÊñπÊ≥ï‰∏çÊòØÂª∫Á´ã‰∏Ä‰∏™ÈùûÂ∏∏Â§çÊùÇÁöÑÁ≥ªÁªüÔºåÊã•ÊúâÂ§ö‰πàÂ§çÊùÇÁöÑÂèòÈáèÔºõËÄåÊòØÊûÑÂª∫‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁÆóÊ≥ïÔºåËøôÊ†∑‰Ω†ÂèØ‰ª•ÂæàÂø´Âú∞ÂÆûÁé∞ÂÆÉ„ÄÇ ‚Äã ÊØèÂΩìÊàëÁ†îÁ©∂Êú∫Âô®Â≠¶‰π†ÁöÑÈóÆÈ¢òÊó∂ÔºåÊàëÊúÄÂ§öÂè™‰ºöËä±‰∏ÄÂ§©ÁöÑÊó∂Èó¥ÔºåÂ∞±ÊòØÂ≠óÈù¢ÊÑè‰πâ‰∏äÁöÑ24Â∞èÊó∂ÔºåÊù•ËØïÂõæÂæàÂø´ÁöÑÊääÁªìÊûúÊêûÂá∫Êù•ÔºåÂç≥‰æøÊïàÊûú‰∏çÂ•Ω„ÄÇÂù¶ÁôΩÁöÑËØ¥ÔºåÂ∞±ÊòØÊ†πÊú¨Ê≤°ÊúâÁî®Â§çÊùÇÁöÑÁ≥ªÁªüÔºå‰ΩÜÊòØÂè™ÊòØÂæàÂø´ÁöÑÂæóÂà∞ÁöÑÁªìÊûú„ÄÇÂç≥‰æøËøêË°åÂæó‰∏çÂÆåÁæéÔºå‰ΩÜÊòØ‰πüÊääÂÆÉËøêË°å‰∏ÄÈÅçÔºåÊúÄÂêéÈÄöËøá‰∫§ÂèâÈ™åËØÅÊù•Ê£ÄÈ™åÊï∞ÊçÆ„ÄÇ‰∏ÄÊó¶ÂÅöÂÆåÔºå‰Ω†ÂèØ‰ª•ÁîªÂá∫Â≠¶‰π†Êõ≤Á∫øÔºåÈÄöËøáÁîªÂá∫Â≠¶‰π†Êõ≤Á∫øÔºå‰ª•ÂèäÊ£ÄÈ™åËØØÂ∑ÆÔºåÊù•ÊâæÂá∫‰Ω†ÁöÑÁÆóÊ≥ïÊòØÂê¶ÊúâÈ´òÂÅèÂ∑ÆÂíåÈ´òÊñπÂ∑ÆÁöÑÈóÆÈ¢òÔºåÊàñËÄÖÂà´ÁöÑÈóÆÈ¢ò„ÄÇÂú®ËøôÊ†∑ÂàÜÊûê‰πãÂêéÔºåÂÜçÊù•ÂÜ≥ÂÆöÁî®Êõ¥Â§öÁöÑÊï∞ÊçÆËÆ≠ÁªÉÔºåÊàñËÄÖÂä†ÂÖ•Êõ¥Â§öÁöÑÁâπÂæÅÂèòÈáèÊòØÂê¶ÊúâÁî®„ÄÇËøô‰πàÂÅöÁöÑÂéüÂõ†ÊòØÔºöËøôÂú®‰Ω†ÂàöÊé•Ëß¶Êú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÊó∂ÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÊñπÊ≥ïÔºå‰Ω†Âπ∂‰∏çËÉΩÊèêÂâçÁü•ÈÅì‰Ω†ÊòØÂê¶ÈúÄË¶ÅÂ§çÊùÇÁöÑÁâπÂæÅÂèòÈáèÔºåÊàñËÄÖ‰Ω†ÊòØÂê¶ÈúÄË¶ÅÊõ¥Â§öÁöÑÊï∞ÊçÆÔºåËøòÊòØÂà´ÁöÑ‰ªÄ‰πà„ÄÇÊèêÂâçÁü•ÈÅì‰Ω†Â∫îËØ•ÂÅö‰ªÄ‰πàÔºåÊòØÈùûÂ∏∏ÈöæÁöÑÔºåÂõ†‰∏∫‰Ω†Áº∫Â∞ëËØÅÊçÆÔºåÁº∫Â∞ëÂ≠¶‰π†Êõ≤Á∫ø„ÄÇÂõ†Ê≠§Ôºå‰Ω†ÂæàÈöæÁü•ÈÅì‰Ω†Â∫îËØ•ÊääÊó∂Èó¥Ëä±Âú®‰ªÄ‰πàÂú∞ÊñπÊù•ÊèêÈ´òÁÆóÊ≥ïÁöÑË°®Áé∞„ÄÇ‰ΩÜÊòØÂΩì‰Ω†ÂÆûË∑µ‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÂç≥‰æø‰∏çÂÆåÁæéÁöÑÊñπÊ≥ïÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈÄöËøáÁîªÂá∫Â≠¶‰π†Êõ≤Á∫øÊù•ÂÅöÂá∫Ëøõ‰∏ÄÊ≠•ÁöÑÈÄâÊã©„ÄÇ‰Ω†ÂèØ‰ª•Áî®ËøôÁßçÊñπÂºèÊù•ÈÅøÂÖç‰∏ÄÁßçÁîµËÑëÁºñÁ®ãÈáåÁöÑËøáÊó©‰ºòÂåñÈóÆÈ¢òÔºåËøôÁßçÁêÜÂøµÊòØÔºöÊàë‰ª¨ÂøÖÈ°ªÁî®ËØÅÊçÆÊù•È¢ÜÂØºÊàë‰ª¨ÁöÑÂÜ≥Á≠ñÔºåÊÄéÊ†∑ÂàÜÈÖçËá™Â∑±ÁöÑÊó∂Èó¥Êù•‰ºòÂåñÁÆóÊ≥ïÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖÂá≠Áõ¥ËßâÔºåÂá≠Áõ¥ËßâÂæóÂá∫ÁöÑ‰∏úË•ø‰∏ÄËà¨ÊÄªÊòØÈîôËØØÁöÑ„ÄÇÈô§‰∫ÜÁîªÂá∫Â≠¶‰π†Êõ≤Á∫ø‰πãÂ§ñÔºå‰∏Ä‰ª∂ÈùûÂ∏∏ÊúâÁî®ÁöÑ‰∫ãÊòØËØØÂ∑ÆÂàÜÊûêÔºåÊàëÁöÑÊÑèÊÄùÊòØËØ¥ÔºöÂΩìÊàë‰ª¨Âú®ÊûÑÈÄ†ÂûÉÂúæÈÇÆ‰ª∂ÂàÜÁ±ªÂô®Êó∂ÔºåÊàë‰ºöÁúã‰∏ÄÁúãÊàëÁöÑ‰∫§ÂèâÈ™åËØÅÊï∞ÊçÆÈõÜÔºåÁÑ∂Âêé‰∫≤Ëá™Áúã‰∏ÄÁúãÂì™‰∫õÈÇÆ‰ª∂Ë¢´ÁÆóÊ≥ïÈîôËØØÂú∞ÂàÜÁ±ª„ÄÇÂõ†Ê≠§ÔºåÈÄöËøáËøô‰∫õË¢´ÁÆóÊ≥ïÈîôËØØÂàÜÁ±ªÁöÑÂûÉÂúæÈÇÆ‰ª∂‰∏éÈùûÂûÉÂúæÈÇÆ‰ª∂Ôºå‰Ω†ÂèØ‰ª•ÂèëÁé∞Êüê‰∫õÁ≥ªÁªüÊÄßÁöÑËßÑÂæãÔºö‰ªÄ‰πàÁ±ªÂûãÁöÑÈÇÆ‰ª∂ÊÄªÊòØË¢´ÈîôËØØÂàÜÁ±ª„ÄÇÁªèÂ∏∏Âú∞ËøôÊ†∑ÂÅö‰πãÂêéÔºåËøô‰∏™ËøáÁ®ãËÉΩÂêØÂèë‰Ω†ÊûÑÈÄ†Êñ∞ÁöÑÁâπÂæÅÂèòÈáèÔºåÊàñËÄÖÂëäËØâ‰Ω†ÔºöÁé∞Âú®Ëøô‰∏™Á≥ªÁªüÁöÑÁü≠Â§ÑÔºåÁÑ∂ÂêéÂêØÂèë‰Ω†Â¶Ç‰ΩïÂéªÊèêÈ´òÂÆÉ„ÄÇ ‚Äã ÊûÑÂª∫‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÁöÑÊé®ËçêÊñπÊ≥ï‰∏∫Ôºö ‚Äã 1. ‰ªé‰∏Ä‰∏™ÁÆÄÂçïÁöÑËÉΩÂø´ÈÄüÂÆûÁé∞ÁöÑÁÆóÊ≥ïÂºÄÂßãÔºåÂÆûÁé∞ËØ•ÁÆóÊ≥ïÂπ∂Áî®‰∫§ÂèâÈ™åËØÅÈõÜÊï∞ÊçÆÊµãËØïËøô‰∏™ÁÆóÊ≥ï ‚Äã 2.ÁªòÂà∂Â≠¶‰π†Êõ≤Á∫øÔºåÂÜ≥ÂÆöÊòØÂ¢ûÂä†Êõ¥Â§öÊï∞ÊçÆÔºåÊàñËÄÖÊ∑ªÂä†Êõ¥Â§öÁâπÂæÅÔºåËøòÊòØÂÖ∂‰ªñÈÄâÊã© ‚Äã 3.ËøõË°åËØØÂ∑ÆÂàÜÊûêÔºö‰∫∫Â∑•Ê£ÄÊü•‰∫§ÂèâÈ™åËØÅÈõÜ‰∏≠Êàë‰ª¨ÁÆóÊ≥ï‰∏≠‰∫ßÁîüÈ¢ÑÊµãËØØÂ∑ÆÁöÑÂÆû‰æãÔºåÁúãÁúãËøô‰∫õÂÆû‰æãÊòØÂê¶ÊúâÊüêÁßçÁ≥ªÁªüÂåñÁöÑË∂ãÂäø ‚Äã ‰ª•Êàë‰ª¨ÁöÑÂûÉÂúæÈÇÆ‰ª∂ËøáÊª§Âô®‰∏∫‰æãÔºåËØØÂ∑ÆÂàÜÊûêË¶ÅÂÅöÁöÑÊó¢ÊòØÊ£ÄÈ™å‰∫§ÂèâÈ™åËØÅÈõÜ‰∏≠Êàë‰ª¨ÁöÑÁÆóÊ≥ï‰∫ßÁîüÈîôËØØÈ¢ÑÊµãÁöÑÊâÄÊúâÈÇÆ‰ª∂ÔºåÁúãÔºöÊòØÂê¶ËÉΩÂ∞ÜËøô‰∫õÈÇÆ‰ª∂ÊåâÁÖßÁ±ªÂàÜÁªÑ„ÄÇ‰æãÂ¶ÇÂåªËçØÂìÅÂûÉÂúæÈÇÆ‰ª∂Ôºå‰ªøÂÜíÂìÅÂûÉÂúæÈÇÆ‰ª∂ÊàñËÄÖÂØÜÁ†ÅÁ™ÉÂèñÈÇÆ‰ª∂Á≠â„ÄÇÁÑ∂ÂêéÁúãÂàÜÁ±ªÂô®ÂØπÂì™‰∏ÄÁªÑÈÇÆ‰ª∂ÁöÑÈ¢ÑÊµãËØØÂ∑ÆÊúÄÂ§ßÔºåÂπ∂ÁùÄÊâã‰ºòÂåñ„ÄÇ ‚Äã ÊÄùËÄÉÊÄéÊ†∑ËÉΩÊîπËøõÂàÜÁ±ªÂô®„ÄÇ‰æãÂ¶ÇÔºåÂèëÁé∞ÊòØÂê¶Áº∫Â∞ëÊüê‰∫õÁâπÂæÅÔºåËÆ∞‰∏ãËøô‰∫õÁâπÂæÅÂá∫Áé∞ÁöÑÊ¨°Êï∞„ÄÇ ‚Äã ‰æãÂ¶ÇËÆ∞ÂΩï‰∏ãÈîôËØØÊãºÂÜôÂá∫Áé∞‰∫ÜÂ§öÂ∞ëÊ¨°ÔºåÂºÇÂ∏∏ÁöÑÈÇÆ‰ª∂Ë∑ØÁî±ÊÉÖÂÜµÂá∫Áé∞‰∫ÜÂ§öÂ∞ëÊ¨°Á≠âÁ≠âÔºåÁÑ∂Âêé‰ªéÂá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÊÉÖÂÜµÂºÄÂßãÁùÄÊâã‰ºòÂåñ„ÄÇ ‚Äã ËØØÂ∑ÆÂàÜÊûêÂπ∂‰∏çÊÄªËÉΩÂ∏ÆÂä©Êàë‰ª¨Âà§Êñ≠Â∫îËØ•ÈááÂèñÊÄéÊ†∑ÁöÑË°åÂä®„ÄÇÊúâÊó∂Êàë‰ª¨ÈúÄË¶ÅÂ∞ùËØï‰∏çÂêåÁöÑÊ®°ÂûãÔºåÁÑ∂ÂêéËøõË°åÊØîËæÉÔºåÂú®Ê®°ÂûãÊØîËæÉÊó∂ÔºåÁî®Êï∞ÂÄºÊù•Âà§Êñ≠Âì™‰∏Ä‰∏™Ê®°ÂûãÊõ¥Â•ΩÊõ¥ÊúâÊïàÔºåÈÄöÂ∏∏Êàë‰ª¨ÊòØÁúã‰∫§ÂèâÈ™åËØÅÈõÜÁöÑËØØÂ∑Æ„ÄÇ ‚Äã Âú®Êàë‰ª¨ÁöÑÂûÉÂúæÈÇÆ‰ª∂ÂàÜÁ±ªÂô®‰æãÂ≠ê‰∏≠ÔºåÂØπ‰∫é‚ÄúÊàë‰ª¨ÊòØÂê¶Â∫îËØ•Â∞Üdiscount/discounts/discounted/discountingÂ§ÑÁêÜÊàêÂêå‰∏Ä‰∏™ËØçÔºü‚ÄùÂ¶ÇÊûúËøôÊ†∑ÂÅöÂèØ‰ª•ÊîπÂñÑÊàë‰ª¨ÁÆóÊ≥ïÔºåÊàë‰ª¨‰ºöÈááÁî®‰∏Ä‰∫õÊà™ËØçËΩØ‰ª∂„ÄÇËØØÂ∑ÆÂàÜÊûê‰∏çËÉΩÂ∏ÆÂä©Êàë‰ª¨ÂÅöÂá∫ËøôÁ±ªÂà§Êñ≠ÔºåÊàë‰ª¨Âè™ËÉΩÂ∞ùËØïÈááÁî®Âíå‰∏çÈááÁî®Êà™ËØçËΩØ‰ª∂Ëøô‰∏§Áßç‰∏çÂêåÊñπÊ°àÔºåÁÑ∂ÂêéÊ†πÊçÆÊï∞ÂÄºÊ£ÄÈ™åÁöÑÁªìÊûúÊù•Âà§Êñ≠Âì™‰∏ÄÁßçÊõ¥Â•Ω„ÄÇ ‚Äã Âõ†Ê≠§ÔºåÂΩì‰Ω†Âú®ÊûÑÈÄ†Â≠¶‰π†ÁÆóÊ≥ïÁöÑÊó∂ÂÄôÔºå‰Ω†ÊÄªÊòØ‰ºöÂéªÂ∞ùËØïÂæàÂ§öÊñ∞ÁöÑÊÉ≥Ê≥ïÔºåÂÆûÁé∞Âá∫ÂæàÂ§öÁâàÊú¨ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂ¶ÇÊûúÊØè‰∏ÄÊ¨°‰Ω†ÂÆûË∑µÊñ∞ÊÉ≥Ê≥ïÁöÑÊó∂ÂÄôÔºå‰Ω†ÈÉΩË¶ÅÊâãÂä®Âú∞Ê£ÄÊµãËøô‰∫õ‰æãÂ≠êÔºåÂéªÁúãÁúãÊòØË°®Áé∞Â∑ÆËøòÊòØË°®Áé∞Â•ΩÔºåÈÇ£‰πàËøôÂæàÈöæËÆ©‰Ω†ÂÅöÂá∫ÂÜ≥ÂÆö„ÄÇÂà∞Â∫ïÊòØÂê¶‰ΩøÁî®ËØçÂπ≤ÊèêÂèñÔºåÊòØÂê¶Âå∫ÂàÜÂ§ßÂ∞èÂÜô„ÄÇ‰ΩÜÊòØÈÄöËøá‰∏Ä‰∏™ÈáèÂåñÁöÑÊï∞ÂÄºËØÑ‰º∞Ôºå‰Ω†ÂèØ‰ª•ÁúãÁúãËøô‰∏™Êï∞Â≠óÔºåËØØÂ∑ÆÊòØÂèòÂ§ßËøòÊòØÂèòÂ∞è‰∫Ü„ÄÇ‰Ω†ÂèØ‰ª•ÈÄöËøáÂÆÉÊõ¥Âø´Âú∞ÂÆûË∑µ‰Ω†ÁöÑÊñ∞ÊÉ≥Ê≥ïÔºåÂÆÉÂü∫Êú¨‰∏äÈùûÂ∏∏Áõ¥ËßÇÂú∞ÂëäËØâ‰Ω†Ôºö‰Ω†ÁöÑÊÉ≥Ê≥ïÊòØÊèêÈ´ò‰∫ÜÁÆóÊ≥ïË°®Áé∞ÔºåËøòÊòØËÆ©ÂÆÉÂèòÂæóÊõ¥ÂùèÔºåËøô‰ºöÂ§ßÂ§ßÊèêÈ´ò‰Ω†ÂÆûË∑µÁÆóÊ≥ïÊó∂ÁöÑÈÄüÂ∫¶„ÄÇÊâÄ‰ª•ÊàëÂº∫ÁÉàÊé®ËçêÂú®‰∫§ÂèâÈ™åËØÅÈõÜ‰∏äÊù•ÂÆûÊñΩËØØÂ∑ÆÂàÜÊûêÔºåËÄå‰∏çÊòØÂú®ÊµãËØïÈõÜ‰∏ä„ÄÇ‰ΩÜÊòØÔºåËøòÊòØÊúâ‰∏Ä‰∫õ‰∫∫‰ºöÂú®ÊµãËØïÈõÜ‰∏äÊù•ÂÅöËØØÂ∑ÆÂàÜÊûê„ÄÇÂç≥‰ΩøËøô‰ªéÊï∞Â≠¶‰∏äËÆ≤ÊòØ‰∏çÂêàÈÄÇÁöÑ„ÄÇÊâÄ‰ª•ÊàëËøòÊòØÊé®Ëçê‰Ω†Âú®‰∫§ÂèâÈ™åËØÅÂêëÈáè‰∏äÊù•ÂÅöËØØÂ∑ÆÂàÜÊûê„ÄÇ ‚Äã ÊÄªÁªì‰∏Ä‰∏ãÔºåÂΩì‰Ω†Âú®Á†îÁ©∂‰∏Ä‰∏™Êñ∞ÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÊó∂ÔºåÊàëÊÄªÊòØÊé®Ëçê‰Ω†ÂÆûÁé∞‰∏Ä‰∏™ËæÉ‰∏∫ÁÆÄÂçïÂø´ÈÄü„ÄÅÂç≥‰æø‰∏çÊòØÈÇ£‰πàÂÆåÁæéÁöÑÁÆóÊ≥ï„ÄÇÊàëÂá†‰πé‰ªéÊú™ËßÅËøá‰∫∫‰ª¨ËøôÊ†∑ÂÅö„ÄÇÂ§ßÂÆ∂ÁªèÂ∏∏Âπ≤ÁöÑ‰∫ãÊÉÖÊòØÔºöËä±Ë¥πÂ§ßÈáèÁöÑÊó∂Èó¥Âú®ÊûÑÈÄ†ÁÆóÊ≥ï‰∏äÔºåÊûÑÈÄ†‰ªñ‰ª¨‰ª•‰∏∫ÁöÑÁÆÄÂçïÁöÑÊñπÊ≥ï„ÄÇÂõ†Ê≠§Ôºå‰∏çË¶ÅÊãÖÂøÉ‰Ω†ÁöÑÁÆóÊ≥ïÂ§™ÁÆÄÂçïÔºåÊàñËÄÖÂ§™‰∏çÂÆåÁæéÔºåËÄåÊòØÂ∞ΩÂèØËÉΩÂø´Âú∞ÂÆûÁé∞‰Ω†ÁöÑÁÆóÊ≥ï„ÄÇÂΩì‰Ω†Êúâ‰∫ÜÂàùÂßãÁöÑÂÆûÁé∞‰πãÂêéÔºåÂÆÉ‰ºöÂèòÊàê‰∏Ä‰∏™ÈùûÂ∏∏ÊúâÂäõÁöÑÂ∑•ÂÖ∑ÔºåÊù•Â∏ÆÂä©‰Ω†ÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•ÁöÑÂÅöÊ≥ï„ÄÇÂõ†‰∏∫Êàë‰ª¨ÂèØ‰ª•ÂÖàÁúãÁúãÁÆóÊ≥ïÈÄ†ÊàêÁöÑÈîôËØØÔºåÈÄöËøáËØØÂ∑ÆÂàÜÊûêÔºåÊù•ÁúãÁúã‰ªñÁäØ‰∫Ü‰ªÄ‰πàÈîôÔºåÁÑ∂ÂêéÊù•ÂÜ≥ÂÆö‰ºòÂåñÁöÑÊñπÂºè„ÄÇÂè¶‰∏Ä‰ª∂‰∫ãÊòØÔºöÂÅáËÆæ‰Ω†Êúâ‰∫Ü‰∏Ä‰∏™Âø´ÈÄüËÄå‰∏çÂÆåÁæéÁöÑÁÆóÊ≥ïÂÆûÁé∞ÔºåÂèàÊúâ‰∏Ä‰∏™Êï∞ÂÄºÁöÑËØÑ‰º∞Êï∞ÊçÆÔºåËøô‰ºöÂ∏ÆÂä©‰Ω†Â∞ùËØïÊñ∞ÁöÑÊÉ≥Ê≥ïÔºåÂø´ÈÄüÂú∞ÂèëÁé∞‰Ω†Â∞ùËØïÁöÑËøô‰∫õÊÉ≥Ê≥ïÊòØÂê¶ËÉΩÂ§üÊèêÈ´òÁÆóÊ≥ïÁöÑË°®Áé∞Ôºå‰ªéËÄå‰Ω†‰ºöÊõ¥Âø´Âú∞ÂÅöÂá∫ÂÜ≥ÂÆöÔºåÂú®ÁÆóÊ≥ï‰∏≠ÊîæÂºÉ‰ªÄ‰πàÔºåÂê∏Êî∂‰ªÄ‰πàËØØÂ∑ÆÂàÜÊûêÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨Á≥ªÁªüÂåñÂú∞ÈÄâÊã©ËØ•ÂÅö‰ªÄ‰πà„ÄÇ 11.3 Á±ªÂÅèÊñúÁöÑËØØÂ∑ÆÂ∫¶ÈáèÂèÇËÄÉËßÜÈ¢ë: 11 - 3 - Error Metrics for Skewed Classes (12 min).mkv ‚Äã Âú®ÂâçÈù¢ÁöÑËØæÁ®ã‰∏≠ÔºåÊàëÊèêÂà∞‰∫ÜËØØÂ∑ÆÂàÜÊûêÔºå‰ª•ÂèäËÆæÂÆöËØØÂ∑ÆÂ∫¶ÈáèÂÄºÁöÑÈáçË¶ÅÊÄß„ÄÇÈÇ£Â∞±ÊòØÔºåËÆæÂÆöÊüê‰∏™ÂÆûÊï∞Êù•ËØÑ‰º∞‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂπ∂Ë°°ÈáèÂÆÉÁöÑË°®Áé∞ÔºåÊúâ‰∫ÜÁÆóÊ≥ïÁöÑËØÑ‰º∞ÂíåËØØÂ∑ÆÂ∫¶ÈáèÂÄº„ÄÇÊúâ‰∏Ä‰ª∂ÈáçË¶ÅÁöÑ‰∫ãÊÉÖË¶ÅÊ≥®ÊÑèÔºåÂ∞±ÊòØ‰ΩøÁî®‰∏Ä‰∏™ÂêàÈÄÇÁöÑËØØÂ∑ÆÂ∫¶ÈáèÂÄºÔºåËøôÊúâÊó∂‰ºöÂØπ‰∫é‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÈÄ†ÊàêÈùûÂ∏∏ÂæÆÂ¶ôÁöÑÂΩ±ÂìçÔºåËøô‰ª∂ÈáçË¶ÅÁöÑ‰∫ãÊÉÖÂ∞±ÊòØÂÅèÊñúÁ±ªÔºàskewed classesÔºâÁöÑÈóÆÈ¢ò„ÄÇÁ±ªÂÅèÊñúÊÉÖÂÜµË°®Áé∞‰∏∫Êàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜ‰∏≠ÊúâÈùûÂ∏∏Â§öÁöÑÂêå‰∏ÄÁßçÁ±ªÁöÑÂÆû‰æãÔºåÂè™ÊúâÂæàÂ∞ëÊàñÊ≤°ÊúâÂÖ∂‰ªñÁ±ªÁöÑÂÆû‰æã„ÄÇ ‚Äã ‰æãÂ¶ÇÊàë‰ª¨Â∏åÊúõÁî®ÁÆóÊ≥ïÊù•È¢ÑÊµãÁôåÁóáÊòØÂê¶ÊòØÊÅ∂ÊÄßÁöÑÔºåÂú®Êàë‰ª¨ÁöÑËÆ≠ÁªÉÈõÜ‰∏≠ÔºåÂè™Êúâ0.5%ÁöÑÂÆû‰æãÊòØÊÅ∂ÊÄßËÇøÁò§„ÄÇÂÅáËÆæÊàë‰ª¨ÁºñÂÜô‰∏Ä‰∏™ÈùûÂ≠¶‰π†ËÄåÊù•ÁöÑÁÆóÊ≥ïÔºåÂú®ÊâÄÊúâÊÉÖÂÜµ‰∏ãÈÉΩÈ¢ÑÊµãËÇøÁò§ÊòØËâØÊÄßÁöÑÔºåÈÇ£‰πàËØØÂ∑ÆÂè™Êúâ0.5%„ÄÇÁÑ∂ËÄåÊàë‰ª¨ÈÄöËøáËÆ≠ÁªÉËÄåÂæóÂà∞ÁöÑÁ•ûÁªèÁΩëÁªúÁÆóÊ≥ïÂç¥Êúâ1%ÁöÑËØØÂ∑Æ„ÄÇËøôÊó∂ÔºåËØØÂ∑ÆÁöÑÂ§ßÂ∞èÊòØ‰∏çËÉΩËßÜ‰∏∫ËØÑÂà§ÁÆóÊ≥ïÊïàÊûúÁöÑ‰æùÊçÆÁöÑ„ÄÇ ‚Äã Êü•ÂáÜÁéáÔºàPrecisionÔºâÂíåÊü•ÂÖ®ÁéáÔºàRecallÔºâ Êàë‰ª¨Â∞ÜÁÆóÊ≥ïÈ¢ÑÊµãÁöÑÁªìÊûúÂàÜÊàêÂõõÁßçÊÉÖÂÜµÔºö ‚Äã 1. Ê≠£Á°ÆËÇØÂÆöÔºàTrue Positive,TPÔºâÔºöÈ¢ÑÊµã‰∏∫ÁúüÔºåÂÆûÈôÖ‰∏∫Áúü ‚Äã 2.Ê≠£Á°ÆÂê¶ÂÆöÔºàTrue Negative,TNÔºâÔºöÈ¢ÑÊµã‰∏∫ÂÅáÔºåÂÆûÈôÖ‰∏∫ÂÅá ‚Äã 3.ÈîôËØØËÇØÂÆöÔºàFalse Positive,FPÔºâÔºöÈ¢ÑÊµã‰∏∫ÁúüÔºåÂÆûÈôÖ‰∏∫ÂÅá ‚Äã 4.ÈîôËØØÂê¶ÂÆöÔºàFalse Negative,FNÔºâÔºöÈ¢ÑÊµã‰∏∫ÂÅáÔºåÂÆûÈôÖ‰∏∫Áúü ‚Äã ÂàôÔºöÊü•ÂáÜÁéá=TP/(TP+FP)„ÄÇ‰æãÔºåÂú®ÊâÄÊúâÊàë‰ª¨È¢ÑÊµãÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫‰∏≠ÔºåÂÆûÈôÖ‰∏äÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫ÁöÑÁôæÂàÜÊØîÔºåË∂äÈ´òË∂äÂ•Ω„ÄÇ ‚Äã Êü•ÂÖ®Áéá=TP/(TP+FN)„ÄÇ‰æãÔºåÂú®ÊâÄÊúâÂÆûÈôÖ‰∏äÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫‰∏≠ÔºåÊàêÂäüÈ¢ÑÊµãÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫ÁöÑÁôæÂàÜÊØîÔºåË∂äÈ´òË∂äÂ•Ω„ÄÇ ‚Äã ËøôÊ†∑ÔºåÂØπ‰∫éÊàë‰ª¨ÂàöÊâçÈÇ£‰∏™ÊÄªÊòØÈ¢ÑÊµãÁóÖ‰∫∫ËÇøÁò§‰∏∫ËâØÊÄßÁöÑÁÆóÊ≥ïÔºåÂÖ∂Êü•ÂÖ®ÁéáÊòØ0„ÄÇ È¢ÑÊµãÂÄº Positive Negtive ÂÆûÈôÖÂÄº Positive TP FN Negtive FP TN 11.4 Êü•ÂáÜÁéáÂíåÊü•ÂÖ®Áéá‰πãÈó¥ÁöÑÊùÉË°°ÂèÇËÄÉËßÜÈ¢ë: 11 - 4 - Trading Off Precision and Recall (14 min).mkv ‚Äã Âú®‰πãÂâçÁöÑËØæÁ®ã‰∏≠ÔºåÊàë‰ª¨Ë∞àÂà∞Êü•ÂáÜÁéáÂíåÂè¨ÂõûÁéáÔºå‰Ωú‰∏∫ÈÅáÂà∞ÂÅèÊñúÁ±ªÈóÆÈ¢òÁöÑËØÑ‰º∞Â∫¶ÈáèÂÄº„ÄÇÂú®ÂæàÂ§öÂ∫îÁî®‰∏≠ÔºåÊàë‰ª¨Â∏åÊúõËÉΩÂ§ü‰øùËØÅÊü•ÂáÜÁéáÂíåÂè¨ÂõûÁéáÁöÑÁõ∏ÂØπÂπ≥Ë°°„ÄÇ ‚Äã Âú®ËøôËäÇËØæ‰∏≠ÔºåÊàëÂ∞ÜÂëäËØâ‰Ω†Â∫îËØ•ÊÄé‰πàÂÅöÔºåÂêåÊó∂‰πüÂêë‰Ω†Â±ïÁ§∫‰∏Ä‰∫õÊü•ÂáÜÁéáÂíåÂè¨ÂõûÁéá‰Ωú‰∏∫ÁÆóÊ≥ïËØÑ‰º∞Â∫¶ÈáèÂÄºÁöÑÊõ¥ÊúâÊïàÁöÑÊñπÂºè„ÄÇÁªßÁª≠Ê≤øÁî®ÂàöÊâçÈ¢ÑÊµãËÇøÁò§ÊÄßË¥®ÁöÑ‰æãÂ≠ê„ÄÇÂÅá‰ΩøÔºåÊàë‰ª¨ÁöÑÁÆóÊ≥ïËæìÂá∫ÁöÑÁªìÊûúÂú®0-1 ‰πãÈó¥ÔºåÊàë‰ª¨‰ΩøÁî®ÈòÄÂÄº0.5 Êù•È¢ÑÊµãÁúüÂíåÂÅá„ÄÇ ‚Äã Êü•ÂáÜÁéá(Precision)=TP/(TP+FP)‰æãÔºåÂú®ÊâÄÊúâÊàë‰ª¨È¢ÑÊµãÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫‰∏≠ÔºåÂÆûÈôÖ‰∏äÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫ÁöÑÁôæÂàÜÊØîÔºåË∂äÈ´òË∂äÂ•Ω„ÄÇ ‚Äã Êü•ÂÖ®Áéá(Recall)=TP/(TP+FN)‰æãÔºåÂú®ÊâÄÊúâÂÆûÈôÖ‰∏äÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫‰∏≠ÔºåÊàêÂäüÈ¢ÑÊµãÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫ÁöÑÁôæÂàÜÊØîÔºåË∂äÈ´òË∂äÂ•Ω„ÄÇ ‚Äã Â¶ÇÊûúÊàë‰ª¨Â∏åÊúõÂè™Âú®ÈùûÂ∏∏Á°Æ‰ø°ÁöÑÊÉÖÂÜµ‰∏ãÈ¢ÑÊµã‰∏∫ÁúüÔºàËÇøÁò§‰∏∫ÊÅ∂ÊÄßÔºâÔºåÂç≥Êàë‰ª¨Â∏åÊúõÊõ¥È´òÁöÑÊü•ÂáÜÁéáÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®ÊØî0.5Êõ¥Â§ßÁöÑÈòÄÂÄºÔºåÂ¶Ç0.7Ôºå0.9„ÄÇËøôÊ†∑ÂÅöÊàë‰ª¨‰ºöÂáèÂ∞ëÈîôËØØÈ¢ÑÊµãÁóÖ‰∫∫‰∏∫ÊÅ∂ÊÄßËÇøÁò§ÁöÑÊÉÖÂÜµÔºåÂêåÊó∂Âç¥‰ºöÂ¢ûÂä†Êú™ËÉΩÊàêÂäüÈ¢ÑÊµãËÇøÁò§‰∏∫ÊÅ∂ÊÄßÁöÑÊÉÖÂÜµ„ÄÇ ‚Äã Â¶ÇÊûúÊàë‰ª¨Â∏åÊúõÊèêÈ´òÊü•ÂÖ®ÁéáÔºåÂ∞ΩÂèØËÉΩÂú∞ËÆ©ÊâÄÊúâÊúâÂèØËÉΩÊòØÊÅ∂ÊÄßËÇøÁò§ÁöÑÁóÖ‰∫∫ÈÉΩÂæóÂà∞Ëøõ‰∏ÄÊ≠•Âú∞Ê£ÄÊü•„ÄÅËØäÊñ≠ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®ÊØî0.5Êõ¥Â∞èÁöÑÈòÄÂÄºÔºåÂ¶Ç0.3„ÄÇ ‚Äã Êàë‰ª¨ÂèØ‰ª•Â∞Ü‰∏çÂêåÈòÄÂÄºÊÉÖÂÜµ‰∏ãÔºåÊü•ÂÖ®Áéá‰∏éÊü•ÂáÜÁéáÁöÑÂÖ≥Á≥ªÁªòÂà∂ÊàêÂõæË°®ÔºåÊõ≤Á∫øÁöÑÂΩ¢Áä∂Ê†πÊçÆÊï∞ÊçÆÁöÑ‰∏çÂêåËÄå‰∏çÂêåÔºö ‚Äã Êàë‰ª¨Â∏åÊúõÊúâ‰∏Ä‰∏™Â∏ÆÂä©Êàë‰ª¨ÈÄâÊã©Ëøô‰∏™ÈòÄÂÄºÁöÑÊñπÊ≥ï„ÄÇ‰∏ÄÁßçÊñπÊ≥ïÊòØËÆ°ÁÆóF1 ÂÄºÔºàF1 ScoreÔºâÔºåÂÖ∂ËÆ°ÁÆóÂÖ¨Âºè‰∏∫Ôºö ${{F}_{1}}Score:2\frac{PR}{P+R}$ Êàë‰ª¨ÈÄâÊã©‰ΩøÂæóF1ÂÄºÊúÄÈ´òÁöÑÈòÄÂÄº„ÄÇ 11.5 Êú∫Âô®Â≠¶‰π†ÁöÑÊï∞ÊçÆÂèÇËÄÉËßÜÈ¢ë: 11 - 5 - Data For Machine Learning (11 min).mkv ‚Äã Âú®‰πãÂâçÁöÑËßÜÈ¢ë‰∏≠ÔºåÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜËØÑ‰ª∑ÊåáÊ†á„ÄÇÂú®Ëøô‰∏™ËßÜÈ¢ë‰∏≠ÔºåÊàëË¶ÅÁ®çÂæÆËΩ¨Êç¢‰∏Ä‰∏ãÔºåËÆ®ËÆ∫‰∏Ä‰∏ãÊú∫Âô®Â≠¶‰π†Á≥ªÁªüËÆæËÆ°‰∏≠Âè¶‰∏Ä‰∏™ÈáçË¶ÅÁöÑÊñπÈù¢ÔºåËøôÂæÄÂæÄÊ∂âÂèäÂà∞Áî®Êù•ËÆ≠ÁªÉÁöÑÊï∞ÊçÆÊúâÂ§öÂ∞ë„ÄÇÂú®‰πãÂâçÁöÑ‰∏Ä‰∫õËßÜÈ¢ë‰∏≠ÔºåÊàëÊõæÂëäËØ´Â§ßÂÆ∂‰∏çË¶ÅÁõ≤ÁõÆÂú∞ÂºÄÂßãÔºåËÄåÊòØËä±Â§ßÈáèÁöÑÊó∂Èó¥Êù•Êî∂ÈõÜÂ§ßÈáèÁöÑÊï∞ÊçÆÔºåÂõ†‰∏∫Êï∞ÊçÆÊúâÊó∂ÊòØÂîØ‰∏ÄËÉΩÂÆûÈôÖËµ∑Âà∞‰ΩúÁî®ÁöÑ„ÄÇ‰ΩÜ‰∫ãÂÆûËØÅÊòéÔºåÂú®‰∏ÄÂÆöÊù°‰ª∂‰∏ãÔºåÊàë‰ºöÂú®Ëøô‰∏™ËßÜÈ¢ëÈáåËÆ≤Âà∞Ëøô‰∫õÊù°‰ª∂ÊòØ‰ªÄ‰πà„ÄÇÂæóÂà∞Â§ßÈáèÁöÑÊï∞ÊçÆÂπ∂Âú®ÊüêÁßçÁ±ªÂûãÁöÑÂ≠¶‰π†ÁÆóÊ≥ï‰∏≠ËøõË°åËÆ≠ÁªÉÔºåÂèØ‰ª•ÊòØ‰∏ÄÁßçÊúâÊïàÁöÑÊñπÊ≥ïÊù•Ëé∑Âæó‰∏Ä‰∏™ÂÖ∑ÊúâËâØÂ•ΩÊÄßËÉΩÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇËÄåËøôÁßçÊÉÖÂÜµÂæÄÂæÄÂá∫Áé∞Âú®Ëøô‰∫õÊù°‰ª∂ÂØπ‰∫é‰Ω†ÁöÑÈóÆÈ¢òÈÉΩÊàêÁ´ã„ÄÇÂπ∂‰∏î‰Ω†ËÉΩÂ§üÂæóÂà∞Â§ßÈáèÊï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ã„ÄÇËøôÂèØ‰ª•ÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÊñπÂºèÊù•Ëé∑ÂæóÈùûÂ∏∏È´òÊÄßËÉΩÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÂú®ËøôÊÆµËßÜÈ¢ë‰∏≠ÔºåËÆ©Êàë‰ª¨‰∏ÄËµ∑ËÆ®ËÆ∫‰∏Ä‰∏ãËøô‰∏™ÈóÆÈ¢ò„ÄÇ ‚Äã ÂæàÂ§öÂæàÂ§öÂπ¥ÂâçÔºåÊàëËÆ§ËØÜÁöÑ‰∏§‰ΩçÁ†îÁ©∂‰∫∫ÂëòMichele Banko ÂíåEric BrillËøõË°å‰∫Ü‰∏ÄÈ°πÊúâË∂£ÁöÑÁ†îÁ©∂Ôºå‰ªñ‰ª¨Â∞ùËØïÈÄöËøáÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊù•Âå∫ÂàÜÂ∏∏ËßÅÁöÑÊòìÊ∑∑Ê∑ÜÁöÑÂçïËØçÔºå‰ªñ‰ª¨Â∞ùËØï‰∫ÜËÆ∏Â§öÁßç‰∏çÂêåÁöÑÁÆóÊ≥ïÔºåÂπ∂ÂèëÁé∞Êï∞ÊçÆÈáèÈùûÂ∏∏Â§ßÊó∂ÔºåËøô‰∫õ‰∏çÂêåÁ±ªÂûãÁöÑÁÆóÊ≥ïÊïàÊûúÈÉΩÂæàÂ•Ω„ÄÇ ‚Äã ÊØîÂ¶ÇÔºåÂú®ËøôÊ†∑ÁöÑÂè•Â≠ê‰∏≠ÔºöÊó©È§êÊàëÂêÉ‰∫Ü__‰∏™È∏°Ëõã(to,two,too)ÔºåÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠Ôºå‚ÄúÊó©È§êÊàëÂêÉ‰∫Ü2‰∏™È∏°Ëõã‚ÄùÔºåËøôÊòØ‰∏Ä‰∏™ÊòìÊ∑∑Ê∑ÜÁöÑÂçïËØçÁöÑ‰æãÂ≠ê„ÄÇ‰∫éÊòØ‰ªñ‰ª¨ÊääËØ∏Â¶ÇËøôÊ†∑ÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÔºåÂΩìÂÅö‰∏ÄÁ±ªÁõëÁù£Â≠¶‰π†ÈóÆÈ¢òÔºåÂπ∂Â∞ùËØïÂ∞ÜÂÖ∂ÂàÜÁ±ªÔºå‰ªÄ‰πàÊ†∑ÁöÑËØçÔºåÂú®‰∏Ä‰∏™Ëã±ÊñáÂè•Â≠êÁâπÂÆöÁöÑ‰ΩçÁΩÆÔºåÊâçÊòØÂêàÈÄÇÁöÑ„ÄÇ‰ªñ‰ª¨Áî®‰∫ÜÂá†Áßç‰∏çÂêåÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåËøô‰∫õÁÆóÊ≥ïÈÉΩÊòØÂú®‰ªñ‰ª¨2001Âπ¥ËøõË°åÁ†îÁ©∂ÁöÑÊó∂ÂÄôÔºåÈÉΩÂ∑≤ÁªèË¢´ÂÖ¨ËÆ§ÊòØÊØîËæÉÈ¢ÜÂÖàÁöÑ„ÄÇÂõ†Ê≠§‰ªñ‰ª¨‰ΩøÁî®‰∫Ü‰∏Ä‰∏™ÊñπÂ∑ÆÔºåÁî®‰∫éÈÄªËæëÂõûÂΩí‰∏äÁöÑ‰∏Ä‰∏™ÊñπÂ∑ÆÔºåË¢´Áß∞‰Ωú‚ÄùÊÑüÁü•Âô®‚Äù(perceptron)„ÄÇ‰ªñ‰ª¨‰πüÈááÂèñ‰∫Ü‰∏Ä‰∫õËøáÂéªÂ∏∏Áî®Ôºå‰ΩÜÊòØÁé∞Âú®ÊØîËæÉÂ∞ëÁî®ÁöÑÁÆóÊ≥ïÔºåÊØîÂ¶Ç WinnowÁÆóÊ≥ïÔºåÂæàÁ±ª‰ºº‰∫éÂõûÂΩíÈóÆÈ¢òÔºå‰ΩÜÂú®‰∏Ä‰∫õÊñπÈù¢ÂèàÊúâÊâÄ‰∏çÂêåÔºåËøáÂéªÁî®ÂæóÊØîËæÉÂ§öÔºå‰ΩÜÁé∞Âú®Áî®Âæó‰∏çÂ§™Â§ö„ÄÇËøòÊúâ‰∏ÄÁßçÂü∫‰∫éÂÜÖÂ≠òÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÁé∞Âú®‰πüÁî®ÂæóÊØîËæÉÂ∞ë‰∫ÜÔºå‰ΩÜÊòØÊàëÁ®çÂêé‰ºöËÆ®ËÆ∫‰∏ÄÁÇπÔºåËÄå‰∏î‰ªñ‰ª¨Áî®‰∫Ü‰∏Ä‰∏™Êú¥Á¥†ÁÆóÊ≥ï„ÄÇËøô‰∫õÂÖ∑‰ΩìÁÆóÊ≥ïÁöÑÁªÜËäÇ‰∏çÈÇ£‰πàÈáçË¶ÅÔºåÊàë‰ª¨‰∏ãÈù¢Â∏åÊúõÊé¢ËÆ®Ôºå‰ªÄ‰πàÊó∂ÂÄôÊàë‰ª¨‰ºöÂ∏åÊúõËé∑ÂæóÊõ¥Â§öÊï∞ÊçÆÔºåËÄåÈùû‰øÆÊîπÁÆóÊ≥ï„ÄÇ‰ªñ‰ª¨ÊâÄÂÅöÁöÑÂ∞±ÊòØÊîπÂèò‰∫ÜËÆ≠ÁªÉÊï∞ÊçÆÈõÜÁöÑÂ§ßÂ∞èÔºåÂπ∂Â∞ùËØïÂ∞ÜËøô‰∫õÂ≠¶‰π†ÁÆóÊ≥ïÁî®‰∫é‰∏çÂêåÂ§ßÂ∞èÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏≠ÔºåËøôÂ∞±ÊòØ‰ªñ‰ª¨ÂæóÂà∞ÁöÑÁªìÊûú„ÄÇ ‚Äã Ëøô‰∫õË∂ãÂäøÈùûÂ∏∏ÊòéÊòæÔºåÈ¶ñÂÖàÂ§ßÈÉ®ÂàÜÁÆóÊ≥ïÔºåÈÉΩÂÖ∑ÊúâÁõ∏‰ººÁöÑÊÄßËÉΩÔºåÂÖ∂Ê¨°ÔºåÈöèÁùÄËÆ≠ÁªÉÊï∞ÊçÆÈõÜÁöÑÂ¢ûÂ§ßÔºåÂú®Ê®™ËΩ¥‰∏ä‰ª£Ë°®‰ª•Áôæ‰∏á‰∏∫Âçï‰ΩçÁöÑËÆ≠ÁªÉÈõÜÂ§ßÂ∞èÔºå‰ªé0.1‰∏™Áôæ‰∏áÂà∞1000Áôæ‰∏áÔºå‰πüÂ∞±ÊòØÂà∞‰∫Ü10‰∫øËßÑÊ®°ÁöÑËÆ≠ÁªÉÈõÜÁöÑÊ†∑Êú¨ÔºåËøô‰∫õÁÆóÊ≥ïÁöÑÊÄßËÉΩ‰πüÈÉΩÂØπÂ∫îÂú∞Â¢ûÂº∫‰∫Ü„ÄÇ ‚Äã ‰∫ãÂÆû‰∏äÔºåÂ¶ÇÊûú‰Ω†ÈÄâÊã©‰ªªÊÑè‰∏Ä‰∏™ÁÆóÊ≥ïÔºåÂèØËÉΩÊòØÈÄâÊã©‰∫Ü‰∏Ä‰∏™‚ÄùÂä£Á≠âÁöÑ‚ÄùÁÆóÊ≥ïÔºåÂ¶ÇÊûú‰Ω†ÁªôËøô‰∏™Âä£Á≠âÁÆóÊ≥ïÊõ¥Â§öÁöÑÊï∞ÊçÆÔºåÈÇ£‰πà‰ªéËøô‰∫õ‰æãÂ≠ê‰∏≠ÁúãËµ∑Êù•ÁöÑËØùÔºåÂÆÉÁúã‰∏äÂéªÂæàÊúâÂèØËÉΩ‰ºöÂÖ∂‰ªñÁÆóÊ≥ïÊõ¥Â•ΩÔºåÁîöËá≥‰ºöÊØî‚Äù‰ºòÁ≠âÁÆóÊ≥ï‚ÄùÊõ¥Â•Ω„ÄÇÁî±‰∫éËøôÈ°πÂéüÂßãÁöÑÁ†îÁ©∂ÈùûÂ∏∏ÂÖ∑ÊúâÂΩ±ÂìçÂäõÔºåÂõ†Ê≠§Â∑≤ÁªèÊúâ‰∏ÄÁ≥ªÂàóËÆ∏Â§ö‰∏çÂêåÁöÑÁ†îÁ©∂ÊòæÁ§∫‰∫ÜÁ±ª‰ººÁöÑÁªìÊûú„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåËÆ∏Â§ö‰∏çÂêåÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÊúâÊó∂ÂÄæÂêë‰∫éË°®Áé∞Âá∫ÈùûÂ∏∏Áõ∏‰ººÁöÑË°®Áé∞ÔºåËøôËøòÂèñÂÜ≥‰∫é‰∏Ä‰∫õÁªÜËäÇÔºå‰ΩÜÊòØÁúüÊ≠£ËÉΩÊèêÈ´òÊÄßËÉΩÁöÑÔºåÊòØ‰Ω†ËÉΩÂ§üÁªô‰∏Ä‰∏™ÁÆóÊ≥ïÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇÂÉèËøôÊ†∑ÁöÑÁªìÊûúÔºåÂºïËµ∑‰∫Ü‰∏ÄÁßçÂú®Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÊôÆÈÅçÂÖ±ËØÜÔºö‚ÄùÂèñÂæóÊàêÂäüÁöÑ‰∫∫‰∏çÊòØÊã•ÊúâÊúÄÂ•ΩÁÆóÊ≥ïÁöÑ‰∫∫ÔºåËÄåÊòØÊã•ÊúâÊúÄÂ§öÊï∞ÊçÆÁöÑ‰∫∫‚Äù„ÄÇ ‚Äã ÈÇ£‰πàËøôÁßçËØ¥Ê≥ïÂú®‰ªÄ‰πàÊó∂ÂÄôÊòØÁúüÔºå‰ªÄ‰πàÊó∂ÂÄôÊòØÂÅáÂë¢ÔºüÂõ†‰∏∫Â¶ÇÊûúÊàë‰ª¨Êúâ‰∏Ä‰∏™Â≠¶‰π†ÁÆóÊ≥ïÔºåÂπ∂‰∏îÂ¶ÇÊûúËøôÁßçËØ¥Ê≥ïÊòØÁúüÁöÑÔºåÈÇ£‰πàÂæóÂà∞Â§ßÈáèÁöÑÊï∞ÊçÆÈÄöÂ∏∏ÊòØ‰øùËØÅÊàë‰ª¨ÂÖ∑Êúâ‰∏Ä‰∏™È´òÊÄßËÉΩÁÆóÊ≥ïÁöÑÊúÄ‰Ω≥ÊñπÂºèÔºåËÄå‰∏çÊòØÂéª‰∫âËæ©Â∫îËØ•Áî®‰ªÄ‰πàÊ†∑ÁöÑÁÆóÊ≥ï„ÄÇ ‚Äã ÂÅáÂ¶ÇÊúâËøôÊ†∑‰∏Ä‰∫õÂÅáËÆæÔºåÂú®Ëøô‰∫õÂÅáËÆæ‰∏ãÊúâÂ§ßÈáèÊàë‰ª¨ËÆ§‰∏∫ÊúâÁî®ÁöÑËÆ≠ÁªÉÈõÜÔºåÊàë‰ª¨ÂÅáËÆæÂú®Êàë‰ª¨ÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢ò‰∏≠ÔºåÁâπÂæÅÂÄº$x$ÂåÖÂê´‰∫ÜË∂≥Â§üÁöÑ‰ø°ÊÅØÔºåËøô‰∫õ‰ø°ÊÅØÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨Áî®Êù•ÂáÜÁ°ÆÂú∞È¢ÑÊµã$y$Ôºå‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊàë‰ª¨ÈááÁî®‰∫Ü‰∏Ä‰∫õÂÆπÊòìÊ∑∑Ê∑ÜÁöÑËØçÔºåÂ¶ÇÔºötwo„ÄÅto„ÄÅtooÔºåÂÅáÂ¶ÇËØ¥ÂÆÉËÉΩÂ§üÊèèËø∞$x$ÔºåÊçïÊçâÂà∞ÈúÄË¶ÅÂ°´ÂÜôÁöÑÁ©∫ÁôΩÂ§ÑÂë®Âõ¥ÁöÑËØçËØ≠ÔºåÈÇ£‰πàÁâπÂæÅÊçïÊçâÂà∞‰πãÂêéÔºåÊàë‰ª¨Â∞±Â∏åÊúõÊúâÂØπ‰∫é‚ÄúÊó©È•≠ÊàëÂêÉ‰∫Ü__È∏°Ëõã‚ÄùÔºåÈÇ£‰πàËøôÂ∞±ÊúâÂ§ßÈáèÁöÑ‰ø°ÊÅØÊù•ÂëäËØâÊàë‰∏≠Èó¥ÊàëÈúÄË¶ÅÂ°´ÁöÑËØçÊòØ‚Äú‰∏§‰∏™‚Äù(two)ÔºåËÄå‰∏çÊòØÂçïËØç to ÊàñtooÔºåÂõ†Ê≠§ÁâπÂæÅÊçïÊçâÔºåÂì™ÊÄïÊòØÂë®Âõ¥ËØçËØ≠‰∏≠ÁöÑ‰∏Ä‰∏™ËØçÔºåÂ∞±ËÉΩÂ§üÁªôÊàëË∂≥Â§üÁöÑ‰ø°ÊÅØÊù•Á°ÆÂÆöÂá∫Ê†áÁ≠æ $y$ÊòØ‰ªÄ‰πà„ÄÇÊç¢Âè•ËØùËØ¥Ôºå‰ªéËøô‰∏âÁªÑÊòìÊ∑∑Ê∑ÜÁöÑËØç‰∏≠ÔºåÊàëÂ∫îËØ•ÈÄâ‰ªÄ‰πàËØçÊù•Â°´Á©∫„ÄÇ ‚Äã ÈÇ£‰πàËÆ©Êàë‰ª¨Êù•Áúã‰∏ÄÁúãÔºåÂ§ßÈáèÁöÑÊï∞ÊçÆÊòØÊúâÂ∏ÆÂä©ÁöÑÊÉÖÂÜµ„ÄÇÂÅáËÆæÁâπÂæÅÂÄºÊúâË∂≥Â§üÁöÑ‰ø°ÊÅØÊù•È¢ÑÊµã$y$ÂÄºÔºåÂÅáËÆæÊàë‰ª¨‰ΩøÁî®‰∏ÄÁßçÈúÄË¶ÅÂ§ßÈáèÂèÇÊï∞ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊØîÂ¶ÇÊúâÂæàÂ§öÁâπÂæÅÁöÑÈÄªËæëÂõûÂΩíÊàñÁ∫øÊÄßÂõûÂΩíÔºåÊàñËÄÖÁî®Â∏¶ÊúâËÆ∏Â§öÈöêËóèÂçïÂÖÉÁöÑÁ•ûÁªèÁΩëÁªúÔºåÈÇ£ÂèàÊòØÂè¶Â§ñ‰∏ÄÁßçÂ∏¶ÊúâÂæàÂ§öÂèÇÊï∞ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåËøô‰∫õÈÉΩÊòØÈùûÂ∏∏Âº∫Â§ßÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÂÆÉ‰ª¨ÊúâÂæàÂ§öÂèÇÊï∞ÔºåËøô‰∫õÂèÇÊï∞ÂèØ‰ª•ÊãüÂêàÈùûÂ∏∏Â§çÊùÇÁöÑÂáΩÊï∞ÔºåÂõ†Ê≠§ÊàëË¶ÅË∞ÉÁî®Ëøô‰∫õÔºåÊàëÂ∞ÜÊääËøô‰∫õÁÆóÊ≥ïÊÉ≥Ë±°Êàê‰ΩéÂÅèÂ∑ÆÁÆóÊ≥ïÔºåÂõ†‰∏∫Êàë‰ª¨ËÉΩÂ§üÊãüÂêàÈùûÂ∏∏Â§çÊùÇÁöÑÂáΩÊï∞ÔºåËÄå‰∏îÂõ†‰∏∫Êàë‰ª¨ÊúâÈùûÂ∏∏Âº∫Â§ßÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåËøô‰∫õÂ≠¶‰π†ÁÆóÊ≥ïËÉΩÂ§üÊãüÂêàÈùûÂ∏∏Â§çÊùÇÁöÑÂáΩÊï∞„ÄÇÂæàÊúâÂèØËÉΩÔºåÂ¶ÇÊûúÊàë‰ª¨Áî®Ëøô‰∫õÊï∞ÊçÆËøêË°åËøô‰∫õÁÆóÊ≥ïÔºåËøôÁßçÁÆóÊ≥ïËÉΩÂæàÂ•ΩÂú∞ÊãüÂêàËÆ≠ÁªÉÈõÜÔºåÂõ†Ê≠§ÔºåËÆ≠ÁªÉËØØÂ∑ÆÂ∞±‰ºöÂæà‰Ωé‰∫Ü„ÄÇ ‚Äã Áé∞Âú®ÂÅáËÆæÊàë‰ª¨‰ΩøÁî®‰∫ÜÈùûÂ∏∏ÈùûÂ∏∏Â§ßÁöÑËÆ≠ÁªÉÈõÜÔºåÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂ∞ΩÁÆ°Êàë‰ª¨Â∏åÊúõÊúâÂæàÂ§öÂèÇÊï∞Ôºå‰ΩÜÊòØÂ¶ÇÊûúËÆ≠ÁªÉÈõÜÊØîÂèÇÊï∞ÁöÑÊï∞ÈáèËøòÂ§ßÔºåÁîöËá≥ÊòØÊõ¥Â§öÔºåÈÇ£‰πàËøô‰∫õÁÆóÊ≥ïÂ∞±‰∏çÂ§™ÂèØËÉΩ‰ºöËøáÂ∫¶ÊãüÂêà„ÄÇ‰πüÂ∞±ÊòØËØ¥ËÆ≠ÁªÉËØØÂ∑ÆÊúâÂ∏åÊúõÊé•ËøëÊµãËØïËØØÂ∑Æ„ÄÇ ‚Äã Âè¶‰∏ÄÁßçËÄÉËôëËøô‰∏™ÈóÆÈ¢òÁöÑËßíÂ∫¶ÊòØ‰∏∫‰∫ÜÊúâ‰∏Ä‰∏™È´òÊÄßËÉΩÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊàë‰ª¨Â∏åÊúõÂÆÉ‰∏çË¶ÅÊúâÈ´òÁöÑÂÅèÂ∑ÆÂíåÊñπÂ∑Æ„ÄÇ ‚Äã Âõ†Ê≠§ÂÅèÂ∑ÆÈóÆÈ¢òÔºåÊàë‰πàÂ∞ÜÈÄöËøáÁ°Æ‰øùÊúâ‰∏Ä‰∏™ÂÖ∑ÊúâÂæàÂ§öÂèÇÊï∞ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÊù•Ëß£ÂÜ≥Ôºå‰ª•‰æøÊàë‰ª¨ËÉΩÂ§üÂæóÂà∞‰∏Ä‰∏™ËæÉ‰ΩéÂÅèÂ∑ÆÁöÑÁÆóÊ≥ïÔºåÂπ∂‰∏îÈÄöËøáÁî®ÈùûÂ∏∏Â§ßÁöÑËÆ≠ÁªÉÈõÜÊù•‰øùËØÅ„ÄÇ ‚Äã Êàë‰ª¨Âú®Ê≠§Ê≤°ÊúâÊñπÂ∑ÆÈóÆÈ¢òÔºåÊàë‰ª¨ÁöÑÁÆóÊ≥ïÂ∞ÜÊ≤°ÊúâÊñπÂ∑ÆÔºåÂπ∂‰∏îÈÄöËøáÂ∞ÜËøô‰∏§‰∏™ÂÄºÊîæÂú®‰∏ÄËµ∑ÔºåÊàë‰ª¨ÊúÄÁªàÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™‰ΩéËØØÂ∑ÆÂíå‰ΩéÊñπÂ∑ÆÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇËøô‰ΩøÂæóÊàë‰ª¨ËÉΩÂ§üÂæàÂ•ΩÂú∞ÊµãËØïÊµãËØïÊï∞ÊçÆÈõÜ„ÄÇ‰ªéÊ†πÊú¨‰∏äÊù•ËØ¥ÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑÂÅáËÆæÔºöÁâπÂæÅÂÄºÊúâË∂≥Â§üÁöÑ‰ø°ÊÅØÈáèÔºå‰∏îÊàë‰ª¨Êúâ‰∏ÄÁ±ªÂæàÂ•ΩÁöÑÂáΩÊï∞ÔºåËøôÊòØ‰∏∫‰ªÄ‰πàËÉΩ‰øùËØÅ‰ΩéËØØÂ∑ÆÁöÑÂÖ≥ÈîÆÊâÄÂú®„ÄÇÂÆÉÊúâÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåËøôËÉΩ‰øùËØÅÂæóÂà∞Êõ¥Â§öÁöÑÊñπÂ∑ÆÂÄºÔºåÂõ†Ê≠§ËøôÁªôÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∫õÂèØËÉΩÁöÑÊù°‰ª∂ÔºåÂ¶ÇÊûú‰Ω†ÊúâÂ§ßÈáèÁöÑÊï∞ÊçÆÔºåËÄå‰∏î‰Ω†ËÆ≠ÁªÉ‰∫Ü‰∏ÄÁßçÂ∏¶ÊúâÂæàÂ§öÂèÇÊï∞ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÈÇ£‰πàËøôÂ∞Ü‰ºöÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÊñπÂºèÔºåÊù•Êèê‰æõ‰∏Ä‰∏™È´òÊÄßËÉΩÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇ ‚Äã ÊàëËßâÂæóÂÖ≥ÈîÆÁöÑÊµãËØïÔºöÈ¶ñÂÖàÔºå‰∏Ä‰∏™‰∫∫Á±ª‰∏ìÂÆ∂ÁúãÂà∞‰∫ÜÁâπÂæÅÂÄº $x$ÔºåËÉΩÂæàÊúâ‰ø°ÂøÉÁöÑÈ¢ÑÊµãÂá∫$y$ÂÄºÂêóÔºüÂõ†‰∏∫ËøôÂèØ‰ª•ËØÅÊòé $ y$ ÂèØ‰ª•Ê†πÊçÆÁâπÂæÅÂÄº$x$Ë¢´ÂáÜÁ°ÆÂú∞È¢ÑÊµãÂá∫Êù•„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÂÆûÈôÖ‰∏äËÉΩÂæóÂà∞‰∏ÄÁªÑÂ∫ûÂ§ßÁöÑËÆ≠ÁªÉÈõÜÔºåÂπ∂‰∏îÂú®Ëøô‰∏™ËÆ≠ÁªÉÈõÜ‰∏≠ËÆ≠ÁªÉ‰∏Ä‰∏™ÊúâÂæàÂ§öÂèÇÊï∞ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂêóÔºüÂ¶ÇÊûú‰Ω†‰∏çËÉΩÂÅöÂà∞Ëøô‰∏§ËÄÖÔºåÈÇ£‰πàÊõ¥Â§öÊó∂ÂÄôÔºå‰Ω†‰ºöÂæóÂà∞‰∏Ä‰∏™ÊÄßËÉΩÂæàÂ•ΩÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[„ÄêËΩ¨„ÄëÁ•ûÁªèÁΩëÁªúÊµÖËÆ≤Ôºö‰ªéÁ•ûÁªèÂÖÉÂà∞Ê∑±Â∫¶Â≠¶‰π†]]></title>
    <url>%2F2018%2F05%2F30%2F%E3%80%90%E8%BD%AC%E3%80%91%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B5%85%E8%AE%B2%EF%BC%9A%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%85%83%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[ËøôÂèàÊòØÊàëÂ∏∏ÁúãÁöÑÂ§ßÁ•ûÂÜôÁöÑ‰∏ÄÁØáÂçöÂÆ¢Ôºå‰ªéÊúÄÂàùÁöÑ‰ªéÊú∫Âô®Â≠¶‰π†Ë∞àËµ∑‰ΩøÊàëÂÖ•Èó®Êú∫Âô®Â≠¶‰π†ÔºåÂà∞Áé∞Âú®Â≠¶Âà∞‰∫ÜÁ•ûÁªèÁΩëÁªúÔºåÂèàÊâæÂà∞‰∫Ü‰ªñÁöÑÂçöÂÆ¢ÔºåÂ∏åÊúõÂØπÊàëÂ≠¶‰π†Á•ûÁªèÁΩëÁªúÊúâÊâÄÂ∏ÆÂä©„ÄÇ ÂéüÊñáÂú∞ÂùÄÔºöhttps://www.cnblogs.com/subconscious/p/5058741.html#first ‰ΩúËÄÖÔºöËÆ°ÁÆóÊú∫ÁöÑÊΩúÊÑèËØÜ Á•ûÁªèÁΩëÁªúÊòØ‰∏ÄÈó®ÈáçË¶ÅÁöÑÊú∫Âô®Â≠¶‰π†ÊäÄÊúØ„ÄÇÂÆÉÊòØÁõÆÂâçÊúÄ‰∏∫ÁÅ´ÁÉ≠ÁöÑÁ†îÁ©∂ÊñπÂêë‚ÄìÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂü∫Á°Ä„ÄÇÂ≠¶‰π†Á•ûÁªèÁΩëÁªú‰∏ç‰ªÖÂèØ‰ª•ËÆ©‰Ω†ÊéåÊè°‰∏ÄÈó®Âº∫Â§ßÁöÑÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºåÂêåÊó∂‰πüÂèØ‰ª•Êõ¥Â•ΩÂú∞Â∏ÆÂä©‰Ω†ÁêÜËß£Ê∑±Â∫¶Â≠¶‰π†ÊäÄÊúØ„ÄÇ Êú¨Êñá‰ª•‰∏ÄÁßçÁÆÄÂçïÁöÑÔºåÂæ™Â∫èÁöÑÊñπÂºèËÆ≤Ëß£Á•ûÁªèÁΩëÁªú„ÄÇÈÄÇÂêàÂØπÁ•ûÁªèÁΩëÁªú‰∫ÜËß£‰∏çÂ§öÁöÑÂêåÂ≠¶„ÄÇÊú¨ÊñáÂØπÈòÖËØªÊ≤°Êúâ‰∏ÄÂÆöÁöÑÂâçÊèêË¶ÅÊ±ÇÔºå‰ΩÜÊòØÊáÇ‰∏Ä‰∫õÊú∫Âô®Â≠¶‰π†Âü∫Á°Ä‰ºöÊõ¥Â•ΩÂú∞Â∏ÆÂä©ÁêÜËß£Êú¨Êñá„ÄÇ Á•ûÁªèÁΩëÁªúÊòØ‰∏ÄÁßçÊ®°Êãü‰∫∫ËÑëÁöÑÁ•ûÁªèÁΩëÁªú‰ª•ÊúüËÉΩÂ§üÂÆûÁé∞Á±ª‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú∫Âô®Â≠¶‰π†ÊäÄÊúØ„ÄÇ‰∫∫ËÑë‰∏≠ÁöÑÁ•ûÁªèÁΩëÁªúÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Â§çÊùÇÁöÑÁªÑÁªá„ÄÇÊàê‰∫∫ÁöÑÂ§ßËÑë‰∏≠‰º∞ËÆ°Êúâ1000‰∫ø‰∏™Á•ûÁªèÂÖÉ‰πãÂ§ö„ÄÇÂõæ1 ‰∫∫ËÑëÁ•ûÁªèÁΩëÁªú&nbsp; ÈÇ£‰πàÊú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÁ•ûÁªèÁΩëÁªúÊòØÂ¶Ç‰ΩïÂÆûÁé∞ËøôÁßçÊ®°ÊãüÁöÑÔºåÂπ∂‰∏îËææÂà∞‰∏Ä‰∏™ÊÉä‰∫∫ÁöÑËâØÂ•ΩÊïàÊûúÁöÑÔºüÈÄöËøáÊú¨ÊñáÔºå‰Ω†ÂèØ‰ª•‰∫ÜËß£Âà∞Ëøô‰∫õÈóÆÈ¢òÁöÑÁ≠îÊ°àÔºåÂêåÊó∂ËøòËÉΩÁü•ÈÅìÁ•ûÁªèÁΩëÁªúÁöÑÂéÜÂè≤Ôºå‰ª•ÂèäÂ¶Ç‰ΩïËæÉÂ•ΩÂú∞Â≠¶‰π†ÂÆÉ„ÄÇ Áî±‰∫éÊú¨ÊñáËæÉÈïøÔºå‰∏∫Êñπ‰æøËØªËÄÖÔºå‰ª•‰∏ãÊòØÊú¨ÊñáÁöÑÁõÆÂΩïÔºö ‰∏Ä.ÂâçË®Ä ‰∫å.Á•ûÁªèÂÖÉ ‰∏â.ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÊÑüÁü•Âô®Ôºâ Âõõ.‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàÂ§öÂ±ÇÊÑüÁü•Âô®Ôºâ ‰∫î.Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÊ∑±Â∫¶Â≠¶‰π†Ôºâ ÂÖ≠.ÂõûÈ°æ ‰∏É.Â±ïÊúõ ÂÖ´.ÊÄªÁªì ‰πù.ÂêéËÆ∞ ÂçÅ.Â§áÊ≥®&nbsp;‰∏Ä. ÂâçË®Ä ËÆ©Êàë‰ª¨Êù•Áúã‰∏Ä‰∏™ÁªèÂÖ∏ÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇËøôÊòØ‰∏Ä‰∏™ÂåÖÂê´‰∏â‰∏™Â±ÇÊ¨°ÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇÁ∫¢Ëâ≤ÁöÑÊòØËæìÂÖ•Â±ÇÔºåÁªøËâ≤ÁöÑÊòØËæìÂá∫Â±ÇÔºåÁ¥´Ëâ≤ÁöÑÊòØ‰∏≠Èó¥Â±ÇÔºà‰πüÂè´ÈöêËóèÂ±ÇÔºâ„ÄÇËæìÂÖ•Â±ÇÊúâ3‰∏™ËæìÂÖ•ÂçïÂÖÉÔºåÈöêËóèÂ±ÇÊúâ4‰∏™ÂçïÂÖÉÔºåËæìÂá∫Â±ÇÊúâ2‰∏™ÂçïÂÖÉ„ÄÇÂêéÊñá‰∏≠ÔºåÊàë‰ª¨Áªü‰∏Ä‰ΩøÁî®ËøôÁßçÈ¢úËâ≤Êù•Ë°®ËææÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑ„ÄÇÂõæ2 Á•ûÁªèÁΩëÁªúÁªìÊûÑÂõæ&nbsp; Âú®ÂºÄÂßã‰ªãÁªçÂâçÔºåÊúâ‰∏Ä‰∫õÁü•ËØÜÂèØ‰ª•ÂÖàËÆ∞Âú®ÂøÉÈáåÔºöËÆæËÆ°‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊó∂ÔºåËæìÂÖ•Â±Ç‰∏éËæìÂá∫Â±ÇÁöÑËäÇÁÇπÊï∞ÂæÄÂæÄÊòØÂõ∫ÂÆöÁöÑÔºå‰∏≠Èó¥Â±ÇÂàôÂèØ‰ª•Ëá™Áî±ÊåáÂÆöÔºõÁ•ûÁªèÁΩëÁªúÁªìÊûÑÂõæ‰∏≠ÁöÑÊãìÊâë‰∏éÁÆ≠Â§¥‰ª£Ë°®ÁùÄÈ¢ÑÊµãËøáÁ®ãÊó∂Êï∞ÊçÆÁöÑÊµÅÂêëÔºåË∑üËÆ≠ÁªÉÊó∂ÁöÑÊï∞ÊçÆÊµÅÊúâ‰∏ÄÂÆöÁöÑÂå∫Âà´ÔºõÁªìÊûÑÂõæÈáåÁöÑÂÖ≥ÈîÆ‰∏çÊòØÂúÜÂúàÔºà‰ª£Ë°®‚ÄúÁ•ûÁªèÂÖÉ‚ÄùÔºâÔºåËÄåÊòØËøûÊé•Á∫øÔºà‰ª£Ë°®‚ÄúÁ•ûÁªèÂÖÉ‚Äù‰πãÈó¥ÁöÑËøûÊé•Ôºâ„ÄÇÊØè‰∏™ËøûÊé•Á∫øÂØπÂ∫î‰∏Ä‰∏™‰∏çÂêåÁöÑÊùÉÈáçÔºàÂÖ∂ÂÄºÁß∞‰∏∫ÊùÉÂÄºÔºâÔºåËøôÊòØÈúÄË¶ÅËÆ≠ÁªÉÂæóÂà∞ÁöÑ„ÄÇ&nbsp;&nbsp; Èô§‰∫Ü‰ªéÂ∑¶Âà∞Âè≥ÁöÑÂΩ¢ÂºèË°®ËææÁöÑÁªìÊûÑÂõæÔºåËøòÊúâ‰∏ÄÁßçÂ∏∏ËßÅÁöÑË°®ËææÂΩ¢ÂºèÊòØ‰ªé‰∏ãÂà∞‰∏äÊù•Ë°®Á§∫‰∏Ä‰∏™Á•ûÁªèÁΩëÁªú„ÄÇËøôÊó∂ÂÄôÔºåËæìÂÖ•Â±ÇÂú®ÂõæÁöÑÊúÄ‰∏ãÊñπ„ÄÇËæìÂá∫Â±ÇÂàôÂú®ÂõæÁöÑÊúÄ‰∏äÊñπÔºåÂ¶Ç‰∏ãÂõæÔºöÂõæ3&nbsp;‰ªé‰∏ãÂà∞‰∏äÁöÑÁ•ûÁªèÁΩëÁªúÁªìÊûÑÂõæ&nbsp;&nbsp; ‰ªéÂ∑¶Âà∞Âè≥ÁöÑË°®ËææÂΩ¢Âºè‰ª•Andrew&nbsp;NgÂíåLeCunÁöÑÊñáÁåÆ‰ΩøÁî®ËæÉÂ§öÔºåCaffeÈáå‰ΩøÁî®ÁöÑÂàôÊòØ‰ªé‰∏ãÂà∞‰∏äÁöÑË°®Ëææ„ÄÇÂú®Êú¨Êñá‰∏≠‰ΩøÁî®Andrew&nbsp;Ng‰ª£Ë°®ÁöÑ‰ªéÂ∑¶Âà∞Âè≥ÁöÑË°®ËææÂΩ¢Âºè„ÄÇ ‰∏ãÈù¢‰ªéÁÆÄÂçïÁöÑÁ•ûÁªèÂÖÉÂºÄÂßãËØ¥Ëµ∑Ôºå‰∏ÄÊ≠•‰∏ÄÊ≠•‰ªãÁªçÁ•ûÁªèÁΩëÁªúÂ§çÊùÇÁªìÊûÑÁöÑÂΩ¢Êàê„ÄÇ&nbsp;‰∫å.&nbsp;Á•ûÁªèÂÖÉ 1.ÂºïÂ≠ê ÂØπ‰∫éÁ•ûÁªèÂÖÉÁöÑÁ†îÁ©∂Áî±Êù•Â∑≤‰πÖÔºå1904Âπ¥ÁîüÁâ©Â≠¶ÂÆ∂Â∞±Â∑≤ÁªèÁü•Êôì‰∫ÜÁ•ûÁªèÂÖÉÁöÑÁªÑÊàêÁªìÊûÑ„ÄÇ ‰∏Ä‰∏™Á•ûÁªèÂÖÉÈÄöÂ∏∏ÂÖ∑ÊúâÂ§ö‰∏™Ê†ëÁ™ÅÔºå‰∏ªË¶ÅÁî®Êù•Êé•Âèó‰º†ÂÖ•‰ø°ÊÅØÔºõËÄåËΩ¥Á™ÅÂè™Êúâ‰∏ÄÊù°ÔºåËΩ¥Á™ÅÂ∞æÁ´ØÊúâËÆ∏Â§öËΩ¥Á™ÅÊú´Ê¢¢ÂèØ‰ª•ÁªôÂÖ∂‰ªñÂ§ö‰∏™Á•ûÁªèÂÖÉ‰º†ÈÄí‰ø°ÊÅØ„ÄÇËΩ¥Á™ÅÊú´Ê¢¢Ë∑üÂÖ∂‰ªñÁ•ûÁªèÂÖÉÁöÑÊ†ëÁ™Å‰∫ßÁîüËøûÊé•Ôºå‰ªéËÄå‰º†ÈÄí‰ø°Âè∑„ÄÇËøô‰∏™ËøûÊé•ÁöÑ‰ΩçÁΩÆÂú®ÁîüÁâ©Â≠¶‰∏äÂè´ÂÅö‚ÄúÁ™ÅËß¶‚Äù„ÄÇ ‰∫∫ËÑë‰∏≠ÁöÑÁ•ûÁªèÂÖÉÂΩ¢Áä∂ÂèØ‰ª•Áî®‰∏ãÂõæÂÅöÁÆÄÂçïÁöÑËØ¥ÊòéÔºöÂõæ4 Á•ûÁªèÂÖÉ&nbsp;&nbsp; 1943Âπ¥ÔºåÂøÉÁêÜÂ≠¶ÂÆ∂McCullochÂíåÊï∞Â≠¶ÂÆ∂PittsÂèÇËÄÉ‰∫ÜÁîüÁâ©Á•ûÁªèÂÖÉÁöÑÁªìÊûÑÔºåÂèëË°®‰∫ÜÊäΩË±°ÁöÑÁ•ûÁªèÂÖÉÊ®°ÂûãMP„ÄÇÂú®‰∏ãÊñá‰∏≠ÔºåÊàë‰ª¨‰ºöÂÖ∑‰Ωì‰ªãÁªçÁ•ûÁªèÂÖÉÊ®°Âûã„ÄÇ&nbsp;&nbsp;&nbsp;Âõæ5 Warren McCullochÔºàÂ∑¶ÔºâÂíå&nbsp;Walter PittsÔºàÂè≥Ôºâ&nbsp;&nbsp; 2.ÁªìÊûÑ&nbsp; Á•ûÁªèÂÖÉÊ®°ÂûãÊòØ‰∏Ä‰∏™ÂåÖÂê´ËæìÂÖ•ÔºåËæìÂá∫‰∏éËÆ°ÁÆóÂäüËÉΩÁöÑÊ®°Âûã„ÄÇËæìÂÖ•ÂèØ‰ª•Á±ªÊØî‰∏∫Á•ûÁªèÂÖÉÁöÑÊ†ëÁ™ÅÔºåËÄåËæìÂá∫ÂèØ‰ª•Á±ªÊØî‰∏∫Á•ûÁªèÂÖÉÁöÑËΩ¥Á™ÅÔºåËÆ°ÁÆóÂàôÂèØ‰ª•Á±ªÊØî‰∏∫ÁªÜËÉûÊ†∏„ÄÇ ‰∏ãÂõæÊòØ‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑÁ•ûÁªèÂÖÉÊ®°ÂûãÔºöÂåÖÂê´Êúâ3‰∏™ËæìÂÖ•Ôºå1‰∏™ËæìÂá∫Ôºå‰ª•Âèä2‰∏™ËÆ°ÁÆóÂäüËÉΩ„ÄÇ Ê≥®ÊÑè‰∏≠Èó¥ÁöÑÁÆ≠Â§¥Á∫ø„ÄÇËøô‰∫õÁ∫øÁß∞‰∏∫‚ÄúËøûÊé•‚Äù„ÄÇÊØè‰∏™‰∏äÊúâ‰∏Ä‰∏™‚ÄúÊùÉÂÄº‚Äù„ÄÇÂõæ6 Á•ûÁªèÂÖÉÊ®°Âûã&nbsp;&nbsp; ËøûÊé•ÊòØÁ•ûÁªèÂÖÉ‰∏≠ÊúÄÈáçË¶ÅÁöÑ‰∏úË•ø„ÄÇÊØè‰∏Ä‰∏™ËøûÊé•‰∏äÈÉΩÊúâ‰∏Ä‰∏™ÊùÉÈáç„ÄÇ ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉÁÆóÊ≥ïÂ∞±ÊòØËÆ©ÊùÉÈáçÁöÑÂÄºË∞ÉÊï¥Âà∞ÊúÄ‰Ω≥Ôºå‰ª•‰ΩøÂæóÊï¥‰∏™ÁΩëÁªúÁöÑÈ¢ÑÊµãÊïàÊûúÊúÄÂ•Ω„ÄÇ Êàë‰ª¨‰ΩøÁî®aÊù•Ë°®Á§∫ËæìÂÖ•ÔºåÁî®wÊù•Ë°®Á§∫ÊùÉÂÄº„ÄÇ‰∏Ä‰∏™Ë°®Á§∫ËøûÊé•ÁöÑÊúâÂêëÁÆ≠Â§¥ÂèØ‰ª•ËøôÊ†∑ÁêÜËß£ÔºöÂú®ÂàùÁ´ØÔºå‰º†ÈÄíÁöÑ‰ø°Âè∑Â§ßÂ∞è‰ªçÁÑ∂ÊòØaÔºåÁ´Ø‰∏≠Èó¥ÊúâÂä†ÊùÉÂèÇÊï∞wÔºåÁªèËøáËøô‰∏™Âä†ÊùÉÂêéÁöÑ‰ø°Âè∑‰ºöÂèòÊàêawÔºåÂõ†Ê≠§Âú®ËøûÊé•ÁöÑÊú´Á´ØÔºå‰ø°Âè∑ÁöÑÂ§ßÂ∞èÂ∞±ÂèòÊàê‰∫Üaw„ÄÇ Âú®ÂÖ∂‰ªñÁªòÂõæÊ®°ÂûãÈáåÔºåÊúâÂêëÁÆ≠Â§¥ÂèØËÉΩË°®Á§∫ÁöÑÊòØÂÄºÁöÑ‰∏çÂèò‰º†ÈÄí„ÄÇËÄåÂú®Á•ûÁªèÂÖÉÊ®°ÂûãÈáåÔºåÊØè‰∏™ÊúâÂêëÁÆ≠Â§¥Ë°®Á§∫ÁöÑÊòØÂÄºÁöÑÂä†ÊùÉ‰º†ÈÄí„ÄÇÂõæ7 ËøûÊé•ÔºàconnectionÔºâ&nbsp;&nbsp;&nbsp; Â¶ÇÊûúÊàë‰ª¨Â∞ÜÁ•ûÁªèÂÖÉÂõæ‰∏≠ÁöÑÊâÄÊúâÂèòÈáèÁî®Á¨¶Âè∑Ë°®Á§∫ÔºåÂπ∂‰∏îÂÜôÂá∫ËæìÂá∫ÁöÑËÆ°ÁÆóÂÖ¨ÂºèÁöÑËØùÔºåÂ∞±ÊòØ‰∏ãÂõæ„ÄÇÂõæ8 Á•ûÁªèÂÖÉËÆ°ÁÆó&nbsp;&nbsp;&nbsp; ÂèØËßÅzÊòØÂú®ËæìÂÖ•ÂíåÊùÉÂÄºÁöÑÁ∫øÊÄßÂä†ÊùÉÂíåÂè†Âä†‰∫Ü‰∏Ä‰∏™ÂáΩÊï∞gÁöÑÂÄº„ÄÇÂú®MPÊ®°ÂûãÈáåÔºåÂáΩÊï∞gÊòØsgnÂáΩÊï∞Ôºå‰πüÂ∞±ÊòØÂèñÁ¨¶Âè∑ÂáΩÊï∞„ÄÇËøô‰∏™ÂáΩÊï∞ÂΩìËæìÂÖ•Â§ß‰∫é0Êó∂ÔºåËæìÂá∫1ÔºåÂê¶ÂàôËæìÂá∫0„ÄÇ ‰∏ãÈù¢ÂØπÁ•ûÁªèÂÖÉÊ®°ÂûãÁöÑÂõæËøõË°å‰∏Ä‰∫õÊâ©Â±ï„ÄÇÈ¶ñÂÖàÂ∞ÜsumÂáΩÊï∞‰∏ésgnÂáΩÊï∞ÂêàÂπ∂Âà∞‰∏Ä‰∏™ÂúÜÂúàÈáåÔºå‰ª£Ë°®Á•ûÁªèÂÖÉÁöÑÂÜÖÈÉ®ËÆ°ÁÆó„ÄÇÂÖ∂Ê¨°ÔºåÊääËæìÂÖ•a‰∏éËæìÂá∫zÂÜôÂà∞ËøûÊé•Á∫øÁöÑÂ∑¶‰∏äÊñπÔºå‰æø‰∫éÂêéÈù¢ÁîªÂ§çÊùÇÁöÑÁΩëÁªú„ÄÇÊúÄÂêéËØ¥ÊòéÔºå‰∏Ä‰∏™Á•ûÁªèÂÖÉÂèØ‰ª•ÂºïÂá∫Â§ö‰∏™‰ª£Ë°®ËæìÂá∫ÁöÑÊúâÂêëÁÆ≠Â§¥Ôºå‰ΩÜÂÄºÈÉΩÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇ Á•ûÁªèÂÖÉÂèØ‰ª•Áúã‰Ωú‰∏Ä‰∏™ËÆ°ÁÆó‰∏éÂ≠òÂÇ®ÂçïÂÖÉ„ÄÇËÆ°ÁÆóÊòØÁ•ûÁªèÂÖÉÂØπÂÖ∂ÁöÑËæìÂÖ•ËøõË°åËÆ°ÁÆóÂäüËÉΩ„ÄÇÂ≠òÂÇ®ÊòØÁ•ûÁªèÂÖÉ‰ºöÊöÇÂ≠òËÆ°ÁÆóÁªìÊûúÔºåÂπ∂‰º†ÈÄíÂà∞‰∏ã‰∏ÄÂ±Ç„ÄÇÂõæ9 Á•ûÁªèÂÖÉÊâ©Â±ï&nbsp;&nbsp; ÂΩìÊàë‰ª¨Áî®‚ÄúÁ•ûÁªèÂÖÉ‚ÄùÁªÑÊàêÁΩëÁªú‰ª•ÂêéÔºåÊèèËø∞ÁΩëÁªú‰∏≠ÁöÑÊüê‰∏™‚ÄúÁ•ûÁªèÂÖÉ‚ÄùÊó∂ÔºåÊàë‰ª¨Êõ¥Â§öÂú∞‰ºöÁî®‚ÄúÂçïÂÖÉ‚ÄùÔºàunitÔºâÊù•Êåá‰ª£„ÄÇÂêåÊó∂Áî±‰∫éÁ•ûÁªèÁΩëÁªúÁöÑË°®Áé∞ÂΩ¢ÂºèÊòØ‰∏Ä‰∏™ÊúâÂêëÂõæÔºåÊúâÊó∂‰πü‰ºöÁî®‚ÄúËäÇÁÇπ‚ÄùÔºànodeÔºâÊù•Ë°®ËææÂêåÊ†∑ÁöÑÊÑèÊÄù„ÄÇ&nbsp; 3.ÊïàÊûú&nbsp; Á•ûÁªèÂÖÉÊ®°ÂûãÁöÑ‰ΩøÁî®ÂèØ‰ª•ËøôÊ†∑ÁêÜËß£Ôºö Êàë‰ª¨Êúâ‰∏Ä‰∏™Êï∞ÊçÆÔºåÁß∞‰πã‰∏∫Ê†∑Êú¨„ÄÇÊ†∑Êú¨ÊúâÂõõ‰∏™Â±ûÊÄßÔºåÂÖ∂‰∏≠‰∏â‰∏™Â±ûÊÄßÂ∑≤Áü•Ôºå‰∏Ä‰∏™Â±ûÊÄßÊú™Áü•„ÄÇÊàë‰ª¨ÈúÄË¶ÅÂÅöÁöÑÂ∞±ÊòØÈÄöËøá‰∏â‰∏™Â∑≤Áü•Â±ûÊÄßÈ¢ÑÊµãÊú™Áü•Â±ûÊÄß„ÄÇ ÂÖ∑‰ΩìÂäûÊ≥ïÂ∞±ÊòØ‰ΩøÁî®Á•ûÁªèÂÖÉÁöÑÂÖ¨ÂºèËøõË°åËÆ°ÁÆó„ÄÇ‰∏â‰∏™Â∑≤Áü•Â±ûÊÄßÁöÑÂÄºÊòØa1Ôºåa2Ôºåa3ÔºåÊú™Áü•Â±ûÊÄßÁöÑÂÄºÊòØz„ÄÇzÂèØ‰ª•ÈÄöËøáÂÖ¨ÂºèËÆ°ÁÆóÂá∫Êù•„ÄÇ ËøôÈáåÔºåÂ∑≤Áü•ÁöÑÂ±ûÊÄßÁß∞‰πã‰∏∫ÁâπÂæÅÔºåÊú™Áü•ÁöÑÂ±ûÊÄßÁß∞‰πã‰∏∫ÁõÆÊ†á„ÄÇÂÅáËÆæÁâπÂæÅ‰∏éÁõÆÊ†á‰πãÈó¥Á°ÆÂÆûÊòØÁ∫øÊÄßÂÖ≥Á≥ªÔºåÂπ∂‰∏îÊàë‰ª¨Â∑≤ÁªèÂæóÂà∞Ë°®Á§∫Ëøô‰∏™ÂÖ≥Á≥ªÁöÑÊùÉÂÄºw1Ôºåw2Ôºåw3„ÄÇÈÇ£‰πàÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÈÄöËøáÁ•ûÁªèÂÖÉÊ®°ÂûãÈ¢ÑÊµãÊñ∞Ê†∑Êú¨ÁöÑÁõÆÊ†á„ÄÇ 4.ÂΩ±Âìç 1943Âπ¥ÂèëÂ∏ÉÁöÑMPÊ®°ÂûãÔºåËôΩÁÑ∂ÁÆÄÂçïÔºå‰ΩÜÂ∑≤ÁªèÂª∫Á´ã‰∫ÜÁ•ûÁªèÁΩëÁªúÂ§ßÂé¶ÁöÑÂú∞Âü∫„ÄÇ‰ΩÜÊòØÔºåMPÊ®°Âûã‰∏≠ÔºåÊùÉÈáçÁöÑÂÄºÈÉΩÊòØÈ¢ÑÂÖàËÆæÁΩÆÁöÑÔºåÂõ†Ê≠§‰∏çËÉΩÂ≠¶‰π†„ÄÇ 1949Âπ¥ÂøÉÁêÜÂ≠¶ÂÆ∂HebbÊèêÂá∫‰∫ÜHebbÂ≠¶‰π†ÁéáÔºåËÆ§‰∏∫‰∫∫ËÑëÁ•ûÁªèÁªÜËÉûÁöÑÁ™ÅËß¶Ôºà‰πüÂ∞±ÊòØËøûÊé•Ôºâ‰∏äÁöÑÂº∫Â∫¶‰∏äÂèØ‰ª•ÂèòÂåñÁöÑ„ÄÇ‰∫éÊòØËÆ°ÁÆóÁßëÂ≠¶ÂÆ∂‰ª¨ÂºÄÂßãËÄÉËôëÁî®Ë∞ÉÊï¥ÊùÉÂÄºÁöÑÊñπÊ≥ïÊù•ËÆ©Êú∫Âô®Â≠¶‰π†„ÄÇËøô‰∏∫ÂêéÈù¢ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á°Ä„ÄÇÂõæ10 Donald Olding Hebb&nbsp;&nbsp; Â∞ΩÁÆ°Á•ûÁªèÂÖÉÊ®°Âûã‰∏éHebbÂ≠¶‰π†ÂæãÈÉΩÂ∑≤ËØûÁîüÔºå‰ΩÜÈôê‰∫éÂΩìÊó∂ÁöÑËÆ°ÁÆóÊú∫ËÉΩÂäõÔºåÁõ¥Âà∞Êé•Ëøë10Âπ¥ÂêéÔºåÁ¨¨‰∏Ä‰∏™ÁúüÊ≠£ÊÑè‰πâÁöÑÁ•ûÁªèÁΩëÁªúÊâçËØûÁîü„ÄÇ&nbsp;‰∏â. ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÊÑüÁü•Âô®Ôºâ 1.ÂºïÂ≠ê 1958Âπ¥ÔºåËÆ°ÁÆóÁßëÂ≠¶ÂÆ∂RosenblattÊèêÂá∫‰∫ÜÁî±‰∏§Â±ÇÁ•ûÁªèÂÖÉÁªÑÊàêÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇ‰ªñÁªôÂÆÉËµ∑‰∫Ü‰∏Ä‰∏™ÂêçÂ≠ó‚Äì‚ÄúÊÑüÁü•Âô®‚ÄùÔºàPerceptronÔºâÔºàÊúâÁöÑÊñáÁåÆÁøªËØëÊàê‚ÄúÊÑüÁü•Êú∫‚ÄùÔºå‰∏ãÊñáÁªü‰∏ÄÁî®‚ÄúÊÑüÁü•Âô®‚ÄùÊù•Êåá‰ª£Ôºâ„ÄÇ ÊÑüÁü•Âô®ÊòØÂΩìÊó∂È¶ñ‰∏™ÂèØ‰ª•Â≠¶‰π†ÁöÑ‰∫∫Â∑•Á•ûÁªèÁΩëÁªú„ÄÇRosenblattÁé∞Âú∫ÊºîÁ§∫‰∫ÜÂÖ∂Â≠¶‰π†ËØÜÂà´ÁÆÄÂçïÂõæÂÉèÁöÑËøáÁ®ãÔºåÂú®ÂΩìÊó∂ÁöÑÁ§æ‰ºöÂºïËµ∑‰∫ÜËΩ∞Âä®„ÄÇ ‰∫∫‰ª¨ËÆ§‰∏∫Â∑≤ÁªèÂèëÁé∞‰∫ÜÊô∫ËÉΩÁöÑÂ••ÁßòÔºåËÆ∏Â§öÂ≠¶ËÄÖÂíåÁßëÁ†îÊú∫ÊûÑÁ∫∑Á∫∑ÊäïÂÖ•Âà∞Á•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂‰∏≠„ÄÇÁæéÂõΩÂÜõÊñπÂ§ßÂäõËµÑÂä©‰∫ÜÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂ÔºåÂπ∂ËÆ§‰∏∫Á•ûÁªèÁΩëÁªúÊØî‚ÄúÂéüÂ≠êÂºπÂ∑•Á®ã‚ÄùÊõ¥ÈáçË¶Å„ÄÇËøôÊÆµÊó∂Èó¥Áõ¥Âà∞1969Âπ¥ÊâçÁªìÊùüÔºåËøô‰∏™Êó∂ÊúüÂèØ‰ª•Áúã‰ΩúÁ•ûÁªèÁΩëÁªúÁöÑÁ¨¨‰∏ÄÊ¨°È´òÊΩÆ„ÄÇÂõæ11 Rosenblat‰∏éÊÑüÁü•Âô®&nbsp; 2.ÁªìÊûÑ ‰∏ãÈù¢Êù•ËØ¥ÊòéÊÑüÁü•Âô®Ê®°Âûã„ÄÇ Âú®ÂéüÊù•MPÊ®°ÂûãÁöÑ‚ÄúËæìÂÖ•‚Äù‰ΩçÁΩÆÊ∑ªÂä†Á•ûÁªèÂÖÉËäÇÁÇπÔºåÊ†áÂøóÂÖ∂‰∏∫‚ÄúËæìÂÖ•ÂçïÂÖÉ‚Äù„ÄÇÂÖ∂‰Ωô‰∏çÂèòÔºå‰∫éÊòØÊàë‰ª¨Â∞±Êúâ‰∫Ü‰∏ãÂõæÔºö‰ªéÊú¨ÂõæÂºÄÂßãÔºåÊàë‰ª¨Â∞ÜÊùÉÂÄºw1, w2, w3ÂÜôÂà∞‚ÄúËøûÊé•Á∫ø‚ÄùÁöÑ‰∏≠Èó¥„ÄÇÂõæ12 ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú&nbsp;&nbsp; Âú®‚ÄúÊÑüÁü•Âô®‚Äù‰∏≠ÔºåÊúâ‰∏§‰∏™Â±ÇÊ¨°„ÄÇÂàÜÂà´ÊòØËæìÂÖ•Â±ÇÂíåËæìÂá∫Â±Ç„ÄÇËæìÂÖ•Â±ÇÈáåÁöÑ‚ÄúËæìÂÖ•ÂçïÂÖÉ‚ÄùÂè™Ë¥üË¥£‰º†ËæìÊï∞ÊçÆÔºå‰∏çÂÅöËÆ°ÁÆó„ÄÇËæìÂá∫Â±ÇÈáåÁöÑ‚ÄúËæìÂá∫ÂçïÂÖÉ‚ÄùÂàôÈúÄË¶ÅÂØπÂâçÈù¢‰∏ÄÂ±ÇÁöÑËæìÂÖ•ËøõË°åËÆ°ÁÆó„ÄÇ Êàë‰ª¨ÊääÈúÄË¶ÅËÆ°ÁÆóÁöÑÂ±ÇÊ¨°Áß∞‰πã‰∏∫‚ÄúËÆ°ÁÆóÂ±Ç‚ÄùÔºåÂπ∂ÊääÊã•Êúâ‰∏Ä‰∏™ËÆ°ÁÆóÂ±ÇÁöÑÁΩëÁªúÁß∞‰πã‰∏∫‚ÄúÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú‚Äù„ÄÇÊúâ‰∏Ä‰∫õÊñáÁåÆ‰ºöÊåâÁÖßÁΩëÁªúÊã•ÊúâÁöÑÂ±ÇÊï∞Êù•ÂëΩÂêçÔºå‰æãÂ¶ÇÊää‚ÄúÊÑüÁü•Âô®‚ÄùÁß∞‰∏∫‰∏§Â±ÇÁ•ûÁªèÁΩëÁªú„ÄÇ‰ΩÜÂú®Êú¨ÊñáÈáåÔºåÊàë‰ª¨Ê†πÊçÆËÆ°ÁÆóÂ±ÇÁöÑÊï∞ÈáèÊù•ÂëΩÂêç„ÄÇ ÂÅáÂ¶ÇÊàë‰ª¨Ë¶ÅÈ¢ÑÊµãÁöÑÁõÆÊ†á‰∏çÂÜçÊòØ‰∏Ä‰∏™ÂÄºÔºåËÄåÊòØ‰∏Ä‰∏™ÂêëÈáèÔºå‰æãÂ¶Ç[2,3]„ÄÇÈÇ£‰πàÂèØ‰ª•Âú®ËæìÂá∫Â±ÇÂÜçÂ¢ûÂä†‰∏Ä‰∏™‚ÄúËæìÂá∫ÂçïÂÖÉ‚Äù„ÄÇ ‰∏ãÂõæÊòæÁ§∫‰∫ÜÂ∏¶Êúâ‰∏§‰∏™ËæìÂá∫ÂçïÂÖÉÁöÑÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºåÂÖ∂‰∏≠ËæìÂá∫ÂçïÂÖÉz1ÁöÑËÆ°ÁÆóÂÖ¨ÂºèÂ¶Ç‰∏ãÂõæ„ÄÇÂõæ13 ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú(Z1)&nbsp; ÂèØ‰ª•ÁúãÂà∞Ôºåz1ÁöÑËÆ°ÁÆóË∑üÂéüÂÖàÁöÑzÂπ∂Ê≤°ÊúâÂå∫Âà´„ÄÇ Êàë‰ª¨Â∑≤Áü•‰∏Ä‰∏™Á•ûÁªèÂÖÉÁöÑËæìÂá∫ÂèØ‰ª•ÂêëÂ§ö‰∏™Á•ûÁªèÂÖÉ‰º†ÈÄíÔºåÂõ†Ê≠§z2ÁöÑËÆ°ÁÆóÂÖ¨ÂºèÂ¶Ç‰∏ãÂõæ„ÄÇÂõæ14 ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú(Z2)&nbsp; ÂèØ‰ª•ÁúãÂà∞Ôºåz2ÁöÑËÆ°ÁÆó‰∏≠Èô§‰∫Ü‰∏â‰∏™Êñ∞ÁöÑÊùÉÂÄºÔºöw4Ôºåw5Ôºåw6‰ª•Â§ñÔºåÂÖ∂‰ªñ‰∏éz1ÊòØ‰∏ÄÊ†∑ÁöÑ„ÄÇ Êï¥‰∏™ÁΩëÁªúÁöÑËæìÂá∫Â¶Ç‰∏ãÂõæ„ÄÇÂõæ15 ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú(Z1ÂíåZ2)&nbsp; ÁõÆÂâçÁöÑË°®ËææÂÖ¨ÂºèÊúâ‰∏ÄÁÇπ‰∏çËÆ©‰∫∫Êª°ÊÑèÁöÑÂ∞±ÊòØÔºöw4Ôºåw5Ôºåw6ÊòØÂêéÊù•Âä†ÁöÑÔºåÂæàÈöæË°®Áé∞Âá∫Ë∑üÂéüÂÖàÁöÑw1Ôºåw2Ôºåw3ÁöÑÂÖ≥Á≥ª„ÄÇ Âõ†Ê≠§Êàë‰ª¨ÊîπÁî®‰∫åÁª¥ÁöÑ‰∏ãÊ†áÔºåÁî®wx,yÊù•Ë°®Ëææ‰∏Ä‰∏™ÊùÉÂÄº„ÄÇ‰∏ãÊ†á‰∏≠ÁöÑx‰ª£Ë°®Âêé‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉÁöÑÂ∫èÂè∑ÔºåËÄåy‰ª£Ë°®Ââç‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉÁöÑÂ∫èÂè∑ÔºàÂ∫èÂè∑ÁöÑÈ°∫Â∫è‰ªé‰∏äÂà∞‰∏ãÔºâ„ÄÇ ‰æãÂ¶ÇÔºåw1,2‰ª£Ë°®Âêé‰∏ÄÂ±ÇÁöÑÁ¨¨1‰∏™Á•ûÁªèÂÖÉ‰∏éÂâç‰∏ÄÂ±ÇÁöÑÁ¨¨2‰∏™Á•ûÁªèÂÖÉÁöÑËøûÊé•ÁöÑÊùÉÂÄºÔºàËøôÁßçÊ†áËÆ∞ÊñπÂºèÂèÇÁÖß‰∫ÜAndrew NgÁöÑËØæ‰ª∂Ôºâ„ÄÇÊ†πÊçÆ‰ª•‰∏äÊñπÊ≥ïÊ†áËÆ∞ÔºåÊàë‰ª¨Êúâ‰∫Ü‰∏ãÂõæ„ÄÇÂõæ16 ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú(Êâ©Â±ï)&nbsp; Â¶ÇÊûúÊàë‰ª¨‰ªîÁªÜÁúãËæìÂá∫ÁöÑËÆ°ÁÆóÂÖ¨ÂºèÔºå‰ºöÂèëÁé∞Ëøô‰∏§‰∏™ÂÖ¨ÂºèÂ∞±ÊòØÁ∫øÊÄß‰ª£Êï∞ÊñπÁ®ãÁªÑ„ÄÇÂõ†Ê≠§ÂèØ‰ª•Áî®Áü©Èòµ‰πòÊ≥ïÊù•Ë°®ËææËøô‰∏§‰∏™ÂÖ¨Âºè„ÄÇ ‰æãÂ¶ÇÔºåËæìÂÖ•ÁöÑÂèòÈáèÊòØ[a1Ôºåa2Ôºåa3]TÔºà‰ª£Ë°®Áî±a1Ôºåa2Ôºåa3ÁªÑÊàêÁöÑÂàóÂêëÈáèÔºâÔºåÁî®ÂêëÈáèaÊù•Ë°®Á§∫„ÄÇÊñπÁ®ãÁöÑÂ∑¶ËæπÊòØ[z1Ôºåz2]TÔºåÁî®ÂêëÈáèzÊù•Ë°®Á§∫„ÄÇ Á≥ªÊï∞ÂàôÊòØÁü©ÈòµWÔºà2Ë°å3ÂàóÁöÑÁü©ÈòµÔºåÊéíÂàóÂΩ¢Âºè‰∏éÂÖ¨Âºè‰∏≠ÁöÑ‰∏ÄÊ†∑Ôºâ„ÄÇ ‰∫éÊòØÔºåËæìÂá∫ÂÖ¨ÂºèÂèØ‰ª•ÊîπÂÜôÊàêÔºög(W a) = z;&nbsp; Ëøô‰∏™ÂÖ¨ÂºèÂ∞±ÊòØÁ•ûÁªèÁΩëÁªú‰∏≠‰ªéÂâç‰∏ÄÂ±ÇËÆ°ÁÆóÂêé‰∏ÄÂ±ÇÁöÑÁü©ÈòµËøêÁÆó„ÄÇ 3.ÊïàÊûú ‰∏éÁ•ûÁªèÂÖÉÊ®°Âûã‰∏çÂêåÔºåÊÑüÁü•Âô®‰∏≠ÁöÑÊùÉÂÄºÊòØÈÄöËøáËÆ≠ÁªÉÂæóÂà∞ÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊ†πÊçÆ‰ª•ÂâçÁöÑÁü•ËØÜÊàë‰ª¨Áü•ÈÅìÔºåÊÑüÁü•Âô®Á±ª‰ºº‰∏Ä‰∏™ÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºåÂèØ‰ª•ÂÅöÁ∫øÊÄßÂàÜÁ±ª‰ªªÂä°„ÄÇ Êàë‰ª¨ÂèØ‰ª•Áî®ÂÜ≥Á≠ñÂàÜÁïåÊù•ÂΩ¢Ë±°ÁöÑË°®ËææÂàÜÁ±ªÁöÑÊïàÊûú„ÄÇÂÜ≥Á≠ñÂàÜÁïåÂ∞±ÊòØÂú®‰∫åÁª¥ÁöÑÊï∞ÊçÆÂπ≥Èù¢‰∏≠ÂàíÂá∫‰∏ÄÊù°Áõ¥Á∫øÔºåÂΩìÊï∞ÊçÆÁöÑÁª¥Â∫¶ÊòØ3Áª¥ÁöÑÊó∂ÂÄôÔºåÂ∞±ÊòØÂàíÂá∫‰∏Ä‰∏™Âπ≥Èù¢ÔºåÂΩìÊï∞ÊçÆÁöÑÁª¥Â∫¶ÊòØnÁª¥Êó∂ÔºåÂ∞±ÊòØÂàíÂá∫‰∏Ä‰∏™n-1Áª¥ÁöÑË∂ÖÂπ≥Èù¢„ÄÇ ‰∏ãÂõæÊòæÁ§∫‰∫ÜÂú®‰∫åÁª¥Âπ≥Èù¢‰∏≠ÂàíÂá∫ÂÜ≥Á≠ñÂàÜÁïåÁöÑÊïàÊûúÔºå‰πüÂ∞±ÊòØÊÑüÁü•Âô®ÁöÑÂàÜÁ±ªÊïàÊûú„ÄÇÂõæ17 ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÂÜ≥Á≠ñÂàÜÁïåÔºâ 4.ÂΩ±Âìç ÊÑüÁü•Âô®Âè™ËÉΩÂÅöÁÆÄÂçïÁöÑÁ∫øÊÄßÂàÜÁ±ª‰ªªÂä°„ÄÇ‰ΩÜÊòØÂΩìÊó∂ÁöÑ‰∫∫‰ª¨ÁÉ≠ÊÉÖÂ§™Ëøá‰∫éÈ´òÊ∂®ÔºåÂπ∂Ê≤°Êúâ‰∫∫Ê∏ÖÈÜíÁöÑËÆ§ËØÜÂà∞ËøôÁÇπ„ÄÇ‰∫éÊòØÔºåÂΩì‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüÁöÑÂ∑®ÊìòMinskyÊåáÂá∫ËøôÁÇπÊó∂Ôºå‰∫ãÊÄÅÂ∞±ÂèëÁîü‰∫ÜÂèòÂåñ„ÄÇ MinskyÂú®1969Âπ¥Âá∫Áâà‰∫Ü‰∏ÄÊú¨Âè´„ÄäPerceptron„ÄãÁöÑ‰π¶ÔºåÈáåÈù¢Áî®ËØ¶ÁªÜÁöÑÊï∞Â≠¶ËØÅÊòé‰∫ÜÊÑüÁü•Âô®ÁöÑÂº±ÁÇπÔºåÂ∞§ÂÖ∂ÊòØÊÑüÁü•Âô®ÂØπXORÔºàÂºÇÊàñÔºâËøôÊ†∑ÁöÑÁÆÄÂçïÂàÜÁ±ª‰ªªÂä°ÈÉΩÊó†Ê≥ïËß£ÂÜ≥„ÄÇ MinskyËÆ§‰∏∫ÔºåÂ¶ÇÊûúÂ∞ÜËÆ°ÁÆóÂ±ÇÂ¢ûÂä†Âà∞‰∏§Â±ÇÔºåËÆ°ÁÆóÈáèÂàôËøáÂ§ßÔºåËÄå‰∏îÊ≤°ÊúâÊúâÊïàÁöÑÂ≠¶‰π†ÁÆóÊ≥ï„ÄÇÊâÄ‰ª•Ôºå‰ªñËÆ§‰∏∫Á†îÁ©∂Êõ¥Ê∑±Â±ÇÁöÑÁΩëÁªúÊòØÊ≤°Êúâ‰ª∑ÂÄºÁöÑ„ÄÇÔºàÊú¨ÊñáÊàêÊñáÂêé‰∏Ä‰∏™ÊúàÔºåÂç≥2016Âπ¥1ÊúàÔºåMinskyÂú®ÁæéÂõΩÂéª‰∏ñ„ÄÇË∞®Âú®Êú¨Êñá‰∏≠Á∫™ÂøµËøô‰ΩçËëóÂêçÁöÑËÆ°ÁÆóÊú∫Á†îÁ©∂‰∏ìÂÆ∂‰∏éÂ§ßÊãø„ÄÇÔºâ&nbsp; &nbsp;Âõæ18 Marvin Minsky Áî±‰∫éMinskyÁöÑÂ∑®Â§ßÂΩ±ÂìçÂäõ‰ª•Âèä‰π¶‰∏≠ÂëàÁé∞ÁöÑÊÇ≤ËßÇÊÄÅÂ∫¶ÔºåËÆ©ÂæàÂ§öÂ≠¶ËÄÖÂíåÂÆûÈ™åÂÆ§Á∫∑Á∫∑ÊîæÂºÉ‰∫ÜÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂„ÄÇÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂Èô∑ÂÖ•‰∫ÜÂÜ∞Ê≤≥Êúü„ÄÇËøô‰∏™Êó∂ÊúüÂèàË¢´Áß∞‰∏∫‚ÄúAI winter‚Äù„ÄÇ Êé•Ëøë10Âπ¥‰ª•ÂêéÔºåÂØπ‰∫é‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂ÊâçÂ∏¶Êù•Á•ûÁªèÁΩëÁªúÁöÑÂ§çËãè„ÄÇ&nbsp;Âõõ. ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàÂ§öÂ±ÇÊÑüÁü•Âô®Ôºâ 1.ÂºïÂ≠ê ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÊòØÊú¨ÊñáÁöÑÈáçÁÇπÔºåÂõ†‰∏∫Ê≠£ÊòØÂú®ËøôÊó∂ÂÄôÔºåÁ•ûÁªèÁΩëÁªúÂºÄÂßã‰∫ÜÂ§ßËåÉÂõ¥ÁöÑÊé®Âπø‰∏é‰ΩøÁî®„ÄÇ MinskyËØ¥ËøáÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÊó†Ê≥ïËß£ÂÜ≥ÂºÇÊàñÈóÆÈ¢ò„ÄÇ‰ΩÜÊòØÂΩìÂ¢ûÂä†‰∏Ä‰∏™ËÆ°ÁÆóÂ±Ç‰ª•ÂêéÔºå‰∏§Â±ÇÁ•ûÁªèÁΩëÁªú‰∏ç‰ªÖÂèØ‰ª•Ëß£ÂÜ≥ÂºÇÊàñÈóÆÈ¢òÔºåËÄå‰∏îÂÖ∑ÊúâÈùûÂ∏∏Â•ΩÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ªÊïàÊûú„ÄÇ‰∏çËøá‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑËÆ°ÁÆóÊòØ‰∏Ä‰∏™ÈóÆÈ¢òÔºåÊ≤°Êúâ‰∏Ä‰∏™ËæÉÂ•ΩÁöÑËß£Ê≥ï„ÄÇ 1986Âπ¥ÔºåRumelharÂíåHintonÁ≠â‰∫∫ÊèêÂá∫‰∫ÜÂèçÂêë‰º†Êí≠ÔºàBackpropagationÔºåBPÔºâÁÆóÊ≥ïÔºåËß£ÂÜ≥‰∫Ü‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÊâÄÈúÄË¶ÅÁöÑÂ§çÊùÇËÆ°ÁÆóÈáèÈóÆÈ¢òÔºå‰ªéËÄåÂ∏¶Âä®‰∫Ü‰∏öÁïå‰ΩøÁî®‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁ†îÁ©∂ÁöÑÁÉ≠ÊΩÆ„ÄÇÁõÆÂâçÔºåÂ§ßÈáèÁöÑÊïôÊéàÁ•ûÁªèÁΩëÁªúÁöÑÊïôÊùêÔºåÈÉΩÊòØÈáçÁÇπ‰ªãÁªç‰∏§Â±ÇÔºàÂ∏¶‰∏Ä‰∏™ÈöêËóèÂ±ÇÔºâÁ•ûÁªèÁΩëÁªúÁöÑÂÜÖÂÆπ„ÄÇ&nbsp; ËøôÊó∂ÂÄôÁöÑHintonËøòÂæàÂπ¥ËΩªÔºå30Âπ¥‰ª•ÂêéÔºåÊ≠£ÊòØ‰ªñÈáçÊñ∞ÂÆö‰πâ‰∫ÜÁ•ûÁªèÁΩëÁªúÔºåÂ∏¶Êù•‰∫ÜÁ•ûÁªèÁΩëÁªúÂ§çËãèÁöÑÂèà‰∏ÄÊò•„ÄÇ&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;Âõæ19 David&nbsp;RumelhartÔºàÂ∑¶Ôºâ‰ª•Âèä&nbsp;Geoffery HintonÔºàÂè≥Ôºâ&nbsp; 2.ÁªìÊûÑ ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÈô§‰∫ÜÂåÖÂê´‰∏Ä‰∏™ËæìÂÖ•Â±ÇÔºå‰∏Ä‰∏™ËæìÂá∫Â±Ç‰ª•Â§ñÔºåËøòÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™‰∏≠Èó¥Â±Ç„ÄÇÊ≠§Êó∂Ôºå‰∏≠Èó¥Â±ÇÂíåËæìÂá∫Â±ÇÈÉΩÊòØËÆ°ÁÆóÂ±Ç„ÄÇÊàë‰ª¨Êâ©Â±ï‰∏äËäÇÁöÑÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºåÂú®Âè≥ËæπÊñ∞Âä†‰∏Ä‰∏™Â±ÇÊ¨°ÔºàÂè™Âê´Êúâ‰∏Ä‰∏™ËäÇÁÇπÔºâ„ÄÇ Áé∞Âú®ÔºåÊàë‰ª¨ÁöÑÊùÉÂÄºÁü©ÈòµÂ¢ûÂä†Âà∞‰∫Ü‰∏§‰∏™ÔºåÊàë‰ª¨Áî®‰∏äÊ†áÊù•Âå∫ÂàÜ‰∏çÂêåÂ±ÇÊ¨°‰πãÈó¥ÁöÑÂèòÈáè„ÄÇ ‰æãÂ¶Çax(y)‰ª£Ë°®Á¨¨yÂ±ÇÁöÑÁ¨¨x‰∏™ËäÇÁÇπ„ÄÇz1Ôºåz2ÂèòÊàê‰∫Üa1(2)Ôºåa2(2)„ÄÇ‰∏ãÂõæÁªôÂá∫‰∫Üa1(2)Ôºåa2(2)ÁöÑËÆ°ÁÆóÂÖ¨Âºè„ÄÇÂõæ20 ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºà‰∏≠Èó¥Â±ÇËÆ°ÁÆóÔºâ&nbsp; ËÆ°ÁÆóÊúÄÁªàËæìÂá∫zÁöÑÊñπÂºèÊòØÂà©Áî®‰∫Ü‰∏≠Èó¥Â±ÇÁöÑa1(2)Ôºåa2(2)ÂíåÁ¨¨‰∫å‰∏™ÊùÉÂÄºÁü©ÈòµËÆ°ÁÆóÂæóÂà∞ÁöÑÔºåÂ¶Ç‰∏ãÂõæ„ÄÇÂõæ21 ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàËæìÂá∫Â±ÇËÆ°ÁÆóÔºâ&nbsp; ÂÅáËÆæÊàë‰ª¨ÁöÑÈ¢ÑÊµãÁõÆÊ†áÊòØ‰∏Ä‰∏™ÂêëÈáèÔºåÈÇ£‰πà‰∏éÂâçÈù¢Á±ª‰ººÔºåÂè™ÈúÄË¶ÅÂú®‚ÄúËæìÂá∫Â±Ç‚ÄùÂÜçÂ¢ûÂä†ËäÇÁÇπÂç≥ÂèØ„ÄÇ Êàë‰ª¨‰ΩøÁî®ÂêëÈáèÂíåÁü©ÈòµÊù•Ë°®Á§∫Â±ÇÊ¨°‰∏≠ÁöÑÂèòÈáè„ÄÇa(1)Ôºåa(2)ÔºåzÊòØÁΩëÁªú‰∏≠‰º†ËæìÁöÑÂêëÈáèÊï∞ÊçÆ„ÄÇW(1)ÂíåW(2)ÊòØÁΩëÁªúÁöÑÁü©ÈòµÂèÇÊï∞„ÄÇÂ¶Ç‰∏ãÂõæ„ÄÇÂõæ22 ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàÂêëÈáèÂΩ¢ÂºèÔºâ&nbsp; ‰ΩøÁî®Áü©ÈòµËøêÁÆóÊù•Ë°®ËææÊï¥‰∏™ËÆ°ÁÆóÂÖ¨ÂºèÁöÑËØùÂ¶Ç‰∏ãÔºö&nbsp; g(W(1)&nbsp;&nbsp;a(1)) =&nbsp;a(2);&nbsp;g(W(2)&nbsp;&nbsp;a(2)) =&nbsp;z;&nbsp; Áî±Ê≠§ÂèØËßÅÔºå‰ΩøÁî®Áü©ÈòµËøêÁÆóÊù•Ë°®ËææÊòØÂæàÁÆÄÊ¥ÅÁöÑÔºåËÄå‰∏î‰πü‰∏ç‰ºöÂèóÂà∞ËäÇÁÇπÊï∞Â¢ûÂ§öÁöÑÂΩ±ÂìçÔºàÊó†ËÆ∫ÊúâÂ§öÂ∞ëËäÇÁÇπÂèÇ‰∏éËøêÁÆóÔºå‰πòÊ≥ï‰∏§Á´ØÈÉΩÂè™Êúâ‰∏Ä‰∏™ÂèòÈáèÔºâ„ÄÇÂõ†Ê≠§Á•ûÁªèÁΩëÁªúÁöÑÊïôÁ®ã‰∏≠Â§ßÈáè‰ΩøÁî®Áü©ÈòµËøêÁÆóÊù•ÊèèËø∞„ÄÇ ÈúÄË¶ÅËØ¥ÊòéÁöÑÊòØÔºåËá≥‰ªä‰∏∫Ê≠¢ÔºåÊàë‰ª¨ÂØπÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑÂõæÁöÑËÆ®ËÆ∫‰∏≠ÈÉΩÊ≤°ÊúâÊèêÂà∞ÂÅèÁΩÆËäÇÁÇπÔºàbias unitÔºâ„ÄÇ‰∫ãÂÆû‰∏äÔºåËøô‰∫õËäÇÁÇπÊòØÈªòËÆ§Â≠òÂú®ÁöÑ„ÄÇÂÆÉÊú¨Ë¥®‰∏äÊòØ‰∏Ä‰∏™Âè™Âê´ÊúâÂ≠òÂÇ®ÂäüËÉΩÔºå‰∏îÂ≠òÂÇ®ÂÄºÊ∞∏Ëøú‰∏∫1ÁöÑÂçïÂÖÉ„ÄÇÂú®Á•ûÁªèÁΩëÁªúÁöÑÊØè‰∏™Â±ÇÊ¨°‰∏≠ÔºåÈô§‰∫ÜËæìÂá∫Â±Ç‰ª•Â§ñÔºåÈÉΩ‰ºöÂê´ÊúâËøôÊ†∑‰∏Ä‰∏™ÂÅèÁΩÆÂçïÂÖÉ„ÄÇÊ≠£Â¶ÇÁ∫øÊÄßÂõûÂΩíÊ®°Âûã‰∏éÈÄªËæëÂõûÂΩíÊ®°Âûã‰∏≠ÁöÑ‰∏ÄÊ†∑„ÄÇ ÂÅèÁΩÆÂçïÂÖÉ‰∏éÂêé‰∏ÄÂ±ÇÁöÑÊâÄÊúâËäÇÁÇπÈÉΩÊúâËøûÊé•ÔºåÊàë‰ª¨ËÆæËøô‰∫õÂèÇÊï∞ÂÄº‰∏∫ÂêëÈáèbÔºåÁß∞‰πã‰∏∫ÂÅèÁΩÆ„ÄÇÂ¶Ç‰∏ãÂõæ„ÄÇÂõæ23 ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàËÄÉËôëÂÅèÁΩÆËäÇÁÇπÔºâ&nbsp; ÂèØ‰ª•ÁúãÂá∫ÔºåÂÅèÁΩÆËäÇÁÇπÂæàÂ•ΩËÆ§ÔºåÂõ†‰∏∫ÂÖ∂Ê≤°ÊúâËæìÂÖ•ÔºàÂâç‰∏ÄÂ±Ç‰∏≠Ê≤°ÊúâÁÆ≠Â§¥ÊåáÂêëÂÆÉÔºâ„ÄÇÊúâ‰∫õÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑÂõæ‰∏≠‰ºöÊääÂÅèÁΩÆËäÇÁÇπÊòéÊòæÁîªÂá∫Êù•ÔºåÊúâ‰∫õ‰∏ç‰ºö„ÄÇ‰∏ÄËà¨ÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÈÉΩ‰∏ç‰ºöÊòéÁ°ÆÁîªÂá∫ÂÅèÁΩÆËäÇÁÇπ„ÄÇ&nbsp; Âú®ËÄÉËôë‰∫ÜÂÅèÁΩÆ‰ª•ÂêéÁöÑ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÁöÑÁü©ÈòµËøêÁÆóÂ¶Ç‰∏ãÔºö&nbsp;&nbsp;g(W(1)&nbsp;&nbsp;a(1)&nbsp;+ b(1)) =&nbsp;a(2);&nbsp;g(W(2)&nbsp;&nbsp;a(2)&nbsp;+ b(2)) =&nbsp;z;&nbsp; ÈúÄË¶ÅËØ¥ÊòéÁöÑÊòØÔºåÂú®‰∏§Â±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåÊàë‰ª¨‰∏çÂÜç‰ΩøÁî®sgnÂáΩÊï∞‰Ωú‰∏∫ÂáΩÊï∞gÔºåËÄåÊòØ‰ΩøÁî®Âπ≥ÊªëÂáΩÊï∞sigmoid‰Ωú‰∏∫ÂáΩÊï∞g„ÄÇÊàë‰ª¨ÊääÂáΩÊï∞g‰πüÁß∞‰ΩúÊøÄÊ¥ªÂáΩÊï∞Ôºàactive&nbsp;functionÔºâ„ÄÇ ‰∫ãÂÆû‰∏äÔºåÁ•ûÁªèÁΩëÁªúÁöÑÊú¨Ë¥®Â∞±ÊòØÈÄöËøáÂèÇÊï∞‰∏éÊøÄÊ¥ªÂáΩÊï∞Êù•ÊãüÂêàÁâπÂæÅ‰∏éÁõÆÊ†á‰πãÈó¥ÁöÑÁúüÂÆûÂáΩÊï∞ÂÖ≥Á≥ª„ÄÇÂàùÂ≠¶ËÄÖÂèØËÉΩËÆ§‰∏∫ÁîªÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑÂõæÊòØ‰∏∫‰∫ÜÂú®Á®ãÂ∫è‰∏≠ÂÆûÁé∞Ëøô‰∫õÂúÜÂúà‰∏éÁ∫øÔºå‰ΩÜÂú®‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÁöÑÁ®ãÂ∫è‰∏≠ÔºåÊó¢Ê≤°Êúâ‚ÄúÁ∫ø‚ÄùËøô‰∏™ÂØπË±°Ôºå‰πüÊ≤°Êúâ‚ÄúÂçïÂÖÉ‚ÄùËøô‰∏™ÂØπË±°„ÄÇÂÆûÁé∞‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊúÄÈúÄË¶ÅÁöÑÊòØÁ∫øÊÄß‰ª£Êï∞Â∫ì„ÄÇ 3.ÊïàÊûú ‰∏éÂçïÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏çÂêå„ÄÇÁêÜËÆ∫ËØÅÊòéÔºå‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÂèØ‰ª•Êó†ÈôêÈÄºËøë‰ªªÊÑèËøûÁª≠ÂáΩÊï∞„ÄÇ ËøôÊòØ‰ªÄ‰πàÊÑèÊÄùÂë¢Ôºü‰πüÂ∞±ÊòØËØ¥ÔºåÈù¢ÂØπÂ§çÊùÇÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ª‰ªªÂä°Ôºå‰∏§Â±ÇÔºàÂ∏¶‰∏Ä‰∏™ÈöêËóèÂ±ÇÔºâÁ•ûÁªèÁΩëÁªúÂèØ‰ª•ÂàÜÁ±ªÁöÑÂæàÂ•Ω„ÄÇ ‰∏ãÈù¢Â∞±ÊòØ‰∏Ä‰∏™‰æãÂ≠êÔºàÊ≠§‰∏§ÂõæÊù•Ëá™colahÁöÑÂçöÂÆ¢ÔºâÔºåÁ∫¢Ëâ≤ÁöÑÁ∫ø‰∏éËìùËâ≤ÁöÑÁ∫ø‰ª£Ë°®Êï∞ÊçÆ„ÄÇËÄåÁ∫¢Ëâ≤Âå∫ÂüüÂíåËìùËâ≤Âå∫Âüü‰ª£Ë°®Áî±Á•ûÁªèÁΩëÁªúÂàíÂºÄÁöÑÂå∫ÂüüÔºå‰∏§ËÄÖÁöÑÂàÜÁïåÁ∫øÂ∞±ÊòØÂÜ≥Á≠ñÂàÜÁïå„ÄÇÂõæ24 ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàÂÜ≥Á≠ñÂàÜÁïåÔºâ ÂèØ‰ª•ÁúãÂà∞ÔºåËøô‰∏™‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑÂÜ≥Á≠ñÂàÜÁïåÊòØÈùûÂ∏∏Âπ≥ÊªëÁöÑÊõ≤Á∫øÔºåËÄå‰∏îÂàÜÁ±ªÁöÑÂæàÂ•Ω„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂâçÈù¢Â∑≤ÁªèÂ≠¶Âà∞ËøáÔºåÂçïÂ±ÇÁΩëÁªúÂè™ËÉΩÂÅöÁ∫øÊÄßÂàÜÁ±ª‰ªªÂä°„ÄÇËÄå‰∏§Â±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÂêé‰∏ÄÂ±Ç‰πüÊòØÁ∫øÊÄßÂàÜÁ±ªÂ±ÇÔºåÂ∫îËØ•Âè™ËÉΩÂÅöÁ∫øÊÄßÂàÜÁ±ª‰ªªÂä°„ÄÇ‰∏∫‰ªÄ‰πà‰∏§‰∏™Á∫øÊÄßÂàÜÁ±ª‰ªªÂä°ÁªìÂêàÂ∞±ÂèØ‰ª•ÂÅöÈùûÁ∫øÊÄßÂàÜÁ±ª‰ªªÂä°Ôºü Êàë‰ª¨ÂèØ‰ª•ÊääËæìÂá∫Â±ÇÁöÑÂÜ≥Á≠ñÂàÜÁïåÂçïÁã¨ÊãøÂá∫Êù•Áúã‰∏Ä‰∏ã„ÄÇÂ∞±ÊòØ‰∏ãÂõæ„ÄÇÂõæ25 ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºàÁ©∫Èó¥ÂèòÊç¢Ôºâ&nbsp; ÂèØ‰ª•ÁúãÂà∞ÔºåËæìÂá∫Â±ÇÁöÑÂÜ≥Á≠ñÂàÜÁïå‰ªçÁÑ∂ÊòØÁõ¥Á∫ø„ÄÇÂÖ≥ÈîÆÂ∞±ÊòØÔºå‰ªéËæìÂÖ•Â±ÇÂà∞ÈöêËóèÂ±ÇÊó∂ÔºåÊï∞ÊçÆÂèëÁîü‰∫ÜÁ©∫Èó¥ÂèòÊç¢„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰∏§Â±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåÈöêËóèÂ±ÇÂØπÂéüÂßãÁöÑÊï∞ÊçÆËøõË°å‰∫Ü‰∏Ä‰∏™Á©∫Èó¥ÂèòÊç¢Ôºå‰ΩøÂÖ∂ÂèØ‰ª•Ë¢´Á∫øÊÄßÂàÜÁ±ªÔºåÁÑ∂ÂêéËæìÂá∫Â±ÇÁöÑÂÜ≥Á≠ñÂàÜÁïåÂàíÂá∫‰∫Ü‰∏Ä‰∏™Á∫øÊÄßÂàÜÁ±ªÂàÜÁïåÁ∫øÔºåÂØπÂÖ∂ËøõË°åÂàÜÁ±ª„ÄÇ ËøôÊ†∑Â∞±ÂØºÂá∫‰∫Ü‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÂèØ‰ª•ÂÅöÈùûÁ∫øÊÄßÂàÜÁ±ªÁöÑÂÖ≥ÈîÆ‚ÄìÈöêËóèÂ±Ç„ÄÇËÅîÊÉ≥Âà∞Êàë‰ª¨‰∏ÄÂºÄÂßãÊé®ÂØºÂá∫ÁöÑÁü©ÈòµÂÖ¨ÂºèÔºåÊàë‰ª¨Áü•ÈÅìÔºåÁü©ÈòµÂíåÂêëÈáèÁõ∏‰πòÔºåÊú¨Ë¥®‰∏äÂ∞±ÊòØÂØπÂêëÈáèÁöÑÂùêÊ†áÁ©∫Èó¥ËøõË°å‰∏Ä‰∏™ÂèòÊç¢„ÄÇÂõ†Ê≠§ÔºåÈöêËóèÂ±ÇÁöÑÂèÇÊï∞Áü©ÈòµÁöÑ‰ΩúÁî®Â∞±ÊòØ‰ΩøÂæóÊï∞ÊçÆÁöÑÂéüÂßãÂùêÊ†áÁ©∫Èó¥‰ªéÁ∫øÊÄß‰∏çÂèØÂàÜÔºåËΩ¨Êç¢Êàê‰∫ÜÁ∫øÊÄßÂèØÂàÜ„ÄÇ ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÈÄöËøá‰∏§Â±ÇÁöÑÁ∫øÊÄßÊ®°ÂûãÊ®°Êãü‰∫ÜÊï∞ÊçÆÂÜÖÁúüÂÆûÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞„ÄÇÂõ†Ê≠§ÔºåÂ§öÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªúÁöÑÊú¨Ë¥®Â∞±ÊòØÂ§çÊùÇÂáΩÊï∞ÊãüÂêà„ÄÇ ‰∏ãÈù¢Êù•ËÆ®ËÆ∫‰∏Ä‰∏ãÈöêËóèÂ±ÇÁöÑËäÇÁÇπÊï∞ËÆæËÆ°„ÄÇÂú®ËÆæËÆ°‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊó∂ÔºåËæìÂÖ•Â±ÇÁöÑËäÇÁÇπÊï∞ÈúÄË¶Å‰∏éÁâπÂæÅÁöÑÁª¥Â∫¶ÂåπÈÖçÔºåËæìÂá∫Â±ÇÁöÑËäÇÁÇπÊï∞Ë¶Å‰∏éÁõÆÊ†áÁöÑÁª¥Â∫¶ÂåπÈÖç„ÄÇËÄå‰∏≠Èó¥Â±ÇÁöÑËäÇÁÇπÊï∞ÔºåÂç¥ÊòØÁî±ËÆæËÆ°ËÄÖÊåáÂÆöÁöÑ„ÄÇÂõ†Ê≠§Ôºå‚ÄúËá™Áî±‚ÄùÊääÊè°Âú®ËÆæËÆ°ËÄÖÁöÑÊâã‰∏≠„ÄÇ‰ΩÜÊòØÔºåËäÇÁÇπÊï∞ËÆæÁΩÆÁöÑÂ§öÂ∞ëÔºåÂç¥‰ºöÂΩ±ÂìçÂà∞Êï¥‰∏™Ê®°ÂûãÁöÑÊïàÊûú„ÄÇÂ¶Ç‰ΩïÂÜ≥ÂÆöËøô‰∏™Ëá™Áî±Â±ÇÁöÑËäÇÁÇπÊï∞Âë¢ÔºüÁõÆÂâç‰∏öÁïåÊ≤°ÊúâÂÆåÂñÑÁöÑÁêÜËÆ∫Êù•ÊåáÂØºËøô‰∏™ÂÜ≥Á≠ñ„ÄÇ‰∏ÄËà¨ÊòØÊ†πÊçÆÁªèÈ™åÊù•ËÆæÁΩÆ„ÄÇËæÉÂ•ΩÁöÑÊñπÊ≥ïÂ∞±ÊòØÈ¢ÑÂÖàËÆæÂÆöÂá†‰∏™ÂèØÈÄâÂÄºÔºåÈÄöËøáÂàáÊç¢ËøôÂá†‰∏™ÂÄºÊù•ÁúãÊï¥‰∏™Ê®°ÂûãÁöÑÈ¢ÑÊµãÊïàÊûúÔºåÈÄâÊã©ÊïàÊûúÊúÄÂ•ΩÁöÑÂÄº‰Ωú‰∏∫ÊúÄÁªàÈÄâÊã©„ÄÇËøôÁßçÊñπÊ≥ïÂèàÂè´ÂÅöGrid&nbsp;SearchÔºàÁΩëÊ†ºÊêúÁ¥¢Ôºâ„ÄÇ ‰∫ÜËß£‰∫Ü‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑ‰ª•ÂêéÔºåÊàë‰ª¨Â∞±ÂèØ‰ª•ÁúãÊáÇÂÖ∂ÂÆÉÁ±ª‰ººÁöÑÁªìÊûÑÂõæ„ÄÇ‰æãÂ¶ÇEasyPRÂ≠óÁ¨¶ËØÜÂà´ÁΩëÁªúÊû∂ÊûÑÔºà‰∏ãÂõæÔºâ„ÄÇÂõæ26 EasyPRÂ≠óÁ¨¶ËØÜÂà´ÁΩëÁªú&nbsp; EasyPR‰ΩøÁî®‰∫ÜÂ≠óÁ¨¶ÁöÑÂõæÂÉèÂéªËøõË°åÂ≠óÁ¨¶ÊñáÂ≠óÁöÑËØÜÂà´„ÄÇËæìÂÖ•ÊòØ120Áª¥ÁöÑÂêëÈáè„ÄÇËæìÂá∫ÊòØË¶ÅÈ¢ÑÊµãÁöÑÊñáÂ≠óÁ±ªÂà´ÔºåÂÖ±Êúâ65Á±ª„ÄÇÊ†πÊçÆÂÆûÈ™åÔºåÊàë‰ª¨ÊµãËØï‰∫Ü‰∏Ä‰∫õÈöêËóèÂ±ÇÊï∞ÁõÆÔºåÂèëÁé∞ÂΩìÂÄº‰∏∫40Êó∂ÔºåÊï¥‰∏™ÁΩëÁªúÂú®ÊµãËØïÈõÜ‰∏äÁöÑÊïàÊûúËæÉÂ•ΩÔºåÂõ†Ê≠§ÈÄâÊã©ÁΩëÁªúÁöÑÊúÄÁªàÁªìÊûÑÂ∞±ÊòØ120Ôºå40Ôºå65„ÄÇ 4.ËÆ≠ÁªÉ ‰∏ãÈù¢ÁÆÄÂçï‰ªãÁªç‰∏Ä‰∏ã‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉ„ÄÇ Âú®RosenblatÊèêÂá∫ÁöÑÊÑüÁü•Âô®Ê®°Âûã‰∏≠ÔºåÊ®°Âûã‰∏≠ÁöÑÂèÇÊï∞ÂèØ‰ª•Ë¢´ËÆ≠ÁªÉÔºå‰ΩÜÊòØ‰ΩøÁî®ÁöÑÊñπÊ≥ïËæÉ‰∏∫ÁÆÄÂçïÔºåÂπ∂Ê≤°Êúâ‰ΩøÁî®ÁõÆÂâçÊú∫Âô®Â≠¶‰π†‰∏≠ÈÄöÁî®ÁöÑÊñπÊ≥ïÔºåËøôÂØºËá¥ÂÖ∂Êâ©Â±ïÊÄß‰∏éÈÄÇÁî®ÊÄßÈùûÂ∏∏ÊúâÈôê„ÄÇ‰ªé‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÂºÄÂßãÔºåÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂‰∫∫ÂëòÂºÄÂßã‰ΩøÁî®Êú∫Âô®Â≠¶‰π†Áõ∏ÂÖ≥ÁöÑÊäÄÊúØËøõË°åÁ•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉ„ÄÇ‰æãÂ¶ÇÁî®Â§ßÈáèÁöÑÊï∞ÊçÆÔºà1000-10000Â∑¶Âè≥ÔºâÔºå‰ΩøÁî®ÁÆóÊ≥ïËøõË°å‰ºòÂåñÁ≠âÁ≠âÔºå‰ªéËÄå‰ΩøÂæóÊ®°ÂûãËÆ≠ÁªÉÂèØ‰ª•Ëé∑ÂæóÊÄßËÉΩ‰∏éÊï∞ÊçÆÂà©Áî®‰∏äÁöÑÂèåÈáç‰ºòÂäø„ÄÇ Êú∫Âô®Â≠¶‰π†Ê®°ÂûãËÆ≠ÁªÉÁöÑÁõÆÁöÑÔºåÂ∞±ÊòØ‰ΩøÂæóÂèÇÊï∞Â∞ΩÂèØËÉΩÁöÑ‰∏éÁúüÂÆûÁöÑÊ®°ÂûãÈÄºËøë„ÄÇÂÖ∑‰ΩìÂÅöÊ≥ïÊòØËøôÊ†∑ÁöÑ„ÄÇÈ¶ñÂÖàÁªôÊâÄÊúâÂèÇÊï∞Ëµã‰∏äÈöèÊú∫ÂÄº„ÄÇÊàë‰ª¨‰ΩøÁî®Ëøô‰∫õÈöèÊú∫ÁîüÊàêÁöÑÂèÇÊï∞ÂÄºÔºåÊù•È¢ÑÊµãËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÁöÑÊ†∑Êú¨„ÄÇÊ†∑Êú¨ÁöÑÈ¢ÑÊµãÁõÆÊ†á‰∏∫ypÔºåÁúüÂÆûÁõÆÊ†á‰∏∫y„ÄÇÈÇ£‰πàÔºåÂÆö‰πâ‰∏Ä‰∏™ÂÄºlossÔºåËÆ°ÁÆóÂÖ¨ÂºèÂ¶Ç‰∏ã„ÄÇloss = (yp&nbsp;- y)2&nbsp; Ëøô‰∏™ÂÄºÁß∞‰πã‰∏∫ÊçüÂ§±ÔºàlossÔºâÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÂ∞±ÊòØ‰ΩøÂØπÊâÄÊúâËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊçüÂ§±ÂíåÂ∞ΩÂèØËÉΩÁöÑÂ∞è„ÄÇ Â¶ÇÊûúÂ∞ÜÂÖàÂâçÁöÑÁ•ûÁªèÁΩëÁªúÈ¢ÑÊµãÁöÑÁü©ÈòµÂÖ¨ÂºèÂ∏¶ÂÖ•Âà∞yp‰∏≠ÔºàÂõ†‰∏∫Êúâz=ypÔºâÔºåÈÇ£‰πàÊàë‰ª¨ÂèØ‰ª•ÊääÊçüÂ§±ÂÜô‰∏∫ÂÖ≥‰∫éÂèÇÊï∞ÔºàparameterÔºâÁöÑÂáΩÊï∞ÔºåËøô‰∏™ÂáΩÊï∞Áß∞‰πã‰∏∫ÊçüÂ§±ÂáΩÊï∞Ôºàloss functionÔºâ„ÄÇ‰∏ãÈù¢ÁöÑÈóÆÈ¢òÂ∞±ÊòØÊ±ÇÔºöÂ¶Ç‰Ωï‰ºòÂåñÂèÇÊï∞ÔºåËÉΩÂ§üËÆ©ÊçüÂ§±ÂáΩÊï∞ÁöÑÂÄºÊúÄÂ∞è„ÄÇ Ê≠§Êó∂Ëøô‰∏™ÈóÆÈ¢òÂ∞±Ë¢´ËΩ¨Âåñ‰∏∫‰∏Ä‰∏™‰ºòÂåñÈóÆÈ¢ò„ÄÇ‰∏Ä‰∏™Â∏∏Áî®ÊñπÊ≥ïÂ∞±ÊòØÈ´òÁ≠âÊï∞Â≠¶‰∏≠ÁöÑÊ±ÇÂØºÔºå‰ΩÜÊòØËøôÈáåÁöÑÈóÆÈ¢òÁî±‰∫éÂèÇÊï∞‰∏çÊ≠¢‰∏Ä‰∏™ÔºåÊ±ÇÂØºÂêéËÆ°ÁÆóÂØºÊï∞Á≠â‰∫é0ÁöÑËøêÁÆóÈáèÂæàÂ§ßÔºåÊâÄ‰ª•‰∏ÄËà¨Êù•ËØ¥Ëß£ÂÜ≥Ëøô‰∏™‰ºòÂåñÈóÆÈ¢ò‰ΩøÁî®ÁöÑÊòØÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï„ÄÇÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊØèÊ¨°ËÆ°ÁÆóÂèÇÊï∞Âú®ÂΩìÂâçÁöÑÊ¢ØÂ∫¶ÔºåÁÑ∂ÂêéËÆ©ÂèÇÊï∞ÂêëÁùÄÊ¢ØÂ∫¶ÁöÑÂèçÊñπÂêëÂâçËøõ‰∏ÄÊÆµË∑ùÁ¶ªÔºå‰∏çÊñ≠ÈáçÂ§çÔºåÁõ¥Âà∞Ê¢ØÂ∫¶Êé•ËøëÈõ∂Êó∂Êà™Ê≠¢„ÄÇ‰∏ÄËà¨Ëøô‰∏™Êó∂ÂÄôÔºåÊâÄÊúâÁöÑÂèÇÊï∞ÊÅ∞Â•ΩËææÂà∞‰ΩøÊçüÂ§±ÂáΩÊï∞ËææÂà∞‰∏Ä‰∏™ÊúÄ‰ΩéÂÄºÁöÑÁä∂ÊÄÅ„ÄÇ Âú®Á•ûÁªèÁΩëÁªúÊ®°Âûã‰∏≠ÔºåÁî±‰∫éÁªìÊûÑÂ§çÊùÇÔºåÊØèÊ¨°ËÆ°ÁÆóÊ¢ØÂ∫¶ÁöÑ‰ª£‰ª∑ÂæàÂ§ß„ÄÇÂõ†Ê≠§ËøòÈúÄË¶Å‰ΩøÁî®ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï„ÄÇÂèçÂêë‰º†Êí≠ÁÆóÊ≥ïÊòØÂà©Áî®‰∫ÜÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑËøõË°åÁöÑËÆ°ÁÆó„ÄÇ‰∏ç‰∏ÄÊ¨°ËÆ°ÁÆóÊâÄÊúâÂèÇÊï∞ÁöÑÊ¢ØÂ∫¶ÔºåËÄåÊòØ‰ªéÂêéÂæÄÂâç„ÄÇÈ¶ñÂÖàËÆ°ÁÆóËæìÂá∫Â±ÇÁöÑÊ¢ØÂ∫¶ÔºåÁÑ∂ÂêéÊòØÁ¨¨‰∫å‰∏™ÂèÇÊï∞Áü©ÈòµÁöÑÊ¢ØÂ∫¶ÔºåÊé•ÁùÄÊòØ‰∏≠Èó¥Â±ÇÁöÑÊ¢ØÂ∫¶ÔºåÂÜçÁÑ∂ÂêéÊòØÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞Áü©ÈòµÁöÑÊ¢ØÂ∫¶ÔºåÊúÄÂêéÊòØËæìÂÖ•Â±ÇÁöÑÊ¢ØÂ∫¶„ÄÇËÆ°ÁÆóÁªìÊùü‰ª•ÂêéÔºåÊâÄË¶ÅÁöÑ‰∏§‰∏™ÂèÇÊï∞Áü©ÈòµÁöÑÊ¢ØÂ∫¶Â∞±ÈÉΩÊúâ‰∫Ü„ÄÇ ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ïÂèØ‰ª•Áõ¥ËßÇÁöÑÁêÜËß£‰∏∫‰∏ãÂõæ„ÄÇÊ¢ØÂ∫¶ÁöÑËÆ°ÁÆó‰ªéÂêéÂæÄÂâçÔºå‰∏ÄÂ±ÇÂ±ÇÂèçÂêë‰º†Êí≠„ÄÇÂâçÁºÄE‰ª£Ë°®ÁùÄÁõ∏ÂØπÂØºÊï∞ÁöÑÊÑèÊÄù„ÄÇÂõæ27 ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï&nbsp; ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ïÁöÑÂêØÁ§∫ÊòØÊï∞Â≠¶‰∏≠ÁöÑÈìæÂºèÊ≥ïÂàô„ÄÇÂú®Ê≠§ÈúÄË¶ÅËØ¥ÊòéÁöÑÊòØÔºåÂ∞ΩÁÆ°Êó©ÊúüÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂‰∫∫ÂëòÂä™Âäõ‰ªéÁîüÁâ©Â≠¶‰∏≠ÂæóÂà∞ÂêØÂèëÔºå‰ΩÜ‰ªéBPÁÆóÊ≥ïÂºÄÂßãÔºåÁ†îÁ©∂ËÄÖ‰ª¨Êõ¥Â§öÂú∞‰ªéÊï∞Â≠¶‰∏äÂØªÊ±ÇÈóÆÈ¢òÁöÑÊúÄ‰ºòËß£„ÄÇ‰∏çÂÜçÁõ≤ÁõÆÊ®°Êãü‰∫∫ËÑëÁΩëÁªúÊòØÁ•ûÁªèÁΩëÁªúÁ†îÁ©∂Ëµ∞ÂêëÊàêÁÜüÁöÑÊ†áÂøó„ÄÇÊ≠£Â¶ÇÁßëÂ≠¶ÂÆ∂‰ª¨ÂèØ‰ª•‰ªéÈ∏üÁ±ªÁöÑÈ£ûË°å‰∏≠ÂæóÂà∞ÂêØÂèëÔºå‰ΩÜÊ≤°ÊúâÂøÖË¶Å‰∏ÄÂÆöË¶ÅÂÆåÂÖ®Ê®°ÊãüÈ∏üÁ±ªÁöÑÈ£ûË°åÊñπÂºèÔºå‰πüËÉΩÂà∂ÈÄ†ÂèØ‰ª•È£ûÂ§©ÁöÑÈ£ûÊú∫„ÄÇ ‰ºòÂåñÈóÆÈ¢òÂè™ÊòØËÆ≠ÁªÉ‰∏≠ÁöÑ‰∏Ä‰∏™ÈÉ®ÂàÜ„ÄÇÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢ò‰πãÊâÄ‰ª•Áß∞‰∏∫Â≠¶‰π†ÈóÆÈ¢òÔºåËÄå‰∏çÊòØ‰ºòÂåñÈóÆÈ¢òÔºåÂ∞±ÊòØÂõ†‰∏∫ÂÆÉ‰∏ç‰ªÖË¶ÅÊ±ÇÊï∞ÊçÆÂú®ËÆ≠ÁªÉÈõÜ‰∏äÊ±ÇÂæó‰∏Ä‰∏™ËæÉÂ∞èÁöÑËØØÂ∑ÆÔºåÂú®ÊµãËØïÈõÜ‰∏ä‰πüË¶ÅË°®Áé∞Â•Ω„ÄÇÂõ†‰∏∫Ê®°ÂûãÊúÄÁªàÊòØË¶ÅÈÉ®ÁΩ≤Âà∞Ê≤°ÊúâËßÅËøáËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁúüÂÆûÂú∫ÊôØ„ÄÇÊèêÂçáÊ®°ÂûãÂú®ÊµãËØïÈõÜ‰∏äÁöÑÈ¢ÑÊµãÊïàÊûúÁöÑ‰∏ªÈ¢òÂè´ÂÅöÊ≥õÂåñÔºàgeneralizationÔºâÔºåÁõ∏ÂÖ≥ÊñπÊ≥ïË¢´Áß∞‰ΩúÊ≠£ÂàôÂåñÔºàregularizationÔºâ„ÄÇÁ•ûÁªèÁΩëÁªú‰∏≠Â∏∏Áî®ÁöÑÊ≥õÂåñÊäÄÊúØÊúâÊùÉÈáçË°∞ÂáèÁ≠â„ÄÇ 5.ÂΩ±Âìç ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÂú®Â§ö‰∏™Âú∞ÊñπÁöÑÂ∫îÁî®ËØ¥Êòé‰∫ÜÂÖ∂ÊïàÁî®‰∏é‰ª∑ÂÄº„ÄÇ10Âπ¥ÂâçÂõ∞Êâ∞Á•ûÁªèÁΩëÁªúÁïåÁöÑÂºÇÊàñÈóÆÈ¢òË¢´ËΩªÊùæËß£ÂÜ≥„ÄÇÁ•ûÁªèÁΩëÁªúÂú®Ëøô‰∏™Êó∂ÂÄôÔºåÂ∑≤ÁªèÂèØ‰ª•ÂèëÂäõ‰∫éËØ≠Èü≥ËØÜÂà´ÔºåÂõæÂÉèËØÜÂà´ÔºåËá™Âä®È©æÈ©∂Á≠âÂ§ö‰∏™È¢ÜÂüü„ÄÇ ÂéÜÂè≤ÊÄªÊòØÊÉä‰∫∫ÁöÑÁõ∏‰ººÔºåÁ•ûÁªèÁΩëÁªúÁöÑÂ≠¶ËÄÖ‰ª¨ÂÜçÊ¨°Áôª‰∏ä‰∫Ü„ÄäÁ∫ΩÁ∫¶Êó∂Êä•„ÄãÁöÑ‰∏ìËÆø„ÄÇ‰∫∫‰ª¨ËÆ§‰∏∫Á•ûÁªèÁΩëÁªúÂèØ‰ª•Ëß£ÂÜ≥ËÆ∏Â§öÈóÆÈ¢ò„ÄÇÂ∞±ËøûÂ®±‰πêÁïåÈÉΩÂºÄÂßãÂèóÂà∞‰∫ÜÂΩ±ÂìçÔºåÂΩìÂπ¥ÁöÑ„ÄäÁªàÁªìËÄÖ„ÄãÁîµÂΩ±‰∏≠ÁöÑÈòøËØ∫ÈÉΩËµ∂Êó∂È´¶Âú∞ËØ¥‰∏ÄÂè•ÔºöÊàëÁöÑCPUÊòØ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÂ§ÑÁêÜÂô®Ôºå‰∏Ä‰∏™‰ºöÂ≠¶‰π†ÁöÑËÆ°ÁÆóÊú∫„ÄÇ ‰ΩÜÊòØÁ•ûÁªèÁΩëÁªú‰ªçÁÑ∂Â≠òÂú®Ëã•Âπ≤ÁöÑÈóÆÈ¢òÔºöÂ∞ΩÁÆ°‰ΩøÁî®‰∫ÜBPÁÆóÊ≥ïÔºå‰∏ÄÊ¨°Á•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉ‰ªçÁÑ∂ËÄóÊó∂Â§™‰πÖÔºåËÄå‰∏îÂõ∞Êâ∞ËÆ≠ÁªÉ‰ºòÂåñÁöÑ‰∏Ä‰∏™ÈóÆÈ¢òÂ∞±ÊòØÂ±ÄÈÉ®ÊúÄ‰ºòËß£ÈóÆÈ¢òÔºåËøô‰ΩøÂæóÁ•ûÁªèÁΩëÁªúÁöÑ‰ºòÂåñËæÉ‰∏∫Âõ∞Èöæ„ÄÇÂêåÊó∂ÔºåÈöêËóèÂ±ÇÁöÑËäÇÁÇπÊï∞ÈúÄË¶ÅË∞ÉÂèÇÔºåËøô‰ΩøÂæó‰ΩøÁî®‰∏çÂ§™Êñπ‰æøÔºåÂ∑•Á®ãÂíåÁ†îÁ©∂‰∫∫ÂëòÂØπÊ≠§Â§öÊúâÊä±ÊÄ®„ÄÇ 90Âπ¥‰ª£‰∏≠ÊúüÔºåÁî±VapnikÁ≠â‰∫∫ÂèëÊòéÁöÑSVMÔºàSupport Vector MachinesÔºåÊîØÊåÅÂêëÈáèÊú∫ÔºâÁÆóÊ≥ïËØûÁîüÔºåÂæàÂø´Â∞±Âú®Ëã•Âπ≤‰∏™ÊñπÈù¢‰ΩìÁé∞Âá∫‰∫ÜÂØπÊØîÁ•ûÁªèÁΩëÁªúÁöÑ‰ºòÂäøÔºöÊó†ÈúÄË∞ÉÂèÇÔºõÈ´òÊïàÔºõÂÖ®Â±ÄÊúÄ‰ºòËß£„ÄÇÂü∫‰∫é‰ª•‰∏äÁßçÁßçÁêÜÁî±ÔºåSVMËøÖÈÄüÊâìË¥•‰∫ÜÁ•ûÁªèÁΩëÁªúÁÆóÊ≥ïÊàê‰∏∫‰∏ªÊµÅ„ÄÇÂõæ28 Vladimir Vapnik&nbsp; Á•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂ÂÜçÊ¨°Èô∑ÂÖ•‰∫ÜÂÜ∞Ê≤≥Êúü„ÄÇÂΩìÊó∂ÔºåÂè™Ë¶Å‰Ω†ÁöÑËÆ∫Êñá‰∏≠ÂåÖÂê´Á•ûÁªèÁΩëÁªúÁõ∏ÂÖ≥ÁöÑÂ≠óÁúºÔºåÈùûÂ∏∏ÂÆπÊòìË¢´‰ºöËÆÆÂíåÊúüÂàäÊãíÊî∂ÔºåÁ†îÁ©∂ÁïåÈÇ£Êó∂ÂØπÁ•ûÁªèÁΩëÁªúÁöÑ‰∏çÂæÖËßÅÂèØÊÉ≥ËÄåÁü•„ÄÇ&nbsp;‰∫î. Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÊ∑±Â∫¶Â≠¶‰π†Ôºâ 1.ÂºïÂ≠ê Âú®Ë¢´‰∫∫ÊëíÂºÉÁöÑ10Âπ¥‰∏≠ÔºåÊúâÂá†‰∏™Â≠¶ËÄÖ‰ªçÁÑ∂Âú®ÂùöÊåÅÁ†îÁ©∂„ÄÇËøôÂÖ∂‰∏≠ÁöÑÊ£ãÊâãÂ∞±ÊòØÂä†ÊãøÂ§ßÂ§ö‰º¶Â§öÂ§ßÂ≠¶ÁöÑGeoffery HintonÊïôÊéà„ÄÇ 2006Âπ¥ÔºåHintonÂú®„ÄäScience„ÄãÂíåÁõ∏ÂÖ≥ÊúüÂàä‰∏äÂèëË°®‰∫ÜËÆ∫ÊñáÔºåÈ¶ñÊ¨°ÊèêÂá∫‰∫Ü‚ÄúÊ∑±Â∫¶‰ø°ÂøµÁΩëÁªú‚ÄùÁöÑÊ¶ÇÂøµ„ÄÇ‰∏é‰º†ÁªüÁöÑËÆ≠ÁªÉÊñπÂºè‰∏çÂêåÔºå‚ÄúÊ∑±Â∫¶‰ø°ÂøµÁΩëÁªú‚ÄùÊúâ‰∏Ä‰∏™‚ÄúÈ¢ÑËÆ≠ÁªÉ‚ÄùÔºàpre-trainingÔºâÁöÑËøáÁ®ãÔºåËøôÂèØ‰ª•Êñπ‰æøÁöÑËÆ©Á•ûÁªèÁΩëÁªú‰∏≠ÁöÑÊùÉÂÄºÊâæÂà∞‰∏Ä‰∏™Êé•ËøëÊúÄ‰ºòËß£ÁöÑÂÄºÔºå‰πãÂêéÂÜç‰ΩøÁî®‚ÄúÂæÆË∞É‚Äù(fine-tuning)ÊäÄÊúØÊù•ÂØπÊï¥‰∏™ÁΩëÁªúËøõË°å‰ºòÂåñËÆ≠ÁªÉ„ÄÇËøô‰∏§‰∏™ÊäÄÊúØÁöÑËøêÁî®Â§ßÂπÖÂ∫¶ÂáèÂ∞ë‰∫ÜËÆ≠ÁªÉÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúÁöÑÊó∂Èó¥„ÄÇ‰ªñÁªôÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúÁõ∏ÂÖ≥ÁöÑÂ≠¶‰π†ÊñπÊ≥ïËµã‰∫à‰∫Ü‰∏Ä‰∏™Êñ∞ÂêçËØç‚Äì‚ÄúÊ∑±Â∫¶Â≠¶‰π†‚Äù„ÄÇ&nbsp; ÂæàÂø´ÔºåÊ∑±Â∫¶Â≠¶‰π†Âú®ËØ≠Èü≥ËØÜÂà´È¢ÜÂüüÊöÇÈú≤Â§¥Ëßí„ÄÇÊé•ÁùÄÔºå2012Âπ¥ÔºåÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÂèàÂú®ÂõæÂÉèËØÜÂà´È¢ÜÂüüÂ§ßÂ±ïÊã≥ËÑö„ÄÇHinton‰∏é‰ªñÁöÑÂ≠¶ÁîüÂú®ImageNetÁ´ûËµõ‰∏≠ÔºåÁî®Â§öÂ±ÇÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÊàêÂäüÂú∞ÂØπÂåÖÂê´‰∏ÄÂçÉÁ±ªÂà´ÁöÑ‰∏ÄÁôæ‰∏áÂº†ÂõæÁâáËøõË°å‰∫ÜËÆ≠ÁªÉÔºåÂèñÂæó‰∫ÜÂàÜÁ±ªÈîôËØØÁéá15%ÁöÑÂ•ΩÊàêÁª©ÔºåËøô‰∏™ÊàêÁª©ÊØîÁ¨¨‰∫åÂêçÈ´ò‰∫ÜËøë11‰∏™ÁôæÂàÜÁÇπÔºåÂÖÖÂàÜËØÅÊòé‰∫ÜÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊïàÊûúÁöÑ‰ºòË∂äÊÄß„ÄÇ Âú®Ëøô‰πãÂêéÔºåÂÖ≥‰∫éÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂‰∏éÂ∫îÁî®‰∏çÊñ≠Ê∂åÁé∞„ÄÇÂõæ29 Geoffery Hinton&nbsp;&nbsp; Áî±‰∫éÁØáÂπÖÂéüÂõ†ÔºåÊú¨Êñá‰∏ç‰ªãÁªçCNNÔºàConventional Neural NetworkÔºåÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºâ‰∏éRNNÔºàRecurrent Neural NetworkÔºåÈÄíÂΩíÁ•ûÁªèÁΩëÁªúÔºâÁöÑÊû∂ÊûÑÔºå‰∏ãÈù¢Êàë‰ª¨Âè™ËÆ®ËÆ∫ÊôÆÈÄöÁöÑÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªú„ÄÇ 2.ÁªìÊûÑ Êàë‰ª¨Âª∂Áª≠‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑÊñπÂºèÊù•ËÆæËÆ°‰∏Ä‰∏™Â§öÂ±ÇÁ•ûÁªèÁΩëÁªú„ÄÇ Âú®‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑËæìÂá∫Â±ÇÂêéÈù¢ÔºåÁªßÁª≠Ê∑ªÂä†Â±ÇÊ¨°„ÄÇÂéüÊù•ÁöÑËæìÂá∫Â±ÇÂèòÊàê‰∏≠Èó¥Â±ÇÔºåÊñ∞Âä†ÁöÑÂ±ÇÊ¨°Êàê‰∏∫Êñ∞ÁöÑËæìÂá∫Â±Ç„ÄÇÊâÄ‰ª•ÂèØ‰ª•ÂæóÂà∞‰∏ãÂõæ„ÄÇÂõæ30 Â§öÂ±ÇÁ•ûÁªèÁΩëÁªú&nbsp; ‰æùÁÖßËøôÊ†∑ÁöÑÊñπÂºè‰∏çÊñ≠Ê∑ªÂä†ÔºåÊàë‰ª¨ÂèØ‰ª•ÂæóÂà∞Êõ¥Â§öÂ±ÇÁöÑÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªú„ÄÇÂÖ¨ÂºèÊé®ÂØºÁöÑËØùÂÖ∂ÂÆûË∑ü‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁ±ª‰ººÔºå‰ΩøÁî®Áü©ÈòµËøêÁÆóÁöÑËØùÂ∞±‰ªÖ‰ªÖÊòØÂä†‰∏Ä‰∏™ÂÖ¨ÂºèËÄåÂ∑≤„ÄÇ Âú®Â∑≤Áü•ËæìÂÖ•a(1)ÔºåÂèÇÊï∞W(1)ÔºåW(2)ÔºåW(3)ÁöÑÊÉÖÂÜµ‰∏ãÔºåËæìÂá∫zÁöÑÊé®ÂØºÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö&nbsp; &nbsp; &nbsp;g(W(1)&nbsp;&nbsp;a(1)) =&nbsp;a(2);&nbsp;&nbsp; &nbsp; g(W(2)&nbsp;&nbsp;a(2)) =&nbsp;a(3);g(W(3)&nbsp;&nbsp;a(3)) = z;&nbsp; Â§öÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåËæìÂá∫‰πüÊòØÊåâÁÖß‰∏ÄÂ±Ç‰∏ÄÂ±ÇÁöÑÊñπÂºèÊù•ËÆ°ÁÆó„ÄÇ‰ªéÊúÄÂ§ñÈù¢ÁöÑÂ±ÇÂºÄÂßãÔºåÁÆóÂá∫ÊâÄÊúâÂçïÂÖÉÁöÑÂÄº‰ª•ÂêéÔºåÂÜçÁªßÁª≠ËÆ°ÁÆóÊõ¥Ê∑±‰∏ÄÂ±Ç„ÄÇÂè™ÊúâÂΩìÂâçÂ±ÇÊâÄÊúâÂçïÂÖÉÁöÑÂÄºÈÉΩËÆ°ÁÆóÂÆåÊØï‰ª•ÂêéÔºåÊâç‰ºöÁÆó‰∏ã‰∏ÄÂ±Ç„ÄÇÊúâÁÇπÂÉèËÆ°ÁÆóÂêëÂâç‰∏çÊñ≠Êé®ËøõÁöÑÊÑüËßâ„ÄÇÊâÄ‰ª•Ëøô‰∏™ËøáÁ®ãÂè´ÂÅö‚ÄúÊ≠£Âêë‰º†Êí≠‚Äù„ÄÇ ‰∏ãÈù¢ËÆ®ËÆ∫‰∏Ä‰∏ãÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÂèÇÊï∞„ÄÇ È¶ñÂÖàÊàë‰ª¨ÁúãÁ¨¨‰∏ÄÂº†ÂõæÔºåÂèØ‰ª•ÁúãÂá∫W(1)‰∏≠Êúâ6‰∏™ÂèÇÊï∞ÔºåW(2)‰∏≠Êúâ4‰∏™ÂèÇÊï∞ÔºåW(3)‰∏≠Êúâ6‰∏™ÂèÇÊï∞ÔºåÊâÄ‰ª•Êï¥‰∏™Á•ûÁªèÁΩëÁªú‰∏≠ÁöÑÂèÇÊï∞Êúâ16‰∏™ÔºàËøôÈáåÊàë‰ª¨‰∏çËÄÉËôëÂÅèÁΩÆËäÇÁÇπÔºå‰∏ãÂêåÔºâ„ÄÇ&nbsp;Âõæ31 Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàËæÉÂ∞ëÂèÇÊï∞Ôºâ&nbsp; ÂÅáËÆæÊàë‰ª¨Â∞Ü‰∏≠Èó¥Â±ÇÁöÑËäÇÁÇπÊï∞ÂÅö‰∏Ä‰∏ãË∞ÉÊï¥„ÄÇÁ¨¨‰∏Ä‰∏™‰∏≠Èó¥Â±ÇÊîπ‰∏∫3‰∏™ÂçïÂÖÉÔºåÁ¨¨‰∫å‰∏™‰∏≠Èó¥Â±ÇÊîπ‰∏∫4‰∏™ÂçïÂÖÉ„ÄÇ ÁªèËøáË∞ÉÊï¥‰ª•ÂêéÔºåÊï¥‰∏™ÁΩëÁªúÁöÑÂèÇÊï∞ÂèòÊàê‰∫Ü33‰∏™„ÄÇ&nbsp;Âõæ32 Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàËæÉÂ§öÂèÇÊï∞Ôºâ&nbsp; ËôΩÁÑ∂Â±ÇÊï∞‰øùÊåÅ‰∏çÂèòÔºå‰ΩÜÊòØÁ¨¨‰∫å‰∏™Á•ûÁªèÁΩëÁªúÁöÑÂèÇÊï∞Êï∞ÈáèÂç¥ÊòØÁ¨¨‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÁöÑÊé•Ëøë‰∏§ÂÄç‰πãÂ§öÔºå‰ªéËÄåÂ∏¶Êù•‰∫ÜÊõ¥Â•ΩÁöÑË°®Á§∫ÔºàrepresentionÔºâËÉΩÂäõ„ÄÇË°®Á§∫ËÉΩÂäõÊòØÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊÄßË¥®Ôºå‰∏ãÈù¢‰ºöÂÅö‰ªãÁªç„ÄÇ Âú®ÂèÇÊï∞‰∏ÄËá¥ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨‰πüÂèØ‰ª•Ëé∑Âæó‰∏Ä‰∏™‚ÄúÊõ¥Ê∑±‚ÄùÁöÑÁΩëÁªú„ÄÇ&nbsp;Âõæ33 Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÊõ¥Ê∑±ÁöÑÂ±ÇÊ¨°Ôºâ&nbsp; ‰∏äÂõæÁöÑÁΩëÁªú‰∏≠ÔºåËôΩÁÑ∂ÂèÇÊï∞Êï∞Èáè‰ªçÁÑ∂ÊòØ33Ôºå‰ΩÜÂç¥Êúâ4‰∏™‰∏≠Èó¥Â±ÇÔºåÊòØÂéüÊù•Â±ÇÊï∞ÁöÑÊé•Ëøë‰∏§ÂÄç„ÄÇËøôÊÑèÂë≥ÁùÄ‰∏ÄÊ†∑ÁöÑÂèÇÊï∞Êï∞ÈáèÔºåÂèØ‰ª•Áî®Êõ¥Ê∑±ÁöÑÂ±ÇÊ¨°ÂéªË°®Ëææ„ÄÇ 3.ÊïàÊûú ‰∏é‰∏§Â±ÇÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏çÂêå„ÄÇÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÂ±ÇÊï∞Â¢ûÂä†‰∫ÜÂæàÂ§ö„ÄÇ Â¢ûÂä†Êõ¥Â§öÁöÑÂ±ÇÊ¨°Êúâ‰ªÄ‰πàÂ•ΩÂ§ÑÔºüÊõ¥Ê∑±ÂÖ•ÁöÑË°®Á§∫ÁâπÂæÅÔºå‰ª•ÂèäÊõ¥Âº∫ÁöÑÂáΩÊï∞Ê®°ÊãüËÉΩÂäõ„ÄÇ Êõ¥Ê∑±ÂÖ•ÁöÑË°®Á§∫ÁâπÂæÅÂèØ‰ª•ËøôÊ†∑ÁêÜËß£ÔºåÈöèÁùÄÁΩëÁªúÁöÑÂ±ÇÊï∞Â¢ûÂä†ÔºåÊØè‰∏ÄÂ±ÇÂØπ‰∫éÂâç‰∏ÄÂ±ÇÊ¨°ÁöÑÊäΩË±°Ë°®Á§∫Êõ¥Ê∑±ÂÖ•„ÄÇÂú®Á•ûÁªèÁΩëÁªú‰∏≠ÔºåÊØè‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉÂ≠¶‰π†Âà∞ÁöÑÊòØÂâç‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉÂÄºÁöÑÊõ¥ÊäΩË±°ÁöÑË°®Á§∫„ÄÇ‰æãÂ¶ÇÁ¨¨‰∏Ä‰∏™ÈöêËóèÂ±ÇÂ≠¶‰π†Âà∞ÁöÑÊòØ‚ÄúËæπÁºò‚ÄùÁöÑÁâπÂæÅÔºåÁ¨¨‰∫å‰∏™ÈöêËóèÂ±ÇÂ≠¶‰π†Âà∞ÁöÑÊòØÁî±‚ÄúËæπÁºò‚ÄùÁªÑÊàêÁöÑ‚ÄúÂΩ¢Áä∂‚ÄùÁöÑÁâπÂæÅÔºåÁ¨¨‰∏â‰∏™ÈöêËóèÂ±ÇÂ≠¶‰π†Âà∞ÁöÑÊòØÁî±‚ÄúÂΩ¢Áä∂‚ÄùÁªÑÊàêÁöÑ‚ÄúÂõæÊ°à‚ÄùÁöÑÁâπÂæÅÔºåÊúÄÂêéÁöÑÈöêËóèÂ±ÇÂ≠¶‰π†Âà∞ÁöÑÊòØÁî±‚ÄúÂõæÊ°à‚ÄùÁªÑÊàêÁöÑ‚ÄúÁõÆÊ†á‚ÄùÁöÑÁâπÂæÅ„ÄÇÈÄöËøáÊäΩÂèñÊõ¥ÊäΩË±°ÁöÑÁâπÂæÅÊù•ÂØπ‰∫ãÁâ©ËøõË°åÂå∫ÂàÜÔºå‰ªéËÄåËé∑ÂæóÊõ¥Â•ΩÁöÑÂå∫ÂàÜ‰∏éÂàÜÁ±ªËÉΩÂäõ„ÄÇ ÂÖ≥‰∫éÈÄêÂ±ÇÁâπÂæÅÂ≠¶‰π†ÁöÑ‰æãÂ≠êÔºåÂèØ‰ª•ÂèÇËÄÉ‰∏ãÂõæ„ÄÇ&nbsp;Âõæ34 Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÁâπÂæÅÂ≠¶‰π†Ôºâ&nbsp; Êõ¥Âº∫ÁöÑÂáΩÊï∞Ê®°ÊãüËÉΩÂäõÊòØÁî±‰∫éÈöèÁùÄÂ±ÇÊï∞ÁöÑÂ¢ûÂä†ÔºåÊï¥‰∏™ÁΩëÁªúÁöÑÂèÇÊï∞Â∞±Ë∂äÂ§ö„ÄÇËÄåÁ•ûÁªèÁΩëÁªúÂÖ∂ÂÆûÊú¨Ë¥®Â∞±ÊòØÊ®°ÊãüÁâπÂæÅ‰∏éÁõÆÊ†á‰πãÈó¥ÁöÑÁúüÂÆûÂÖ≥Á≥ªÂáΩÊï∞ÁöÑÊñπÊ≥ïÔºåÊõ¥Â§öÁöÑÂèÇÊï∞ÊÑèÂë≥ÁùÄÂÖ∂Ê®°ÊãüÁöÑÂáΩÊï∞ÂèØ‰ª•Êõ¥Âä†ÁöÑÂ§çÊùÇÔºåÂèØ‰ª•ÊúâÊõ¥Â§öÁöÑÂÆπÈáèÔºàcapcityÔºâÂéªÊãüÂêàÁúüÊ≠£ÁöÑÂÖ≥Á≥ª„ÄÇ ÈÄöËøáÁ†îÁ©∂ÂèëÁé∞ÔºåÂú®ÂèÇÊï∞Êï∞Èáè‰∏ÄÊ†∑ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊõ¥Ê∑±ÁöÑÁΩëÁªúÂæÄÂæÄÂÖ∑ÊúâÊØîÊµÖÂ±ÇÁöÑÁΩëÁªúÊõ¥Â•ΩÁöÑËØÜÂà´ÊïàÁéá„ÄÇËøôÁÇπ‰πüÂú®ImageNetÁöÑÂ§öÊ¨°Â§ßËµõ‰∏≠ÂæóÂà∞‰∫ÜËØÅÂÆû„ÄÇ‰ªé2012Âπ¥Ëµ∑ÔºåÊØèÂπ¥Ëé∑ÂæóImageNetÂÜ†ÂÜõÁöÑÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑÂ±ÇÊï∞ÈÄêÂπ¥Â¢ûÂä†Ôºå2015Âπ¥ÊúÄÂ•ΩÁöÑÊñπÊ≥ïGoogleNetÊòØ‰∏Ä‰∏™Â§öËææ22Â±ÇÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇ Âú®ÊúÄÊñ∞‰∏ÄÂ±äÁöÑImageNetÂ§ßËµõ‰∏äÔºåÁõÆÂâçÊãøÂà∞ÊúÄÂ•ΩÊàêÁª©ÁöÑMSRAÂõ¢ÈòüÁöÑÊñπÊ≥ï‰ΩøÁî®ÁöÑÊõ¥ÊòØ‰∏Ä‰∏™Ê∑±Ëææ152Â±ÇÁöÑÁΩëÁªúÔºÅÂÖ≥‰∫éËøô‰∏™ÊñπÊ≥ïÊõ¥Â§öÁöÑ‰ø°ÊÅØÊúâÂÖ¥Ë∂£ÁöÑÂèØ‰ª•Êü•ÈòÖImageNetÁΩëÁ´ô„ÄÇ 4.ËÆ≠ÁªÉ Âú®ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÊó∂ÔºåÊàë‰ª¨‰ΩøÁî®ÁöÑÊøÄÊ¥ªÂáΩÊï∞ÊòØsgnÂáΩÊï∞„ÄÇÂà∞‰∫Ü‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÊó∂ÔºåÊàë‰ª¨‰ΩøÁî®ÁöÑÊúÄÂ§öÁöÑÊòØsigmoidÂáΩÊï∞„ÄÇËÄåÂà∞‰∫ÜÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúÊó∂ÔºåÈÄöËøá‰∏ÄÁ≥ªÂàóÁöÑÁ†îÁ©∂ÂèëÁé∞ÔºåReLUÂáΩÊï∞Âú®ËÆ≠ÁªÉÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúÊó∂ÔºåÊõ¥ÂÆπÊòìÊî∂ÊïõÔºåÂπ∂‰∏îÈ¢ÑÊµãÊÄßËÉΩÊõ¥Â•Ω„ÄÇÂõ†Ê≠§ÔºåÁõÆÂâçÂú®Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÔºåÊúÄÊµÅË°åÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞ÊòØReLUÂáΩÊï∞„ÄÇReLUÂáΩÊï∞‰∏çÊòØ‰º†ÁªüÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞ÔºåËÄåÊòØÂàÜÊÆµÁ∫øÊÄßÂáΩÊï∞„ÄÇÂÖ∂Ë°®ËææÂºèÈùûÂ∏∏ÁÆÄÂçïÔºåÂ∞±ÊòØy=max(x,0)„ÄÇÁÆÄËÄåË®Ä‰πãÔºåÂú®xÂ§ß‰∫é0ÔºåËæìÂá∫Â∞±ÊòØËæìÂÖ•ÔºåËÄåÂú®xÂ∞è‰∫é0Êó∂ÔºåËæìÂá∫Â∞±‰øùÊåÅ‰∏∫0„ÄÇËøôÁßçÂáΩÊï∞ÁöÑËÆæËÆ°ÂêØÂèëÊù•Ëá™‰∫éÁîüÁâ©Á•ûÁªèÂÖÉÂØπ‰∫éÊøÄÂä±ÁöÑÁ∫øÊÄßÂìçÂ∫îÔºå‰ª•ÂèäÂΩì‰Ωé‰∫éÊüê‰∏™ÈòàÂÄºÂêéÂ∞±‰∏çÂÜçÂìçÂ∫îÁöÑÊ®°Êãü„ÄÇ Âú®Â§öÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåËÆ≠ÁªÉÁöÑ‰∏ªÈ¢ò‰ªçÁÑ∂ÊòØ‰ºòÂåñÂíåÊ≥õÂåñ„ÄÇÂΩì‰ΩøÁî®Ë∂≥Â§üÂº∫ÁöÑËÆ°ÁÆóËäØÁâáÔºà‰æãÂ¶ÇGPUÂõæÂΩ¢Âä†ÈÄüÂç°ÔºâÊó∂ÔºåÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰ª•ÂèäÂèçÂêë‰º†Êí≠ÁÆóÊ≥ïÂú®Â§öÂ±ÇÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑËÆ≠ÁªÉ‰∏≠‰ªçÁÑ∂Â∑•‰ΩúÁöÑÂæàÂ•Ω„ÄÇÁõÆÂâçÂ≠¶ÊúØÁïå‰∏ªË¶ÅÁöÑÁ†îÁ©∂Êó¢Âú®‰∫éÂºÄÂèëÊñ∞ÁöÑÁÆóÊ≥ïÔºå‰πüÂú®‰∫éÂØπËøô‰∏§‰∏™ÁÆóÊ≥ïËøõË°å‰∏çÊñ≠ÁöÑ‰ºòÂåñÔºå‰æãÂ¶ÇÔºåÂ¢ûÂä†‰∫Ü‰∏ÄÁßçÂ∏¶Âä®ÈáèÂõ†Â≠êÔºàmomentumÔºâÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï„ÄÇ Âú®Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÔºåÊ≥õÂåñÊäÄÊúØÂèòÁöÑÊØî‰ª•ÂæÄÊõ¥Âä†ÁöÑÈáçË¶Å„ÄÇËøô‰∏ªË¶ÅÊòØÂõ†‰∏∫Á•ûÁªèÁΩëÁªúÁöÑÂ±ÇÊï∞Â¢ûÂä†‰∫ÜÔºåÂèÇÊï∞‰πüÂ¢ûÂä†‰∫ÜÔºåË°®Á§∫ËÉΩÂäõÂ§ßÂπÖÂ∫¶Â¢ûÂº∫ÔºåÂæàÂÆπÊòìÂá∫Áé∞ËøáÊãüÂêàÁé∞Ë±°„ÄÇÂõ†Ê≠§Ê≠£ÂàôÂåñÊäÄÊúØÂ∞±ÊòæÂæóÂçÅÂàÜÈáçË¶Å„ÄÇÁõÆÂâçÔºåDropoutÊäÄÊúØÔºå‰ª•ÂèäÊï∞ÊçÆÊâ©ÂÆπÔºàData-AugmentationÔºâÊäÄÊúØÊòØÁõÆÂâç‰ΩøÁî®ÁöÑÊúÄÂ§öÁöÑÊ≠£ÂàôÂåñÊäÄÊúØ„ÄÇ 5.ÂΩ±Âìç ÁõÆÂâçÔºåÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÂú®‰∫∫Â∑•Êô∫ËÉΩÁïåÂç†ÊçÆÁªüÊ≤ªÂú∞‰Ωç„ÄÇ‰ΩÜÂá°ÊúâÂÖ≥‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∫ß‰∏öÊä•ÈÅìÔºåÂøÖÁÑ∂Á¶ª‰∏çÂºÄÊ∑±Â∫¶Â≠¶‰π†„ÄÇÁ•ûÁªèÁΩëÁªúÁïåÂΩì‰∏ãÁöÑÂõõ‰ΩçÂºïÈ¢ÜËÄÖÈô§‰∫ÜÂâçÊñáÊâÄËØ¥ÁöÑNgÔºåHinton‰ª•Â§ñÔºåËøòÊúâCNNÁöÑÂèëÊòé‰∫∫Yann LecunÔºå‰ª•Âèä„ÄäDeep Learning„ÄãÁöÑ‰ΩúËÄÖBengio„ÄÇ ÂâçÊÆµÊó∂Èó¥‰∏ÄÁõ¥ÂØπ‰∫∫Â∑•Êô∫ËÉΩÊåÅË∞®ÊÖéÊÄÅÂ∫¶ÁöÑÈ©¨ÊñØÂÖãÔºåÊêû‰∫Ü‰∏Ä‰∏™OpenAIÈ°πÁõÆÔºåÈÇÄËØ∑Bengio‰Ωú‰∏∫È´òÁ∫ßÈ°æÈóÆ„ÄÇÈ©¨ÊñØÂÖãËÆ§‰∏∫Ôºå‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØ‰∏çÂ∫îËØ•ÊéåÊè°Âú®Â§ßÂÖ¨Âè∏Â¶ÇGoogleÔºåFacebookÁöÑÊâãÈáåÔºåÊõ¥Â∫îËØ•‰Ωú‰∏∫‰∏ÄÁßçÂºÄÊîæÊäÄÊúØÔºåËÆ©ÊâÄÊúâ‰∫∫ÈÉΩÂèØ‰ª•ÂèÇ‰∏éÁ†îÁ©∂„ÄÇÈ©¨ÊñØÂÖãÁöÑËøôÁßçÁ≤æÁ•ûÂÄºÂæóËÆ©‰∫∫Êï¨‰Ω©„ÄÇ&nbsp; &nbsp;Âõæ35 Yann LeCunÔºàÂ∑¶ÔºâÂíå&nbsp;Yoshua BengioÔºàÂè≥Ôºâ&nbsp; Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂‰ªçÂú®ËøõË°å‰∏≠„ÄÇÁé∞Âú®ÊúÄ‰∏∫ÁÅ´ÁÉ≠ÁöÑÁ†îÁ©∂ÊäÄÊúØÂåÖÊã¨RNNÔºåLSTMÁ≠âÔºåÁ†îÁ©∂ÊñπÂêëÂàôÊòØÂõæÂÉèÁêÜËß£ÊñπÈù¢„ÄÇÂõæÂÉèÁêÜËß£ÊäÄÊúØÊòØÁªôËÆ°ÁÆóÊú∫‰∏ÄÂπÖÂõæÁâáÔºåËÆ©ÂÆÉÁî®ËØ≠Ë®ÄÊù•Ë°®ËææËøôÂπÖÂõæÁâáÁöÑÊÑèÊÄù„ÄÇImageNetÁ´ûËµõ‰πüÂú®‰∏çÊñ≠Âè¨ÂºÄÔºåÊúâÊõ¥Â§öÁöÑÊñπÊ≥ïÊ∂åÁé∞Âá∫Êù•ÔºåÂà∑Êñ∞‰ª•ÂæÄÁöÑÊ≠£Á°ÆÁéá„ÄÇ&nbsp;ÂÖ≠. ÂõûÈ°æ 1.ÂΩ±Âìç Êàë‰ª¨ÂõûÈ°æ‰∏Ä‰∏ãÁ•ûÁªèÁΩëÁªúÂèëÂ±ïÁöÑÂéÜÁ®ã„ÄÇÁ•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïÂéÜÂè≤Êõ≤ÊäòËç°ÊºæÔºåÊó¢ÊúâË¢´‰∫∫Êçß‰∏äÂ§©ÁöÑÊó∂ÂàªÔºå‰πüÊúâÊëîËêΩÂú®Ë°óÂ§¥Êó†‰∫∫ÈóÆÊ¥•ÁöÑÊó∂ÊÆµÔºå‰∏≠Èó¥ÁªèÂéÜ‰∫ÜÊï∞Ê¨°Â§ßËµ∑Â§ßËêΩ„ÄÇ ‰ªéÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºàÊÑüÁü•Âô®ÔºâÂºÄÂßãÔºåÂà∞ÂåÖÂê´‰∏Ä‰∏™ÈöêËóèÂ±ÇÁöÑ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºåÂÜçÂà∞Â§öÂ±ÇÁöÑÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÔºå‰∏ÄÂÖ±Êúâ‰∏âÊ¨°ÂÖ¥Ëµ∑ËøáÁ®ã„ÄÇËØ¶ËßÅ‰∏ãÂõæ„ÄÇ&nbsp;Âõæ36 ‰∏âËµ∑‰∏âËêΩÁöÑÁ•ûÁªèÁΩëÁªú&nbsp; ‰∏äÂõæ‰∏≠ÁöÑÈ°∂ÁÇπ‰∏éË∞∑Â∫ïÂèØ‰ª•Áúã‰ΩúÁ•ûÁªèÁΩëÁªúÂèëÂ±ïÁöÑÈ´òÂ≥∞‰∏é‰ΩéË∞∑„ÄÇÂõæ‰∏≠ÁöÑÊ®™ËΩ¥ÊòØÊó∂Èó¥Ôºå‰ª•Âπ¥‰∏∫Âçï‰Ωç„ÄÇÁ∫µËΩ¥ÊòØ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÂΩ±ÂìçÂäõÁöÑÁ§∫ÊÑèË°®Á§∫„ÄÇÂ¶ÇÊûúÊää1949Âπ¥HebbÊ®°ÂûãÊèêÂá∫Âà∞1958Âπ¥ÁöÑÊÑüÁü•Êú∫ËØûÁîüËøô‰∏™10Âπ¥ËßÜ‰∏∫ËêΩ‰∏ãÔºàÊ≤°ÊúâÂÖ¥Ëµ∑ÔºâÁöÑËØùÔºåÈÇ£‰πàÁ•ûÁªèÁΩëÁªúÁÆóÊòØÁªèÂéÜ‰∫Ü‚Äú‰∏âËµ∑‰∏âËêΩ‚ÄùËøôÊ†∑‰∏Ä‰∏™ËøáÁ®ãÔºåË∑ü‚ÄúÂ∞èÂπ≥‚ÄùÂêåÂøóÁ±ª‰ºº„ÄÇ‰øóËØùËØ¥ÔºåÂ§©Â∞ÜÈôçÂ§ß‰ªª‰∫éÊñØ‰∫∫‰πüÔºåÂøÖÂÖàËã¶ÂÖ∂ÂøÉÂøóÔºåÂä≥ÂÖ∂Á≠ãÈ™®„ÄÇÁªèÂéÜËøáÂ¶ÇÊ≠§Â§öÊ≥¢ÊäòÁöÑÁ•ûÁªèÁΩëÁªúËÉΩÂ§üÂú®Áé∞Èò∂ÊÆµÂèñÂæóÊàêÂäü‰πüÂèØ‰ª•Ë¢´ÁúãÂÅöÊòØÁ£®Á†∫ÁöÑÁßØÁ¥ØÂêß„ÄÇ ÂéÜÂè≤ÊúÄÂ§ßÁöÑÂ•ΩÂ§ÑÊòØÂèØ‰ª•ÁªôÁé∞Âú®ÂÅöÂèÇËÄÉ„ÄÇÁßëÂ≠¶ÁöÑÁ†îÁ©∂ÂëàÁé∞Ëû∫ÊóãÂΩ¢‰∏äÂçáÁöÑËøáÁ®ãÔºå‰∏çÂèØËÉΩ‰∏ÄÂ∏ÜÈ£éÈ°∫„ÄÇÂêåÊó∂ÔºåËøô‰πüÁªôÁé∞Âú®ËøáÂàÜÁÉ≠Ë°∑Ê∑±Â∫¶Â≠¶‰π†‰∏é‰∫∫Â∑•Êô∫ËÉΩÁöÑ‰∫∫Êï≤ÂìçË≠¶ÈíüÔºåÂõ†‰∏∫Ëøô‰∏çÊòØÁ¨¨‰∏ÄÊ¨°‰∫∫‰ª¨Âõ†‰∏∫Á•ûÁªèÁΩëÁªúËÄåÁñØÁãÇ‰∫Ü„ÄÇ1958Âπ¥Âà∞1969Âπ¥Ôºå‰ª•Âèä1985Âπ¥Âà∞1995ÔºåËøô‰∏§‰∏™ÂçÅÂπ¥Èó¥‰∫∫‰ª¨ÂØπ‰∫éÁ•ûÁªèÁΩëÁªú‰ª•Âèä‰∫∫Â∑•Êô∫ËÉΩÁöÑÊúüÂæÖÂπ∂‰∏çÁé∞Âú®‰ΩéÔºåÂèØÁªìÊûúÂ¶Ç‰ΩïÂ§ßÂÆ∂‰πüËÉΩÁúãÁöÑÂæàÊ∏ÖÊ•ö„ÄÇ Âõ†Ê≠§ÔºåÂÜ∑ÈùôÊâçÊòØÂØπÂæÖÁõÆÂâçÊ∑±Â∫¶Â≠¶‰π†ÁÉ≠ÊΩÆÁöÑÊúÄÂ•ΩÂäûÊ≥ï„ÄÇÂ¶ÇÊûúÂõ†‰∏∫Ê∑±Â∫¶Â≠¶‰π†ÁÅ´ÁÉ≠ÔºåÊàñËÄÖÂèØ‰ª•Êúâ‚ÄúÈí±ÊôØ‚ÄùÂ∞±‰∏ÄÁ™ùËúÇÁöÑÊ∂åÂÖ•ÔºåÈÇ£‰πàÊúÄÁªàÁöÑÂèóÂÆ≥‰∫∫Âè™ËÉΩÊòØËá™Â∑±„ÄÇÁ•ûÁªèÁΩëÁªúÁïåÂ∑≤Áªè‰∏§Ê¨°ÊúâË¢´‰∫∫‰ª¨Êçß‰∏äÂ§©‰∫ÜÁöÑÂ¢ÉÂÜµÔºåÁõ∏‰ø°‰πüÂØπ‰∫éÊçßÂæóË∂äÈ´òÔºåÊëîÂæóË∂äÊÉ®ËøôÂè•ËØùÊ∑±Êúâ‰Ωì‰ºö„ÄÇÂõ†Ê≠§ÔºåÁ•ûÁªèÁΩëÁªúÁïåÁöÑÂ≠¶ËÄÖ‰πüÂøÖÈ°ªÁªôËøôËÇ°ÁÉ≠ÊΩÆÊµá‰∏ä‰∏ÄÁõÜÊ∞¥Ôºå‰∏çË¶ÅËÆ©Â™í‰Ωì‰ª•ÂèäÊäïËµÑÂÆ∂‰ª¨ËøáÂàÜÁöÑÈ´òÁúãËøôÈó®ÊäÄÊúØ„ÄÇÂæàÊúâÂèØËÉΩÔºå‰∏âÂçÅÂπ¥Ê≤≥‰∏úÔºå‰∏âÂçÅÂπ¥Ê≤≥Ë•øÔºåÂú®Âá†Âπ¥ÂêéÔºåÁ•ûÁªèÁΩëÁªúÂ∞±ÂÜçÊ¨°Èô∑ÂÖ•Ë∞∑Â∫ï„ÄÇÊ†πÊçÆ‰∏äÂõæÁöÑÂéÜÂè≤Êõ≤Á∫øÂõæÔºåËøôÊòØÂæàÊúâÂèØËÉΩÁöÑ„ÄÇ 2.ÊïàÊûú ‰∏ãÈù¢ËØ¥‰∏Ä‰∏ãÁ•ûÁªèÁΩëÁªú‰∏∫‰ªÄ‰πàËÉΩËøô‰πàÁÅ´ÁÉ≠ÔºüÁÆÄËÄåË®Ä‰πãÔºåÂ∞±ÊòØÂÖ∂Â≠¶‰π†ÊïàÊûúÁöÑÂº∫Â§ß„ÄÇÈöèÁùÄÁ•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïÔºåÂÖ∂Ë°®Á§∫ÊÄßËÉΩË∂äÊù•Ë∂äÂº∫„ÄÇ ‰ªéÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºåÂà∞‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºåÂÜçÂà∞Â§öÂ±ÇÁ•ûÁªèÁΩëÁªúÔºå‰∏ãÂõæËØ¥Êòé‰∫ÜÔºåÈöèÁùÄÁΩëÁªúÂ±ÇÊï∞ÁöÑÂ¢ûÂä†Ôºå‰ª•ÂèäÊøÄÊ¥ªÂáΩÊï∞ÁöÑË∞ÉÊï¥ÔºåÁ•ûÁªèÁΩëÁªúÊâÄËÉΩÊãüÂêàÁöÑÂÜ≥Á≠ñÂàÜÁïåÂπ≥Èù¢ÁöÑËÉΩÂäõ„ÄÇ&nbsp;Âõæ37 Ë°®Á§∫ËÉΩÂäõ‰∏çÊñ≠Â¢ûÂº∫&nbsp; ÂèØ‰ª•ÁúãÂá∫ÔºåÈöèÁùÄÂ±ÇÊï∞Â¢ûÂä†ÔºåÂÖ∂ÈùûÁ∫øÊÄßÂàÜÁïåÊãüÂêàËÉΩÂäõ‰∏çÊñ≠Â¢ûÂº∫„ÄÇÂõæ‰∏≠ÁöÑÂàÜÁïåÁ∫øÂπ∂‰∏ç‰ª£Ë°®ÁúüÂÆûËÆ≠ÁªÉÂá∫ÁöÑÊïàÊûúÔºåÊõ¥Â§öÁöÑÊòØÁ§∫ÊÑèÊïàÊûú„ÄÇ Á•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂‰∏éÂ∫îÁî®‰πãÊâÄ‰ª•ËÉΩÂ§ü‰∏çÊñ≠Âú∞ÁÅ´ÁÉ≠ÂèëÂ±ï‰∏ãÂéªÔºå‰∏éÂÖ∂Âº∫Â§ßÁöÑÂáΩÊï∞ÊãüÂêàËÉΩÂäõÊòØÂàÜ‰∏çÂºÄÂÖ≥Á≥ªÁöÑ„ÄÇ 3.Â§ñÂõ† ÂΩìÁÑ∂ÔºåÂÖâÊúâÂº∫Â§ßÁöÑÂÜÖÂú®ËÉΩÂäõÔºåÂπ∂‰∏ç‰∏ÄÂÆöËÉΩÊàêÂäü„ÄÇ‰∏Ä‰∏™ÊàêÂäüÁöÑÊäÄÊúØ‰∏éÊñπÊ≥ïÔºå‰∏ç‰ªÖÈúÄË¶ÅÂÜÖÂõ†ÁöÑ‰ΩúÁî®ÔºåËøòÈúÄË¶ÅÊó∂Âäø‰∏éÁéØÂ¢ÉÁöÑÈÖçÂêà„ÄÇÁ•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïËÉåÂêéÁöÑÂ§ñÂú®ÂéüÂõ†ÂèØ‰ª•Ë¢´ÊÄªÁªì‰∏∫ÔºöÊõ¥Âº∫ÁöÑËÆ°ÁÆóÊÄßËÉΩÔºåÊõ¥Â§öÁöÑÊï∞ÊçÆÔºå‰ª•ÂèäÊõ¥Â•ΩÁöÑËÆ≠ÁªÉÊñπÊ≥ï„ÄÇÂè™ÊúâÊª°Ë∂≥Ëøô‰∫õÊù°‰ª∂Êó∂ÔºåÁ•ûÁªèÁΩëÁªúÁöÑÂáΩÊï∞ÊãüÂêàËÉΩÂäõÊâçËÉΩÂæóÂ∑≤‰ΩìÁé∞ÔºåËßÅ‰∏ãÂõæ„ÄÇ&nbsp;Âõæ38 ÂèëÂ±ïÁöÑÂ§ñÂú®ÂéüÂõ†&nbsp; ‰πãÊâÄ‰ª•Âú®ÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÂπ¥‰ª£ÔºåRosenblatÊó†Ê≥ïÂà∂‰Ωú‰∏Ä‰∏™ÂèåÂ±ÇÂàÜÁ±ªÂô®ÔºåÂ∞±Âú®‰∫éÂΩìÊó∂ÁöÑËÆ°ÁÆóÊÄßËÉΩ‰∏çË∂≥ÔºåMinsky‰πü‰ª•Ê≠§Êù•ÊâìÂéãÁ•ûÁªèÁΩëÁªú„ÄÇ‰ΩÜÊòØMinskyÊ≤°ÊúâÊñôÂà∞Ôºå‰ªÖ‰ªÖ10Âπ¥‰ª•ÂêéÔºåËÆ°ÁÆóÊú∫CPUÁöÑÂø´ÈÄüÂèëÂ±ïÂ∑≤Áªè‰ΩøÂæóÊàë‰ª¨ÂèØ‰ª•ÂÅö‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉÔºåÂπ∂‰∏îËøòÊúâÂø´ÈÄüÁöÑÂ≠¶‰π†ÁÆóÊ≥ïBP„ÄÇ ‰ΩÜÊòØÂú®‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÂø´ÈÄüÊµÅË°åÁöÑÂπ¥‰ª£„ÄÇÊõ¥È´òÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªúÁî±‰∫éËÆ°ÁÆóÊÄßËÉΩÁöÑÈóÆÈ¢òÔºå‰ª•Âèä‰∏Ä‰∫õËÆ°ÁÆóÊñπÊ≥ïÁöÑÈóÆÈ¢òÔºåÂÖ∂‰ºòÂäøÊó†Ê≥ïÂæóÂà∞‰ΩìÁé∞„ÄÇÁõ¥Âà∞2012Âπ¥ÔºåÁ†îÁ©∂‰∫∫ÂëòÂèëÁé∞ÔºåÁî®‰∫éÈ´òÊÄßËÉΩËÆ°ÁÆóÁöÑÂõæÂΩ¢Âä†ÈÄüÂç°ÔºàGPUÔºâÂèØ‰ª•ÊûÅ‰Ω≥Âú∞ÂåπÈÖçÁ•ûÁªèÁΩëÁªúËÆ≠ÁªÉÊâÄÈúÄË¶ÅÁöÑË¶ÅÊ±ÇÔºöÈ´òÂπ∂Ë°åÊÄßÔºåÈ´òÂ≠òÂÇ®ÔºåÊ≤°ÊúâÂ§™Â§öÁöÑÊéßÂà∂ÈúÄÊ±ÇÔºåÈÖçÂêàÈ¢ÑËÆ≠ÁªÉÁ≠âÁÆóÊ≥ïÔºåÁ•ûÁªèÁΩëÁªúÊâçÂæó‰ª•Â§ßÊîæÂÖâÂΩ©„ÄÇ ‰∫íËÅîÁΩëÊó∂‰ª£ÔºåÂ§ßÈáèÁöÑÊï∞ÊçÆË¢´Êî∂ÈõÜÊï¥ÁêÜÔºåÊõ¥Â•ΩÁöÑËÆ≠ÁªÉÊñπÊ≥ï‰∏çÊñ≠Ë¢´ÂèëÁé∞„ÄÇÊâÄÊúâËøô‰∏ÄÂàáÈÉΩÊª°Ë∂≥‰∫ÜÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªúÂèëÊå•ËÉΩÂäõÁöÑÊù°‰ª∂„ÄÇ ‚ÄúÊó∂ÂäøÈÄ†Ëã±ÈõÑ‚ÄùÔºåÊ≠£Â¶ÇHintonÂú®2006Âπ¥ÁöÑËÆ∫ÊñáÈáåËØ¥ÈÅìÁöÑ ‚Äú‚Ä¶&nbsp;provided&nbsp;that&nbsp;computers&nbsp;were&nbsp;fast&nbsp;enough,&nbsp;data&nbsp;sets&nbsp;were&nbsp;big&nbsp;enough,&nbsp;and&nbsp;the&nbsp;initial&nbsp;weights&nbsp;were&nbsp;close&nbsp;enough&nbsp;to&nbsp;a&nbsp;good&nbsp;solution.&nbsp;All&nbsp;three&nbsp;conditions&nbsp;are&nbsp;now&nbsp;satisfied.‚ÄùÔºå&nbsp; Â§ñÂú®Êù°‰ª∂ÁöÑÊª°Ë∂≥‰πüÊòØÁ•ûÁªèÁΩëÁªú‰ªéÁ•ûÁªèÂÖÉÂæó‰ª•ÂèëÂ±ïÂà∞ÁõÆÂâçÁöÑÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑÈáçË¶ÅÂõ†Á¥†„ÄÇ Èô§Ê≠§‰ª•Â§ñÔºå‰∏ÄÈó®ÊäÄÊúØÁöÑÂèëÊâ¨Ê≤°Êúâ‚Äú‰ºØ‰πê‚Äù‰πüÊòØ‰∏çË°åÁöÑ„ÄÇÂú®Á•ûÁªèÁΩëÁªúÊº´ÈïøÁöÑÂéÜÂè≤‰∏≠ÔºåÊ≠£ÊòØÁî±‰∫éËÆ∏Â§öÁ†îÁ©∂‰∫∫ÂëòÁöÑÈî≤ËÄå‰∏çËàçÔºå‰∏çÊñ≠ÈíªÁ†îÔºåÊâçËÉΩÊúâ‰∫ÜÁé∞Âú®ÁöÑÊàêÂ∞±„ÄÇÂâçÊúüÁöÑRosenblatÔºåRumelhartÊ≤°ÊúâËßÅËØÅÂà∞Á•ûÁªèÁΩëÁªúÂ¶Ç‰ªäÁöÑÊµÅË°å‰∏éÂú∞‰Ωç„ÄÇ‰ΩÜÊòØÂú®ÈÇ£‰∏™Êó∂‰ª£Ôºå‰ªñ‰ª¨‰∏∫Á•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïÊâÄÊâì‰∏ãÁöÑÂü∫Á°ÄÔºåÂç¥‰ºöÊ∞∏ËøúÊµÅ‰º†‰∏ãÂéªÔºå‰∏ç‰ºöÈÄÄËâ≤„ÄÇ&nbsp;‰∏É. Â±ïÊúõ 1.ÈáèÂ≠êËÆ°ÁÆó ÂõûÂà∞Êàë‰ª¨ÂØπÁ•ûÁªèÁΩëÁªúÂéÜÂè≤ÁöÑËÆ®ËÆ∫ÔºåÊ†πÊçÆÂéÜÂè≤Ë∂ãÂäøÂõæÊù•ÁúãÔºåÁ•ûÁªèÁΩëÁªú‰ª•ÂèäÊ∑±Â∫¶Â≠¶‰π†‰ºö‰∏ç‰ºöÂÉè‰ª•ÂæÄ‰∏ÄÊ†∑ÂÜçÊ¨°Èô∑ÂÖ•Ë∞∑Â∫ïÔºü‰ΩúËÄÖËÆ§‰∏∫ÔºåËøô‰∏™ËøáÁ®ãÂèØËÉΩÂèñÂÜ≥‰∫éÈáèÂ≠êËÆ°ÁÆóÊú∫ÁöÑÂèëÂ±ï„ÄÇ Ê†πÊçÆ‰∏Ä‰∫õÊúÄËøëÁöÑÁ†îÁ©∂ÂèëÁé∞Ôºå‰∫∫ËÑëÂÜÖÈÉ®ËøõË°åÁöÑËÆ°ÁÆóÂèØËÉΩÊòØÁ±ª‰ºº‰∫éÈáèÂ≠êËÆ°ÁÆóÂΩ¢ÊÄÅÁöÑ‰∏úË•ø„ÄÇËÄå‰∏îÁõÆÂâçÂ∑≤Áü•ÁöÑÊúÄÂ§ßÁ•ûÁªèÁΩëÁªúË∑ü‰∫∫ËÑëÁöÑÁ•ûÁªèÂÖÉÊï∞ÈáèÁõ∏ÊØîÔºå‰ªçÁÑ∂ÊòæÂæóÈùûÂ∏∏Â∞èÔºå‰ªÖ‰∏çÂèä1%Â∑¶Âè≥„ÄÇÊâÄ‰ª•Êú™Êù•ÁúüÊ≠£ÊÉ≥ÂÆûÁé∞‰∫∫ËÑëÁ•ûÁªèÁΩëÁªúÁöÑÊ®°ÊãüÔºåÂèØËÉΩÈúÄË¶ÅÂÄüÂä©ÈáèÂ≠êËÆ°ÁÆóÁöÑÂº∫Â§ßËÆ°ÁÆóËÉΩÂäõ„ÄÇ ÂêÑÂ§ßÁ†îÁ©∂ÁªÑ‰πüÂ∑≤ÁªèËÆ§ËØÜÂà∞‰∫ÜÈáèÂ≠êËÆ°ÁÆóÁöÑÈáçË¶ÅÊÄß„ÄÇË∞∑Ê≠åÂ∞±Âú®ÂºÄÂ±ïÈáèÂ≠êËÆ°ÁÆóÊú∫D-waveÁöÑÁ†îÁ©∂ÔºåÂ∏åÊúõÁî®ÈáèÂ≠êËÆ°ÁÆóÊù•ËøõË°åÊú∫Âô®Â≠¶‰π†ÔºåÂπ∂‰∏îÂú®ÂâçÊÆµÊó∂Èó¥Êúâ‰∫ÜÁ™ÅÁ†¥ÊÄßÁöÑËøõÂ±ï„ÄÇÂõΩÂÜÖÊñπÈù¢ÔºåÈòøÈáåÂíå‰∏≠ÁßëÈô¢Âêà‰ΩúÊàêÁ´ã‰∫ÜÈáèÂ≠êËÆ°ÁÆóÂÆûÈ™åÂÆ§ÔºåÊÑèÂõæËøõË°åÈáèÂ≠êËÆ°ÁÆóÁöÑÁ†îÁ©∂„ÄÇ Â¶ÇÊûúÈáèÂ≠êËÆ°ÁÆóÂèëÂ±ï‰∏çÂäõÔºå‰ªçÁÑ∂ÈúÄË¶ÅÊï∞ÂçÅÂπ¥ÊâçËÉΩ‰ΩøÊàë‰ª¨ÁöÑËÆ°ÁÆóËÉΩÂäõÂæó‰ª•Á™ÅÈ£ûÁåõËøõÁöÑÂèëÂ±ïÔºåÈÇ£‰πàÁº∫Â∞ë‰∫ÜÂº∫Â§ßËÆ°ÁÆóËÉΩÂäõÁöÑÁ•ûÁªèÁΩëÁªúÂèØËÉΩ‰ºöÊó†Ê≥ï‰∏ÄÂ∏ÜÈ£éÈ°∫ÁöÑÂèëÂ±ï‰∏ãÂéª„ÄÇËøôÁßçÊÉÖÂÜµÂèØ‰ª•Á±ªÊØî‰∏∫80-90Âπ¥Êó∂ÊúüÁ•ûÁªèÁΩëÁªúÂõ†‰∏∫ËÆ°ÁÆóËÉΩÂäõÁöÑÈôêÂà∂ËÄåË¢´‰Ωé‰º∞‰∏éÂøΩËßÜ„ÄÇÂÅáËÆæÈáèÂ≠êËÆ°ÁÆóÊú∫ÁúüÁöÑËÉΩÂ§ü‰∏éÁ•ûÁªèÁΩëÁªúÁªìÂêàÔºåÂπ∂‰∏îÂä©ÂäõÁúüÊ≠£ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑËØûÁîüÔºåËÄå‰∏îÈáèÂ≠êËÆ°ÁÆóÊú∫ÂèëÂ±ïÈúÄË¶Å10Âπ¥ÁöÑËØùÔºåÈÇ£‰πàÁ•ûÁªèÁΩëÁªúÂèØËÉΩËøòÊúâ10Âπ¥ÁöÑÂèëÂ±ïÊúü„ÄÇÁõ¥Âà∞ÈÇ£Êó∂Êúü‰ª•ÂêéÔºåÁ•ûÁªèÁΩëÁªúÊâçËÉΩÁúüÊ≠£Êé•ËøëÂÆûÁé∞AIËøô‰∏ÄÁõÆÊ†á„ÄÇ&nbsp;Âõæ39 ÈáèÂ≠êËÆ°ÁÆó&nbsp; 2.‰∫∫Â∑•Êô∫ËÉΩ ÊúÄÂêéÔºå‰ΩúËÄÖÊÉ≥ÁÆÄÂçïÂú∞Ë∞àË∞àÂØπÁõÆÂâç‰∫∫Â∑•Êô∫ËÉΩÁöÑÁúãÊ≥ï„ÄÇËôΩÁÑ∂Áé∞Âú®‰∫∫Â∑•Êô∫ËÉΩÈùûÂ∏∏ÁÅ´ÁÉ≠Ôºå‰ΩÜÊòØË∑ùÁ¶ªÁúüÊ≠£ÁöÑ‰∫∫Â∑•Êô∫ËÉΩËøòÊúâÂæàÂ§ßÁöÑË∑ùÁ¶ª„ÄÇÂ∞±ÊãøËÆ°ÁÆóÊú∫ËßÜËßâÊñπÂêëÊù•ËØ¥ÔºåÈù¢ÂØπÁ®çÂæÆÂ§çÊùÇ‰∏Ä‰∫õÁöÑÂú∫ÊôØÔºå‰ª•ÂèäÊòì‰∫éÊ∑∑Ê∑ÜÁöÑÂõæÂÉèÔºåËÆ°ÁÆóÊú∫Â∞±ÂèØËÉΩÈöæ‰ª•ËØÜÂà´„ÄÇÂõ†Ê≠§ÔºåËøô‰∏™ÊñπÂêëËøòÊúâÂæàÂ§öÁöÑÂ∑•‰ΩúË¶ÅÂÅö„ÄÇ Â∞±ÊôÆÈÄö‰∫∫ÁúãÊù•ÔºåËøô‰πàËæõËã¶ÁöÑÂÅöÂêÑÁßçÂÆûÈ™åÔºå‰ª•ÂèäÊäïÂÖ•Â§ßÈáèÁöÑ‰∫∫ÂäõÂ∞±ÊòØ‰∏∫‰∫ÜÂÆûÁé∞‰∏Ä‰∫õ‰∏çÂèäÂ≠©Á´•ËÉΩÂäõÁöÑËßÜËßâËÉΩÂäõÔºåÊú™ÂÖçÊúâ‰∫õ‰∏çÂÄº„ÄÇ‰ΩÜÊòØËøôÂè™ÊòØÁ¨¨‰∏ÄÊ≠•„ÄÇËôΩÁÑ∂ËÆ°ÁÆóÊú∫ÈúÄË¶ÅÂæàÂ§ßÁöÑËøêÁÆóÈáèÊâçËÉΩÂÆåÊàê‰∏Ä‰∏™ÊôÆÈÄö‰∫∫ÁÆÄÂçïËÉΩÂÆåÊàêÁöÑËØÜÂõæÂ∑•‰ΩúÔºå‰ΩÜËÆ°ÁÆóÊú∫ÊúÄÂ§ßÁöÑ‰ºòÂäøÂú®‰∫éÂπ∂Ë°åÂåñ‰∏éÊâπÈáèÊé®ÂπøËÉΩÂäõ„ÄÇ‰ΩøÁî®ËÆ°ÁÆóÊú∫‰ª•ÂêéÔºåÊàë‰ª¨ÂèØ‰ª•ÂæàËΩªÊòìÂú∞Â∞Ü‰ª•ÂâçÈúÄË¶Å‰∫∫ÁúºÂéªÂà§Êñ≠ÁöÑÂ∑•‰Ωú‰∫§ÁªôËÆ°ÁÆóÊú∫ÂÅöÔºåËÄå‰∏îÂá†‰πéÊ≤°Êúâ‰ªª‰ΩïÁöÑÊé®ÂπøÊàêÊú¨„ÄÇËøôÂ∞±ÂÖ∑ÊúâÂæàÂ§ßÁöÑ‰ª∑ÂÄº„ÄÇÊ≠£Â¶ÇÁÅ´ËΩ¶ÂàöËØûÁîüÁöÑÊó∂ÂÄôÔºåÊúâ‰∫∫Âò≤Á¨ëÂÆÉÂèàÁ¨®ÂèàÈáçÔºåÈÄüÂ∫¶ËøòÊ≤°ÊúâÈ©¨Âø´„ÄÇ‰ΩÜÊòØÂæàÂø´ËßÑÊ®°ÂåñÊé®ÂπøÁöÑÁÅ´ËΩ¶Â∞±Êõø‰ª£‰∫ÜÈ©¨ËΩ¶ÁöÑ‰ΩøÁî®„ÄÇ‰∫∫Â∑•Êô∫ËÉΩ‰πüÊòØÂ¶ÇÊ≠§„ÄÇËøô‰πüÊòØ‰∏∫‰ªÄ‰πàÁõÆÂâç‰∏ñÁïå‰∏äÂêÑËëóÂêçÂÖ¨Âè∏‰ª•ÂèäÊîøÂ∫úÈÉΩÂØπÊ≠§ÁÉ≠Ë°∑ÁöÑÂéüÂõ†„ÄÇ ÁõÆÂâçÁúãÊù•ÔºåÁ•ûÁªèÁΩëÁªúË¶ÅÊÉ≥ÂÆûÁé∞‰∫∫Â∑•Êô∫ËÉΩËøòÊúâÂæàÂ§öÁöÑË∑ØË¶ÅËµ∞Ôºå‰ΩÜÊñπÂêëËá≥Â∞ëÊòØÊ≠£Á°ÆÁöÑÔºå‰∏ãÈù¢Â∞±Ë¶ÅÁúãÂêéÊù•ËÄÖÁöÑ‰∏çÊñ≠Âä™Âäõ‰∫Ü„ÄÇÂõæ40 ‰∫∫Â∑•Êô∫ËÉΩ&nbsp;ÂÖ´ ÊÄªÁªì Êú¨ÊñáÂõûÈ°æ‰∫ÜÁ•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïÂéÜÂè≤Ôºå‰ªéÁ•ûÁªèÂÖÉÂºÄÂßãÔºåÂéÜÁªèÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºå‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºåÁõ¥Âà∞Â§öÂ±ÇÁ•ûÁªèÁΩëÁªú„ÄÇÂú®ÂéÜÂè≤‰ªãÁªç‰∏≠Á©øÊèíËÆ≤Ëß£Á•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑÔºåÂàÜÁ±ªÊïàÊûú‰ª•ÂèäËÆ≠ÁªÉÊñπÊ≥ïÁ≠â„ÄÇÊú¨ÊñáËØ¥Êòé‰∫ÜÁ•ûÁªèÁΩëÁªúÂÜÖÈÉ®ÂÆûÈôÖ‰∏äÂ∞±ÊòØÁü©ÈòµËÆ°ÁÆóÔºåÂú®Á®ãÂ∫è‰∏≠ÁöÑÂÆûÁé∞Ê≤°Êúâ‚ÄúÁÇπ‚ÄùÂíå‚ÄúÁ∫ø‚ÄùÁöÑÂØπË±°„ÄÇÊú¨ÊñáËØ¥Êòé‰∫ÜÁ•ûÁªèÁΩëÁªúÂº∫Â§ßÈ¢ÑÊµãËÉΩÂäõÁöÑÊ†πÊú¨ÔºåÂ∞±ÊòØÂ§öÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªúÂèØ‰ª•Êó†ÈôêÈÄºËøëÁúüÂÆûÁöÑÂØπÂ∫îÂáΩÊï∞Ôºå‰ªéËÄåÊ®°ÊãüÊï∞ÊçÆ‰πãÈó¥ÁöÑÁúüÂÆûÂÖ≥Á≥ª„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåÊú¨ÊñáÂõûÈ°æ‰∫ÜÁ•ûÁªèÁΩëÁªúÂèëÂ±ïÁöÑÂéÜÁ®ãÔºåÂàÜÊûê‰∫ÜÁ•ûÁªèÁΩëÁªúÂèëÂ±ïÁöÑÂ§ñÂú®ÂéüÂõ†ÔºåÂåÖÊã¨ËÆ°ÁÆóËÉΩÂäõÁöÑÂ¢ûÂº∫ÔºåÊï∞ÊçÆÁöÑÂ¢ûÂ§öÔºå‰ª•ÂèäÊñπÊ≥ïÁöÑÂàõÊñ∞Á≠â„ÄÇÊúÄÂêéÔºåÊú¨ÊñáÂØπÁ•ûÁªèÁΩëÁªúÁöÑÊú™Êù•ËøõË°å‰∫ÜÂ±ïÊúõÔºåÂåÖÊã¨ÈáèÂ≠êËÆ°ÁÆó‰∏éÁ•ûÁªèÁΩëÁªúÁªìÂêàÁöÑÂèØËÉΩÊÄßÔºå‰ª•ÂèäÊé¢ËÆ®Êú™Êù•‰∫∫Â∑•Êô∫ËÉΩÂèëÂ±ïÁöÑÂâçÊôØ‰∏é‰ª∑ÂÄº„ÄÇ&nbsp;‰πù.&nbsp;ÂêéËÆ∞ Êú¨ÁØáÊñáÁ´†ÂèØ‰ª•ËßÜ‰∏∫‰ΩúËÄÖ‰∏ÄÂπ¥Êù•ÂØπÁ•ûÁªèÁΩëÁªúÁöÑÁêÜËß£‰∏éÊÄªÁªìÔºåÂåÖÊã¨ÂÆûÈ™åÁöÑ‰Ωì‰ºöÔºå‰π¶Á±çÁöÑÈòÖËØªÔºå‰ª•ÂèäÊÄùËÄÉÁöÑÁÅ´Ëä±Á≠â„ÄÇÁ•ûÁªèÁΩëÁªúËôΩÁÑ∂ÈáçË¶ÅÔºå‰ΩÜÂ≠¶‰π†Âπ∂‰∏çÂÆπÊòì„ÄÇËøô‰∏ªË¶ÅÊòØÁî±‰∫éÂÖ∂ÁªìÊûÑÂõæËæÉ‰∏∫ÈöæÊáÇÔºå‰ª•ÂèäÂéÜÂè≤ÂèëÂ±ïÁöÑÂéüÂõ†ÔºåÂØºËá¥Ê¶ÇÂøµÂÆπÊòìÊ∑∑Ê∑ÜÔºå‰∏Ä‰∫õ‰ªãÁªçÁöÑÂçöÂÆ¢‰∏éÁΩëÁ´ôÂÜÖÂÆπÊñ∞Êóß‰∏çÈΩê„ÄÇÊú¨ÁØáÊñáÁ´†ÁùÄÁúº‰∫éËøô‰∫õÈóÆÈ¢òÔºåÊ≤°ÊúâÂ§™Â§öÁöÑÊï∞Â≠¶Êé®ÂØºÔºåÊÑèÂõæ‰ª•‰∏ÄÁßçÁÆÄÂçïÁöÑÔºåÁõ¥ËßÇÁöÑÊñπÂºèÂØπÁ•ûÁªèÁΩëÁªúËøõË°åËÆ≤Ëß£„ÄÇÂú®2015Âπ¥ÊúÄÂêé‰∏ÄÂ§©Áªà‰∫éÂÜôÂÆå„ÄÇÂ∏åÊúõÊú¨ÊñáÂèØ‰ª•ÂØπÂêÑ‰ΩçÊúâÊâÄÂ∏ÆÂä©„ÄÇ&nbsp;&nbsp; ‰ΩúËÄÖÂæàÊÑüË∞¢ËÉΩÂ§üÈòÖËØªÂà∞ËøôÈáåÁöÑËØªËÄÖ„ÄÇÂ¶ÇÊûúÁúãÂÆåËßâÂæóÂ•ΩÁöÑËØùÔºåËøòËØ∑ËΩªËΩªÁÇπ‰∏Ä‰∏ãËµûÔºå‰Ω†‰ª¨ÁöÑÈºìÂä±Â∞±ÊòØ‰ΩúËÄÖÁªßÁª≠Ë°åÊñáÁöÑÂä®Âäõ„ÄÇÊú¨ÊñáÁöÑÂ§áÊ≥®ÈÉ®ÂàÜÊòØ‰∏Ä‰∫õÂØπÁ•ûÁªèÁΩëÁªúÂ≠¶‰π†ÁöÑÂª∫ËÆÆÔºå‰æõË°•ÂÖÖÈòÖËØª‰∏éÂèÇËÄÉ„ÄÇ ÁõÆÂâç‰∏∫Ê≠¢ÔºåEasyPRÁöÑ1.4ÁâàÂ∑≤ÁªèÂ∞ÜÁ•ûÁªèÁΩëÁªúÔºàANNÔºâËÆ≠ÁªÉÁöÑÊ®°ÂùóÂä†‰ª•ÂºÄÊîæÔºåÂºÄÂèëËÄÖ‰ª¨ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™Ê®°ÂùóÊù•ËøõË°åËá™Â∑±ÁöÑÂ≠óÁ¨¶Ê®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÇÊúâÂÖ¥Ë∂£ÁöÑÂèØ‰ª•‰∏ãËΩΩ„ÄÇ&nbsp;ÂçÅ. Â§áÊ≥® Á•ûÁªèÁΩëÁªúËôΩÁÑ∂ÂæàÈáçË¶ÅÔºå‰ΩÜÊòØÂØπ‰∫éÁ•ûÁªèÁΩëÁªúÁöÑÂ≠¶‰π†ÔºåÂç¥Âπ∂‰∏çÂÆπÊòì„ÄÇËøô‰∫õÂ≠¶‰π†Âõ∞Èöæ‰∏ªË¶ÅÊù•Ëá™‰ª•‰∏ã‰∏â‰∏™ÊñπÈù¢ÔºöÊ¶ÇÂøµÔºåÁ±ªÂà´ÔºåÊïôÁ®ã„ÄÇ‰∏ãÈù¢ÁÆÄÂçïËØ¥ÊòéËøô‰∏âÁÇπ„ÄÇ 1.Ê¶ÇÂøµ ÂØπ‰∫é‰∏ÄÈó®ÊäÄÊúØÁöÑÂ≠¶‰π†ËÄåË®ÄÔºåÈ¶ñÂÖàÊúÄÈáçË¶ÅÁöÑÊòØÂºÑÊ∏ÖÊ¶ÇÂøµ„ÄÇÂè™ÊúâÂ∞ÜÊ¶ÇÂøµÁêÜËß£Ê∏ÖÊ•öÔºåÊâçËÉΩÈ°∫ÁïÖÁöÑËøõË°åÂêéÈù¢ÁöÑÂ≠¶‰π†„ÄÇÁî±‰∫éÁ•ûÁªèÁΩëÁªúÊº´ÈïøÁöÑÂèëÂ±ïÂéÜÂè≤ÔºåÁªèÂ∏∏‰ºöÊúâ‰∏Ä‰∫õÊ¶ÇÂøµÂÆπÊòìÊ∑∑Ê∑ÜÔºåËÆ©‰∫∫Â≠¶‰π†‰∏≠‰∫ßÁîüÂõ∞ÊÉë„ÄÇËøôÈáåÈù¢ÂåÖÊã¨ÂéÜÂè≤ÁöÑÊúØËØ≠Ôºå‰∏ç‰∏ÄËá¥ÁöÑËØ¥Ê≥ïÔºå‰ª•ÂèäË¢´ÈÅóÂøòÁöÑÁ†îÁ©∂Á≠â„ÄÇ ÂéÜÂè≤ÁöÑÊúØËØ≠ Ëøô‰∏™ÁöÑ‰ª£Ë°®Â∞±ÊòØÂ§öÂ±ÇÊÑüÁü•Âô®ÔºàMLPÔºâËøô‰∏™ÊúØËØ≠„ÄÇËµ∑ÂàùÁúãÊñáÁåÆÊó∂ÂæàÈöæÁêÜËß£ÁöÑ‰∏Ä‰∏™ÈóÆÈ¢òÂ∞±ÊòØÔºå‰∏∫‰ªÄ‰πàÁ•ûÁªèÁΩëÁªúÂèàÊúâÂè¶‰∏Ä‰∏™ÂêçÁß∞ÔºöMLP„ÄÇÂÖ∂ÂÆûMLPÔºàMulti-Layer PerceptronÔºâÁöÑÂêçÁß∞Ëµ∑Ê∫ê‰∫é50-60Âπ¥‰ª£ÁöÑÊÑüÁü•Âô®ÔºàPerceptronÔºâ„ÄÇÁî±‰∫éÊàë‰ª¨Âú®ÊÑüÁü•Âô®‰πã‰∏äÂèàÂ¢ûÂä†‰∫Ü‰∏Ä‰∏™ËÆ°ÁÆóÂ±ÇÔºåÂõ†Ê≠§Áß∞‰∏∫Â§öÂ±ÇÊÑüÁü•Âô®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËôΩÁÑ∂Âè´‚ÄúÂ§öÂ±Ç‚ÄùÔºåMLP‰∏ÄËà¨ÈÉΩÊåáÁöÑÊòØ‰∏§Â±ÇÔºàÂ∏¶‰∏Ä‰∏™ÈöêËóèÂ±ÇÁöÑÔºâÁ•ûÁªèÁΩëÁªú„ÄÇ MLPËøô‰∏™ÊúØËØ≠Â±û‰∫éÂéÜÂè≤ÈÅóÁïôÁöÑ‰∫ßÁâ©„ÄÇÁé∞Âú®Êàë‰ª¨‰∏ÄËà¨Â∞±ËØ¥Á•ûÁªèÁΩëÁªúÔºå‰ª•ÂèäÊ∑±Â∫¶Á•ûÁªèÁΩëÁªú„ÄÇÂâçËÄÖ‰ª£Ë°®Â∏¶‰∏Ä‰∏™ÈöêËóèÂ±ÇÁöÑ‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúÔºå‰πüÊòØEasyPRÁõÆÂâç‰ΩøÁî®ÁöÑËØÜÂà´ÁΩëÁªúÔºåÂêéËÄÖÊåáÊ∑±Â∫¶Â≠¶‰π†ÁöÑÁΩëÁªú„ÄÇ ‰∏ç‰∏ÄËá¥ÁöÑËØ¥Ê≥ï Ëøô‰∏™ÊúÄÊòéÊòæÁöÑ‰ª£Ë°®Â∞±ÊòØÊçüÂ§±ÂáΩÊï∞loss&nbsp;functionÔºåËøô‰∏™ËøòÊúâ‰∏§‰∏™ËØ¥Ê≥ïÊòØË∑üÂÆÉÂÆåÂÖ®‰∏ÄËá¥ÁöÑÊÑèÊÄùÔºåÂàÜÂà´ÊòØÊÆãÂ∑ÆÂáΩÊï∞error&nbsp;functionÔºå‰ª•Âèä‰ª£‰ª∑ÂáΩÊï∞cost&nbsp;function„ÄÇloss&nbsp;functionÊòØÁõÆÂâçÊ∑±Â∫¶Â≠¶‰π†ÈáåÁî®ÁöÑËæÉÂ§öÁöÑ‰∏ÄÁßçËØ¥Ê≥ïÔºåcaffeÈáå‰πüÊòØËøô‰πàÂè´ÁöÑ„ÄÇcost&nbsp;functionÂàôÊòØNgÂú®courseraÊïôÂ≠¶ËßÜÈ¢ëÈáåÁî®Âà∞ÁöÑÁªü‰∏ÄËØ¥Ê≥ï„ÄÇËøô‰∏âËÄÖÈÉΩÊòØÂêå‰∏Ä‰∏™ÊÑèÊÄùÔºåÈÉΩÊòØ‰ºòÂåñÈóÆÈ¢òÊâÄÈúÄË¶ÅÊ±ÇËß£ÁöÑÊñπÁ®ã„ÄÇËôΩÁÑ∂Âú®‰ΩøÁî®ÁöÑÊó∂ÂÄô‰∏çÂÅöËßÑÂÆöÔºå‰ΩÜÊòØÂú®Âê¨Âà∞ÂêÑÁßçËÆ≤Ëß£Êó∂Ë¶ÅÂøÉÈáåÊòéÁôΩ„ÄÇ ÂÜçÊù•Â∞±ÊòØÊùÉÈáçweightÂíåÂèÇÊï∞parameterÁöÑËØ¥Ê≥ïÔºåÁ•ûÁªèÁΩëÁªúÁïåÁî±‰∫é‰ª•ÂâçÁöÑÊÉØ‰æãÔºå‰∏ÄËà¨‰ºöÂ∞ÜËÆ≠ÁªÉÂæóÂà∞ÁöÑÂèÇÊï∞Áß∞‰πã‰∏∫ÊùÉÈáçÔºåËÄå‰∏çÂÉèÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÂ∞±Áß∞‰πã‰∏∫ÂèÇÊï∞„ÄÇËøô‰∏™ÈúÄË¶ÅËÆ∞‰ΩèÂ∞±Â•Ω„ÄÇ‰∏çËøáÂú®ÁõÆÂâçÁöÑ‰ΩøÁî®ÊÉØ‰æã‰∏≠Ôºå‰πüÊúâËøôÊ†∑‰∏ÄÁßçËßÑÂÆö„ÄÇÈÇ£Â∞±ÊòØÈùûÂÅèÁΩÆËäÇÁÇπËøûÊé•‰∏äÁöÑÂÄºÁß∞‰πã‰∏∫ÊùÉÈáçÔºåËÄåÂÅèÁΩÆËäÇÁÇπ‰∏äÁöÑÂÄºÁß∞‰πã‰∏∫ÂÅèÁΩÆÔºå‰∏§ËÄÖÁªü‰∏ÄËµ∑Êù•Áß∞‰πã‰∏∫ÂèÇÊï∞„ÄÇ Âè¶Â§ñ‰∏Ä‰∏™Âêå‰πâËØçÂ∞±ÊòØÊøÄÊ¥ªÂáΩÊï∞active functionÂíåËΩ¨ÁßªÂáΩÊï∞transfer function‰∫Ü„ÄÇÂêåÊ†∑Ôºå‰ªñ‰ª¨‰ª£Ë°®‰∏Ä‰∏™ÊÑèÊÄùÔºåÈÉΩÊòØÂè†Âä†ÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞ÁöÑËØ¥Ê≥ï„ÄÇ Ë¢´ÈÅóÂøòÁöÑÁ†îÁ©∂ Áî±‰∫éÁ•ûÁªèÁΩëÁªúÂèëÂ±ïÂéÜÂè≤Â∑≤ÁªèÊúâ70Âπ¥ÁöÑÊº´ÈïøÂéÜÂè≤ÔºåÂõ†Ê≠§Âú®Á†îÁ©∂ËøáÁ®ã‰∏≠ÔºåÂøÖÁÑ∂Êúâ‰∏Ä‰∫õÁ†îÁ©∂ÂàÜÊîØÂ±û‰∫éË¢´ÈÅóÂøòÈò∂ÊÆµ„ÄÇËøôÈáåÈù¢ÂåÖÊã¨ÂêÑÁßç‰∏çÂêåÁöÑÁΩëÁªúÔºå‰æãÂ¶ÇSOMÔºàSelf-Organizing MapÔºåËá™ÁªÑÁªáÁâπÂæÅÊò†Â∞ÑÁΩëÁªúÔºâÔºåSNNÔºàSynergetic Neural NetworkÔºåÂçèÂêåÁ•ûÁªèÁΩëÁªúÔºâÔºåARTÔºàAdaptive Resonance TheoryÔºåËá™ÈÄÇÂ∫îÂÖ±ÊåØÁêÜËÆ∫ÁΩëÁªúÔºâÁ≠âÁ≠â„ÄÇÊâÄ‰ª•ÁúãÂéÜÂè≤ÊñáÁåÆÊó∂‰ºöÁúãÂà∞ËÆ∏Â§öÊ≤°ËßÅËøáÁöÑÊ¶ÇÂøµ‰∏éÂêçËØç„ÄÇ Êúâ‰∫õÂéÜÂè≤ÁΩëÁªúÁîöËá≥‰ºöÈáçÊñ∞Êàê‰∏∫Êñ∞ÁöÑÁ†îÁ©∂ÁÉ≠ÁÇπÔºå‰æãÂ¶ÇRNN‰∏éLSTMÂ∞±ÊòØ80Âπ¥‰ª£Â∑¶Âè≥ÂºÄÂßãÁöÑÁ†îÁ©∂ÔºåÁõÆÂâçÂ∑≤ÁªèÊòØÊ∑±Â∫¶Â≠¶‰π†Á†îÁ©∂‰∏≠ÁöÑÈáçË¶Å‰∏ÄÈó®ÊäÄÊúØÔºåÂú®ËØ≠Èü≥‰∏éÊñáÂ≠óËØÜÂà´‰∏≠ÊúâÂæàÂ•ΩÁöÑÊïàÊûú„ÄÇ ÂØπ‰∫éËøô‰∫õÊòì‰∫éÊ∑∑Ê∑Ü‰ª•ÂèäÂºÑÈîôÁöÑÊ¶ÇÂøµÔºåÂä°ÂøÖÈúÄË¶ÅÂ§öÊñπÂèÇËÄÉÊñáÁåÆÔºåÁêÜÊ∏Ö‰∏ä‰∏ãÊñáÔºåËøôÊ†∑Êâç‰∏ç‰ºöÂú®Â≠¶‰π†‰∏éÈòÖËØªËøáÁ®ã‰∏≠Ëø∑Á≥ä„ÄÇ 2.Á±ªÂà´ ‰∏ãÈù¢Ë∞à‰∏Ä‰∏ãÂÖ≥‰∫éÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑ‰∏çÂêåÁ±ªÂà´„ÄÇ ÂÖ∂ÂÆûÊú¨ÊñáÁöÑÂêçÂ≠ó‚ÄúÁ•ûÁªèÁΩëÁªúÊµÖËÆ≤‚ÄùÂπ∂‰∏çÂêàÈÄÇÔºåÂõ†‰∏∫Êú¨ÊñáÂπ∂‰∏çÊòØËÆ≤ÁöÑÊòØ‚ÄúÁ•ûÁªèÁΩëÁªú‚ÄùÁöÑÂÜÖÂÆπÔºåËÄåÊòØÂÖ∂‰∏≠ÁöÑ‰∏Ä‰∏™Â≠êÁ±ªÔºå‰πüÊòØÁõÆÂâçÊúÄÂ∏∏ËØ¥ÁöÑÂâçÈ¶àÁ•ûÁªèÁΩëÁªú„ÄÇÊ†πÊçÆ‰∏ãÂõæÁöÑÂàÜÁ±ªÂèØ‰ª•ÁúãÂá∫„ÄÇ&nbsp;Âõæ41 Á•ûÁªèÁΩëÁªúÁöÑÁ±ªÂà´&nbsp; Á•ûÁªèÁΩëÁªúÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÂÆΩÊ≥õÁöÑÁß∞ÂëºÔºåÂÆÉÂåÖÊã¨‰∏§Á±ªÔºå‰∏ÄÁ±ªÊòØÁî®ËÆ°ÁÆóÊú∫ÁöÑÊñπÂºèÂéªÊ®°Êãü‰∫∫ËÑëÔºåËøôÂ∞±ÊòØÊàë‰ª¨Â∏∏ËØ¥ÁöÑANNÔºà‰∫∫Â∑•Á•ûÁªèÁΩëÁªúÔºâÔºåÂè¶‰∏ÄÁ±ªÊòØÁ†îÁ©∂ÁîüÁâ©Â≠¶‰∏äÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂèàÂè´ÁîüÁâ©Á•ûÁªèÁΩëÁªú„ÄÇÂØπ‰∫éÊàë‰ª¨ËÆ°ÁÆóÊú∫‰∫∫Â£´ËÄåË®ÄÔºåËÇØÂÆöÊòØÁ†îÁ©∂ÂâçËÄÖ„ÄÇ Âú®‰∫∫Â∑•Á•ûÁªèÁΩëÁªú‰πã‰∏≠ÔºåÂèàÂàÜ‰∏∫ÂâçÈ¶àÁ•ûÁªèÁΩëÁªúÂíåÂèçÈ¶àÁ•ûÁªèÁΩëÁªúËøô‰∏§Áßç„ÄÇÈÇ£‰πàÂÆÉ‰ª¨‰∏§ËÄÖÁöÑÂå∫Âà´ÊòØ‰ªÄ‰πàÂë¢ÔºüËøô‰∏™ÂÖ∂ÂÆûÂú®‰∫éÂÆÉ‰ª¨ÁöÑÁªìÊûÑÂõæ„ÄÇÊàë‰ª¨ÂèØ‰ª•ÊääÁªìÊûÑÂõæÁúã‰ΩúÊòØ‰∏Ä‰∏™ÊúâÂêëÂõæ„ÄÇÂÖ∂‰∏≠Á•ûÁªèÂÖÉ‰ª£Ë°®È°∂ÁÇπÔºåËøûÊé•‰ª£Ë°®ÊúâÂêëËæπ„ÄÇÂØπ‰∫éÂâçÈ¶àÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåËøô‰∏™ÊúâÂêëÂõæÊòØÊ≤°ÊúâÂõûË∑ØÁöÑ„ÄÇ‰Ω†ÂèØ‰ª•‰ªîÁªÜËßÇÂØüÊú¨Êñá‰∏≠Âá∫Áé∞ÁöÑÊâÄÊúâÁ•ûÁªèÁΩëÁªúÁöÑÁªìÊûÑÂõæÔºåÁ°ÆËÆ§‰∏Ä‰∏ã„ÄÇËÄåÂØπ‰∫éÂèçÈ¶àÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåÁªìÊûÑÂõæÁöÑÊúâÂêëÂõæÊòØÊúâÂõûË∑ØÁöÑ„ÄÇÂèçÈ¶àÁ•ûÁªèÁΩëÁªú‰πüÊòØ‰∏ÄÁ±ªÈáçË¶ÅÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇÂÖ∂‰∏≠HopfieldÁΩëÁªúÂ∞±ÊòØÂèçÈ¶àÁ•ûÁªèÁΩëÁªú„ÄÇÊ∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑRNN‰πüÂ±û‰∫é‰∏ÄÁßçÂèçÈ¶àÁ•ûÁªèÁΩëÁªú„ÄÇ ÂÖ∑‰ΩìÂà∞ÂâçÈ¶àÁ•ûÁªèÁΩëÁªú‰∏≠ÔºåÂ∞±Êúâ‰∫ÜÊú¨Êñá‰∏≠ÊâÄÂàÜÂà´ÊèèËø∞ÁöÑ‰∏â‰∏™ÁΩëÁªúÔºöÂçïÂ±ÇÁ•ûÁªèÁΩëÁªúÔºåÂèåÂ±ÇÁ•ûÁªèÁΩëÁªúÔºå‰ª•ÂèäÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªú„ÄÇÊ∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑCNNÂ±û‰∫é‰∏ÄÁßçÁâπÊÆäÁöÑÂ§öÂ±ÇÁ•ûÁªèÁΩëÁªú„ÄÇÂè¶Â§ñÔºåÂú®‰∏Ä‰∫õBlog‰∏≠ÂíåÊñáÁåÆ‰∏≠ÁúãÂà∞ÁöÑBPÁ•ûÁªèÁΩëÁªúÊòØ‰ªÄ‰πàÔºüÂÖ∂ÂÆûÂÆÉ‰ª¨Â∞±ÊòØ‰ΩøÁî®‰∫ÜÂèçÂêë‰º†Êí≠BPÁÆóÊ≥ïÁöÑ‰∏§Â±ÇÂâçÈ¶àÁ•ûÁªèÁΩëÁªú„ÄÇ‰πüÊòØÊúÄÊôÆÈÅçÁöÑ‰∏ÄÁßç‰∏§Â±ÇÁ•ûÁªèÁΩëÁªú„ÄÇ ÈÄöËøá‰ª•‰∏äÂàÜÊûêÂèØ‰ª•ÁúãÂá∫ÔºåÁ•ûÁªèÁΩëÁªúËøôÁßçËØ¥Ê≥ïÂÖ∂ÂÆûÊòØÈùûÂ∏∏Âπø‰πâÁöÑÔºåÂÖ∑‰ΩìÂú®ÊñáÁ´†‰∏≠ËØ¥ÁöÑÊòØ‰ªÄ‰πàÁΩëÁªúÔºåÈúÄË¶ÅÊ†πÊçÆÊñá‰∏≠ÁöÑÂÜÖÂÆπÂä†‰ª•Âå∫ÂàÜ„ÄÇ 3.ÊïôÁ®ã Â¶Ç‰ΩïÊõ¥Â•ΩÁöÑÂ≠¶‰π†Á•ûÁªèÁΩëÁªúÔºåËÆ§ÁúüÁöÑÂ≠¶‰π†‰∏ÄÈó®ËØæÁ®ãÊàñËÄÖÁúã‰∏ÄÊú¨Ëëó‰ΩúÈÉΩÊòØÂæàÊúâÂøÖË¶ÅÁöÑ„ÄÇ ËØ¥Âà∞ÁΩëÁªúÊïôÁ®ãÁöÑËØùÔºåËøôÈáåÂøÖÈ°ªËØ¥‰∏Ä‰∏ãNgÁöÑÊú∫Âô®Â≠¶‰π†ËØæÁ®ã„ÄÇÂØπ‰∫é‰∏Ä‰∏™ÂàùÂ≠¶ËÄÖËÄåË®ÄÔºåNgÁöÑËØæÁ®ãËßÜÈ¢ëÊòØÈùûÂ∏∏ÊúâÂ∏ÆÂä©ÁöÑ„ÄÇNg‰∏ÄÂÖ±ÂºÄËÆæËøá‰∏§Èó®Êú∫Âô®Â≠¶‰π†ÂÖ¨ÂºÄËØæÁ®ãÔºö‰∏Ä‰∏™ÊòØ2003Âπ¥Âú®StandfordÂºÄËÆæÁöÑÔºåÈù¢ÂêëÂÖ®ÁêÉÁöÑÂ≠¶ÁîüÔºåËøô‰∏™ËßÜÈ¢ëÁé∞Âú®ÂèØ‰ª•Âú®ÁΩëÊòìÂÖ¨ÂºÄËØæ‰∏äÊâæÂà∞ÔºõÂè¶‰∏Ä‰∏™ÊòØ2010Âπ¥‰∏ìÈó®‰∏∫Coursera‰∏äÁöÑÁî®Êà∑ÂºÄËÆæÁöÑÔºåÈúÄË¶ÅÁôªÈôÜCoursera‰∏äÊâçËÉΩÂ≠¶‰π†„ÄÇ ‰ΩÜÊòØÔºåÈúÄË¶ÅÊ≥®ÊÑèÁÇπÊòØÔºåËøô‰∏§‰∏™ËØæÁ®ãÂØπÂæÖÁ•ûÁªèÁΩëÁªúÁöÑÊÄÅÂ∫¶ÊúâÁÇπ‰∏çÂêå„ÄÇÊó©‰∫õÁöÑËØæÁ®ã‰∏ÄÂÖ±Êúâ20ËäÇËØæÔºåNgËä±‰∫ÜËã•Âπ≤ËäÇËØæÂéª‰∏ìÈó®ËÆ≤SVM‰ª•ÂèäSVMÁöÑÊé®ÂØºÔºåËÄåÂΩìÊó∂ÁöÑÁ•ûÁªèÁΩëÁªúÔºå‰ªÖ‰ªÖÊîæ‰∫ÜÂá†ÊÆµËßÜÈ¢ëÔºåËä±‰∫ÜÂ§ßÊ¶Ç‰∏çÂà∞20ÂàÜÈíüÔºà‰∏ÄËäÇËØæ60ÂàÜÈíüÂ∑¶Âè≥Ôºâ„ÄÇËÄåÂà∞‰∫ÜÂêéÊù•ÁöÑËØæÁ®ãÊó∂ÔºåÊÄªÂÖ±10ËäÇÁöÑËØæÁ®ã‰∏≠ÔºåNgÁªô‰∫ÜÂÆåÊï¥ÁöÑ‰∏§ËäÇÁªôÁ•ûÁªèÁΩëÁªúÔºåËØ¶ÁªÜ‰ªãÁªç‰∫ÜÁ•ûÁªèÁΩëÁªúÁöÑÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï„ÄÇÂêåÊó∂ÁªôSVMÂè™Êúâ‰∏ÄËäÇËØæÔºåÂπ∂‰∏îÊ≤°ÊúâÂÜçËÆ≤SVMÁöÑÊé®ÂØºËøáÁ®ã„ÄÇ‰∏ãÈù¢‰∏§Âº†ÂõæÂàÜÂà´ÊòØNg‰ªãÁªçÁ•ûÁªèÁΩëÁªúÁöÑÂºÄÁØáÔºåÂèØ‰ª•Â§ßËá¥ÁúãÂá∫‰∏Ä‰∫õÁ´ØÂÄ™„ÄÇ&nbsp;Âõæ42 Ng‰∏éÁ•ûÁªèÁΩëÁªú&nbsp; ‰∏∫‰ªÄ‰πàNgÂØπÂæÖÁ•ûÁªèÁΩëÁªúÁöÑÂèçÂ∫îÂâçÂêéÁõ∏Â∑ÆÈÇ£‰πàÂ§ßÔºü‰∫ãÂÆû‰∏äÂ∞±ÊòØÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂéüÂõ†„ÄÇNgÂÆûË∑µ‰∫ÜÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊïàÊûúÔºåËÆ§ËØÜÂà∞Ê∑±Â∫¶Â≠¶‰π†ÁöÑÂü∫Á°Ä‚ÄìÁ•ûÁªèÁΩëÁªúÁöÑÈáçË¶ÅÊÄß„ÄÇËøôÂ∞±ÊòØ‰ªñÂú®ÂêéÈù¢ÈáçÁÇπ‰ªãÁªçÁ•ûÁªèÁΩëÁªúÁöÑÂéüÂõ†„ÄÇÊÄª‰πãÔºåÂØπ‰∫éÁ•ûÁªèÁΩëÁªúÁöÑÂ≠¶‰π†ËÄåË®ÄÔºåÊàëÊõ¥Êé®ËçêCoursera‰∏äÁöÑ„ÄÇÂõ†‰∏∫Âú®ÈÇ£‰∏™Êó∂ÂÄôÔºåNgÊâçÊòØÁúüÊ≠£ÁöÑÊääÁ•ûÁªèÁΩëÁªú‰Ωú‰∏∫‰∏ÄÈó®ÈáçË¶ÅÁöÑÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÂéª‰º†Êéà„ÄÇ‰Ω†ÂèØ‰ª•‰ªé‰ªñ‰∏äËØæÁöÑÊÄÅÂ∫¶‰∏≠ÊÑüÂèóÂà∞‰ªñÁöÑÈáçËßÜÔºå‰ª•Âèä‰ªñÂ∏åÊúõ‰Ω†ËÉΩÂ≠¶Â•ΩÁöÑÊúüÊúõ„ÄÇ&nbsp;ÁâàÊùÉËØ¥ÊòéÔºö Êú¨Êñá‰∏≠ÁöÑÊâÄÊúâÊñáÂ≠óÔºåÂõæÁâáÔºå‰ª£Á†ÅÁöÑÁâàÊùÉÈÉΩÊòØÂ±û‰∫é‰ΩúËÄÖÂíåÂçöÂÆ¢Âõ≠ÂÖ±ÂêåÊâÄÊúâ„ÄÇÊ¨¢ËøéËΩ¨ËΩΩÔºå‰ΩÜÊòØÂä°ÂøÖÊ≥®Êòé‰ΩúËÄÖ‰∏éÂá∫Â§Ñ„ÄÇ‰ªª‰ΩïÊú™ÁªèÂÖÅËÆ∏ÁöÑÂâΩÁ™É‰ª•ÂèäÁà¨Ëô´ÊäìÂèñÈÉΩÂ±û‰∫é‰æµÊùÉÔºå‰ΩúËÄÖÂíåÂçöÂÆ¢Âõ≠‰øùÁïôÊâÄÊúâÊùÉÂà©„ÄÇ&nbsp;&nbsp;ÂèÇËÄÉÊñáÁåÆÔºö 1.Neural Networks 2.Andrew Ng&nbsp;Neural Networks&nbsp; 3.Á•ûÁªèÁΩëÁªúÁÆÄÂè≤ 4.‰∏≠ÁßëÈô¢ Âè≤Âø†Ê§ç Á•ûÁªèÁΩëÁªú&nbsp;ËÆ≤‰πâ 5.Ê∑±Â∫¶Â≠¶‰π† ËÉ°ÊôìÊûó&nbsp;L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/kesyoban.model.json"},"display":{"position":"right","width":130,"height":260},"mobile":{"show":false},"log":false,"tagMode":false});]]></content>
      <categories>
        <category>ËΩ¨ËΩΩ</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†ÔºåÁ•ûÁªèÁΩëÁªú</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ÂæÆËΩØÁ¨îËØïÁÆóÊ≥ïÔºà‰∏ÄÔºâ]]></title>
    <url>%2F2018%2F05%2F29%2F%E5%BE%AE%E8%BD%AF%E7%AC%94%E8%AF%95%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÊúÄËøëÊ±ÇËÅå‰∏≠Êé•Âà∞ÁöÑÂ•ΩÂ§öÂ§ñÂåÖÂÖ¨Âè∏ÁöÑÁîµËØùÔºå‰∏ÄËà¨ÊàëÈÉΩÊòØÊãíÁªùÁöÑÔºåÂÖ∂‰∏≠ÂëäÁü•Â§ñÂåÖÂà∞ÂæÆËΩØÁöÑÂ∞±Êúâ‰∏âÂÆ∂ÔºåÊúâ‰∏ÄÂÆ∂ËØ¥ÊòØÂæÆËΩØÂ∞èÂÜ∞È°πÁõÆÔºåÁªô‰∫ÜÊàëÂÖ´ÈÅìÁÆóÊ≥ïÈ¢òÔºåÈÉΩ‰∏çÊòØÂ§™ÈöæÔºåÊúâÁöÑÂú®LeetCode‰∏äËøòÂÅöËøáÔºåÂú®ËøôÈáåËÆ∞ÂΩï‰∏Ä‰∏ãÔºåÊ≠£Â•Ω‰πüÊï¥ÁêÜ‰∏ãLeetCode‰∏äÂà∑ËøáÁöÑÈ¢ò„ÄÇ ËøôÈáåËÆ∞ÂΩïÁöÑÁÆóÊ≥ïÊòØÂè™Áî®pythonÂÆûÁé∞Ôºå‰πüÊòØÊàëÁõÆÂâçËÉΩÊÉ≥Âà∞ÁöÑÊúÄ‰ºòËß£Ôºå‰∏ÄÂÖ±ÂÖ´‰∏™ÈóÆÈ¢ò„ÄÇ ÂÆåÊàê‰∏Ä‰∏™ÂáΩÊï∞Ôºödef Add(num1, num2):ÂÖ∂‰∏≠Ôºå‰∏§‰∏™ËæìÂÖ•ÈÉΩÊòØÊï∞Â≠óÔºåÈÉΩÊòØÂ≠óÁ¨¶‰∏≤ÔºàÂ¶ÇÔºö‚Äú12345678986543210123456789‚ÄùÔºâÔºåË¶ÅÊ±ÇËÆ°ÁÆó‰∏§‰∏™Êï∞Â≠óÁöÑÂíåÔºåËøîÂõû‰∏Ä‰∏™Â≠óÁ¨¶‰∏≤Ôºå‰∏çËÉΩ‰ΩøÁî®ÂÜÖÁΩÆÂáΩÊï∞ÔºåÂ¶ÇintÔºålongÁ≠â„ÄÇ‰æãÂ¶ÇÔºåËæìÂÖ•‰∏§‰∏™Êï∞Â≠óÊòØÔºö‚Äú1000000000000000‚ÄùÂíå‚Äú-1‚ÄùÔºåËøîÂõû‚Äú999999999999999‚Äù„ÄÇ Ëøô‰∏™ÈóÆÈ¢òÊØîËæÉÁÆÄÂçï‰∫ÜÔºå‰∏ªË¶ÅÂ∞±ÊòØ‰∏â‰∏™Â∞èÈóÆÈ¢òÔºö Â≠óÁ¨¶‰∏≤ÂíåÊï∞Â≠óÁöÑ‰∫íËΩ¨ Âä†Ê≥ïÁöÑËøõ‰Ωç ÂáèÊ≥ïÁöÑÂÄü‰Ωç Â≠óÁ¨¶‰∏≤ÂíåÊï∞Â≠óÁöÑ‰∫íËΩ¨‰∏çËÆ©Áî®intÂáΩÊï∞ÔºåËøô‰∏™ÁÆÄÂçïÔºåpythonÂè™Ë¶ÅÂÜô‰∏™Â≠óÂÖ∏Â∞±Ëß£ÂÜ≥‰∫ÜÔºåCÁöÑËØùÂ∞±Ë¶ÅÂÜôswitch caseÊù•‰∏Ä‰∏™‰∏Ä‰∏™ÊØîËæÉ‰∫Ü„ÄÇËøôÈáåÂ∞±Ëß£ÂÜ≥‰∫ÜÂ≠óÁ¨¶ËΩ¨Êï∞Â≠óÁöÑÈóÆÈ¢ò‰∫Ü„ÄÇ Âà∞ÁöÑÊï∞Â≠óÂºÄÂßãËÆ°ÁÆóÔºåÂõ†‰∏∫Ë¶ÅËÆæËÆ°ÂÄü‰ΩçÂíåËøõ‰ΩçÔºåÁ≠îÊ°à‰ºöÊúâÂõõÁßçÊÉÖÂÜµ Ê≠£Êï∞ + Ê≠£Êï∞ = Ê≠£Êï∞ 2 + 3 = 5 Ë¥üÊï∞ + Ë¥üÊï∞ = Ë¥üÊï∞ -2 + -3 = -5 Â§ßÊ≠£Êï∞ + Ë¥üÊï∞ = Ê≠£Êï∞ -2 + 3 = 1 Ê≠£Êï∞ + Â§ßË¥üÊï∞ = Ë¥üÊï∞ 2 + -3 = -1 Ë≤å‰ººÂ∞±ÊòØËøôÊ†∑Ôºå‰ΩÜÊòØËßÇÂØüÁªìÊûúÈô§‰∫ÜË¥üÂè∑Â∞±ÊòØ‰∏§ÁßçÔºåÊâÄ‰ª•Á®ãÂ∫è‰∏ÄÂºÄÂßãÂ∫îËØ•ÂÖàÂàÜÊûêË¥üÂè∑ÔºåËøõ‰ΩçÁöÑÊÉÖÂÜµÊúâ1,2ÔºåÂÄü‰ΩçÊÉÖÂÜµÊòØ3,4ÔºåÊ≠£Â•ΩËøô‰∏§‰∏™ÁªìÊûúÈô§‰∫ÜË¥üÂè∑Á≠îÊ°à‰∏ÄÊ†∑ÔºåÊâÄ‰ª•ÂàÜ‰∏§Á±ªÂ∞±OK 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# ÈóÆÈ¢ò 1def question1_add(num1, num2): # ÂàõÂª∫‰∏™Â≠óÂÖ∏Áî®Êù•ÊääÂ≠óÁ¨¶ËΩ¨‰∏∫int‰æø‰∫éËÆ°ÁÆó def strtoint(str): numdict = &#123;"0": 0, "1": 1, "2": 2, "3": 3, "4": 4, "5": 5, "6": 6, "7": 7, "8": 8, "9": 9&#125; return numdict.get(str) # ÊääÂàóË°®‰∏≠ÁöÑÊï∞Â≠óËΩ¨‰ºöÂ≠óÁ¨¶‰∏≤ def inttostr(lt): ls2 = [str(i) for i in lt] return ''.join(ls2) lt, x, y = [], [], [] # ‰∏§‰∏™Êï∞ÊòØÂê¶‰∏∫Ë¥üÊï∞ÁöÑÊ†áËÆ∞ minusflag1, minusflag2 = 0, 0 # È¶ñÂÖàÂÖàÊèêÂèñÂá∫Ë¥üÂè∑ÔºåËÆ∞ÂΩïË¥üÂè∑ÁöÑÊÉÖÂÜµ if num1[0] is "-": x = list(map(strtoint, num1[1:])) minusflag1 = 1 else: x = list(map(strtoint, num1)) if num2[0] is "-": y = list(map(strtoint, num2[1:])) minusflag2 = 1 else: y = list(map(strtoint, num2)) # Êää x‰Ωú‰∏∫ÊúÄÈïøÁöÑÈÇ£ÂàóÔºåyÊòØÁü≠ÁöÑÈÇ£Âàó if len(x) &lt; len(y): x, y = y, x maxlen, minlen = len(x), len(y) # Âú®Áü≠ÁöÑÈÇ£ÂàóÂâçÈù¢Êèí‰∏ä0ËÆ©‰∏§Âàó‰∏ÄÊ†∑ÈΩê‰ª•‰æø‰∫éËÆ°ÁÆó for i in range(maxlen-minlen): y.insert(0, 0) # ËÆ°ÁÆóÈÄöÂ∏∏ÊòØ‰ªéÊúÄ‰Ωé‰ΩçÂºÄÂßãÔºåÊâÄ‰ª•i‰ªéÊúÄ‰Ωé‰ΩçÂºÄÂßã # carryËÆ∞ÂΩïÂÄü‰ΩçÂíåËøõ‰ΩçÊÉÖÂÜµ i, carry = 0, 0 # ‰∏§‰∏™Êï∞ÈÉΩÊòØÊ≠£Êï∞ÊàñË¥üÊï∞ if (minusflag1 == 0 and minusflag2 == 0) or (minusflag1 == 1 and minusflag2 == 1): # +1ÊòØ‰∏∫‰∫ÜÈò≤Ê≠¢ÊúÄÈ´ò‰ΩçÊúâËøõ‰ΩçÁöÑÊÉÖÂÜµÔºåÁªôÊúÄÈ´ò‰ΩçÂä†‰∏Ä‰∏™0 for j in range(maxlen+1): i -= 1 if j &lt; maxlen: sum = x[i] + y[i] + carry else: sum = carry # ‰∏§‰∏™Êï∞Áõ∏Âä†Â§ß‰∫éÂçÅ‰ª£Ë°®ÊúâËøõ‰ΩçÔºå ÊääÁªìÊûúÂíå10ÁöÑÂïÜÁªôÊñ∞ÂàóË°®Ôºå‰ΩôÁªôËøõ‰ΩçÊ†áÂøó if sum &gt;= 10: lt.insert(0, sum%10) carry = sum//10 else: lt.insert(0, sum) carry = 0 # Â¶ÇÊûúÊúÄÈ´ò‰ΩçÊ≤°ÊúâËøõ‰Ωç Êää0Âà†Èô§ if lt[0] == 0: lt.pop(0) # Â¶ÇÊûúÈÉΩ‰∏∫Ë¥üÊï∞ Âä† - if minusflag1 == 1 and minusflag2 == 1: lt.insert(0, "-") return inttostr(lt) else: return inttostr(lt) # ‰∏ÄÊ≠£‰∏ÄË¥ü if (minusflag1 == 1 and minusflag2 == 0) or (minusflag1 == 0 and minusflag2 == 1): for j in range(maxlen): i -= 1 sum = x[i] - y[i] + carry if sum &lt; 0: lt.insert(0, sum%10) carry = sum//10 else: lt.insert(0, sum) carry = 0 while lt[0] == 0: lt.pop(0) if len(lt) == 1: break # Âà§Êñ≠ÊòØÂê¶Â∫îËØ•Âä† - Âè∑ if (num1[0] is "-" and len(num1[1:]) &gt; len(num2)) or num2[0] is "-" and len(num2[1:]) &gt; len(num1) : lt.insert(0, "-") return inttostr(lt) return inttostr(lt) ÁªôÂÆö‰∏Ä‰∏™Êï∞ÁªÑnumsÔºåÁÑ∂ÂêéÂØπÂÖ∂ÊéíÂ∫èÔºå‰ΩøÂæóÊéíÂ∫èÁªìÊûúÊª°Ë∂≥nums[0] &lt; nums[1] &gt; nums[2] &lt; nums[3]‚Ä¶„ÄÇ ‰æãÂ¶ÇÁªôÂÆöÊï∞ÁªÑnums=[1,2,3,4,5,6,7,8,9],ÂÖ∂‰∏≠‰∏Ä‰∏™Êª°Ë∂≥Êù°‰ª∂ÁöÑÁªìÊûúÊòØ12345.ÁªôÂá∫‰∏Ä‰∏™ÁªìÊûúÂç≥ÂèØÔºàÂèØËÉΩÊó†Ëß£Ôºâ„ÄÇÊúÄ‰ºòËß£Ê≥ïÊòØO(n)Êó∂Èó¥Â§çÊùÇÂ∫¶ÂíåO(1)Á©∫Èó¥Â§çÊùÇÂ∫¶„ÄÇ ÂéüÈ¢ò‰ΩçÁΩÆÔºöhttps://leetcode.com/problems/wiggle-sort-ii/ ËøôÈÅìÈ¢òÂ∞±ÊØîËæÉÊúâË∂£‰∫ÜÔºåLeetCode‰∏äÂ§ßÁ•ûÁªôÂá∫ÁöÑÁÆóÊ≥ïÊå∫Â§öÔºå‰ΩÜÊòØÊúÄ‰ºòËß£‰∏çÊòØO(n)ÔºåÁî®pythonÂÆûÁé∞ÁöÑËØùËøòËÉΩÊØîO(n)Â∞è„ÄÇ ÂÖàËØ¥ÊàëÁúãÂà∞È¢òÁ¨¨‰∏ÄÁúºÁöÑÊÉ≥Ê≥ïÂíåÁúã‰∫ÜLeetCode‰∏äÂ§ßÁ•ûÁöÑÊñπÊ≥ïÂêßÔºåÂæàÁÆÄÂçïÂ∞±‰∏âË°å 123nums.sort()median = len(nums[::2]) - 1nums[::2], nums[1::2] = nums[median::-1], nums[:median:-1] È¶ñÂÖàÊéíÂ∫èÔºåÊâæÂà∞‰∏≠‰ΩçÊï∞ÔºåÁÑ∂ÂêéÊää‰∏≠‰ΩçÊï∞Â∑¶Âè≥‰∏§ËæπÁöÑ‰∫§ÂèâÁõ∏ÊéíÂ∞±OK‰∫Ü„ÄÇ Â•ΩÂêßÔºåËØ¶ÁªÜ‰∏ÄÁÇπÂêßÔºåS‰ª£Ë°®ÊØî‰∏≠‰ΩçÊï∞Â∞èÁöÑÔºåL‰ª£Ë°®ÊØî‰∏≠‰ΩçÊï∞Â§ßÁöÑÔºåM‰ª£Ë°®‰∏≠‰ΩçÊï∞ 1234Small half: M . S . S . S Small half: M . S . S . S .Large half: . L . L . M . Large half: . L . L . L . M-------------------------- --------------------------Together: M L S L S M S Together: M L S L S L S M Ê†πÊçÆËøô‰∏™ÂéüÁêÜËøòÂèØ‰ª•ÂÜôÊàêÂÖ∂‰ªñÂΩ¢Âºè123nums.sort()median = len(nums[::2])nums[1::2], nums[::2] = nums[median:],nums[:median] Ëøô‰∏™ÊñπÂºèÁÆÄÂçï‰ΩÜÊòØ‰∏çÊª°Ë∂≥O(n)Êó∂Èó¥Â§çÊùÇÂ∫¶ÁöÑË¶ÅÊ±ÇÔºåËøô‰∏™ÊñπÊ≥ïÊòØLeetCode‰∏äÂ§ßÁ•ûÊÉ≥Âá∫ÁöÑÂè´virtual indexingÔºåÂú∞ÂùÄ123456Ëß£Èáä‰∏Ä‰∏ãsite()ÂáΩÊï∞ÁöÑ‰ΩúÁî®‰∏∫‰∫ÜÈò≤Ê≠¢medianÁöÑÂÖÉÁ¥†Êå®Âú®‰∏ÄËµ∑Ôºå‰πüÂ∞±ÊòØËØ¥Â•áÊï∞‰ΩçÁΩÆ‰∏äÁöÑÂÄºÊòØmedianÔºåÂêåÊó∂‰∏é‰ªñÁõ∏ÈÇªÁöÑÊüê‰∏™ÂÅ∂Êï∞‰ΩçÁΩÆ‰∏äÁöÑÂÄº‰πüÊòØmedianÂØºËá¥ÊéíÂ∫èÂ§±Ë¥•‰∏∫‰∫ÜÈÅøÂÖçËøô‰∏™ÈóÆÈ¢òÔºåÂèØ‰ª•ÈááÁî®‰∏ÄÁßçÊñπÊ≥ïÔºåÂç≥Âè¶j ÊØèÊ¨°ÁßªÂä®‰∏§Ê≠•Ôºå‰πüÂ∞±ÊòØËØ¥ÂÖàÂè¶jÁõ¥Á∫øÂ•áÊï∞‰ΩçÁΩÆÔºåÂÜçÂè¶jÊåáÂêëÂÅ∂Êï∞‰ΩçÁΩÆÔºåÊâÄ‰ª•ÂØπ‰∫éÂ§ßÂ∞è‰∏∫10ÁöÑÂ∫èÂàóÔºåjÁöÑÂèòÂåñÂèØËÉΩÂÉèÊòØËøôÊ†∑ 1 -&gt; 3 -&gt; 5 -&gt; 7 -&gt; 9 -&gt; 0 -&gt; 2 -&gt; 4 -&gt; 6 -&gt; 8123456789101112131415161718192021222324252627ÊöÇ‰∏îÂÖà‰∏çËÄÉËôëÊÄé‰πàÂÆûÁé∞ËøôÊ†∑ÁöÑÊîπÂèòÔºåÂÖàËØ¥‰∏Ä‰∏ãËøôÊ†∑ÂÅöÂ∏¶Êù•ÁöÑÂ•ΩÂ§ÑÁî±‰∏äÈù¢jÁöÑÂèòÂåñÂèØÁü•ÔºåjÁöÑÊîπÂèòÊòØÊØèÊ¨°ÁßªÂä®‰∏§Ê≠•ÔºåÊâÄ‰ª•ÔºåÊ†πÊçÆÁÆóÊ≥ïÊèèËø∞„ÄÇÊâÄÊúâÂíåmedianÁõ∏Á≠âÁöÑÂÖÉÁ¥†‰∏ÄÂÆöÊòØÊúÄÂêéÊâçÂõ∫ÂÆö‰ΩçÁΩÆÔºåÂèàÂõ†‰∏∫ÂΩìjÊåáÂêëÁöÑÂÄºÁ≠â‰∫émedianÊó∂ÔºåÊòØ‰∏ç‰∏éiÂíåkÊåáÂêëÁöÑ‰ªª‰Ωï‰∏Ä‰∏™ÂÖÉÁ¥†‰∫§Êç¢ÁöÑ„ÄÇÊâÄ‰ª•ÔºåÊØèÊ¨°ÁßªÂä®‰∏§Ê≠•Â∏¶Êù•ÁöÑÁªìÊûúÊòØËøô‰∫õmedianÊ∞∏Ëøú‰∏çÂèØËÉΩÁõ∏ÈÇª„ÄÇÊç¢Âè•ËØùËØ¥Â∞±ÊòØÊ∞∏Ëøú‰∏ç‰ºöÂá∫Áé∞‰∏§‰∏™medianÊå®ÁùÄÁöÑÊÉÖÂÜµ```pythondef question2_sort2(nums): def site(n): return (1 + 2 * n) % (len(nums) | 1) nums.sort() if len(nums) % 2 == 0: median = (nums[len(nums) // 2] + nums[len(nums) // 2 - 1]) / 2 else: median = nums[len(nums) // 2] i, j, k = 0, 0, len(nums) - 1 while j &lt;= k: if nums[site(j)] &gt; median: nums[site(i)], nums[site(j)] = nums[site(j)], nums[site(i)] i += 1 j += 1 elif nums[site(j)] &lt; median: nums[site(j)], nums[site(k)] = nums[site(k)], nums[site(j)] k -= 1 j += 1 # Ê≤°ÈîôÂ∞±ÊòØËøôÈáåÔºåÊàëËÆ§‰∏∫ÊâßË°åËøá‰∫§Êç¢ÂêéjÂ∞±Âú®Ê≠£Á°ÆÁöÑ‰ΩçÁΩÆ‰∏ä‰∫ÜÔºåÊâÄ‰ª•ÊàëËÆ©j+1ÁªìÊûúÂ∞±ÊòØÂæ™ÁéØÊ¨°Êï∞ÂáèÂ∞ë‰∫ÜÔºåÂ¶ÇÊûúËøõË°åj+1Âàô‰ºöÂæ™ÁéØNÊ¨°Ôºå‰∏§ÁßçÁöÑÁªìÊûú‰∏çÂêå‰ΩÜÈÉΩÂ§çÂêàÊù°‰ª∂ else: j += 1 return nums ÂÜô‰∏Ä‰∏™ÂáΩÊï∞ÔºåËæìÂÖ•ÊòØ‰∏§‰∏™intÊï∞ÁªÑAÂíåB„ÄÇË¶ÅÊ±Ç‰ªéAÂíåB‰∏≠ÂàÜÂà´ÂèñÂá∫‰∏Ä‰∏™Êï∞Ôºå‰Ωø‰ªñ‰ª¨ÁöÑÂíå‰∏∫20„ÄÇÊâìÂç∞Âá∫ÊâÄÊúâÁöÑÁªÑÂêà„ÄÇË¶ÅÊ±ÇÊï∞Â≠óÂú®Êï∞ÁªÑ‰∏≠ÁöÑ‰ΩçÁΩÆÂíåÊï∞Â≠óÊú¨Ë∫´„ÄÇÊØîÂ¶ÇËæìÂÖ•‰∏∫ A = [18, 2, 7, 8, 3], B = [17, 1, 19]ÔºåËæìÂá∫‰∏∫ 3 (A4) + 17 (B0) = 20ÔºåË°®Á§∫AÁöÑÁ¨¨4‰∏™ÂÖÉÁ¥†ÊòØ3ÔºåBÁöÑÁ¨¨0‰∏™ÂÖÉÁ¥†ÊòØ17 ËøôÂ∞±ÊòØÈÅìÈÄÅÂàÜÈ¢ò‰∫ÜÔºåÂµåÂ•óÂæ™ÁéØÂ∞±OK‰∫ÜÔºåÊ≤°‰ªÄ‰πàÂ•ΩËØ¥ÁöÑ„ÄÇ1234567def question3_take(a, b): for i in range(len(a)): for j in range(len(b)): if a[i] + b[j] == 20: print("%d (A%d) + %d (B%d) = 20" % (a[i], i, b[j], j)) return print(" No solution!") ÂÜô‰∏Ä‰∏™ÂáΩÊï∞ÔºåËæìÂÖ•‰∏Ä‰∏™ÈöèÊú∫ÁöÑ01Â∫èÂàóÔºåÊâìÂç∞Âá∫Ëøô‰∏™Â∫èÂàó‰∏≠ÊúÄÈïøÁöÑ01‰∫§ÊõøÂá∫Áé∞ÁöÑÂ∫èÂàóÁöÑËµ∑Âßã‰ΩçÁΩÆÂíåÁªìÊùü‰ΩçÁΩÆ„ÄÇ‰æãÂ¶ÇÔºöËæìÂÖ•‚Äú000101010101101‚ÄùÔºåËæìÂá∫Ëµ∑Âßã‰ΩçÁΩÆ2, ÁªìÊùü‰ΩçÁΩÆ10 ËøôÈ¢òËÆ©ÊàëÁ∫†Áªì‰∫Ü‰∏ãÔºåÂõ†‰∏∫ÈúÄË¶ÅËÆ∞ÂΩïÁöÑ‰ΩçÁΩÆÊúâÁÇπÂ§ö Âõ†‰∏∫Êàë‰ª¨Ë¶ÅÈÅçÂéÜËøô‰∏™Â∫èÂàó‰∏≠ÊâÄÊúâÁöÑ01ÊâÄ‰ª•Ë¶Å‰∏§‰∏™ÊåáÈíàÂêåÊó∂ÁßªÂä®ÊâçËÉΩÁ°Æ‰øù01ÁöÑÂá∫Áé∞ÔºåÂΩìÂá∫Áé∞01Êàë‰ª¨ËÆ°Êï∞Âô®n +1ÔºåÁÑ∂ÂêéÂà§Êñ≠ÊòØÂê¶Âà∞ÁªìÂ∞æÊàñËÄÖ‰∏ã‰∏Ä‰∏™‰∏çÊòØ01ÁöÑÊÉÖÂÜµÔºåÊàë‰ª¨Â∞±ÁªìÊùüËøôÊÆµÔºåËÆ∞ÂΩïËøôÊÆµÁöÑÈïøÂ∫¶ÂíåÁªìÊùüÂºÄÂßãÁöÑ‰ΩçÁΩÆÔºåÂ¶ÇÊûú‰∏ã‰∏ÄÊÆµÂá∫Áé∞ÁöÑ01ÈïøÊàë‰ª¨Â∞±ÊõøÊç¢Êéâ‰∏äÊ¨°ÁöÑËÆ∞ÂΩï„ÄÇ ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØ01ÂèØËÉΩÂá∫Áé∞Âú®Â∫èÂàóÁöÑÂ•áÊï∞ÊàñÂÅ∂Êï∞‰Ωç‰∏äÔºåÊâÄ‰ª•Ë¶ÅÈÅçÂéÜ‰∏§Ê¨°ÔºåÂÜçÊØîËæÉÂ•áÂÅ∂‰∏äÂì™‰∏™ÈïøÔºåËøîÂõûÈïøÁöÑÈÇ£ÊÆµ„ÄÇ 12345678910111213141516171819202122232425def func(i, j, num): start, end, n, count = 0, 0, 0, 0 while j &lt; len(num): if num[i] is '0' and num[j] is '1': n += 1 if j+1 &gt;= len(num) - 1 or num[i+2] is '1' or num[j+2] is '0': if n &gt; count: count = n n = 0 end = j + 1 start = end - count*2 i += 2 j += 2 return start, enddef question4(num): i, j = 0, 1 start1, end1 = func(i, j, num) i, j = 1, 2 start2, end2 = func(i, j, num) if end1 - start1 &gt; end2- start2: return start1, end1 else: return start2, end2]]></content>
      <categories>
        <category>ÁÆóÊ≥ïÁªÉ‰π†</category>
      </categories>
      <tags>
        <tag>ÁÆóÊ≥ï</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[„ÄêËΩ¨„ÄëÊú∫Âô®Â≠¶‰π†Ê≥ïÂàôÔºöMLÂ∑•Á®ãÁöÑÊúÄ‰Ω≥ÂÆûË∑µ]]></title>
    <url>%2F2018%2F05%2F21%2F%5B%E8%BD%AC%5D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B3%95%E5%88%99%EF%BC%9AML%E5%B7%A5%E7%A8%8B%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Êú∫Âô®Â≠¶‰π†Ê≥ïÂàôÔºöMLÂ∑•Á®ãÁöÑÊúÄ‰Ω≥ÂÆûË∑µ ‰ΩúËÄÖÊó†ÈÇ™Êú∫Âô®Â≠¶‰π†Á†îÁ©∂ËÄÖÔºå‰∫∫Â∑•Êô∫ÈöúÊé®ËøõËÄÖ„ÄÇMartin Zinkevich Âú®2016Âπ¥Â∞Ü google ÂÜÖÂÆπÂ§öÂπ¥ÂÖ≥‰∫éÊú∫Âô®Â≠¶‰π†Áõ∏ÂÖ≥ÁöÑÁªèÈ™åÂàÜ‰∫´‰∫ÜÂá∫Êù•ÔºåËøôÁØáÊñáÁ´†ÊòØÂØπËØ•ÂàÜ‰∫´ÁöÑ‰∏Ä‰∫õÁøªËØë+Ëß£ËØªÔºåÂ¶ÇÊûúÊÉ≥Êü•ÁúãÂéüÊñáËØ∑ÂèÇËßÅÔºöhttps://developers.google.com/machine-learning/rules-of-ml/&nbsp;„ÄÇÊúØËØ≠Âú®ËØ¥Âà∞ÂÖ∑‰ΩìÁöÑÁõ∏ÂÖ≥ÁªèÈ™å‰πãÂâçÔºåÂÖàÊù•‰∫ÜËß£‰∏ãÂ∏∏Áî®ÁöÑÊúØËØ≠„ÄÇÁ§∫‰æãÔºàInstanceÔºâÔºöÈÇ£‰∫õ‰Ω†Ë¶Å‰∏∫ÂÖ∂ÂÅöÂá∫È¢ÑÊµãÁöÑ‰∫ãÁâ©Áß∞‰∏∫Á§∫‰æã„ÄÇ‰æãÂ¶ÇÔºåÁ§∫‰æãÂèØËÉΩÊòØ‰∏Ä‰∏™ÁΩëÈ°µÔºå‰Ω†Ë¶ÅÂ∞ÜÂÖ∂ÂΩí‰∏∫‚ÄúÂÖ≥‰∫éÁå´ÁöÑ‚ÄùÁΩëÈ°µÊàñËÄÖ‚Äú‰∏çÊòØÂÖ≥‰∫éÁå´ÁöÑ‚ÄùÁΩëÈ°µ„ÄÇÊ†áÁ≠æÔºàLabelÔºâÔºöÈ¢ÑÊµã‰ªªÂä°ÁöÑÁ≠îÊ°àÊàñÁªìÊûúÁß∞‰∏∫Ê†áÁ≠æ„ÄÇÊó†ËÆ∫ÊòØÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑÁ≠îÊ°àÊàñÁªìÊûúÔºåËøòÊòØËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁ≠îÊ°àÊàñÁªìÊûúÔºåÈÉΩÂèØ‰ª•Áß∞‰∏∫Ê†áÁ≠æ„ÄÇ‰æãÂ¶ÇÔºåÂ∞ÜÁΩëÈ°µÊ†áËÆ∞‰∏∫‚ÄúÂÖ≥‰∫éÁå´ÁöÑ‚Äù„ÄÇÁâπÂæÅÔºàFeatureÔºâÔºöÈ¢ÑÊµã‰ªªÂä°‰∏≠Á§∫‰æãÁöÑÂ±ûÊÄßÂç≥‰∏∫‚ÄúÁâπÂæÅ‚Äù„ÄÇ‰æãÂ¶ÇÔºåÁΩëÈ°µÂèØ‰ª•Êúâ‚ÄúÂåÖÂê´ËØçÊ±á‚ÄòÁå´‚Äô‚ÄùÁöÑÁâπÂæÅ„ÄÇÁâπÂæÅÊ†èÔºàFeature ColumnÔºâÔºöÁâπÂæÅÊ†èÊòØÁõ∏ÂÖ≥ÁâπÂæÅÁöÑÈõÜÂêàÔºåÂ¶ÇÁî®Êà∑ÊâÄ‰ΩèÂú∞Âå∫Â≠òÂú®ÁöÑÊâÄÊúâÂèØËÉΩÂõΩÁ±çÁöÑÈõÜÂêà„ÄÇÂú®Âêå‰∏Ä‰∏™Ê†∑Êú¨ÁöÑÂêå‰∏Ä‰∏™ÁâπÂæÅÊ†è‰∏≠ÂèØËÉΩÊúâ‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÁâπÂæÅ„ÄÇÁâπÂæÅÊ†èÁõ∏ÂΩì‰∫éÔºàÈõÖËôéÊàñÂæÆËΩØÁöÑÔºâËôöÊãüÊú∫Á≥ªÁªüÁöÑ ‚ÄúÂëΩÂêçÁ©∫Èó¥ÔºànamespaceÔºâ‚ÄùÊàñ‚ÄúÂüüÔºàfieldÔºâ‚Äù„ÄÇÊ†∑Êú¨ÔºàExampleÔºâÔºöÊ†∑Êú¨ÂåÖÂê´Á§∫‰æãÔºàÂÖ∑ÊúâÂêÑÁßçÁâπÂæÅÔºâÂíå‰∏Ä‰∏™Ê†áÁ≠æ„ÄÇÊ®°ÂûãÔºàModelÔºâÔºöÊ®°ÂûãÊòØÈ¢ÑÊµã‰ªªÂä°ÁöÑÊï∞Â≠¶Ë°®ËææÂΩ¢Âºè„ÄÇÂÖàÊòØÈÄöËøáÊ†∑Êú¨ËÆ≠ÁªÉÊ®°ÂûãÔºåËÄåÂêéÂà©Áî®Ê®°ÂûãÂÅöÂá∫È¢ÑÊµã„ÄÇÊåáÊ†áÔºàMetricÔºâÔºöÊåáÊ†áÊòØÊåá‰∏ÄÁ≥ªÂàóÁöÑÊï∞Â≠óÔºåËøô‰∫õÊï∞Â≠óÁõ¥Êé•ÊàñÈó¥Êé•ÁöÑÈÉΩË¢´‰ºòÂåñËøá„ÄÇÁõÆÊ†áÔºàObjectiveÔºâÔºöÁõÆÊ†áÊòØÊåáÁÆóÊ≥ïÁªèËøá‰ºòÂåñÔºåÂä™ÂäõË¶ÅËææÂà∞ÁöÑÂ∫¶ÈáèÊ†áÂáÜ„ÄÇÂ∑•‰ΩúÊµÅÔºàPipelineÔºâÔºöÂ∑•‰ΩúÊµÅÊåáÁöÑÊòØÂõ¥ÁªïÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïËÄåÂ≠òÂú®ÁöÑÂü∫Á°ÄÊû∂ÊûÑ„ÄÇ‰ªéÂâçÁ´ØÊêúÈõÜÊï∞ÊçÆ„ÄÅÂ∞ÜÊêúÈõÜÂà∞ÁöÑÊï∞ÊçÆÊîæÂÖ•ËÆ≠ÁªÉÊï∞ÊçÆÊñá‰ª∂Â§π„ÄÅËÆ≠ÁªÉ‰∏Ä‰∏™ÊàñÂ§ö‰∏™Ê®°Âûã‰ª•ÂèäÂ∞ÜÊ®°ÂûãÁî®‰∫éÁîü‰∫ßÁ≠âËøáÁ®ãÔºåÈÉΩÂ±û‰∫éÂ∑•‰ΩúÊµÅ„ÄÇÁÇπÂáªÁéáÔºàClick-through RateÔºâÔºöÁî®Êà∑ÊµèËßàÁΩëÈ°µÊó∂ÂØπÂåÖÂê´ÂπøÂëäÈìæÊé•ÁöÑÁÇπÂáªÊ¨°Êï∞Âç†ÊµèËßàÊ¨°Êï∞ÁöÑÁôæÂàÜÊØî„ÄÇÊ¶ÇËø∞Ë¶ÅÊÉ≥ÂàõÈÄ†Âá∫‰ºòÁßÄÁöÑ‰∫ßÂìÅÔºö‰Ω†ÈúÄË¶Å‰ª•‰∏Ä‰Ωç‰ºòÁßÄÂ∑•Á®ãÂ∏àÁöÑË∫´‰ªΩÂéªËøêÁî®Ê∑±Â∫¶Â≠¶‰π†ÔºÅËÆ∞‰ΩèÔºÅ‰Ω†‰∏çÂçïÂçïÊòØ‰∏Ä‰ΩçÊú∫Âô®Â≠¶‰π†ÁöÑÁ†îÁ©∂ËÄÖÔºÅ‰∫ãÂÆû‰∏äÔºå‰Ω†ÊâÄÈù¢‰∏¥ÁöÑÂ§ßÂ§öÊï∞ÈóÆÈ¢òÈÉΩÊòØÂ∑•Á®ãÈóÆÈ¢ò„ÄÇÂç≥‰æøÊã•ÊúâË∂≥‰ª•Â™≤ÁæéÊú∫Âô®Â≠¶‰π†‰∏ìÂÆ∂ÁöÑÁêÜËÆ∫Áü•ËØÜÔºåË¶ÅÊÉ≥ÊúâÊâÄÁ™ÅÁ†¥ÔºåÂ§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÈÉΩÂú®‰æùËµñÁ§∫‰æãÁöÑËâØÂ•ΩÁâπÂæÅÔºåËÄåÈùû‰ºòÁßÄÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÂü∫Êú¨ÊñπÊ≥ïÂ¶Ç‰∏ãÔºöÁ°Æ‰øù‰Ω†ÁöÑÂ∑•‰ΩúÊµÅÂêÑËøûÊé•Á´ØÂçÅÂàÜÂèØÈù†‰ªéÊ†ëÁ´ãÂêàÁêÜÁöÑÁõÆÊ†áÂºÄÂßãÁî®ÁÆÄÂçïÁöÑÊñπÂºèÔºåÊ∑ªÂä†Á¨¶ÂêàÂ∏∏ËØÜÁöÑÁâπÂæÅÁ°Æ‰øù‰Ω†ÁöÑÂ∑•‰ΩúÊµÅÂßãÁªàÂèØÈù†ËøôÁßçÊñπÊ≥ïËÉΩÂ∏¶Êù•Áõ∏ÂΩìÂ§öÁöÑÁõàÂà©Ôºå‰πüËÉΩÂú®ËæÉÈïøÊó∂Èó¥Èáå‰ª§ËÆ∏Â§ö‰∫∫ÈÉΩÊª°ÊÑèÔºåÁîöËá≥ËøòÂèØËÉΩÂÆûÁé∞ÂèåËµ¢„ÄÇÂè™ÊúâÂú®ÁÆÄÂçïÊäÄÂ∑ß‰∏çÂèëÊå•‰ªª‰Ωï‰ΩúÁî®ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊâçËÄÉËôë‰ΩøÁî®Â§çÊùÇÁöÑ‰∏Ä‰∫õÁöÑÊñπÊ≥ï„ÄÇÊñπÊ≥ïË∂äÂ§çÊùÇÔºå‰∫ßÂìÅÊúÄÁªàËæìÂá∫ÈÄüÂ∫¶ÊÖ¢„ÄÇÂΩìÊâÄÊúâÁöÑÁÆÄÂçïÊäÄÂ∑ßÁî®ÂÆåÂêéÔºåÂæàÂèØËÉΩÂ∞±Ë¶ÅËÄÉËôëÊúÄÂâçÊ≤øÊú∫Âô®Â≠¶‰π†ÊúØ‰∫Ü„ÄÇÊú¨ÊñáÊ°£‰∏ªË¶ÅÁî±ÂõõÈÉ®ÂàÜÁªÑÊàêÔºöÁ¨¨‰∏ÄÈÉ®ÂàÜÔºöÂ∏ÆÂä©‰Ω†ÊòéÁôΩÊòØÂê¶Âà∞‰∫ÜÈúÄË¶ÅÊûÑÂª∫‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁ¨¨‰∫åÈÉ®ÂàÜÔºöÈÉ®ÁΩ≤‰Ω†ÁöÑÁ¨¨‰∏Ä‰∏™Â∑•‰ΩúÊµÅÁ¨¨‰∏âÈÉ®ÂàÜÔºöÂæÄÂ∑•‰ΩúÊµÅÂ¢ûÂä†Êñ∞ÁâπÂæÅÊó∂ÁöÑÂèëÂ∏ÉÂíåËø≠‰ª£Ôºå‰ª•ÂèäÂ¶Ç‰ΩïËØÑ‰ª∑Ê®°ÂûãÂíåËÆ≠ÁªÉ-ÊúçÂä°ÂÄæÊñúÔºàtraining-serving shew)Á¨¨ÂõõÈÉ®ÂàÜÔºöËææÂà∞Á®≥ÂÆöÈò∂ÊÆµÂêéËØ•ÁªßÁª≠ÂÅö‰ªÄ‰πà„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰πãÂâçRule #1:Don‚Äôt be afraid to launch a product without machine learning.Ê≥ïÂàô 1:‰∏çË¶ÅÂÆ≥ÊÄïÂèëÂ∏É‰∏ÄÊ¨æÊ≤°ÊúâÁî®Âà∞Êú∫Âô®Â≠¶‰π†ÁöÑ‰∫ßÂìÅÊú∫Âô®Â≠¶‰π†ÊòØÂæàÈÖ∑Ôºå‰ΩÜÂÆÉÈúÄË¶ÅÊï∞ÊçÆ„ÄÇÂ¶ÇÊûú‰Ω†ËÆ§‰∏∫Êú∫Âô®Â≠¶‰π†ÂèØ‰ª•ÊèêÈ´ò 100% Êî∂ÁõäÔºåÈÇ£‰πàÂêØÂèëÂºèËßÑÂàôÂèØ‰ª•Ëé∑Âæó 50% Êî∂Áõä„ÄÇRule #2: First, design and implement metrics.Ê≥ïÂàô2ÔºöÈ¶ñÂÖàÈúÄË¶ÅËÆæËÆ°ÂíåÂÆûÁé∞ËØÑ‰º∞ÊåáÊ†áÂú®ÊûÑÂª∫ÂÖ∑‰ΩìÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªü‰πãÂâçÔºåÈ¶ñÂÖàÂú®ÂΩìÂâçÁ≥ªÁªü‰∏≠ËÆ∞ÂΩïÂ∞ΩÈáèËØ¶ÁªÜÁöÑÂéÜÂè≤‰ø°ÊÅØ„ÄÇÂéüÂõ†Â¶Ç‰∏ãÔºöÂú®Êó©ÊúüÔºåÊõ¥ÂÆπÊòìËé∑ÂæóÁ≥ªÁªüÁî®Êà∑ÁöÑÊùÉÈôêËÆ∏ÂèØÔºàËé∑ÂæóÁ≥ªÁªüÁî®Êà∑ÊùÉÈôêÂêéÔºåÊõ¥ÂÆπÊòìÊî∂ÈõÜÂêÑÁßçÊï∞ÊçÆÔºâ„ÄÇÂ¶ÇÊûú‰Ω†ËßâÂæóÊüê‰∏™ÈóÆÈ¢ò‰ª•Âêé‰ºöÂèóÂà∞ÂÖ≥Ê≥®ÔºåÊúÄÂ•ΩÊòØ‰ªéÁé∞Áä∂ÂºÄÂßãÂ∞±ÊêúÈõÜÂéÜÂè≤Êï∞ÊçÆ„ÄÇÂ¶ÇÊûúËÆæËÆ°Á≥ªÁªüÁöÑÊó∂ÂÄôËÄÉËôë‰∫ÜËØÑ‰º∞ÊåáÊ†áÔºåËøôÂØπÂ∞ÜÊù•‰ºöÂ§ßÊúâÁõäÂ§Ñ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåËøôÊòØ‰∏∫‰∫ÜËÆ©‰Ω†‰ª•Âêé‰∏çÁî®Âú®Êó•ÂøóÊñá‰ª∂‰∏≠ÂØªÊâæÁõ∏ÂÖ≥ÁöÑÂ≠óÁ¨¶‰∏≤„ÄÇ‰Ω†ËÉΩÂ§üÊ≥®ÊÑèÂà∞‰ªÄ‰πàÔºàÈöèÁùÄÊó∂Èó¥ÔºâÊîπÂèò‰∫ÜÔºå‰ªÄ‰πàÔºàÈöèÁùÄÊó∂Èó¥ÔºâÊ≤°ÊúâÊîπÂèò„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåÂÅáËÆæ‰Ω†ÊÉ≥Ë¶ÅÁõ¥Êé•‰ºòÂåñ‰∏ÄÂ§©ÁöÑÊ¥ªË∑ÉÁî®Êà∑Èáè„ÄÇÁÑ∂ËÄåÂú®Êó©ÊúüÂØπÁ≥ªÁªüÁöÑÂ§ÑÁêÜ‰∏≠ÂèØËÉΩ‰ºöÂèëÁé∞Áî®Êà∑‰ΩìÈ™åÁöÑÂèòÂåñÂπ∂Ê≤°ÊúâÊòæËëóÊîπÂèòÊ¥ªË∑ÉÁî®Êà∑ÈáèÁöÑÂ∫¶Èáè„ÄÇRule #3: Choose machine learning over a complex heuristic.Ê≥ïÂàô3Ôºö‰ºòÂÖàÈÄâÊã©Êú∫Âô®Â≠¶‰π†ËÄå‰∏çÊòØÂ§çÊùÇÁöÑÂêØÂèëÂºèËßÑÂàôÁÆÄÂçïÁöÑÂêØÂèëÂºèÊñπÊ≥ïÂèØ‰ª•ËΩªÊùæÂ∫îÁî®Âà∞‰∫ßÂìÅ‰∏äÔºåËÄåÂ§çÊùÇÁöÑÂêØÂèëÂºèÊñπÊ≥ïÂç¥Èöæ‰ª•Áª¥Êä§„ÄÇ‰∏ÄÊó¶‰Ω†Êã•Êúâ‰∫ÜË∂≥Â§üÁöÑÊï∞ÊçÆÔºåÂπ∂‰∏îÂØπË¶ÅÂÆûÁé∞ÁöÑÁõÆÊ†áÊúâ‰∫ÜÂü∫Êú¨ÁöÑÊ¶ÇÂøµÔºåÈÇ£Â∞±ËΩ¨ÂêëÊú∫Âô®Â≠¶‰π†Âêß„ÄÇÂú®Â§ßÂ§öÊï∞ËΩØ‰ª∂Â∑•Á®ã‰∏≠Ôºå‰∏çÁÆ°‰ΩøÁî®ÁöÑÊòØÂêØÂèëÊñπÊ≥ïËøòÊòØÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºåÈÉΩÈúÄË¶ÅÁªèÂ∏∏Êõ¥Êñ∞ÁÆóÊ≥ï„ÄÇ‰ΩÜÊòØ‰Ω†‰ºöÂèëÁé∞Ôºå‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÊ®°ÂûãÊõ¥ÂÆπÊòìÊõ¥Êñ∞ÂíåÁª¥Êä§„ÄÇÊú∫Âô®Â≠¶‰π†Èò∂ÊÆµ 1ÔºöÁ¨¨‰∏ÄÊù°Â∑•‰ΩúÊµÅÊûÑÂª∫Á¨¨‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†Â∑•‰ΩúÊµÅÊó∂Ôºå‰∏ÄÂÆöË¶ÅÊõ¥Â§öÂÖ≥Ê≥®Á≥ªÁªüÂü∫Á°ÄÊû∂ÊûÑÁöÑÂª∫ËÆæ„ÄÇËôΩÁÑ∂Êú∫Âô®Â≠¶‰π†ÁöÑÁÆóÊ≥ï‰ª§‰∫∫ÊøÄÂä®Ôºå‰ΩÜÊòØÂõ†‰∏∫Âü∫Á°ÄÊû∂ÊûÑ‰∏çÁªôÂäõÊâæ‰∏çÂà∞ÈóÆÈ¢òÊó∂‰ºö‰ª§‰∫∫ÊäìÁãÇ„ÄÇRule #4: Keep the first model simple and get the infrastructure right.Ê≥ïÂàô4ÔºöÁ¨¨‰∏Ä‰∏™Ê®°ÂûãË¶ÅÁÆÄÂçïÔºå‰ΩÜÊòØÂü∫Á°ÄÊû∂ÊûÑË¶ÅÊ≠£Á°ÆÁ¨¨‰∏Ä‰∏™Ê®°ÂûãÂØπ‰Ω†ÁöÑ‰∫ßÂìÅÊèêÈ´òÊúÄÂ§ßÔºåÂõ†Ê≠§ÂÆÉ‰∏çÈúÄË¶ÅÊúâÂ§öËä±Âì®„ÄÇÁõ∏ÂèçÔºå‰Ω†‰ºöÁ¢∞Âà∞ÊØî‰Ω†ÊÉ≥Ë±°ÁöÑÂ§öÁöÑÂü∫Á°ÄÊû∂ÊûÑÊñπÈù¢ÁöÑÈóÆÈ¢ò„ÄÇÂú®Âà´‰∫∫‰ΩøÁî®‰Ω†ÁöÑÁöÑÊñ∞Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÂâçÔºå‰Ω†ÈúÄË¶ÅÁ°ÆÂÆöÔºöÂ¶Ç‰Ωï‰∏∫‰Ω†ÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂæóÂà∞Ê†∑Êú¨‰∏∫‰Ω†ÁöÑÁ≥ªÁªüÂàùÊ≠•ÂÆö‰πâ‚ÄúÂ•Ω‚Äù‰∏é‚ÄúÂùè‚ÄùÁöÑÊ†áÂáÜÂ¶Ç‰ΩïÂ∞ÜÊ®°ÂûãÈõÜÊàêÂà∞Â∫îÁî®Á®ãÂ∫è‰∏≠„ÄÇ‰Ω†ÂèØ‰ª•Áõ¥Êé•Â∞ÜÊ®°ÂûãÂ∫îÁî®Âà∞Âú®Á∫øÂ∫îÁî®Á®ãÂ∫è‰∏≠Ôºå‰πüÂèØ‰ª•Âú®Á¶ªÁ∫øÊ†∑Êú¨ÁöÑÂü∫Á°Ä‰∏äÂØπÊ®°ÂûãËøõË°åÈ¢ÑËÆ°ÁÆóÔºàpreÔºçcomputeÔºâÔºåÁÑ∂ÂêéÊää‰∏éËÆ°ÁÆóÁöÑÁªìÊûúÂÇ®Â≠òÂú®Ë°®Ê†º‰∏≠„ÄÇÈÄâÊã©ÁÆÄÂçïÁöÑÁâπÂæÅÔºåËøôÊ†∑‰ºöÊõ¥ÂÆπÊòìÁ°Æ‰øùÔºöÁâπÂæÅÊ≠£Á°ÆÂ∫îÁî®Âà∞ÁÆóÊ≥ï‰∏≠Ê®°ÂûãËÉΩÂ§üÂ≠¶‰π†Âà∞ÂêàÁêÜÁöÑÊùÉÈáçÁâπÂæÅÊ≠£Á°ÆÂ∫îÁî®Âà∞ÊúçÂä°Âô®Ê®°ÂûãÔºà‰πüÂ∞±ÊòØÁîü‰∫ßÁéØÂ¢ÉÁöÑÊ®°ÂûãÔºâ‰∏≠‰Ω†ÁöÑÁ≥ªÁªüÂ¶ÇÊûúËÉΩÂ§üÂèØÈù†Âú∞ÈÅµÂÆàËøô‰∏âÁÇπÔºå‰Ω†Â∞±ÂÆåÊàê‰∫ÜÂ§ßÂ§öÊï∞Â∑•‰Ωú„ÄÇ‰Ω†ÁöÑÁÆÄÂçïÊ®°ÂûãËÉΩÂ§üÊèê‰æõÂü∫ÂáÜÊåáÊ†áÂíåÂü∫ÂáÜË°å‰∏∫Ôºå‰Ω†ÂèØ‰ª•Áî®Êù•ÊµãÈáèÊõ¥Âä†Â§çÊùÇÁöÑÊ®°Âûã„ÄÇRule #5: Test the infrastructure independently from the machine learning.Ê≥ïÂàô5ÔºöÁã¨Á´ã‰∫éÊú∫Âô®Â≠¶‰π†Êù•ÊµãËØïÊû∂ÊûÑÊµÅÁ®ã‰∏ç‰ªÖÈúÄË¶ÅÁ°Æ‰øùÂü∫Á°ÄÊû∂ÊûÑÁöÑÂèØÊµãËØïÊÄßÔºåËøòÈúÄË¶ÅÁ°Æ‰øùÁ≥ªÁªüÁöÑÂ≠¶‰π†ÈÉ®ÂàÜÔºàlearning partÔºâÊòØÂ∞ÅË£ÖÂ•ΩÁöÑÔºàencapsulatedÔºâÔºåËøôÊ†∑ÊâçËÉΩÊµãËØïÊâÄÊúâ‰∏é‰πãÁõ∏ÂÖ≥ÁöÑÈÉ®‰ª∂„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºöÊµãËØïËæìÂÖ•Âà∞ÁÆóÊ≥ï‰∏≠ÁöÑÊï∞ÊçÆ„ÄÇÊ£ÄÊü•Â∫îËØ•Â°´ÂÖÖÁöÑÁâπÂæÅÊ†èÊòØÂê¶Ê≠£Á°ÆÂ°´ÂÖÖ„ÄÇÊµãËØïÊ®°ÂûãÂú®ËÆ≠ÁªÉÁÆóÊ≥ï‰πãÂ§ñÁöÑËøêË°åÊÉÖÂÜµ„ÄÇÁ°Æ‰øùÊ®°ÂûãÁöÑËÆ≠ÁªÉÁéØÂ¢É‰∏≠ÂíåÊúçÂä°ÁéØÂ¢É‰∏≠ÁöÑÂæóÂàÜÁõ∏Âêå„ÄÇÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™ÁâπÁÇπÂ∞±ÊòØ‰∏çÂèØÈ¢ÑÊµãÊÄß„ÄÇÂõ†Ê≠§Ôºå‰Ω†ÂøÖÈ°ªÁ°Æ‰øùÂú®ËÆ≠ÁªÉÂíåÂÆûÈôÖËøêË°å‰∏≠ÂàõÈÄ†Ê†∑Êú¨ÁöÑ‰ª£Á†ÅËÉΩË¢´ÊµãËØïÔºåÂπ∂‰∏îÂú®ÂÆûÈôÖËøêË°å‰∏≠ÂßãÁªà‰ΩøÁî®Âêå‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÊ®°Âûã„ÄÇRule #6: Be careful about dropped data when copying pipelines.Ê≥ïÂàô6ÔºöÂ§çÂà∂Â∑•‰ΩúÊµÅÊó∂ÁïôÊÑè‰∏¢Â§±ÁöÑÊï∞ÊçÆÊàë‰ª¨ÊúâÊó∂ÂÄô‰ºöÈÄöËøáÂ§çÂà∂Â∑≤ÁªèÂ≠òÂú®ÁöÑÂ∑•‰ΩúÊµÅÊù•ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÂ∑•‰ΩúÊµÅ„ÄÇÂú®Êñ∞ÁöÑÂ∑•‰ΩúÊµÅ‰∏≠ÈúÄË¶ÅÁöÑÊï∞ÊçÆÔºåÂæàÂèØËÉΩÂú®ÊóßÁöÑÊï∞ÊçÆÊµÅÂ∞±‰∏¢ÂºÉ‰∫Ü„ÄÇRule #7: Turn heuristics into features, or handle them externally.Ê≥ïÂàô 7: Â∞ÜÂêØÂèëËßÑÂàôËΩ¨Âåñ‰∏∫ÁâπÂæÅÔºåÊàñËÄÖÂú®Â§ñÈÉ®Â§ÑÁêÜÂÆÉ‰ª¨Êú∫Âô®Â≠¶‰π†Á≥ªÁªüËß£ÂÜ≥ÁöÑÈóÆÈ¢òÈÄöÂ∏∏ÈÉΩ‰∏çÊòØÊñ∞ÈóÆÈ¢òÔºåËÄåÊòØÂØπÂ∑≤ÊúâÈóÆÈ¢òÁöÑËøõ‰∏ÄÊ≠•‰ºòÂåñ„ÄÇËøôÊÑèÂë≥ÁùÄÊúâÂæàÂ§öÂ∑≤ÊúâÁöÑËßÑÂàôÊàñËÄÖÂêØÂèëÂºèËßÑÂàôÂèØ‰æõ‰ΩøÁî®„ÄÇËøôÈÉ®ÂàÜ‰ø°ÊÅØÂ∫îËØ•Ë¢´ÂÖÖÂàÜÂà©Áî®„ÄÇ‰∏ãÈù¢ÊòØÂá†ÁßçÂêØÂèëÂºèËßÑÂàôÂèØ‰ª•Ë¢´‰ΩøÁî®ÁöÑÊñπÂºèÔºöÁî®ÂêØÂèëÂºèËßÑÂàôËøõË°åÈ¢ÑÂ§ÑÁêÜ„ÄÇ Ëã•ÁâπÂæÅÁõ∏ÂΩìÂÆåÁæéÔºåÂàôÂèØ‰ª•ÈááÁî®Ëøô‰∏™ÊñπÊ≥ï„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåÂú®ÂûÉÂúæÈÇÆ‰ª∂ËøáÊª§Âô®‰∏≠ÔºåÂ¶ÇÊûúÂèë‰ª∂‰∫∫Â∑≤ÁªèË¢´Âä†ÂÖ•ÈªëÂêçÂçï‰∫ÜÔºåÂàôÂèØ‰ª•‰∏çÁî®ÈáçÊñ∞Â≠¶‰π†‚ÄúÈªëÂêçÂçï‚ÄùÁöÑÊ¶ÇÂøµ„ÄÇÁõ¥Êé•ÈòªÊ≠¢ËØ•‰ø°ÊÅØÂ∞±ÂèØ‰ª•ÔºÅËøôÁßçÊñπÊ≥ïÂú®‰∫åÂÖÉÂàÜÁ±ªÔºàbinary classificationÔºâ‰ªªÂä°‰∏≠ÂæàÊúâÁî®„ÄÇÂàõÂª∫ÁâπÂæÅ„ÄÇ Áõ¥Êé•‰ªéÂêØÂèëÂºèËßÑÂàô‰∏≠ÂàõÂª∫ÁâπÂæÅ‰ºöÂæà‰æøÊç∑„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåËã•Ë¶ÅÁî®ÂêØÂèëÂºèËßÑÂàô‰∏∫Êüê‰∏™Êü•ËØ¢ÁªìÊûúËÆ°ÁÆóÁõ∏ÂÖ≥Â∫¶Ôºå‰Ω†ÂèØ‰ª•ÊääÂàÜÊï∞Á∫≥ÂÖ•ÁâπÂæÅÁöÑÂÄº‰∏≠„ÄÇÊé•‰∏ãÊù•ÔºåÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÊñπÊ≥ïÊù•Â§ÑÁêÜËøô‰∫õÂÄºÔºà‰æãÂ¶ÇÔºåÊääËøô‰∫õÂÄºËΩ¨Âåñ‰∏∫Áî±‰∏ÄÁ≥ªÂàóÁ¶ªÊï£ÂÄºÁªÑÊàêÁöÑÊúâÈôêÈõÜÔºåÊàñËÄÖ‰πüÂèØ‰ª•‰∏éÂÖ∂ÂÆÉÁâπÂæÅÁõ∏ÁªìÂêàÔºâÔºå‰ΩÜÊòØË¶Å‰ªéÂêØÂèëÂºèÊñπÊ≥ïÁîüÊàêÁöÑÂéüÂßãÊï∞ÊçÆÂÖ•Êâã„ÄÇÊåñÊéòÂêØÂèëÂºèÊñπÊ≥ïÁöÑÂéüÂßãËæìÂÖ•Êï∞ÊçÆ„ÄÇ ÂØπ‰∫éÊüêÊ¨æ appÔºåËã•Â≠òÂú®‰∏Ä‰∏™ÂêØÂèëÂºèÊñπÊ≥ïÔºåÂÖ∂ÂåÖÂê´ÂÆâË£ÖÈáè„ÄÅÊñáÊú¨Â≠óÁ¨¶Êï∞ÂíåÂΩìÂ§©Êó•ÊúüÁ≠âË¶ÅÁ¥†ÔºåÂèØ‰ª•ËÄÉËôëÂ∞ÜËøô‰∫õÂéüÂßã‰ø°ÊÅØÂçïÁã¨‰Ωú‰∏∫ÁâπÂæÅ‰ΩøÁî®„ÄÇ‰øÆÊîπÊ†áÁ≠æ„ÄÇÂΩì‰Ω†ÂèëËßâÂêØÂèëÂºèÊñπÊ≥ïÊçïÊçâ‰∫Ü‰∏Ä‰∫õ‰ø°ÊÅØÔºåËÄåËøô‰∫õ‰ø°ÊÅØÊ≤°ÊúâÂåÖÂê´Âú®Ê†áËÆ∞‰∏≠ÔºåËøôÊó∂ÂèØ‰ª•ËÄÉËôëËØ•ÈÄâÈ°π„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåÂ¶ÇÊûú‰Ω†ÊÉ≥ËÆ©‰∏ãËΩΩÈáèËææÂà∞ÊúÄÂ§ßÔºå‰ΩÜÂêåÊó∂ÂØπÂÜÖÂÆπÁöÑË¥®ÈáèÊúâË¶ÅÊ±ÇÔºåÈÇ£‰πàÂèØ‰ª•Áî® app ÁöÑÂπ≥ÂùáËØÑÁ∫ß‰πò‰ª•Ê†áËÆ∞Êù•Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇÁõëÊéß‰∏ÄËà¨Êù•ËØ¥ÔºåÊâÄÊúâÁ≥ªÁªüÈÉΩË¶ÅËÆæÁΩÆËâØÂ•ΩÁöÑË≠¶Á§∫Á®ãÂ∫èÔºåË≠¶Êä•Á≥ªÁªüÈúÄË¶ÅÈ°∫Âà©ÊâßË°åÔºåÊàñËÄÖËÆæÁΩÆ‰∏Ä‰∏™‰ª™Ë°®ÊùøÈ°µÈù¢Ôºàdashboard pageÔºâ„ÄÇRule #8: Know the freshness requirements of your system.Ê≥ïÂàô 8: ‰∫ÜËß£‰Ω†Á≥ªÁªüÂØπÊñ∞È≤úÂ∫¶ÁöÑË¶ÅÊ±ÇÂ¶ÇÊûú‰Ω†‰ΩøÁî®ÁöÑÊòØ‰∏ÄÂ§©ÂâçÁöÑÊóßÊ®°ÂûãÔºåËøêË°åÁä∂ÂÜµ‰ºö‰∏ãÈôçÂ§öÂ∞ëÔºüÂ¶ÇÊûúÊòØ‰∏ÄÂë®ÂâçÁöÑÂë¢ÔºüÊàñ‰∏Ä‰∏™Â≠£Â∫¶ÂâçÁöÑÂë¢ÔºüÁü•ÈÅì‰ΩïÊó∂ËØ•Âà∑Êñ∞Á≥ªÁªüËÉΩÂ∏ÆÂä©‰Ω†ÂàíÂàÜÁõëÊéßÁöÑ‰ºòÂÖàÁ∫ß„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÊ®°Âûã‰∏ÄÂ§©Ê≤°ÊúâÊõ¥Êñ∞ÔºåÂèóÁõä‰æø‰∏ãÈôç 10%ÔºåÂõ†Ê≠§ÊúâÂøÖË¶ÅÊåáÊ¥æ‰∏ÄÂêçÂ∑•Á®ãÂ∏àÊó∂Êó∂ÂÖ≥Ê≥®ÂÆÉÁöÑÂä®ÊÄÅ„ÄÇÂ§ßÂ§öÊï∞ÂπøÂëäÊúçÂä°Á≥ªÁªüÊØèÂ§©ÈÉΩ‰ºöÊúâÊñ∞ÁöÑÂπøÂëäÈúÄË¶ÅÂ§ÑÁêÜÂíåÊõ¥Êñ∞„ÄÇÊ≠§Â§ñÔºåË¶ÅÁïôÊÑèÁ≥ªÁªüÂØπÊñ∞È≤úÂ∫¶ÁöÑË¶ÅÊ±Ç‰ºöÈöèÁùÄÊó∂Èó¥ÂèòÂåñÔºåÁâπÂà´ÊòØÂú®Ê∑ªÂä†ÊàñÁßªÈô§ÁâπÂæÅÊ†èÁöÑÊó∂ÂÄôÔºåÈúÄË¶ÅÂ∞§‰∏∫Ê≥®ÊÑè„ÄÇRule #9: Detect problems before exporting models.Ê≥ïÂàô 9: ËæìÂá∫ÔºàÂèëÂ∏ÉÔºâÊ®°ÂûãÂâçÂèëÁé∞ÈóÆÈ¢òËÆ∏Â§öÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÈÉΩÂ≠òÂú®ËøôÊ†∑‰∏Ä‰∏™Èò∂ÊÆµÔºöÁõ¥Êé•ÊääÊ®°ÂûãËæìÂá∫ËøêË°å„ÄÇÂ¶ÇÊûúÈóÆÈ¢òÂá∫Áé∞Âú®Ê®°ÂûãËæìÂá∫‰πãÂêéÔºåÈÇ£‰πàËøô‰∏™ÈóÆÈ¢òÂ∞±ÊòØÁî®Êà∑ÊâÄÈù¢‰∏¥ÁöÑÈóÆÈ¢ò„ÄÇËÄåÂ¶ÇÊûúÈóÆÈ¢òÂá∫Áé∞Âú®Ê®°ÂûãËæìÂá∫‰πãÂâçÔºåÂ∞±ÊòØËÆ≠ÁªÉËøáÁ®ã‰∏≠ÁöÑÈóÆÈ¢òÔºåÁî®Êà∑‰∏ç‰ºöÂèëÁé∞„ÄÇËæìÂá∫Ê®°Âûã‰πãÂâçËØ∑ÂÅöÂ•ΩÂÆåÊï¥ÊÄßÊ£ÄÊü•Ôºàsanity checkÔºâ„ÄÇÂÖ∑‰ΩìÊù•ËÆ≤ÔºåÁ°Æ‰øùÊ®°ÂûãÂú®ÁïôÂ≠òÊï∞ÊçÆ‰∏äËøêË°åÂêàÁêÜÔºå‰æãÂ¶ÇAUC„ÄÇRule #10: Watch for silent failures.Ê≥ïÂàô10ÔºöÊ≥®ÊÑèÈöêËóèÊÄßÊïÖÈöúÊØîËµ∑ÂÖ∂ÂÆÉÁ≥ªÁªüÔºåÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÊõ¥ÂÆπÊòìÂá∫Áé∞ÊΩúÂú®ÁöÑÈóÆÈ¢ò„ÄÇÂÅáËÆæÁ≥ªÁªüÁöÑÊüê‰∏™ÁâπÂÆöÁöÑË°®Ê†º‰∏çÂÜçËøõË°åÊõ¥Êñ∞ÔºåÊï¥‰∏™Á≥ªÁªüÈÄöËøáË∞ÉÊï¥‰ªç‰ºö‰øùÊåÅËâØÂ•ΩÁöÑËøêË°åÊ∞¥ÂáÜÔºå‰ΩÜÊòØ‰ºöÊÖ¢ÊÖ¢Ë°∞Âáè„ÄÇÊúâÊó∂Êúâ‰∫õË°®Ê†ºÂá†‰∏™ÊúàÈÉΩ‰∏ç‰ºöÂà∑Êñ∞‰∏ÄÊ¨°ÔºåËÄåÂè™ÈúÄÁÆÄÂçïÁöÑÂà∑Êñ∞Â∞±ËÉΩÂ§ßÂπÖÂ∫¶ÊèêÂçáÁ≥ªÁªüÁöÑËøêË°åÊ∞¥ÂáÜÔºåÊïàÊûúÁîöËá≥Ë∂ÖËøáËØ•Â≠£Â∫¶ÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÈÇ£‰∫õÊ®°ÂûãÔºÅ‰æãÂ¶ÇÔºåÁî±‰∫éÁ≥ªÁªüÂÆûÁé∞ÔºàimplementationÔºâÂèëÁîüÂèòÂåñÔºåÁâπÂæÅÁöÑË¶ÜÁõñËåÉÂõ¥‰πü‰ºöÂèëÁîüÁõ∏Â∫îÁöÑÂèòÂåñÔºöÊØîÂ¶ÇÔºåÊüê‰∏™ÁâπÂæÅÊ†èÂàöÂºÄÂßãÂèØËÉΩÂåÖÂê´ 90%ÁöÑÊ†∑Êú¨ÔºåÊé•‰∏ãÊù•Âç¥ÂèØËÉΩÁ™ÅÁÑ∂‰∏ãÈôçÂà∞ 60ÔºÖ„ÄÇËß£ÂÜ≥ÊñπÊ≥ïÊòØÊòØÂØπÂÖ≥ÈîÆÊï∞ÊçÆÁöÑÁªüËÆ°‰ø°ÊÅØËøõË°åÁõëÊéßÔºåÂπ∂‰∏îÂë®ÊúüÊÄßÂØπÂÖ≥ÈîÆÊï∞ÊçÆËøõË°å‰∫∫Â∑•Ê£ÄÊü•„ÄÇRule #11: Give feature columns owners and documentation.Ê≥ïÂàô 11Ôºö‰∏∫ÁâπÂæÅÊ†èÊåáÂÆöË¥üË¥£‰∫∫Âπ∂ËÆ∞ÂΩïÊñáÊ°£Â¶ÇÊûúÁ≥ªÁªüÁöÑËßÑÊ®°ÊØîËæÉÂ§ßÔºåÂπ∂‰∏îÁâπÂæÅÊ†èÊØîËæÉÂ§öÔºåÈÇ£‰πàÂøÖÈ°ªÊ∏ÖÊ•öÊØè‰∏™ÁâπÂæÅÊ†èÁöÑÂàõÂª∫ËÄÖÊàñËÄÖÁª¥Êä§ËÄÖ„ÄÇÂ¶ÇÊûúÊüê‰∏™‰∫ÜËß£ËØ•ÁâπÂæÅÊ†èÁöÑ‰∫∫Á¶ªÂºÄ‰∫ÜÔºå‰∏ÄÂÆöË¶ÅÁ°Æ‰øùÂè¶Â§ñËøòÊúâ‰∫∫‰∫ÜËß£ËøôÈÉ®ÂàÜ‰ø°ÊÅØ„ÄÇËôΩÁÑ∂ÂæàÂ§öÁâπÂæÅÊ†èÁöÑÂêçÂ≠óÈùûÂ∏∏Áõ¥ËßÇÔºå‰ΩÜÊúÄÂ•ΩËøòÊòØ‰ΩøÁî®Êõ¥ËØ¶Â∞ΩÁöÑÊñáÊ°£Êù•ÊèèËø∞Ëøô‰∫õÁâπÂæÅÁöÑÂÜÖÂÆπ„ÄÅÊù•Ëá™Âì™Èáå‰ª•ÂèäÂÆÉ‰ª¨ÁöÑ‰ΩúÁî®„ÄÇ‰Ω†ÁöÑÁ¨¨‰∏Ä‰∏™ÁõÆÊ†áÔºàObjectiveÔºâobjective ÊòØÊ®°ÂûãËØïÂõæ‰ºòÂåñÁöÑÂÄºÔºåËÄå metric ÊåáÁöÑÊòØ‰ªª‰ΩïÁî®Êù•ËØÑ‰º∞Á≥ªÁªüÁöÑÂÄº„ÄÇRule #12: Don‚Äôt overthink which objective you choose to directly optimize.Ê≥ïÂàô 12: ‰∏çË¶ÅËøá‰∫éÁ∫†ÁªìËØ•‰ºòÂåñÂì™‰∏™ÁõÆÊ†á‰Ω†ÊúâÊàêÂçÉ‰∏ä‰∏áÂÖ≥ÂøÉÁöÑÊåáÊ†áÔºåËøô‰∫õÊåáÊ†á‰πüÂÄºÂæó‰Ω†ÂéªÊµãËØï„ÄÇ‰ΩÜÊòØÔºåÂú®Êú∫Âô®Â≠¶‰π†ËøáÁ®ãÁöÑÊó©ÊúüÔºå‰Ω†‰ºöÂèëÁé∞ÔºåÂç≥‰Ωø‰Ω†Âπ∂Ê≤°ÊúâÁõ¥Êé•Âéª‰ºòÂåñÔºå‰ªñ‰ª¨‰πüÈÉΩ‰ºö‰∏äÂçá„ÄÇÊØîÂ¶ÇÔºå‰Ω†ÂÖ≥ÂøÉÁÇπÂáªÊ¨°Êï∞ÔºåÂÅúÁïôÊó∂Èó¥‰ª•ÂèäÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑Êï∞„ÄÇÂ¶ÇÊûú‰ªÖ‰ºòÂåñ‰∫ÜÁÇπÂáªÊ¨°Êï∞ÔºåÈÄöÂ∏∏‰πü‰ºöÁúãÂà∞ÂÅúÁïôÊó∂Èó¥Â¢ûÂä†‰∫Ü„ÄÇÊâÄ‰ª•ÔºåÂΩìÊèêÈ´òÊâÄÊúâÁöÑÊåáÊ†áÈÉΩ‰∏çÈöæÁöÑÊó∂ÂÄôÔºåÂ∞±Ê≤°ÂøÖË¶ÅËä±ÂøÉÊÄùÊù•Â¶Ç‰ΩïÊùÉË°°‰∏çÂêåÁöÑÊåáÊ†á„ÄÇ‰∏çËøáËøáÁäπ‰∏çÂèäÔºö‰∏çË¶ÅÊ∑∑Ê∑Ü‰∫Ü‰Ω†ÁöÑÁõÆÊ†áÂíåÁ≥ªÁªüÁöÑÊï¥‰ΩìÂÅ•Â∫∑Â∫¶„ÄÇRule #13: Choose a simple, observable and attributable metric for your first objective.Ê≥ïÂàô 13ÔºöÈÄâÊã©‰∏Ä‰∏™ÁÆÄÂçï„ÄÅÂèØËßÇÊµãÂπ∂‰∏îÂèØÂΩíÁ±ªÁöÑËØÑ‰º∞ÊåáÊ†áÔºàmetricÔºâ‰Ωú‰∏∫‰Ω†ÁöÑÁ¨¨‰∏Ä‰∏™ÁõÆÊ†áÔºàobjectiveÔºâÊúâÊó∂ÂÄô‰Ω†Ëá™‰ª•‰∏∫‰Ω†Ê∏ÖÊ•öÁúüÂÆûÁöÑÁõÆÊ†á,‰ΩÜÈöèÁùÄ‰Ω†ÂØπÊï∞ÊçÆÁöÑËßÇÂØüÔºåÂØπËÄÅÁ≥ªÁªüÂíåÊñ∞ÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÁöÑÂàÜÊûêÔºå‰Ω†‰ºöÂèëÁé∞‰Ω†ÂèàÊÉ≥Ë¶ÅË∞ÉÊï¥„ÄÇËÄå‰∏îÔºå‰∏çÂêåÁöÑÂõ¢ÈòüÊàêÂëòÂØπ‰∫éÁúüÂÆûÁõÆÊ†áÂπ∂‰∏çËÉΩËææÊàê‰∏ÄËá¥„ÄÇÊú∫Âô®Â≠¶‰π†ÁöÑÁõÆÊ†áÂøÖÈ°ªÊòØËÉΩÂæàÂÆπÊòìÊµãÈáèÁöÑÔºåÂπ∂‰∏î‰∏ÄÂÆöÊòØ‚ÄúÁúüÂÆû‚ÄùÁõÆÊ†áÁöÑ‰ª£Ë®Ä„ÄÇÂõ†Ê≠§ÔºåÂú®ÁÆÄÂçïÁöÑÊú∫Âô®Â≠¶‰π†ÁõÆÊ†á‰∏äËÆ≠ÁªÉÔºåÂπ∂ÂàõÂª∫‰∏Ä‰∏™‚ÄúÂÜ≥Á≠ñÂ±Ç‚ÄùÔºå‰ª•ÂÖÅËÆ∏‰Ω†Âú®‰∏äÈù¢Â¢ûÂä†È¢ùÂ§ñÁöÑÈÄªËæëÔºàËøô‰∫õÈÄªËæëÔºåË∂äÁÆÄÂçïË∂äÂ•ΩÔºâÊù•ÂΩ¢ÊàêÊúÄÂêéÁöÑÊéíÂ∫è„ÄÇÊúÄÂÆπÊòìÂª∫Ê®°ÁöÑÊòØÈÇ£‰∫õÂèØ‰ª•Áõ¥Êé•ËßÇÂØüÂπ∂ÂèØÂΩíÂ±ûÂà∞Á≥ªÁªüÁöÑÊüê‰∏™Âä®‰ΩúÁöÑÁî®Êà∑Ë°å‰∏∫ÔºöÊéíÂ∫èÁöÑÈìæÊé•Ë¢´ÁÇπÂáª‰∫ÜÂêóÔºüÊéíÂ∫èÁöÑÁâ©ÂìÅË¢´‰∏ãËΩΩ‰∫ÜÂêóÔºüÊéíÂ∫èÁöÑÁâ©ÂìÅË¢´ËΩ¨Âèë/ÂõûÂ§ç/ÈÇÆ‰ª∂ËÆ¢ÈòÖ‰∫ÜÂêóÔºüÊéíÂ∫èÁöÑÁâ©ÂìÅË¢´ËØÑ‰ª∑‰∫ÜÂêóÔºüÂ±ïÁ§∫ÁöÑÁâ©ÂìÅÊòØÂê¶Ë¢´Ê†áÊ≥®‰∏∫ÂûÉÂúæ/Ëâ≤ÊÉÖ/Êö¥ÂäõÔºüÊúÄÂºÄÂßãË¶ÅÈÅøÂÖçÂØπÈó¥Êé•ÊïàÊûúÂª∫Ê®°ÔºöÁî®Êà∑Á¨¨‰∫åÂ§©‰ºöÊù•ËÆøÂêóÔºüÁî®Êà∑ËÆøÈóÆÊó∂Èó¥ÊòØÂ§öÈïøÔºüÊØèÊó•Ê¥ªË∑ÉÁî®Êà∑ÊòØ‰ªÄ‰πàÊ†∑ÁöÑÔºüÈó¥Êé•ÊïàÊûúÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑÊåáÊ†áÔºåÂú®A/B testÂíåÂèëÂ∏ÉÂÜ≥ÂÆöÁöÑÊó∂ÂÄôÂèØ‰ª•‰ΩøÁî®„ÄÇÊúÄÂêéÔºå‰∏çË¶ÅËØïÂõæËÆ©Êú∫Âô®Â≠¶‰π†Êù•ÂõûÁ≠î‰ª•‰∏ãÈóÆÈ¢òÔºöÁî®Êà∑‰ΩøÁî®‰Ω†ÁöÑ‰∫ßÂìÅÊòØÂê¶ÂºÄÂøÉÁî®Êà∑ÊòØÂê¶ÊúâÊª°ÊÑèÁöÑ‰ΩìÈ™å‰∫ßÂìÅÊòØÂê¶ÊèêÈ´ò‰∫ÜÁî®Êà∑ÁöÑÊï¥‰ΩìÂπ∏Á¶èÊÑüËøô‰∫õÊòØÂê¶ÂΩ±Âìç‰∫ÜÂÖ¨Âè∏ÁöÑÊï¥‰ΩìÂÅ•Â∫∑Â∫¶Ëøô‰∫õÈÉΩÂæàÈáçË¶ÅÔºå‰ΩÜÂ§™ÈöæËØÑ‰º∞‰∫Ü„ÄÇ‰∏éÂÖ∂Â¶ÇÊ≠§Ôºå‰∏çÂ¶ÇËÄÉËôëÂÖ∂‰ªñ‰ª£ÊõøÁöÑÔºöÊØîÂ¶ÇÔºåÁî®Êà∑Â¶ÇÊûúÈ´òÂÖ¥ÔºåÈÇ£ÂÅúÁïôÊó∂Èó¥Â∞±Â∫îËØ•Êõ¥Èïø„ÄÇÂ¶ÇÊûúÁî®Êà∑Êª°ÊÑèÔºå‰ªñÂ∞±‰ºöÂÜçÊ¨°ÈÄ†ËÆø„ÄÇRule #14: Starting with an interpretable model makes debugging easier.Ê≥ïÂàô 14Ôºö‰ªéÂÆπÊòìËß£ÈáäÁöÑÊ®°ÂûãÂÖ•Êâã‰ºöËÆ©Ë∞ÉËØïËøáÁ®ãÊõ¥Âä†ÂÆπÊòìÁ∫øÊÄßÂõûÂΩíÔºåÈÄªËæëÂõûÂΩíÂíåÊ≥äÊùæÂõûÂΩíÁõ¥Êé•Áî±Ê¶ÇÁéáÊ®°ÂûãÊøÄÂèë„ÄÇÊØè‰∏™È¢ÑÊµãÂèØËß£Èáä‰∏∫Ê¶ÇÁéáÊàñÊúüÊúõÂÄº„ÄÇËøô‰ΩøÂæó‰ªñ‰ª¨ÊØîÈÇ£‰∫õ‰ΩøÁî®ÁõÆÊ†áÊù•Áõ¥Êé•‰ºòÂåñÂàÜÁ±ªÂáÜÁ°ÆÊÄßÂíåÊéíÂ∫èÊÄßËÉΩÁöÑÊ®°ÂûãË¶ÅÊõ¥ÂÆπÊòìË∞ÉËØï„ÄÇÊØîÂ¶ÇÔºåÂ¶ÇÊûúËÆ≠ÁªÉÊó∂ÁöÑÊ¶ÇÁéáÂíåÈ¢ÑÊµãÊó∂ÁöÑÊ¶ÇÁéáÔºåÊàñËÄÖÁîü‰∫ßÁ≥ªÁªü‰∏äÁöÑÊü•ÁúãÂà∞ÁöÑÊ¶ÇÁéáÊúâÂÅèÂ∑ÆÔºåÈÇ£ËØ¥ÊòéÂ≠òÂú®ÊüêÁßçÈóÆÈ¢ò„ÄÇRule #15: Separate Spam Filtering and Quality Ranking in a Policy Layer.Ê≥ïÂàô 15ÔºöÂú®Á≠ñÁï•Â±ÇÂ∞ÜÂûÉÂúæ‰ø°ÊÅØËøáÊª§ÂíåË¥®ÈáèÊéíÂêçÂàÜÂºÄË¥®ÈáèÊéíÂêçÊòØ‰∏ÄÈó®Ëâ∫ÊúØÔºåËÄåÂûÉÂúæËøáÊª§ÊòØ‰∏ÄÂú∫Êàò‰∫â„ÄÇÈÇ£‰∫õ‰ΩøÁî®‰Ω†Á≥ªÁªüÁöÑ‰∫∫ÈùûÂ∏∏Ê∏ÖÊ•ö‰Ω†ÈááÁî®‰ªÄ‰πàÊù•ËØÑ‰ª∑‰∏ÄÁØáÂ∏ñÂ≠êÁöÑË¥®ÈáèÔºåÊâÄ‰ª•‰ªñ‰ª¨‰ºöÊÉ≥Â∞ΩÂäûÊ≥ïÊù•‰ΩøÂæó‰ªñ‰ª¨ÁöÑÂ∏ñÂ≠êÂÖ∑ÊúâËøô‰∫õÂ±ûÊÄß„ÄÇÂõ†Ê≠§ÔºåË¥®ÈáèÊéíÂ∫èÂ∫îËØ•ÂÖ≥Ê≥®ÂØπÂì™‰∫õËØöÂÆûÂèëÂ∏ÉÁöÑÂÜÖÂÆπËøõË°åÊéíÂ∫è„ÄÇÂ¶ÇÊûúÂ∞ÜÂûÉÂúæÈÇÆ‰ª∂ÊéíÈ´òÂêçÊ¨°ÔºåÈÇ£Ë¥®ÈáèÊéíÂ∫èÂ≠¶‰π†Âô®Â∞±Â§ßÊâìÊäòÊâ£„ÄÇÂêåÁêÜ‰πüË¶ÅÂ∞ÜÁ≤ó‰øóÁöÑÂÜÖÂÆπ‰ªéË¥®ÈáèÊéíÂ∫è‰∏≠ÊãøÂá∫ÂàÜÂºÄÂ§ÑÁêÜ„ÄÇÂûÉÂúæËøáÊª§Â∞±ÊòØÂè¶Â§ñ‰∏ÄÂõû‰∫ã„ÄÇ‰Ω†ÂøÖÈ°ªËÄÉËôëÂà∞Ë¶ÅÁîüÊàêÁöÑÁâπÂæÅ‰ºöÁªèÂ∏∏ÊÄßÁöÑÊîπÂèò„ÄÇ‰Ω†‰ºöËæìÂÖ•ÂæàÂ§öÊòéÊòæÁöÑËßÑÂàôÂà∞Á≥ªÁªü‰∏≠„ÄÇËá≥Â∞ëË¶Å‰øùËØÅ‰Ω†ÁöÑÊ®°ÂûãÊòØÊØèÊó•Êõ¥Êñ∞ÁöÑ„ÄÇÂêåÊó∂ÔºåË¶ÅÈáçÁÇπËÄÉËôëÂÜÖÂÆπÂàõÂª∫ËÄÖÁöÑ‰ø°Ë™âÈóÆÈ¢ò„ÄÇÊú∫Âô®Â≠¶‰π†Èò∂ÊÆµ 2ÔºöÁâπÂæÅÂ∑•Á®ãÂú®Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁ†îÂèëÂë®ÊúüÁöÑÁ¨¨‰∏ÄÈò∂ÊÆµÔºåÈáçÁÇπÊòØÊääËÆ≠ÁªÉÊï∞ÊçÆÂØºÂÖ•Â≠¶‰π†Á≥ªÁªüÔºåÂæóÂà∞ÊÑüÂÖ¥Ë∂£ÁöÑËØÑ‰ª∑ÊåáÊ†áÔºåÂπ∂ÂàõÂª∫Âü∫Á°ÄÊû∂ÊûÑ„ÄÇÂΩì‰Ω†Êúâ‰∫Ü‰∏Ä‰∏™Á´ØÂØπÁ´ØÁöÑÁ≥ªÁªüÔºåÂπ∂‰∏îËØ•Á≥ªÁªüÁöÑÂçïÂÖÉÂíåÊµãËØïÈÉΩ‰ª™Ë°®Âåñ‰πãÂêéÔºåÁ¨¨‰∫åÈò∂ÊÆµ‰æøÂºÄÂßã‰∫Ü„ÄÇÁ¨¨‰∫åÈò∂ÊÆµÈúÄË¶ÅÁ∫≥ÂÖ•Â∞ΩÂèØËÉΩÂ§öÁöÑÊúâÊïàÁâπÂæÅÔºåÂπ∂‰æùÊçÆÁõ¥ËßÇÁöÑÊÑüËßâÁªÑÂêàËµ∑Êù•„ÄÇÂú®Ëøô‰∏™Èò∂ÊÆµÔºåÊâÄÊúâÁöÑËØÑ‰º∞ÊåáÊ†á‰ªçÁÑ∂‰ºö‰∏äÂçá„ÄÇRule #16: Plan to launch and iterate.Ê≥ïÂàô16ÔºöÂÅöÂ•ΩÊåÅÁª≠Ëø≠‰ª£‰∏äÁ∫øÁöÑÂáÜÂ§á‰∏çË¶ÅÊúüÊúõÁé∞Âú®ÂèëÂ∏ÉÁöÑËøô‰∏™Ê®°ÂûãÊòØÊúÄÁªàÁöÑÊ®°Âûã„ÄÇÂõ†Ê≠§ÔºåËÄÉËôë‰Ω†ÁªôÂΩìÂâçËøô‰∏™Ê®°ÂûãÂ¢ûÂä†ÁöÑÂ§çÊùÇÂ∫¶‰ºö‰∏ç‰ºöÂáèÊÖ¢ÂêéÁª≠ÁöÑÂèëÂ∏É„ÄÇËÆ∏Â§öÂõ¢ÈòüÊØèÂ≠£Â∫¶Êé®Âá∫‰∏Ä‰∏™Ê®°ÂûãÊàñËÄÖÊõ¥Â§öÂπ¥„ÄÇ‰πãÊâÄ‰ª•‰∏çÊñ≠ÂèëÂ∏ÉÊñ∞Ê®°ÂûãÔºåÊúâ‰∏â‰∏™Âü∫Êú¨ÂéüÂõ†Ôºö‰Ω†‰ºö‰∏çÊñ≠Âú∞ÊÉ≥Âà∞Êñ∞ÁöÑÁâπÂæÅ„ÄÇ‰Ω†‰ºö‰∏çÊñ≠Âú∞Ë∞ÉÊï¥Âπ∂‰ª•Êñ∞ÁöÑÊñπÂºèÁªÑÂêàÊóßÁöÑÁâπÂæÅ„ÄÇ‰Ω†‰ºö‰∏çÊñ≠Ë∞É‰ºòÁõÆÊ†á„ÄÇRule #17: Start with directly observed and reported features as opposed to learned features.Ê≥ïÂàô 17Ôºö‰ºòÂÖà‰ΩøÁî®Áõ¥Êé•ËßÇÊµãÊàñÊî∂ÈõÜÂà∞ÁöÑÁâπÂæÅÔºåËÄå‰∏çÊòØÂ≠¶‰π†Âá∫Êù•ÁöÑÁâπÂæÅÔºàlearned featuresÔºâÂÖàÊèèËø∞‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂ≠¶‰π†Âá∫Êù•ÁöÑÁâπÂæÅÔºàlearned featuresÔºâ„ÄÇÂ≠¶‰π†Âá∫Êù•ÁöÑÁâπÂæÅÔºàlearned featuresÔºâÊòØÁî±Â§ñÈÉ®Á≥ªÁªüÔºàÊØîÂ¶ÇÊó†ÁõëÁù£ËÅöÁ±ªÁ≥ªÁªüÔºâÊàñÂ≠¶‰π†ËÄÖÊú¨Ë∫´ÔºàÊØîÂ¶ÇÂõ†Â≠êÊ®°Âûã„ÄÅÊ∑±Â∫¶Â≠¶‰π†ÔºâÁîüÊàêÁöÑÁâπÂæÅ„ÄÇ‰∏§ÁßçÊñπÂºèÁîüÊàêÁöÑÁâπÂæÅÈÉΩÂæàÊúâÁî®Ôºå‰ΩÜ‰πüÊúâÂæàÂ§öÈóÆÈ¢òÔºåÂõ†Ê≠§‰∏çÂ∫îÂΩìÁî®Âú®Á¨¨‰∏Ä‰∏™Ê®°Âûã‰∏≠„ÄÇRule #18: Explore with features of content that generalize across contexts.Ê≥ïÂàô 18ÔºöÊé¢Á¥¢‰ΩøÁî®ÂèØ‰ª•Ë∑®Âú∫ÊôØÁöÑÂÜÖÂÆπÁâπÂæÅÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåÊú∫Âô®Â≠¶‰π†Âè™Âç†Âà∞‰∏Ä‰∏™Â§ßÁ≥ªÁªü‰∏≠ÁöÑÂæàÂ∞è‰∏ÄÈÉ®ÂàÜÔºåÂõ†Ê≠§‰Ω†ÂøÖÈ°ªË¶ÅËØïÁùÄ‰ªé‰∏çÂêåËßíÂ∫¶ÂÆ°ËßÜ‰∏Ä‰∏™Áî®Êà∑Ë°å‰∏∫„ÄÇÊØîÂ¶ÇÁÉ≠Èó®Êé®ËçêËøô‰∏ÄÂú∫ÊôØÔºå‰∏ÄËà¨ÊÉÖÂÜµ‰∏ãËÆ∫ÂùõÈáå‚ÄúÁÉ≠Èó®Êé®Ëçê‚ÄùÈáåÁöÑÂ∏ñÂ≠êÈÉΩ‰ºöÊúâËÆ∏Â§öËØÑËÆ∫„ÄÅÂàÜ‰∫´ÂíåÈòÖËØªÈáèÔºåÂ¶ÇÊûúÂà©Áî®Ëøô‰∫õÁªüËÆ°Êï∞ÊçÆÂØπÊ®°ÂûãÂ±ïÂºÄËÆ≠ÁªÉÔºåÁÑ∂ÂêéÂØπ‰∏Ä‰∏™Êñ∞Â∏ñÂ≠êËøõË°å‰ºòÂåñÔºåÂ∞±ÊúâÂèØËÉΩ‰ΩøÂÖ∂Êàê‰∏∫ÁÉ≠Èó®Â∏ñÂ≠ê„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåYouTube‰∏äËá™Âä®Êí≠ÊîæÁöÑ‰∏ã‰∏Ä‰∏™ËßÜÈ¢ë‰πüÊúâËÆ∏Â§öÈÄâÊã©Ôºå‰æãÂ¶ÇÂèØ‰ª•Ê†πÊçÆÂ§ßÈÉ®ÂàÜÁî®Êà∑ÁöÑËßÇÁúãÈ°∫Â∫èÊé®ËçêÔºåÊàñËÄÖÊ†πÊçÆÁî®Êà∑ËØÑÂàÜÊé®ËçêÁ≠â„ÄÇÊÄª‰πãÔºåÂ¶ÇÊûú‰Ω†Â∞Ü‰∏Ä‰∏™Áî®Êà∑Ë°å‰∏∫Áî®‰ΩúÊ®°ÂûãÁöÑÊ†áËÆ∞ÔºàlabelÔºâÔºåÈÇ£‰πàÂú®‰∏çÂêåÁöÑ‰∏ä‰∏ãÊñáÊù°‰ª∂‰∏ãÂÆ°ËßÜËøô‰∏ÄË°å‰∏∫ÔºåÂèØËÉΩ‰ºöÂæóÂà∞Êõ¥‰∏∞ÂØåÁöÑÁâπÂæÅÔºàfeatureÔºâÔºå‰πüÂ∞±Êõ¥Âà©‰∫éÊ®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØËøô‰∏é‰∏™ÊÄßÂåñ‰∏çÂêåÔºö‰∏™ÊÄßÂåñÊòØÁ°ÆÂÆöÁî®Êà∑ÊòØÂê¶Âú®ÁâπÂÆöÁöÑ‰∏ä‰∏ãÊñáÁéØÂ¢É‰∏≠ÂñúÊ¨¢Êüê‰∏ÄÂÜÖÂÆπÔºåÂπ∂ÂèëÁé∞Âì™‰∫õÁî®Êà∑ÂñúÊ¨¢ÔºåÂñúÊ¨¢ÁöÑÁ®ãÂ∫¶Â¶Ç‰Ωï„ÄÇRule #19: Use very specific features when you can.Ê≥ïÂàô 19ÔºöÂ∞ΩÈáè‰ΩøÁî®ÈùûÂ∏∏ÂÖ∑‰ΩìÁöÑÁâπÂæÅÂú®Êµ∑ÈáèÊï∞ÊçÆÁöÑÊîØÊåÅ‰∏ãÔºåÂç≥‰ΩøÂ≠¶‰π†Êï∞Áôæ‰∏á‰∏™ÁÆÄÂçïÁöÑÁâπÂæÅ‰πüÊØî‰ªÖ‰ªÖÂ≠¶‰π†Âá†‰∏™Â§çÊùÇÁöÑÁâπÂæÅË¶ÅÂÆπÊòìÂÆûÁé∞„ÄÇÁî±‰∫éË¢´Ê£ÄÁ¥¢ÁöÑÊñáÊú¨Ê†áËØÜ‰∏éËßÑËåÉÂåñÁöÑÊü•ËØ¢Âπ∂‰∏ç‰ºöÊèê‰æõÂ§™Â§öÁöÑÂΩí‰∏ÄÂåñ‰ø°ÊÅØÔºåÂè™‰ºöË∞ÉÊï¥Â§¥ÈÉ®Êü•ËØ¢‰∏≠ÁöÑÊ†áËÆ∞ÊéíÂ∫è„ÄÇÂõ†Ê≠§‰Ω†‰∏çÂøÖÊãÖÂøÉËôΩÁÑ∂Êï¥‰ΩìÁöÑÊï∞ÊçÆË¶ÜÁõñÁéáÈ´òËææ90%‰ª•‰∏äÔºå‰ΩÜÈíàÂØπÊØè‰∏™ÁâπÂæÅÁªÑÈáåÁöÑÂçï‰∏ÄÁâπÂæÅÂç¥Ê≤°ÊúâÂ§öÂ∞ëËÆ≠ÁªÉÊï∞ÊçÆÂèØÁî®ÁöÑÊÉÖÂÜµ„ÄÇÂè¶Â§ñÔºå‰Ω†‰πüÂèØ‰ª•Â∞ùËØïÊ≠£ÂàôÂåñÁöÑÊñπÊ≥ïÊù•Â¢ûÂä†ÊØè‰∏™ÁâπÂæÅÊâÄÂØπÂ∫îÁöÑÊ†∑Êú¨Êï∞„ÄÇRule #20: Combine and modify existing features to create new features in human‚Äìunderstandable ways.Ê≥ïÂàô 20: Áî®‰∫∫Á±ªÂèØÁêÜËß£ÁöÑÊñπÂºèÂØπÂ∑≤ÊúâÁâπÂæÅËøõË°åÁªÑÂêàÂíå‰øÆÊîπÊúâÂæàÂ§öÁßçÊñπÊ≥ïÁªÑÂêàÂíåÊîπËâØÁâπÂæÅ„ÄÇÂÉè TensorFlow ËøôÊ†∑ÁöÑÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÔºåÂÆÉÂÖÅËÆ∏ÈÄöËøá transformations È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ„ÄÇÂÖ∂ÊúÄÊ†áÂáÜÁöÑ‰∏§ÁßçÊñπÊ≥ïÂàÜÂà´ÊòØ‚ÄúdiscretizationÔºàÁ¶ªÊï£ÂåñÔºâ‚ÄùÂíå‚ÄúcrossesÔºàÂèâÁßØÔºâ‚Äù„ÄÇDiscretization ‰ºöÊ†πÊçÆ‰∏Ä‰∏™ËøûÁª≠ÁöÑÁâπÂæÅÂàõÂª∫ËÆ∏Â§öÁ¶ªÊï£ÁöÑÁâπÂæÅ„ÄÇÂÅáÂÆöÂπ¥ÈæÑÊòØ‰∏Ä‰∏™ËøûÁª≠ÁöÑÁâπÂæÅ„ÄÇÊàë‰ª¨ÂèØ‰ª•ÂàõÂª∫Â¶Ç‰∏ãÁâπÂæÅÔºåÂΩìÂπ¥ÈæÑÂ∞è‰∫é 18 Êó∂ËÆ∞‰∏∫ 1ÔºåÊàñËÄÖÂΩìÂπ¥ÈæÑÂú® 18 Âà∞35 Â≤Å‰πãÈó¥Êó∂‰∏∫ 1Ôºå‰ª•Ê≠§Á±ªÊé®„ÄÇ‰∏çÁî®ËøáÂ§öËÄÉËôëËøô‰∫õÊï∞ÊçÆÁöÑËæπÁïåÈóÆÈ¢òÔºöÁÆÄÂçïÁöÑÊï∞Â≠óÂèØ‰ª•Áªô‰Ω†ÊúÄÁõ¥ËßÇÁöÑÂÜ≤Âáª„ÄÇCrossÁî±‰∏§‰∏™ÊàñÂ§ö‰∏™ÁâπÂæÅÊ†èÁªÑÊàê„ÄÇÊ†πÊçÆTensorFlowÁªôÂá∫ÁöÑËß£ÈáäÔºå ÁâπÂæÅÊ†èÊòØ‰∏ÄÁªÑÂêåÁ±ªÁöÑÁâπÂæÅ„ÄÇÔºàÂ¶ÇÔΩõÁî∑ÔºåÂ•≥ÔΩù„ÄÅÔΩõÁæéÂõΩÔºåÂä†ÊãøÂ§ßÔºåÂ¢®Ë•øÂì•ÔΩùÁ≠âÔºâ„ÄÇËÄåCrossÊòØ‰∏Ä‰∏™Êñ∞ÁöÑÁâπÂæÅÊ†èÔºåÂèØ‰ª•Áî®ÔΩõÁî∑ÔºåÂ•≥ÔΩù√óÔΩõÁæéÂõΩÔºåÂä†ÊãøÂ§ßÔºåÂ¢®Ë•øÂì•ÔΩùÁ≠âÊù•ÁÆÄÂçïÁöÑË°®Á§∫„ÄÇÊñ∞ÁöÑÁâπÂæÅÊ†è‰ºöÂåÖÂê´‰ª•‰∏ãÁâπÂæÅÔºåÂ¶ÇÔΩõÁî∑ÔºåÂä†ÊãøÂ§ßÔΩù„ÄÇ‰ΩøÁî®TensorFlowÊó∂ÂèØ‰ª•ËÆ©ÂÆÉÂ∏Æ‰Ω†ÂàõÂª∫cross„ÄÇÔΩõÁî∑ÔºåÂä†ÊãøÂ§ßÔΩùÂèØ‰ª•Âú®Ê†∑Êú¨‰∏≠‰ª£Ë°®Áî∑ÊÄßÂä†ÊãøÂ§ß‰∫∫„ÄÇÊ≥®ÊÑèËã•Ê®°Âûã‰ΩøÁî®‰∏â‰∏™‰ª•‰∏äÁöÑÁâπÂæÅÊ†èÁªÑÊàêÁöÑcrossÔºåÂàôÈúÄË¶ÅÂ§ßÈáèÁöÑÊï∞ÊçÆÊù•ËÆ≠ÁªÉÊ®°Âûã„ÄÇCross ‰ºö‰∫ßÁîüÂ∫ûÂ§ßÁöÑÁâπÂæÅÊ†èÔºåÊúâÂèØËÉΩÂØºËá¥ËøáÊãüÂêàÁé∞Ë±°„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåÂÅáËÆæ‰Ω†Ë¶ÅÂÅöÊüêÁßçÊêúÁ¥¢„ÄÇÊ£ÄÁ¥¢ËØçÊûÑÊàê‰∏Ä‰∏™ÁâπÂæÅÊ†èÔºåÊñáÊ°£‰∏≠ÁöÑËØçÊûÑÊàêÂè¶‰∏Ä‰∏™ÁâπÂæÅÊ†è„ÄÇ‰Ω†ÂèØ‰ª•ÈÄöËøácross Êù•ÁªÑÂêàÂÆÉ‰ª¨Ôºå‰ΩÜËøôÊ†∑‰ºöÂá∫Áé∞ÂæàÂ§öÁâπÂæÅ„ÄÇÂ§ÑÁêÜÊñáÊú¨Êó∂ÔºåÊúâ‰∏§‰∏™Êõø‰ª£ÊÄßÊñπÊ°à„ÄÇÊúÄËãõÂàªÁöÑÊñπÊ°àÊòØ dot productÔºàÁÇπÁßØÔºâ„ÄÇÁÇπÁßØ‰ªÖÁªüËÆ°Ê£ÄÁ¥¢ËØçÂíåÊñáÊ°£ËØç‰∏≠ÁöÑÂÖ¨ÂÖ±ËØçÊ±á„ÄÇÂæóÂà∞ÁöÑÁâπÂæÅÂèØ‰ª•Ë¢´Á¶ªÊï£Âåñ„ÄÇÂè¶‰∏ÄÁßçÊñπÊ°àÊòØÂèñintersectionÔºà‰∫§ÈõÜÔºâÔºöÂõ†Ê≠§ÔºåÊàë‰ª¨Êúâ‰∏Ä‰∏™ÁâπÂæÅÊù•Ë°®Á§∫ÂΩì‚ÄúponyÔºàËâ≤ÊÉÖÔºâ‚ÄùËøô‰∏™ËØçÂêåÊó∂Âá∫Áé∞Âú®ÊñáÊ°£ÂíåÊ£ÄÁ¥¢ËØç‰∏≠ÔºåÂè¶‰∏Ä‰∏™ÁâπÂæÅË°®Á§∫‚Äúthe‚ÄùÂêåÊó∂Âá∫Áé∞Âú®ÊñáÊ°£ÂíåÊ£ÄÁ¥¢ËØç‰∏≠„ÄÇRule #21: The number of feature weights you can learn in a linear model is roughly proportional to the amount of data you have.Ê≥ïÂàô 21ÔºöÁ∫øÊÄßÊ®°Âûã‰∏≠ÁöÑÁâπÂæÅÊùÉÈáçÁöÑÊï∞ÈáèÂ∫îÂ§ßËá¥ÂíåÊ†∑Êú¨Êï∞ÈáèÂΩ¢Êàê‰∏ÄÂÆöÁöÑÊØî‰æãÂÖ≥‰∫éÊ®°ÂûãÁ©∂Á´üÂ§öÂ§çÊùÇÊâçÂêàÈÄÇÔºåÁªüËÆ°Â≠¶‰π†ÁêÜËÆ∫ÊúâËÆ∏Â§öÊúâË∂£ÁöÑÁªìËÆ∫„ÄÇ‰ΩÜÊÄªÁöÑÊù•ËØ¥ÔºåËøô‰∏ÄÊù°Ê≥ïÂàôÂ∞±Ë∂≥Â§ü‰∫Ü„ÄÇÊàëÊõæÂíå‰∏Ä‰∫õ‰∫∫‰∫§ÊµÅËøáÔºåÂú®‰ªñ‰ª¨ÁúãÊù•ÔºåË¶ÅÊÉ≥Â≠¶Âà∞‰∫õ‰∏úË•øÔºå‰∏ÄÂçÉ‰∏™Ê†∑Êú¨ËøúËøú‰∏çÂ§üÔºåËá≥Â∞ëÈúÄË¶Å‰∏ÄÁôæ‰∏á‰∏™Ê†∑Êú¨„ÄÇËøôÊòØÂõ†‰∏∫Ôºå‰ªñ‰ª¨Ë¢´ÁâπÂÆöÁöÑÂ≠¶‰π†ÊñπÊ≥ïÊùüÁºö‰∫ÜÊâãËÑö„ÄÇËÄåËØÄÁ™çÂ∞±ÊòØÔºåÊ†πÊçÆÊï∞ÊçÆÂ§ßÂ∞èË∞ÉÊï¥Â≠¶‰π†ÊñπÊ≥ïÔºöÂ¶ÇÊûú‰Ω†Âú®ÂºÄÂèë‰∏Ä‰∏™ÊêúÁ¥¢ÊéíÂêçÁ≥ªÁªüÔºåÂπ∂‰∏îÊúâÊï∞Áôæ‰∏á‰∏çÂêåÁöÑËØçÊ±áÂ≠òÂú®‰∫éÊñáÊ°£ÂíåÊ£ÄÁ¥¢ËØç‰∏≠ÔºåËÄå‰Ω†‰ªÖÊúâ 1000 ‰∏™Â∏¶ÊúâÊ†áËÆ∞ÁöÑÊ†∑Êú¨„ÄÇÈÇ£‰πà‰Ω†Â∫îËØ•‰ΩøÁî®ÊñáÊ°£ÂíåÊ£ÄÁ¥¢ËØçÁöÑÁÇπÁßØÁâπÂæÅ„ÄÅ TFÔºçIDF ‰ª•ÂèäÂÖ∂ÂÆÉÂÖ≠‰∏™‰∫∫Â∑•ËÆæËÆ°ÁöÑÁâπÂæÅ„ÄÇ 1000 ‰∏™Ê†∑Êú¨ÔºåÂØπÂ∫î 12‰∏™Â∑¶Âè≥ÁöÑÁâπÂæÅ„ÄÇÂ¶ÇÊûúÊúâ‰∏ÄÁôæ‰∏á‰∏™ÁöÑÊ†∑Êú¨ÔºåÈÇ£Â∞±ÈÄöËøá regularization ÊàñÁâπÂæÅ selectionÔºåÂèñÊñáÊ°£ÁâπÂæÅÊ†èÂíåÊ£ÄÁ¥¢ËØçÁâπÂæÅÊ†èÁöÑ‰∫§ÈõÜ„ÄÇËøôÊ†∑‰Ω†ËÉΩÂæóÂà∞Êï∞Áôæ‰∏á‰∏™ÁâπÂæÅÔºå‰ΩÜ regularization‰ºöÂ∏Æ‰Ω†ÂáèÂ∞ë‰∫õËÆ∏ÁöÑÁâπÂæÅ„ÄÇ‰∏ÄÂçÉ‰∏á‰∏™Ê†∑Êú¨ÔºåÂØπÂ∫îÂ§ßÁ∫¶ÂçÅ‰∏á‰∏™ÁâπÂæÅ„ÄÇÂ¶ÇÊûúÊúâÂçÅ‰∫ø‰∏™‰πÉËá≥Âá†ÂçÉ‰∫ø‰∏™Ê†∑Êú¨Ôºå‰Ω†ÂèØ‰ª•ÈÄöËøá regularization ÂíåÁâπÂæÅÈÄâÂèñÔºåÂèñÊñáÊ°£ÁâπÂæÅÊ†èÂíå query token ÁöÑÂèâÁßØ„ÄÇÂ¶ÇÊûúÊúâÂçÅ‰∫ø‰∏™Ê†∑Êú¨ÔºåÈÇ£‰πà‰Ω†‰ºöÂæóÂà∞‰∏ÄÂçÉ‰∏á‰∏™ÁâπÂæÅ„ÄÇRule #22: Clean up features you are no longer using.Ê≥ïÂàô22ÔºöÊ∏ÖÁêÜ‰∏çÂÜç‰ΩøÁî®ÁöÑÁâπÂæÅÂΩìÂÜ≥ÂÆöË¶ÅÊ∏ÖÈô§Âì™‰∫õÁâπÂæÅÊó∂ÔºåÈúÄË¶ÅËÄÉËôëÂÖ∂Ë¶ÜÁõñÁéáÔºåÂç≥ËØ•È°πÁâπÂæÅË¶ÜÁõñ‰∫ÜÂ§öÂ∞ëÊ†∑Êú¨„ÄÇ‰∏æ‰∏™‰æãÂ≠êÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏Ä‰∫õÊØîËæÉÁâπÂà´ÁöÑÁâπÂæÅÔºå‰ΩÜÂè™Êúâ 8% ÁöÑÁî®Êà∑‰∏é‰πãÁõ∏ÂÖ≥ÔºåÈÇ£‰πàËøô‰∫õÁâπÂæÅÂ∞±Êó†Ë∂≥ËΩªÈáç‰∫Ü„ÄÇÂêåÊó∂ÔºåÊúâ‰∫õÁâπÂæÅÂèØËÉΩË∂ÖË∂äÂÆÉ‰ª¨ÁöÑÊùÉÈáç„ÄÇÊØîÂ¶ÇÊüê‰∏™ÁâπÂæÅ‰ªÖË¶ÜÁõñ 1% ÁöÑÊï∞ÊçÆÔºå‰ΩÜ 90% ÁöÑÊ≠£Ê†∑Êú¨ÈÉΩÂê´ÊúâËøôÁßçÁâπÂæÅ„ÄÇÈÇ£‰πàÔºå‰πüÂ∫îÂΩìÂ∞ÜËøô‰∏™ÁâπÂæÅÊ∑ªÂä†ËøõÊù•„ÄÇÁ≥ªÁªüÁöÑ‰∫∫Â∑•ÂàÜÊûêÂú®ËøõÂÖ•Êú∫Âô®Â≠¶‰π†Á¨¨‰∏âÈò∂ÊÆµÂâçÔºåÊúâ‰∏Ä‰∫õÂú®Êú∫Âô®Â≠¶‰π†ËØæÁ®ã‰∏äÂ≠¶‰π†‰∏çÂà∞ÁöÑÂÜÖÂÆπ‰πüÈùûÂ∏∏ÂÄºÂæóÂÖ≥Ê≥®ÔºöÂ¶Ç‰ΩïÊ£ÄÊµã‰∏Ä‰∏™Ê®°ÂûãÂπ∂ÊîπËøõÂÆÉ„ÄÇËøô‰∏éÂÖ∂ËØ¥ÊòØÈó®ÁßëÂ≠¶ÔºåËøò‰∏çÂ¶ÇËØ¥ÊòØ‰∏ÄÈó®Ëâ∫ÊúØ„ÄÇËøôÈáåÂÜç‰ªãÁªçÂá†ÁßçË¶ÅÈÅøÂÖçÁöÑÂèçÊ®°ÂºèÔºàanti-patternsÔºâRule #23: You are not a typical end user.Ê≥ïÂàô 23: ‰Ω†Âπ∂ÈùûÂÖ∏ÂûãÁªàÁ´ØÁî®Êà∑ËøôÂèØËÉΩÊòØËÆ©‰∏Ä‰∏™Âõ¢ÈòüÈô∑ÂÖ•Âõ∞Â¢ÉÁöÑÊúÄÁÆÄÂçïÁöÑÊñπÊ≥ï„ÄÇËôΩÁÑ∂fishfoodingÔºàÂè™Âú®Âõ¢ÈòüÂÜÖÈÉ®‰ΩøÁî®ÂéüÂûãÔºâÂíådogfoodingÔºàÂè™Âú®ÂÖ¨Âè∏ÂÜÖÈÉ®‰ΩøÁî®ÂéüÂûãÔºâÈÉΩÊúâËÆ∏Â§ö‰ºòÁÇπÔºå‰ΩÜÊó†ËÆ∫Âì™‰∏ÄÁßçÔºåÂºÄÂèëËÄÖÈÉΩÂ∫îËØ•È¶ñÂÖàÁ°ÆËÆ§ËøôÁßçÊñπÂºèÊòØÂê¶Á¨¶ÂêàÊÄßËÉΩË¶ÅÊ±Ç„ÄÇË¶ÅÈÅøÂÖç‰ΩøÁî®‰∏Ä‰∏™ÊòéÊòæ‰∏çÂ•ΩÁöÑÊîπÂèòÔºåÂêåÊó∂Ôºå‰ªª‰ΩïÁúãËµ∑Êù•ÂêàÁêÜÁöÑ‰∫ßÂìÅÁ≠ñÁï•‰πüÂ∫îËØ•Ëøõ‰∏ÄÊ≠•ÁöÑÊµãËØïÔºå‰∏çÁÆ°ÊòØÈÄöËøáËÆ©Èùû‰∏ì‰∏ö‰∫∫Â£´Êù•ÂõûÁ≠îÈóÆÈ¢òÔºåËøòÊòØÈÄöËøá‰∏Ä‰∏™ÂØπÁúüÂÆûÁî®Êà∑ÁöÑÁ∫ø‰∏äÂÆûÈ™å„ÄÇRule #24: Measure the delta between models.Ê≥ïÂàô24ÔºöÊµãÈáèÊ®°ÂûãÈó¥ÁöÑÂ∑ÆÂºÇÂú®Â∞Ü‰Ω†ÁöÑÊ®°ÂûãÂèëÂ∏É‰∏äÁ∫øÂâçÔºå‰∏Ä‰∏™ÊúÄÁÆÄÂçïÔºåÊúâÊó∂‰πüÊòØÊúÄÊúâÊïàÁöÑÊµãËØïÊòØÊØîËæÉ‰Ω†ÂΩìÂâçÁöÑÊ®°ÂûãÂíåÂ∑≤Áªè‰∫§‰ªòÁöÑÊ®°ÂûãÁîü‰∫ßÁöÑÁªìÊûú‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÂ¶ÇÊûúÂ∑ÆÂºÇÂæàÂ∞èÔºåÈÇ£‰∏çÂÜçÈúÄË¶ÅÂÅöÂÆûÈ™åÔºå‰Ω†‰πüÁü•ÈÅì‰Ω†Ëøô‰∏™Ê®°Âûã‰∏ç‰ºöÂ∏¶Êù•‰ªÄ‰πàÊîπÂèò„ÄÇÂ¶ÇÊûúÂ∑ÆÂºÇÂæàÂ§ßÔºåÈÇ£Â∞±Ë¶ÅÁªßÁª≠Á°ÆÂÆöËøôÁßçÊîπÂèòÊòØ‰∏çÊòØÂ•ΩÁöÑ„ÄÇÊ£ÄÊü•ÂØπÁ≠âÂ∑ÆÂàÜÂæàÂ§ßÁöÑÊü•ËØ¢ËÉΩÂ∏ÆÂä©ÁêÜËß£ÊîπÂèòÁöÑÊÄßË¥®ÔºàÊòØÂèòÂ•ΩÔºåËøòÊòØÂèòÂùèÔºâ„ÄÇ‰ΩÜÊòØÔºå‰ΩøÁî®‰∏çÂêåÊ®°ÂûãËøõË°åÊØîËæÉÂâçÔºåÈúÄË¶ÅÁ°Æ‰øùËØ•Ê®°ÂûãÂíåÂÆÉÊú¨Ë∫´ÊØîËæÉÔºåËøô‰∏™Â∑ÆÂºÇÂæàÂ∞èÔºàÁêÜÊÉ≥ÊÉÖÂÜµÂ∫îËØ•ÊòØÊó†‰ªª‰ΩïÂ∑ÆÂºÇÔºâ„ÄÇRule #25: When choosing models, utilitarian performance trumps predictive power.Ê≥ïÂàô 25: ÈÄâÊã©Ê®°ÂûãÊó∂ÔºåÊÄßËÉΩË°®Áé∞ÊØîÈ¢ÑÊµãÂäõÊõ¥ÈáçË¶ÅËôΩÁÑ∂Êàë‰ª¨ËÆ≠ÁªÉÊ®°ÂûãÊó∂ objective ‰∏ÄËà¨ÈÉΩÊòØ loglossÔºå‰πüÂ∞±ÊòØËØ¥ÂÆûÂú®ËøΩÊ±ÇÊ®°ÂûãÁöÑÈ¢ÑÊµãËÉΩÂäõ„ÄÇ‰ΩÜÊòØÊàë‰ª¨Âú®‰∏äÂ±ÇÂ∫îÁî®‰∏≠Âç¥ÂèØËÉΩÊúâÂ§öÁßçÁî®ÈÄîÔºå‰æãÂ¶ÇÂèØËÉΩ‰ºöÁî®Êù•ÊéíÂ∫èÔºåÈÇ£‰πàËøôÊó∂ÂÖ∑‰ΩìÁöÑÈ¢ÑÊµãËÉΩÂäõÂ∞±‰∏çÂ¶ÇÊéíÂ∫èËÉΩÂäõÈáçË¶ÅÔºõÂ¶ÇÊûúÁî®Êù•ÂàíÂÆöÈòàÂÄºÁÑ∂ÂêéË∑üÊ†πÊçÆÈòàÂÄºÂà§Êñ≠ÂûÉÂúæÈÇÆ‰ª∂ÔºåÈÇ£‰πàÂáÜÁ°ÆÁéáÂ∞±Êõ¥ÈáçË¶Å„ÄÇÂΩìÁÑ∂Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãËøôÂá†‰∏™ÊåáÊ†áÊòØ‰∏ÄËá¥ÁöÑ„ÄÇRule #26: Look for patterns in the measured errors, and create new features.Ê≥ïÂàô 26: Âú®ÈîôËØØ‰∏≠ÂØªÊâæËßÑÂæãÔºåÁÑ∂ÂêéÂàõÂª∫Êñ∞ÁâπÂæÅÂÅáËÆæ‰Ω†ÁöÑÊ®°ÂûãÂú®Êüê‰∏™Ê†∑Êú¨‰∏≠È¢ÑÊµãÈîôËØØ„ÄÇÂú®ÂàÜÁ±ª‰ªªÂä°‰∏≠ÔºåËøôÂèØËÉΩÊòØËØØÊä•ÊàñÊºèÊä•„ÄÇÂú®ÊéíÂêç‰ªªÂä°‰∏≠ÔºåËøôÂèØËÉΩÊòØ‰∏Ä‰∏™Ê≠£ÂêëÂà§Êñ≠Âº±‰∫éÈÄÜÂêëÂà§Êñ≠ÁöÑÁªÑ„ÄÇ‰ΩÜÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÂú®Ëøô‰∏™Ê†∑Êú¨‰∏≠Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁü•ÈÅìÂÆÉÈîô‰∫ÜÔºåÈúÄË¶Å‰øÆÊ≠£„ÄÇÂ¶ÇÊûú‰Ω†Ê≠§Êó∂ÁªôÊ®°Âûã‰∏Ä‰∏™ÂÖÅËÆ∏ÂÆÉ‰øÆÂ§çÁöÑÁâπÂæÅÔºåÈÇ£‰πàÊ®°ÂûãÂ∞ÜÂ∞ùËØïËá™Ë°å‰øÆÂ§çËøô‰∏™ÈîôËØØ„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂ¶ÇÊûú‰Ω†Â∞ùËØïÂü∫‰∫éÊú™Âá∫ÈîôÁöÑÊ†∑Êú¨ÂàõÂª∫ÁâπÂæÅÔºåÈÇ£‰πàËØ•ÁâπÂæÅÂ∞ÜÂæàÂèØËÉΩË¢´Á≥ªÁªüÂøΩÁï•„ÄÇ‰æãÂ¶ÇÔºåÂÅáËÆæÂú® Google PlayÂïÜÂ∫óÁöÑÂ∫îÁî®ÊêúÁ¥¢‰∏≠ÔºåÊúâ‰∫∫ÊêúÁ¥¢‚ÄúÂÖçË¥πÊ∏∏Êàè‚ÄùÔºå‰ΩÜÂÖ∂‰∏≠‰∏Ä‰∏™ÊéíÂêçÈù†ÂâçÁöÑÊêúÁ¥¢ÁªìÊûúÂç¥ÊòØ‰∏ÄÊ¨æÂÖ∂‰ªñAppÔºåÊâÄ‰ª•‰Ω†‰∏∫ÂÖ∂‰ªñAppÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÁâπÂæÅ„ÄÇ‰ΩÜÂ¶ÇÊûú‰Ω†Â∞ÜÂÖ∂‰ªñAppÁöÑÂÆâË£ÖÊï∞ÊúÄÂ§ßÂåñÔºåÂç≥‰∫∫‰ª¨Âú®ÊêúÁ¥¢ÂÖçË¥πÊ∏∏ÊàèÊó∂ÂÆâË£Ö‰∫ÜÂÖ∂‰ªñAppÔºåÈÇ£‰πàËøô‰∏™ÂÖ∂‰ªñAppÁöÑÁâπÂæÅÂ∞±‰∏ç‰ºö‰∫ßÁîüÂÖ∂Â∫îÊúâÁöÑÊïàÊûú„ÄÇÊâÄ‰ª•ÔºåÊ≠£Á°ÆÁöÑÂÅöÊ≥ïÊòØ‰∏ÄÊó¶Âá∫Áé∞Ê†∑Êú¨ÈîôËØØÔºåÈÇ£‰πàÂ∫îËØ•Âú®ÂΩìÂâçÁöÑÁâπÂæÅÈõÜ‰πãÂ§ñÂØªÊâæËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûú‰Ω†ÁöÑÁ≥ªÁªüÈôç‰Ωé‰∫ÜÂÜÖÂÆπËæÉÈïøÁöÑÂ∏ñÂ≠êÁöÑÊéíÂêçÔºåÈÇ£Â∞±Â∫îËØ•ÊôÆÈÅçÂ¢ûÂä†Â∏ñÂ≠êÁöÑÈïøÂ∫¶„ÄÇËÄå‰∏î‰πü‰∏çË¶ÅÊãòÊ≥•‰∫éÂ§™ÂÖ∑‰ΩìÁöÑÁªÜËäÇ„ÄÇ‰æãÂ¶Ç‰Ω†Ë¶ÅÂ¢ûÂä†Â∏ñÂ≠êÁöÑÈïøÂ∫¶ÔºåÂ∞±‰∏çË¶ÅÁåúÊµãÈïøÂ∫¶ÁöÑÂÖ∑‰ΩìÂê´‰πâÔºåËÄåÂ∫îËØ•Áõ¥Êé•Ê∑ªÂä†Âá†‰∏™Áõ∏ÂÖ≥ÁöÑÁâπÂæÅÔºå‰∫§ÁªôÊ®°ÂûãËá™Ë°åÂ§ÑÁêÜÔºåËøôÊâçÊòØÊúÄÁÆÄÂçïÊúâÊïàÁöÑÊñπÊ≥ï„ÄÇRule #27: Try to quantify observed undesirable behavior.Ê≥ïÂàô 27ÔºöÂ∞ùËØïÈáèÂåñËßÇÂØüÂà∞ÁöÑÂºÇÂ∏∏Ë°å‰∏∫Â¶ÇÊûúÂú®Á≥ªÁªü‰∏≠ËßÇÂØüÂà∞‰∫ÜÊ®°ÂûãÊ≤°Êúâ‰ºòÂåñÂà∞ÁöÑÈóÆÈ¢òÔºåÂÖ∏ÂûãÁöÑ‰æãÂ¶ÇÊé®ËçêÁ≥ªÁªüÈÄºÊ†º‰∏çÂ§üËøôÁßçÈóÆÈ¢òÔºåËøôÊó∂Â∫îËØ•Âä™ÂäõÂ∞ÜËøôÁßç‰∏çÊª°ÊÑèËΩ¨Âåñ‰∏∫ÂÖ∑‰ΩìÁöÑÊï∞Â≠óÔºåÂÖ∑‰ΩìÊù•ËÆ≤ÂèØ‰ª•ÈÄöËøá‰∫∫Â∑•Ê†áÊ≥®Á≠âÊñπÊ≥ïÊ†áÊ≥®Âá∫‰∏çÊª°ÊÑèÁöÑÁâ©ÂìÅÔºåÁÑ∂ÂêéËøõË°åÁªüËÆ°„ÄÇÂ¶ÇÊûúÈóÆÈ¢òÂèØ‰ª•Ë¢´ÈáèÂåñÔºåÂêéÈù¢Â∞±ÂèØ‰ª•Â∞ÜÂÖ∂Áî®‰ΩúÁâπÂæÅ„ÄÅobjectiveÊàñËÄÖmetric„ÄÇÊï¥‰ΩìÂéüÂàôÂ∞±ÊòØ‚ÄúÂÖàÈáèÂåñÔºåÂÜç‰ºòÂåñ‚Äù„ÄÇRule #28: Be aware that identical short-term behavior does not imply identical long-term behavior.Ê≥ïÂàô 28ÔºöÁü≠ÊúüË°å‰∏∫Áõ∏ÂêåÂπ∂‰∏ç‰ª£Ë°®ÈïøÊúüË°å‰∏∫‰πüÁõ∏ÂêåÂÅáËÆæ‰Ω†Êúâ‰∏Ä‰∏™Êñ∞Á≥ªÁªüÔºåÂÆÉÂèØ‰ª•Êü•ÁúãÊØè‰∏™doc_idÂíåexact_queryÔºåÁÑ∂ÂêéÊ†πÊçÆÊØè‰∏™ÊñáÊ°£ÁöÑÊØèÊ¨°Êü•ËØ¢Ë°å‰∏∫ËÆ°ÁÆóÂÖ∂ÁÇπÂáªÁéá„ÄÇ‰Ω†ÂèëÁé∞ÂÆÉÁöÑË°å‰∏∫Âá†‰πé‰∏éÂΩìÂâçÁ≥ªÁªüÁöÑÂπ∂Ë°åÂíåA/BÊµãËØïÁªìÊûúÂÆåÂÖ®Áõ∏ÂêåÔºåËÄå‰∏îÂÆÉÂæàÁÆÄÂçïÔºå‰∫éÊòØ‰Ω†ÂêØÂä®‰∫ÜËøô‰∏™Á≥ªÁªü„ÄÇÂç¥Ê≤°ÊúâÊñ∞ÁöÑÂ∫îÁî®ÊòæÁ§∫Ôºå‰∏∫‰ªÄ‰πàÔºüÁî±‰∫é‰Ω†ÁöÑÁ≥ªÁªüÂè™Âü∫‰∫éËá™Â∑±ÁöÑÂéÜÂè≤Êü•ËØ¢ËÆ∞ÂΩïÊòæÁ§∫ÊñáÊ°£ÔºåÊâÄ‰ª•‰∏çÁü•ÈÅìÂ∫îËØ•ÊòæÁ§∫‰∏Ä‰∏™Êñ∞ÁöÑÊñáÊ°£„ÄÇË¶Å‰∫ÜËß£‰∏Ä‰∏™Á≥ªÁªüÂú®ÈïøÊúüË°å‰∏∫‰∏≠Â¶Ç‰ΩïÂ∑•‰ΩúÁöÑÂîØ‰∏ÄÂäûÊ≥ïÔºåÂ∞±ÊòØËÆ©ÂÆÉÂè™Âü∫‰∫éÂΩìÂâçÁöÑÊ®°ÂûãÊï∞ÊçÆÂ±ïÂºÄËÆ≠ÁªÉ„ÄÇËøô‰∏ÄÁÇπÈùûÂ∏∏Âõ∞Èöæ„ÄÇËÆ≠ÁªÉÂÅèÂ∑ÆÔºàTrainingÔºçServing SkewÔºâËÆ≠ÁªÉÂÅèÂ∑ÆÊòØÊåáËÆ≠ÁªÉÊó∂ÁöÑË°®Áé∞ÂíåÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÂÆûÈôÖËøêË°åÊó∂ÁöÑË°®Áé∞ÁöÑÂ∑ÆÂà´„ÄÇËøôÁßçÂÅèÂ∑ÆÂèØËÉΩÁî±‰ª•‰∏ãÂõ†Á¥†ÂºïËµ∑ÔºöÂú®ËÆ≠ÁªÉÊó∂ÂíåÂú®ÂÆûÈôÖÂ∑•‰ΩúÊµÅ‰∏≠Áî®‰∏çÂêåÁöÑÊñπÂºèÂ§ÑÁêÜÊï∞ÊçÆ„ÄÇËÆ≠ÁªÉ‰∏≠ÁöÑÊï∞ÊçÆÂíåÂú®ÂÆûÈôÖËøêË°å‰∏≠ÁöÑÂàÜÂ∏É‰∏çÂêå„ÄÇÊ®°ÂûãÂíåÁÆóÊ≥ï‰πãÈó¥Â≠òÂú®ÂèçÈ¶àÂæ™ÁéØ„ÄÇËß£ÂÜ≥ËøôÁ±ªÈóÆÈ¢òÁöÑÊ†∏ÂøÉÊòØÂØπÁ≥ªÁªüÂíåÊï∞ÊçÆÁöÑÂèòÂåñËøõË°åÁõëÊéßÔºåÁ°Æ‰øù‰∏ÄÂàáÂ∑ÆÂºÇÈÉΩÂú®ÁõëÊéß‰πãÂÜÖÔºå‰∏ç‰ºöÊÇÑÊÇÑËøõÂÖ•Á≥ªÁªü„ÄÇRule #29: The best way to make sure that you train like you serve is to save the set of features used at serving time, and then pipe those features to a log to use them at training time.Ê≥ïÂàô 29Ôºö Ë¶ÅËÆ©ÂÆûÈôÖ‰∫ßÂìÅÂíåËÆ≠ÁªÉÊó∂Ë°®Áé∞‰∏ÄÊ†∑Â•ΩÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÊòØÂÆûÈôÖËøêË°å‰∏≠‰øùÁïôÁâπÂæÅÈõÜÔºåÂπ∂ËÆ∞ÂΩïÂà∞Êó•Âøó‰∏≠‰ª•‰æøËÆ≠ÁªÉ‰∏≠‰ΩøÁî®Âç≥‰Ωø‰Ω†‰∏çËÉΩÂØπÊØè‰∏™Ê†∑‰æãÈÉΩËøôÊ†∑ÂÅöÔºåÂÅö‰∏ÄÂ∞èÈÉ®ÂàÜ‰πüÊØî‰ªÄ‰πà‰πü‰∏çÂÅöÂ•ΩÔºåËøôÊ†∑‰Ω†Â∞±ÂèØ‰ª•È™åËØÅÊúçÂä°ÂíåËÆ≠ÁªÉ‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄßÔºàËßÅËßÑÂàô37Ôºâ„ÄÇÂú® Google ÈááÂèñ‰∫ÜËøôÈ°πÊé™ÊñΩÁöÑÂõ¢ÈòüÊúâÊó∂ÂÄô‰ºöÂØπÂÖ∂ÊïàÊûúÊÑüÂà∞ÊÉäËÆ∂„ÄÇÊØîÂ¶ÇYouTube‰∏ªÈ°µÂú®ÊúçÂä°Êó∂‰ºöÂàáÊç¢Âà∞Êó•ÂøóËÆ∞ÂΩïÁâπÂæÅÔºåËøô‰∏ç‰ªÖÂ§ßÂ§ßÊèêÈ´ò‰∫ÜÊúçÂä°Ë¥®ÈáèÔºåËÄå‰∏îÂáèÂ∞ë‰∫Ü‰ª£Á†ÅÂ§çÊùÇÂ∫¶„ÄÇÁõÆÂâçÊúâËÆ∏Â§öÂõ¢ÈòüÈÉΩÂ∑≤ÁªèÂú®ÂÖ∂Âü∫Á°ÄËÆæÊñΩ‰∏äÈááÁî®‰∫ÜËøôÁßçÁ≠ñÁï•„ÄÇRule #30: Importance-weight sampled data, don‚Äôt arbitrarily drop it!Ê≥ïÂàô30ÔºöÁªôÊäΩÊ†∑Êï∞ÊçÆÊåâÈáçË¶ÅÊÄßËµãÊùÉÈáçÔºå‰∏çË¶ÅÈöèÊÑè‰∏¢ÂºÉÂÆÉ‰ª¨ÂΩìÊàë‰ª¨ÊúâÂ§™Â§öËÆ≠ÁªÉÊï∞ÊçÆÊó∂ÔºåÊàë‰ª¨‰ºöÂè™ÂèñÂÖ∂‰∏≠ÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ‰ΩÜËøôÊòØÈîôËØØÁöÑ„ÄÇÊ≠£Á°ÆÁöÑÂÅöÊ≥ïÊòØÔºåÂ¶ÇÊûú‰Ω†ÁªôÊüêÊù°Ê†∑Êú¨30%ÁöÑÈááÊ†∑ÊùÉÈáçÔºåÈÇ£‰πàÂú®ËÆ≠ÁªÉÊó∂Â∞±ÁªôÂÆÉ10/3ÁöÑËÆ≠ÁªÉÊùÉÈáç„ÄÇÈÄöËøáËøôÊ†∑ÁöÑÈáçË¶ÅÊÄßËµãÊùÉÔºàimportance weightÔºâÔºåÊï¥‰∏™ËÆ≠ÁªÉÁªìÊûúÁöÑÊ†°ÂáÜÊÄßÔºàcalibrationÔºâÂ∞±ËøòËÉΩÂ§ü‰øùËØÅ„ÄÇRule #31: Beware that if you join data from a table at training and serving time, the data in the table may change.Ê≥ïÂàô 31ÔºöÂ¶ÇÊûúË¶Å‰ªéË°®Ê†º‰∏≠ÁªÑÂêàÊï∞ÊçÆÔºåÊ≥®ÊÑèËÆ≠ÁªÉÊó∂ÂíåÂÆûÈôÖËøêË°åÊó∂Ë°®Ê†ºÂèØËÉΩÂèëÁîüÊîπÂèòÂÅáËÆæ‰Ω†Ë¶ÅÊääÊñáÊ°£ id ÂíåÂåÖÂê´ÊñáÊ°£ÁâπÂæÅÁöÑË°®Ê†ºÔºàÊØîÂ¶ÇËØÑËÆ∫ÊàñÁÇπÂáªÁöÑÊï∞ÈáèÔºâÁªìÂêàËµ∑Êù•„ÄÇ‰ªéËÆ≠ÁªÉÂíåÂÆûÈôÖËøêË°åÔºåË°®Ê†º‰∏≠ÁöÑÁâπÂæÅÂèØËÉΩ‰ºöÊîπÂèòÔºà‰æãÂ¶ÇÁî®Êà∑ÂØπÁâ©ÂìÅÁöÑËØÑËÆ∫Êï∞ÔºâÔºåÊ®°ÂûãÂØπÂêå‰∏ÄÊñáÊ°£ÂÅöÁöÑÈ¢ÑÊµã‰πüËÉΩ‰∏çÂêå„ÄÇË¶ÅÈÅøÂÖçËøôËøôÁ±ªÈóÆÈ¢òÔºåÊúÄÁÆÄÂçïÁöÑÂäûÊ≥ïÂ∞±ÊòØËÆ∞ÂΩïÊâÄÊúâÂÆûÈôÖËøêË°åÊó∂ÁöÑÁâπÂæÅ„ÄÇËã•Ë°®Ê†ºÂè™ÊòØÁºìÊÖ¢ÁöÑÂèòÂåñÔºå‰Ω†‰πüÂèØ‰ª•ÊåâÁÖßÊØèÂ∞èÊó∂ÊàñÊØèÂ§©ÁöÑÈ¢ëÁéáÂØπÂÖ∂ÂÅöÂá∫ËÆ∞ÂΩïÔºåÂæóÂà∞Ë∂≥Â§üÁõ∏ËøëÁöÑÊï∞ÊçÆ„ÄÇÊ≥®ÊÑèËøôÊ†∑‰∏çËÉΩÂÆåÁæéÁöÑËß£ÂÜ≥ÈóÆÈ¢ò„ÄÇRule #32: Re-use code between your training pipeline and your serving pipeline whenever possible.Ê≥ïÂàô 32: Â∞ΩÈáèÂú®ËÆ≠ÁªÉÊµÅÂíåÂÆûÈôÖËøêË°åÊµÅ‰∏≠‰ΩøÁî®ÈáçÂ§ç‰ª£Á†ÅÈ¶ñÂÖàÈúÄË¶ÅÊòéÁ°Æ‰∏ÄÁÇπÔºöÊâπÂ§ÑÁêÜÂíåÂú®Á∫øÂ§ÑÁêÜÂπ∂‰∏ç‰∏ÄÊ†∑„ÄÇÂú®Á∫øÂ§ÑÁêÜ‰∏≠Ôºå‰Ω†ÂøÖÈ°ªÂèäÊó∂Â§ÑÁêÜÊØè‰∏Ä‰∏™ËØ∑Ê±ÇÔºàÊØîÂ¶ÇÔºåÂøÖÈ°ª‰∏∫ÊØè‰∏™Êü•ËØ¢ÂçïÁã¨Êü•ÊâæÔºâÔºåËÄåÊâπÂ§ÑÁêÜÔºå‰Ω†ÂèØ‰ª•ÂêàÂπ∂ÂÆåÊàê„ÄÇÊúçÂä°Êó∂Ôºå‰Ω†Ë¶ÅÂÅöÁöÑÊòØÂú®Á∫øÂ§ÑÁêÜÔºåËÄåËÆ≠ÁªÉÊòØÊâπÂ§ÑÁêÜ‰ªªÂä°„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåËøòÊòØÊúâÂæàÂ§öÂèØ‰ª•ÈáçÁî®‰ª£Á†ÅÁöÑÂú∞Êñπ„ÄÇÊØîÂ¶ÇËØ¥Ôºå‰Ω†ÂèØ‰ª•ÂàõÂª∫ÁâπÂÆö‰∫éÁ≥ªÁªüÁöÑÂØπË±°ÔºåÂÖ∂‰∏≠ÁöÑÊâÄÊúâËÅîÁªìÂíåÊü•ËØ¢ÁªìÊûúÈÉΩ‰ª•‰∫∫Á±ªÂèØËØªÁöÑÊñπÂºèÂ≠òÂÇ®ÔºåÈîôËØØ‰πüÂèØ‰ª•Ë¢´ÁÆÄÂçïÂú∞ÊµãËØï„ÄÇÁÑ∂ÂêéÔºå‰∏ÄÊó¶Âú®ÊúçÂä°ÊàñËÆ≠ÁªÉÊúüÈó¥Êî∂ÈõÜ‰∫ÜÊâÄÊúâ‰ø°ÊÅØÔºå‰Ω†Â∞±ÂèØ‰ª•ÈÄöËøá‰∏ÄÁßçÈÄöÁî®ÊñπÊ≥ïÂú®Ëøô‰∏™ÁâπÂÆöÂØπË±°ÂíåÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÈúÄË¶ÅÁöÑÊ†ºÂºè‰πãÈó¥ÂΩ¢Êàê‰∫íÈÄöÔºåËÆ≠ÁªÉÂíåÊúçÂä°ÁöÑÂÅèÂ∑Æ‰πüÂæó‰ª•Ê∂àÈô§„ÄÇÂõ†Ê≠§ÔºåÂ∞ΩÈáè‰∏çË¶ÅÂú®ËÆ≠ÁªÉÊó∂ÂíåÊúçÂä°Êó∂‰ΩøÁî®‰∏çÂêåÁöÑÂèòÊàêËØ≠Ë®ÄÔºåÊØïÁ´üËøôÊ†∑‰ºöËÆ©‰Ω†Ê≤°Ê≥ïÈáçÁî®‰ª£Á†Å„ÄÇRule #33: If you produce a model based on the data until January 5th, test the model on the data from January 6th and after.Ê≥ïÂàô 33: Â¶ÇÊûúËÆ≠ÁªÉÊï∞ÊçÆÊòØ1Êúà5Êó•‰πãÂâçÁöÑÔºåÈÇ£‰πàÊµãËØïÊï∞ÊçÆË¶Å‰ªé1Êúà6Êó•ÂºÄÂßãÊµãËØïÊ®°ÂûãÊó∂Â∫îÂΩì‰ΩøÁî®ÁöÑÊØîËÆ≠ÁªÉÊ®°ÂûãÊó∂Êõ¥Âä†Êñ∞ÁöÑÊï∞ÊçÆÔºåÂõ†‰∏∫ËøôÊõ¥ËÉΩÂèçÊò†‰Ω†ÁöÑÁ≥ªÁªüÂÆûÈôÖËøêË°åË°®Áé∞„ÄÇÂ¶ÇÊûú‰Ω†Áî® 1 Êúà 5 Êó•ÂâçÁöÑÊï∞ÊçÆÁîüÊàê‰∫Ü‰∏Ä‰∏™Ê®°ÂûãÔºåÈÇ£Â∞±ÂæóÁî® 1Êúà 6 Âè∑‰πãÂêéÁöÑÊï∞ÊçÆÊµãËØïÂÆÉ„ÄÇ‰Ω†‰ºöÂèëÁé∞ÔºåÂú®Êñ∞ÁöÑÊï∞ÊçÆ‰∏ãÊ®°ÂûãË°®Áé∞ÂæóÊ≤°ÈÇ£‰πàÂ•ΩÔºå‰ΩÜ‰πü‰∏ç‰ºöÂ∑ÆÂà∞Âì™ÈáåÂéª„ÄÇËøô‰∏™ÁªìÊûúÊõ¥Âä†Êé•ËøëÁúüÂÆûËøêË°åÊó∂ÁöÑË°®Áé∞„ÄÇRule #34: In binary classification for filtering (such as spam detection or determining interesting emails), make small short-term sacrifices in performance for very clean data.Ê≥ïÂàô 34ÔºöÂú®ËøáÊª§Á±ªÁöÑ‰ªªÂä°‰∏≠ÔºåË¢´Ê†áËÆ∞‰∏∫Ë¥üÁöÑÊ†∑Êú¨ÊòØ‰∏ç‰ºöÂ±ïÁ§∫ÁªôÁî®Êà∑ÁöÑÔºå‰æãÂ¶ÇÂèØËÉΩ‰ºöÊää75%Ê†áËÆ∞‰∏∫Ë¥üÁöÑÊ†∑Êú¨ÈòªÊã¶‰Ωè‰∏çÂ±ïÁé∞ÁªôÁî®Êà∑„ÄÇ‰ΩÜÂ¶ÇÊûú‰Ω†Âè™‰ªéÂ±ïÁ§∫ÁªôÁî®Êà∑ÁöÑÁªìÊûú‰∏≠Ëé∑Âèñ‰∏ãÊ¨°ËÆ≠ÁªÉÁöÑÊ†∑Êú¨ÔºåÊòæÁÑ∂‰Ω†ÁöÑËÆ≠ÁªÉÊ†∑Êú¨ÊòØÊúâÂÅèÁöÑÊõ¥Â•ΩÁöÑÂÅöÊ≥ïÊòØ‰ΩøÁî®‰∏ÄÂÆöÊØî‰æãÁöÑÊµÅÈáèÔºà‰æãÂ¶Ç1%Ôºâ‰∏ìÈó®Êî∂ÈõÜËÆ≠ÁªÉÊï∞ÊçÆÔºåÂú®ËøôÈÉ®ÂàÜÊµÅÈáè‰∏≠ÁöÑÁî®Êà∑‰ºöÁúãÂà∞ÊâÄÊúâÁöÑÊ†∑Êú¨„ÄÇËøôÊ†∑ÊòæÁÑ∂‰ºöÂΩ±ÂìçÁ∫ø‰∏äÁöÑÁúüÂÆûËøáÊª§ÊïàÊûúÔºå‰ΩÜÊòØ‰ºöÊî∂ÈõÜÂà∞Êõ¥Â•ΩÁöÑÊï∞ÊçÆÔºåÊõ¥ÊúâÂà©‰∫éÁ≥ªÁªüÁöÑÈïøËøúÂèëÂ±ï„ÄÇÂê¶ÂàôÁ≥ªÁªü‰ºöË∂äËÆ≠ÁªÉË∂äÂÅèÔºåÊÖ¢ÊÖ¢Â∞±‰∏çÂèØÁî®‰∫Ü„ÄÇÂêåÊó∂ËøòËÉΩ‰øùËØÅËá≥Â∞ëËøáÊª§Êéâ74%ÁöÑË¥üÊ†∑Êú¨ÔºåÂØπÁ≥ªÁªüÁöÑÂΩ±Âìç‰πü‰∏çÊòØÂæàÂ§ß„ÄÇ‰ΩÜÊòØÂ¶ÇÊûú‰Ω†ÁöÑÁ≥ªÁªü‰ºöËøáÊª§Êéâ95%ÊàñËÄÖÊõ¥Â§öÁöÑË¥üÊ†∑Êú¨ÔºåËøôÁßçÂÅöÊ≥ïÂ∞±‰∏çÈÇ£‰πàÂèØË°å‰∫Ü„ÄÇÂç≥‰ΩøÂ¶ÇÊ≠§Ôºå‰∏∫‰∫ÜÂáÜÁ°ÆË°°ÈáèÊ®°ÂûãÁöÑÊïàÊûúÔºå‰Ω†‰ªçÁÑ∂ÂèØ‰ª•ÈÄöËøáÊûÑÈÄ†‰∏Ä‰∏™Êõ¥Â∞èÁöÑÊï∞ÊçÆÈõÜÔºà0.1%ÊàñËÄÖÊõ¥Â∞èÔºâÊù•ÊµãËØï„ÄÇÂçÅ‰∏áÁ∫ßÂà´ÁöÑÊ†∑Êú¨Ë∂≥Â§üÁªôÂá∫ÂáÜÁ°ÆÁöÑËØÑ‰ª∑ÊåáÊ†á‰∫Ü„ÄÇRule #35: Beware of the inherent skew in ranking problems.Ê≥ïÂàô 35: Ê≥®ÊÑèÊéíÂ∫èÈóÆÈ¢òÂ≠òÂú®Âõ∫ÊúâÂÅèÂ∑ÆÂΩì‰Ω†ÂØπÊéíÂ∫èÁÆóÊ≥ïÂÅöÂá∫Ë∂≥Â§üÂ§öÁöÑÊîπÂä®Êó∂Ôºå‰∏ÄÊñπÈù¢‰ºöÂºïËµ∑ÂÆåÂÖ®‰∏çÂêåÁöÑÊéíÂ∫èÁªìÊûúÔºåÂè¶‰∏ÄÊñπÈù¢‰πüÂèØËÉΩÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊîπÂèòÁÆóÊ≥ïÊú™Êù•ÂèØËÉΩË¶ÅÂ§ÑÁêÜÁöÑÊï∞ÊçÆ„ÄÇËøô‰ºöÂºïÂÖ•‰∏Ä‰∫õÂõ∫ÊúâÂÅèÂ∑ÆÔºåÂõ†Ê≠§‰Ω†ÂøÖÈ°ª‰∫ãÂÖàÂÖÖÂàÜËÆ§ËØÜÂà∞Ëøô‰∏ÄÁÇπ„ÄÇ‰ª•‰∏ãËøô‰∫õÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÂ∏Æ‰Ω†‰ºòÂåñËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇÂØπÊ∂µÁõñÊõ¥Â§öÊü•ËØ¢ÁöÑÁâπÂæÅËøõË°åÊõ¥È´òÁöÑÊ≠£ÂàôÂåñÔºåËÄå‰∏çÊòØÈÇ£‰∫õÂè™Ë¶ÜÁõñÂçï‰∏ÄÊü•ËØ¢ÁöÑÁâπÂæÅ„ÄÇËøôÁßçÊñπÂºè‰ΩøÂæóÊ®°ÂûãÊõ¥ÂÅèÂ•ΩÈÇ£‰∫õÈíàÂØπ‰∏™Âà´Êü•ËØ¢ÁöÑÁâπÂæÅÔºåËÄå‰∏çÊòØÈÇ£‰∫õËÉΩÂ§üÊ≥õÂåñÂà∞ÂÖ®ÈÉ®Êü•ËØ¢ÁöÑÁâπÂæÅ„ÄÇËøôÁßçÊñπÂºèËÉΩÂ§üÂ∏ÆÂä©ÈòªÊ≠¢ÈùûÂ∏∏ÊµÅË°åÁöÑÁªìÊûúËøõÂÖ•‰∏çÁõ∏ÂÖ≥Êü•ËØ¢„ÄÇËøôÁÇπÂíåÊõ¥‰º†ÁªüÁöÑÂª∫ËÆÆ‰∏ç‰∏ÄÊ†∑Ôºå‰º†ÁªüÂª∫ËÆÆÂ∫îËØ•ÂØπÊõ¥Áã¨ÁâπÁöÑÁâπÂæÅÈõÜËøõË°åÊõ¥È´òÁöÑÊ≠£ÂàôÂåñ„ÄÇÂè™ÂÖÅËÆ∏ÁâπÂæÅÂÖ∑ÊúâÊ≠£ÂêëÊùÉÈáçÔºåËøôÊ†∑‰∏ÄÊù•Â∞±ËÉΩ‰øùËØÅ‰ªª‰ΩïÂ•ΩÁâπÂæÅÈÉΩ‰ºöÊØîÊú™Áü•ÁâπÂæÅÂêàÈÄÇ„ÄÇ‰∏çË¶ÅÊúâÈÇ£‰∫õ‰ªÖ‰ªÖÂÅèÊñáÊ°£Ôºàdocument-onlyÔºâÁöÑÁâπÂæÅ„ÄÇËøôÊòØÊ≥ïÂàô1ÁöÑÊûÅÁ´ØÁâàÊú¨„ÄÇÊØîÂ¶ÇÔºå‰∏çÁÆ°ÊêúÁ¥¢ËØ∑Ê±ÇÊòØ‰ªÄ‰πàÔºåÂç≥‰Ωø‰∏Ä‰∏™ÁªôÂÆöÁöÑÂ∫îÁî®Á®ãÂ∫èÊòØÂΩìÂâçÁöÑÁÉ≠Èó®‰∏ãËΩΩÔºå‰Ω†‰πü‰∏ç‰ºöÊÉ≥Âú®ÊâÄÊúâÂú∞ÊñπÈÉΩÊòæÁ§∫ÂÆÉ„ÄÇÊ≤°Êúâ‰ªÖ‰ªÖÂÅèÊñáÊ°£Á±ªÁâπÂæÅÔºåËøô‰ºöÂæàÂÆπÊòìÂÆûÁé∞„ÄÇRule #36: Avoid feedback loops with positional features.Ê≥ïÂàô 36ÔºöÁî®‰ΩçÁΩÆÁâπÂæÅÊù•ÈÅøÂÖçÂèçÈ¶àÂõûË∑ØÂ§ßÂÆ∂ÈÉΩÁü•ÈÅìÊéíÂ∫è‰ΩçÁΩÆÊú¨Ë∫´Â∞±‰ºöÂΩ±ÂìçÁî®Êà∑ÊòØÂê¶‰ºöÂØπÁâ©ÂìÅ‰∫ßÁîü‰∫íÂä®Ôºå‰æãÂ¶ÇÁÇπÂáª„ÄÇÊâÄ‰ª•Â¶ÇÊûúÊ®°Âûã‰∏≠Ê≤°Êúâ‰ΩçÁΩÆÁâπÂæÅÔºåÊú¨Êù•Áî±‰∫é‰ΩçÁΩÆÂØºËá¥ÁöÑÂΩ±Âìç‰ºöË¢´ÁÆóÂà∞ÂÖ∂‰ªñÁâπÂæÅÂ§¥‰∏äÂéªÔºåÂØºËá¥Ê®°Âûã‰∏çÂ§üÂáÜ„ÄÇÂèØ‰ª•Áî®Âä†ÂÖ•‰ΩçÁΩÆÁâπÂæÅÁöÑÊñπÊ≥ïÊù•ÈÅøÂÖçËøôÁßçÈóÆÈ¢òÔºåÂÖ∑‰ΩìÊù•ËÆ≤ÔºåÂú®ËÆ≠ÁªÉÊó∂Âä†ÂÖ•‰ΩçÁΩÆÁâπÂæÅÔºåÈ¢ÑÊµãÊó∂ÂéªÊéâ‰ΩçÁΩÆÁâπÂæÅÔºåÊàñËÄÖÁªôÊâÄÊúâÊ†∑Êú¨‰∏ÄÊ†∑ÁöÑ‰ΩçÁΩÆÁâπÂæÅ„ÄÇËøôÊ†∑‰ºöËÆ©Ê®°ÂûãÊõ¥Ê≠£Á°ÆÂú∞ÂàÜÈÖçÁâπÂæÅÁöÑÊùÉÈáç„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºå‰ΩçÁΩÆÁâπÂæÅË¶Å‰øùÊåÅÁõ∏ÂØπÁã¨Á´ãÔºå‰∏çË¶Å‰∏éÂÖ∂‰ªñÁâπÂæÅÂèëÁîüÂÖ≥ËÅî„ÄÇÂèØ‰ª•Â∞Ü‰ΩçÁΩÆÁõ∏ÂÖ≥ÁöÑÁâπÂæÅÁî®‰∏Ä‰∏™ÂáΩÊï∞Ë°®ËææÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂‰ªñÁâπÂæÅÁî®Âè¶Â§ñÁöÑÂáΩÊï∞Ë°®ËææÔºåÁÑ∂ÂêéÁªÑÂêàËµ∑Êù•„ÄÇÂÖ∑‰ΩìÂ∫îÁî®‰∏≠ÔºåÂèØ‰ª•ÈÄöËøá‰ΩçÁΩÆÁâπÂæÅ‰∏ç‰∏é‰ªª‰ΩïÂÖ∂‰ªñÁâπÂæÅ‰∫§ÂèâÊù•ÂÆûÁé∞Ëøô‰∏™ÁõÆÁöÑ„ÄÇMeasure Training/Serving Skew.Ê≥ïÂàô 37: Ë°°ÈáèËÆ≠ÁªÉÂíåÊúçÂä°‰πãÈó¥ÁöÑÂ∑ÆÂºÇÂæàÂ§öÊÉÖÂÜµ‰ºöÂºïËµ∑ÂÅèÂ∑Æ„ÄÇÂ§ßËá¥‰∏äÂàÜ‰∏∫‰∏Ä‰∫õÂá†ÁßçÔºöËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇËøôÁßçÂ∑ÆÂºÇ‰ºöÁªèÂ∏∏Â≠òÂú®ÔºåËÄå‰∏î‰∏ç‰∏ÄÂÆöÊòØÂùè‰∫ã„ÄÇÊµãËØïÈõÜÂíå‚ÄúÁ¨¨‰∫åÂ§©‚ÄùÊï∞ÊçÆÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇËøôÁßçÂ∑ÆÂºÇ‰πü‰ºö‰∏ÄÁõ¥Â≠òÂú®ÔºåËÄåËøô‰∏™‚ÄúÁ¨¨‰∫åÂ§©‚ÄùÊï∞ÊçÆ‰∏äÁöÑË°®Áé∞ÊòØÊàë‰ª¨Â∫îËØ•Âä™Âäõ‰ºòÂåñÁöÑÔºå‰æãÂ¶ÇÈÄöËøáÊ≠£ÂàôÂåñ„ÄÇËøô‰∏§ËÄÖ‰πãÈó¥Â∑ÆÂºÇÂ¶ÇÊûúËøáÂ§ßÔºåÂèØËÉΩÊòØÂõ†‰∏∫Áî®Âà∞‰∫Ü‰∏Ä‰∫õÊó∂Èó¥ÊïèÊÑüÁöÑÁâπÂæÅÔºåÂØºËá¥Ê®°ÂûãÊïàÊûúÂèòÂåñÊòéÊòæ„ÄÇ‚ÄúÁ¨¨‰∫åÂ§©‚ÄùÊï∞ÊçÆÂíåÁ∫ø‰∏äÊï∞ÊçÆÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇÂ¶ÇÊûúÂêåÊ†∑‰∏ÄÊù°Ê†∑Êú¨ÔºåÂú®ËÆ≠ÁªÉÊó∂ÁªôÂá∫ÁöÑÁªìÊûúÂíåÁ∫ø‰∏äÊúçÂä°Êó∂ÁªôÂá∫ÁöÑÁªìÊûú‰∏ç‰∏ÄËá¥ÔºåÈÇ£‰πàËøôÊÑèÂë≥ÁùÄÂ∑•Á®ãÂÆûÁé∞‰∏≠Âá∫Áé∞‰∫Übug„ÄÇÊú∫Âô®Â≠¶‰π†Á¨¨‰∏âÈò∂ÊÆµÔºöÊîæÊÖ¢ÈÄüÂ∫¶„ÄÅ‰ºòÂåñÁªÜÂåñÂíåÂ§çÊùÇÁöÑÊ®°Âûã‰∏ÄËà¨‰ºöÊúâ‰∏Ä‰∫õÊòéÁ°ÆÁöÑ‰ø°Âè∑Êù•Ê†áËØÜÁ¨¨‰∫åÈò∂ÊÆµÁöÑÂ∞æÂ£∞„ÄÇÈ¶ñÂÖàÔºåÊØèÊúàÁöÑÊèêÂçá‰ºöÈÄêÊ≠•Èôç‰Ωé„ÄÇ‰Ω†ÂºÄÂßãÂú®‰∏çÂêåÊåáÊ†á‰πãÈó¥ÂÅöÊùÉË°°ÔºåÊúâÁöÑ‰∏äÂçáÊúâÁöÑ‰∏ãÈôç„ÄÇËøôÂ∞Ü‰ºöÂèòÂæóË∂äÊù•Ë∂äÊúâË∂£„ÄÇÂ¢ûÈïøË∂äÊù•Ë∂äÈöæÂÆûÁé∞ÔºåÂøÖÈ°ªË¶ÅËÄÉËôëÊõ¥Âä†Â§çÊùÇÁöÑÊú∫Âô®Â≠¶‰π†„ÄÇË≠¶ÂëäÔºöÁõ∏ÂØπ‰∫éÂâçÈù¢‰∏§‰∏™Èò∂ÊÆµÔºåËøôÈÉ®ÂàÜ‰ºöÊúâÂæàÂ§öÂºÄÊîæÂºèÁöÑÊ≥ïÂàô„ÄÇÁ¨¨‰∏ÄÈò∂ÊÆµÂíåÁ¨¨‰∫åÈò∂ÊÆµÁöÑÊú∫Âô®Â≠¶‰π†ÊòØÂø´‰πêÁöÑ„ÄÇÂΩìÂà∞‰∫ÜÁ¨¨‰∏âÈò∂ÊÆµÔºåÊØè‰∏™Âõ¢ÈòüÂ∞±‰∏çËÉΩ‰∏çÂéªÊâæÂà∞‰ªñ‰ª¨Ëá™Â∑±ÁöÑÈÄîÂæÑ‰∫Ü„ÄÇRule #38: Don‚Äôt waste time on new features if unaligned objectives have become the issue.Ê≥ïÂàô 38Ôºö Â¶ÇÊûúÁõÆÊ†áÊ≤°ÊúâËææÊàê‰∏ÄËá¥ÔºåÂ∞±‰∏çË¶ÅÂú®Êñ∞ÁâπÂæÅ‰∏äÊµ™Ë¥πÊó∂Èó¥ÂΩìËææÂà∞ËØÑ‰º∞ÊåáÊ†áÁì∂È¢àÔºå‰Ω†ÁöÑÂõ¢ÈòüÂºÄÂßãÂÖ≥Ê≥®Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÁõÆÊ†áËåÉÂõ¥‰πãÂ§ñÁöÑÈóÆÈ¢ò„ÄÇÂ¶ÇÂêå‰πãÂâçÊèêÂà∞ÁöÑÔºåÂ¶ÇÊûú‰∫ßÂìÅÁõÆÊ†áÊ≤°ÊúâÂåÖÊã¨Âú®ÁÆóÊ≥ïÁõÆÊ†á‰πãÂÜÖÔºå‰Ω†Â∞±Âæó‰øÆÊîπÂÖ∂‰∏≠‰∏Ä‰∏™„ÄÇÊØîÂ¶ÇËØ¥Ôºå‰Ω†‰πüËÆ∏‰ºòÂåñÁöÑÊòØÁÇπÂáªÊï∞„ÄÅÁÇπËµûÊàñËÄÖ‰∏ãËΩΩÈáèÔºå‰ΩÜÂèëÂ∏ÉÂÜ≥Á≠ñËøòÊòØ‰æùËµñ‰∫é‰∫∫Á±ªËØÑ‰º∞ËÄÖ„ÄÇRule #39: Launch decisions are a proxy for long-term product goals.Ê≥ïÂàô 39ÔºöÊ®°ÂûãÂèëÂ∏ÉÂÜ≥Á≠ñÊòØÈïøÊúü‰∫ßÂìÅÁõÆÊ†áÁöÑ‰ª£ÁêÜËøô‰∏™Ê≥ïÂàôÂ≠óÈù¢‰∏äÊúâÁÇπÈöæ‰ª•ÁêÜËß£ÔºåÂÖ∂ÂÆû‰ΩúËÄÖÊ†∏ÂøÉÂ∞±ÊòØÂú®ËÆ≤‰∏Ä‰ª∂‰∫ãÊÉÖÔºöÁ≥ªÁªü„ÄÅ‰∫ßÂìÅÁîöËá≥ÂÖ¨Âè∏ÁöÑÈïøËøúÂèëÂ±ïÈúÄË¶ÅÈÄöËøáÂ§ö‰∏™ÊåáÊ†áÊù•ÁªºÂêàË°°ÈáèÔºåËÄåÊñ∞Ê®°ÂûãÊòØÂê¶‰∏äÁ∫øË¶ÅÁªºÂêàËÄÉËôëËøô‰∫õÊåáÊ†á„ÄÇÊâÄË∞ì‰ª£ÁêÜÔºåÊåáÁöÑÂ∞±ÊòØ‰ºòÂåñËøô‰∫õÁªºÂêàÊåáÊ†áÂ∞±ÊòØÂú®‰ºòÂåñ‰∫ßÂìÅ„ÄÅÂÖ¨Âè∏ÁöÑÈïøËøúÁõÆÊ†á„ÄÇÂÜ≥Á≠ñÂè™ÊúâÂú®ÊâÄÊúâÊåáÊ†áÈÉΩÂú®ÂèòÂ•ΩÁöÑÊÉÖÂÜµ‰∏ãÊâç‰ºöÂèòÂæóÁÆÄÂçï„ÄÇ‰ΩÜÂ∏∏Â∏∏‰∫ãÊÉÖÊ≤°ÈÇ£‰πàÁÆÄÂçïÔºåÂ∞§ÂÖ∂ÊòØÂΩì‰∏çÂêåÊåáÊ†á‰πãÈó¥Êó†Ê≥ïÊç¢ÁÆóÁöÑÊó∂ÂÄôÔºå‰æãÂ¶ÇAÁ≥ªÁªüÊúâ‰∏ÄÁôæ‰∏áÊó•Ê¥ªÂíåÂõõÁôæ‰∏áÊó•Êî∂ÂÖ•ÔºåBÁ≥ªÁªüÊúâ‰∏§Áôæ‰∏áÊó•Ê¥ªÂíå‰∏§Áôæ‰∏áÊó•Êî∂ÂÖ•Ôºå‰Ω†‰ºö‰ªéAÂàáÊç¢Âà∞BÂêóÔºüÊàñËÄÖÂèçËøáÊù•ÔºüÁ≠îÊ°àÊòØÊàñËÆ∏ÈÉΩ‰∏ç‰ºöÔºåÂõ†‰∏∫‰Ω†‰∏çÁü•ÈÅìÊüê‰∏™ÊåáÊ†áÁöÑÊèêÂçáÊòØÂê¶‰ºöcoverÂè¶Â§ñ‰∏Ä‰∏™ÊåáÊ†áÁöÑ‰∏ãÈôç„ÄÇÂÖ≥ÈîÆÊòØÔºåÊ≤°Êúâ‰ªª‰Ωï‰∏Ä‰∏™ÊåáÊ†áËÉΩÂõûÁ≠îÔºö‚Äú‰∫îÂπ¥ÂêéÊàëÁöÑ‰∫ßÂìÅÂú®Âì™Èáå‚ÄùÔºüËÄåÊØè‰∏™‰∏™‰ΩìÔºåÂ∞§ÂÖ∂ÊòØÂ∑•Á®ãÂ∏à‰ª¨ÔºåÊòæÁÑ∂Êõ¥ÂñúÊ¨¢ËÉΩÂ§üÁõ¥Êé•‰ºòÂåñÁöÑÁõÆÊ†áÔºåËÄåËøô‰πüÊòØÊú∫Âô®Â≠¶‰π†Á≥ªÁªüÂ∏∏ËßÅÁöÑÂú∫ÊôØ „ÄÇÁé∞Âú®‰πüÊúâ‰∏Ä‰∫õÂ§öÁõÆÊ†áÂ≠¶‰π†Á≥ªÁªüÂú®ËØïÂõæËß£ÂÜ≥ËøôÁßçÈóÆÈ¢ò„ÄÇ‰ΩÜ‰ªçÁÑ∂ÊúâÂæàÂ§öÁõÆÊ†áÊó†Ê≥ïÂª∫Ê®°‰∏∫Êú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÔºåÊØîÂ¶ÇÁî®Êà∑‰∏∫‰ªÄ‰πà‰ºöÊù•ËÆøÈóÆ‰Ω†ÁöÑÁΩëÁ´ôÁ≠âÁ≠â„ÄÇ‰ΩúËÄÖËØ¥ËøôÊòØ‰∏™AI-completeÈóÆÈ¢òÔºå‰πüÂ∏∏Ë¢´Áß∞‰∏∫Âº∫AIÈóÆÈ¢òÔºåÁÆÄÂçïÊù•ËØ¥Â∞±ÊòØ‰∏çËÉΩÁî®Êüê‰∏™Âçï‰∏ÄÁÆóÊ≥ïËß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇRule #40: Keep ensembles simple.Ê≥ïÂàô 40: ‰øùÊåÅÊ®°ÂûãÈõÜÂêàÔºàensemblesÔºâÁöÑÁÆÄÂçïÊÄßÊé•Êî∂ÂéüÂßãÁâπÂæÅ„ÄÅÁõ¥Êé•ÂØπÂÜÖÂÆπÊéíÂ∫èÁöÑÁªü‰∏ÄÊ®°ÂûãÔºåÊòØÊúÄÂÆπÊòìÁêÜËß£„ÄÅÊúÄÂÆπÊòì‰øÆË°•ÊºèÊ¥ûÁöÑÊ®°Âûã„ÄÇ‰ΩÜÊòØÔºå‰∏Ä‰∏™ÈõÜÊàêÊ®°ÂûãÔºà‰∏Ä‰∏™ÊääÂÖ∂‰ªñÊ®°ÂûãÂæóÂàÜÁªÑÂêàÂú®‰∏ÄËµ∑ÁöÑ‚ÄúÊ®°Âûã‚ÄùÔºâÁöÑÊïàÊûú‰ºöÊõ¥Â•Ω„ÄÇ‰∏∫‰øùÊåÅÁÆÄÊ¥ÅÔºåÊØè‰∏™Ê®°ÂûãÂ∫îËØ•Ë¶Å‰πàÊòØ‰∏Ä‰∏™Âè™Êé•Êî∂ÂÖ∂‰ªñÊ®°ÂûãÁöÑËæìÂÖ•ÁöÑÈõÜÊàêÊ®°ÂûãÔºåË¶Å‰πàÊòØ‰∏Ä‰∏™ÊúâÂ§öÁßçÁâπÂæÅÁöÑÂü∫Á°ÄÊ®°ÂûãÔºå‰ΩÜ‰∏çËÉΩ‰∏§ËÄÖÁöÜÊòØ„ÄÇÂ¶ÇÊûú‰Ω†ÊúâÂçïÁã¨ËÆ≠ÁªÉ„ÄÅÂü∫‰∫éÂÖ∂ÂÆÉÊ®°ÂûãÁöÑÊ®°ÂûãÔºåÊääÂÆÉ‰ª¨ÁªÑÂêàÂà∞‰∏ÄËµ∑‰ºöÂØºËá¥‰∏çÂ•ΩÁöÑË°å‰∏∫„ÄÇÂè™‰ΩøÁî®ÁÆÄÂçïÊ®°ÂûãÊù•ÈõÜÊàêÈÇ£‰∫õ‰ªÖ‰ªÖÊää‰Ω†ÁöÑÂü∫Á°ÄÊ®°ÂûãËæìÂá∫ÂΩìÂÅöËæìÂÖ•„ÄÇ‰Ω†ÂêåÊ†∑ÊÉ≥Ë¶ÅÁªôËøô‰∫õÈõÜÊàêÊ®°ÂûãÂä†‰∏äÂ±ûÊÄß„ÄÇÊØîÂ¶ÇÔºåÂü∫Á°ÄÊ®°ÂûãÁîüÊàêÂæóÂàÜÁöÑÊèêÈ´òÔºå‰∏çÂ∫îËØ•Èôç‰ΩéÈõÜÊàêÊ®°ÂûãÁöÑÂàÜÊï∞„ÄÇÂè¶Â§ñÔºåÂ¶ÇÊûúËøûÂÖ•Ê®°ÂûãÂú®ËØ≠‰πâ‰∏äÂèØËß£ÈáäÔºàÊØîÂ¶ÇÊ†°ÂáÜ‰∫ÜÁöÑÔºâÂ∞±ÊúÄÂ•Ω‰∫ÜÔºåËøôÊ†∑ÂÖ∂‰∏ãÂ±ÇÊ®°ÂûãÁöÑÊîπÂèò‰∏ç‰ºöÂΩ±ÂìçÈõÜÊàêÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂº∫Ë°åËÆ©‰∏ãÂ±ÇÂàÜÁ±ªÂô®È¢ÑÊµãÁöÑÊ¶ÇÁéáÂçáÈ´òÔºå‰∏ç‰ºöÈôç‰ΩéÈõÜÊàêÊ®°ÂûãÁöÑÈ¢ÑÊµãÊ¶ÇÁéá„ÄÇRule #41: When performance plateaus, look for qualitatively new sources of information to add rather than refining existing signals.Ê≥ïÂàô 41ÔºöÂΩìÊïàÊûúËøõÂÖ•Áì∂È¢àÊúüÔºåÂØªÊâæÊú¨Ë¥®‰∏äÊñ∞ÁöÑ‰ø°ÊÅØÊ∫êÔºåËÄå‰∏çÊòØ‰ºòÂåñÂ∑≤ÊúâÁöÑ‰ø°Âè∑„ÄÇ‰Ω†ÂÖàÊòØÊ∑ªÂä†‰∫Ü‰∏Ä‰∫õÁî®Êà∑ÁöÑ‰∫∫Âè£‰ø°ÊÅØÔºåÂèàÊ∑ªÂä†‰∫Ü‰∏Ä‰∫õÊñáÊ°£ËØçÊ±áÁöÑ‰ø°ÊÅØÔºåÊé•ÁùÄ‰Ω†ÂèàÊµèËßà‰∫Ü‰∏ÄÈÅçÊ®°ÁâàÔºåËÄåÂêéÂèàË∞ÉÊï¥‰∫ÜËßÑÂàôÔºå‰ΩÜÊòØÊúÄÂêéÔºåÂÖ≥ÈîÆÂ∫¶ÈáèÂç¥Âè™ÊèêÂçá‰∫Ü‰∏çÂà∞ 1%„ÄÇÁé∞Âú®ÊÄé‰πàÂäûÔºüËøôÊó∂ÂÄôÂ∫îËØ•Áî®ÂÆåÂÖ®‰∏çÂêåÁöÑÁâπÂæÅÊê≠Âª∫Âü∫Á°ÄÊû∂ÊûÑÔºåÊØîÂ¶ÇÁî®Êà∑Êò®Â§©Ôºè‰∏äÂë®ÔºèÂéªÂπ¥ËÆøÈóÆÁöÑÊñáÊ°£ÁöÑÂéÜÂè≤ËÆ∞ÂΩï„ÄÇÂà©Áî® wikidata ÊàñÂØπÂÖ¨Âè∏Êù•ËØ¥ÊØîËæÉÈáçË¶ÅÁöÑ‰∏úË•øÔºàÊØîÂ¶Ç Google ÁöÑÁü•ËØÜÂõæÔºâ„ÄÇ‰Ω†ÊàñËÆ∏ÈúÄË¶Å‰ΩøÁî®Ê∑±Â∫¶Â≠¶‰π†„ÄÇÂºÄÂßãË∞ÉÊï¥‰Ω†ÂØπÊäïËµÑÂõûÊä•ÁöÑÊúüÊúõÔºåÂπ∂‰ΩúÂá∫Áõ∏Â∫îÂä™Âäõ„ÄÇÂ¶ÇÂêåÊâÄÊúâÂ∑•Á®ãÈ°πÁõÆÔºå‰Ω†ÈúÄË¶ÅÂπ≥Ë°°Êñ∞Â¢ûÂä†ÁöÑÁâπÂæÅ‰∏éÊèêÈ´òÁöÑÂ§çÊùÇÂ∫¶„ÄÇRule #42: Don‚Äôt expect diversity, personalization, or relevance to be as correlated with popularity as you think they are.Ê≥ïÂàô 42Ôºö‰∏çË¶ÅÊúüÊúõÂ§öÊ†∑ÊÄß„ÄÅ‰∏™ÊÄßÂåñ„ÄÅÁõ∏ÂÖ≥ÊÄßÂíåÂèóÊ¨¢ËøéÁ®ãÂ∫¶‰πãÈó¥ÊúâÁ¥ßÂØÜËÅîÁ≥ª‰∏ÄÁ≥ªÂàóÂÜÖÂÆπÁöÑÂ§öÊ†∑ÊÄßËÉΩÊÑèÂë≥ÁùÄËÆ∏Â§ö‰∏úË•øÔºåÂÜÖÂÆπÊù•Ê∫êÁöÑÂ§öÊ†∑ÊÄßÊúÄ‰∏∫ÊôÆÈÅç„ÄÇ‰∏™ÊÄßÂåñÊÑèÂë≥ÁùÄÊØè‰∏™Áî®Êà∑ÈÉΩËÉΩËé∑ÂæóÂÆÉËá™Â∑±ÊÑüÂÖ¥Ë∂£ÁöÑÁªìÊûú„ÄÇÁõ∏ÂÖ≥ÊÄßÊÑèÂë≥ÁùÄ‰∏Ä‰∏™ÁâπÂÆöÁöÑÊü•ËØ¢ÂØπ‰∫éÊüê‰∏™Êü•ËØ¢ÊÄªÊØîÂÖ∂‰ªñÊõ¥ÂêàÈÄÇ„ÄÇÊòæÁÑ∂ÔºåËøô‰∏â‰∏™Â±ûÊÄßÁöÑÂÆö‰πâÂíåÊ†áÂáÜÈÉΩ‰∏çÁõ∏Âêå„ÄÇÈóÆÈ¢òÊòØÊ†áÂáÜÂæàÈöæÊâìÁ†¥„ÄÇÊ≥®ÊÑèÔºöÂ¶ÇÊûú‰Ω†ÁöÑÁ≥ªÁªüÂú®ÁªüËÆ°ÁÇπÂáªÈáè„ÄÅËÄóË¥πÊó∂Èó¥„ÄÅÊµèËßàÊï∞„ÄÅÁÇπËµûÊï∞„ÄÅÂàÜ‰∫´Êï∞Á≠âÁ≠âÔºå‰Ω†‰∫ãÂÆû‰∏äÂú®Ë°°ÈáèÂÜÖÂÆπÁöÑÂèóÊ¨¢ËøéÁ®ãÂ∫¶„ÄÇÊúâÂõ¢ÈòüËØïÂõæÂ≠¶‰π†ÂÖ∑Â§áÂ§öÊ†∑ÊÄßÁöÑ‰∏™ÊÄßÂåñÊ®°Âûã„ÄÇ‰∏∫‰∏™ÊÄßÂåñÔºå‰ªñ‰ª¨Âä†ÂÖ•ÂÖÅËÆ∏Á≥ªÁªüËøõË°å‰∏™ÊÄßÂåñÁöÑÁâπÂæÅÔºàÊúâÁöÑÁâπÂæÅ‰ª£Ë°®Áî®Êà∑ÂÖ¥Ë∂£ÔºâÔºåÊàñËÄÖÂä†ÂÖ•Â§öÊ†∑ÊÄßÔºàË°®Á§∫ËØ•ÊñáÊ°£‰∏éÂÖ∂ÂÆÉËøîÂõûÊñáÊ°£ÊúâÁõ∏ÂêåÁâπÂæÅÁöÑÁâπÂæÅÔºåÊØîÂ¶Ç‰ΩúËÄÖÂíåÂÜÖÂÆπÔºâÔºåÁÑ∂ÂêéÂèëÁé∞Ëøô‰∫õÁâπÂæÅÊØî‰ªñ‰ª¨È¢ÑÊÉ≥ÁöÑÂæóÂà∞Êõ¥‰ΩéÁöÑÊùÉÈáçÔºàÊúâÊó∂ÊòØ‰∏çÂêåÁöÑ‰ø°Âè∑Ôºâ„ÄÇËøô‰∏çÊÑèÂë≥ÁùÄÂ§öÊ†∑ÊÄß„ÄÅ‰∏™ÊÄßÂåñÂíåÁõ∏ÂÖ≥ÊÄßÂ∞±‰∏çÈáçË¶Å„ÄÇÂ∞±ÂÉè‰πãÂâçÁöÑËßÑÂàôÊåáÂá∫ÁöÑÔºå‰Ω†ÂèØ‰ª•ÈÄöËøáÂêéÂ§ÑÁêÜÊù•Â¢ûÂä†Â§öÊ†∑ÊÄßÊàñËÄÖÁõ∏ÂÖ≥ÊÄß„ÄÇÂ¶ÇÊûú‰Ω†ÁúãÂà∞Êõ¥ÈïøËøúÁöÑÁõÆÊ†áÂ¢ûÈïø‰∫ÜÔºåÈÇ£Ëá≥Â∞ë‰Ω†ÂèØ‰ª•Â£∞Áß∞ÔºåÈô§‰∫ÜÂèóÊ¨¢ËøéÂ∫¶ÔºåÂ§öÊ†∑ÊÄß/Áõ∏ÂÖ≥ÊÄßÊòØÊúâ‰ª∑ÂÄºÁöÑ„ÄÇ‰Ω†ÂèØ‰ª•ÁªßÁª≠‰ΩøÁî®ÂêéÂ§ÑÁêÜÔºåÊàñËÄÖ‰Ω†‰πüÂèØ‰ª•Âü∫‰∫éÂ§öÊ†∑ÊÄßÊàñÁõ∏ÂÖ≥ÊÄßÁõ¥Êé•‰øÆÊîπ‰Ω†ÁöÑÁõÆÊ†á„ÄÇRule #43: Your friends tend to be the same across different products. Your interests tend not to be.Ê≥ïÂàô 43: Âú®‰∏çÂêåÁöÑ‰∫ßÂìÅ‰∏≠Ôºå‰Ω†ÁöÑÊúãÂèãÂèØËÉΩÁõ∏ÂêåÔºå‰ΩÜÂÖ¥Ë∂£Âç¥‰∏çÂ∞ΩÁÑ∂Google ÁªèÂ∏∏Âú®‰∏çÂêå‰∫ßÂìÅ‰∏ä‰ΩøÁî®ÂêåÊ†∑ÁöÑÂ•ΩÂèãÂÖ≥Á≥ªÈ¢ÑÊµãÊ®°ÂûãÔºåÂπ∂‰∏îÂèñÂæó‰∫ÜÂæàÂ•ΩÁöÑÊïàÊûúÔºåËøôËØÅÊòé‰∏çÂêåÁöÑ‰∫ßÂìÅ‰∏äÂ•ΩÂèãÂÖ≥Á≥ªÊòØÂèØ‰ª•ËøÅÁßªÁöÑÔºåÊØïÁ´ü‰ªñ‰ª¨ÊòØÂõ∫ÂÆöÁöÑÂêå‰∏ÄÊâπ‰∫∫„ÄÇ‰ΩÜ‰ªñ‰ª¨Â∞ùËØïÂ∞Ü‰∏Ä‰∏™‰∫ßÂìÅ‰∏äÁöÑ‰∏™ÊÄßÂåñÁâπÂæÅ‰ΩøÁî®Âà∞Âè¶Â§ñ‰∏Ä‰∏™‰∫ßÂìÅ‰∏äÊó∂Âç¥Â∏∏Â∏∏Âæó‰∏çÂà∞Â•ΩÁªìÊûú„ÄÇÂèØË°åÁöÑÂÅöÊ≥ïÊòØ‰ΩøÁî®‰∏Ä‰∏™Êï∞ÊçÆÊ∫ê‰∏äÁöÑÂéüÂßãÊï∞ÊçÆÊù•È¢ÑÊµãÂè¶Â§ñÊï∞ÊçÆÊ∫ê‰∏äÁöÑË°å‰∏∫ÔºåËÄå‰∏çÊòØ‰ΩøÁî®Âä†Â∑•ÂêéÁöÑÁâπÂæÅ„ÄÇÊ≠§Â§ñÔºåÁî®Êà∑Âú®Âè¶‰∏Ä‰∏™Êï∞ÊçÆÊ∫ê‰∏äÁöÑË°å‰∏∫ÂéÜÂè≤‰πü‰ºöÊúâÁî®„ÄÇ]]></content>
      <categories>
        <category>ËΩ¨ËΩΩ</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Ôºà‰∏ÉÔºâ]]></title>
    <url>%2F2018%2F05%2F15%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[[toc] ËøôÈáåÂºÄÂßãÂ≠¶‰π†Á•ûÁªèÁΩëÁªúÔºåÂâç‰∏Ä‰∏™ËßÜÂ±èÁöÑÁªìÂ∞æÂê¥ÊÅ©ËææÊïôÊéàËØ¥‰ºöÁ∫øÊÄßÂõûÂΩíÂíåÈÄªËæëÂõûÂΩíÂ∞±Ë∂ÖËøáÁ°ÖË∞∑ÁöÑÂ§ßÈÉ®ÂàÜÁ®ãÂ∫èÂëò‰∫ÜÔºåËÄå‰∏îÈÇ£‰∫õÁ®ãÂ∫èÂëòÊ∑∑ÁöÑËøò‰∏çÈîôÔºåÂê¨Âà∞ËøôÈáåÂΩìÁÑ∂ÊòØÂæàÂºÄÂøÉÂïäÔºå‰ΩÜÊòØÊÉ≥ËßÜÈ¢ëÊòØ2011Âπ¥ÁöÑÔºå‰∏ÉÂπ¥ÂâçÊáÇËøô‰∫õÁöÑÁ°ÆÊòØ‰∏çÊòì‰∫ÜÔºåÁé∞Âú®ÊòØ2018Âπ¥‰∫ÜÔºåÊàëÊâçÂºÄÂßãÂ≠¶ÔºåÊòØ‰∏çÊòØÂ§™Ëøü‰∫ÜÔºü ÈùûÁ∫øÊÄßÂÅáËÆæÔºàNon linear HypothesesÔºâÁ•ûÁªèÁΩëÁªúÂÆûÈôÖ‰∏äÊòØ‰∏Ä‰∏™Áõ∏ÂØπÂè§ËÄÅÁöÑÁÆóÊ≥ïÔºåÊòØ20‰∏ñÁ∫™80Âπ¥‰ª£Êó∂ÊúüÂá∫Áé∞ÁöÑÔºå‰ΩÜÊòØÊ≤°ÊúâÊàê‰∏∫ÂèëÂ±ïÁöÑÁÉ≠ÁÇπÔºåÈöèÁùÄÁé∞‰ª£ËÆ°ÁÆóÊú∫ËÆ°ÁÆóËÉΩÂäõÁöÑÊèêÂçáÔºåËøëÂπ¥Êù•ÔºåÁ•ûÁªèÁΩëÁªúÂèàÊàê‰∏∫Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ï‰∏≠ÁöÑ‰∏Ä‰∏™ÁÉ≠ÁÇπ„ÄÇ ‰πãÂâçÂ∑≤ÁªèÂ≠¶‰π†ËøáÁ∫øÊÄßÂõûÂΩíÂíåÈÄªËæëÂõûÂΩíÁÆóÊ≥ïÔºå‰∏∫‰ªÄ‰πàËøòË¶ÅÁ†îÁ©∂Á•ûÁªèÁΩëÁªúÂë¢Ôºü‰∏∫‰∫ÜÈòêËø∞Á†îÁ©∂Á•ûÁªèÁΩëÁªúÁÆóÊ≥ïÁõÆÁöÑÔºåÊàë‰ª¨È¶ñÂÖàÊù•ÁúãÂá†‰∏™Êú∫Âô®Â≠¶‰π†ÁöÑÈóÆÈ¢ò‰Ωú‰∏∫‰æãÂ≠êÔºåËøôÂá†‰∏™‰æãÂ≠êÈÉΩ‰æùËµñ‰∫éÂ§çÊùÇÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ªÂô® ËÄÉËôëËøô‰∏™ÁõëÁù£Â≠¶‰π†ÁöÑÂàÜÁ±ªÈóÆÈ¢òÔºåÊàë‰ª¨Â∑≤ÁªèÊúâ‰∫ÜÂØπÂ∫îÁöÑËÆ≠ÁªÉÈõÜÔºåÂ¶ÇÊûúÂà©Áî®ÈÄªËæëÂõûÂΩíÁÆóÊ≥ïÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÈ¶ñÂÖàÈúÄË¶ÅÊûÑÈÄ†‰∏Ä‰∏™ÂåÖÂê´ÂæàÂ§öÈùûÁ∫øÊÄßÈ°πÁöÑÈÄªËæëÂõûÂΩíÂáΩÊï∞ÔºåËøôÈáåg‰ªçÊòØsÂûãÂáΩÊï∞ÔºàÂç≥f(x)=1/(1+e^-x)Ôºâ„ÄÇÊàë‰ª¨ËÉΩËÆ©ÂáΩÊï∞ÂåÖÂê´ËÆ∏Â§öÂÉèËøôÊ†∑ÁöÑÂ§öÈ°πÂºèÔºåÂΩìÂ§öÈ°πÂºèÁöÑÈ°πÊï∞Ë∂≥Â§üÁöÑÁöÑÊó∂ÂÄô‰Ω†ËÉΩÂ§üÂæóÂà∞‰∏Ä‰∏™ÂàÜÂºÄÊ≠£Ê†∑Êú¨ÂíåË¥üÊ†∑Êú¨ÁöÑÂà§ÂÆöËæπÁïå„ÄÇ ‰æãÂ¶ÇÂΩìÂè™Êúâ‰∏§È°πÊó∂ÊØîÂ¶Çx1Âíåx2ÔºåËøôÁßçÊñπÊ≥ïÁ°ÆÂÆûËÉΩÂ§üÂæóÂà∞‰∏çÈîôÁöÑÁªìÊûúÔºåÂõ†‰∏∫‰Ω†ÂèØ‰ª•Êääx1Âíåx2ÁöÑÊâÄÊúâÁªÑÂêàÈÉΩÂåÖÂê´Âà∞Â§öÈ°πÂºè‰∏≠Ôºå‰ΩÜÊòØÂØπ‰∫éËÆ∏Â§öÂ§çÊùÇÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢òËÄåË®ÄÔºåËÆæËÆ°ÁöÑÂ§öÈ°πÂºèÂæÄÂæÄÂ§ö‰∫é‰∏§È°π„ÄÇ ‰æãÂ¶ÇÊàë‰ª¨‰πãÂâçËÆ®ËÆ∫ËøáÁöÑÊàø‰ª∑È¢ÑÊµãÈóÆÈ¢òÔºåÂÅáËÆæÁé∞Âú®Â§ÑÁêÜÁöÑÊòØÂÖ≥‰∫éÊàøÂ±ãÁöÑÂàÜÁ±ªÈóÆÈ¢òËÄå‰∏çÊòØ‰∏Ä‰∏™ÂõûÂΩíÈóÆÈ¢ò„ÄÇÂÅáËÆæ‰Ω†ÂØπ‰∏ÄÊ†ãÊàøÂ≠êÁöÑÂ§öÊñπÈù¢ÁâπÁÇπÈÉΩÊúâÊâÄ‰∫ÜËß£Ôºå‰Ω†ÊÉ≥È¢ÑÊµãÊàøÂ±ãÂú®Êú™Êù•ÂçäÂπ¥ÂÜÖËÉΩÂ§üË¢´ÂçñÂá∫ÂéªÁöÑÊ¶ÇÁéáÔºåËøôÊòØ‰∏Ä‰∏™ÂàÜÁ±ªÈóÆÈ¢ò„ÄÇ Êàë‰ª¨ÂèØ‰ª•ÊÉ≥Âà∞ËÆ∏Â§öÁâπÂæÅÔºåÂØπ‰∫é‰∏çÂêåÁöÑÊàøÂ≠êÊúâÂèØËÉΩÊúâ‰∏äÁôæ‰∏™ÁâπÂæÅÔºåÂØπ‰∫éËøôÁ±ªÈóÆÈ¢òÂ¶ÇÊûúË¶ÅÂåÖÂê´ÊâÄÊúâÁöÑ‰∫åÊ¨°È°πÔºåÂç≥‰ΩøÂè™ÂåÖÂê´‰∫åÈ°πÂºèÊàñÂ§öÈ°πÂºèÁöÑËÆ°ÁÆóÔºåÊúÄÁªàÁöÑÂ§öÈ°πÂºè‰πüÂèØËÉΩÊúâÂæàÂ§öÈ°πÔºåÊØîÂ¶Çx1^2 ,x1x2 ,x1x3 ,x1x4Áõ¥Âà∞x1x100,Êé•ÁùÄËøòÊúâx2^2, x2x3Á≠âÁ≠âÂæàÂ§öÈ°π„ÄÇÂõ†Ê≠§Âç≥‰ΩøÂè™ËÄÉËôë‰∫åÈò∂È°πÔºå‰πüÂ∞±ÊòØËØ¥‰∏§‰∏™È°πÁöÑ‰πòÁßØx1‰πò‰ª•x1Á≠âÁ≠âÁ±ª‰ºº‰∫éÊ≠§ÁöÑÈ°πÔºåÈÇ£‰πàÔºåÂú®n=100ÁöÑÊÉÖÂÜµ‰∏ãÊúÄÁªà‰πüÊúâ5050‰∏™‰∫åÊ¨°È°π„ÄÇ ËÄå‰∏îÈöèÁùÄÁâπÂæÅ‰∏™Êï∞nÁöÑÂ¢ûÂä†Ôºå‰∫åÊ¨°È°πÁöÑ‰∏™Êï∞Â§ßÁ∫¶‰ª• n^2 ÁöÑÈáèÁ∫ßÂ¢ûÈïøÔºåÂÖ∂‰∏≠nÊòØÂéüÂßãÈ°πÁöÑ‰∏™Êï∞ÔºåÂç≥Êàë‰ª¨‰πãÂâçËØ¥ËøáÁöÑx1Âà∞x100Ëøô‰∫õÈ°π„ÄÇ‰∫ãÂÆû‰∏ä‰∫åÊ¨°È°πÁöÑ‰∏™Êï∞Â§ßÁ∫¶ÊòØÔºàn^2Ôºâ/2‰∏™ÔºåÂõ†Ê≠§Ë¶ÅÂåÖÂê´ÊâÄÊúâÁöÑ‰∫åÊ¨°È°πÊòØÂæàÂõ∞ÈöæÁöÑÔºåÊâÄ‰ª•ËøôÂèØËÉΩ‰∏çÊòØ‰∏Ä‰∏™Â•ΩÁöÑÂÅöÊ≥ï„ÄÇ ËÄå‰∏îÁî±‰∫éÈ°πÊï∞ÁöÑËøáÂ§öÔºåÊúÄÂêéÁöÑÁªìÊûúÂèØËÉΩÊòØËøáÊãüÂêàÁöÑÔºåÊ≠§Â§ñÔºåÂú®Â§ÑÁêÜËøô‰πàÂ§öÈ°πÊó∂‰πüÂ≠òÂú®ËøêÁÆóÈáèËøáÂ§ßÁöÑÈóÆÈ¢ò„ÄÇÂΩìÁÑ∂ÔºåÊàë‰ª¨‰πüÂèØ‰ª•ËØïËØïÂè™ÂåÖÂê´‰∏äËæπËøô‰∫õ‰∫åÊ¨°È°πÁöÑÂ≠êÈõÜÔºå‰æãÂ¶ÇÔºåÊàë‰ª¨Âè™ËÄÉËôëx1^2Ôºå x2^2Ôºå x3^3Áõ¥Âà∞ x100^2Ëøô‰∫õÈ°πÔºåËøôÊ†∑Â∞±ÂèØ‰ª•Â∞Ü‰∫åÊ¨°È°πÁöÑÊï∞ÈáèÂ§ßÂπÖÂ∫¶ÂáèÂ∞ëÔºåÂáèÂ∞ëÂà∞Âè™Êúâ100‰∏™‰∫åÊ¨°È°π„ÄÇ‰ΩÜÊòØÁî±‰∫éÂøΩÁï•‰∫ÜÂ§™Â§öÈ°πÔºåÂú®Â§ÑÁêÜÁ±ª‰ººÂ∑¶‰∏äËßíÁöÑÊï∞ÊçÆÊó∂Ôºå‰∏çÂ§™ÂèØËÉΩÂæóÂà∞ÁêÜÊÉ≥ÁöÑÁªìÊûú„ÄÇ ÂÆûÈôÖ‰∏äÂ¶ÇÊûúÂè™ËÄÉËôëx1ÁöÑÂπ≥ÊñπÂà∞x100ÁöÑÂπ≥ÊñπËøô‰∏ÄÁôæ‰∏™‰∫åÊ¨°È°πÔºåÈÇ£‰πà‰Ω†ÂèØËÉΩ‰ºöÊãüÂêàÂá∫‰∏Ä‰∫õÁâπÂà´ÁöÑÂÅáËÆæÔºåÊØîÂ¶ÇÂèØËÉΩÊãüÂêàÂá∫‰∏Ä‰∏™Ê§≠ÂúÜÁä∂ÁöÑÊõ≤Á∫øÔºå‰ΩÜÊòØËÇØÂÆö‰∏ç‰ºöÊãüÂêàÂá∫Â∑¶‰∏äËßíËøô‰∏™Êï∞ÊçÆÈõÜÁöÑÂàÜÁïåÁ∫øÔºåÊâÄ‰ª•5000‰∏™‰∫åÊ¨°È°πÁúãËµ∑Êù•Â∑≤ÁªèÂæàÂ§ö‰∫Ü„ÄÇ ËÄåÁé∞Âú®ÁöÑÂÅáËÆæËøòÂåÖÊã¨‰∏âÊ¨°È°πÔºå ‰æãÂ¶Çx1x2x3, x1^2x2, x10x11x17Á≠âÁ≠âÔºåÁ±ª‰ººÁöÑ‰∏âÊ¨°È°πÊúâÂæàÂ§öÂæàÂ§öÔºå‰∫ãÂÆû‰∏äÔºå‰∏âÊ¨°È°πÁöÑ‰∏™Êï∞ÊòØn^3ÁöÑÈáèÁ∫ßÂ¢ûÂä†„ÄÇÂΩìn=100Êó∂ÔºåÂèØ‰ª•ËÆ°ÁÆóÂá∫Êù•ÊúÄÂêéËÉΩÂæóÂà∞Â§ßÊ¶Ç17000‰∏™‰∏âÊ¨°È°π„ÄÇ ÊâÄ‰ª•ÔºåÂΩìÂàùÂßãÁâπÂæÅ‰∏™Êï∞nÂ¢ûÂ§ßÊó∂ÔºåËøô‰∫õÈ´òÈò∂Â§öÈ°πÂºèÂ∞Ü‰ª•Âá†‰ΩïÁ∫ßÊï∞ÈÄíÂ¢ûÔºåÁâπÂæÅÁ©∫Èó¥‰πüÈöè‰πãÊÄ•ÂâßËÜ®ËÉÄ„ÄÇÂΩìÁâπÂæÅÂÄº‰∏™Êï∞nÂæàÂ§ßÊó∂ÔºåÂ¶ÇÊûúÊâæÂá∫ÈôÑÂä†È°πÊù•Âª∫Á´ã‰∏Ä‰∫õÂàÜÁ±ªÂô®ÔºåËøôÂπ∂‰∏çÊòØ‰∏Ä‰∏™Â•ΩÂÅöÊ≥ï„ÄÇÂØπ‰∫éËÆ∏Â§öÂÆûÈôÖÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÔºåÁâπÂæÅ‰∏™Êï∞nÊòØÂæàÂ§ßÁöÑ„ÄÇ Êàë‰ª¨ÁúãÁúã‰∏ãËæπËøô‰∏™‰æãÂ≠êÔºåËøôÊòØÂÖ≥‰∫éËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠ÁöÑ‰∏Ä‰∏™ÈóÆÈ¢ò„ÄÇÂÅáËÆæ‰Ω†ÊÉ≥Ë¶Å‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊù•ËÆ≠ÁªÉ‰∏Ä‰∏™ÂàÜÁ±ªÂô®Ôºå‰Ωø‰ªñÊ£ÄÊµã‰∏Ä‰∏™ÂõæÂÉèÊòØÂê¶‰∏∫‰∏ÄËæÜÊ±ΩËΩ¶„ÄÇÂæàÂ§ö‰∫∫ÂèØËÉΩ‰ºöÂ•ΩÂ•áÔºåËßâÂæóËøôÂØπËÆ°ÁÆóÂô®ËßÜËßâÊù•ËØ¥Êúâ‰ªÄ‰πàÈöæÁöÑÔºü ÂΩìÊàë‰ª¨Ëá™Â∑±ÁúãËøôÂπÖÂõæÂÉèÊó∂ÈáåÈù¢Êúâ‰ªÄ‰πà‰∫ã‰∏ÄÁõÆ‰∫ÜÁÑ∂ÁöÑ‰∫ãÊÉÖÔºå‰Ω†ËÇØÂÆö‰ºöÂ•áÊÄ™Ôºå‰∏∫‰ªÄ‰πàÂ≠¶ÁÆóÊ≥ï‰ºö‰∏çÁü•ÈÅìÂõæÂÉèÊòØ‰ªÄ‰πà„ÄÇ ‰∏∫‰∫ÜËß£Á≠îËøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂèñÂá∫ËøôÂπÖÂõæÂÉèÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂ∞ÜÂÖ∂ÊîæÂ§ßÔºåÊØîÂ¶ÇËøôÂπÖÂõæ‰∏≠ÔºåÊ±ΩËΩ¶ÁöÑÈó®ÊääÊâãÔºåÁ∫¢Ê°Ü‰∏≠ÁöÑÈÉ®ÂàÜÔºå‰∫∫ËÇâÁúºÁúãÂà∞‰∏ÄËæÜËΩ¶Êó∂ÔºåËÆ°ÁÆóÊú∫ÁúãÂà∞ÁöÑÊòØ‰∏Ä‰∏™ËøôÊ†∑ÁöÑÊï∞ÊçÆÁü©Èòµ„ÄÇ ÂÆÉ‰ª¨Ë°®Á§∫‰∫ÜÂÉèÁ¥†Âº∫Â∫¶ÂÄºÔºåÂëäËØâÊàë‰ª¨ÂõæÂÉè‰∏≠ÊØè‰∏™ÂÉèÁ¥†ÁöÑ‰∫ÆÂ∫¶ÂÄº„ÄÇÂõ†Ê≠§ÔºåÂØπ‰∫éËÆ°ÁÆóÊú∫ËßÜËßâÊù•ËØ¥ÈóÆÈ¢òÂ∞±ÂèòÊàê‰∫ÜÔºåÊ†πÊçÆËøô‰∏™ÂÉèÁ¥†ÁÇπ‰∫ÆÂ∫¶Áü©ÈòµÊù•ÂëäËØâÊàë‰ª¨Ëøô‰∫õÊï∞ÂÄºÊòØÂê¶‰ª£Ë°®‰∏Ä‰∏™Ê±ΩËΩ¶Èó®ÊääÊâã„ÄÇ ÂÖ∑‰ΩìËÄåË®ÄÔºåÂΩìÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÊûÑÈÄ†‰∏Ä‰∏™Ê±ΩËΩ¶ËØÜÂà´Âô®Êó∂ÔºåÊàë‰ª¨ÊÉ≥Âá∫‰∏Ä‰∏™Â∏¶Ê†áÁ≠æÁöÑÊ†∑Êú¨ÈõÜÔºåÂÖ∂‰∏≠‰∏Ä‰∫õÊ†∑Êú¨ÊòØÂêÑÁ±ªÊ±ΩËΩ¶ÔºåËÄåÂè¶‰∏ÄÈÉ®ÂàÜÊ†∑Êú¨ÊòØÂÖ∂‰ªñ‰ªª‰Ωï‰∏úË•ø„ÄÇÂ∞ÜËøô‰∏™Ê†∑Êú¨ËæìÂÖ•ÁªôÂ≠¶‰π†ÁÆóÊ≥ï‰ª•ËÆ≠ÁªÉÂá∫‰∏Ä‰∏™ÂàÜÁ±ªÂô®ÔºåÂΩìËÆ≠ÁªÉÂÆåÊØïÂêéÔºåÊàë‰ª¨ËæìÂÖ•‰∏ÄÂâØÊñ∞ÁöÑÂõæÁâáÔºåËÆ©ÂàÜÁ±ªÂô®Âà§Âà´‚ÄúËøôÊòØ‰ªÄ‰πà‰∏úË•øÔºü‚ÄùÁêÜÊÉ≥ÊÉÖÂÜµ‰∏ãÔºåÂàÜÁ±ªÂô®ËÉΩËØÜÂà´Âá∫ËøôÊòØ‰∏ÄËæÜÊ±ΩËΩ¶„ÄÇ ‰∏∫‰∫ÜÁêÜËß£ÂºïÂÖ•ÈùûÁ∫øÊÄßÂàÜÁ±ªÂô®ÁöÑÂøÖË¶ÅÊÄßÔºåÊàë‰ª¨‰ªéÂ≠¶‰π†ÁÆóÊ≥ïÁöÑËÆ≠ÁªÉÊ†∑Êú¨‰∏≠ÊåëÈÄâÂá∫‰∏Ä‰∫õÊ±ΩËΩ¶ÁöÑÂõæÁâáÂíåÈùûÊ±ΩËΩ¶ÁöÑÂõæÁâá„ÄÇËÆ©Êàë‰ª¨‰ªéÂÖ∂‰∏≠ÊØèÂπÖÂõæÁâá‰∏≠ÊåëÂá∫‰∏ÄÁªÑÂÉèÁ¥†ÁîµÔºå‰æãÂ¶Ç‰∏äÂõæÂÉèÁ¥†ÁÇπ1ÁöÑ‰ΩçÁΩÆÂíåÂÉèÁ¥†2ÁöÑ‰ΩçÁΩÆ„ÄÇ Âú®ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫ËøôÂπÖÊ±ΩËΩ¶ÁöÑ‰ΩçÁΩÆÔºåÂÖ∂‰ªñÂùêÊ†áÁ≥ª‰∏≠ÁöÑ‰ΩçÁΩÆÂèñÂÜ≥‰∫éÂÉèÁ¥†ÁÇπ1ÂíåÂÉèÁ¥†ÁÇπ2ÁöÑ‰∫ÆÂ∫¶„ÄÇËÆ©Êàë‰ª¨Áî®ÂêåÊ†∑ÁöÑÊñπÊ≥ïÂú®ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫ÂÖ∂‰ªñÂõæÁâá‰∏≠Ê±ΩËΩ¶ÁöÑ‰ΩçÁΩÆ„ÄÇÊé•ÁùÄÊàë‰ª¨Âú®ÂùêÊ†áÁ≥ª‰∏≠ÁªßÁª≠Áîª‰∏ä‰∏§‰∏™ÈùûÊ±ΩËΩ¶Ê†∑Êú¨„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ÁªßÁª≠Âú®ÂùêÊ†áÁ≥ª‰∏≠Áîª‰∏äÊõ¥Â§öÊñ∞Ê†∑Êú¨ÔºåÁî®‚Äú+‚ÄùË°®Á§∫Ê±ΩËΩ¶ÂõæÁâáÔºåÁî®‚Äú-‚ÄùË°®Á§∫ÈùûÊ±ΩËΩ¶ÂõæÁâáÔºåÊàë‰ª¨Â∞ÜÂèëÁé∞Ê±ΩËΩ¶Ê†∑Êú¨ÂíåÈùûÊ±ΩËΩ¶Ê†∑Êú¨ÂàÜÂ∏ÉÂú®ÂùêÊ†áÁ≥ª‰∏≠ÁöÑ‰∏çÂêåÂå∫ÂüüÔºåÂõ†Ê≠§Êàë‰ª¨Áé∞Âú®ÈúÄË¶Å‰∏Ä‰∏™ÈùûÁ∫øÊÄßÂàÜÁ±ªÂô®ÔºåÊù•Â∞ΩÈáèÂàÜÂºÄËøô‰∏§Á±ªÊ†∑Êú¨„ÄÇ Ëøô‰∏™ÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÁâπÂæÅÁ©∫Èó¥ÁöÑÁª¥Â∫¶ÊòØÂ§öÂ∞ëÔºü ÊòæÁÑ∂Âú®ÁúüÂÆûÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨‰∏çÂèØËÉΩÂè™Âèñ‰∏§‰∏™ÂÉèÁ¥†ÁÇπÊù•ÂÅöÁâπÂæÅ„ÄÇÂÅáËÆæÊàë‰ª¨Áî®50*50ÂÉèÁ¥†ÁöÑÂõæÁâáÔºåÊ≥®ÊÑèÔºåÊàë‰ª¨ÁöÑÂõæÁâáÂ∑≤ÁªèË∂≥Â§üÂ∞è‰∫ÜÔºåÈïøÂÆΩÂè™ÂêÑÊúâ50‰∏™ÂÉèÁ¥†Ôºå‰ΩÜËøô‰æùÁÑ∂ÊòØ25000‰∏™ÂÉèÁ¥†ÁÇπÔºåÂõ†Ê≠§ÔºåÊàë‰ª¨ÁöÑÁâπÂæÅÂêëÈáèÁöÑÂÖÉÁ¥†Êï∞Èáè n=2500„ÄÇÁâπÂæÅÂêëÈáèXÂåÖÂê´‰∫ÜÊâÄÊúâÂÉèÁ¥†ÁÇπÁöÑ‰∫ÆÂ∫¶ÂÄº„ÄÇ ÂØπ‰∫éÂÖ∏ÂûãÁöÑËÆ°ÁÆóÊú∫ÂõæÁâáË°®Á§∫ÊñπÊ≥ïÔºåÂ¶ÇÊûúÂÇ®Â≠òÁöÑÊØè‰∏™ÂÉèÁ¥†ÁÇπÁÅ∞Â∫¶ÂÄºÔºàËâ≤ÂΩ©ÁöÑÂº∫ÁÉàÁ®ãÂ∫¶ÔºâÔºåÈÇ£‰πàÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂÄºÂ∫îËØ•Âú®0 Âà∞255‰πãÈó¥„ÄÇÂõ†Ê≠§ÔºåËøô‰∏™ÈóÆÈ¢ò‰∏≠n=2500 ‰ΩÜÊòØËøôÂè™ÊòØ‰ΩøÁî®ÁÅ∞Â∫¶ÂõæÁâáÁöÑÊÉÖÂÜµÔºåÂ¶ÇÊûúÊàë‰ª¨Áî®ÁöÑÊòØRGBÂΩ©Ëâ≤ÂõæÂÉèÔºåÊØè‰∏™ÂÉèÁ¥†ÁÇπÂåÖÂê´Á∫¢ÔºåÁªøÔºåËìù‰∏â‰∏™Â≠êÂÉèÁ¥†ÔºåÈÇ£‰πàn=7500„ÄÇ Âõ†Ê≠§ÔºåÂ¶ÇÊûúÊàë‰ª¨ÈùûË¶ÅÈÄöËøáÂåÖÂê´ÊâÄÊúâÁöÑ‰∫åÊ¨°È°πÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈùûÁ∫øÊÄßÈóÆÈ¢òÔºåÈÇ£‰πà‰ªÖ‰ªÖ‰∫åÊ¨°È°π xi * xjÊÄªÂÖ±ÊúâÂ§ßÁ∫¶300‰∏á‰∏™Ôºà2500^2/2ÔºâÔºåËøô‰∏™Êï∞Â≠óÂ§ßÁöÑÊúâÁÇπÁ¶ªË∞±‰∫Ü„ÄÇÂØπ‰∫éÊØè‰∏™Ê†∑Êú¨Êù•ËØ¥ÔºåË¶ÅÂèëÁé∞Âπ∂Ë°®Á§∫ÊâÄÊúâËøô300‰∏á‰∏™È°πÔºåËøô‰∏™ËÆ°ÁÆóÊàêÊú¨Â§™È´ò„ÄÇÂõ†Ê≠§ÔºåÂè™ÊòØÁÆÄÂçïÁöÑÂ¢ûÂä†‰∫åÊ¨°È°πÊàñËÄÖ‰∏âÊ¨°È°π‰πãÁ±ªÁöÑÈÄªËæëÂõûÂΩíÁÆóÊ≥ïÂπ∂‰∏çÊòØ‰∏Ä‰∏™Ëß£ÂÜ≥Â§çÊùÇÁ∫øÊÄßÈóÆÈ¢òÁöÑÂ•ΩÂäûÊ≥ï„ÄÇÂõ†‰∏∫nÂæàÂ§ßÊó∂ÔºåÂ∞Ü‰ºö‰∫ßÁîüÈùûÂ∏∏Â§öÁöÑÁâπÂæÅÈ°π„ÄÇ Êé•‰∏ãÊù•ÔºåÊàë‰ª¨‰ºöËÆ®ËÆ∫Á•ûÁªèÁΩëÁªúÔºå‰ªñÂú®Ëß£ÂÜ≥Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ªÈóÆÈ¢ò‰∏äÔºåË¢´ËØÅÊòéÊòØ‰∏ÄÁßçÂ•ΩÁöÑÂ§öÁöÑÁÆóÊ≥ïÔºåÂèäÊó∂‰Ω†ËæìÂÖ•ÁöÑÁâπÂæÅÁ©∫Èó¥ÊàñËæìÂÖ•ÁöÑÁâπÂæÅÁª¥Â∫¶nÂæàÂ§ßÔºå‰πüËÉΩËΩªÊùæÊêûÂÆö„ÄÇ Á•ûÁªèÂÖÉÂíåÂ§ßËÑëÔºàNeurons and the brainÔºâÁ•ûÁªèÁΩëÁªúÊòØ‰∏ÄÁßçÂæàÂè§ËÄÅÁöÑÁÆóÊ≥ïÔºå‰ªñÊúÄÂàù‰∫ßÁîüÁöÑÁõÆÁöÑÊòØÂà∂ÈÄ†Ê®°ÊãüÂ§ßËÑëÁöÑÊú∫Âô®„ÄÇÊàë‰ª¨Â∞Ü‰ºöËÆ®ËÆ∫Á•ûÁªèÁΩëÁªúÔºåÂõ†‰∏∫‰ªñËÉΩÂæàÂ•ΩÁöÑËß£ÂÜ≥‰∏çÂêåÁöÑÊú∫Âô®Â≠¶‰π†ÈóÆÈ¢òÔºåËÄå‰∏çÊòØÂè™Âõ†‰∏∫‰ªñ‰ª¨Âú®ÈÄªËæë‰∏äË°åÁöÑÈÄö„ÄÇ Á•ûÁªèÁΩëÁªú‰∫ßÁîüÁöÑÂéüÂõ†ÊòØ‰∫∫‰ª¨ÊÉ≥Â∞ùËØïËÆæËÆ°Âá∫Ê®°ÊãüÂ§ßËÑëÁöÑËÆ°ÁÆó„ÄÇ‰ªéÊüêÁßçÊÑè‰πâ‰∏äËØ¥ÔºåÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥Ë¶ÅÂª∫Á´ãÂ≠¶‰π†Á≥ªÁªüÈÇ£‰∏∫‰ªÄ‰πà‰∏çÂéªÊ®°ÊãüÊàë‰ª¨ÊâÄËÆ§ËØÜÁöÑÊúÄÁ•ûÂ•áÁöÑÂ≠¶‰π†Êú∫Âô®‚Äì‰∫∫Á±ªÁöÑÂ§ßËÑëÁöÑÔºü Á•ûÁªèÁΩëÁªúÈÄêÊ∏êÂÖ¥Ëµ∑‰∫é‰∫åÂçÅ‰∏ñÁ∫™ÂÖ´‰πùÂçÅÂπ¥‰ª£ÔºåÂ∫îÁî®ÁöÑÈùûÂ∏∏ÂπøÊ≥õ„ÄÇ‰ΩÜÁî±‰∫éÂêÑÁßçÂéüÂõ†Âú®90Âπ¥‰ª£ÁöÑÂêéÊúüÂ∫îÁî®ÂáèÂ∞ëÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÂéüÂõ†ÊòØÁ•ûÁªèÁΩëÁªúÊòØ‰∏ÄÁßçËÆ°ÁÆóÈáèÊúâ‰∫õÂÅèÂ§ßÁöÑÁÆóÊ≥ïÔºå‰ΩÜÊòØÊúÄËøëÁ•ûÁªèÁΩëÁªúÂèà‰∏úÂ±±ÂÜçËµ∑‰∫ÜÔºåÂ§ßÊ¶Ç Áî±‰∫éËøëÂπ¥Êù•ËÆ°ÁÆóÊú∫ÁöÑËøêË°åÈÄüÂ∫¶ÂèòÂø´ÔºåÊâçË∂≥‰ª•ÁúüÊ≠£ËøêË°åËµ∑Â§ßËßÑÊ®°ÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇ Ê≠£ÂºèÁî±‰∫éËøô‰∏™ÂéüÂõ†ÂíåÂÖ∂‰ªñ‰∏Ä‰∫õÊàë‰ª¨ÂêéÈù¢‰ºöËÆ®ËÆ∫ÁöÑÊäÄÊúØÂõ†Á¥†ÔºåÂ¶Ç‰ªäÁöÑÁ•ûÁªèÁΩëÁªúÂØπ‰∫éËÆ∏Â§öÂ∫îÁî®Êù•ËØ¥ÊòØÊúÄÂÖàËøõÁöÑÊäÄÊúØ„ÄÇ ÂΩì‰Ω†Ê®°ÊãüÂ§ßËÑëÊó∂ÔºåÊòØÊåáÊÉ≥Âà∂ÈÄ†Âá∫‰∫é‰∫∫Á±ªÂ§ßËÑëÊïàÊûúÁõ∏ÂêåÁöÑÊú∫Âô®„ÄÇÂ§ßËÑëÂèØ‰ª•Â≠¶‰ºöÂéªÁúãËÄå‰∏çÊòØÂê¨ÁöÑÊñπÂºèÂ§ÑÁêÜÂõæÂÉèÔºåÂ≠¶‰ºöÂ§ÑÁêÜÊàë‰ª¨ÁöÑËß¶Ëßâ„ÄÇÊàë‰ª¨ËÉΩÂ≠¶‰π†Êï∞Â≠¶ÔºåÂ≠¶‰π†ËÆ°ÁÆóÂæÆÁßØÂàÜÔºåËÄå‰∏îÂ§ßËÑëËÉΩÂ§ÑÁêÜÂêÑÁßç‰∏çÂêåÁöÑ‰ª§‰∫∫ÊÉäÂ•áÁöÑ‰∫ãÊÉÖ„ÄÇ‰ºº‰πéÂ¶ÇÊûú‰Ω†ÊÉ≥Ë¶ÅÊ®°‰ªøÂÆÉÔºå‰Ω†ÈúÄË¶ÅÂÜôËÆ∏Â§ö‰∏çÂêåÁöÑËΩØ‰ª∂Êù•Ê®°ÊãüÊâÄÊúâÂ§ßËÑëÂëäËØâÊàë‰ª¨Ëøô‰∫õ‰∫îËä±ÂÖ´Èó®ÁöÑÂ•áÂ¶ôÁöÑ‰∫ãÊÉÖ„ÄÇ Â¶ÇÊûúÂÅáËÆæÂ§ßËÑëÂ§ÑÁêÜÊâÄÊúâËøô‰∫õ‰∏çÂêå‰∫ãÊÉÖ‰∏çÈúÄË¶Å‰∏äÂçÉ‰∏™Á®ãÂ∫èÂéªÂÆûÁé∞‰ªñÔºåÁõ∏ÂèçÔºåÂ§ßËÑëÂè™ÈúÄË¶Å‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂ∞±ÂèØ‰ª•‰∫ÜÂë¢Ôºü Â∞ΩÁÆ°ËøôÂè™ÊòØ‰∏Ä‰∏™ÂÅáËÆæÔºå‰∏çËøáËÆ©ÊàëÂíå‰Ω†ÂàÜ‰∫´‰∏Ä‰∫õËøôÊñπÈù¢ÁöÑËØÅÊçÆ„ÄÇ Â¶ÇÂõæÂ§ßËÑëËøô‰∏™ÈÉ®ÂàÜÔºåËøô‰∏ÄÂ∞èÁâáÁ∫¢Ëâ≤Âå∫ÂüüÊòØ‰Ω†ÁöÑÂê¨ËßâÁöÆÂ±ÇÔºåÂ¶ÇÊûú‰Ω†ÈÄöËøáÊàëËØ¥ÁöÑËØùÊù•ÁêÜËß£ÊàëË°®ËææÁöÑÂÜÖÂÆπÔºåÈÇ£‰πàÊòØÈù†ËÄ≥ÊúµÊé•Êî∂Âà∞Â£∞Èü≥‰ø°Âè∑Âπ∂ÊääÂ£∞Èü≥‰ø°Âè∑‰º†ÈÄíÁªô‰Ω†ÁöÑÂê¨ËßâË°®ÁöÆÂ±ÇÔºåÊ≠£Âõ†Â¶ÇÊ≠§Ôºå‰Ω†ÊâçËÉΩÊòéÁôΩÊàëÁöÑËØù„ÄÇ Á•ûÁªèÁ≥ªÁªüÁßëÂ≠¶ÂÆ∂ÂÅö‰∫Ü‰∏Ä‰∏™ÊúâË∂£ÁöÑÂÆûÈ™åÔºåÊääËÄ≥ÊúµÂà∞Âê¨ËßâË°®ÁöÆÁöÑÁ•ûÁªèÂàáÊñ≠„ÄÇÂú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºåÂ∞ÜÂÖ∂ÈáçÊñ∞Êé•Âà∞‰∏Ä‰∏™Âä®Áâ©ÁöÑÂ§ßËÑë‰∏äÔºåËøôÊ†∑‰ªéÁúºÁùõÁúãÂà∞ÁöÑËßÜËßâÁ•ûÁªèÁöÑ‰ø°Âè∑ÊúÄÁªàÂ∞Ü‰º†Âà∞Âê¨ËßâË°®ÁöÆÂ±ÇÔºåÁªìÊûúË°®ÊòéÔºåÂê¨ËßâË°®ÁöÆÂ±ÇÂ∞Ü‰ºöÂ≠¶‰ºö‚ÄúÁúã‚Äù„ÄÇ ÊâÄ‰ª•ÔºåÂ¶ÇÊûú‰Ω†ÂØπÂä®Áâ©ËøôÊ†∑ÂÅöÈÇ£‰πàÂä®Áâ©Â∞±ÂèØ‰ª•ÂÆåÊàêËßÜËßâËæ®Âà´‰ªªÂä°Ôºå‰ªñ‰ª¨ÂèØ‰ª•ÁúãÂõæÂÉèÔºåÂπ∂Ê†πÊçÆÂõæÂÉèÂÅöÂá∫ÈÄÇÂΩìÁöÑÂÜ≥ÂÆö„ÄÇÂÆÉ‰ª¨Ê≠£ÊòØÈÄöËøáËÑëÁªÑÁªá‰∏≠ÁöÑËøô‰∏™ÈÉ®ÂàÜÂÆåÊàêÁöÑ„ÄÇ ‰∏ãÈù¢Âú®‰∏æÂè¶‰∏Ä‰∏™‰æãÂ≠êÔºåËøôÂùóÁ∫¢Ëâ≤ÁöÑËÑëÁªÑÁªáÊòØ‰Ω†ÁöÑË∫Ø‰ΩìÊÑüËßâÁöÆÂ±ÇÔºåËøôÊòØ‰Ω†Áî®Êù•Â§ÑÁêÜËß¶ËßâÁöÑ„ÄÇÂ¶ÇÊûú‰Ω†ÂÅö‰∏Ä‰∏™ÂíåÂàöÊâçÁ±ª‰ººÁöÑÈáçÊé•ÂÆûÈ™åÔºåÈÇ£‰πàË∫Ø‰ΩìÊÑüËßâÁöÆÂ±Ç‰πüËÉΩ‰ºö‚ÄúÁúã‚ÄùÔºåËøô‰∏™ÂÆûÈ™åÂíåÂÖ∂‰ªñ‰∏Ä‰∫õÁ±ª‰ººÁöÑÂÆûÈ™åË¢´Áß∞‰∏∫Á•ûÁªèÈáçÊé•ÂÆûÈ™å„ÄÇ‰ªéËøô‰∏™ÊÑè‰πâ‰∏äËØ¥ÔºåÂ¶ÇÊûú‰∫∫‰ΩìÊúâÂêå‰∏ÄÂùóËÑëÁªÑÁªáÂèØ‰ª•Â§ÑÁêÜÂÖâ„ÄÅÂ£∞ÊàñËß¶Ëßâ‰ø°Âè∑ÔºåÈÇ£‰πà‰πüËÆ∏Â≠òÂú®‰∏ÄÁßçÂ≠¶‰π†ÊñπÊ≥ïÂèØ‰ª•ÂêåÊó∂Â§ÑÁêÜËßÜËßâÔºåÂê¨ËßâÂíåËß¶ËßâÔºåËÄå‰∏çÊòØÈúÄË¶ÅÊàêÂçÉ‰∏™‰∏çÂêåÁöÑÁ®ãÂ∫èÊàñËÄÖÁÆóÊ≥ïÊù•ÂÅöËøô‰∫õ„ÄÇ Â§ßËÑëËÉΩÂ§üÂÆåÊàêÁöÑÊàêÂçÉ‰∏ä‰∏áÁöÑ‰∫ãÔºåÊàë‰ª¨ÈúÄË¶ÅÂÅöÁöÑÂ∞±ÊòØÊâæÂá∫‰∏Ä‰∫õËøë‰ººÁöÑÊàñÂÆûÈôÖÁöÑÂ§ßËÑëÂ≠¶‰π†ÁÆóÊ≥ïÔºåÁÑ∂ÂêéÂÆûÁé∞ÂÆÉÔºåÂ§ßËÑëÈÄöËøáËá™Â≠¶ÊéåÊè°Â¶Ç‰ΩïÂ§ÑÁêÜËøô‰∫õ‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèØ‰ª•ÁåúÊÉ≥ÔºåÂ¶ÇÊûúÊàë‰ª¨Êää‰ªª‰Ωï‰∏ÄÁßç‰º†ÊÑüÂô®Êé•Âà∞Â§ßËÑëÁöÑ‰ªª‰Ωï‰∏Ä‰∏™ÈÉ®‰ΩçÔºåÂ§ßËÑëÂ∞±‰ºöÂ≠¶‰ºöÂ§ÑÁêÜÂÆÉ„ÄÇ ÂÜçÁúã‰∏äÂõæÁöÑÂá†‰∏™‰æãÂ≠êÔºåÂ∑¶‰∏äËßíËøôÂº†ÂõæÊòØÁî®ËàåÂ§¥Â≠¶‰ºö‚ÄúÁúã‚ÄùÁöÑ‰∏Ä‰∏™‰æãÂ≠ê„ÄÇËøôÂÆûÈôÖ‰∏äÊòØ‰∏Ä‰∏™Âêç‰∏∫BrainPortÁöÑÁ≥ªÁªüÔºå‰ªñÁé∞Âú®Ê≠£Âú®FDAÔºàÁæéÂõΩÈ£üÂìÅËçØÁâ©ÁÆ°ÁêÜÂ±ÄÔºâÁöÑ‰∏¥Â∫äËØïÈ™åÈò∂ÊÆµÔºå‰ªñÂ∏ÆÂä©Â§±Êòé‰∫∫Â£´ÁúãËßÅ‰∫ãÁâ©„ÄÇ‰ªñÁöÑÂéüÁêÜÊòØÔºåÂú®‰Ω†ÂâçÈ¢ùÊà¥‰∏ä‰∏Ä‰∏™ÁÅ∞Â∫¶ÊëÑÂÉèÂ§¥Ôºå‰ªñËÉΩÂ§üËé∑Âèñ‰Ω†Èù¢ÂâçÁöÑ‰∫ãÁâ©ÁöÑ‰ΩéÂàÜËæ®ÁéáÁöÑÁÅ∞Â∫¶ÂõæÂÉè„ÄÇ‰Ω†ËøûÊé•‰∏ÄÊ†πÁ∫øÂà∞ËàåÂ§¥‰∏äÂÆâË£ÖÁöÑÁîµÊûÅÈòµÂàó‰∏äÔºåÈÇ£‰πàÊØè‰∏™ÂÉèÁ¥†ÈÉΩË¢´Êò†Â∞ÑÂà∞‰Ω†ËàåÂ§¥‰∏äÁöÑÊüê‰∏™‰ΩçÁΩÆ„ÄÇÂèØËÉΩÁîµÂéãÂÄºÈ´òÁöÑÁÇπÂØπÂ∫î‰∏Ä‰∏™ÊöóÂÉèÁ¥†ÔºåÁîµÂéãÂÄºÁöÑÁÇπÂØπÂ∫î‰∫ÆÂÉèÁ¥†„ÄÇ Âç≥‰Ωø‰æùÈù†ÂÆÉÁé∞Âú®ÁöÑÂäüËÉΩÔºå‰ΩøÁî®ËøôÁßçÁ≥ªÁªüÂ∞±ËÉΩÂ§üËÆ©‰∫∫Âú®Âá†ÂçÅÂàÜÈíüÈáåÂ≠¶‰ºöÁî®Êàë‰ª¨ÁöÑËàåÂ§¥Áúã‰∏úË•ø„ÄÇ ‰∏ãÈù¢ÊòØÁ¨¨‰∫å‰∏™‰æãÂ≠êÔºåÂÖ≥‰∫é‰∫∫‰ΩìÂõûÂ£∞ÂÆö‰ΩçÊàñËÄÖËØ¥‰∫∫‰ΩìÂ£∞Á∫≥„ÄÇ‰Ω†Êúâ‰∏§ÁßçÊñπÊ≥ïÂèØ‰ª•ÂÆûÁé∞Ôºå‰Ω†ÂèØ‰ª•ÂºπÂìçÊåáÊàñËÄÖÂíÇËàåÂ§¥„ÄÇÁé∞Âú®ÊúâÂ§±Êòé‰∫∫Â£´Á°ÆÂÆûÂú®Â≠¶Ê†°ÈáåÊé•ÂèóËøôÊ†∑ÁöÑÂüπËÆ≠ÔºåÂπ∂Â≠¶‰ºöËß£ËØª‰ªéÁéØÂ¢ÉÂèçÂºπÂõûÊù•ÁöÑÂ£∞Ê≥¢Ê®°Âºè‚ÄîËøôÂ∞±ÊòØÂ£∞Á∫≥„ÄÇ Â¶ÇÊûú‰Ω†ÊêúÁ¥¢ YouTube ‰πãÂêéÔºåÂ∞±‰ºöÂèëÁé∞Êúâ‰∫õËßÜÈ¢ëËÆ≤Ëø∞‰∫Ü‰∏Ä‰∏™‰ª§‰∫∫Áß∞Â•áÁöÑÂ≠©Â≠êÔºå‰ªñÂõ†‰∏∫ÁôåÁóáÁúºÁêÉÊÉ®ÈÅ≠ÁßªÈô§ÔºåËôΩÁÑ∂Â§±Âéª‰∫ÜÁúºÁêÉÔºå‰ΩÜÊòØÈÄöËøáÊâìÂìçÊåá‰ªñÂèØ‰ª•ÂõõÂ§ÑËµ∞Âä®ËÄå‰∏çÊíûÂà∞‰ªª‰Ωï‰∏úË•ø„ÄÇ‰ªñËÉΩÊªëÊªëÊùøÔºå‰ªñÂèØ‰ª•Â∞ÜÁØÆÁêÉÊäïÂÖ•ÁØÆÊ°Ü‰∏≠„ÄÇ Á¨¨‰∏â‰∏™‰æãÂ≠êÊòØËß¶ËßâÁöÆÂ∏¶ÔºåÂ¶ÇÊûú‰Ω†ÊääÂÆÉÊà¥Âú®ËÖ∞‰∏äÔºåËúÇÈ∏£Âô®‰ºöÂìçÔºåËÄå‰∏îÊÄªÊòØÊúùÂêëÂåóÊó∂ÂèëÂá∫Âó°Âó°Â£∞„ÄÇÂÆÉÂèØ‰ª•‰Ωø‰∫∫Êã•ÊúâÊñπÂêëÊÑüÔºåÁî®Á±ª‰ºº‰∫éÈ∏üÁ±ªÊÑüÁü•ÊñπÂêëÁöÑÊñπÂºè„ÄÇ ËøòÊúâ‰∏Ä‰∫õÁ¶ªÂ•áÁöÑ‰æãÂ≠êÔºåÂ¶ÇÊûú‰Ω†Âú®ÈùíËõôË∫´‰∏äÊèíÂÖ•Á¨¨‰∏âÂè™ÁúºÔºåÈùíËõô‰πüËÉΩÂ≠¶‰ºö‰ΩøÁî®ÈÇ£Âè™ÁúºÁùõ„ÄÇ Âõ†Ê≠§ÔºåËøôÂ∞Ü‰ºöÈùûÂ∏∏‰ª§‰∫∫ÊÉäÂ•á„ÄÇÂ¶ÇÊûú‰Ω†ËÉΩÊääÂá†‰πé‰ªª‰Ωï‰º†ÊÑüÂô®Êé•ÂÖ•Âà∞Â§ßËÑë‰∏≠ÔºåÂ§ßËÑëÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÂ∞±ËÉΩÊâæÂá∫Â≠¶‰π†Êï∞ÊçÆÁöÑÊñπÊ≥ïÂπ∂Â§ÑÁêÜËøô‰∫õÊï∞ÊçÆ„ÄÇ‰ªéÊüêÁßçÊÑè‰πâ‰∏äÊù•ËØ¥Â¶ÇÊûúÊàë‰ª¨ËÉΩÊâæÂá∫Â§ßËÑëÁöÑÂ≠¶‰π†ÁÆóÊ≥ïÔºåÁÑ∂ÂêéÂú®ËÆ°ÁÆóÊú∫‰∏äÊâßË°åÂ§ßËÑëÂ≠¶‰π†ÁÆóÊ≥ïÊàñ‰∏é‰πãÁõ∏‰ººÁöÑÁÆóÊ≥ïÔºå‰πüËÆ∏ËøôÂ∞ÜÊòØÊàë‰ª¨Âêë‰∫∫Â∑•Êô∫ËÉΩËøàËøõÂÅöÂá∫ÁöÑÊúÄÂ•ΩÁöÑÂ∞ùËØï„ÄÇ Ê®°ÂûãË°®Á§∫ÔºàModel RepresentationÔºâÁ•ûÁªèÁΩëÁªúÊòØÂú®Ê®°‰ªøÂ§ßËÑë‰∏≠ÁöÑÁ•ûÁªèÂÖÉÊàñËÄÖÁ•ûÁªèÁΩëÁªúÊó∂ÂèëÊòéÁöÑ„ÄÇÂõ†Ê≠§ÔºåË¶ÅËß£ÈáäÂ¶Ç‰ΩïË°®Á§∫Ê®°ÂûãÂÅáËÆæÔºåÊàë‰ª¨‰∏çÂ¶®ÂÖàÊù•ÁúãÂçï‰∏™Á•ûÁªèÂÖÉÂú®Â§ßËÑë‰∏≠ÊòØ‰ªÄ‰πàÊ†∑ÁöÑ„ÄÇ Êàë‰ª¨ÁöÑÂ§ßËÑë‰∏≠ÂÖÖÊª°‰∫ÜÂ¶Ç‰∏äÂõæÊâÄÁ§∫ÁöÑËøôÊ†∑ÁöÑÁöÑÁ•ûÁªèÂÖÉÔºåÁ•ûÁªèÂÖÉÊòØÂ§ßËÑë‰∏≠‰øÑÁªÜËÉûÔºåÂÖ∂‰∏≠Êúâ‰∏§ÁÇπÂÄºÂæóÊàë‰ª¨Ê≥®ÊÑèÔºå‰∏ÄÊòØÁ•ûÁªèÂÖÉÊúâÂÉèËøôÊ†∑ÁöÑÁªÜËÉû‰∏ªÈ¢òÔºàNucleusÔºâÔºå‰∫åÊòØÁ•ûÁªèÂÖÉÊúâ‰∏ÄÂÆöÊï∞ÈáèÁöÑËæìÂÖ•Á•ûÁªèÂíåËæìÂá∫Á•ûÁªè„ÄÇËøô‰∫õËæìÂÖ•Á•ûÁªèÂè´ÂÅöÊ†ëÁ™ÅÔºàdendriteÔºâÔºåÂèØ‰ª•Êää‰ªñ‰ª¨ÊÉ≥Ë±°ÊàêËæìÂÖ•ÁîµÁ∫øÔºå‰ªñ‰ª¨Êé•ÂèóÊù•Ëá™ÂÖ∂‰ªñÁ•ûÁªèÂÖÉÁöÑ‰ø°ÊÅØ„ÄÇÁ•ûÁªèÂÖÉÁöÑËæìÂá∫Á•ûÁªèÁÑ¶‰ΩúËΩ¥Á™ÅÔºàAxonÔºâÔºåËøô‰∫õËæìÂá∫Á•ûÁªèÊòØÁî®Êù•ÁªôÂÖ∂‰ªñÁ•ûÁªèÂÖÉ‰º†ÈÄí‰ø°Âè∑ÊàñËÄÖ‰º†ÈÄí‰ø°ÊÅØÁöÑ„ÄÇ ÁÆÄËÄåË®Ä‰πãÔºåÁ•ûÁªèÂÖÉÊòØ‰∏Ä‰∏™ËÆ°ÁÆóÂçïÂÖÉÔºå‰ªñ‰ªéËæìÂÖ•Á•ûÁªèÊé•Âèó‰∏ÄÂÆöÊï∞ÁõÆÁöÑ‰ø°ÊÅØÔºåÂπ∂ÂÅö‰∏Ä‰∫õËÆ°ÁÆóÔºåÁÑ∂ÂêéÂ∞ÜÁªìÊûúÈÄöËøá‰ªñÁöÑËΩ¥Á™Å‰º†ÈÄÅÂà∞ÂÖ∂‰ªñËäÇÁÇπÊàñËÄÖÂ§ßËÑë‰∏≠ÁöÑÂÖ∂‰ªñÁ•ûÁªèÂÖÉ„ÄÇ ‰∏ãÈù¢ÊòØÁ•ûÁªèÂÖÉÁöÑÁ§∫ÊÑèÂõæÔºö Á•ûÁªèÂÖÉÂà©Áî®ÂæÆÂº±ÁöÑÁîµÊµÅËøõË°åÊ≤üÈÄö„ÄÇËøô‰∫õÂº±ÁîµÊµÅ‰πüÁß∞‰ΩúÂä®‰ΩúÁîµ‰ΩçÔºåÂÖ∂ÂÆûÂ∞±ÊòØÂæÆÂº±ÁöÑÁîµÊµÅ„ÄÇÊâÄ‰ª•Â¶ÇÊûúÁ•ûÁªèÂÖÉÊÉ≥Ë¶Å‰º†ÈÄí‰∏Ä‰∏™Ê∂àÊÅØÔºå‰ªñÂ∞±‰ºöÈÄöËøáÂÆÉÁöÑËΩ¥Á™ÅÂèëÈÄÅ‰∏ÄÊÆµÂæÆÂº±ÁîµÊµÅÁªôÂÖ∂‰ªñÁ•ûÁªèÂÖÉ„ÄÇ ‰∏äÂõæ‰∏≠ÔºåÈªÑËâ≤ÁöÑÂúÜÂúàÂ∞±‰ª£Ë°®‰∫Ü‰∏Ä‰∏™Á•ûÁªèÂÖÉÔºåX‰∏∫ËæìÂÖ•ÂêëÈáèÔºåŒ∏‰ª£Ë°®Á•ûÁªèÂÖÉÁöÑÊùÉÈáçÔºàÂ∞±ÊòØÊàë‰ª¨‰πãÂâçÊâÄËØ¥ÁöÑÊ®°ÂûãÂèÇÊï∞ÔºâÔºåhŒ∏(x)‰ª£Ë°®ÊøÄÂä±ÂáΩÊï∞ÔºàÂú®Á•ûÁªèÁΩëÁªúÊúØËØ≠‰∏≠ÔºåÊøÄÂä±ÂáΩÊï∞Âè™ÂØπÁ±ª‰ººÈùûÁ∫øÊÄßÂáΩÊï∞Ôºàg(z)ÁöÑÂè¶‰∏Ä‰∏™ÊúØËØ≠Áß∞ÂëºÔºåg(z)Á≠â‰∫é1Èô§‰ª•1Âä†eÁöÑ-zÊ¨°ÊñπÔºâ„ÄÇ ÂÆûÈôÖ‰∏ä‰Ω†ÂèØ‰ª•ËøôÊ†∑ÁêÜËß£ÔºåÁ•ûÁªèÂÖÉÂ∞±ÊòØÊùÉÈáçŒ∏„ÄÇ ÂΩìÂ∞ÜËæìÂÖ•ÈÄÅËøõÁ•ûÁªèÂÖÉÂêéÔºåÁªèËÆ°ÁÆóÔºàÂ∞±ÊòØX^TŒ∏Ôºâ‰ºöÊúâ‰∏Ä‰∏™ËæìÂá∫ÔºåËøô‰∏™ËæìÂá∫ÂÜçÈÄÅËøõÊøÄÂä±ÂáΩÊï∞‰∏≠Ôºå‰æøÂæóÂà∞‰∫ÜÁ•ûÁªèÂÖÉÁöÑÁúüÂÆûËæìÂá∫„ÄÇ Ê≥®ÊÑèÔºöÂΩìÊàë‰ª¨ÁªòÂà∂‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊó∂ÔºåÈÄöÂ∏∏Êàë‰ºöÂè™ÁªòÂà∂ËäÇÁÇπx1,x2,x3Á≠âÁ≠âÔºå‰ΩÜÊúâÊó∂ÂèØ‰ª•Â¢ûÂä†‰∏Ä‰∏™È¢ùÂ§ñÁöÑËäÇÁÇπx0ÔºåËøô‰∏™x0ËäÇÁÇπÊúâÊó∂Ë¢´Áß∞‰ΩúÂÅèÁΩÆÁ•ûÁªèÂÖÉ„ÄÇ‰ΩÜÂõ†‰∏∫x0ÊÄªÊòØÁ≠â‰∫é1ÔºåÂéªÂì¶‰ª¨‰ºöÁîªÂá∫ÂÆÉÔºåÊúâÊó∂Êàë‰ª¨‰∏ç‰ºöÁîªÂá∫ÔºåËøôË¶ÅÁúãÁîªÂá∫‰ªñÊòØÂê¶ÂØπ‰æãÂ≠êÊúâÂà©„ÄÇ Á•ûÁªèÁΩëÁªúÂ∞±ÊòØ‰∏çÂêåÁöÑÁ•ûÁªèÂÖÉÁªÑÂêàÂú®‰∏ÄËµ∑ÔºåÁ¨¨‰∏ÄÂ±Ç‰∏∫ËæìÂÖ•Â±ÇÔºåÊúÄÂêé‰∏ÄÂ±Ç‰∏∫ËæìÂá∫Â±ÇÔºåËÄå‰∏î‰∏≠Èó¥ÁöÑÊâÄÊúâÂ±ÇÂùá‰∏∫ÈöêËóèÂ±Ç„ÄÇ Ê≥®ÊÑèÔºöËæìÂÖ•ÂçïÂÖÉx1Ôºåx2Ôºåx3ÔºåÂÜçËØ¥‰∏ÄÊ¨°ÔºåÊúâÊó∂‰πüÂèØ‰ª•Áîª‰∏äÈ¢ùÂ§ñÁöÑËäÇÁÇπx0.ÂêåÊó∂ÔºåËøôÈáåÊúâ‰∏â‰∏™Á•ûÁªèÂÖÉÔºåÊàëÂú®ÈáåÈù¢ÂÜô‰∫Üa1(2) „ÄÅ a2(2) Âíåa3(2) ,ÁÑ∂ÂêéÂÜçÊ¨°ËØ¥ÊòéËøôÈáåÊàëÂèØ‰ª•Ê∑ªÂä†‰∏Ä‰∏™a0(2) ÔºåËøôÂíåx0‰∏ÄÊ†∑Ôºå‰ª£Ë°®‰∏Ä‰∏™È¢ùÂ§ñÁöÑÂÅèÂ∫¶Âçï‰ΩçÔºåÂÆÉÁöÑÂÄºÊ∞∏ËøúÊòØ1ÔºåÊ≥®ÊÑèÔºöa1(2) „ÄÅ a2(2) Âíåa3(2)‰∏≠ËÆ°ÁÆóÁöÑÊòØgÔºàX^TŒ∏ÔºâÁöÑÂÄºÔºåËÄåa0(2)‰∏≠Â≠òÊîæÁöÑÂ∞±ÊòØÂÅèÁΩÆ1„ÄÇ Â¶ÇÊûú‰∏Ä‰∏™ÁΩëÁªúÂú®Á¨¨jÂ±ÇÊúâsj‰∏™ÂçïÂÖÉÔºåÂú®j+1Â±ÇÊúâsj+1‰∏™ÂçïÂÖÉÔºåÈÇ£‰πàÁü©ÈòµŒ∏(j)Âç≥ÊéßÂà∂Á¨¨jÂ±ÇÂà∞Á¨¨j+1Â±ÇÁöÑÊò†Â∞Ñ„ÄÇ Áü©ÈòµŒ∏(j)ÁöÑÁª¥Â∫¶ÊòØs(j+1)*(sj+1),s(j+1)Ë°åÔºå(sj+1)Âàó ÊÄª‰πãÔºå‰∏äÈù¢ÁöÑÂõæÂ±ïÁ§∫‰∫ÜÊòØÊÄéÊ†∑ÂÆö‰πâ‰∏Ä‰∏™‰∫∫Â∑•ÁΩëÁªúÁöÑ„ÄÇËøô‰∏™Á•ûÁªèÁΩëÁªúÂÆö‰πâ‰∫ÜÂáΩÊï∞h:‰ªéËæìÂÖ•xÂà∞ËæìÂá∫yÁöÑÊò†Â∞Ñ„ÄÇÊàëÂ∞ÜËøô‰∫õÂÅáËÆæÁöÑÂèÇÊï∞ËÆ∞‰∏∫Â§ßÂÜôÁöÑŒ∏ÔºåËøôÊ†∑‰∏ÄÊù•‰∏çÂêåÁöÑŒ∏ÂØπÂ∫î‰∏çÂêåÁöÑÂÅáËÆæÔºåÊâÄ‰ª•Êàë‰ª¨Êúâ‰∏çÂêåÁöÑÂáΩÊï∞ÔºåÊØîÂ¶ÇËØ¥‰ªéxÂà∞yÁöÑÊò†Â∞Ñ„ÄÇ ‰ª•‰∏äÂ∞±ÊòØÊàë‰ª¨ÊÄé‰πà‰ªéÊï∞Â≠¶‰∏äÂÆö‰πâÁ•ûÁªèÁΩëÁªúÁöÑÂÅáËÆæ ‰∏ãÈù¢Â∞ÜËÆ≤Ëß£Â¶Ç‰ΩïÈ´òÊïàÁöÑËøõË°åËÆ°ÁÆóÔºåÂπ∂Â±ïÁ§∫‰∏Ä‰∏™ÂêëÈáèÂåñÁöÑÂÆûÁé∞ÊñπÊ≥ïÔºåÊõ¥ÈáçË¶ÅÁöÑÊòØËÆ©‰Ω†ÊòéÁôΩËøôÊ†∑Ë°®Á§∫Á•ûÁªèÁΩëÁªúÊòØ‰∏Ä‰∏™Â•ΩÊñπÊ≥ïÔºåÂπ∂‰∏îÊòéÁôΩÂÆÉ‰ª¨ÊÄéÊ†∑Â∏ÆÂä©Êàë‰ª¨Â≠¶‰π†Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂÅáËÆæ ‰ª•ÂâçÊàë‰ª¨ËØ¥ËøáËÆ°ÁÆóÂá∫ÂÅáËÆæËæìÂá∫ÁöÑÊ≠•È™§ÔºåÈÄöËøáÂ∑¶ËæπÁöÑËøô‰∫õÊñπÁ®ãËÆ°ÁÆóÂá∫‰∏â‰∏™ÈöêËóèÁöÑÂçïÂÖÉÁöÑÊøÄÂä±ÂÄºÔºåÁÑ∂ÂêéÂà©Áî®Ëøô‰∫õÂÄºÊù•ËÆ°ÁÆóÂÅáËÆæÂáΩÊï∞h(x)ÁöÑÊúÄÁªàËæìÂá∫ÔºåÊé•‰∏ãÊù•ÊàëË¶ÅÂÆö‰πâ‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÈ°πÔºåÂõ†Ê≠§Ôºå‰∏äÂõæ‰∏≠ËìùËâ≤Á∫øÁöÑÈ°πÊää‰ªñÂÆö‰πâ‰∏∫z‰∏äÊ†áÔºà2Ôºâ‰∏ãÊ†á1ÔºåËøôÊ†∑‰∏ÄÊù•Â∞±Êúâ‰∫Üa(2)1 Ëøô‰∏™È°πÔºåÁ≠â‰∫ég(z(2)1)(‰∏äÊ†á2ÁöÑÊÑèÊÄùÊòØ‰∏éÁ¨¨‰∫åÂ±ÇÁõ∏ÂÖ≥ÔºåÂç≥Á•ûÁªèÁΩëÁªúÁöÑÈöêËóèÂ±ÇÊúâÂÖ≥)Êé•‰∏ãÊù•ÁîªÁ∫¢Á∫øÁöÑÈ°πÂêåÊ†∑ÂÆö‰πâ‰∏∫z(2)2ÔºåÊúÄÂêé‰∏ÄÈ°πÂÆö‰πâ‰∏∫z(2)3ÔºåËøôÊ†∑Êàë‰ª¨Â∞±Êúâa(2)3=g(z(2)3)ÔºåÊâÄ‰ª•Ëøô‰∫õZÁöÑÂÄºÊòØÁ∫øÊÄßÁªÑÂêàÔºåÊòØËæìÂÖ•ÂÄºx1,x2,x3ÁöÑÂä†ÊùÉÁ∫øÊÄßÁªÑÂêàÔºå‰ªñÂ∞ÜËøõÂÖ•‰∏Ä‰∏™ÁâπÂÆöÁöÑÁ•ûÁªèÂÖÉÔºåÁ±ª‰ºº‰∫éÁü©ÈòµÂêëÈáèÁöÑ‰πòÊ≥ï„ÄÇ Áé∞Âú®Áúã‰∏ÄÁ∫øÁÅ∞Ëâ≤Ê°ÜÈáåÁöÑ‰∏ÄÁª¥Êï∞ÁªÑÔºå‰Ω†ÂèØËÉΩ‰ºöÊ≥®ÊÑèÂà∞Ëøô‰∏ÄÂùóÂØπÂ∫î‰∫ÜÁü©ÈòµÂêëÈáèÁöÑËøêÁÆóx1‰πò‰ª•ÂêëÈáèxÔºåËßÇÂØüÂà∞Ëøô‰∏ÄÁÇπÊàëÂ∞±ËÉΩÂ§üÂ∞ÜÁ•ûÁªèÁΩëÁªúÁöÑËøêÁÆóÂêëÈáèÂåñÔºåÂÖ∑‰ΩìËÄåË®ÄÊàë‰ª¨ÂÆö‰πâÁâπÂæÅÂêëÈáèx‰∏∫x0,x1,x2,x3ÁªÑÊàêÁöÑÂêëÈáèÔºåÂÖ∂‰∏≠x0=1ÔºåÂπ∂ÂÆö‰πâz^2‰∏∫Ëøô‰∫õÂÄºÁªÑÊàêÁöÑÂêëÈáèÔºåÊ≥®ÊÑèÔºöËøôÈáåÁöÑZ(2)ÊòØ‰∏Ä‰∏™‰∏âÁª¥ÂêëÈáè„ÄÇ ‰∏ãÈù¢Êàë‰ª¨ÂèØ‰ª•ËøôÊ†∑ÂêëÈáèÂåñ1(2) „ÄÅ a2(2) Âíåa3(2)ÁöÑËÆ°ÁÆóÊàë‰ª¨Âè™Áî®‰∏§‰∏™Ê≠•È™§z(2)Á≠â‰∫éŒ∏(1)‰πò‰ª•xÔºåÁÑ∂Âêéa(2)Á≠â‰∫ég(z(2))ÔºåÈúÄË¶ÅÊòéÁôΩÁöÑÊòØËøôÈáåÁöÑz(2)ÊòØ‰∏Ä‰∏™‰∏âÁª¥ÂêëÈáèÔºåÂπ∂‰∏îa(2)‰πüÊòØ‰∏Ä‰∏™‰∏âÁª¥ÂêëÈáèÂõ†Ê≠§ËøôÈáåÁöÑÊøÄÂä±Â∞ÜsÂáΩÊï∞ÈÄêÂÖÉÁ¥†‰ΩúÁî®‰∫éz(2)‰∏≠ÁöÑÊØè‰∏™ÂÖÉÁ¥†z(2)Â∞±Á≠â‰∫éŒ∏(1)‰πò‰ª•a(1)„ÄÇÂΩìÁÑ∂x‰πüÊúâÂÅèÁΩÆÂçïÂÖÉx0Ôºå È°∫‰æøËØ¥‰∏Ä‰∏ãÔºå‰∏∫‰∫ÜËÆ©Êàë‰ª¨ÁöÑÁ¨¶Âè∑ÂíåÊé•‰∏ãÊù•ÁöÑÂ∑•‰Ωú‰∏ÄËá¥ÔºåÂú®ËæìÂÖ•Â±ÇÔºåËôΩÁÑ∂Êàë‰ª¨ÊúâËæìÂÖ•x‰ΩÜÊòØÊàë‰ª¨ËøòÂèØ‰ª•ÊääËøô‰∫õÊÉ≥ÊàêÊòØÁ¨¨‰∏ÄÂ±ÇÁöÑÊøÄÂä±ÔºåÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•ÂÆö‰πâÁ¨¨‰∏ÄÂ±ÇÁöÑÊøÄÂä±a(1)=x,Âõ†Ê≠§a(1)Â∞±ÊòØ‰∏Ä‰∏™ÂêëÈáè‰∫ÜÔºåÊàë‰ª¨ÂèØ‰ª•ÊääËøôÈáåÁöÑxÊõøÊç¢Êàêa(1) Áé∞Âú®Êàë‰ª¨ÂæóÂà∞‰∫Üa1Ôºåa2Ôºåa3ÁöÑÂÄºÔºå‰ΩÜÊòØÊàë‰ª¨ÂêåÊ†∑ÈúÄË¶Å‰∏Ä‰∏™ÂÄºa0Ôºå‰ªñÂØπÂ∫îÈöêËóèÂ±ÇÂæóÂà∞Ëøô‰∏™ËæìÂá∫ÁöÑÂÅèÁΩÆÂçïÂÖÉÔºåËøôÊó∂a(2)Â∞±ÊòØ‰∏Ä‰∏™ÂõõÁª¥ÁöÑÁâπÂæÅÂêëÈáè„ÄÇ ‰∏∫‰∫ÜËÆ°ÁÆóÂÅáËÆæÁöÑÂÆûÈôÖËæìÂá∫ÂÄºhÔºåÊàë‰ª¨Âè™ÈúÄË¶ÅËÆ°ÁÆóz(3),z(3)Á≠â‰∫éÁªøËâ≤Ê°ÜÊ°Ü‰∏≠ÁöÑÈ°πÁõÆÔºåÊúÄÂêéÂÅáËÆæÂáΩÊï∞h(x)ËæìÂá∫‰ªñÁ≠â‰∫éa(3),a(3)ÊòØËæìÂá∫Â±ÇÂîØ‰∏ÄÁöÑÂçïÂÖÉÔºå‰ªñÊòØ‰∏Ä‰∏™ÂÆûÊï∞„ÄÇ Ëøô‰∏™h(x)ÁöÑËÆ°ÁÆóËøáÁ®ã‰πüÊàê‰∏∫ÂêëÂâç‰º†Êí≠(forward propagation),ËøôÊ†∑ÁöÑÂëΩÂêçÊòØÂõ†‰∏∫Êàë‰ª¨ÊòØ‰ªéËæìÂÖ•Â±ÇÁöÑÊøÄÂä±ÂºÄÂßãÔºåÁÑ∂ÂêéËøõË°åÂêëÂâç‰º†Êí≠ÁªôÈöêËóèÂ±ÇÔºåÂπ∂ËÆ°ÁÆóÈöêËóèÂ±ÇÔºåÁÑ∂ÂêéÊàë‰ª¨ÁªßÁª≠ÂêëÂâç‰º†Êí≠ÔºåËÆ°ÁÆóËæìÂá∫Â±ÇÁöÑÊøÄÂä±ÔºåËøô‰∏™‰ªéËæìÂÖ•Â±ÇÂà∞ÈöêËóèÂ±ÇÂÜçÂà∞ËæìÂá∫Â±Ç‰∏ÄÊ¨°ËÆ°ÁÆóÊøÄÂä±ÁöÑËøáÁ®ãÂè´ÂêëÂâç‰º†Êí≠„ÄÇ Êàë‰ª¨ÂàöÂàöÂæóÂà∞‰∫ÜËøô‰∏ÄËøáÁ®ãÁöÑÂêëÈáèÂåñÂÆûÁé∞ÊñπÊ≥ïÔºåÂ¶ÇÊûúÁî®Âè≥ËæπÁöÑÂÖ¨ÂºèËÆ°ÁÆóÔºå‰ºöÂæóÂà∞‰∏Ä‰∏™ÊúâÊïàÁöÑËÆ°ÁÆóh(x)ÁöÑÊñπÊ≥ï ËøôÁßçÂêëÂâç‰º†Êí≠ÁöÑËßíÂ∫¶ÔºåÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨‰∫ÜËß£Á•ûÁªèÁΩëÁªúÁöÑÂéüÁêÜÔºåÂ∏ÆÂä©Êàë‰ª¨Â≠¶‰π†ÈùûÁ∫øÊÄßÂÅáËÆæ Áúã‰∏äÈù¢ËøôÂπÖÂõæÔºåÊàë‰ª¨ÂÖàÁõñ‰ΩèÂõæÁâáÂ∑¶ËæπÁöÑÈÉ®ÂàÜÔºåÂ¶ÇÊûúÂè™ÁúãÂè≥ËæπÔºåËøôÁúãËµ∑Êù•ÂæàÂÉèÈÄªËæëÂõûÂΩíÔºåÂú®ÈÄªËæëÂõûÂΩí‰∏≠Êàë‰ª¨Áî®ÊúÄÂêé‰∏Ä‰∏™ËäÇÁÇπÔºå‰πüÂ∞±ÊòØÊúÄÂêé‰∏Ä‰∏™ÈÄªËæëÂõûÂΩíÂçïÂÖÉÊù•È¢ÑÊµãh(x)ÁöÑÂÄºÔºåÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂÅáËÆæËæìÂá∫ÁöÑh(x)Á≠â‰∫ésÂûãÊøÄÂä±ÂáΩÊï∞g(Œòa1+Œòa2‚Ä¶)„ÄÇÂÖ∂‰∏≠aÁî±ÈÇ£‰∏â‰∏™ÂçïÂÖÉ‰∏ÄÊ†∑Ôºå‰∏∫‰∫ÜÂíåÊàë‰ª¨‰πãÂâçÁöÑÂÆö‰πâ‰øùÊåÅ‰∏ÄËá¥ÔºåÈúÄË¶ÅÊ∑ªÂä†Á∫¢Ëâ≤ÁöÑ‰∏äÊ†áÂíå‰∏ãÊ†á1ÔºåÂõ†‰∏∫Êàë‰ª¨Âè™Êúâ‰∏Ä‰∏™ËæìÂá∫ÂçïÂÖÉÔºå‰ΩÜÂ¶ÇÊûú‰Ω†Âè™ËßÇÂØüËìùËâ≤ÁöÑÈÉ®ÂàÜÔºåËøôÁúãËµ∑Êù•ÈùûÂ∏∏ÂÉèÊ†áÂáÜÁöÑÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºå‰∏çÂêå‰πãÂ§ÑÂú®‰∫éÔºåÊàëÁé∞Âú®Áî®ÁöÑÊòØÂ§ßÂÜôÁöÑŒòÔºåËÄå‰∏çÊòØÂ∞èÂÜôÁöÑŒòÔºåËøôÊ†∑ÂÅöÂÆåÊàë‰ª¨Âè™ÂæóÂà∞‰∫ÜÈÄªËæëÂõûÂΩíÔºå‰ΩÜÊòØÈÄªËæëÂõûÂΩíËæìÂÖ•ÁâπÂæÅÂÄºÊòØÈÄöËøáÈöêËóèÂ±ÇËÆ°ÁÆóÁöÑ„ÄÇ ÂÜçËØ¥‰∏ÄÈÅçÔºåÁ•ûÁªèÁΩëÁªúÊâÄÂÅöÁöÑÂ∞±ÂÉèÈÄªËæëÂõûÂΩíÔºå‰ΩÜÊòØÂÆÉ‰∏çÊòØ‰ΩøÁî®x1Ôºåx2Ôºåx3‰Ωú‰∏∫ËæìÂÖ•ÁâπÂæÅÔºåËÄåÊòØÁî®a1Ôºåa2Ôºåa3‰Ωú‰∏∫Êñ∞ÁöÑËæìÂÖ•ÁâπÂæÅÔºåÂêåÊ†∑ÁöÑÊàë‰ª¨ÈúÄË¶ÅÊää‰∏äÊ†áÂä†‰∏äÊù•Âíå‰πãÂâçÁöÑËÆ∞Âè∑‰øùÊåÅ‰∏ÄËá¥ÔºåÊúâË∂£ÁöÑÊòØÁâπÂæÅÂÄºa1Ôºåa2Ôºåa2ÊòØÂΩìÂÅöËæìÂÖ•ÂáΩÊï∞Êù•Â≠¶‰π†ÁöÑÔºåÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂ∞±ÊòØ‰ªéÁ¨¨‰∏ÄÂ±ÇÊò†Â∞ÑÂà∞Á¨¨‰∫åÂ±ÇÁöÑÂáΩÊï∞ÔºåËøô‰∏™ÂáΩÊï∞Áî±ÂÖ∂‰ªñ‰∏ÄÁªÑÂèÇÊï∞Œ∏(1)ÂÜ≥ÂÆöÔºåËÄåÂú®Á•ûÁªèÁΩëÁªú‰∏äÔºå‰ªñÊ≤°ÊúâÁî®ËæìÂÖ•ÁâπÂæÅx1Ôºåx2Ôºåx3ÔºåÊù•ËÆ≠ÁªÉÈÄªËæëÂõûÂΩíËÄåÊòØËá™Â∑±ËÆ≠ÁªÉÈÄªËæëÂõûÂΩíÁöÑËæìÂÖ•a1Ôºåa2Ôºåa3ÔºåÂèØ‰ª•ÊÉ≥Ë±°ÔºåÂ¶ÇÊûúÂú®Œ∏1‰∏≠ÈÄâÊã©‰∏çÂêåÁöÑÂèÇÊï∞ÔºåÂèØ‰ª•Â≠¶‰π†‰∏Ä‰∫õÂæàÊúâË∂£ÂíåÂ§çÊùÇÁöÑÁâπÂæÅÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™Êõ¥Â•ΩÁöÑÂÅáËÆæÔºåÊØî‰ΩøÁî®ÂéüÂßãËæìÂÖ•x1Ôºåx2Êàñx3Êó∂ÂæóÂà∞ÁöÑÂÅáËÆæÊõ¥Â•Ω„ÄÇ ‰Ω†‰πüÂèØ‰ª•x1Ôºåx2Ôºåx3Á≠â‰Ωú‰∏∫ËæìÂÖ•È°πÔºå‰ΩÜÊòØËøô‰∏™ÁÆóÊ≥ïÂèØ‰ª•ÁÅµÊ¥ªÁöÑÂø´ÈÄüÂ≠¶‰π†‰ªªÊÑèÁöÑÁâπÂæÅÈ°πÔºåÊääËøô‰∫õa1Ôºåa2Ôºåa3,ËæìÂÖ•Ëøô‰∏™ÊúÄÂêéÁöÑÂçïÂÖÉÔºåÂÆûÈôÖ‰∏ä‰ªñÊòØÈÄªËæëÂõûÂΩí„ÄÇ ËøòÂèØ‰ª•Áî®ÂÖ∂‰ªñÁ±ªÂûãÂõæË°®Á§∫Á•ûÁªèÁΩëÁªúÔºåÁ•ûÁªèÁΩëÁªú‰∏≠Á•ûÁªèÂÖÉÁõ∏ËøûÊé•ÁöÑÊñπÂºèÔºåÁß∞‰∏∫Á•ûÁªèÁΩëÁªúÁöÑÊû∂ÊûÑÔºåÊâÄ‰ª•Êû∂ÊûÑÊòØÊåáÔºå‰∏çÂêåÁöÑÁ•ûÁªèÂÖÉÊòØÂ¶Ç‰ΩïÁõ∏‰∫íËøûÊé•ÁöÑÔºåËøôÈáåÊúâ‰∏™‰∏Ä‰∏çÂêåÁöÑÁ•ûÁªèÁΩëÁªúÊû∂ÊûÑÁöÑ‰æãÂ≠êÔºå‰Ω†ÂèØ‰ª•ÊÑèËØÜÂà∞Ëøô‰∏™Á¨¨‰∫åÂ±ÇÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÔºåÊàë‰ª¨Êúâ‰∏â‰∏™ÈöêËóèÂçïÂÖÉÔºåÂÆÉ‰ª¨Ê†πÊçÆËæìÂÖ•Â±ÇËÆ°ÁÆó‰∏Ä‰∏™Â§çÊùÇÁöÑÂáΩÊï∞ÔºåÁÑ∂ÂêéÂà∞Á¨¨‰∏âÂ±ÇÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÁ¨¨‰∫åÂ±ÇËÆ≠ÁªÉÂá∫ÁöÑÁâπÂæÅÈ°π‰Ωú‰∏∫ËæìÂÖ•ÔºåÂπ∂Âú®Á¨¨‰∏âÂ±ÇËÆ°ÁÆó‰∏Ä‰∫õÊõ¥Â§çÊùÇÁöÑÂáΩÊï∞ÔºåËøôÊ†∑‰Ω†Âú®Á¨¨ÂõõÊ¨°ÔºåÂç≥ËæìÂá∫Â±ÇÊó∂ÔºåÂ∞±ÂèØ‰ª•Âà©Áî®Á¨¨‰∏âÂ±ÇËÆ≠ÁªÉÂá∫ÁöÑÊõ¥Â§çÊùÇÁöÑÁâπÂæÅÈ°π‰Ωú‰∏∫ËæìÂÖ•Ôºå‰ª•Ê≠§ÂæóÂà∞ÈùûÂ∏∏ÊúâË∂£ÁöÑÈùûÁ∫øÊÄßÂÅáËÆæ„ÄÇÈ°∫‰æøËØ¥‰∏ãÔºåÂú®Ëøô‰∏™ÁΩëÁªú‰∏≠ÔºåÁ¨¨‰∏ÄÂ±ÇË¢´Áß∞‰∏∫ËæìÂÖ•Â±ÇÔºåÁ¨¨ÂõõÂ±Ç‰ªçÁÑ∂ÊòØÊàë‰ª¨ÁöÑËæìÂá∫Â±ÇÔºåËøô‰∏™ÁΩëÁªúÊúâ‰∏§‰∏™ÈöêËóèÂ±ÇÔºåÊâÄ‰ª•ÈÉΩË¢´Áß∞‰∏∫ÈöêËóèÂ±Ç‰ªª‰Ωï‰∏Ä‰∏™‰∏çÊòØËæìÂÖ•Â±ÇÊàñËÄÖËæìÂá∫Â±ÇÁöÑ„ÄÇ Á§∫‰æãÂíåÁõ¥ËßâÔºàExamples and IntuitionsÔºâÊé•‰∏ãÊù•ËÆ≤Ëß£‰∏§‰∏™‰æãÂ≠êÊù•ËØ¥ÊòéÁ•ûÁªèÁΩëÁªúÊòØÂ¶Ç‰ΩïËÆ°ÁÆóÁöÑ„ÄÇ ÂÖ≥‰∫éËæìÂÖ•ÁöÑÂ§çÊùÇÁöÑÈùûÁ∫øÊÄßÂáΩÊï∞ÔºåÂ∏åÊúõËøô‰∏™‰æãÂ≠êÂèØ‰ª•ËÆ©‰Ω†‰∫ÜËß£ÔºåÁ•ûÁªèÁΩëÁªúÂèØ‰ª•Áî®Êù•Â≠¶‰π†Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂÅáËÆæ Êàë‰ª¨Êúâx1Ôºåx2Ë¶Å‰πàÂèñ0Ë¶Å‰πàÂèñ1ÔºåÊâÄ‰ª•x1Âíåx2Âè™ËÉΩÊúâ‰∏§ÁßçÂèñÂÄºÔºåÂú®Ëøô‰∏™‰æãÂ≠ê‰∏≠ÔºåÊàëÂè™ÁîªÂá∫‰∫ÜÔºå‰∏§‰∏™Ê≠£Ê†∑Êú¨Âíå‰∏§‰∏™Ë¥üÊ†∑Êú¨Ôºå‰Ω†ÂèØ‰ª•ËÆ§‰∏∫ËøôÊòØ‰∏Ä‰∏™Â§çÊùÇÊ†∑Êú¨ÁöÑÁÆÄÂçïÁâàÊú¨ÔºåÂíãËøô‰∏™Â§çÊùÇÈóÆÈ¢ò‰∏≠ÔºåÊàë‰ª¨ÂèØËÉΩÂú®Âè≥‰∏äËßíÊúâ‰∏ÄÂ†ÜÊ≠£Ê†∑Êú¨ÔºåÂíåÂ∑¶‰∏äËßí‰∏ÄÂ†ÜÁî®ÂúàÂúàË°®Á§∫ÁöÑË¥üÊ†∑Êú¨ÔºåÊàë‰ª¨ÊÉ≥Ë¶ÅÂ≠¶‰π†‰∏ÄÁßçÈùûÁ∫øÊÄßÁöÑÂÜ≥Á≠ñËæπÁïåÊù•Âå∫ÂàÜÊ≠£Ë¥üÊ†∑Êú¨„ÄÇ Êàë‰ª¨Áî®Â∑¶ËæπÁöÑ‰æãÂ≠êÊù•ËØ¥ÊòéÔºåÂÖ∑‰ΩìÊù•ËÆ≤Êàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÁöÑÊòØÁõÆÊ†áÂáΩÊï∞yÁ≠â‰∫éx1ÂºÇÊàñx2ÔºåÊàñËÄÖy‰πüÂèØ‰ª•Á≠â‰∫éx1ÂºÇÊàñÈùûx2ÔºåÂÖ∂‰∏≠ÂºÇÊàñÈùûË°®Á§∫x1ÂºÇÊàñx2ÂêéÂèñÂèçÔºåx1ÂºÇÊàñx2‰∏∫ÁúüÂΩì‰∏î‰ªÖÂΩìËøô‰∏§‰∏™ÂÄºÔºåx1ÊàñËÄÖx2‰∏≠Êúâ‰∏î‰ªÖÊúâ‰∏Ä‰∏™‰∏∫1ÔºåÂ¶ÇÊûúÊàëÁî®xNORÁöÑ‰æãÂ≠êÊØîÁî®NOT‰Ωú‰∏∫‰æãÂ≠êÁªìÊûú‰ºöÂ•Ω‰∏Ä‰∫õÔºå‰ΩÜËøô‰∏§‰∏™ÂÖ∂ÂÆûÊòØÁõ∏ÂêåÁöÑÔºåËøôÂ∞±ÊÑèÂë≥ÁùÄÂú®x1ÂºÇÊàñx2ÂêéÂÜçÂèñÂèçÔºåÂç≥‰ªñ‰ª¨ÂêåÊó∂‰∏∫ÁúüÊàñËÄÖÂêåÊó∂‰∏∫ÂÅáÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Â∞Ü‰ºöËé∑ÂæóyÁ≠â‰∫é1Ôºåy‰∏∫0ÁöÑÁªìÊûúÊòØÔºåÂ¶ÇÊûú‰ªñ‰ª¨‰∏≠‰ªÖÊúâ‰∏Ä‰∏™‰∏∫ÁúüÔºåÂàôy‰∏∫0„ÄÇ Êàë‰ª¨ËÉΩÂê¶ÊâæÂà∞‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊ®°ÂûãÊù•ÊãüÂêàËøôÁßçËÆ≠ÁªÉÈõÜÔºå‰∏∫‰∫ÜÂª∫Á´ãËÉΩÂ§üÊãüÂêàXNORËøêÁÆóÔºåÊàë‰ª¨ÂÖàÊãüÂêà‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ•ûÁªèÁΩëÁªúÔºåÂÆÉÊãüÂêà‰∫Ü‚Äú‰∏îËøêÁÆó‚Äù„ÄÇ ÂÅáËÆæÊàë‰ª¨ÊúâËæìÂÖ•x1Ôºåx2ÈÉΩÊòØ‰∫åËøõÂà∂ÔºåÂç≥Ë¶Å‰πàÊòØ0Ë¶Å‰πàÊòØ1ÔºåÊàë‰ª¨ÁöÑÁõÆÊ†áÂáΩÊï∞yÁ≠â‰∫éx1‰∏îx2Ôºå‰∏Ä‰∏™ÈÄªËæë‰∏éËøêÁÆóÔºåÈÇ£‰πàÊàë‰ª¨ÊÄéÊ†∑ÂæóÂà∞‰∏Ä‰∏™ÂÖ∑ÊúâÂçï‰∏™Á•ûÁªèÂÖÉÁöÑÁ•ûÁªèÁΩëÁªúÊù•ËÆ°ÁÆóËøô‰∏™ÈÄªËæë‰∏éÂë¢Ôºü Êàë‰ª¨ÁªôËøô‰∏™ÁΩëÁªúÂàÜÈÖç‰∏Ä‰∫õÊùÉÈáçÊàñÂèÇÊï∞Ôºå-30Ôºå+20Ôºå+20ÔºåÂç≥Êàë‰ª¨ÁªôxÁöÑÂâçÈù¢Á≥ªÊï∞ËµãÂÄºÔºåÊâÄ‰ª•Êàë‰ª¨ÁöÑh(x)=g(-30+20x1+20x2),Âè≥‰∏äËßíÁöÑÂõæÂ∞±ÊòØÊàë‰ª¨ÁöÑsÂûãÂáΩÊï∞ÔºåÁÑ∂ÂêéÊàë‰ª¨ÁúãÂõõÁßçËæìÂÖ•ÁöÑÂèØËÉΩÊÄßÔºåÂ∞±ÊòØ‰∏éËøêÁÆóÁöÑÁªìÊûú„ÄÇ ÂêåÊ†∑Êàë‰ª¨Áî®Á•ûÁªèÁΩëÁªúÂÆûÁé∞ÊàñËøêÁÆóÁÑ∂ÂêéËÆ≤Ëß£Êõ¥‰∏∫ËµãÂÄºÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇ Êàë‰ª¨Âè™Ë¶ÅÂú®x1ÂâçÈù¢ÊîæÂÖ•‰∏Ä‰∏™ÂæàÂ§ßÁöÑË¥üÊï∞ÔºåÂ∞±ÂèØ‰ª•ÂÆûÁé∞ÈùûÁöÑÂäüËÉΩ„ÄÇ Êàë‰ª¨Áé∞Âú®ÊääËøô‰∏â‰∏™ÂäüËÉΩÊîæÂú®‰∏ÄËµ∑ÔºåÂ∞±ÂèØ‰ª•ÂÆûÁé∞x1 XNOR x2ÁöÑÂäüËÉΩ„ÄÇ ÂΩìÂ±ÇÊï∞ÂæàÂ§öÁöÑÊó∂ÂÄôÔºå‰Ω†Êúâ‰∏Ä‰∏™Áõ∏ÂØπÁÆÄÂçïÁöÑËæìÂÖ•ÈáèÁöÑÂáΩÊï∞‰Ωú‰∏∫Á¨¨‰∫åÂ±ÇÔºåËÄåÁ¨¨‰∏âÂ±ÇÂèØ‰ª•Âª∫Á´ãÂú®Ê≠§Âü∫Á°Ä‰∏äÂª∫Á´ã‰∏Ä‰∫õÊõ¥Âä†Â§çÊùÇÁöÑÂáΩÊï∞ÔºåÁÑ∂ÂêéÂú®‰∏ã‰∏ÄÂ±ÇÂèàÂú®ËÆ°ÁÆó‰∏Ä‰∏™Á®çÂæÆÂ§çÊùÇÁöÑÂáΩÊï∞ÔºåÊàë‰ª¨ÂèØ‰ª•ËøêÁî®Êõ¥Ê∑±Â±ÇÁöÑÂáΩÊï∞ËÆ°ÁÆóÊõ¥Âä†Â§çÊùÇÁöÑÂáΩÊï∞„ÄÇ Á•ûÁªèÁΩëÁªúËøòÂèØ‰ª•Áî®‰∫éËØÜÂà´ÊâãÂÜôÊï∞Â≠ó„ÄÇ ÂÆÉ‰ΩøÁî®ÁöÑËæìÂÖ•ÊòØ‰∏çÂêåÁöÑÂõæÂÉèÊàñËÄÖËØ¥Â∞±ÊòØ‰∏Ä‰∫õÂéüÂßãÁöÑÂÉèÁ¥†ÁÇπ„ÄÇÁ¨¨‰∏ÄÂ±ÇËÆ°ÁÆóÂá∫‰∏Ä‰∫õÁâπÂæÅÔºåÁÑ∂Âêé‰∏ã‰∏ÄÂ±ÇÂÜçËÆ°ÁÆóÂá∫‰∏Ä‰∫õÁ®çÂ§çÊùÇÁöÑÁâπÂæÅÔºåÁÑ∂ÂêéÊòØÊõ¥Â§çÊùÇÁöÑÁâπÂæÅÔºåÁÑ∂ÂêéËøô‰∫õÁâπÂæÅÂÆûÈôÖ‰∏äË¢´ÊúÄÁªà‰º†ÈÄíÁªôÊúÄÂêé‰∏ÄÂ±ÇÈÄªËæëÂõûÂΩíÂàÜÁ±ªÂô®‰∏äÔºå‰ΩøÂÖ∂ÂáÜÁ°ÆÂú∞È¢ÑÊµãÂá∫Á•ûÁªèÁΩëÁªú‚ÄúÁúã‚ÄùÂà∞ÁöÑÊï∞Â≠ó„ÄÇ Â§öÁ±ªÂàÜÁ±ªÔºàMulticlass ClassificationÔºâÂú®Â§öÂàÜÁ±ªÈóÆÈ¢ò‰∏≠Êàë‰ª¨Â¶Ç‰ΩïÂ§ÑÁêÜÔºü ÂíåÂ§ÑÁêÜÈÄªËæëÂõûÂΩíÁöÑÂ§öÂàÜÁ±ªÈóÆÈ¢ò‰∏ÄÊ†∑„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>Á•ûÁªèÁΩëÁªú</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÔºàÂÖ≠Ôºâ]]></title>
    <url>%2F2018%2F05%2F10%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ËøôÈáåËÆ∞ÂΩï‰∫ÜËßÜÈ¢ëÁ¨¨‰∏ÉËäÇÁöÑÂÜÖÂÆπÔºå‰∏ªË¶ÅÂÖ≥‰∫éÊ≠£ÂàôÂåñÁöÑÈóÆÈ¢ò Ê¨†ÊãüÂêà(under fitting)ÂíåËøáÊãüÂêà(over fitting)Áé∞Âú®Â∑≤ÁªèÂ≠¶‰π†‰∫Ü‰∏Ä‰∫õ‰∏çÂêåÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÂåÖÊã¨Á∫øÊÄßÂõûÂΩíÂíåÈÄªËæëÂõûÂΩíÔºåÂÆÉ‰ª¨ËÉΩÂ§üÊúâÊïàÁöÑËß£ÂÜ≥ËÆ∏Â§öÈóÆÈ¢òÔºå‰ΩÜÊòØÂ∞ÜÂÆÉ‰ª¨Â∫îÁî®Âà∞Êüê‰∫õÁâπÂÆöÁöÑÊú∫Âô®Â≠¶‰π†‰∏≠Êó∂ÔºåÂ∞±‰ºöÂá∫Áé∞Ê¨†ÊãüÂêàÊàñËÄÖËøáÊãüÂêàÁöÑÈóÆÈ¢òÔºåÂØºËá¥ÊïàÊûúÂæàÂ∑ÆÔºåÈÄöËøáÊ≠£ÂàôÂåñÁöÑÊñπÊ≥ïÂèØ‰ª•ÊîπÂñÑÁÆóÊ≥ïÔºå‰∏ãÈù¢‰ªãÁªç‰ªÄ‰πàÊòØËøáÊãüÂêà‰∏éÊ¨†ÊãüÂêà„ÄÇÁªßÁª≠Áî®Á∫øÊÄßÂõûÂΩíÈ¢ÑÊµãÊàø‰ª∑ÁöÑ‰æãÂ≠êÔºö È¶ñÂÖàÁúãÁ¨¨‰∏ÄÂπÖÂõæÔºå‰ΩøÁî®‰∏ÄÊù°Áõ¥Á∫øÂáΩÊï∞Êù•ÊãüÂêàÊï∞ÊçÆÔºåÂæàÊòæÁÑ∂ÈöèÁùÄÊàøÂ≠êÈù¢ÁßØÁöÑÂ¢ûÂ§ßÔºåÊàøÂ±ã‰ª∑Ê†ºÁöÑÂèòÂåñË∂äÁ®≥ÂÆöÊàñËÄÖËØ¥ÊòØË∂äÂÉèÂè≥Ë∂äË∂ã‰∫éÂπ≥ÊªëÔºåÂõ†Ê≠§Á∫øÊÄßÂõûÂΩíÂπ∂Ê≤°ÊúâÂæàÂ•ΩÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ==Êàë‰ª¨ÊääÊ≠§Á±ªÊÉÖÂÜµÁß∞‰∏∫Ê¨†ÊãüÂêà(underfitting)ÔºåÊàñËÄÖÂè´‰ΩúÂè´ÂÅöÈ´òÂÅèÂ∑Æ(bias)„ÄÇ== Ëøô‰∏§ÁßçËØ¥Ê≥ïÂ§ßËá¥Áõ∏‰ººÔºåÈÉΩË°®Á§∫Ê≤°ÊúâÂæàÂ•ΩÂú∞ÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇÈ´òÂÅèÂ∑ÆËøô‰∏™ËØçÊòØ machine learning ÁöÑÁ†îÁ©∂ÂàùÊúü‰º†‰∏ãÊù•ÁöÑ‰∏Ä‰∏™‰∏ì‰∏öÂêçËØçÔºåÂÖ∑‰ΩìÂà∞Ëøô‰∏™ÈóÆÈ¢òÔºåÊÑèÊÄùÂ∞±ÊòØËØ¥Â¶ÇÊûúÁî®Á∫øÊÄßÂõûÂΩíËøô‰∏™ÁÆóÊ≥ïÂéªÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆÔºåÈÇ£‰πàËØ•ÁÆóÊ≥ïÂÆûÈôÖ‰∏ä‰ºö‰∫ßÁîü‰∏Ä‰∏™ÈùûÂ∏∏Â§ßÁöÑÂÅèÂ∑ÆÊàñËÄÖËØ¥Â≠òÂú®‰∏Ä‰∏™ÂæàÂº∫ÁöÑÂÅèËßÅ„ÄÇ Âú®Á¨¨‰∫åÂπÖÂõæÊàë‰ª¨Áî®‰∫Ü‰∏Ä‰∏™‰∫åÊ¨°ÂáΩÊï∞ÂéªÊãüÂêàÊï∞ÊçÆÔºåÂèØ‰ª•ÊãüÂêàÂá∫‰∏ÄÊù°ÂêàÁêÜÁöÑÊõ≤Á∫øÔºå‰∫ãÂÆûËØÅÊòéËøôÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÊãüÂêàÊïàÊûú„ÄÇ Á¨¨‰∏âÂπÖÂõæÔºåÂú®ËøôÈáåÊàë‰ª¨Êúâ‰∫î‰∏™ËÆ≠ÁªÉÊï∞ÊçÆÔºåÊâÄ‰ª•‰ΩøÁî®‰∫Ü‰∫î‰∏™ÂèÇÊï∞Œ∏0Âà∞Œ∏4ÁöÑ‰∏Ä‰∏™ÂõõÊ¨°Â§öÈ°πÂºèÂéªÊãüÂêàÊï∞ÊçÆÔºåÂÆÉ‰ºº‰πéÊòØ‰∏Ä‰∏™ÂæàÂ•ΩÁöÑÊãüÂêàÔºåÂõ†‰∏∫ÂÆÉÊàêÂäüÁöÑÈÄöËøá‰∫ÜÊàë‰ª¨ÁöÑÊâÄÊúâËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ΩÜÊòØÂÆÉÈùûÂ∏∏ÁöÑÊâ≠Êõ≤ÔºåÂú®‰∏ä‰∏ãÊ≥¢Âä®ÔºåÊâÄ‰ª•‰∫ãÂÆû‰∏äÊàë‰ª¨Âπ∂‰∏çËÆ§‰∏∫ÂÆÉÊòØ‰∏Ä‰∏™È¢ÑÊµãÊàø‰ª∑ÁöÑÂ•ΩÊ®°Âûã„ÄÇ ==Êàë‰ª¨ÊääËøôÁ±ªÊÉÖÂÜµÂè´ÂÅöËøáÊãüÂêà(overfitting)Ôºå‰πüÂè´È´òÊñπÂ∑Æ(variance)„ÄÇ== ‰∏éÈ´òÂÅèÂ∑Æ‰∏ÄÊ†∑ÔºåÈ´òÊñπÂ∑ÆÂêåÊ†∑‰πüÊòØ‰∏Ä‰∏™ÂéÜÂè≤‰∏äÁöÑÂè´Ê≥ï„ÄÇ‰ªéÁ¨¨‰∏ÄÂç∞Ë±°‰∏äÊù•ËØ¥ÔºåÂ¶ÇÊûúÊàë‰ª¨ÊãüÂêà‰∏Ä‰∏™È´òÈò∂Â§öÈ°πÂºèÔºåÈÇ£‰πàËøô‰∏™ÂáΩÊï∞ËÉΩÂæàÂ•ΩÁöÑÊãüÂêàËÆ≠ÁªÉÈõÜÔºàËÉΩÊãüÂêàÂá†‰πéÊâÄÊúâÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºâÔºå‰ΩÜËøô‰πüÂ∞±Èù¢‰∏¥ÂáΩÊï∞ÂèØËÉΩÂ§™ËøáÂ∫ûÂ§ßÁöÑÈóÆÈ¢òÔºåÂèòÈáèÂ§™Â§ö„ÄÇ==ÂêåÊó∂Â¶ÇÊûúÊàë‰ª¨Ê≤°ÊúâË∂≥Â§üÁöÑÊï∞ÊçÆÈõÜÔºàËÆ≠ÁªÉÈõÜÔºâÂéªÁ∫¶ÊùüËøô‰∏™ÂèòÈáèËøáÂ§öÁöÑÊ®°ÂûãÔºåÈÇ£‰πàÂ∞±‰ºöÂèëÁîüËøáÊãüÂêà„ÄÇ==12‰∏∫‰ªÄ‰πàË∂≥Â§üÂ§öÁöÑÂ§öÈ°πÂºèÂèØ‰ª•ÂÆåÁæéÁöÑÊãüÂêàÊï∞ÊçÆÔºüÊ≥∞ÂãíÂÖ¨ÂºèÂ±ïÂºÄÂºè„ÄÇ Ê¶ÇÊã¨ÁöÑËØ¥ÔºåËøáÊãüÂêàÂ∞Ü‰ºöÂèëÁîüÂú®ÂèòÈáèÔºàÁâπÂæÅÔºâËøáÂ§öÁöÑÊó∂ÂÄôÔºåËøôÊó∂ÂÄôËÆ≠ÁªÉÂá∫ÁöÑÊñπÁ®ãÊÄªËÉΩÂ§üÂæàÂ•ΩÁöÑÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆÔºåÊàë‰ª¨ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Êó†ÈôêË∂ã‰∫é0ÊàñËÄÖÂ∞±ÊòØ0Ôºå‰ΩÜÊòØËøôÊ†∑ÂçÉÊñπÁôæËÆ°ÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊõ≤Á∫øÊó†Ê≥ïÊ≥õÂåñÂà∞Êñ∞ÁöÑÊ†∑Êú¨Êï∞ÊçÆ‰∏≠Ôºå‰ª•Ëá≥‰∫éÊó†Ê≥ïÈ¢ÑÊµãÊñ∞ÁöÑÊ†∑Êú¨‰ª∑Ê†º„ÄÇÊúØËØ≠Ê≥õÂåñÊåáÁöÑÊòØ‰∏Ä‰∏™ÂÅáËÆæÊ®°ÂûãËÉΩÂ§üÂ∫îÁî®Âà∞Êñ∞Ê†∑Êú¨ÁöÑËÉΩÂäõÔºåÊñ∞Ê†∑Êú¨ÊåáÁöÑÊòØ‰∏çÂú®ËÆ≠ÁªÉÈõÜ‰∏≠ÁöÑÊ†∑Êú¨Êï∞ÊçÆ„ÄÇ ËøáÊãüÂêàÂíåÊ¨†ÊãüÂêàÁöÑÊÉÖÂÜµ‰∏ç‰ªÖÂá∫Áé∞Âú®Á∫øÊÄßÂõûÂΩí‰πü‰ºöÂá∫Áé∞Âú®ÈÄªËæëÂõûÂΩíÁöÑÈóÆÈ¢òËøáÂ§öÁöÑÂèòÈáèÔºàÁâπÂæÅÔºâÔºåÂêåÊó∂Âè™ÊúâÈùûÂ∏∏Â∞ëÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ºöÂØºËá¥Âá∫Áé∞ËøáÂ∫¶ÊãüÂêàÁöÑÈóÆÈ¢ò Â¶Ç‰ΩïÈÅøÂÖçËøáÊãüÂêàÂë¢ÔºüÊúâ‰ª•‰∏ã‰∏§‰∏™ÊñπÂºèÊù•ÈÅøÂÖçËøáÊãüÂêà ÂáèÂ∞ëÈÄâÂèñÂèòÈáèÁöÑÊï∞ÈáèÔºå‰øùÁïôÊõ¥Âä†ÈáçË¶ÅÁöÑÁâπÂæÅ ÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÂèØ‰ª•‰∫∫Â∑•Ê£ÄÊü•ÊØè‰∏ÄÈ°πÂèòÈáèÔºåÂπ∂‰ª•Ê≠§Êù•Á°ÆÂÆöÂì™‰∫õÂèòÈáèÊõ¥‰∏∫ÈáçË¶ÅÔºåÁÑ∂ÂêéÔºå‰øùÁïôÈÇ£‰∫õÊõ¥‰∏∫ÈáçË¶ÅÁöÑÁâπÂæÅÂèòÈáè„ÄÇËá≥‰∫éÔºåÂì™‰∫õÂèòÈáèÂ∫îËØ•ËàçÂºÉÔºåÊàë‰ª¨‰ª•ÂêéÂú®ËÆ®ËÆ∫ÔºåËøô‰ºöÊ∂âÂèäÂà∞Ê®°ÂûãÈÄâÊã©ÁÆóÊ≥ïÔºåËøôÁßçÁÆóÊ≥ïÊòØÂèØ‰ª•Ëá™Âä®ÈÄâÊã©ÈááÁî®Âì™‰∫õÁâπÂæÅÂèòÈáèÔºåËá™Âä®ËàçÂºÉ‰∏çÈúÄË¶ÅÁöÑÂèòÈáè„ÄÇËøôÁ±ªÂÅöÊ≥ïÈùûÂ∏∏ÊúâÊïàÔºå‰ΩÜÊòØÂÖ∂Áº∫ÁÇπÊòØÂΩì‰Ω†ËàçÂºÉ‰∏ÄÈÉ®ÂàÜÁâπÂæÅÂèòÈáèÊó∂Ôºå‰Ω†‰πüËàçÂºÉ‰∫ÜÈóÆÈ¢ò‰∏≠ÁöÑ‰∏Ä‰∫õ‰ø°ÊÅØ„ÄÇ‰æãÂ¶ÇÔºå‰πüËÆ∏ÊâÄÊúâÁöÑÁâπÂæÅÂèòÈáèÂØπ‰∫éÈ¢ÑÊµãÊàø‰ª∑ÈÉΩÊòØÊúâÁî®ÁöÑÔºåÊàë‰ª¨ÂÆûÈôÖ‰∏äÂπ∂‰∏çÊÉ≥ËàçÂºÉ‰∏Ä‰∫õ‰ø°ÊÅØÊàñËÄÖËØ¥ËàçÂºÉËøô‰∫õÁâπÂæÅÂèòÈáè„ÄÇ Ê≠£ÂàôÂåñ Ê≠£ÂàôÂåñ‰∏≠Êàë‰ª¨Â∞Ü‰øùÁïôÊâÄÊúâÁöÑÁâπÂæÅÂèòÈáèÔºå‰ΩÜÊòØ‰ºöÂáèÂ∞èÁâπÂæÅÂèòÈáèÁöÑÊï∞ÈáèÁ∫ßÔºàÂèÇÊï∞Êï∞ÂÄºÁöÑÂ§ßÂ∞èŒ∏(j)Ôºâ„ÄÇ Ëøô‰∏™ÊñπÊ≥ïÈùûÂ∏∏ÊúâÊïàÔºåÂΩìÊàë‰ª¨ÊúâÂæàÂ§öÁâπÂæÅÂèòÈáèÊó∂ÔºåÂÖ∂‰∏≠ÊØè‰∏Ä‰∏™ÂèòÈáèÈÉΩËÉΩÂØπÈ¢ÑÊµã‰∫ßÁîü‰∏ÄÁÇπÂΩ±Âìç„ÄÇÊ≠£Â¶ÇÊàë‰ª¨Âú®Êàø‰ª∑È¢ÑÊµãÁöÑ‰æãÂ≠ê‰∏≠ÁúãÂà∞ÁöÑÈÇ£Ê†∑ÔºåÊàë‰ª¨ÂèØ‰ª•ÊúâÂæàÂ§öÁâπÂæÅÂèòÈáèÔºåÂÖ∂‰∏≠ÊØè‰∏Ä‰∏™ÂèòÈáèÈÉΩÊòØÊúâÁî®ÁöÑÔºåÂõ†Ê≠§Êàë‰ª¨‰∏çÂ∏åÊúõÊääÂÆÉ‰ª¨Âà†ÊéâÔºåËøôÂ∞±ÂØºËá¥‰∫ÜÊ≠£ÂàôÂåñÊ¶ÇÂøµÁöÑÂèëÁîü„ÄÇ Êé•‰∏ãÊù•Êàë‰ª¨‰ºöËÆ®ËÆ∫ÊÄéÊ†∑Â∫îÁî®Ê≠£ÂàôÂåñÂíå‰ªÄ‰πàÂè´ÂÅöÊ≠£ÂàôÂåñÂùáÂÄºÔºåÁÑ∂ÂêéÂ∞ÜÂºÄÂßãËÆ®ËÆ∫ÊÄéÊ†∑‰ΩøÁî®Ê≠£ÂàôÂåñÊù•‰ΩøÂ≠¶‰π†ÁÆóÊ≥ïÊ≠£Â∏∏Â∑•‰ΩúÔºåÂπ∂ÈÅøÂÖçËøáÊãüÂêà„ÄÇ Êú∫Âô®Â≠¶‰π†ÁöÑÊ≠£ÂàôÂåñÂú®ÂâçÈù¢‰ªãÁªç‰∫ÜÁî®‰∫åÊ¨°ÂáΩÊï∞ÂéªÊãüÂêàËøô‰∫õÊï∞ÊçÆÔºå‰ªñÁöÑÊãüÂêàÊïàÊûúÊòØÂæàÂ•ΩÁöÑÔºåÁÑ∂ËÄåÊàë‰ª¨Áî®Êõ¥È´òÊ¨°ÁöÑÂ§öÈ°πÂºèÂéªÊãüÂêàÔºåÊúÄÁªàÂà∞ÁöÑ‰∏Ä‰∏™Êõ≤Á∫øÔºåÂ∞ΩÁÆ°‰ªñÂæàÂ•ΩÁöÑÊãüÂêà‰∫ÜËÆ≠ÁªÉÈõÜÔºå‰ΩÜÂπ∂‰∏çÊòØ‰∏Ä‰∏™Â•ΩÁöÑÁªìÊûúÔºåÂõ†‰∏∫‰ªñËøáÂ∫¶ÊãüÂêà‰∫ÜÊï∞ÊçÆÔºåÊâÄ‰ª•‰∏ÄËà¨ÊÄß‰∏çÂ•Ω„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ËÄÉËôë‰∏ãÈù¢ÁöÑÂÅáËÆæÔºåÊàë‰ª¨ÊÉ≥Ë¶ÅÂä†‰∏äÊÉ©ÁΩöÈ°π‰ªéËÄå‰ΩøÂèÇÊï∞ Œ∏3 Âíå Œ∏4 Ë∂≥Â§üÂ∞èÔºå‰∏äÈù¢ÂáΩÊï∞ÊòØÊàë‰ª¨ÁöÑ‰ºòÂåñÁõÆÊ†áÔºå‰πüÂ∞±ÊòØËØ¥Êàë‰ª¨Ë¶ÅÂ∞ΩÈáèÂáèÂ∞ë‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂùáÊñπÂ∑ÆÔºåÂØπ‰∫éËøô‰∏™ÂáΩÊï∞Êàë‰ª¨ÂØπÂÆÉÊ∑ªÂä†‰∏Ä‰∫õÈ°πÔºåÂä†‰∏ä 1000 ‰πò‰ª• Œ∏3 ÁöÑÂπ≥ÊñπÔºåÂÜçÂä†‰∏ä 1000 ‰πò‰ª• Œ∏4 ÁöÑÂπ≥ÊñπÔºå‰∫éÊòØÂá∫Áé∞‰∫Ü‰∏ãÈù¢ÁöÑÂºèÂ≠êÔºö 1000 Âè™ÊòØÊàëÈöè‰æøÂÜôÁöÑÊüê‰∏™ËæÉÂ§ßÁöÑÊï∞Â≠óËÄåÂ∑≤„ÄÇÁé∞Âú®ÔºåÂ¶ÇÊûúÊàë‰ª¨Ë¶ÅÊúÄÂ∞èÂåñËøô‰∏™ÂáΩÊï∞ÔºåÈÇ£‰πà‰∏∫‰∫ÜÊúÄÂ∞èÂåñËøô‰∏™Êñ∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåÊàë‰ª¨Ë¶ÅËÆ© Œ∏3 Âíå Œ∏4 Â∞ΩÂèØËÉΩÂ∞è„ÄÇÂõ†‰∏∫ÔºåÂ¶ÇÊûú‰Ω†Âú®ÂéüÊúâ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂü∫Á°Ä‰∏äÂä†‰∏ä 1000 ‰πò‰ª• Œ∏3 Ëøô‰∏ÄÈ°π ÔºåÈÇ£‰πàËøô‰∏™Êñ∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Â∞ÜÂèòÂæóÂæàÂ§ßÔºåÊâÄ‰ª•ÔºåÂΩìÊàë‰ª¨ÊúÄÂ∞èÂåñËøô‰∏™Êñ∞ÁöÑ‰ª£‰ª∑ÂáΩÊï∞Êó∂Ôºå Êàë‰ª¨Â∞Ü‰Ωø Œ∏3 ÁöÑÂÄºÊé•Ëøë‰∫é 0ÔºåÂêåÊ†∑ Œ∏4 ÁöÑÂÄº‰πüÊé•Ëøë‰∫é 0ÔºåÂ∞±ÂÉèÊàë‰ª¨ÂøΩÁï•‰∫ÜËøô‰∏§‰∏™ÂÄº‰∏ÄÊ†∑„ÄÇÂ¶ÇÊûúÊàë‰ª¨ÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºà Œ∏3 Âíå Œ∏4 Êé•Ëøë 0 ÔºâÔºåÈÇ£‰πàÊàë‰ª¨Â∞ÜÂæóÂà∞‰∏Ä‰∏™Ëøë‰ººÁöÑ‰∫åÊ¨°ÂáΩÊï∞„ÄÇ Âõ†Ê≠§ÔºåÊàë‰ª¨ÊúÄÁªàÊÅ∞ÂΩìÂú∞ÊãüÂêà‰∫ÜÊï∞ÊçÆÔºåÊàë‰ª¨ÊâÄ‰ΩøÁî®ÁöÑÊ≠£ÊòØ‰∫åÊ¨°ÂáΩÊï∞Âä†‰∏ä‰∏Ä‰∫õÈùûÂ∏∏Â∞èÔºåË¥°ÁåÆÂæàÂ∞èÈ°πÔºàÂõ†‰∏∫Ëøô‰∫õÈ°πÁöÑ Œ∏3„ÄÅ Œ∏4 ÈùûÂ∏∏Êé•Ëøë‰∫é0Ôºâ„ÄÇÊòæÁÑ∂ÔºåËøôÊòØ‰∏Ä‰∏™Êõ¥Â•ΩÁöÑÂÅáËÆæ„ÄÇ Ê≠£ÂàôÂåñËÉåÂêéÁöÑÊÄùË∑ØÔºåÂ¶ÇÊûúÊàë‰ª¨ÁöÑÂèÇÊï∞ÂÄºÂØπÂ∫î‰∏Ä‰∏™ËæÉÂ∞èÁöÑÂÄºÁöÑÔºàÂèÇÊï∞ÂÄºËæÉÂ∞èÔºâÔºåÈÇ£‰πàÊàë‰ª¨‰ºöÈÅìÈÅì‰∏Ä‰∏™ÂΩ¢ÂºèÊõ¥ÁÆÄÂçïÁöÑÂÅáËÆæ„ÄÇ Âú®‰∏äÈù¢ÁöÑ‰æãÂ≠ê‰∏≠ÔºåÊàë‰ª¨ÁöÑÊÉ©ÁΩöÁöÑÂè™ÊòØŒ∏3ÂíåŒ∏4Ôºå‰ΩøËøô‰∏§‰∏™ÂÄºÂùáÊé•Ëøë‰∫éÈõ∂Ôºå‰ªéËÄåÂæóÂà∞‰∫Ü‰∏Ä‰∏™Êõ¥ÁÆÄÂçïÁöÑÂÅáËÆæÔºåÂÆûÈôÖ‰∏äËøô‰∏™ÂÅáËÆæÁ±ª‰ºº‰∏Ä‰∏™‰∫åÊ¨°ÂáΩÊï∞„ÄÇ Êõ¥ÁÆÄÂçïÁöÑËÆ≤ÔºåÂ¶ÇÊûúÊàë‰ª¨ÂÉèÊÉ©ÁΩöŒ∏3ÂíåŒ∏4ËøôÊ†∑ÊÉ©ÁΩöÂÖ∂‰ªñÂèÇÊï∞ÔºåÈÇ£‰πàÊàë‰ª¨ÂæÄÂæÄÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™Áõ∏ÂØπÁÆÄÂçïÁöÑÂÅáËÆæÂáΩÊï∞„ÄÇ ==ÂÆûÈôÖ‰∏äÔºåËøô‰∫õÂèÇÊï∞ÁöÑÂÄºË∂äÂ∞èÔºåÂØπÂ∫îÁöÑÂáΩÊï∞Êõ≤Á∫øË∂äÂπ≥ÊªëÔºå‰πüÂ∞±ÊòØÊõ¥Âä†ÁÆÄÂçïÁöÑÂáΩÊï∞ÔºåÂõ†Ê≠§ÔºåÂ∞±‰∏çÊòìÂèëÁîüËøáÊãüÂêàÁöÑÈóÆÈ¢ò„ÄÇ== ‰∏∫‰ªÄ‰πàË∂äÂ∞èÁöÑÂèÇÊï∞ÂØπÂ∫î‰∏Ä‰∏™Áõ∏ÂØπÁÆÄÂçïÁöÑÂÅáËÆæÂáΩÊï∞ÔºåÂÖ∑‰ΩìÁúã‰∏ãÈù¢Ëøô‰∏™‰æãÂ≠ê„ÄÇ ÂØπ‰∫éÊàøÂ±ã‰ª∑Ê†ºÁöÑÈ¢ÑÊµãÊàë‰ª¨ÂèØËÉΩÂèà‰∏äÁôæ‰∏™ÁâπÂæÅÔºå‰∏éÂàöÂàöÊâÄËØ¥ÁöÑÂ§öÈ°πÂºè‰æãÂ≠ê‰∏çÂêåÔºåÊàë‰ª¨Âπ∂‰∏çÁü•ÈÅìŒ∏3ÂíåŒ∏4ÊòØÈ´òÈò∂Â§öÈ°πÂºèÁöÑÈ°πÔºåÊâÄ‰ª•ÔºåÊàë‰ª¨Êúâ‰∏ÄÁôæ‰∏™ÁâπÂæÅÔºå‰ΩÜÊòØÊàë‰ª¨ÈÇ£Âπ∂‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÈÄâÊã©ÂÖ≥ËÅîÂ∫¶Êõ¥Â•ΩÁöÑÂèÇÊï∞ÔºåÂ¶Ç‰ΩïÁº©Â∞èÂèÇÊï∞ÁöÑÊï∞ÁõÆÁ≠âÁ≠â„ÄÇ Âõ†Ê≠§Âú®Ê≠£ÂàôÂåñÈáåÔºåÊàë‰ª¨Ë¶ÅÂÅöÁöÑ‰∫ãÊÉÖÔºåÂ∞±ÊòØÂáèÂ∞èÊàë‰ª¨ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÊâÄÊúâÁöÑÂèÇÊï∞ÂÄºÔºåÂõ†‰∏∫Êàë‰ª¨Âπ∂‰∏çÁü•ÈÅìÂì™‰∏Ä‰∏™ÊàñÂá†‰∏™Ë¶ÅÂéªÁº©Â∞èÔºåÊâÄ‰ª•Êàë‰ª¨Ë¶Å‰øÆÊîπ‰ª£‰ª∑ÂáΩÊï∞ÔºåÂú®ÂêéÈù¢Ê∑ªÂä†‰∏ÄÈ°πÔºåÂ∞±ÂÉèÊàë‰ª¨Âú®ÊñπÊã¨Âè∑ÈáåÁöÑËøôÈ°πÔºåÂΩìÊàë‰ª¨Ê∑ªÂä†‰∏Ä‰∏™È¢ùÂ§ñÁöÑÊ≠£ÂàôÂåñÈ°πÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨Áº©Â∞è‰∫ÜÊØè‰∏Ä‰∏™ÂèÇÊï∞„ÄÇ È°∫‰æøËØ¥‰∏Ä‰∏ãÔºåÊåâÁÖßÊÉØ‰æãÔºåÊàë‰ª¨Ê≤°ÊúâÂéªÊÉ©ÁΩö Œ∏0ÔºåÂõ†Ê≠§ Œ∏0ÁöÑÂÄºÊòØÂ§ßÁöÑ„ÄÇËøôÂ∞±ÊòØ‰∏Ä‰∏™Á∫¶ÂÆö‰ªé 1 Âà∞ n ÁöÑÊ±ÇÂíåÔºåËÄå‰∏çÊòØ‰ªé 0 Âà∞ n ÁöÑÊ±ÇÂíå„ÄÇ‰ΩÜÂÖ∂ÂÆûÂú®ÂÆûË∑µ‰∏≠ËøôÂè™‰ºöÊúâÈùûÂ∏∏Â∞èÁöÑÂ∑ÆÂºÇÔºåÊó†ËÆ∫‰Ω†ÊòØÂê¶ÂåÖÊã¨ËøôŒ∏0ËøôÈ°π„ÄÇ‰ΩÜÊòØÊåâÁÖßÊÉØ‰æãÔºåÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÊàë‰ª¨ËøòÊòØÂè™‰ªé Œ∏1 Âà∞ Œ∏n ËøõË°åÊ≠£ÂàôÂåñ„ÄÇ Â∏¶ŒªÁöÑÁöÑËøôÈ°πÂ∞±ÊòØ‰∏Ä‰∏™Ê≠£ÂàôÂåñÈ°πÔºåÂπ∂‰∏îŒªÂú®ËøôÈáåÊàë‰ª¨Áß∞ÂÅöÊ≠£ÂàôÂåñÂèÇÊï∞„ÄÇ ==Œª Ë¶ÅÂÅöÁöÑÂ∞±ÊòØÊéßÂà∂Âú®‰∏§‰∏™‰∏çÂêåÁöÑÁõÆÊ†á‰∏≠ÁöÑÂπ≥Ë°°ÂÖ≥Á≥ª„ÄÇ== Á¨¨‰∏Ä‰∏™ÁõÆÊ†áÂ∞±ÊòØÊàë‰ª¨ÊÉ≥Ë¶Å‰ΩøÂÅáËÆæÂáΩÊï∞Êõ¥Â•ΩÁöÑÊãüÂêàËÆ≠ÁªÉÊï∞ÊçÆ Á¨¨‰∫å‰∏™ÁõÆÊ†áÊòØË¶Å‰øùÊåÅÊàë‰ª¨ÁöÑÂèÇÊï∞ËæÉÂ∞èÈÄöËøáÊ≠£ÂàôÂåñ ËÄåŒªËøô‰∏™Ê≠£ÂàôÂåñÂèÇÊï∞ÈúÄË¶ÅÊéßÂà∂ÁöÑÊòØ‰∏§ËÄÖ‰πãÈó¥ÁöÑÂπ≥Ë°°ÔºåÊó¢Âπ≥Ë°°ÊãüÂêàËÆ≠ÁªÉÁöÑÁõÆÊ†áÂíå‰øùÊåÅÂèÇÊï∞ÂÄºËæÉÂ∞èÁöÑÁõÆÊ†á„ÄÇ‰ªéËÄå‰øùÊåÅÂÅáËÆæÁöÑÂΩ¢ÂºèÁõ∏ÂØπÁÆÄÂçïÔºåÊù•ÈÅøÂÖçËøáÊãüÂêà„ÄÇ ÂØπ‰∫éÊàøÂ±ã‰ª∑Ê†ºÈ¢ÑÊµãÊù•ËØ¥ÔºåÊàë‰ª¨‰πãÂâçÊâÄÁî®ÁöÑÈùûÂ∏∏Â§öÁöÑÈ´òÈò∂Â§öÈ°πÂºèÊù•ÊãüÂêàÔºåÊàë‰ª¨Â∞Ü‰ºöÂæóÂà∞‰∏Ä‰∏™ÈùûÂ∏∏ÂºØÊõ≤ÂíåÂ§çÊùÇÁöÑÊõ≤Á∫øÂáΩÊï∞ÔºåÁé∞Âú®Âè™ÈúÄË¶ÅÈÄöËøáÊ≠£ÂàôÂåñÁöÑ‰ºòÂåñÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™Êõ¥Âä†ÂêàÈÄÇÁöÑÊõ≤Á∫øÔºåËøô‰∏™Êõ≤Á∫ø‰∏çÊòØ‰∏Ä‰∏™ÁúüÊ≠£ÁöÑ‰∫åÊ¨°ÂáΩÊï∞Êõ≤Á∫øÔºåËÄåÊòØÊõ¥Âä†ÁöÑÊµÅÁïÖÂíåÁÆÄÂçïÁöÑ‰∏Ä‰∏™Êõ≤Á∫ø„ÄÇËøôÊ†∑Â∞±ÂæóÂà∞‰∫ÜÂØπ‰∫éËøô‰∏™Êï∞ÊçÆÈõÜÊõ¥Â•ΩÁöÑÂÅáËÆæÂáΩÊï∞„ÄÇ ÂÜç‰∏ÄÊ¨°ËØ¥Êòé‰∏ãÔºåËøôÈÉ®ÂàÜÂÜÖÂÆπÁöÑÁ°ÆÊúâ‰∫õÈöæ‰ª•ÊòéÁôΩÔºå‰∏∫‰ªÄ‰πàÂä†‰∏äÂèÇÊï∞ÁöÑÂΩ±ÂìçÂèØ‰ª•ÂÖ∑ÊúâËøôÁßçÊïàÊûúÔºü‰ΩÜÂ¶ÇÊûú‰Ω†‰∫≤Ëá™ÂÆûÁé∞‰∫ÜÊ≠£ËßÑÂåñÔºå‰Ω†Â∞ÜËÉΩÂ§üÁúãÂà∞ËøôÁßçÂΩ±ÂìçÁöÑÊúÄÁõ¥ËßÇÁöÑÊÑüÂèó„ÄÇ Âú®Ê≠£ÂàôÂåñÁ∫øÊÄßÂõûÂΩí‰∏≠ÔºåÂ¶ÇÊûúÊ≠£ÂàôÂåñÂèÇÊï∞ÂÄºŒªË¢´ËÆæÂÆöÁöÑÈùûÂ∏∏Â§ßÔºåÈÇ£‰πà‰ºöÂèëÁîü‰ªÄ‰πàÂë¢ÔºüÊàë‰ª¨ÈùûÂ∏∏Â§ßÁöÑÊÉ©ÁΩöÂèÇÊï∞Œ∏1 Œ∏2 Œ∏3 Œ∏4 ‚Ä¶ ‰πüÂ∞±ÊòØËØ¥ÔºåÊàë‰ª¨ÊúÄÁªàÊÉ©ÁΩöŒ∏1 Œ∏2 Œ∏3 Œ∏4 ‚Ä¶ Âú®‰∏Ä‰∏™ÈùûÂ∏∏Â§ßÁöÑÁ®ãÂ∫¶ÔºåÈÇ£‰πàÊàë‰ª¨‰ºö‰ΩøÊâÄÊúâËøô‰∫õÂèÇÊï∞Êé•Ëøë‰∫éÈõ∂„ÄÇ Â¶ÇÊûúÊàë‰ª¨Ëøô‰πàÂÅöÔºåÈÇ£‰πàÂ∞±ÊÑèÂë≥ÁùÄÊàë‰ª¨ÁöÑÂÅáËÆæÁõ∏ÂΩì‰∫éÂéªÊéâ‰∫ÜËøô‰∫õÈ°πÔºåÂπ∂‰∏î‰ΩøÊàë‰ª¨Âè™Áïô‰∏ã‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂÅáËÆæÔºåËøô‰∏™ÂÅáËÆæÂè™ËÉΩË°®ÊòéÊàøÂ±ã‰ª∑Ê†ºÁ≠â‰∫éŒ∏0ÁöÑÂÄºÔºåÈÇ£Â∞±ÊòØÁ±ª‰ºº‰∏é‰∏ÄÊù°Ê∞¥Âπ≥ÁöÑÁõ¥Á∫øÔºåÂØπ‰∫éÊï∞ÊçÆÊù•ËØ¥Â∞±ÊòØ‰∏Ä‰∏™Ê¨†ÊãüÂêà„ÄÇËøôÊòØ‰∏Ä‰∏™Â§±Ë¥•ÁöÑÂÅáËÆæÁõ¥Á∫øÔºåÂØπ‰∫éËÆ≠ÁªÉÈõÜÊù•ËØ¥ËøôÂ∞±ÊòØ‰∏ÄÊù°Âπ≥ÊªëÁöÑÁõ¥Á∫øÔºåÂÆÉÊ≤°Êúâ‰ªª‰ΩïË∂ãÂäøÔºåÂÆÉ‰∏ç‰ºöÂéªË∂ãÂêëÂ§ßÈÉ®ÂàÜÁöÑËÆ≠ÁªÉÊ†∑Êú¨ÁöÑ‰ªª‰ΩïÂÄº„ÄÇ Âè¶‰∏Ä‰∏™ËØ¥Ê≥ïÂ∞±ÊòØËøôÁßçÂÅáËÆæÊúâËøá‰∫éÂº∫ÁÉàÁöÑÂÅèËßÅÊàñËÄÖËØ¥‰ΩøÈ´òÂÅèÂ∑ÆÔºåËÆ§‰∏∫È¢ÑÊµãÁöÑ‰ª∑Ê†ºÂè™Á≠â‰∫éŒ∏0ÔºåÂØπ‰∫éÊï∞ÊçÆÊù•ËØ¥Âè™ÊòØ‰∏ÄÊù°Ê∞¥Âπ≥Á∫ø„ÄÇ Âõ†Ê≠§Ôºå‰∏∫‰∫Ü‰ΩøÊ≠£ÂàôÂåñËøêË°åËâØÂ•ΩÔºåÊàë‰ª¨Â∫îÂΩìÊ≥®ÊÑè‰∏Ä‰∫õÊñπÈù¢ÔºåÂ∫îËØ•ÂéªÈÄâÊã©‰∏Ä‰∏™‰∏çÈîôÁöÑÊ≠£ÂàôÂåñÂèÇÊï∞ŒªÔºåÂΩìÊàë‰ª¨‰ª•ÂêéËÆ≤Âà∞Â§öÈáçÈÄâÊã©Êó∂Êàë‰ª¨Â∞ÜËÆ®ËÆ∫‰∏ÄÁßçÊñπÊ≥ïÊù•Ëá™Âä®ÈÄâÊã©Ê≠£ÂàôÂåñÂèÇÊï∞ ŒªÔºå‰∏∫‰∫Ü‰ΩøÁî®Ê≠£ÂàôÂåñÔºåÊé•‰∏ãÊù•Êàë‰ª¨Â∞ÜÊääËøô‰∫õÊ¶ÇÂøµÂ∫îÁî®Âà∞Âà∞Á∫øÊÄßÂõûÂΩíÂíåÈÄªËæëÂõûÂΩí‰∏≠ÂéªÔºåÈÇ£‰πàÊàë‰ª¨Â∞±ÂèØ‰ª•ËÆ©‰ªñ‰ª¨ÈÅøÂÖçËøáÂ∫¶ÊãüÂêà‰∫Ü„ÄÇ Ê≠£ÂàôÂåñÁöÑÁ∫øÊÄßÂõûÂΩí ÔºàRegularized Linear RegressionÔºâ‰πãÂâçÂÜôËøáÁ∫øÊÄßÂõûÂΩíÁöÑ‰ª£‰ª∑ÂáΩÊï∞Â¶Ç‰∏ãÔºö ÂØπ‰∫éÁ∫øÊÄßÂõûÂΩíÁöÑÊ±ÇËß£ÔºåÊàë‰ª¨‰πãÂâçËøêÁî®‰∫Ü‰∏§ÁßçÂ≠¶‰π†ÁÆóÊ≥ïÔºå‰∏ÄÁßçÂü∫‰∫éÊ¢ØÂ∫¶‰∏ãÈôçÔºå‰∏ÄÁßçÂü∫‰∫éÊ≠£ËßÑÊñπÁ®ã„ÄÇ Ê¢ØÂ∫¶‰∏ãÈôç Ê≠£ËßÑÊñπÁ®ã ‰∏çÂèØÈÄÜÊÉÖÂÜµÂΩìÂá∫Áé∞Ê†∑Êú¨Êï∞ÈáèMÊØîÁâπÂæÅÊï∞NÂ∞ëÊàñÁ≠â‰∫éÊó∂ÔºåÁü©ÈòµXTXÂ∞ÜÂá∫Áé∞‰∏çÂèØÈÄÜÊàñËÄÖÂ•áÂºÇÔºàsingluarÔºâÁü©ÈòµÔºåÁî®Âè¶‰∏Ä‰∏™ËØ¥Ê≥ïÂ∞±ÊòØÁü©ÈòµÁöÑÈÄÄÂåñÔºàdegenerateÔºâÔºåËøôÊó∂Êàë‰ª¨Â∞±Ê≤°ÂäûÊ≥ïÁî®Ê≠£ËßÑÊñπÁ®ãÊù•Ê±Ç Œ∏„ÄÇ Ê≠£ÂàôÂåñÂèØ‰ª•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÂÖ∑‰ΩìÁöÑËØ¥Âè™Ë¶ÅÊ≠£ÂàôÂèÇÊï∞ÊòØ‰∏•Ê†ºÂ§ß‰∫éÈõ∂ÔºåÂÆûÈôÖ‰∏äÔºåÂèØ‰ª•ËØÅÊòé‰∏äÂõæÁöÑËìùÊã¨Âè∑ÈÉ®ÂàÜÊòØÂèØÈÄÜÁöÑÔºàinvertableÔºâÔºåÂõ†Ê≠§Ê≠£ÂàôÂåñÂèØ‰ª•Ëß£ÂÜ≥‰ªª‰ΩïXTX‰∏çÂèØÈÄÜÁöÑÈóÆÈ¢ò„ÄÇ ÊâÄ‰ª•Áé∞Âú®ÂèØ‰ª•ÂÆûÁé∞Á∫øÊÄßÂõûÂΩíÈÅøÂÖçËøáÂ∫¶ÊãüÂêàÁöÑÈóÆÈ¢òÔºåÂç≥‰ΩøÊòØ‰∏Ä‰∏™Áõ∏ÂØπËæÉÂ∞èÁöÑËÆ≠ÁªÉÈõÜÂêàÈáåÈù¢ÊúâÂæàÂ§öÁöÑÁâπÂæÅÂÄº„ÄÇ Ê≠£ÂàôÂåñÁöÑÈÄªËæëÂõûÂΩíÔºàRegularized Logistic RegressionÔºâÈÄªËæëÂõûÂΩíÁöÑÊ≠£ÂàôÂåñÂÆûÈôÖ‰∏äÂíåÁ∫øÊÄßÂõûÂΩíÁöÑÊ≠£ÂàôÂåñÂçÅÂàÜÁöÑÁõ∏‰ºº„ÄÇ ÂêåÊ†∑‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÔºö Â¶ÇÊûúÂú®È´òÁ∫ß‰ºòÂåñÁÆóÊ≥ï‰∏≠Ôºå‰ΩøÁî®Ê≠£ÂàôÂåñÊäÄÊúØÁöÑËØùÔºåÈÇ£‰πàÂØπ‰∫éËøôÁ±ªÁÆóÊ≥ïÊàë‰ª¨ÈúÄË¶ÅËá™Â∑±ÂÆö‰πâcostfunction Ëøô‰∏™Êàë‰ª¨Ëá™ÂÆö‰πâÁöÑ costFunction ÁöÑËæìÂÖ•‰∏∫ÂêëÈáè Œ∏ ÔºåËøîÂõûÂÄºÊúâ‰∏§È°πÔºåÂàÜÂà´ÊòØ‰ª£‰ª∑ÂáΩÊï∞ jVal ‰ª•Âèä Ê¢ØÂ∫¶gradient„ÄÇ ÊÄª‰πãÊàë‰ª¨ÈúÄË¶ÅÁöÑÂ∞±ÊòØËøô‰∏™Ëá™ÂÆö‰πâÂáΩÊï∞costFunctionÔºåÈíàÂØπOctaveËÄåË®ÄÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜËøô‰∏™ÂáΩÊï∞‰Ωú‰∏∫ÂèÇÊï∞‰º†ÂÖ•Âà∞ fminunc Á≥ªÁªüÂáΩÊï∞‰∏≠Ôºàfminunc Áî®Êù•Ê±ÇÂáΩÊï∞ÁöÑÊúÄÂ∞èÂÄºÔºåÂ∞Ü@costFunction‰Ωú‰∏∫ÂèÇÊï∞‰ª£ËøõÂéªÔºåÊ≥®ÊÑè @costFunction Á±ª‰ºº‰∫éCËØ≠Ë®Ä‰∏≠ÁöÑÂáΩÊï∞ÊåáÈíàÔºâÔºåfminuncËøîÂõûÁöÑÊòØÂáΩÊï∞ costFunction Âú®Êó†Á∫¶ÊùüÊù°‰ª∂‰∏ãÁöÑÊúÄÂ∞èÂÄºÔºåÂç≥Êàë‰ª¨Êèê‰æõÁöÑ‰ª£‰ª∑ÂáΩÊï∞ jVal ÁöÑÊúÄÂ∞èÂÄºÔºåÂΩìÁÑ∂‰πü‰ºöËøîÂõûÂêëÈáè Œ∏ ÁöÑËß£„ÄÇ ‰∏äËø∞ÊñπÊ≥ïÊòæÁÑ∂ÂØπÊ≠£ÂàôÂåñÈÄªËæëÂõûÂΩíÊòØÈÄÇÁî®ÁöÑ„ÄÇ ÊÄªÁªì‰ªéËøôÈáåÂºÄÂßãÊÑüËßâËØæÁ®ãÂ∑≤ÁªèÊúâ‰∫õÈöæÂ∫¶‰∫ÜÔºåÂÖ≥‰∫éÊ≠£ÂàôÂåñÊàë‰πüÊòØÊü•ÈòÖ‰∫ÜÂÖ∂‰ªñÁõ∏ÂÖ≥ËµÑÊñôÊâçÂæó‰ª•ÊòéÁôΩÔºåÂ∞ùËØïÂÜô‰∏™ÂÖ≥‰∫éÊ≠£ÂàôÂåñÁöÑÁ®ãÂ∫èÂêß„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>Ê≠£ÂàôÂåñ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ê≠£ÂàôÂåñ]]></title>
    <url>%2F2018%2F05%2F09%2F%E6%AD%A3%E5%88%99%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÈÅáÂà∞‰∫ÜÈöæÈ¢òÔºåÂ∞±ÊòØÂØπÊ≠£ÂàôÂåñÁöÑÁêÜËß£ÔºåÈÄöËøáÊü•ÈòÖËµÑÊñôÔºåËÆ∞ÂΩï‰∏ã‰ªÄ‰πàÊòØÊ≠£ÂàôÂåñ„ÄÇ Ê≠£ÂàôÂåñÊ®°ÂûãÈÄâÊã©ÁöÑÂÖ∏ÂûãÊñπÊ≥ïÊòØÊ≠£ÂàôÂåñÔºàregularizationÔºâ„ÄÇÊ≠£ÂàôÂåñÊòØÁªìÊûÑÈ£éÈô©ÊúÄÂ∞èÂåñÁ≠ñÁï•ÁöÑÂÆûÁé∞ÔºåÊòØÂú®ÁªèÈ™åÈ£éÈô©‰∏äÂä†‰∏Ä‰∏™Ê≠£ÂàôÂåñÈ°πÔºàregularizerÔºâÊàñÁΩöÈ°πÔºàpenalty termÔºâ„ÄÇÊ≠£ÂàôÂåñÈ°π‰∏ÄËà¨ÊòØÊ®°ÂûãÂ§çÊùÇÂ∫¶ÁöÑÂçïË∞ÉÈÄíÂ¢ûÂáΩÊï∞ÔºåÊ®°ÂûãË∂äÂ§çÊùÇÔºåÊ≠£ÂàôÂåñÂÄºË∂äÂ§ß„ÄÇÊØîÂ¶ÇÔºåÊ≠£ÂàôÂåñÈ°πÂèØ‰ª•ÊòØÊ®°ÂûãÂèÇÊï∞ÂêëÈáèÁöÑ==ËåÉÊï∞==„ÄÇ Âú®ËøôÈáåÊàëÂèàÈÅáÂà∞‰∫Ü‰∏Ä‰∏™ÈóÆÈ¢òÔºå‰ªÄ‰πàÊòØËåÉÊï∞ÔºåÂìéÔºåÈ´òÊï∞Ê≤°Â≠¶Â•ΩÔºåÂï•‰πü‰∏çÁü•ÈÅì‰∫Ü„ÄÇ ËåÉÊï∞(norm)ÊòØÊï∞Â≠¶‰∏≠ÁöÑ‰∏ÄÁßçÂü∫Êú¨Ê¶ÇÂøµ„ÄÇÂú®Ê≥õÂáΩÂàÜÊûê‰∏≠ÔºåÂÆÉÂÆö‰πâÂú®ËµãËåÉÁ∫øÊÄßÁ©∫Èó¥‰∏≠ÔºåÂπ∂Êª°Ë∂≥‰∏ÄÂÆöÁöÑÊù°‰ª∂ÔºåÂç≥‚ë†ÈùûË¥üÊÄßÔºõ‚ë°ÈΩêÊ¨°ÊÄßÔºõ‚ë¢‰∏âËßí‰∏çÁ≠âÂºè„ÄÇÂÆÉÂ∏∏Â∏∏Ë¢´Áî®Êù•Â∫¶ÈáèÊüê‰∏™ÂêëÈáèÁ©∫Èó¥ÔºàÊàñÁü©ÈòµÔºâ‰∏≠ÁöÑÊØè‰∏™ÂêëÈáèÁöÑÈïøÂ∫¶ÊàñÂ§ßÂ∞è„ÄÇ ÁúãÂÆåÂÆö‰πâÂèàÊòØÂ§¥Â§ßÔºåÂÆåÂÖ®‰∏çÁêÜËß£ÂïäÔºÅÂÆö‰πâÂíåÊÄßË¥®‰ªÄ‰πàÁöÑÈÉΩ‰∏çÈáçË¶Å‰∫ÜÔºåËøôÈáåÊàëÂè™ÈúÄË¶ÅÁü•ÈÅìËåÉÊï∞ÊâÄ‰ª£Ë°®ÁöÑÂáΩÊï∞ÊÑè‰πâÔºö12341-ËåÉÊï∞Ôºö‚ïëx‚ïë1=‚îÇx1‚îÇ+‚îÇx2‚îÇ+‚Ä¶+‚îÇxn‚îÇ2-ËåÉÊï∞Ôºö‚ïëx‚ïë2=Ôºà‚îÇx1‚îÇ2+‚îÇx2‚îÇ2+‚Ä¶+‚îÇxn‚îÇ2Ôºâ1/2‚àû-ËåÉÊï∞Ôºö‚ïëx‚ïë‚àû=maxÔºà‚îÇx1‚îÇÔºå‚îÇx2‚îÇÔºå‚Ä¶Ôºå‚îÇxn‚îÇÔºâÂÖ∂‰∏≠2-ËåÉÊï∞Â∞±ÊòØÈÄöÂ∏∏ÊÑè‰πâ‰∏ãÁöÑË∑ùÁ¶ª„ÄÇ Áü©ÈòµËåÉÊï∞Ôºö1234561-ËåÉÊï∞Ôºö‚ïëA‚ïë1 = max&#123; ‚àë|ai1|Ôºå‚àë|ai2|Ôºå‚Ä¶‚Ä¶Ôºå‚àë|ain| &#125; ÔºàÂàóÂíåËåÉÊï∞ÔºåAÊØè‰∏ÄÂàóÂÖÉÁ¥†ÁªùÂØπÂÄº‰πãÂíåÁöÑÊúÄÂ§ßÂÄºÔºâÔºàÂÖ∂‰∏≠‚àë|ai1|Á¨¨‰∏ÄÂàóÂÖÉÁ¥†ÁªùÂØπÂÄºÁöÑÂíå‚àë|ai1|=|a11|+|a21|+...+|an1|ÔºåÂÖ∂‰ΩôÁ±ª‰ººÔºâÔºõ2-ËåÉÊï∞Ôºö‚ïëA‚ïë2 = AÁöÑÊúÄÂ§ßÂ•áÂºÇÂÄº = (max&#123; Œªi(AH*A) &#125;) 1/2 ÔºàË∞±ËåÉÊï∞ÔºåÂç≥A^H*AÁâπÂæÅÂÄºŒªi‰∏≠ÊúÄÂ§ßËÄÖŒª1ÁöÑÂπ≥ÊñπÊ†πÔºåÂÖ∂‰∏≠AH‰∏∫AÁöÑËΩ¨ÁΩÆÂÖ±ËΩ≠Áü©ÈòµÔºâÔºõ‚àû-ËåÉÊï∞Ôºö‚ïëA‚ïë‚àû = max&#123; ‚àë|a1j|Ôºå‚àë|a2j|,...Ôºå‚àë|amj| &#125; ÔºàË°åÂíåËåÉÊï∞ÔºåAÊØè‰∏ÄË°åÂÖÉÁ¥†ÁªùÂØπÂÄº‰πãÂíåÁöÑÊúÄÂ§ßÂÄºÔºâÔºàÂÖ∂‰∏≠‚àë|a1j| ‰∏∫Á¨¨‰∏ÄË°åÂÖÉÁ¥†ÁªùÂØπÂÄºÁöÑÂíåÔºåÂÖ∂‰ΩôÁ±ª‰ººÔºâÔºõ Áúã‰∫ÜËøôÂá†‰∏™‰æãÂ≠êÂ§ßÊ¶ÇÁêÜËß£‰∫ÜÔºåËã•ÔºåÈÇ£‰πàÁªßÁª≠Ê≠£ÂàôÂåñÁöÑËØùÈ¢òÔºåÊ≠£ÂàôÂåñ‰∏ªË¶ÅËß£ÂÜ≥ÁöÑÈóÆÈ¢òÔºö 1.Ê≠£ÂàôÂåñÂ∞±ÊòØÂØπÊúÄÂ∞èÂåñÁªèÈ™åËØØÂ∑ÆÂáΩÊï∞‰∏äÂä†Á∫¶ÊùüÔºåËøôÊ†∑ÁöÑÁ∫¶ÊùüÂèØ‰ª•Ëß£Èáä‰∏∫ÂÖàÈ™åÁü•ËØÜ(Ê≠£ÂàôÂåñÂèÇÊï∞Á≠â‰ª∑‰∫éÂØπÂèÇÊï∞ÂºïÂÖ•ÂÖàÈ™åÂàÜÂ∏É)„ÄÇÁ∫¶ÊùüÊúâÂºïÂØº‰ΩúÁî®ÔºåÂú®‰ºòÂåñËØØÂ∑ÆÂáΩÊï∞ÁöÑÊó∂ÂÄôÂÄæÂêë‰∫éÈÄâÊã©Êª°Ë∂≥Á∫¶ÊùüÁöÑÊ¢ØÂ∫¶ÂáèÂ∞ëÁöÑÊñπÂêëÔºå‰ΩøÊúÄÁªàÁöÑËß£ÂÄæÂêë‰∫éÁ¨¶ÂêàÂÖàÈ™åÁü•ËØÜ(Â¶Ç‰∏ÄËà¨ÁöÑl-normÂÖàÈ™åÔºåË°®Á§∫ÂéüÈóÆÈ¢òÊõ¥ÂèØËÉΩÊòØÊØîËæÉÁÆÄÂçïÁöÑÔºåËøôÊ†∑ÁöÑ‰ºòÂåñÂÄæÂêë‰∫é‰∫ßÁîüÂèÇÊï∞ÂÄºÈáèÁ∫ßÂ∞èÁöÑËß£Ôºå‰∏ÄËà¨ÂØπÂ∫î‰∫éÁ®ÄÁñèÂèÇÊï∞ÁöÑÂπ≥ÊªëËß£)„ÄÇ 2.ÂêåÊó∂ÔºåÊ≠£ÂàôÂåñËß£ÂÜ≥‰∫ÜÈÄÜÈóÆÈ¢òÁöÑ‰∏çÈÄÇÂÆöÊÄßÔºå‰∫ßÁîüÁöÑËß£ÊòØÂ≠òÂú®ÔºåÂîØ‰∏ÄÂêåÊó∂‰πü‰æùËµñ‰∫éÊï∞ÊçÆÁöÑÔºåÂô™Â£∞ÂØπ‰∏çÈÄÇÂÆöÁöÑÂΩ±ÂìçÂ∞±Âº±ÔºåËß£Â∞±‰∏ç‰ºöËøáÊãüÂêàÔºåËÄå‰∏îÂ¶ÇÊûúÂÖàÈ™å(Ê≠£ÂàôÂåñ)ÂêàÈÄÇÔºåÂàôËß£Â∞±ÂÄæÂêë‰∫éÊòØÁ¨¶ÂêàÁúüËß£(Êõ¥‰∏ç‰ºöËøáÊãüÂêà‰∫Ü)ÔºåÂç≥‰ΩøËÆ≠ÁªÉÈõÜ‰∏≠ÂΩºÊ≠§Èó¥‰∏çÁõ∏ÂÖ≥ÁöÑÊ†∑Êú¨Êï∞ÂæàÂ∞ë„ÄÇ Ê≠£ÂàôÂåñ‰∏ÄËà¨ÂÖ∑ÊúâÂ¶Ç‰∏ãÂΩ¢ÂºèÔºöÂÖ∂‰∏≠Á¨¨‰∏ÄÈ°πÊòØÁªèÈ™åÈ£éÈô©ÔºåÁ¨¨‰∫åÈ°πÊòØÊ≠£ÂàôÂåñÈ°πÔºåŒª&gt;=0‰∏∫Ë∞ÉÊï¥‰∏§ËÄÖÂÖ≥Á≥ªÁöÑÁ≥ªÊï∞„ÄÇÊ≠£ÂàôÂåñÈ°πÂèØ‰ª•Âèñ‰∏çÂêåÁöÑÂΩ¢ÂºèÔºå‰æãÂ¶ÇÔºåÂõûÂΩíÈóÆÈ¢òÔºåÊçüÂ§±ÂáΩÊï∞ÊòØÂπ≥ÊñπÊçüÂ§±ÔºåÊ≠£ÂàôÂåñÈ°πÂèØ‰ª•‰ΩøÂèÇÊï∞ÂêëÈáèÁöÑ2ËåÉÁ±ª„ÄÇËåÉÁ±ªÁöÑËÆ∞ÂΩïÂ§ßÊ¶ÇÂ∞±ÊòØËøô‰πàÂ§ö‰∫Ü„ÄÇ Ê≥∞ÂãíÂÖ¨ÂºèÈ°∫‰æøËØ¥‰∏ãÊ≥∞ÂãíÂÖ¨ÂºèÔºåÊòØÂú®Â≠¶‰π†Âê¥ÊÅ©ËææÁöÑÊú∫Âô®Â≠¶‰π†Ê≠£ÂàôÂåñÊó∂ÊâçÊÉ≥Âà∞ÁöÑÔºåÊàë‰ª¨ÁöÑÈ¢ÑÊµãÊ®°ÂûãÊòØ‰∏Ä‰∏™Â§öÈ°πÂºèÁöÑÂíåÔºåÂΩìÂ§öÈ°πÂºèËøáÂ∞ë‰ºöÊ¨†ÊãüÂêàÔºåËøáÂ§ö‰ºöËøáÊãüÂêàÔºåÂΩìÂ§öÈ°πÂºèË∂≥Â§üÂ§öÁöÑÊó∂ÂÄôÂ∞±‰ºöÂå∫ÂàÜÂá∫ÊâÄÊúâÁöÑÁßçÁ±ªÔºåËøô‰∏çÂ∞±ÊòØÊ≥∞ÂãíÂÖ¨ÂºèÂ±ïÂºÄÂºèÂêóÔºü Êï∞Â≠¶‰∏≠ÔºåÊ≥∞ÂãíÂÖ¨ÂºèÊòØ‰∏Ä‰∏™Áî®ÂáΩÊï∞Âú®ÊüêÁÇπÁöÑ‰ø°ÊÅØÊèèËø∞ÂÖ∂ÈôÑËøëÂèñÂÄºÁöÑÂÖ¨Âºè„ÄÇÂ¶ÇÊûúÂáΩÊï∞Ë∂≥Â§üÂπ≥ÊªëÁöÑËØùÔºåÂú®Â∑≤Áü•ÂáΩÊï∞Âú®Êüê‰∏ÄÁÇπÁöÑÂêÑÈò∂ÂØºÊï∞ÂÄºÁöÑÊÉÖÂÜµ‰πã‰∏ãÔºåÊ≥∞ÂãíÂÖ¨ÂºèÂèØ‰ª•Áî®Ëøô‰∫õÂØºÊï∞ÂÄºÂÅöÁ≥ªÊï∞ÊûÑÂª∫‰∏Ä‰∏™Â§öÈ°πÂºèÊù•Ëøë‰ººÂáΩÊï∞Âú®Ëøô‰∏ÄÁÇπÁöÑÈÇªÂüü‰∏≠ÁöÑÂÄº„ÄÇ Ê≥∞ÂãíÂÖ¨ÂºèÊòØÂ∞Ü‰∏Ä‰∏™Âú®x=x0Â§ÑÂÖ∑ÊúânÈò∂ÂØºÊï∞ÁöÑÂáΩÊï∞f(x)Âà©Áî®ÂÖ≥‰∫é(x-x0)ÁöÑnÊ¨°Â§öÈ°πÂºèÊù•ÈÄºËøëÂáΩÊï∞ÁöÑÊñπÊ≥ï„ÄÇËã•ÂáΩÊï∞f(x)Âú®ÂåÖÂê´x0ÁöÑÊüê‰∏™Èó≠Âå∫Èó¥[a,b]‰∏äÂÖ∑ÊúânÈò∂ÂØºÊï∞Ôºå‰∏îÂú®ÂºÄÂå∫Èó¥(a,b)‰∏äÂÖ∑Êúâ(n+1)Èò∂ÂØºÊï∞ÔºåÂàôÂØπÈó≠Âå∫Èó¥[a,b]‰∏ä‰ªªÊÑè‰∏ÄÁÇπxÔºåÊàêÁ´ã‰∏ãÂºèÔºöÂÖ∂‰∏≠,fn^(x)Ë°®Á§∫fn(x)ÁöÑnÈò∂ÂØºÊï∞ÔºåÁ≠âÂè∑ÂêéÁöÑÂ§öÈ°πÂºèÁß∞‰∏∫ÂáΩÊï∞f(x)Âú®x0Â§ÑÁöÑÊ≥∞ÂãíÂ±ïÂºÄÂºèÔºåÂâ©‰ΩôÁöÑRn(x)ÊòØÊ≥∞ÂãíÂÖ¨ÂºèÁöÑ‰ΩôÈ°πÔºåÊòØ(x-x0)nÁöÑÈ´òÈò∂Êó†Á©∑Â∞è„ÄÇ ÂèÇËÄÉÔºöÊùéËà™ ÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï]]></content>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>Ê≠£ÂàôÂåñ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÂÆûÁé∞ÈÄªËæëÂõûÂΩí]]></title>
    <url>%2F2018%2F05%2F04%2FPython%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[È¶ñÂÖàÊÄªÁªì‰∏Ä‰∏ãÂ≠¶‰π†ÔºåËôΩÁÑ∂Âè´ÂõûÂΩí‰ΩÜÊòØÂíåÂõûÂΩíÊ≤°Êúâ‰ªª‰ΩïÂÖ≥Á≥ªÔºåÂàöÂ∞ùËØïÂÜô‰ª£Á†ÅÊó∂ÔºåÊÄùËÄÉÂàÜÁ±ªÈóÆÈ¢òÈô∑ÂÖ•‰∫ÜÁ∫øÊÄßÂõûÂΩíÁöÑÊÄùË∑ØÔºåÁ∫†Áªì‰∫ÜÂ•Ω‰πÖÔºåÂ∑≤ÁªèÊ±ÇÂá∫weights‰ΩÜ‰∏ç‰ºöÊãüÂêàÁõ¥Á∫øÔºåÂêéÊù•Áî®Á¨îÁîª‰∫Ü‰∏ãÁ´ãÂàªÊòéÁôΩÊÄùËÄÉÂÅèÁ¶ª‰∫ÜÔºåÊâÄ‰ª•Â∞±ÁÆóÊúâ‰∫ÜÁîµËÑëËøòÊòØÂ∫îËØ•Áî®Á¨îÂú®Á∫∏‰∏äÁîª‰∏ÄÁîª„ÄÇ ÂÜô‰ª£Á†ÅÈ¶ñÂÖàÁ¨¨‰∏ÄÊ≠•ÊòØË¶ÅÁü•ÈÅìÂÅö‰ªÄ‰πàÔºöÊàëÈúÄË¶ÅÁîª‰∏Ä‰∏™Áõ¥Á∫øÔºåÁõ¥Á∫øÂÖ¨Âºè‰∏∫ Œ∏0 x0 + Œ∏1 x1 + Œ∏2 * x2 = 0 ÂÖ∂‰∏≠x0 = 1„ÄÇÊÉ≥Ë¶ÅÁîªÂá∫ËøôÊù°Áõ¥Á∫øÊàëÈúÄË¶ÅÁü•ÈÅì‰∏â‰∏™Œ∏ÁöÑÂÄºÔºåÈÄöËøáÂê¥Â§ßÂ§ßÁöÑÊú∫Âô®Â≠¶‰π†ËßÜÈ¢ëÊàëÁü•ÈÅìÁöÑÊääŒ∏ÁöÑËΩ¨ÁΩÆ‰πò‰ª•xÁöÑÂ∏¶ÂÖ•ÈÄªËæëÂáΩÊï∞g(z)Â∞±ËÉΩÊ±ÇÂá∫È¢ÑÊµãÂáΩÊï∞h(x),ÁÑ∂ÂêéÈÄöËøáÊ¢ØÂ∫¶‰∏ãÈôçÁöÑÊñπÂºèÊõ¥Êñ∞Œ∏ÔºåÊúÄÁªàÂæóÂà∞Œ∏ÁöÑËøë‰ººÂÄº„ÄÇ123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#!/usr/bin/python# coding=utf-8from sklearn.datasets import load_irisimport matplotlib.pyplot as pltimport numpy as np# ÈÄªËæëÂáΩÊï∞(Logistic function)def gfunc(z): return 1 / (1 + np.exp(-z))# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜÔºöÂºïÂÖ•‰∫ÜÈ∏¢Â∞æËä±Êï∞ÊçÆÈõÜÊù•‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜiris = load_iris()data = iris.datatarget = iris.target# ÂèñÂâç‰∏ÄÁôæË°åÁöÑÁ¨¨‰∏ÄÂàóÂíåÁ¨¨‰∏âÂàóÂÅöÁâπÂæÅÂÄºX = data[0:100, [0, 2]]y = target[0:100]# ÁîªÂá∫ËÆ≠ÁªÉÈõÜÁöÑÊï£ÁÇπÂõælabel = np.array(y)index_0 = np.where(label == 0)plt.scatter(X[index_0, 0], X[index_0, 1], marker='x', color='b', label='0', s=15)index_1 = np.where(label == 1)plt.scatter(X[index_1, 0], X[index_1, 1], marker='o', color='r', label='1', s=15)plt.xlabel('X1')plt.ylabel('X2')plt.legend(loc='upper left')######################################################### ËÆ≠ÁªÉÈõÜÊûÑÂª∫ÂÆåÊàêÂêéÂà§Êñ≠ËæπÁïåÔºåÊàëÁåúËæπÁïåÊòØ‰∏ÄÊù°Áõ¥Á∫ø# Áõ¥Á∫øÁöÑÂÖ¨ÂºèÔºöŒ∏0 * x0 + Œ∏1 * x1 + Œ∏2 * x2 = 0 ÂÖ∂‰∏≠x0 = 1# Âõ†‰∏∫Ëøô‰∏™ÈóÆÈ¢òÈáåÊòØ‰∏Ä‰∏™‰∫åÁª¥ÂàÜÁ±ªÔºåÊâÄ‰ª•ËæπÁïåÊòØÊúâ‰∏â‰∏™Œ∏ÂÜ≥ÂÆöÁöÑ######################################################### ËÆ≠ÁªÉÈõÜÁöÑ‰∏™Êï∞mm = 100# ÈáçÊñ∞ÊûÑÂª∫‰∫ÜXÂêëÈáè Âä†‰∏ä‰∫Üx0=1x0 = np.full(m, 1.0)x0 = np.vstack(x0)x = np.column_stack((x0, X))# ÈöèÊú∫ËÆæÁΩÆ‰∏â‰∏™thetaÂÄºtheta = np.random.randn(3)# ‰∏§ÁßçÁªàÊ≠¢Êù°‰ª∂loop_max = 10000 # ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞(Èò≤Ê≠¢Ê≠ªÂæ™ÁéØ)epsilon = 1e-3error = np.zeros(3)count = 0alpha = 0.001 # Ê≠•Èïøwhile count &lt; loop_max: delta = np.zeros(3) for i in range(m): delta = delta + (gfunc(np.dot(theta, x[i])) - y[i]) * x[i] theta = theta - alpha * delta # Âà§Êñ≠ÊòØÂê¶Â∑≤Êî∂Êïõ if np.linalg.norm(theta - error) &lt; epsilon: finish = 1 break else: error = theta count += 1print("The number of iterations = ", count)print(theta)# x0 = 1# Â∑≤ÁªèÊ±ÇÂæóthetaÂèÇÊï∞ÔºåÁªôÂá∫x1ÁöÑÂÄºÔºåÊ†πÊçÆthetaËÆ°ÁÆóx2ÔºåÁîªÂá∫Áõ¥Á∫øx1 = np.arange(4, 7.5, 0.5)x2 = (- theta[0] - theta[1] * x1) / theta[2]plt.plot(x1, x2, color='black')plt.show() ÂêéÊù•ÊàëÈÄöËøáÂ≠¶‰π†‰ªñ‰∫∫ÁöÑÈÄªËæëÂõûÂΩíÂáΩÊï∞Ôºå‰øÆÊîπÊ≠•ÈïøÔºåËßÇÂØüÊçüÂ§±ÂõæÔºåÂèëÁé∞‰∫Ü‰∫õÊúâË∂£ÁöÑ‰∫ãÔºåÊàëÊää‰ª£Á†ÅÈáçÊûÑ‰∫ÜÔºåÊõ¥‰æø‰∫éÂèØËßÜÂåñ &gt;ÈÄªËæëÂõûÂΩíÊ∫ê‰ª£Á†Å&lt; È¶ñÂÖàÊàëÊääÊ≠•ÈïøËÆæÁΩÆ‰∏∫0.001ÔºåÁÑ∂ÂêéÁîªÂá∫lossÂõæÔºö 0.001ÁöÑÊ≠•Êï∞Â§ßÊ¶ÇËø≠‰ª£2500Â§öÊ¨°ËææÂà∞‰ΩéË∞∑Ôºå‰ªéÂõæ‰∏≠‰∏≠ËßÇÂØüÂà∞lossÊçüÂ§±Áõ∏ÂΩìÂπ≥ÊªëÔºåÊ≤°ÊúâÂá∫Áé∞ÈúáËç° ÁÑ∂ÂêéÊàë‰øÆÊîπ‰∫ÜÊ≠•Êï∞‰∏∫0.01ÔºåÂè™ÈÄöËøá800Ê¨°Ëø≠‰ª£Â∞±‰∏ãÈôçÂà∞‰ΩéË∞∑Ôºå‰ΩÜÊòØÂá∫Áé∞ÈúáËç°ÔºåÂ¶ÇÊûúÂú®Á∫øÊÄßÂõûÂΩí‰∏≠Âá∫Áé∞ÈúáËç°Âàô‰∏ç‰ºöÊî∂ÊïõÔºå‰ΩÜÊòØÂú®ÈÄªËæëÂõûÂΩíÈóÆÈ¢ò‰∏≠ÔºåÂ∞ΩÁÆ°Âá∫Áé∞‰∫ÜÈúáËç°Ôºå‰ΩÜÊúÄÁªàËøòÊòØÊî∂Êïõ„ÄÇ‰ΩÜÂ¶ÇÊûúÊàëÊääÊ≠•Êï∞ËÆæÁΩÆÁöÑÊõ¥Â§ß0.02Êó∂ÔºåÂ∞±‰ºöÊØè1800Ê¨°ÂêéÂá∫Áé∞ÈúáËç°ÁöÑÊÉÖÂÜµÔºåÊúÄÁªàÊó†Ê≥ïÊî∂Êïõ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰ª£Á†ÅÂÆûÁé∞</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Ôºà‰∫îÔºâ]]></title>
    <url>%2F2018%2F04%2F24%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÊúÄËøë‰∫ãÊÉÖÊØîËæÉÂ§öÔºåÂèàÊáíÊÉ∞‰∫ÜÔºåÁªßÁª≠Â≠¶‰π†„ÄÇ ÂàÜÁ±ªÈóÆÈ¢ò‰ªÄ‰πàÊòØÂàÜÁ±ªÈóÆÈ¢òÔºå‰æãÂ¶ÇÔºöÂûÉÂúæÈÇÆ‰ª∂ÂàÜÁ±ªÔºåÊÅ∂ÊÄßËÇøÁò§È¢ÑÊµã„ÄÇÂú®ÂàÜÁ±ªÈóÆÈ¢ò‰∏≠‰∏ÄËà¨ÁªìÊûúÊòØ0Âíå1Ôºå1Áß∞‰∏∫Ê≠£Ê†∑Êú¨ÊàñÊ≠£Á±ªÔºå0Áß∞‰∏∫Ë¥üÊ†∑Êú¨ÊàñË¥üÁ±ª„ÄÇ È¶ñÂÖàËÆ≤Ëß£ÁöÑÊòØÁÆÄÂçïÁöÑ‰∏§ÂèòÈáèÂàÜÁ±ªÈóÆÈ¢ò‰ΩøÁî®Á∫øÊÄßÂõûÂΩíÁöÑÊñπÂºèËß£ÂÜ≥ÂàÜÁ±ªÈóÆÈ¢òÂ¶Ç‰ΩïÔºüÂ¶ÇÊûúÊòØ‰∏äÂõæËøôÊ†∑ÁöÑ‰æãÂ≠êÊù•ÁúãÔºå‰ΩøÁî®Á∫øÊÄßÂõûÂΩíÁöÑÊñπÂºèË≤å‰ººÂèØ‰ª•Ëß£ÂÜ≥ÂàÜÁ±ªÈóÆÈ¢òÔºå‰ΩÜÊòØÂ¶ÇÊûúÂ≠òÂú®‰∏Ä‰∏™‰∏•ÈáçÂÅèÂ∑ÆÁöÑÁâπÂæÅÊó∂Ôºå‰ΩøÁî®Á∫øÊÄßÂõûÂΩíÊãüÂêàÂàÜÁ±ªÈóÆÈ¢òÂ∞±‰ºöÂá∫Áé∞‰∏•ÈáçÁöÑÂÅèÂ∑ÆÔºåÂú®ÂàÜÁ±ªÈóÆÈ¢ò‰∏≠ÊúÄÁªàÁöÑÁªìÊûúÂè™Êúâ0Âíå1Ôºå‰ΩÜÊòØÂú®Á∫øÊÄßÂõûÂΩí‰∏≠‰ºöÂá∫Áé∞Â∞è‰∫é1ÂíåÂ§ß‰∫é0ÁöÑÁªìÊûú„ÄÇÊâÄ‰ª•‰ΩøÁî®Á∫øÊÄßÂõûÂΩíÁöÑÊñπÂºè‰∏çËÉΩÂæàÂ•ΩÁöÑÂ§ÑÁêÜÂàÜÁ±ªÈóÆÈ¢òÔºå‰∫éÊòØÂºïÂá∫‰∫ÜÂè¶‰∏ÄÁßçÊ®°ÂûãÔºåÈÄªËæëÂõûÂΩíÔºàÈÄªËæëÂõûÂΩíÁöÑÂè´Ê≥ïÊòØÂéÜÂè≤ÂéüÂõ†ÔºåÂíåÂõûÂΩíÂπ∂Ê≤°Êúâ‰ªÄ‰πàÂÖ≥Á≥ªÔºâ ÈÄªËæëÂõûÂΩí‰ªÄ‰πàÊ†∑ÁöÑÊï∞Â≠¶Ê®°ÂûãÈÄÇÂêàÂõûÂΩíÈóÆÈ¢òÂë¢Ôºü‰∏Ä‰∏™Âè™‰ºöÂú®0‰∏é1‰∏≠Èó¥ÈúáËç°ÁöÑÂáΩÊï∞Ê®°ÂûãÔºö ÂÖ∂‰∏≠Ôºö x,Ë°®Á§∫ÁöÑÊòØÁâπÂæÅÂêëÈáè gÔºå‰ª£Ë°®ÈÄªËæëÂáΩÊï∞(Logistic function)ÊòØ‰∏Ä‰∏™Â∏∏Áî®ÁöÑÊõ≤Á∫øÂáΩÊï∞(Sigmoid function),Ë°®ËææÂºè‰∏∫Ôºö ÂáΩÊï∞ÁöÑÂõæÂÉèÂ∞±Â¶Ç‰∏äÂõæÊâÄÁ§∫„ÄÇ h,Ë°®Á§∫ÁöÑÂ∞±ÊòØÈÄªËæëÂõûÂΩíÔºåÂ∏¶ÂÖ•Âà∞ÂáΩÊï∞g‰∏≠ÔºåÊúÄÁªàÂæóÂà∞ÁöÑË°®ËææÂºèÂ∞±ÊòØ ÂáΩÊï∞hË°®Á§∫ÁöÑÂ∞±ÊòØÂΩìËæìÂÖ•ÁâπÂæÅXÊó∂ÔºåÊ†πÊçÆËæìÂÖ•ÁöÑÁâπÂæÅËÆ°ÁÆóËæìÂá∫ÂèòÈáèY=1ÁöÑÂèØËÉΩÊÄß„ÄÇÂÅáËÆæh(x)=0.7,Ë°®Á§∫ÁöÑÂ∞±ÊòØÊÇ£ÊúâÊÅ∂ÊÄßËÇøÁò§ÁöÑÊ¶ÇÁéá‰∏∫0.7 Âà§ÂÆöËæπÁïå(Decision Boundary)Âà§ÂÆöËæπÁïåËÉΩÂ§üËÆ©Êàë‰ª¨Êõ¥Â•ΩÁöÑÁêÜËß£ÈÄªËæëÂõûÂΩíÂíåÂÅáËÆæÂáΩÊï∞Âú®ËÆ°ÁÆó‰ªÄ‰πà ‰∏äÂõæÂ∞±ÊòØÈÄªËæëÂõûÂΩíÁöÑÂáΩÊï∞ÂíåÂõæÂÉèÔºåÁúã‰∏Ä‰∏ãÊï∞Â≠¶ÊÑè‰πâÔºö123456ÂΩìh &gt;= 0.5Êó∂,È¢ÑÊµãÁªìÊûú y = 1ÔºåÂΩìh &lt; 0.5Êó∂ÔºåÈ¢ÑÊµãÁªìÊûú y = 0,ÊâÄ‰ª•ÔºöÂΩì y = 1 Êó∂Ôºåh(x) = g(z) &gt;= 0.5 ÈÇ£‰πà z &gt;= 0,‰πüÂ∞±ÊòØŒ∏tX&gt;=0;ÂΩìy=0Êó∂ÔºåÊúÄÂêéÂæóÂà∞Œ∏tX&lt;0„ÄÇ ÂÖ∑‰ΩìÁúã‰∏ãÈù¢Ëøô‰∏™‰æãÂ≠ê ÂÖ∂‰∏≠ÁöÑthetaÁöÑÂèÇÊï∞ÂàÜÂà´‰∏∫-3,1,1Â≠òÂú®Â¶Ç‰∏äÂõæÊâÄÁ§∫ÁöÑÊï∞ÊçÆ‰ª•ÂèäË°®Á§∫ÂáΩÊï∞,Â¶ÇÊûúË¶ÅÈ¢ÑÊµãy=1ÁöÑÊ¶ÇÁéáÔºåÊúÄÂêéÂæóÂà∞ÁöÑË°®ËææÂºè‰∏∫Ôºö ÊúÄÂêéÂæóÂà∞ÁöÑÁªìÊûúÂæàÊòéÊòæÊòØ‰∏Ä‰∏™ËøáÔºà0,3ÔºâÔºà3,0ÔºâÁöÑÁõ¥Á∫øÔºö ÂÖ∂‰∏≠ÁöÑÊñπÁ®ãÂ∞±ÊòØ‰∏Ä‰∏™Âà§ÂÆöËæπÁïåÔºåÈÄöËøáËøôÊù°Á∫øÂ∞±ÂèØ‰ª•ÂàÜËæ®Âá∫Ê≠£Ê†∑Êú¨ÂíåË¥üÊ†∑Êú¨‰∫Ü„ÄÇ Èô§‰∫ÜËøôÁßçÁ∫øÊÄßÁöÑÂà§ÂÆöËæπÁïå‰πãÂ§ñÔºåËøòÊúâ‰∏Ä‰∫õÂÖ∂‰ªñÂΩ¢Áä∂ÁöÑÂà§ÂÆöËæπÁïåÔºåÂ¶ÇÂúÜÂΩ¢„ÄÇ ÈÄªËæëÂõûÂΩí‰∏≠ÁöÑ‰ª£‰ª∑ÂáΩÊï∞‰∏äÈù¢Â∞±ÊòØ‰πãÂâçËÆ≤ËøáÁöÑÁ∫øÊÄßÂõûÂΩí‰∏≠ÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÔºåËøô‰∏™‰ª£‰ª∑ÂáΩÊï∞Âú®Á∫øÊÄßÂõûÂΩí‰∏≠ËÉΩÂ§üÂæàÂ•ΩÂú∞‰ΩøÁî®Ôºå‰ΩÜÊòØÂú®ÈÄªËæëÂõûÂΩí‰∏≠Âç¥‰ºöÂá∫Áé∞ÈóÆÈ¢òÔºåÂõ†‰∏∫Â∞ÜÈÄªËæëÂõûÂΩíÁöÑË°®ËææÂºèÂ∏¶ÂÖ•Âà∞hÂáΩÊï∞‰∏≠ÂæóÂà∞ÁöÑÊòØ‰∏Ä‰∏™ÈùûÂá∏ÂáΩÊï∞ÁöÑÂõæÂÉèÔºåÈÇ£‰πàÂ∞±‰ºöÂ≠òÂú®Â§ö‰∏™Â±ÄÈÉ®ÊúÄ‰ºòËß£ÔºåÊó†Ê≥ïÂÉèÂá∏ÂáΩÊï∞‰∏ÄÊ†∑ÂæóÂà∞ÂÖ®Â±ÄÊúÄ‰ºòËß£„ÄÇÁ§∫‰æãÂ¶Ç‰∏ã„ÄÇ ÊâÄ‰ª•Âú®ÈÄªËæëÂõûÂΩí‰∏≠ÈúÄË¶ÅÈáçÊñ∞ÂÆö‰πâ‰ª£‰ª∑ÂáΩÊï∞Ôºö ÊúÄÂêéÂæóÂà∞ÁöÑÂáΩÊï∞hÂíåCostÂáΩÊï∞‰πãÂâçÁöÑÂÖ≥Á≥ªÂ¶Ç‰∏ãÔºö ÊûÑÂª∫‰∏Ä‰∏™ËøôÊ†∑ÁöÑÂáΩÊï∞ÁöÑÂ•ΩÂ§ÑÊòØÂú®‰∫éÔºåÂΩìy=1Êó∂Ôºåh=1ÔºåÂ¶ÇÊûúh‰∏ç‰∏∫1Êó∂ËØØÂ∑ÆÈöèÁùÄhÁöÑÂèòÂ∞èËÄåÂ¢ûÂ§ßÔºõÂêåÊ†∑ÔºåÂΩìy=0Êó∂Ôºåh=0ÔºåÂ¶ÇÊûúh‰∏ç‰∏∫0Êó∂ËØØÂ∑ÆÈöèÁùÄhÁöÑÂèòÂ§ßËÄåÂ¢ûÂ§ß„ÄÇ ‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÂú®‰∏ä‰∏ÄËäÇ‰∏≠ÁöÑÈÄªËæëÂõûÂΩí‰∏≠ÁöÑ‰ª£‰ª∑ÂáΩÊï∞‰∏≠ÁªôÂá∫‰∫Ü‰ª£‰ª∑ÂáΩÊï∞ÁöÑÂÆö‰πâ ÊúÄÂêéÂèØ‰ª•ÁÆÄÂåñ‰∏∫: ÊúÄÁªàÁöÑÊ±ÇËß£ÈóÆÈ¢òÂ∞±ÊòØË¶ÅÊ±ÇÂõûÂΩíÂáΩÊï∞ÁöÑÂÄºÊúÄÂ∞èÔºåÈÇ£‰πàÂêåÊ†∑ÂèØ‰ª•‰ΩøÁî®Âú®Á∫øÊÄßÂõûÂΩí‰∏≠ÊâÄÁî®Âà∞ÁöÑÊ¢ØÂ∫¶ÂáΩÊï∞„ÄÇ ‰∏äÂõæÂ∞±ÊòØÈÄªËæëÂõûÂΩíÁöÑÊ¢ØÂ∫¶Ê±ÇËß£ËøáÁ®ãÔºåËôΩÁÑ∂ÁúãËµ∑Êù•ÂíåÁ∫øÊÄßÂõûÂΩíÁõ∏‰ººÔºå‰ΩÜÂÆûÂàôÊòØÂÆåÂÖ®‰∏çÂêåÁöÑ„ÄÇÂú®Á∫øÊÄßÂõûÂΩí‰∏≠ÔºåhÂáΩÊï∞‰∏∫thetaÁöÑËΩ¨ÁΩÆ‰∏éXÁöÑ‰πòÁßØÔºå‰ΩÜÊòØÂú®ÈÄªËæëÂõûÂΩí‰∏≠Âàô‰∏çÊòØ„ÄÇËøôÊ†∑Â∞±ÂØºËá¥‰∫Ü‰∏§ËÄÖÂú®ËøêÁÆóÊñπÈù¢Âíå‰ºòÂåñÊñπÈù¢ÊòØÂÆåÂÖ®‰∏çÂêåÁöÑ„ÄÇ‰ΩÜÊòØÂú®ËøêË°åÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰πãÂâçÔºåËøõË°åÁâπÂæÅÁº©Êîæ‰æùÊóßÊòØÈùûÂ∏∏ÈáçË¶ÅÁöÑ„ÄÇ È´òÁ∫ß‰ºòÂåñ‰ºòÂåñÁÆóÊ≥ïÈô§‰∫ÜËÆ≤Âà∞ÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï‰πãÂ§ñÔºåËøòÊúâ‰∏Ä‰∫õÂè´ÂÅöÂÖ±ËΩ≠Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ï(BFGS,L-BFGS)„ÄÇ‰ΩøÁî®Ëøô‰∫õÂÖ±ËΩ≠Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÁöÑÂ•ΩÂ§ÑÂú®‰∫éÔºå‰∏çÈúÄË¶ÅÊâãÂä®Âú∞ÈÄâÊã©Â≠¶‰π†ÁéáaÔºåËøô‰∫õÁÆóÊ≥ï‰ºöËá™Ë°åÂ∞ùËØïÈÄâÊã©a;ÊØîÊ¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïËøêÁÆóÊõ¥Âø´„ÄÇ‰∏ÄËà¨ÊÉÖÂÜµ‰∏ãÔºåÂú®Â∏∏ËßÅÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂ∫ì‰∏≠ÈÉΩÂ∏¶ÊúâËøô‰∫õÁÆóÊ≥ïÔºå‰∏çÈúÄË¶ÅÁ®ãÂ∫èÂëòÊâãÂä®ÂÆûÁé∞Ëøô‰∫õÁÆóÊ≥ï„ÄÇ Â§öÁ±ªÂà´ÂàÜÁ±ªÈóÆÈ¢òÁé∞ÂÆû‰∏ñÁïå‰∏≠Èô§‰∫Ü‰∫åÂÖÉÁöÑÂàÜÁ±ªÈóÆÈ¢òËøòÊúâÂ§öÂÖÉÁöÑÂàÜÁ±ªÈóÆÈ¢òÔºå‰æãÂ¶ÇÈÇÆ‰ª∂ÁöÑÁ±ªÂûãÊúâÂ∑•‰ΩúÔºåÊúãÂèãÔºåÂÆ∂‰∫∫ÔºåÁà±Â•ΩÁ≠âÂ§öÁßçÔºåÂàÜÁ±ªÂà∞‰∏çÂêåÁöÑÊñá‰ª∂Â§π‰∏ãÔºåÂ¶ÇÂØπÂ§©Ê∞îÁöÑÂàÜÁ±ªÔºåÊòØÊô¥Â§©„ÄÅÂ§ö‰∫ë„ÄÅÂ∞èÈõ®Á≠âÁ≠âÂ§©Ê∞î„ÄÇ Â§öÂÖÉÂàÜÁ±ªÈóÆÈ¢ò‰∏é‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÁöÑÂå∫Âà´Â¶Ç‰∏ã:Â§öÂÖÉÂàÜÁ±ªÁöÑÊÄùË∑Ø‰∏é‰∫åÂÖÉÂàÜÁ±ªÈóÆÈ¢òÁöÑËß£ÂÜ≥ÊÄùË∑ØÊòØÁ±ª‰ººÁöÑ„ÄÇÂèØ‰ª•Â∞ÜÂ§öÂÖÉÈóÆÈ¢òÂèò‰∏∫‰∏§ÂÖÉÈóÆÈ¢òÔºåÂÖ∑‰ΩìÂ¶Ç‰∏ãÔºö ËøôÊ†∑nÂÖÉÁöÑÂàÜÁ±ªÈóÆÈ¢òÔºåÂ∞±‰ºöËøõË°ånÊ¨°ÁöÑÊú∫Âô®Â≠¶‰π†ÁöÑÂàÜÁ±ªÁÆóÊ≥ï„ÄÇÂØπÊØè‰∏ÄÊ¨°ÁöÑÂàÜÁ±ªÁªìÊûúÂç≥‰∏∫h(x)„ÄÇÈÇ£‰πàÁªèËøánÊ≠§ÂàÜÁ±ª‰πãÂêéÔºåÊúÄÂêéÂæóÂà∞ÁöÑÁªìÊûú‰∏∫: ÈÇ£‰πàÂΩìËæìÂÖ•Êñ∞ÁöÑËÆ≠ÁªÉÈõÜÊàñËÄÖÊòØÂèòÈáèXÔºåÂè™ÈúÄË¶ÅÊåâÁÖß‰∏äÈù¢ÁöÑÊÄùË∑ØËøõË°åÂàÜÁ±ªÔºåÂÖ∂‰∏≠ÁöÑh(x)ÁöÑÊúÄÂ§ßÂÄºÂ∞±ÊòØÂØπÂ∫îÁöÑÊúÄÂêéÁöÑÂàÜÁ±ªÁªìÊûú„ÄÇ ÊÄªÁªìÊú¨Á´†ÂÜôÂÆåÁî®‰∫Ü‰∏ÄÂë®Êó∂Èó¥Ôºå‰ΩÜÂÖ∂ÂÆûËßÜÈ¢ë‰∏ÄÂ§©Â∞±ÁúãÂÆå‰∫ÜÔºåÂçöÂÆ¢ÂÜÖÂÆπÂü∫Êú¨ÊòØÁÖßÊäÑÂà´‰∫∫ÁöÑÔºåÂÖ≥‰∫éÂÖ∑‰ΩìÁöÑ‰ª£Á†ÅÂÆûÁé∞Êü•ÁúãÂè¶‰∏ÄÁØáÂçöÂÆ¢„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†ÔºàÂõõÔºâ]]></title>
    <url>%2F2018%2F04%2F23%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÂâçÂõõÁ´†ÁöÑÂÜÖÂÆπÂ≠¶‰π†ÂÆåÊØïÔºåÁ¨¨‰∫îÁ´†ËÆ≤‰∫ÜOctaveËøô‰∏™ËΩØ‰ª∂ÁöÑ‰ΩøÁî®ÔºåÁ±ª‰ºº‰∫ématlabÔºåÂ§ßÂ≠¶ÊúâËøáÂ≠¶‰π†matlabÁªèÈ™åÊâÄ‰ª•Ëøô‰∏™Â≠¶Ëµ∑Êù•ÊÉ≥ÂØπÊØîËæÉËΩªÊùæÔºå‰∏çËÆ∫ÊòØÂú®UbuntuËøòÊòØwindowsÂÆâË£ÖÈÉΩÂæàÁÆÄÂçïÔºåËøô‰∏™ÁöÑÁïåÈù¢Â∏ÉÂ±ÄÈÉΩÂíåmatlabÂü∫Êú¨‰∏ÄÊ®°‰∏ÄÊ†∑„ÄÇ ËôΩÁÑ∂Áî®pythonÈÉΩÂèØ‰ª•ÂÆûÁé∞Ôºå‰ΩÜOctaveÂºÄÊ∫êÂÖçË¥πÔºåÊØînumpyÊõ¥ÁÆÄÂçïÁöÑÂÆûÁé∞ÁÆóÊ≥ïÔºåÊâÄ‰ª•ÊúâÂøÖË¶ÅÂ≠¶‰π†‰∏Ä‰∏ã„ÄÇ ÂÖ∂ÂÆûÂÖ≥‰∫éOctaveÁöÑ‰∏úË•øÂπ∂‰∏çÊÉ≥ËÆ∞ÂΩïÔºåÂíåmatlab‰∏ÄÊ†∑Ôºå‰ΩÜ‰∏∫‰∫ÜËøô‰∏™ÂçöÂÆ¢ÁöÑÂÆåÊï¥ÊÄßËøòÊòØÁÆÄÂçïÁöÑËÆ∞ÂΩï‰∏Ä‰∏ãÔºåÊàë‰ΩøÁî®ÁöÑÊòØwindowsÁâàÁöÑÁõ¥Êé•ÊâìÂºÄGUIÂ∞±ËÉΩ‰ΩøÁî®‰∫Ü„ÄÇ Âü∫Êú¨Êìç‰Ωú12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152%Âü∫Êú¨ÂõõÂàôËøêÁÆó&gt;&gt; 1+2ans = 3&gt;&gt; 6-1ans = 5&gt;&gt; 5*8ans = 40&gt;&gt; 1/5ans = 0.20000&gt;&gt; 3^6ans = 729%‰∏çÁ≠âÂè∑ÊòØ~ËÄå‰∏çÊòØÔºÅ&gt;&gt; 1==2ans = 0&gt;&gt; 1~=2ans = 1%‰∏é Êàñ ÂºÇÊàñ&gt;&gt; 8 &gt; 1 &amp;&amp; 0ans = 0&gt;&gt; 9 &gt; 1 || 0ans = 1&gt;&gt; xor(1, 0)ans = 1%Â¶ÇÊûú‰Ω†ÊÉ≥ÂàÜÈÖç‰∏Ä‰∏™ÂèòÈáèÔºå‰ΩÜ‰∏çÂ∏åÊúõÂú®Â±èÂπï‰∏äÊòæÁ§∫ÁªìÊûúÔºå‰Ω†ÂèØ‰ª•Âú®ÂëΩ‰ª§ÂêéÂä†‰∏Ä‰∏™ÂàÜÂè∑ÔºåÂèØ‰ª•ÊäëÂà∂ÊâìÂç∞ËæìÂá∫ÔºåÊï≤ÂÖ•ÂõûËΩ¶ÂêéÔºå‰∏çÊâìÂç∞‰ªª‰Ωï‰∏úË•ø„ÄÇ&gt;&gt; a = 3a = 3&gt;&gt; a = 3;&gt;&gt; b = 'hello word';&gt;&gt; bb = hello word%ËÆæÁΩÆAÁ≠â‰∫éÂúÜÂë®ÁéáœÄÔºåÂ¶ÇÊûúÊàëË¶ÅÊâìÂç∞ËØ•ÂÄºÔºåÈÇ£‰πàÂè™ÈúÄÈîÆÂÖ•AÂÉèËøôÊ†∑Â∞±ÊâìÂç∞Âá∫Êù•‰∫Ü„ÄÇ&gt;&gt; a = pi;&gt;&gt; pians = 3.1416&gt;&gt; aa = 3.1416&gt;&gt; disp(sprintf('2 decimals: %0.12f', a))2 decimals: 3.141592653590ËøôÊòØ‰∏ÄÁßçÔºåÊóßÈ£éÊ†ºÁöÑCËØ≠Ë®ÄËØ≠Ê≥ïÔºåÂØπ‰∫é‰πãÂâçÂ∞±Â≠¶ËøáCËØ≠Ë®ÄÁöÑÂêåÂ≠¶Êù•ËØ¥Ôºå‰Ω†ÂèØ‰ª•‰ΩøÁî®ËøôÁßçÂü∫Êú¨ÁöÑËØ≠Ê≥ïÊù•Â∞ÜÁªìÊûúÊâìÂç∞Âà∞Â±èÂπï„ÄÇ‰æãÂ¶Ç sprintfÂëΩ‰ª§ÁöÑÂÖ≠‰∏™Â∞èÊï∞Ôºö0.6%f ,aÔºåËøôÂ∫îËØ•ÊâìÂç∞œÄÁöÑ6‰ΩçÂ∞èÊï∞ÂΩ¢Âºè„ÄÇ‰πüÊúâ‰∏Ä‰∫õÊéßÂà∂ËæìÂá∫ÈïøÁü≠Ê†ºÂºèÁöÑÂø´Êç∑ÂëΩ‰ª§Ôºö&gt;&gt; format long&gt;&gt; aa = 3.14159265358979&gt;&gt; format short&gt;&gt; aa = 3.1416 ÁÆÄÂçïÁöÑËøêÁÆóÁ¨¶Â∞±ÊòØËøô‰∫õÔºåÈáçÁÇπÊòØÂÖ≥‰∫éÁü©ÈòµÁöÑ ÁÆÄÂçïÁü©ÈòµÁöÑÂàõÂª∫1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495ÁÆÄÂçïÁü©ÈòµÁöÑÂàõÂª∫&gt;&gt; A = [1 2; 3 4; 5 6]A = 1 2 3 4 5 6&gt;&gt; A = [2 2;3 3;4 4]A = 2 2 3 3 4 4&gt;&gt; B = [1 2 3]B = 1 2 3&gt;&gt; B = [1; 2; 3]B = 1 2 3&gt;&gt;Ëøô‰∏™ÈõÜÂêàVÊòØ‰∏ÄÁªÑÂÄºÔºå‰ªéÊï∞ÂÄº1ÂºÄÂßãÔºåÂ¢ûÈáèÊàñËØ¥ÊòØÊ≠•Èïø‰∏∫0.1ÔºåÁõ¥Âà∞Â¢ûÂä†Âà∞2ÔºåÊåâÁÖßËøôÊ†∑ÁöÑÊñπÊ≥ïÂØπÂêëÈáèVÊìç‰ΩúÔºåÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™Ë°åÂêëÈáèÔºåËøôÊòØ‰∏Ä‰∏™1Ë°å11ÂàóÁöÑÁü©ÈòµÔºåÂÖ∂Áü©ÈòµÁöÑÂÖÉÁ¥†ÊòØ1 1.1 1.2 1.3Ôºå‰æùÊ≠§Á±ªÊé®ÔºåÁõ¥Âà∞Êï∞ÂÄº2„ÄÇÊàë‰πüÂèØ‰ª•Âª∫Á´ã‰∏Ä‰∏™ÈõÜÂêàVÂπ∂Áî®ÂëΩ‰ª§‚Äú1:6‚ÄùËøõË°åËµãÂÄºÔºåËøôÊ†∑VÂ∞±Ë¢´ËµãÂÄº‰∫Ü1Ëá≥6ÁöÑÂÖ≠‰∏™Êï¥Êï∞„ÄÇ&gt;&gt; v = 1:6v = 1 2 3 4 5 6ËøôÈáåËøòÊúâ‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÊñπÊ≥ïÊù•ÁîüÊàêÁü©Èòµ‰æãÂ¶Ç‚Äúones(2,3)‚ÄùÔºå‰πüÂèØ‰ª•Áî®Êù•ÁîüÊàêÁü©ÈòµÔºö&gt;&gt; ones(2,3)ans = 1 1 1 1 1 1ÂÖÉÁ¥†ÈÉΩ‰∏∫2Ôºå‰∏§Ë°å‰∏âÂàóÁöÑÁü©ÈòµÔºåÂ∞±ÂèØ‰ª•‰ΩøÁî®Ëøô‰∏™ÂëΩ‰ª§Ôºö&gt;&gt; C = 2*ones(2,3)C = 2 2 2 2 2 2‰Ω†ÂèØ‰ª•ÊääËøô‰∏™ÊñπÊ≥ïÂΩìÊàê‰∏Ä‰∏™ÁîüÊàêÁü©ÈòµÁöÑÂø´ÈÄüÊñπÊ≥ï„ÄÇw‰∏∫‰∏Ä‰∏™‰∏ÄË°å‰∏âÂàóÁöÑÈõ∂Áü©ÈòµÔºå‰∏ÄË°å‰∏âÂàóÁöÑAÁü©ÈòµÈáåÁöÑÂÖÉÁ¥†ÂÖ®ÈÉ®ÊòØÈõ∂Ôºö&gt;&gt; W = zeros(1,3)W = 0 0 0Â¶ÇÊûúÊàëÂØπWËøõË°åËµãÂÄºÔºåÁî®RandÂëΩ‰ª§Âª∫Á´ã‰∏Ä‰∏™‰∏ÄË°å‰∏âÂàóÁöÑÁü©ÈòµÔºåÂõ†‰∏∫‰ΩøÁî®‰∫ÜRandÂëΩ‰ª§ÔºåÂàôÂÖ∂‰∏ÄË°å‰∏âÂàóÁöÑÂÖÉÁ¥†Âùá‰∏∫ÈöèÊú∫ÂÄºÔºåÂ¶Ç‚Äúrand(3, 3)‚ÄùÂëΩ‰ª§ÔºåËøôÂ∞±ÁîüÊàê‰∫Ü‰∏Ä‰∏™3√ó3ÁöÑÁü©ÈòµÔºåÂπ∂‰∏îÂÖ∂ÊâÄÊúâÂÖÉÁ¥†Âùá‰∏∫ÈöèÊú∫„ÄÇ&gt;&gt; rand(3,3)ans = 0.60790 0.22000 0.10036 0.61343 0.58981 0.17660 0.22697 0.88276 0.42049&gt;&gt;‰Ω†Áü•ÈÅì‰ªÄ‰πàÊòØÈ´òÊñØÈöèÊú∫ÂèòÈáèÔºåÊàñËÄÖÔºå‰Ω†Áü•ÈÅì‰ªÄ‰πàÊòØÊ≠£ÊÄÅÂàÜÂ∏ÉÁöÑÈöèÊú∫ÂèòÈáèÔºå‰Ω†ÂèØ‰ª•ËÆæÁΩÆÈõÜÂêàWÔºå‰ΩøÂÖ∂Á≠â‰∫é‰∏Ä‰∏™‰∏ÄË°å‰∏âÂàóÁöÑNÁü©ÈòµÔºåÂπ∂‰∏îÔºåÊù•Ëá™‰∏â‰∏™ÂÄºÔºå‰∏Ä‰∏™Âπ≥ÂùáÂÄº‰∏∫0ÁöÑÈ´òÊñØÂàÜÂ∏ÉÔºåÊñπÂ∑ÆÊàñËÄÖÁ≠â‰∫é1ÁöÑÊ†áÂáÜÂÅèÂ∑Æ„ÄÇ&gt;&gt; w = randn(1,3)w = -1.24688 1.87417 -0.70878Âπ∂Áî®histÂëΩ‰ª§ÁªòÂà∂Áõ¥ÊñπÂõæ„ÄÇ&gt;&gt; w = -9 + sqrt(10)*(randn(1, 10000));&gt;&gt; hist(w)&gt;&gt; hist(w,50)ÁªòÂà∂Âçï‰ΩçÁü©ÈòµÔºö&gt;&gt; I = eye(6)I =Diagonal Matrix 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1ÂØπÂëΩ‰ª§‰∏çÊ∏ÖÊ•öÂèØ‰ª•ÈÄöËøáhelpÂëΩ‰ª§Êü•ËØ¢ sizeÂáΩÊï∞123456789101112131415161718&gt;&gt; A = [1: 2; 3 4; 5 6]A = 1 2 3 4 5 6&gt;&gt; size(A) %ËæìÂá∫[Ë°åÊï∞ ÂàóÊï∞]ans = 3 2&gt;&gt; size(A, 1) %Ë°åÊï∞ans = 3&gt;&gt; size(A, 2) %ÂàóÊï∞ans = 2&gt;&gt; length(A) %Ë°åÊï∞ÂíåÂàóÊï∞‰∏≠ÊúÄÂ§ßÂÄºans = 3 ÂØºÂÖ•‰∏éÂØºÂá∫Êï∞ÊçÆ123456load Êñá‰ª∂Âêçwhos %Â∞ÜÂΩìÂâçÁöÑÂèòÈáèÈÉΩÊòæÁ§∫Âá∫Êù•clear A %Â∞ÜÂèòÈáèAÂà†Èô§save hello.mat A; %Â∞ÜÂèòÈáèAÂ≠òÂÖ•hello.matÊñá‰ª∂save hello.txt A -ascii; %Â∞ÜAÂ≠ò‰∏∫ascii ÂèñÁü©Èòµ‰∏≠ÁöÑÂÄº123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&gt;&gt; AA = 1 2 3 4 5 6&gt;&gt; A(3,2) %Áü©ÈòµAÁ¨¨‰∏âË°åÁ¨¨‰∫åÂàóÁöÑÊï∞ans = 6&gt;&gt; A(2,:) %Á¨¨‰∫åË°åÁöÑÊï∞ans = 3 4&gt;&gt; A(:,2) %Á¨¨‰∫åÂàóÁöÑÊï∞ans = 2 4 6&gt;&gt; A([1 3],:) %Á¨¨‰∏ÄË°åÂíåÁ¨¨‰∏âË°åÁöÑÊï∞ans = 1 2 5 6&gt;&gt; A(:,2) = [10;11;12] %‰øÆÊîπÁ¨¨‰∫åÂàóÁöÑÊï∞A = 1 10 3 11 5 12&gt;&gt; A = [A,[100;200;300]] %Â¢ûÂä†‰∏ÄÂàóÊï∞ÊçÆA = 1 10 100 3 11 200 5 12 300&gt;&gt; A(:) %‰øÆÊîπ‰∏∫‰∏ÄÂàóÂêëÈáèans = 1 3 5 10 11 12 100 200 300 ÊãºÊé•Áü©Èòµ12345678910111213141516171819202122232425262728293031&gt;&gt; A = [1 2; 3 4; 5 6]A = 1 2 3 4 5 6&gt;&gt; B = [11 12; 13 14; 15 16]B = 11 12 13 14 15 16&gt;&gt; C = [A B] %Â∞ÜÁü©ÈòµAÂíåBÂπ∂ÂàóÊãºÊé•C = 1 2 11 12 3 4 13 14 5 6 15 16&gt;&gt; C = [A;B] %Âä†ÂàÜÂè∑ÊòØÂ∞ÜBÁü©ÈòµÊãºÊé•Âà∞A‰∏ãÈù¢C = 1 2 3 4 5 6 11 12 13 14 15 16&gt;&gt; Áü©ÈòµËÆ°ÁÆó12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&gt;&gt; a = [1 2; 3 4; 5 6]a = 1 2 3 4 5 6&gt;&gt; B = [11 22; 33 44; 55 66]B = 11 22 33 44 55 66&gt;&gt; C = [1 1; 2 2]C = 1 1 2 2&gt;&gt; V = [1; 2; 3]V = 1 2 3&gt;&gt; A*C %Áü©ÈòµÁõ∏‰πòans = 5 5 11 11 17 17&gt;&gt; A*B %Áõ∏‰πòÊù°‰ª∂ÂøÖÈ°ªÊòØAÁü©ÈòµÁöÑÂàóÁ≠â‰∫éBÁü©ÈòµÁöÑË°åÔºåÂê¶ÂàôÊä•Èîôerror: operator *: nonconformant arguments (op1 is 3x2, op2 is 3x2)&gt;&gt; A.*2 %Áü©Èòµ‰∏≠ÁöÑÊØè‰∏™ÂÖÉÁ¥†ÈÉΩ‰πò‰∫åans = 2 4 6 8 10 12&gt;&gt; A.^2 %ÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂπ≥Êñπans = 1 4 9 16 25 36&gt;&gt; 1./V %ÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂÄíÊï∞ans = 1.00000 0.50000 0.33333 &gt;&gt; V + ones(length(V), 1) %ÊØè‰∏™ÂÖÉÁ¥†ÈÉΩÂä†‰∏Äans = 2 3 4&gt;&gt; A' %AÁöÑËΩ¨ÁΩÆans = 1 3 5 2 4 6&gt;&gt; Áü©ÈòµÁöÑÁ¥¢Âºï123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119&gt;&gt; a = [1 15 2 0.5]a = 1.00000 15.00000 2.00000 0.50000&gt;&gt; [val,ind] = max(a) % val Áü©Èòµ‰∏≠ÁöÑÊúÄÂ§ßÂÖÉÁ¥†Ôºåind ÊúÄÂ§ßÂÄºÁöÑindexval = 15ind = 2&gt;&gt; val = max(A) %Áü©ÈòµÊØèÂàóÁöÑÊúÄÂ§ßÂÄºval = 5 6&gt;&gt; a &lt; 3 %Ê£ÄÊü•Áü©Èòµ‰∏≠ÊØî3Â∞èÁöÑÂÖÉÁ¥†ÔºåËøîÂõûÂ∏ÉÂ∞îÂûãans = 1 0 1 1&gt;&gt; find(a&lt;3) %ÊØî3Â∞èÁöÑÂÖÉÁ¥†ÁöÑ‰ΩçÁΩÆans = 1 3 4&gt;&gt; A = magic(3) %ÂàõÂª∫‰∏Ä‰∏™ÂπªÊñπ ÔºàË°åÔºåÂàóÔºåÂØπËßíÁ∫øÁõ∏Âä†ÊÉ≥Á≠âÔºâA = 8 1 6 3 5 7 4 9 2&gt;&gt; [r c] = find(A&gt;=7) % Á¨¶ÂêàA&gt;=7ÂÖÉÁ¥†ÁöÑË°åÂàóÂùêÊ†ár = 1 3 2c = 1 2 3&gt;&gt; sum(a) %Ê±ÇÊâÄÊúâÂÖÉÁ¥†ÁöÑÂíåans = 18.500&gt;&gt; prod(A) %Ê±ÇÊØèÂàóÁöÑ‰πòÁßØans = 96 45 84&gt;&gt; sum(A) %Ê±ÇÊØèÂàóÁöÑÂíåans = 15 15 15&gt;&gt; floor(a) %ËøîÂõûÂ∞è‰∫éÂÖÉÁ¥†ÁöÑÊúÄÂ∞èÊï¥Êï∞ans = 1 15 2 0&gt;&gt; ceil(a) %ËøîÂõûÂ§ß‰∫éÂÖÉÁ¥†ÁöÑÊúÄÂ§ßÊï¥Êï∞ans = 1 15 2 1&gt;&gt; max(rand(3), rand(3)) %ÊØîËæÉ‰∏§‰∏™Áü©ÈòµËøîÂõûÊúÄÂ§ßÂÄºans = 0.65329 0.32803 0.23948 0.56627 0.37716 0.64170 0.17771 0.81867 0.73937&gt;&gt; max(A, [], 1) %ËøîÂõûÊØè‰∏ÄÂàóÁöÑÊúÄÂ§ßÂÄºans = 8 9 7&gt;&gt; max(A, [], 2) %ËøîÂõûÊØè‰∏ÄË°åÁöÑÊúÄÂ§ßÂÄºans = 8 7 9&gt;&gt; A = magic(9)A = 47 58 69 80 1 12 23 34 45 57 68 79 9 11 22 33 44 46 67 78 8 10 21 32 43 54 56 77 7 18 20 31 42 53 55 66 6 17 19 30 41 52 63 65 76 16 27 29 40 51 62 64 75 5 26 28 39 50 61 72 74 4 15 36 38 49 60 71 73 3 14 25 37 48 59 70 81 2 13 24 35&gt;&gt; sum(A,2) %Ë°åÁöÑÂíåans = 369 369 369 369 369 369 369 369 369&gt;&gt; sum(A,1) %ÂàóÁöÑÂíåans = 369 369 369 369 369 369 369 369 369&gt;&gt; sum(sum(A.* eye(9))) %ÂØπËßíÁ∫øÁöÑÂíåans = 369&gt;&gt; pinv(A) %‰º™ÈÄÜÁü©Èòµ ÁîªÂõæ123&gt; t = [0 : 0.01 : 0.98];&gt;&gt; y1 = sin(2*pi*4*t);&gt;&gt; plot(t, y1,'r') Âú®‰∏Ä‰∏™ÁîªÂ∏É‰∏äÁîª‰∏§ÂâØÂ¶ÇÂõæ12345&gt;&gt; y1 = sin(2*pi*4*t);&gt;&gt; y2 = cos(2*pi*4*t);&gt;&gt; plot(t,y2)&gt;&gt; hold on;&gt;&gt; plot(t, y1,'r') Âπ∂ÂàóÊòæÁ§∫‰∏§‰∏™Âõæ12345&gt;&gt; subplot(1,2,1)&gt;&gt; plot(t,y1)&gt;&gt; subplot(1,2,2)&gt;&gt; plot(t,y2)&gt;&gt; axis([0.5 1 -1 1]) ÁªòÂà∂Áü©Èòµ12345678910&gt;&gt; A = magic(5)A = 17 24 1 8 15 23 5 7 14 16 4 6 13 20 22 10 12 19 21 3 11 18 25 2 9&gt;&gt; imagesc(A) 1&gt;&gt; imagesc(A),colorbar,colormap gray; ÊéßÂà∂ËØ≠Âè•1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556%forÂæ™ÁéØËØ≠Âè•&gt;&gt; v = zeros(1,10)v = 0 0 0 0 0 0 0 0 0 0&gt;&gt; for i = 1: 10v(i) = 2^i;end;&gt;&gt; vv = 2 4 8 16 32 64 128 256 512 1024&gt;&gt;%whileËØ≠Âè•&gt;&gt; while i &lt; 5,v(i) = 100;i = i+1end&gt;&gt; vv = 2 4 8 16 32 64 128 256 512 1024%if breakËØ≠Âè•&gt;&gt; i = 1;&gt;&gt; while true;v(i) = 999;i = i+1if i==6,break;endendi = 2i = 3i = 4i = 5i = 6&gt;&gt; vv = 999 999 999 999 999 64 128 256 512 1024&gt;&gt;&gt;&gt; if v(1) == 1,disp('The value is one!')elseif v(1) == 2,disp('The value is two!')elsedisp('The value is not one or two!')endThe value is not one or two!&gt;&gt; ÂÆö‰πâÂáΩÊï∞Â∞ÜÂáΩÊï∞ÂÆö‰πâÂÜôÂú®Êñá‰ª∂‰∏≠ÔºåÂπ∂ÊääÊñá‰ª∂ÂêçÂëΩÂêç‰∏∫‚ÄòÂáΩÊï∞Âêç.m‚ÄôÔºåÂ∞ÜÊñá‰ª∂ÊîæÂú®ÂΩìÂâçË∑ØÂæÑ‰∏ãÔºåÊàñËÄÖÁî® addpath Â∞ÜÊñá‰ª∂ÁõÆÂΩïÂä†ÂÖ•ÂΩìÂâç‰ºöËØù Êú¨Á´†Â≠¶‰π†ÁªìÊùü]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>octave</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DragonBoard-410CÂºÄÂèëÁéØÂ¢ÉÊê≠Âª∫]]></title>
    <url>%2F2018%2F04%2F19%2FDragonBoard-410C%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ÂàùËØÜDragonBoard 410cDragonBoard 410cÊòØ‰∏ÄÊ¨æÊê≠ËΩΩQualcomm¬Æ Snapdragon‚Ñ¢ 410Ôºà64‰ΩçÁöÑÂõõÊ†∏Â§ÑÁêÜÂô®ÔºâÁöÑÂºÄÂèëÊùøÔºåÂÆÉÂäüËÉΩÈΩêÂÖ®ÔºåÂÖ∑ÊúâÂº∫Â§ßÁöÑÂ§ÑÁêÜËÉΩÂäõÔºåÂÜÖÁΩÆ 8GB eMMC (ÊîØÊåÅÊ†áÂáÜmicroSDÂç°ÊßΩ)ÔºåÂπ∂‰∏îËøòÂÜÖÁΩÆwifi„ÄÅËìùÁâô„ÄÅÂíåGPSÊ®°ÂùóÔºåÂÖ∑ÊúâHDMI ËæìÂá∫ÂèäUSB Êé•Âè£ (3‰∏™)„ÄÇÊâÄÊúâËøô‰∫õÈõÜÊàêÂà∞Âè™Êúâ‰ø°Áî®Âç°Â§ßÂ∞èÁöÑ‰∏ÄÂùóÊùøÂ≠ê‰∏äÔºåÂîÆ‰ª∑‰ªÖ‰∏∫75ÁæéÂÖÉ„ÄÇÊâÄÊúâÁöÑËøô‰∏ÄÂàá‰ΩøÂæóDragonBoard 410cÊàê‰∏∫ÂµåÂÖ•ÂºèËÆ°ÁÆó‰ª•ÂèäÁâ©ËÅîÁΩëÔºàIoTÔºâ‰∫ßÂìÅÁöÑÁêÜÊÉ≥ÈÄâÊã©Ôºå‰æãÂ¶Ç‰∏ã‰∏Ä‰ª£ÁöÑÊú∫Âô®‰∫∫ÔºåÊëÑÂÉèÂ§¥ÔºåÂåªÁñóËÆæÂ§áÔºåËá™Âä®ÂîÆË¥ßÊú∫ÔºåÊô∫ËÉΩÂª∫Á≠ëÔºåÊï∞Â≠óÊ†áÁâåÔºåËµåÂú∫Ê∏∏ÊàèÊú∫Á≠âÁ≠â„ÄÇDragonBoard 410c DragonBoard 410c ÂÖºÂÆπ96BoardsÊ∂àË¥πÁâàÔºàCEÔºâËßÑËåÉÔºåËØ•ËßÑËåÉÁî±LinaroÁ§æÂå∫ÂßîÂëò‰ºöÁªÑÁªáÁª¥Êä§ÔºåÂÆö‰ΩçÁßªÂä®„ÄÅÂµåÂÖ•ÂèäÊï∞Â≠óÂÆ∂Â∫≠È¢ÜÂüü„ÄÇ DragonBoard 410cÁõÆÂâçÂ∑≤ÁªèÂèØ‰ª•ËøêË°åAndroid5.1„ÄÅUbuntu‰ª•ÂèäWindows 10 IoT CoreÁ≠âÁ≥ªÁªüÔºåÂπ∂‰∏îÊòØÈ¶ñÊâπÂèñÂæóÂæÆËΩØËÆ§ËØÅÁöÑËÆæÂ§á‰πã‰∏ÄÔºåËÆ§ËØÅÂêéÂèØÊîØÊåÅAzure IoT SDKÔºåÂèØÈöèÊó∂Áî®‰∫éÁâ©ËÅîÁΩëÂ∫îÁî®„ÄÇ # ÂºÄÂèëÁéØÂ¢ÉÁöÑÊê≠Âª∫Êú¨Ê¨°ÂºÄÂèëÁéØÂ¢ÉÁöÑÊê≠Âª∫ÈÉΩÊòØÂú®windows‰∏ãÂÆåÊàê Âà∑‰∏∫LinuxÁ≥ªÁªü410CÂºÄÂèëÊùøËá™Â∏¶ÂÆâÂçìÁ≥ªÁªüÔºåÈÄöËøáHDMIËøûÊé•ÊòæÁ§∫Âô®Âç≥ÂèØÊòæÁ§∫ÔºåÈÄöËøáUSBËøûÊé•ÈîÆÁõòÈº†Ê†áËøõË°åÊìç‰Ωú„ÄÇÊ≠§Ê¨°ÂºÄÂèëÁéØÂ¢ÉË¶ÅÊ±ÇÊòØLinuxÔºåÊâÄ‰ª•Ë¶ÅÈáçÂà∑Á≥ªÁªüÔºåÂÆòÊñπÊèê‰æõÁöÑÊòØdebianÊ∑±Â∫¶‰øÆÊîπÁöÑÁ≥ªÁªüÔºåÈ´òÈÄöËµ∑ÂêçÂè´linaro„ÄÇLinuxÂÜÖÊ†∏‰∏∫4.140. &gt;&gt;&gt;ÈïúÂÉè‰∏ãËΩΩËøûÊé•ÁÇπËøôÈáå&gt;&gt;&gt;Win32DiskImagerÂç°Âà∑Â∑•ÂÖ∑ÁÇπËøôÈáå ËøôÈáåÊàëÈÄâÊã©‰∫ÜÊúÄÊñ∞ÁöÑ18.01ÁöÑÂç°Âà∑img ÂÜôÂÖ•LinuxÈïúÂÉèÂà∞SDÂç°Êìç‰ΩúÊ≠•È™§Â¶Ç‰∏ãÔºö12345‚óè ‰∏ãËΩΩWin32DiskImagerÂíåÂç°Âà∑ÈïúÂÉè‚óè ÊâìÂºÄDisklmagerÂ∑•ÂÖ∑‚óè ÈÄâÊã©ÈïúÂÉèÊñá‰ª∂Ë∑ØÂæÑ‚óè ÈÄâÊã©ÁîµËÑëÊò†Â∞ÑÁöÑSDÂç°ÁõòÁ¨¶‚óè ÁÇπÂáª Write ÊääÈïúÂÉèÂÜôÂÖ•SDÂç° ‰ΩøÂºÄÂèëÊùø‰ªéSDÂç°ÂêØÂä®Ôºö12345678‚óè Âú®ÂºÄÂèëÊùø‰∏äÊèíÂÖ•ÂÜôÂ•ΩÈïúÂÉèÁöÑsdÂç°‚óè ‰∏Ä‰∏™Èº†Ê†áÂíåÈîÆÁõòËøûÊé•Âà∞410C‰∏ä‚óè ÊòæÁ§∫Âô®ÈÄöËøáHDMIËøûÊé•Âà∞410C‰∏ä‚óè ËÆæÁΩÆÂêØÂä®ÂºÄÂÖ≥S6 - 0100(‰ªésdÂç°ÂêØÂä®)‚óè Êé•ÂÖ•ÁîµÊ∫ê‚óè ÂºÄÂèëÊùøÂ∫îËØ•‰ºöÂêØÂä®Âπ∂ÊòæÁ§∫‰∏Ä‰∏™ÂØπËØùÊ°Ü,ÈÄâÊã©Ë¶ÅÂÆâË£ÖÁöÑÊìç‰ΩúÁ≥ªÁªü‚óè ÈÄâÊã©ÊòæÁ§∫ÁöÑÊìç‰ΩúÁ≥ªÁªü(Linux Linaro)Âπ∂ÁÇπÂáª‚ÄúInstall‚Äù„ÄÇ‚óè Â¶ÇÊûú‰∏ÄÂàáÈÉΩÊàêÂäüËøõÂÖ•‰∏ã‰∏ÄÊ≠• ÈáçÂêØÂºÄÂèëÊùøÔºö1234‚óè ÊãîÊéâÁîµÊ∫êÁ∫ø‚óè ÊãÜ‰∏ãsdÂç°‚óè Â§ç‰ΩçÂêØÂä®ÂºÄÂÖ≥Ë∞ÉÂà∞0000‚óè ÈáçÂêØÂêéÂ∫îËØ•‰ºöÂºïÂØºËøõÂÖ•Êñ∞ÁöÑÁ≥ªÁªü ÈÄöËøáVisual StudioÁºñËØëË∞ÉËØï410CÁöÑÁ®ãÂ∫è‰∏™‰∫∫Êõ¥ÂñúÊ¨¢‰ΩøÁî®VSËÄå‰∏çÊòØEclipseÔºåÂ•ΩÂú®ËøôÊ¨æÂºÄÂèëÊùøÊîØÊåÅ‰ΩøÁî®VS2013Pro‰∫§ÂèâÁºñËØëÔºåÈ¶ñÂÖàÂÆâË£ÖVS2013Êàñ2012Ôºå‰∏çÊîØÊåÅÊõ¥È´òÁâàÊú¨„ÄÇ 1234567891011121314151617181920212223242526272829303132VS2013ÊóóËà∞Áâà/‰∏ì‰∏öÁâà/È´òÁ∫ßÁâà‰∫ßÂìÅÂØÜÈí•Visual Studio Ultimate 2013 KEYÔºàVS2013ÊóóËà∞ÁâàÂØÜÈí•ÔºâÔºöBWG7X-J98B3-W34RT-33B3R-JVYW9Visual Studio Premium 2013 KEYÔºàVS2013È´òÁ∫ßÁâàÂØÜÈí•ÔºâÔºöFBJVC-3CMTX-D8DVP-RTQCT-92494Visual Studio Professional 2013 KEYÔºàVS2013‰∏ì‰∏öÁâàÂØÜÈí•ÔºâÔºö XDM3T-W3T3V-MGJWK-8BFVD-GVPKYTeam Foundation Server 2013 KEYÔºàÂØÜÈí•ÔºâÔºöMHG9J-HHHX9-WWPQP-D8T7H-7KCQGVS2013ÂÆòÊñπ‰∏≠Êñá‰∏ì‰∏öÁâàÔºàVisual Studio Professional 2013ÔºâÂÆâË£ÖÊøÄÊ¥ªÊñπÊ≥ï1„ÄÅ‰∏ãËΩΩÂêéÂæóÂà∞ÁöÑÊòØISOÊñá‰ª∂ÔºåÁõ¥Êé•Ëß£ÂéãÁº©ÊàñÁî®ËôöÊãüÂÖâÈ©±Âä†ËΩΩËøêË°åÈÉΩÂèØ‰ª•2„ÄÅÊó†ÊâÄ‰∏çËóèÂú®ËøôÈáåÁõ¥Êé•Ëß£ÂéãÔºåÁÑ∂ÂêéÂèåÂáª‚Äúvs_ultimate.exe‚ÄùÂºÄÂßãÂÆâË£ÖÔºõ3„ÄÅËÆæÁΩÆÂ•ΩÂÆâË£ÖË∑ØÂæÑÂêéÔºåÁÇπÂáª‚ÄúÊàëÂêåÊÑèËÆ∏ÂèØÊù°Ê¨æÂíåÊù°‰ª∂‚ÄùÁÇπÂáª‚Äú‰∏ã‰∏ÄÊ≠•‚ÄùÁªßÁª≠Ôºõ4„ÄÅÈÄâÊã©ÊÇ®Ë¶ÅÂÆâË£ÖÁöÑVisual Studio 2013ÈÄâÈ°πÔºåÊ†πÊçÆËá™Ë∫´ÈúÄË¶ÅÂãæÈÄâÂÆâË£ÖÔºõ5„ÄÅÊé•‰∏ãÊù•Â∞±ÊòØÊúâÁÇπÊº´ÈïøÁöÑÂÆâË£ÖËøáÁ®ãÔºåËøôÊó∂ÂÄôÂ∞±ÊòØÊãºÁîµËÑëÈÖçÁΩÆÁöÑÊó∂ÂÄô‰∫ÜÔºõ6„ÄÅÊàêÂäüÂÆâË£ÖÂêéÊâìÂºÄËΩØ‰ª∂ÔºåËÆæÁΩÆÂ•ΩÁÜüÊÇâÁöÑÁéØÂ¢ÉÂêØÂä®ÔºàÂåÖÊã¨vb„ÄÅvc„ÄÅvfÁ≠âÂ§ö‰∏™ÂºÄÂèëÁéØÂ¢ÉÔºâ7„ÄÅÁ¨¨‰∏ÄÊ¨°ËøêË°åËΩØ‰ª∂‰ºöÊúâÁÇπÊÖ¢ÔºåÂÜçÁÇπÂáª‚ÄúÂ∏ÆÂä©‚Äù‚Äì‚ÄúÊ≥®ÂÜåËΩØ‰ª∂‚Äù‚ÄìÂèØ‰ª•ÁúãÂà∞ËΩØ‰ª∂Êúâ30Â§©ËØïÁî®ÊúüÔºåÁÇπÂáª‚ÄúÊõ¥ÊîπÊàëÁöÑ‰∫ßÂìÅËÆ∏ÂèØËØÅ‚ÄùÔºõ10„ÄÅËæìÂÖ•visual studio 2013‰∏ì‰∏öÁâàÂØÜÈí•„ÄêXDM3T-W3T3V-MGJWK-8BFVD-GVPKY„Äë11„ÄÅÂà∞ËøôÊ≠•Â∞±Â∑≤ÊàêÂäüÊøÄÊ¥ªvisual studio 2013‰∏ì‰∏öÁâà‰∫ÜÔºåÁé∞Âú®ÊÇ®ÂèØ‰ª•Êó†ÈôêÂà∂ÂÖçË¥π‰ΩøÁî®VS2013„ÄÇVS2013ÂÆòÊñπ‰∏≠Êñá‰∏ì‰∏öÁâàÔºàVisual Studio Professional 2013Ôºâ‰∏ãËΩΩÂú∞ÂùÄVisual Studio Professional 2013 with Update 5 (x86) ÂÆòÊñπ‰∏ì‰∏öÁâà‰∏ãËΩΩÂú∞ÂùÄÔºöed2k://|file|cn_visual_studio_professional_2013_with_update_5_x86_dvd_6815749.iso|5517246464|DEA9BB85B73F6A1F23E638DFE06CEF07|/ ÂÆâË£ÖÂ•Ωvisual studioÂêéÂÆâË£ÖsnapdragondebuggerforvsinstallerÔºåËß£ÂéãÂêéÂÆâË£ÖÂç≥ÂèØ„ÄÇ ‰ªÄ‰πàÊòØ Snapdragon Debugger for Visual StudioÔºü Snapdragon Debugger for Visual Studio ÊòØÂæÆËΩØ Visual Studio IDE ÁöÑ‰∏ÄÊ¨æÊèí‰ª∂Â∑•ÂÖ∑ÔºåÈíàÂØπÁõÆÂâçÊê≠ËΩΩÈ™ÅÈæôÂ§ÑÁêÜÂô®ÁöÑËÆæÂ§áÔºåÂèØË∞ÉËØïÂêÑÁßç API„ÄÇ ÁõÆÂâçËøôÊ¨æÂ∑•ÂÖ∑ÂèØÁî®‰∫éÂú® Microsoft Visual Studio ÁéØÂ¢É‰∏≠ÂàõÂª∫Âπ∂Ë∞ÉËØï Android NDKÂ∫îÁî®„ÄÇ‰ªÖÂèØË∞ÉËØïÂéüÁîü C/C++ ‰ª£Á†ÅÔºå‰∏çÊîØÊåÅË∞ÉËØï Java ‰ª£Á†Å„ÄÇ ÂÖ≥‰∫éÊõ¥Â§öËØ∑ÁúãSnapdragon Debugger for Visual Studio Âø´ÈÄüÂÖ•Èó®ÊåáÂçó Ëøô‰∏™Êèí‰ª∂ÂÆâË£ÖÈúÄË¶ÅËÆ∏Â§ö‰∏úË•øÔºåSDK,NDKÔºåËÄåÊàëÂè™ÊòØÈúÄË¶ÅÁºñËØëCÔºå‰∏çÊÉ≥Ë£ÖÂ§™Â§ö‰∏çÁî®ÁöÑ‰∏úË•øÔºå‰ΩÜÊòØÂèàÊÉ≥Áî®visual studioÔºåÂèØ‰ª•Áî®VSÊù•ËøúÁ®ãË∞ÉËØïLinuxÁ®ãÂ∫è Áî®VS2015ÂºÄÂèëLinuxÁ®ãÂ∫èvs2017Ëá™Â∏¶LinuxÂºÄÂèëÁéØÂ¢ÉÔºåÂèØÊÉúÊàëÂè™Ë£Ö‰∫Ü2015ÔºåÊâÄ‰ª•Â∞ùËØïÁî®2015Êù•ÂºÄÂèëLinuxÈúÄË¶Å‰∏Ä‰∏™Êèí‰ª∂Ôºö Visual C++ for Linux Development(VC_Linux.exe) ÈÄöËøáËøúÁ®ãSSHÂçèËÆÆÊó¢ÂèØ‰ª•Ë∞ÉËØï‰∫Ü Âõ†‰∏∫‰∏≠ÁæéË¥∏ÊòìÊàòÔºåÈ´òÈÄöÂèØËÉΩ‰∏çÁªô‰∏≠ÂõΩ‰æõË¥ß‰∫ÜÔºåÊâÄ‰ª•ÂÖ¨Âè∏ÊîπÁî®NXPÁöÑËäØÁâáÔºåËøô‰∏™È°πÁõÆÂ∞±ÊêÅÊµÖ‰∫ÜÔºåËØùËØ¥NXP‰∏ç‰πüË¢´È´òÈÄöÊî∂Ë¥≠‰∫ÜÂêó ÂèëÁé∞ÈóÆÈ¢òÔºöÊàëÈÄâÊã©ÁöÑ410CÂà∑ÁöÑimgÊòØdebian-283ÔºåÊúâ‰∏™ÈóÆÈ¢òÔºåWiFiËøûÊé•Âêé‰ºöÊó∂‰∏çÊó∂Ëá™Â∑±Êñ≠ÂºÄ‰ΩÜÊòØÊ°åÈù¢Âè≥‰∏ãËßíÁöÑwifiÂõæÊ†áÊòæÁ§∫Ê≠£Â∏∏ÔºåÊü•ÁúãÂÆòÁΩëÊõ¥Êñ∞Êó•ÂøóÔºåÂú®359Â∑≤Áªè‰øÆÂ§çËøô‰∏™ÈóÆÈ¢òÔºå‰ΩÜÊòØÂõ†‰∏∫‰∏≠ÁæéË¥∏ÊòìÊàòÁöÑÂéüÂõ†Êó†Ê≥ï‰ªéÈ´òÈÄöÂÆòÁΩë‰∏ãËΩΩÈïúÂÉè‰∫ÜÔºåÊâÄ‰ª•Ê≤°ÊúâÈ™åËØÅÊòØÂê¶ËøòÂ≠òÂú®Ê¨°BUG„ÄÇ]]></content>
      <categories>
        <category>ÂµåÂÖ•ÂºèÂºÄÂèë</category>
      </categories>
      <tags>
        <tag>ÂµåÂÖ•Âºè</tag>
        <tag>410C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PythonÂÆûÁé∞Ê¢ØÂ∫¶‰∏ãÈôç]]></title>
    <url>%2F2018%2F04%2F19%2FPython%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%2F</url>
    <content type="text"><![CDATA[Áúã‰∫ÜAndrew NgÁöÑÂÖ≥‰∫éÊú∫Âô®Â≠¶‰π†‰∏≠Ê¢ØÂ∫¶‰∏ãÈôçÁöÑÂ≠¶‰π†ÔºåÁî®ÊúÄÁÆÄÂçïÁ≤óÊö¥ÁöÑËß£Ê≥ïÂÆûÁé∞‰∏ã Ê≥®ÊÑèÁöÑÂú∞ÊñπÂ∞±ÊòØ$\theta_0,\theta_1$ÊòØÂêåÊó∂Êõ¥Êñ∞ÁöÑÔºåÊâÄ‰ª•Áî®‰∏Ä‰∏™‰∏¥Êó∂ÂèòÈáèÊé•‰∫Ü‰∏ã Êî∂ÊïõÊù°‰ª∂ÁöÑÂà§Êñ≠ÔºöÂèØ‰ª•ËÆ©ÂáΩÊï∞Ëø≠‰ª£ÊåáÂÆöÁöÑÊ¨°Êï∞ÂêéÈÄÄÂá∫Ôºå‰πüÂèØ‰ª•ËÆ§‰∏∫nÊ¨°Ëø≠‰ª£ÁöÑÁªìÊûúÂíån-1Ê¨°ÁöÑÁªìÊûúÈùûÂ∏∏Êé•ËøëÊó∂Â∞±‰ª£Ë°®‰∏ãÈôçÂà∞Ë∞∑Â∫ïÔºåÈÄÄÂá∫ÂáΩÊï∞ Ê≠•Êï∞alphaÁöÑËÆæÁΩÆÂíåepsilonÁöÑÈÄâÊã©ÔºåËøô‰∏™‰æãÂ≠êÊàëÂ∞ùËØïÊ≠•Êï∞‰∏∫0.0025Êó∂Â∞±‰ºöÊåØËç°Êó†Ê≥ïÊî∂ÊïõÔºåepsilonÁ≠â‰∫é‰∫é0.001Êó∂ÊúâÊó∂‰ºö‰∫ßÁîüÂ±ÄÈÉ®ÊúÄ‰ºòËß£ÔºåÂª∫ËÆÆÊòØ$10^{-4}$ ÊòéÂ§©ÁªßÁª≠Â∞ùËØïÊúÄÂ∞è‰∫å‰πòÊ≥ïÔºåËøô‰∏™‰ª£Á†ÅÂÜôÂæóÊØîËæÉloserÔºåÂÖàÊîæËøôÔºåÂ≠¶ÂÆåÂÜç‰ºòÂåñÔºåËÆ∞ÂΩï‰∏ãÁé∞Âú®Âíå‰ª•ÂêéÁöÑÊÄùËÄÉÊúâ‰ªÄ‰πàÂå∫Âà´12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/python# coding=utf-8import numpy as npfrom scipy import statsimport matplotlib.pyplot as pltimport math # This will import math module# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜ# x ÁâπÂæÅÂÄº# y ÂÆûÈôÖÁªìÊûúx = np.arange(0, 50, 1)m = len(x)y = x/2 + np.random.randn(m) -5# ÁªàÊ≠¢Êù°‰ª∂loop_max = 100000 # ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞(Èò≤Ê≠¢Ê≠ªÂæ™ÁéØ)epsilon = 1e-4 # Á≤æÁ°ÆÂ∫¶alpha = 0.002 # Ê≠•Èïø(Ê≥®ÊÑèÂèñÂÄºËøáÂ§ß‰ºöÂØºËá¥ÊåØËç°Âç≥‰∏çÊî∂Êïõ,ËøáÂ∞èÊî∂ÊïõÈÄüÂ∫¶ÂèòÊÖ¢)count = 0 # Âæ™ÁéØÊ¨°Êï∞finish = 0 # ÁªàÊ≠¢Ê†áÂøótheta = np.random.randn(2)# ÂàùÂßãÂåñtheta#theta = [0.5,-0.5]temp = np.zeros(2)error = 0while count &lt; loop_max: count+=1 sum = np.zeros(2) for i in range(m): sum[0] = sum[0] + (theta[0] + theta[1] * x[i] - y[i]) temp0 = theta[0] - alpha * sum[0] / m for i in range(m): sum[1] = sum[1]+ (theta[0] + theta[1] * x[i] - y[i]) * x[i] temp1 = theta[1] - alpha * sum[1] / m theta[0] = temp0 theta[1] = temp1 # Âà§Êñ≠ÊòØÂê¶Â∑≤Êî∂Êïõ if abs((sum[1]+ sum[0] - error)) &lt; epsilon: finish = 1 break else: error = sum[1]+ sum[0] print('intercept = %s slope = %s' % (theta[0], theta[1]))#slope, intercept, r_value, p_value, slope_std_error = stats.linregress(x, y)#print('intercept = %s slope = %s' % (intercept, slope))print('loop count = %d\n' % count, theta)plt.plot(x, y, 'r*')plt.plot(x, theta[1] * x + theta[0], 'g')#plt.plot(x, slope * x + intercept, 'b')plt.show() ÂÅ∑Êáí‰∫Ü‰∏§Â§©ÂêéÁî®normal equationÊñπÊ≥ïÂÆûÁé∞‰∫ÜÔºåÁªìÊûúÂíåstats.linregressÁöÑÁªìÊûúÂÆåÂÖ®‰∏ÄÊ†∑ÔºåÊ≥®ÊÑèÁü©ÈòµÈúÄË¶ÅÂûÇÁõ¥ÊéíÂàóÔºåËÆ∞ÂΩï‰ø©ÂáΩÊï∞Áî®Êù•‰øÆÊîπÁü©ÈòµÂ†ÜÂè†ÊñπÂºè1234567891011121314151617181920212223242526272829303132333435363738394041424344454647vstack()ÂáΩÊï∞ ÂáΩÊï∞ÂéüÂûãÔºövstack(tup) ÔºåÂèÇÊï∞tupÂèØ‰ª•ÊòØÂÖÉÁªÑÔºåÂàóË°®ÔºåÊàñËÄÖnumpyÊï∞ÁªÑÔºåËøîÂõûÁªìÊûú‰∏∫numpyÁöÑÊï∞ÁªÑ ‰ΩúÁî®ÔºöÂú®ÂûÇÁõ¥ÊñπÂêëÊääÂÖÉÁ¥†Â†ÜÂè†Ëµ∑Êù•&gt;&gt;&gt;import numpy as np&gt;&gt;&gt;a=[[1],[2],[3]]&gt;&gt;&gt;b=[[1],[2],[3]]&gt;&gt;&gt;c=[[1],[2],[3]]&gt;&gt;&gt;d=[[1],[2],[3]]&gt;&gt;&gt;print(np.vstack((a,b,c,d)))[[1] [2] [3] [1] [2] [3] [1] [2] [3] [1] [2] [3]] stackÂáΩÊï∞ÂéüÂûã‰∏∫Ôºöstack(arrays, axis=0) import numpy as npa=[[1,2,3], [4,5,6]]print("ÂàóË°®aÂ¶Ç‰∏ãÔºö")print(a)print("Â¢ûÂä†‰∏ÄÁª¥ÔºåÊñ∞Áª¥Â∫¶ÁöÑ‰∏ãÊ†á‰∏∫0")c=np.stack(a,axis=0)print(c)print("Â¢ûÂä†‰∏ÄÁª¥ÔºåÊñ∞Áª¥Â∫¶ÁöÑ‰∏ãÊ†á‰∏∫1")c=np.stack(a,axis=1)print(c)ËæìÂá∫ÔºöÂàóË°®aÂ¶Ç‰∏ãÔºö[[1, 2, 3], [4, 5, 6]]Â¢ûÂä†‰∏ÄÁª¥ÔºåÊñ∞Áª¥Â∫¶‰∏ãÊ†á‰∏∫0[[1 2 3] [4 5 6]]Â¢ûÂä†‰∏ÄÁª¥ÔºåÊñ∞Áª¥Â∫¶‰∏ãÊ†á‰∏∫1[[1 4] [2 5] [3 6]] Numpy‰∏≠stack()Ôºåhstack()Ôºåvstack()ÂáΩÊï∞ËØ¶Ëß£ 1234567891011121314151617181920212223242526272829#!/usr/bin/python# coding=utf-8import numpy as npfrom scipy import statsimport matplotlib.pyplot as plt# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜ# x ÁâπÂæÅÂÄº# y ÂÆûÈôÖÁªìÊûúx1 = np.arange(0, 50, 1) + np.random.randn(50) -5m = len(x1)x0 = np.full(m, 1.0)y = x1/2 + np.random.randn(m) -5target_data = np.vstack(y) # Â∞ÜÁªìÊûúÁü©Èòµ‰øÆÊîπ‰∏∫ÂûÇÁõ¥ÊñπÂêëx = np.stack((x0, x1), axis=1) # ÊûÑÂª∫XÁü©Èòµ#print(x,y)theta = np.dot(np.dot(np.linalg.inv(np.dot(x.T, x)), x.T), target_data)print(theta)slope, intercept, r_value, p_value, slope_std_error = stats.linregress(x1, y)print('intercept = %s slope = %s' % (intercept, slope))"""ÂæóÂà∞ÁöÑÁªìÊûúÂíåstats.linregressÂáΩÊï∞ÂÆåÂÖ®‰∏ÄÊ†∑ÔºåÁåúÊµãËøô‰∏™ÂáΩÊï∞‰πüÊòØÂ¶ÇÊ≠§ÂÆûÁé∞ÁöÑ"""plt.plot(x1, y, '*')plt.plot(x, slope * x + intercept, 'b')plt.plot(x, theta[1] * x + theta[0], 'r')plt.show() ÈÄöËøáÂ≠¶‰π†Âà´‰∫∫ÁöÑ‰ª£Á†ÅÂíå‰øÆÊîπÂÆåÊàê‰∫ÜÊúÄÁªàÁâàÊú¨ÔºåË¶ÅÊ≥®ÊÑèÊ≠•ÈïøÂíåÁªàÊ≠¢Êù°‰ª∂ÔºåÊ≠•ÈïøalphaÈÄöËøáÂ§öÊ¨°Â∞ùËØïÊúÄÂêéÈÄâÂèñÈÄÇÂêàÂÄº123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/python# coding=utf-8import numpy as npfrom scipy import statsimport matplotlib.pyplot as plt# ÊûÑÈÄ†ËÆ≠ÁªÉÈõÜ# x ÁâπÂæÅÂÄº# y ÂÆûÈôÖÁªìÊûúx1 = np.arange(0, 50, 1) + np.random.randn(50)m = len(x1)x0 = np.full(m, 1.0)x = np.vstack([x0, x1]).Ty = x1/2 + np.random.randn(m) -5# ‰∏§ÁßçÁªàÊ≠¢Êù°‰ª∂loop_max = 10000 # ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞(Èò≤Ê≠¢Ê≠ªÂæ™ÁéØ)epsilon = 1e-4# ÂàùÂßãÂåñÊùÉÂÄºnp.random.seed(0)theta = np.random.randn(2)alpha = 0.002 # Ê≠•Èïø(Ê≥®ÊÑèÂèñÂÄºËøáÂ§ß‰ºöÂØºËá¥ÊåØËç°Âç≥‰∏çÊî∂Êïõ,ËøáÂ∞èÊî∂ÊïõÈÄüÂ∫¶ÂèòÊÖ¢) Â§ß‰∫é0.002‰ºö‰∏çÊî∂Êïõerror = np.zeros(2)count = 0 # Âæ™ÁéØÊ¨°Êï∞while count &lt; loop_max: count += 1 delta = np.zeros(2) for i in range(m): delta = delta + (np.dot(theta, x[i]) - y[i]) * x[i]/m theta = theta - alpha * delta # Âà§Êñ≠ÊòØÂê¶Â∑≤Êî∂Êïõ if np.linalg.norm(theta - error) &lt; epsilon: # np.linalg.norm Ê±ÇËåÉÁ±ªÔºöÂπ≥ÊñπÂíåÔºåÂºÄÊñπ break else: error = theta print(theta)print(theta,count)slope, intercept, r_value, p_value, slope_std_error = stats.linregress(x1, y)print('intercept = %s slope = %s' % (intercept, slope))plt.plot(x1, y, 'g*')plt.plot(x, theta[1] * x + theta[0], 'r')plt.plot(x, slope * x + intercept, 'b')plt.show()]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†‰ª£Á†ÅÂÆûÁé∞</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Ôºà‰∏âÔºâ]]></title>
    <url>%2F2018%2F04%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ÁâπÂæÅÁº©Êîæ Ôºàfeature scalingÔºâÁ°Æ‰øù‰∏çÂêåÁöÑÁâπÂæÅÂÄºÂú®Âêå‰∏Ä‰∏™ËåÉÂõ¥ÂÜÖÔºåËøôÊ†∑ËÉΩ‰øùËØÅÊ¢ØÂ∫¶‰∏ãÈôçËÉΩÂ§üÊõ¥Âø´ÁöÑÊî∂Êïõ„ÄÇ ‰æãÂ¶ÇÔºöx1ÊòØÊàøÂ±ãÂ§ßÂ∞èÔºåÈùûÂ∏∏ÁöÑÂ§ßÔºà0-2000Ôºâx2ÊòØÊàøÈó¥ÂçßÂÆ§Êï∞Ôºà1-5ÔºâÂèÇÊï∞ÈÄÇÂΩìÁöÑÁº©ÊîæÔºå‰ΩøÊî∂ÊïõÁöÑÊõ¥Âø´Âª∫ËÆÆÊääÁâπÂæÅÁº©ÊîæÂà∞-1Âà∞1ÁöÑËåÉÂõ¥ÔºåÂèØ‰ª•ÂÅèÂ∑ÆÔºå‰ΩÜ‰∏çËÉΩÂÅèÂ∑ÆÂ§™Â§ßÔºåÁâπÂæÅÂÄº‰∏çÈúÄË¶ÅÂ§™Á≤æÁ°ÆÔºåÂè™ÊòØÂ∏åÊúõÊ¢ØÂ∫¶‰∏ãÈôçÊî∂ÊïõÊõ¥Âø´„ÄÇ Â≠¶‰π†ÈÄüÁéáÁöÑÈÄâÂèñÂ¶Ç‰ΩïÈÄâÊã©Ê¢ØÂ∫¶‰∏ãÈôçÂ≠¶‰π†ÈÄüÁéá$\alpha$ÔºåÂèØ‰ª•ÁîªÂá∫‰ª£‰ª∑ÂáΩÊï∞ÈöèËø≠‰ª£Ê≠•Êï∞$J(\theta)$Â¢ûÂä†ÁöÑÂáΩÊï∞Êõ≤Á∫øÔºåËßÇÂØüÊõ≤Á∫øÊù•Âà§Êñ≠Ê¢ØÂ∫¶‰∏ãÈôçÁÆóÊ≥ïÊòØÂê¶Êî∂ÊïõÔºå‰∏ãÈù¢Ëøô‰∏™Êõ≤Á∫ø‰∏≠ÔºåÂΩìËø≠‰ª£ËææÂà∞‰∏âÁôæÊó∂Âü∫Êú¨Â∑≤ÁªèÂÅúÊ≠¢‰∏ãÈôçÔºåÊâÄ‰ª•Ëøô‰∏™Êõ≤Á∫ø‰∏≠‰∏âÁôæÊòØÊúÄ‰Ω≥ÁöÑËø≠‰ª£Ê¨°Êï∞‰∏Ä‰∏™ÂÖ∏Âûã‰æãÂ≠êÊù•ÁöÑÂà§Êñ≠ÊòØÂê¶Êî∂ÊïõÔºåÊØîÂ¶Ç‰ª£‰ª∑ÂáΩÊï∞$J(\theta)$Â∑≤ÁªèÂ∞è‰∫é‰∏Ä‰∏™ŒµÔºåÊØîÂ¶ÇËÆæÁΩÆŒµ‰∏∫0.001ÔºåÈÄâÊã©‰∏Ä‰∏™ÈòàÂÄºÊù•ÂëäËØâÁÆóÊ≥ïÂ∑≤ÁªèÊî∂Êïõ„ÄÇ $\alpha$ËøáÂ∞è‰ºöÊî∂ÊïõÂ§™ÊÖ¢ÔºåËøáÂ§ß‰ºöÂØºËá¥ÈúáËç°Êó†Ê≥ïÊî∂ÊïõÔºåÈÄöÂ∏∏‰ºöÂ∞ùËØïÂ§ö‰∏™Œ±Êù•ÊâæÂà∞ÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÈÄüÁéáÔºåÊØîÂ¶Ç‰ªé0.001Âà∞1ÔºåÊØèÊâ©Â§ß‰∏âÂÄçÈÄâÂèñ‰∏Ä‰∏™alphaÊù•Á°ÆÂÆöÂ≠¶‰π†ÈÄüÁéá„ÄÇ Â§öÁâπÂæÅÂÄºÁöÑÁ∫øÊÄßÂõûÂΩíÈóÆÈ¢òÂíåÂâç‰∏ÄÁ´†‰∏ÄÊ†∑ÔºåÂØπÊØè‰∏™ÂèÇÊï∞Œ∏Ê±ÇJÁöÑÂÅèÂØºÊï∞ÔºåÁÑ∂ÂêéÊääÂÆÉ‰ª¨ÂÖ®ÈÉ®ÁΩÆÈõ∂ÔºåÁÑ∂ÂêéÊ±ÇÂá∫Œ∏1Âà∞Œ∏nÁöÑÂÄºÔºåËøôÊ†∑Â∞±ËÉΩÊ±ÇÂá∫ÊúÄÂ∞èÁöÑ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÊâÄÊúâŒ∏ÁöÑÂÄº„ÄÇËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Â§çÊùÇÁöÑÂæÆÂàÜÊñπÁ®ãÔºåÁî®Á∫øÊÄß‰ª£Êï∞ÁöÑÊñπÊ≥ïÂèØ‰ª•Âø´ÈÄüËß£ÂÜ≥„ÄÇ Normal EquationÊûÑÂª∫‰∏§‰∏™Áü©ÈòµÔºåÁü©ÈòµXÁî±x0ÔºàÂÖ®ÈÉ®‰∏∫1ÔºâÔºåx1Ôºåx2‚Ä¶xnÊûÑÊàêÔºåyÊòØÁªìÊûúÁü©ÈòµÔºåXÂíåyÁü©ÈòµÊòØ‰ª•ÂàóÊéíÁöÑÁÆÄÂçïÁöÑËØ¥Â∞±ÊòØ: ÈÄöËøáËÆ°ÁÆóXÁöÑËΩ¨ÁΩÆ‰πò‰ª•XÁöÑÈÄÜ‰πò‰ª•XÁöÑËΩ¨ÁΩÆ‰πò‰ª•YÊù•ÂæóÂà∞Œ∏Â∞±ÊòØËøô‰∏™ÂÖ¨ÂºèÔºåËøôÈáåÊáíÂæóÂÜô‰∏∫‰ªÄ‰πà‰∫ÜÔºåËøô‰∏™‰πüÊòØÊúÄÂ∞è‰∫å‰πòÊ≥ïÁöÑÂÖ¨Âºè„ÄÇ‰ºòÁÇπÊòØ‰∏çÈúÄË¶ÅÈÄâÂèñÂ≠¶‰π†ÈÄüÁéáÔºå‰∏çÈúÄË¶ÅËø≠‰ª£Ôºå‰ΩÜÊòØÂΩìÁâπÂæÅÂÄºÂ§ß‰∫éÁôæ‰∏áÁ∫ßÂà´Ê±ÇÁü©ÈòµÁöÑÈÄÜ‰ºöÈùûÂ∏∏ÊÖ¢ÔºåËøôÊó∂ÂàôÂ∫îËØ•ÈÄâÊã©Ê¢ØÂ∫¶‰∏ãÈôçËÄå‰∏çÊòØÊ†áÂáÜÊñπÁ®ã„ÄÇ ÂΩìÁâπÂæÅÂÄºÂ≠òÂú®Á∫øÊÄßÂÖ≥Á≥ªÊó∂Ôºå‰ºöÂØºËá¥Áü©Èòµ‰∏çÂèØÈÄÜÔºå‰ΩÜÊòØÂèØ‰ª•ÈÄöËøáÊ±Ç‰º™ÈÄÜÊù•Ëé∑ÂèñÁªìÊûúÂàöÔºåÂØπÁªìÊûúÂΩ±Âìç‰∏çÂ§ß„ÄÇ Python‰ª£Á†ÅÂÆûÁé∞ PythonÂÆûÁé∞Ê¢ØÂ∫¶‰∏ãÈôç]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Ôºà‰∫åÔºâ]]></title>
    <url>%2F2018%2F04%2F14%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ËÆ∞ÂæóÂΩìÂπ¥ËÉåËã±ËØ≠ÂçïËØçÁöÑ‰π¶Ê∞∏ËøúÈÉΩÁøªÂú®Á¨¨‰∏ÄÈ°µÔºåabandonËÉå‰∫Ü‰∏ÄÈÅçÂèà‰∏ÄÈÅçÔºåËøòÊòØÊ≤°ÊúâËÆ∞‰ΩèÔºåÁé∞Â¶Ç‰ªäÂë®ÂøóÂçéËÄÅÂ∏àÁöÑ‰π¶‰π∞‰∫ÜÂ•Ω‰πÖÊ≤°ÊúâÁøªÔºåÂê¥ÊÅ©ËææÁöÑËßÜÈ¢ëÁúã‰∫Ü‰∏ÄÈÅçÂèà‰∏ÄÈÅçÔºåÂè™ËÉΩÂ∏åÊúõËøôÊòØÊúÄÂêé‰∏ÄÊ¨°Áúã‰∫Ü„ÄÇ Machine Learning Â≠¶‰π†ËßÜÂ±èÂú∞ÂùÄ ‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π† ‰∏çÂÄüÂä©ÁâπÂÆöÁöÑÁ®ãÂ∫è‰ΩøÁîµËÑëÂ≠¶‰π†ÁöÑÁßëÂ≠¶ ÁõëÁù£Â≠¶‰π†Ôºàsupervised learningÔºâ‰æãÂ¶ÇÔºöÊàø‰ª∑È¢ÑÊµãÔºàÂõûÂΩíÈóÆÈ¢òÔºâÔºåËÇøÁò§È¢ÑÊµãÔºàÂàÜÁ±ªÈóÆÈ¢òÔºâÁõëÁù£Â≠¶‰π†Â∞±ÊòØÁªôÂá∫‰∏ÄÁªÑÁâπÂæÅÂÄºÔºåÂêåÊó∂‰πüÁªôÂá∫ËøôÁªÑÁâπÂæÅÊâÄÂØπÂ∫îÁöÑÁªìÊûú„ÄÇÊØîÂ¶ÇÈÄöËøáÊüê‰∏ÄÂú∞Âå∫ÊàøÂ≠êÁöÑÈù¢ÁßØÂíåÂçßÂÆ§Êï∞Êù•È¢ÑÊµãÊàøÂ≠êÁöÑ‰ª∑Ê†º„ÄÇ Êó†ÁõëÁù£Â≠¶‰π†Ôºàunsupervised learningÔºâÊó†ÁõëÁù£Â≠¶‰π†ÂàôÊòØÂè™ÁªôÂá∫‰∏Ä‰∫õÁâπÂæÅÂÄºÔºå‰ΩÜÊòØÂπ∂Ê≤°ÊúâËøô‰∫õÁâπÂæÅÊâÄÂØπÂ∫îÁöÑÁªìÊûúÔºåÈÄöËøáËøô‰∫õÁâπÂæÅÂÄºÊù•ÂØªÊâæ‰ªñ‰ª¨‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå‰æãÂ¶ÇËÅöÁ±ªÈóÆÈ¢òÔºåÊääÂêå‰∏Ä‰∫ã‰ª∂ÁöÑÊñ∞ÈóªÂàíÂàÜ‰∏∫‰∏ÄÁ±ª„ÄÇ Ê®°ÂûãË°®Á§∫ÔºàModel RepresentationÔºâÁ¨¶Âè∑ÂÆö‰πâmÔºöÊ†∑Êú¨Êï∞ÈáèÔºàtraining examplesÔºâxÔºöËæìÂÖ•ÂÄºÔºåÂèàÂè´ÁâπÂæÅÔºàinput variables/featuresÔºâyÔºöËæìÂá∫ÂÄºÔºåÂèàÂè´ÁõÆÊ†áÂÄºÔºàoutput variables/target variablesÔºâÔºàxÔºåyÔºâÔºöËÆ≠ÁªÉÊ†∑Êú¨Á¨¨i‰∏™ËÆ≠ÁªÉÊ†∑Êú¨Ôºö$(x^i,y^i)$ ÁõëÁù£Â≠¶‰π†ÁöÑÂ∑•‰ΩúÊñπÂºè È¢ÑÊµãÂáΩÊï∞ÁöÑË°®Á§∫$h_\theta(x)=\theta_0+\theta_1x$ ÂÖ≥‰∫é$x$ÂçïÂèòÈáèÁöÑÁ∫øÊÄßÂõûÂΩíÊñπÁ®ã ‰ª£‰ª∑ÂáΩÊï∞Ôºàcost functionÔºâÈ¢ÑÊµãÂáΩÊï∞$h_\theta(x)$ÁöÑÁ∫øÊÄßÊÑè‰πâÔºöÈ¢ÑÊµãÂáΩÊï∞$h_\theta(x)$ÊòØÂÖ≥‰∫é$x$ÁöÑÂáΩÊï∞,ËÄå‰ª£‰ª∑ÂáΩÊï∞ÊòØ‰∏Ä‰∏™ÂÖ≥‰∫é$(\theta_0,\theta_1)$ÁöÑÂáΩÊï∞ $J(\theta_0,\theta_1) = \frac{1}{2m} \sum^m_{i=1}(h_\theta(x^i)-y^i)^2$ ‰ºòÂåñÁõÆÊ†áÔºö$minimize J(\theta_0,\theta_1)$ÊïôÊéàËÆ≤ÁöÑÂæàËØ¶ÁªÜÔºåËøôÈáåËÆ∞‰∏Ä‰∏ãËá™Â∑±ÁöÑËßÅËß£ÂêßÔºö1È¢ÑÊµãÂáΩÊï∞ÊòØÊ†πÊçÆÂ∑≤Áü•ÁâπÂæÅÂêëÈáèÂíåÁªìÊûúÊâÄÊèèËø∞ÁöÑ‰∏Ä‰∏™Á∫øÊÄßÊñπÁ®ãÔºåÊ†πÊçÆÊîπÂèòÁ∫øÊÆµÁöÑÊñúÁéáÊù•ËßÇÂØüÂåπÈÖçÂà∞ÁöÑÁâπÂæÅÂêªÂêàÂ∫¶ËææÔºåÂΩìÈ¢ÑÊµãÂáΩÊï∞ÂèØ‰ª•ÂåπÈÖçÂà∞ÊúÄÂ§öÁâπÂæÅÊó∂ÂàôËøô‰∏™È¢ÑÊµãÂáΩÊï∞ÊòØÊúÄ‰ºòËß£ÔºåÂ¶Ç‰ΩïËé∑ÂèñÊúÄ‰ºòËß£ÂºïÂÖ•‰∫Ü‰ª£‰ª∑ÂáΩÊï∞ÔºåÊâÄË∞ì‰ª£‰ª∑ÂáΩÊï∞Â∞±ÊòØÈ¢ÑÊµãÂáΩÊï∞ÁöÑÁßØÂàÜÔºå Ê¢ØÂ∫¶‰∏ãÈôçÂú®ÂæÆÁßØÂàÜÈáåÈù¢ÔºåÂØπÂ§öÂÖÉÂáΩÊï∞ÁöÑÂèÇÊï∞Ê±Ç‚àÇÂÅèÂØºÊï∞ÔºåÊääÊ±ÇÂæóÁöÑÂêÑ‰∏™ÂèÇÊï∞ÁöÑÂÅèÂØºÊï∞‰ª•ÂêëÈáèÁöÑÂΩ¢ÂºèÂÜôÂá∫Êù•ÔºåÂ∞±ÊòØÊ¢ØÂ∫¶ Ê¢ØÂ∫¶‰∏ãÈôçÊòØËø≠‰ª£Ê≥ïÁöÑ‰∏ÄÁßç,ÂèØ‰ª•Áî®‰∫éÊ±ÇËß£ÊúÄÂ∞è‰∫å‰πòÈóÆÈ¢ò(Á∫øÊÄßÂíåÈùûÁ∫øÊÄßÈÉΩÂèØ‰ª•)„ÄÇÂú®Ê±ÇËß£Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÊ®°ÂûãÂèÇÊï∞ÔºåÂç≥Êó†Á∫¶Êùü‰ºòÂåñÈóÆÈ¢òÊó∂ÔºåÊ¢ØÂ∫¶‰∏ãÈôçÔºàGradient DescentÔºâÊòØÊúÄÂ∏∏ÈááÁî®ÁöÑÊñπÊ≥ï‰πã‰∏ÄÔºåÂè¶‰∏ÄÁßçÂ∏∏Áî®ÁöÑÊñπÊ≥ïÊòØÊúÄÂ∞è‰∫å‰πòÊ≥ï„ÄÇÂú®Ê±ÇËß£ÊçüÂ§±ÂáΩÊï∞ÁöÑÊúÄÂ∞èÂÄºÊó∂ÔºåÂèØ‰ª•ÈÄöËøáÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÊù•‰∏ÄÊ≠•Ê≠•ÁöÑËø≠‰ª£Ê±ÇËß£ÔºåÂæóÂà∞ÊúÄÂ∞èÂåñÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÊ®°ÂûãÂèÇÊï∞ÂÄº„ÄÇÂèçËøáÊù•ÔºåÂ¶ÇÊûúÊàë‰ª¨ÈúÄË¶ÅÊ±ÇËß£ÊçüÂ§±ÂáΩÊï∞ÁöÑÊúÄÂ§ßÂÄºÔºåËøôÊó∂Â∞±ÈúÄË¶ÅÁî®Ê¢ØÂ∫¶‰∏äÂçáÊ≥ïÊù•Ëø≠‰ª£‰∫Ü„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÂü∫‰∫éÂü∫Êú¨ÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂèëÂ±ï‰∫Ü‰∏§ÁßçÊ¢ØÂ∫¶‰∏ãÈôçÊñπÊ≥ïÔºåÂàÜÂà´‰∏∫ÈöèÊú∫Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂíåÊâπÈáèÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ï„ÄÇ ÈÄöËøáÊ¢ØÂ∫¶‰∏ãÈôçÁöÑÊñπÊ≥ïÊù•ÂØªÊâæ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÊúÄ‰ºòËß£Á¨¶Âè∑Ëß£Èáä Ôºö= ËµãÂÄºÁ¨¶ÔºåÊääÂè≥ËæπÁöÑÂÄºËµãÂÄºÁªôÂ∑¶Ëæπ $\alpha$ Â≠¶‰π†ÈÄüÂ∫¶ÔºåÊ≠•ÈïøÔºåËøáÂ∞èÊî∂ÊïõÊó∂Èó¥ËøáÈïøÔºåËøáÂ§ßË∂ÖËøáÊúÄÂ∞èÂÄºÊó†Ê≥ïÊî∂Êïõ $\theta_0$Âíå$\theta_1$ÊòØÂêåÊó∂Êõ¥Êñ∞ÁöÑ Ê¢ØÂ∫¶‰∏ãÈôçÁöÑÁº∫ÁÇπÔºöÈù†ËøëÊûÅÂ∞èÂÄºÊó∂Êî∂ÊïõÈÄüÂ∫¶ÂáèÊÖ¢„ÄÇÁõ¥Á∫øÊêúÁ¥¢Êó∂ÂèØËÉΩ‰ºö‰∫ßÁîü‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇÂèØËÉΩ‰ºö‚Äú‰πãÂ≠óÂΩ¢‚ÄùÂú∞‰∏ãÈôç„ÄÇ‰ºö‰∫ßÁîüÂ±ÄÈÉ®ÊúÄ‰ºòËß£ËÄåÈùûÂÖ®Â±Ä„ÄÇ ÊÄªÁªìËøôÈáåÂü∫Êú¨ÁÆÄÂçïÁöÑËÆ∞ÂΩï‰∫ÜËßÜÈ¢ëÂâç‰∏âÁ´†ÁöÑÂÜÖÂÆπÔºåÊ¢≥ÁêÜ‰∏Ä‰∏ãÁü•ËØÜÁÇπ„ÄÇÂú®Êú∫Âô®Â≠¶‰π†‰∏≠È¶ñÂÖàÈúÄË¶ÅÊúâÊ†∑Êú¨Ôºå‰πüÂè´ËÆ≠ÁªÉÈõÜÔºåÁÑ∂ÂêéÊòØ‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÊääËÆ≠ÁªÉÈõÜÊâîËøõËøô‰∏™ÁÆóÊ≥ï‰∏≠ÔºåÈÄöËøáËø≠‰ª£‰πãÁ±ªÁöÑÊñπÊ≥ïËÆ°ÁÆóÊú∫‰ºöÂèëÁé∞ÂÖ∂‰∏≠ÁöÑËßÑÂæãËÄåÁªôÂá∫Áªü‰∏ÄÁöÑÊ®°Âûã‰ªéËÄåÂÅöÂà∞È¢ÑÊµãÂàÜÊûê„ÄÇ ÂΩìËÆ≠ÁªÉÈõÜÊó¢ÊúâËæìÂÖ•ÂÜÖÂÆπÂèàÊúâËæìÂá∫ÁªìÊûúÔºåÂ∞±ÊòØÁõëÁù£Â≠¶‰π†ÔºàÊØîÂ¶ÇÂõûÂΩíÈóÆÈ¢òÔºâÔºåÂΩìÊ†∑Êú¨ÈáåÊ≤°ÊúâÁªìÊûúÊó∂ÊòØÊó†ÁõëÁù£Â≠¶‰π†ÔºàÊØîÂ¶ÇËÅöÁ±ªÈóÆÈ¢òÔºâ Ê¢ØÂ∫¶‰∏ãÈôçÂ∞±ÊòØÂØªÊâæÊúÄ‰Ω≥ÁöÑÈ¢ÑÊµãÊ®°ÂûãÁöÑÊñπÂºèÔºåÂΩìÊàë‰ª¨Ë¶ÅÂª∫Á´ã‰∏Ä‰∏™ÂáÜÁ°ÆÁöÑÈ¢ÑÊµãÊ®°ÂûãÈúÄË¶Å‰∏çÊñ≠ÊîπÂèòÂèÇÊï∞Ôºà$\theta_0,\theta_1$Ôºâ,‰∫éÊòØÂª∫Á´ã‰∏Ä‰∏™ÂÖ≥‰∫é$\theta_0,\theta_1$ÁöÑÊñπÁ®ãÔºåËøô‰∏™ÊñπÁ®ãÂè´‰ª£‰ª∑ÊñπÁ®ãÔºàcost functionÔºâÔºåÂÖ∂ÂÆûËøô‰∏™ÊñπÁ®ãÂ∞±ÊòØÂ∫¶ÈáèÈ¢ÑÊµãÂáΩÊï∞ÁöÑÁªìÊûúÂíåÂÆûÈôÖÁªìÊûúÁöÑÊñπÂ∑ÆÔºåÂΩìÊñπÂ∑ÆÊúÄÂ∞èÂ∞±ÊòØÊúÄ‰Ω≥$\theta_0,\theta_1$ÔºåÊñπÊ≥ïÂ∞±ÊòØËÆ°ÁÆóÊâÄÊúâÈ¢ÑÊµãÂáΩÊï∞ÁöÑÁªìÊûúÂáèÂÆûÈôÖÁªìÊûúÂíåÁöÑÂπ≥ÊñπÔºåÊñπÂ∑ÆÊúÄÂ∞èÂ∞±‰ª£Ë°®ÊãüÂêàÂ∫¶ÊúÄ‰Ω≥„ÄÇÂèØËßÜÂåñËßÇÂØüÂ∞±ÂêëÊòØÂú®‰∏Ä‰∏™ÂºØÊõ≤ÁöÑÂ±±Ë∞∑‰∏≠ÂØªÊâæÊúÄ‰ΩéÁÇπ„ÄÇ]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êú∫Âô®Â≠¶‰π†Ôºà‰∏ÄÔºâ]]></title>
    <url>%2F2018%2F04%2F10%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ËøôÁØáÂçöÊñáÊòØÂØπAndrew NgÁöÑ Êú∫Âô®Â≠¶‰π†ÂÖ•Èó®ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÔºåÂÖ≥‰∫éÊú∫Âô®Â≠¶‰π†Â∑≤ÁªèÁúã‰∫Ü‰∏ÄÊÆµÊó∂Èó¥‰∫ÜÔºåÁé∞Âú®ÂºÄÂßãÊ≠£ÂºèÊÄªÁªì‰∏Ä‰∏ãËøôÊÆµÊó∂Èó¥ÊâÄÂ≠¶ÁöÑ‰∏úË•øÔºå‰∏ÄËæπÂ≠¶‰π†‰∏ÄËæπËÆ∞ÂΩïÔºåÂ∏åÊúõËÉΩÂ§üÊõ¥ÂÆåËøô‰∏™ÂçöÊñá„ÄÇ È¶ñÂÖàÂ§ç‰π†Êï∞Â≠¶ÔºåÂìéÔºåÂ≠¶Ê†°Â≠¶ÁöÑÂÖ®ËøòÁªôËÄÅÂ∏à‰∫Ü„ÄÇ„ÄÇ„ÄÇ Á∫øÊÄß‰ª£Êï∞ Á∫øÊÄß‰ª£Êï∞ÊòØÊï∞Â≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåÂÆÉÁöÑÁ†îÁ©∂ÂØπË±°ÊòØÂêëÈáèÔºåÂêëÈáèÁ©∫Èó¥ÔºàÊàñÁß∞Á∫øÊÄßÁ©∫Èó¥ÔºâÔºåÁ∫øÊÄßÂèòÊç¢ÂíåÊúâÈôêÁª¥ÁöÑÁ∫øÊÄßÊñπÁ®ãÁªÑ„ÄÇÂêëÈáèÁ©∫Èó¥ÊòØÁé∞‰ª£Êï∞Â≠¶ÁöÑ‰∏Ä‰∏™ÈáçË¶ÅËØæÈ¢òÔºõÂõ†ËÄåÔºåÁ∫øÊÄß‰ª£Êï∞Ë¢´ÂπøÊ≥õÂú∞Â∫îÁî®‰∫éÊäΩË±°‰ª£Êï∞ÂíåÊ≥õÂáΩÂàÜÊûê‰∏≠ÔºõÈÄöËøáËß£ÊûêÂá†‰ΩïÔºåÁ∫øÊÄß‰ª£Êï∞Âæó‰ª•Ë¢´ÂÖ∑‰ΩìË°®Á§∫„ÄÇÁ∫øÊÄß‰ª£Êï∞ÁöÑÁêÜËÆ∫Â∑≤Ë¢´Ê≥õÂåñ‰∏∫ÁÆóÂ≠êÁêÜËÆ∫„ÄÇÁî±‰∫éÁßëÂ≠¶Á†îÁ©∂‰∏≠ÁöÑÈùûÁ∫øÊÄßÊ®°ÂûãÈÄöÂ∏∏ÂèØ‰ª•Ë¢´Ëøë‰ºº‰∏∫Á∫øÊÄßÊ®°ÂûãÔºå‰ΩøÂæóÁ∫øÊÄß‰ª£Êï∞Ë¢´ÂπøÊ≥õÂú∞Â∫îÁî®‰∫éËá™ÁÑ∂ÁßëÂ≠¶ÂíåÁ§æ‰ºöÁßëÂ≠¶‰∏≠„ÄÇ Áü©ÈòµÂÆö‰πâÁî±m$\times$n‰∏™Êï∞ÊéíÂàóÊàêmË°ånÂàóÁöÑÁü©ÈòµÔºåÁÆÄÁß∞m$\times$ËÆ∞‰ΩúÔºö Áü©ÈòµÂä†Ê≥ïÁü©ÈòµÁöÑÂä†Ê≥ïÊª°Ë∂≥‰∏ãÂàóËøêÁÆóÂæã(AÔºåBÔºåCÈÉΩÊòØÂêåÂûãÁü©Èòµ)Ôºö A + B = B + A (A + B) + C = A + (B + C) Âè™ÊúâË°åÂàóÁõ∏ÂêåÁöÑÁöÑÁü©ÈòµÊâçÂèØ‰ª•ËøõË°åÂä†Ê≥ï Áü©ÈòµÂáèÊ≥ï Êï∞‰πòÁü©ÈòµÁöÑÂä†ÂáèÊ≥ïÂíåÁü©ÈòµÁöÑÊï∞‰πòÂêàÁß∞Áü©ÈòµÁöÑÁ∫øÊÄßËøêÁÆó ËΩ¨ÁΩÆÊääÁü©ÈòµAÁöÑË°åÂíåÂàó‰∫íÊç¢‰∫ßÁîüÁöÑÊñ∞Áü©ÈòµÁß∞‰πã‰∏∫Áü©ÈòµAÁöÑËΩ¨ÁΩÆÁü©ÈòµÁöÑËΩ¨ÁΩÆÊª°Ë∂≥‰∏Ä‰∏ãÂÆöÂæãÔºö $$(A^T)^T = A$$ $(\lambda A^T) = \lambda A^T$ $(AB)^T = B^TA^T$ Áü©Èòµ‰πòÊ≥ï‰∏§‰∏™Áü©ÈòµËÉΩÂ§üÁõ∏‰πòÔºåÂΩì‰∏î‰ªÖÂΩìÁ¨¨‰∏Ä‰∏™Áü©ÈòµAÁöÑÂàóÊï∞Á≠â‰∫éÁ¨¨‰∫å‰∏™Áü©ÈòµBÁöÑË°åÊï∞Êó∂ÊâçËÉΩÂÆö‰πâÔºåÂ¶ÇÊûúAÊòØ$m\times n$ÁöÑÁü©ÈòµBÊòØ$n\times p$ÁöÑÁü©ÈòµÔºå‰ªñ‰ª¨ÁöÑ‰πòÁßØCÂ∞ÜÊòØ‰∏Ä‰∏™$m\times p$ÁöÑÁü©Èòµ$C=(C_{ij})$,ÂÆÉÁöÑÊØè‰∏™ÂÖÉÁ¥†ÊòØÔºö $c_{i,j} = a_{i,1}b_{1,j} + a_{i,2}b_{2,j} + ‚Ä¶ + a_{i,n}b{n,j} = \sum_{r=1}^n a_{i,r}b_{r,j}$ ËÆ∞‰ΩúÔºöC = AB ‰æãÂ¶ÇÔºöÁü©ÈòµÁöÑ‰πòÊ≥ïÊª°Ë∂≥‰ª•‰∏ãËøêÁÆóÂæãÔºöÁªìÂêàÂæãÔºåÂàÜÈÖçÂæãÔºåÁü©Èòµ‰πòÊ≥ï‰∏çÊª°Ë∂≥‰∫§Êç¢Âæã„ÄÇ ËΩ¨ÁΩÆ:$(AB)^T=B^TA^T$ ÂΩìÁü©ÈòµAÁöÑÂàóÊï∞Á≠â‰∫éÁü©ÈòµBÁöÑË°åÊï∞Êó∂ÔºåA‰∏éBÂèØ‰ª•Áõ∏‰πò„ÄÇ Áü©ÈòµCÁöÑË°åÊï∞Á≠â‰∫éÁü©ÈòµAÁöÑË°åÊï∞ÔºåCÁöÑÂàóÊï∞Á≠â‰∫éBÁöÑÂàóÊï∞„ÄÇ ‰πòÁßØCÁöÑÁ¨¨mË°åÁ¨¨nÂàóÁöÑÂÖÉÁ¥†Á≠â‰∫éÁü©ÈòµAÁöÑÁ¨¨mË°åÁöÑÂÖÉÁ¥†‰∏éÁü©ÈòµBÁöÑÁ¨¨nÂàóÂØπÂ∫îÂÖÉÁ¥†‰πòÁßØ‰πãÂíå„ÄÇ ÂØºÊï∞ÂØπ‰∫éÊú∫Âô®Â≠¶‰π†‰∏çÈúÄË¶ÅÁêÜËß£ÁöÑÂ§™Ê∑±ÂÖ•ÔºåÊ∑±ÂÖ•ÁöÑËá™Â∑±‰πüÊ≤°Â≠¶ÊáÇ&gt;_&lt;,Â§ßÊ¶ÇÂ∞±ÊòØÁü•ÈÅì‰∏î‰ºöÊ±ÇÂÅèÂØºÔºåÁü•ÈÅìÊñúÁéáÁöÑÊÑè‰πâÂ∞±Â§ü‰∫ÜÔºåÂÖ∂‰ªñÈÉ®ÂàÜÂ§™Â§çÊùÇÂ∞±‰∏çËÆ∞ÂΩï‰∫Ü„ÄÇ„ÄÇ„ÄÇÂ•ΩÂêéÊÇîÂΩìÂàùÊ≤°ÊúâÂ•ΩÂ•ΩÂ≠¶‰π†ÂæÆÁßØÂàÜ Ê¶ÇÁéáËÆ∫ÂÖàÈ™åÊ¶ÇÁéáÂíåÂêéÈ™åÊ¶ÇÁéáÔºö ÂêéÈ™åÊ¶ÇÁéáÊòØÊåáÂú®ÂæóÂà∞‚ÄúÁªìÊûú‚ÄùÁöÑ‰ø°ÊÅØÂêéÈáçÊñ∞‰øÆÊ≠£ÁöÑÊ¶ÇÁéáÔºåÊòØ‚ÄúÊâßÊûúÂØªÂõ†‚ÄùÈóÆÈ¢ò‰∏≠ÁöÑ‚ÄùÊûú‚Äù„ÄÇÂÖàÈ™åÊ¶ÇÁéá‰∏éÂêéÈ™åÊ¶ÇÁéáÊúâ‰∏çÂèØÂàÜÂâ≤ÁöÑËÅîÁ≥ªÔºåÂêéÈ™åÊ¶ÇÁéáÁöÑËÆ°ÁÆóË¶Å‰ª•ÂÖàÈ™åÊ¶ÇÁéá‰∏∫Âü∫Á°Ä„ÄÇ‰∫ãÊÉÖËøòÊ≤°ÊúâÂèëÁîüÔºåË¶ÅÊ±ÇËøô‰ª∂‰∫ãÊÉÖÂèëÁîüÁöÑÂèØËÉΩÊÄßÁöÑÂ§ßÂ∞èÔºåÊòØÂÖàÈ™åÊ¶ÇÁéá„ÄÇ‰∫ãÊÉÖÂ∑≤ÁªèÂèëÁîüÔºåË¶ÅÊ±ÇËøô‰ª∂‰∫ãÊÉÖÂèëÁîüÁöÑÂéüÂõ†ÊòØÁî±Êüê‰∏™Âõ†Á¥†ÂºïËµ∑ÁöÑÂèØËÉΩÊÄßÁöÑÂ§ßÂ∞èÔºåÊòØÂêéÈ™åÊ¶ÇÁéá„ÄÇÂÖàÈ™åÊ¶ÇÁéá‰∏çÊòØÊ†πÊçÆÊúâÂÖ≥Ëá™ÁÑ∂Áä∂ÊÄÅÁöÑÂÖ®ÈÉ®ËµÑÊñôÊµãÂÆöÁöÑÔºåËÄåÂè™ÊòØÂà©Áî®Áé∞ÊúâÁöÑÊùêÊñô(‰∏ªË¶ÅÊòØÂéÜÂè≤ËµÑÊñô)ËÆ°ÁÆóÁöÑÔºõÂêéÈ™åÊ¶ÇÁéá‰ΩøÁî®‰∫ÜÊúâÂÖ≥Ëá™ÁÑ∂Áä∂ÊÄÅÊõ¥Âä†ÂÖ®Èù¢ÁöÑËµÑÊñôÔºåÊó¢ÊúâÂÖàÈ™åÊ¶ÇÁéáËµÑÊñôÔºå‰πüÊúâË°•ÂÖÖËµÑÊñôÔºõÂÖàÈ™åÊ¶ÇÁéáÁöÑËÆ°ÁÆóÊØîËæÉÁÆÄÂçïÔºåÊ≤°Êúâ‰ΩøÁî®Ë¥ùÂè∂ÊñØÂÖ¨ÂºèÔºõËÄåÂêéÈ™åÊ¶ÇÁéáÁöÑËÆ°ÁÆóÔºåË¶Å‰ΩøÁî®Ë¥ùÂè∂ÊñØÂÖ¨ÂºèÔºåËÄå‰∏îÂú®Âà©Áî®Ê†∑Êú¨ËµÑÊñôËÆ°ÁÆóÈÄªËæëÊ¶ÇÁéáÊó∂ÔºåËøòË¶Å‰ΩøÁî®ÁêÜËÆ∫Ê¶ÇÁéáÂàÜÂ∏ÉÔºåÈúÄË¶ÅÊõ¥Â§öÁöÑÊï∞ÁêÜÁªüËÆ°Áü•ËØÜ„ÄÇ ÁõÆÂâçÂÖàÁü•ÈÅìËøôÁÇπÂ∞±Â§ü‰∫ÜÔºåÂÖ∑‰Ωì‰ª•ÂêéÂÜçË°•ÂÖÖ Êï∞Â≠¶Áü•ËØÜÂ§ç‰π†ÂÆåÊØï Ê≠£ÂºèÂºÄÂßãÊú∫Âô®Â≠¶‰π†]]></content>
      <categories>
        <category>Êú∫Âô®Â≠¶‰π†</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Èöè‰æøÁé©Áé©ÁöÑÁé©ÂÆ∂]]></title>
    <url>%2F2018%2F04%2F07%2F%E9%9A%8F%E4%BE%BF%E7%8E%A9%E7%8E%A9%E7%9A%84%E7%8E%A9%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[Â¶ÇÊûú‰ªé‰∏âÂ≤ÅÁúãÂì•Âì•Áé©È©¨ÊàèÂõ¢ÁÆóËµ∑ÔºåÊ∏∏ÊàèÁé©‰∫Ü‰πüÊúâ‰∫åÂçÅ‰∏™Âπ¥Â§¥‰∫ÜÔºå‰ΩÜËøòÊòØ‰∏™Ê∏∏ÊàèËèúÈ∏üÔºåÂ∑≤ÁªèÂè§Á®Ä‰πãÂπ¥ÁöÑÊñØÁöÆÂ∞î‰ºØÊ†ºÂç¥Ë¶ÅÊãç‰∏ÄÈÉ®Â§¥Âè∑Áé©ÂÆ∂ÔºåËøô‰ΩøÊàëÊÄÄÁùÄÊµìÂéöÁöÑÂÖ¥Ë∂£Ëµ∞Ëøõ‰∫ÜÂΩ±Èô¢„ÄÇ Â¶ÇÊûúËØ¥ÊúÄÊó©ÁúãËøáÊñØÁöÆÂ∞î‰ºØÊ†ºÊâßÂØºÁöÑÁîµÂΩ±ÈÇ£Â∫îËØ•ÊòØÂ§ßÁôΩÈ≤®Âíå‰æèÁΩóÁ∫™ÂÖ¨Âõ≠‰∫ÜÔºå‰ΩÜÈÇ£Êó∂ÊàëËøòÂ§™Â∞èÔºåÂ§ßÊ¶Ç‰∏ÉÂÖ´Â≤ÅÔºåÂπ∂‰∏çÁü•ÈÅìÂØºÊºî‰ªÄ‰πàÁöÑÔºå‰ΩÜÊòØÂ§ßÁôΩÈ≤®Âç¥ÁªôÊàëÁïô‰∏ãÊÄïÊ∞¥ÁöÑÂíåÈ±ºÁöÑÂøÉÁêÜÈò¥ÂΩ±ÔºåÂ∞èÊó∂ÂÄôËøûÈ±ºÈÉΩ‰∏çÊï¢ÊäìÔºåÂØπÊÅêÈæôÊ≤°ÊúâÂ§™Â§ßÁöÑÂÖ¥Ë∂£ÊâÄ‰ª•‰æèÁΩóÁ∫™ÂÖ¨Âõ≠Ê≤°Â§™Â§ßÂç∞Ë±°ÔºåÂà∞Âàù‰∏≠Êó∂ÂÄôËã±ËØ≠ËÄÅÂ∏àÁªôÊîæÂ§∫ÂÆùÂ•áÂÖµÔºå‰ªãÁªçËØ¥ÊòØ‰∏Ä‰∏™Â§ö‰πàÊ£íÁöÑÂØºÊºîÊãçÁöÑÔºåÊ≤°ËÆ∞‰ΩèÂØºÊºîÂíåÂâßÊÉÖÔºåÂè™ÊòØË¢´ÁîµÂΩ±‰∏≠ÁöÑÂêÑÁßçÊé¢Èô©ÂØªÂÆùÁöÑËøáÁ®ãÊ∑±Ê∑±Âê∏ÂºïÔºåÁÑ∂ÂêéÂåñË∫´‰∏≠‰∫åÂ∞ëÂπ¥‰∏éÂ∞è‰ºô‰º¥‰ª¨‰∏ÄËµ∑ÂºÄÂßãÂØªÂÆù‰πãÊóÖ„ÄÇÂØπÁîµÂΩ±ÁöÑÁêÜËß£ËøòÊòØË¶ÅÂà∞È´ò‰∏≠Êó∂ÊúüÔºå‰∏ÄÊ¨°ÂõûÂÆ∂ÁöÑË∑Ø‰∏äÔºåË∞àÂà∞‰∫ÜÁîµÂΩ±ÔºåÂ•ΩÂèãËØ¥‰ªñÂú£Âüé‰∏ä‰∏ãËΩΩ‰∫Ü„ÄäÊãØÊïëÂ§ßÂÖµÁëûÊÅ©„ÄãË∂ÖÊ∏ÖÁâàÁöÑÔºåËøûÂºπÈÅìÈÉΩËÉΩÁúãÂà∞ÔºåÊ±§ÂßÜÊ±âÂÖãÊñØÊºîÁöÑ‰∏çÊÑßÊòØÊúÄÂ•ΩÁöÑ‰∫åÊàòÁîµÂΩ±ÔºåÂè¶‰∏Ä‰ΩçÂ•ΩÂèãËØ¥ÊòØÊñØÁöÆÂ∞î‰ºØÊ†ºÊãçÁöÑÔºåÂêßÂï¶ÂêßÂï¶„ÄÇ„ÄÇ„ÄÇ‰ªÄ‰πà‰ªñ‰ª¨Âú®ËØ¥‰ªÄ‰πàÔºåÊàëÁúãÁîµÂΩ±ÈÉΩÊòØÂè™ËÆ∞ÂæóÂâßÊÉÖÂíå‰∏≠ÂõΩÁöÑÊºîÂëòÔºåËÄå‰ªñ‰ª¨ËÉΩÊääÂ§ñÂõΩÁöÑÂØºÊºîÂíåÊºîÂëòÂ¶ÇÊï∞ÂÆ∂ÁèçÔºå‰∏∫‰∫Ü‰∏ç‰∏¢‰∫∫‰∫éÊòØÂõûÂÆ∂ÊÅ∂Ë°•ÔºåÁªìÊûúÂèëÁé∞ÊñØÁöÆÂ∞î‰ºØÊ†ºÊãçÁöÑÁîµÂΩ±Â§ßÈÉΩÁúãËøáÔºå‰ΩÜÂç¥Ê≤°ÂÖ≥Ê≥®ËøáÂØºÊºî(lllÔø¢œâÔø¢)ÔºåÊàëÊ≠£ÊòØ‰ªéÈÇ£Êó∂Ëµ∑ÔºåÁúãÁîµÂΩ±‰∏çÂÜçÊòØÁúãÁúãÂâßÊÉÖ‰∏ÄÁ¨ëËÄåËøá‰∫ÜÔºåËÄåÊòØÊ¨£ËµèÂØºÊºîÂíåÊºîÂëòÁöÑËâ∫ÊúØÔºåÁúãÂÆåÂêé‰ºöÂéªÂíåÂ•ΩÂèãËÅäËÅä‰∏çÂêåÁöÑËßÅËß£ÔºåËøô‰ªø‰Ωõ‰∏∫ÊàëÊâìÂºÄ‰∫ÜÊñ∞‰∏ñÁïåÁöÑÂ§ßÈó®Ôºå‰ªéÊ≠§Ê≤âËø∑ÁîµÂΩ±Êó†Ê≥ïËá™Êãî‰∫Ü„ÄÇ Âë®Êú´ËøéÁùÄÂëºÂëºÁöÑÈ£é‰∏ÄÂ§ßÊó©Ë∑ëÂéªÁîµÂΩ±Èô¢ÔºåÈÄî‰∏≠ÈÅáÂà∞‰∫ÜÂõ†‰∏∫È£éÂ§ßËÄåÊîπÂèòË°åÁ®ãÁöÑ‰∏§‰ΩçÂ•ΩÂèã‰∏ÄËµ∑ÈöèÊàëÂà∞ÂΩ±Èô¢ÔºåËôΩÁÑ∂Êàë‰ª¨‰ª®ÈÉΩÊòØÊ∏∏ÊàèËø∑Ôºå‰ΩÜÂè™ÊúâÊàëÊòØÂΩ±Ëø∑Ôºå‰ªñ‰ø©ÁúãÂÆåÂπ∂Ê≤°Êúâ‰ªÄ‰πàÊÑüÊÉ≥„ÄÇÁîµÂΩ±ÂºÄÂú∫‰ªãÁªç‰∫Ü‰∏ñÁïåËßÇ‰∏éÁ§æ‰ºöËÉåÊôØÔºåÂΩì‰∏ªËßíËøûÊé•ÁªøÊ¥≤Êó∂ÔºåÂ∑ÆÁÇπ‰ΩøÊàë‰∏≠‰∫å‰πãÈ≠ÇÁàÜÂèëÂñäÂá∫‰∫ÜLink StartÔºÅÔºåÂàÄÂâëÁ¨¨‰∏ÄÂ≠£ÊòØÊàëÊúÄÂñúÊ¨¢ÁöÑÂä®Êº´‰πã‰∏ÄÔºåÊé•ÁùÄÈó™ËøáÊàëÁöÑ‰∏ñÁïåÁ≠âÊ∏∏ÊàèÁîªÈù¢Ôºå‰ªãÁªçÂêÑÁßç‰∏ñÁïåÊó∂ËÆ©ÊàëÊÉ≥Âà∞‰∫ÜÊòüÈôÖÁâπÂ∑•¬∑ÂçÉÊòü‰πãÂüéÔºå‰∏Ä‰∏™Âú∫ÊôØÂíåÂ•≥‰∏ª‰∏çÈîôÔºå‰ΩÜÊïÖ‰∫ãÊúâÁÇπËÄÅÂ•óÁöÑÂïÜ‰∏öÁîµÂΩ±ÔºåËøôÊòØÂêïÂÖã¬∑Ë¥ùÊùæÂîØ‰∏ÄËÆ©ÊàëÁúãÁöÑÊúâÁÇπÁûåÁù°ÁöÑÁîµÂΩ±Ôºå‰∏çËÉΩÊÄ™‰ªñÔºåÂè™ÊÄ™ÈÇ£ÊòØ‰∏Ä‰∏™ÁøªÊãçÊó†Êï∞ÈÅçÁöÑÂâßÊú¨ÔºåÂΩìÊó∂ÊãÖÂøÉÊñØÁöÆÂ∞î‰ºØÊ†º‰ºö‰∏ç‰ºöÈô∑ÂÖ•ËøôÁßçÊÉÖÂÜµÔºåËøòÂ•ΩÂÖ®Á®ãÊó†Â∞øÁÇπÔºåÂâßÊÉÖÈùûÂ∏∏Á¥ßÂáë„ÄÇ Á¨¨‰∏ÄÂÖ≥ÊòØËÄÅÂè∏Êú∫ÂºÄËΩ¶Ôºå‰∏ªËßíÁöÑÂ∫ßÈ©æÊúâ‰∫õÁúºÁÜüÔºåÂêéÊù•ÁúãÂà´‰∫∫ËØ¥‰∫ÜÂõûÂà∞Êú™Êù•ÊâçÊÉ≥Ëµ∑Êù•ÔºåÂΩì‰∏ªËßíÂÄíÁùÄÂºÄËΩ¶Êó∂ÔºåÊàëÂõûÊÉ≥‰∫Ü‰∏ãÊàëÊúâÊ≤°ÊúâËøôÊ†∑Áé©ËøáÂë¢Ôºü‰∏Ä‰∏™ÊôïËΩ¶ÁöÑÂ∞èÂ≠©ÂΩìÁÑ∂‰πü‰∏ç‰ºöÂñúÊ¨¢ËµõËΩ¶Ê∏∏ÊàèÔºåÂú®Ê∏∏ÊàèÂéÖÁúãÂà´‰∫∫Áé©ÊûÅÂìÅÈ£ûËΩ¶ÁöÑÊàëÂõ†‰∏∫Ë∑ë‰∏çËøá‰∫∫ÂÆ∂ÊúâÊó∂‰ºöÁîüÊ∞îÁöÑÂÄíÁùÄÂºÄÔºåÂèçÊ≠£‰πüËøΩ‰∏ç‰∏ä‰∫ÜÂ∞±Èöè‰æøÁé©Áé©ÂêßÔºåÂπ∂‰∏çÊòØÊ≤°ÊúâÂ•ΩËÉúÂøÉÔºåËÄåÊòØÊÉ≥‰Ω†‰ª¨ÁúãÊàëÂºÄÂÄí‰∫ÜÔºåËæì‰∫Ü‰πüÂè™ÊòØÂõ†‰∏∫‰∏çÊÉ≥Áé©ÔºåÂëµÂëµ„ÄÇ„ÄÇÂú®‰∏ªËßíÂÄíËΩ¶Âà∞ËææÁªàÁÇπÊó∂ÔºåÊàëÊÉ≥Êàë‰πüÁªèÂ∏∏‰∏çÊåâÊ∏∏ÊàèËÆæËÆ°Ëµ∞Ôºå‰ºöÁûéË∑ë‰∏Ä‰ºö‰ΩÜÈÉΩÊó†ÁñæËÄåÁªàÔºåÊúâÊ≤°ÊúâÂÄíÁùÄÂç¥Ëµ¢ÁöÑÊó∂ÂÄôÂë¢ÔºåÊÄùÁª™ÂõûÂà∞‰∫Ü2008Âπ¥QQÈ£ûËΩ¶‰∏äÁ∫øÊó∂ÔºåÂíåÂ∞è‰ºô‰º¥ÊÑâÂø´ÁöÑÁé©ËÄçÔºåÊàëÂ±û‰∫éÊäÄÊúØÊØîËæÉËèúÁöÑÔºåÊºÇÁßªÈÉΩÊòØ360¬∞ÁöÑÔºåÂú®Áé©ÊúàÁâôÊπæÁöÑÂú∞ÂõæÊó∂ÔºåÂ•ΩÂèãÈÉΩÂø´È¢ÜÂÖàÊàë‰∏ÄÂúà‰∫ÜÔºåËÄåÊàëÊºÇÁßªÂêéÊâæ‰∏çÂà∞ÊñπÂêëÔºåÁªßÁª≠ÂêëÂâçÂºÄ‰ªñÂç¥ËøéÈù¢ÂêëÊàëÂºÄÊù•ÊääÊàëÊíûÂÅè‰∫ÜÔºåËØ¥ÊàëÊÄé‰πàÂèçÁùÄÂºÄÔºåÊàëËØ¥Êàë‰πü‰∏çÁü•Âà∞ÂïäÔºåÁ≥ªÁªü‰πüÊ≤°ÊèêÁ§∫ÊàëÔºåÂèçÊ≠£Êàë‰πüÂàÜ‰∏çÊ∏ÖÊñπÂêëÂ∞±ÁªßÁª≠ÂºÄÔºåÁÑ∂ÂêéÊàëÂ∞±Á¨¨‰∏Ä‰∫ÜÔºåËøòÊâìÁ†¥‰∫ÜËÆ∞ÂΩïÔºåÂ§ßÂÆ∂ÈÉΩÂæàÊÉäËÆ∂ÔºåÊàë‰ª¨‰ªîÁªÜÁ†îÁ©∂‰∏ãÂèëÁé∞‰∫ÜBUGÔºåÂú®Ëøá‰∏Ä‰∏™ÂºØÈÅìÂêéÂèçÂêëÂºÄÂõûÁªàÁÇπ‰πüÁÆóÂÆåÊàê‰∏ÄÂúà‰ΩÜË∑ØÈÄîËøë‰∫Ü‰∏ÄÂçäÔºå‰∫éÊòØÊàë‰ª¨ÂºÄÂßãÂà∑Ëøô‰∏™BUGÊääËá™Â∑±ÁöÑÂêçÊ¨°Âà∑Âà∞‰∫ÜÂÖ®ÊúçÊúÄÈ´òÔºåÂêéÊù•Áé©ÂÆ∂Âü∫Êú¨ÈÉΩÁü•ÈÅì‰∫ÜÔºåË∑ëÂõæÊó∂‰ºöÂèëÁé∞‰∏ÄÂçä‰∫∫Âú®ÂèçÂêëÂºÄÔºåÈÇ£Êó∂Áé©ÁöÑËøòÊòØÂæàÂºÄÂøÉÁöÑÔºåÂÜçÂêéÊù•BUGÂΩìÁÑ∂ÊòØË¢´‰øÆÂ§ç‰∫ÜÔºåÂàÜÊï∞‰πüË¢´Ê∏ÖÈõ∂‰∫ÜÔºåÊ≠£Âú®ÊàëÊÉ≥ÁùÄÂΩìÂπ¥‰∏ÄËµ∑ÂºÄËΩ¶ÁöÑÂú∫ÊôØÊó∂Ôºå‰∏ªËßíÂ∑≤ÁªèÊâæÂà∞‰∫ÜÁ¨¨‰∫åÊù°Á∫øÁ¥¢ÔºåÈó™ÁÅµÊòØÊàëÊúÄÊÉ≥Áúã‰ΩÜÊúÄ‰∏çÊï¢ÁúãÁöÑÊÅêÊÄñÁâá‰∫ÜÔºåÊâÄ‰ª•Ëá≥‰ªäÊ≤°ÊúâÊ≠£ÁúºÁúãËøáÔºåÂΩìÊàë‰ª¨ÁöÑÈí¢ÈìÅÂ∞ëÂπ¥ÊãøÁùÄÁêÉÈÅáÂà∞‰∫Ü‰ø©Â∞èËêùËéâÊó∂ÔºåÊàëÂ∞ΩÁÆ°Ê≤°ÁúãËøá‰ΩÜÊàëËøòÊòØÁü•ÈÅìÔºåË¶ÅÂèëÁîüÊÅêÊÄñÁöÑ‰∫ãÊÉÖ‰∫ÜÔºåÂΩìË°ÄÊ∞¥Ê∂åÂá∫ÁöÑÈïúÂ§¥ÂèàÂá∫Áé∞Êó∂ÔºåÊàëÊÉ≥Ëµ∑‰∫ÜÊòüÁà∑ÁöÑÂäüÂ§´ÔºåÈÇ£ÈÉ®ÁîµÂΩ±ÊòØÊàëÁ¨¨‰∏ÄÊ¨°Áü•ÈÅì‰∫ÜÈó™ÁÅµÔºåÁü•ÈÅì‰∫ÜÔºå‰∏ÄÈÉ®ÁîµÂΩ±ÂèØ‰ª•ÂêëÂè¶‰∏ÄÈÉ®ÁîµÂΩ±Ëá¥Êï¨ÔºåËÄå‰∏çËÉΩËØ¥ÊòØÊäÑË¢≠ÔºåËøòÂ•ΩËøôÊòØ‰∏ÄÈÉ®Â∏¶ÊúâÂñúÂâßËâ≤ÂΩ©ÁöÑÁîµÂΩ±Âπ∂Ê≤°Êúâ‰ªÄ‰πàÊÅêÊÄñÁöÑÈïúÂ§¥ÔºåÁÑ∂ÂêéÂâßÊÉÖÂèëÂ±ïÊúâ‰∫õÂø´ÔºåÁ¨¨‰∏âÂÖ≥IOIÊòØÊÄé‰πàÊâæÂà∞ÁöÑÔºå‰∏ªËßíÁöÑ‰πüÊ≤°ÊúâÊ†πÊçÆÊèêÁ§∫Ëé∑ÂèñÁ¨¨‰∏âÂÖ≥ÁöÑÊÉÖÊä•Ôºå‰∏çÊòØËØ¥Â•ΩÈóØËøá‰∏ÄÂÖ≥ÊâçÊúâÁ¨¨‰∫åÂÖ≥ÂêóÔºüÊÄé‰πàÁúãIOIÈÉΩÊòØ‰∏ÄÁõ¥Âú®ÂáÜÂ§áÁ¨¨‰∏âÂÖ≥ÔºåÂØºÊºî‰πüÊ≤°ÊúâÁªôÊàë‰ª¨Áïô‰∏ãÊÄùËÄÉËøô‰∏™ÈóÆÈ¢òÁöÑÊó∂Èó¥Ôºå‰∫éÊòØÂºÄÂßãÊâìÈõÖËææÂà©ÁöÑÊ∏∏ÊàèÊú∫ÔºåÈõÖËææÂà©ËøòÊòØÈÄöËøáÊïñÂéÇÈïøÁöÑ‰ªãÁªçÊâçÁü•ÈÅìÁöÑÔºåÂΩìÂπ¥ÈõÖËææÂà©Â∞±ÊòØÂõ†‰∏∫ÂºÄÂèë‰∫ÜÊñØÁöÆÂ∞î‰ºØÊ†ºÊãçÁöÑETÂ§ñÊòü‰∫∫Ê∏∏ÊàèËÄåËµ∞ÂêëË°∞ËêΩÁöÑÔºåÊàë‰ª•‰∏∫ÂØºÊºîË¶ÅÊâìËøôÈÉ®Ê∏∏ÊàèÔºå‰∏çÊòØÊõ¥ÊúâË∂£ÔºåÊúÄÂêé‰∏ªËßíÈöè‰æøÁé©Áé©ÊâæÂà∞‰∫ÜÂΩ©ËõãÔºåÔºàÂìàÂìàÔºåÊàëÂèØ‰∏ç‰ºöÂú®ÊàëÂÜôÁöÑ‰ª£Á†ÅÈáåÊîæ‰∏äÊàëÁöÑÂêçÂ≠óÔºåÈÇ£ÂèØÂ∞±Ë¶ÅË¢´‰∏ã‰∏™Êé•ÊâãÁöÑ‰∫∫È™ÇÊ≠ª‰∫ÜÔºâÂèàÁªèËøá‰∫ÜÊúÄÂêéÁöÑËÄÉÈ™åÔºåÂΩì‰∏ªËßíÈóÆÂìàÂà©Ëø™Ê≠ª‰∫ÜÂêóÁöÑÊó∂ÂÄôÂèàËÆ©ÊàëÊÉ≥Âà∞‰∫ÜÂàÄÂâëÁöÑËåÖÂú∫Êô∂ÂΩ¶ÔºåÁªìÂ±ÄÁöÜÂ§ßÊ¨¢ÂñúÔºå‰ΩèÂ±ÖÊàêÂäüÁöÑÂá∫‰ªªCEOÔºåËøéÂ®∂ÁôΩÂØåÁæéÔºåËµ∞‰∏ä‰∫∫ÁîüÂ∑ÖÂ≥∞„ÄÇ ÁúãÂÆåÁîµÂΩ±ËÆ©ÊàëÊòéÁôΩ‰∫ÜÔºåÊ∏∏ÊàèËøòÊòØÈöè‰æøÁé©Áé©Â∞±Â•ΩÔºåÊ∏∏ÊàèÊó†Ê≥ï‰ª£ÊõøÁé∞ÂÆûÁîüÊ¥ªÔºåÈöèÁùÄÂπ¥ÈæÑÁöÑÂ¢ûÈïøÊ∏∏Êàè‰∏≠ÁöÑËÉúË¥üÊòæÂæóÊ≤°ÈÇ£‰πàÈáçË¶Å‰∫ÜÔºåËÉΩÂíåÂ•ΩÊúãÂèãÂºÄÂºÄÈªëÂ∞±ÂæàÁæé‰∫ÜÔºåËøòÊúâ‰∏Ä‰∏™‰ªéÂ∞èÂ∞±ÊòéÁôΩÁöÑÈÅìÁêÜÔºåÊ∏∏ÊàèËøòÊòØË¶ÅÊúâÈòüÂèãÊâçÊúÄÂ•ΩÁé©„ÄÇ]]></content>
      <categories>
        <category>ÂΩ±ËØÑ</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ÂçöÂÆ¢Êê≠Âª∫Á¨îËÆ∞]]></title>
    <url>%2F2018%2F04%2F01%2F%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Êê≠Âª∫ÁéØÂ¢ÉËøôÊ¨°Â∞ùËØïÂú®UbuntuÁéØÂ¢É‰∏ãÊê≠Âª∫github+hexoÂçöÂÆ¢ËΩØ‰ª∂ÈúÄË¶Å‰ª•‰∏ãÂõõ‰∏™: Ubuntu 16.04 Node.js Hexo GitHub UbuntuÂÆâË£ÖÁï• NodeÁéØÂ¢ÉÂÆâË£ÖHexoÂçöÂÆ¢Á≥ªÁªüÊòØÈùôÊÄÅÁΩëÈ°µÁöÑÂΩ¢‰ººÔºå‰æùËµñNode.jsÔºåÁÆÄÂçïÁöÑËØ¥ Node.js Â∞±ÊòØËøêË°åÂú®ÊúçÂä°Á´ØÁöÑ JavaScript„ÄÇNode.js ÊòØ‰∏Ä‰∏™Âü∫‰∫éChrome JavaScript ËøêË°åÊó∂Âª∫Á´ãÁöÑ‰∏Ä‰∏™Âπ≥Âè∞„ÄÇÔºàÂÖ∂ÂÆûÊàëÂπ∂‰∏çÊáÇËøô‰∏™Áé©ÊÑèÔºâÂè™ÊòØHexoÈúÄË¶Å‰ΩøÁî®npmÂÆâË£ÖÔºånpmÊòØ‰æùÊâò‰∫énodeÁöÑÂÆâË£ÖËΩØ‰ª∂ÁÆ°ÁêÜÁ≥ªÁªü ÊñπÊ≥ï‰∏ÄWindowns‰∏ãÁõ¥Êé•‰∏ãËΩΩÂÆâË£ÖÔºåUbuntu ÊàëÂàöÂºÄÂßã‰ΩøÁî®‰∫Üapt-get installÁªìÊûúË£ÖÂÆåÂêéÁâàÊú¨Ëøá‰Ωé‰ΩøÂêéÈù¢ÁöÑÊê≠Âª∫ËøáÁ®ãÊé•ËøûÂá∫ÈîôÔºåÁõ¥Êé•‰ΩøÁî®ÁºñËØëÂ•ΩÁöÑÊñá‰ª∂ÂÆâË£ÖÔºåÈ¶ñÂÖàÂÆòÁΩë‰∏ãËΩΩÊúÄÊñ∞tarÂåÖÁÑ∂ÂêéÈìæÊé•‰∏∫ÂÖ®Â±Ä12345tar xf node-v5.10.1-linux-x64.tar.gz -C /usr/local/cd /usr/local/mv node-v5.10.1-linux-x64/ nodejsln -s /usr/local/nodejs/bin/node /usr/local/binln -s /usr/local/nodejs/bin/npm /usr/local/bin ÊñπÊ≥ï‰∫åÊ∫êÁ†ÅÂÆâË£ÖÂèÇËÄÉ‰∫ÜËèúÈ∏üÊïôÁ®ã 123456789101112131415161718Node.js Ê∫êÁ†ÅÂÆâË£Ö‰ª•‰∏ãÈÉ®ÂàÜÊàë‰ª¨Â∞Ü‰ªãÁªçÂú®Ubuntu Linux‰∏ãÂÆâË£Ö Node.js „ÄÇ ÂÖ∂‰ªñÁöÑLinuxÁ≥ªÁªüÔºåÂ¶ÇCentosÁ≠âÁ±ª‰ººÂ¶Ç‰∏ãÂÆâË£ÖÊ≠•È™§„ÄÇÂú® Github ‰∏äËé∑Âèñ Node.js Ê∫êÁ†ÅÔºö$ sudo git clone https://github.com/nodejs/node.gitCloning into 'node'...‰øÆÊîπÁõÆÂΩïÊùÉÈôêÔºö$ sudo chmod -R 755 node‰ΩøÁî® ./configure ÂàõÂª∫ÁºñËØëÊñá‰ª∂ÔºåÂπ∂ÊåâÁÖßÔºö$ cd node$ sudo ./configure$ sudo make$ sudo make installÊü•Áúã node ÁâàÊú¨Ôºö $ node --versionv10.0.0-pre$npm -v5.6.0 Ê∫êÁ†ÅÁºñËØëÁöÑÊó∂Èó¥ÊØîÊàëÊÉ≥Ë±°‰∏≠ÁöÑÈïøÂïä ÊñπÊ≥ï‰∏ânodesource123# Using Ubuntucurl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash -sudo apt-get install -y nodejs Ê≥®ÂÜå‰∏Ä‰∏™GitHubË¥¶Âè∑ÂÖ≥‰∫éGitÁöÑÂ≠¶‰π†‰ΩøÁúã‰∫ÜÂªñÈõ™Â≥∞ËÄÅÂ∏àÁöÑÂçöÂÆ¢ÔºåÂ•Ω‰πÖ‰πãÂâçÁúãÁöÑÈÉΩÂøò‰∫ÜÔºåÂìéhttps://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000 GithubË¥¶Êà∑Ê≥®ÂÜåÂíåÊñ∞Âª∫È°πÁõÆÔºåÈ°πÁõÆÂøÖÈ°ªË¶ÅÈÅµÂÆàÊ†ºÂºèÔºöË¥¶Êà∑Âêç.github.ioÔºå‰∏çÁÑ∂Êé•‰∏ãÊù•‰ºöÊúâÂæàÂ§öÈ∫ªÁÉ¶„ÄÇÂπ∂‰∏îÈúÄË¶ÅÂãæÈÄâInitialize this repository with a README Âú®Âª∫Â•ΩÁöÑÈ°πÁõÆÂè≥‰æßÊúâ‰∏™settingsÊåâÈíÆÔºåÁÇπÂáªÂÆÉÔºåÂêë‰∏ãÊãâÂà∞GitHub PagesÔºå‰Ω†‰ºöÁúãÂà∞ÈÇ£ËæπÊúâ‰∏™ÁΩëÂùÄÔºåËÆøÈóÆÂÆÉÔºå‰Ω†Â∞Ü‰ºöÊÉäÂ•áÁöÑÂèëÁé∞ËØ•È°πÁõÆÂ∑≤ÁªèË¢´ÈÉ®ÁΩ≤Âà∞ÁΩëÁªú‰∏äÔºåËÉΩÂ§üÈÄöËøáÂ§ñÁΩëÊù•ËÆøÈóÆÂÆÉ„ÄÇ HexoÂÆâË£ÖÊâæ‰∏™ÂêàÈÄÇÁöÑÂú∞Êñπ sudo npm npm install hexo-cli -g 12ÂõΩÂÜÖ‰∏änpmÂæàÊÖ¢ÊàñÂ§±Ë¥•ÔºåÂ∞ùËØïÊ∑òÂÆùÊ∫êÁöÑcnpmhttp://npm.taobao.org/ ËæìÂÖ•hexo -vÊ£ÄÊü•hexoÊòØÂê¶ÂÆâË£ÖÊàêÂäü ËæìÂÖ•hexo init,ÂàùÂßãÂåñÈ°πÁõÆÔºånpmÂõΩÂ§ñÁöÑÊ∫êÊúâÁÇπÊÖ¢ÂïäÔºåÂèØ‰ª•‰øÆÊîπ‰ΩøÁî®Ê∑òÂÆùÊ∫ê ËæìÂÖ•npm installÔºå ÂÆâË£ÖÊâÄÊúâÁªÑ‰ª∂ ËæìÂÖ•hexo gÔºåÂàõÂª∫ÈùôÊÄÅÁΩëÈ°µ ËæìÂÖ•hexo sÔºåÂºÄÂêØÊúçÂä°Âô®ÔºåËÆøÈóÆhttp://localhost:4000 ‰∏≠ÈÄîÂá∫Áé∞‰∫ÜÂ•ΩÂ§öÊ¨°errorÔºåÈô§‰∫ÜË¶ÅÂä†sudoÔºåËøòÊúâ‰∏Ä‰∫õÂ•áÊÄ™ÁöÑÈîôËØØÔºå‰ΩÜÊòØÈáçÂ§ç‰∫ÜÂá†ÈÅçÂ∞±Âè™Ââ©warn‰∫Ü„ÄÇ„ÄÇ„ÄÇ ÊÄªÁªì ‰ΩøÁî®ÊúÄÊñ∞ÁöÑËΩØ‰ª∂ÂíåËäÇÁÇπËÉΩÂáèÂ∞ëÂá∫ÈîôÂá†Áéá Â∞ÜHexo‰∏éGithub pageËÅîÁ≥ªËµ∑Êù•ÔºåËÆæÁΩÆGitÁöÑuser nameÂíåemailÔºàÂ¶ÇÊûúÊòØÁ¨¨‰∏ÄÊ¨°ÁöÑËØùÔºâ gitÊñπÈù¢Âè¶ÂÜô‰∏ÄÁØáÂçöÂÆ¢ ÊµãËØïÔºö Âú®ÁªàÁ´Ø ssh -T git@github.com Hi Voidmort! You&apos;ve successfully authenticated, but GitHub does not provide shell access. ÊàêÂäüÔºÅ ÈÖçÁΩÆDeploymentÔºåÂú®ÂÖ∂Êñá‰ª∂Â§π‰∏≠ÔºåÊâæÂà∞_config.ymlÊñá‰ª∂Ôºå‰øÆÊîπrepoÂÄºÔºàÂú®Êú´Â∞æÔºâ123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:Voidmort/Voidmort.github.io.git branch: master repoÂÄºÊòØgithubÈ°πÁõÆÈáåÁöÑsshÔºàÂè≥‰∏ãËßíÔºâ ÈÉ®ÁΩ≤Âà∞git‰πãÂâçË¶ÅË£Ö‰∏Ä‰∏™Êâ©Â±ïÔºö npm install hexo-deployer-git ‚Äìsave hexoÊåá‰ª§ 123456hexo n "ÊàëÁöÑÂçöÂÆ¢" == hexo new "ÊàëÁöÑÂçöÂÆ¢" #Êñ∞Âª∫ÊñáÁ´†hexo p == hexo publishhexo g == hexo generate#ÁîüÊàêhexo s == hexo server #ÂêØÂä®ÊúçÂä°È¢ÑËßàhexo d == hexo deploy#ÈÉ®ÁΩ≤hexo clean ÂüüÂêçÁªëÂÆöÊàëË¥≠‰π∞‰∫ÜÈòøÈáåÁöÑÂüüÂêçÔºåÈ¶ñÂÖàping voidmort.github.io,Êü•ÁúãIPÂú∞ÂùÄÁÑ∂ÂêéÁõ¥Êé•Âú®ÈòøÈáåÂüüÂêçÁÆ°ÁêÜÈáåÁÇπÊñ∞ÊâãÂºïÂØºÂÜô‰∏äIPÂú∞ÂùÄÔºåÁÑ∂Âêé‰ΩøÁî®Êñ∞ÂüüÂêçÁôªÈôÜÔºåÂèëÁé∞‰∏ä‰∏çÂéª„ÄÇ„ÄÇ„ÄÇÂú®GitHub setting‰∏≠ÊâæÂà∞Custom domain ÂÜô‰∏äÂàöË¥≠‰π∞ÁöÑÂüüÂêç OKÔºÅ ÂçöÂÆ¢Êê≠Âª∫ÂÆåÊàê Next ‰∏ªÈ¢òÊôãÁ∫ß‰∏ªÈ¢òÂú∞ÂùÄÔºötheme-next.iissnan.com ÊêúÁ¥¢ÊúçÂä°ÂæÆÊêúÁ¥¢ Áî± lzlun129 Ë¥°ÁåÆ npm install swig-templates TBD Local Search Áî± flashlab Ë¥°ÁåÆ Ê∑ªÂä†ÁôæÂ∫¶/Ë∞∑Ê≠å/Êú¨Âú∞ Ëá™ÂÆö‰πâÁ´ôÁÇπÂÜÖÂÆπÊêúÁ¥¢ ÂÆâË£Ö hexo-generator-searchdbÔºåÂú®Á´ôÁÇπÁöÑÊ†πÁõÆÂΩï‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö $ npm install hexo-generator-searchdb ‚Äìsave Problem$ hexo dERROR Deployer not found: git npm install ‚Äìsave hexo-deployer-git search: path: search.xml field: post format: html limit: 10000 ÁºñËæë ‰∏ªÈ¢òÈÖçÁΩÆÊñá‰ª∂ÔºåÂêØÁî®Êú¨Âú∞ÊêúÁ¥¢ÂäüËÉΩÔºö Local searchlocal_search: enable: true RSSÔºö ÈúÄË¶ÅÂÖàÂÆâË£Ö hexo-generator-feed Êèí‰ª∂„ÄÇhttps://github.com/hexojs/hexo-generator-feed Live2DÔºöhttps://www.npmjs.com/package/hexo-helper-live2d]]></content>
      <categories>
        <category>Â≠¶‰π†Á¨îËÆ∞</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkdownÂ≠¶‰π†Á¨îËÆ∞]]></title>
    <url>%2F2018%2F03%2F30%2FMarkdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ÂàùÊ¨°ÂÜôÂçöÂÆ¢Ôºå‰ªéÊê≠Âª∫github hexoËµ∞‰∫Ü‰∏çÂ∞ëÂùëÔºåÁ®çÂêéËÆ∞ÂΩïÊê≠Âª∫ÂçöÂÆ¢ËøáÁ®ãÔºåÈ¶ñÂÖàÂ≠¶‰π†‰ΩøÁî®markdownÊïôÁ®ãÊù•Ê∫êÔºöhttp://www.markdown.cn/markdownÊòØ‰∏Ä‰∏™HTMLÁöÑËΩ¨Êç¢Â∑•ÂÖ∑ÔºåÊòØHTMLÁöÑ‰π¶ÂÜôÊ†ºÂºè Ê†áÈ¢òËØ≠Ê≥ïÁ±ªAtxÂΩ¢ÂºèÂú®È¶ñË°åÊèíÂÖ•1‰∏™Âà∞6‰∏™#ÔºåÂØπÂ∫îÂà∞Ê†áÈ¢ò1Âà∞6‰∏ÄÂÆöË¶Å# + Á©∫Ê†º + Ê†áÈ¢òÂä†Á©∫Ê†ºÔºÅÔºÅÔºÅÔºÅÔºÅÔºÅ123# ‰∏ÄÁ∫ßÊ†áÈ¢ò## ‰∫åÁ∫ßÊ†áÈ¢ò###### ÂÖ≠Á∫ßÊ†áÈ¢ò Âå∫ÂùóÂºïÁî®ÊÆµÈ¶ñ‰ΩøÁî® &gt; ‰Ωú‰∏∫ÂºïÁî®ÔºåÂºïÁî®ÈÉ®ÂàÜ‰πüÊîØÊåÅmarkdownËØ≠Ê≥ï1234&gt;hello word!&gt;# Ê†áÈ¢ò‰∏Ä&gt;‰ª£Á†ÅÊèêÁ§∫Ôºö&gt; return Null; hello word! Ê†áÈ¢ò‰∏Ä‰ª£Á†ÅÊèêÁ§∫Ôºö return Null; ÂàóË°®markdownÊîØÊåÅÊúâÂ∫èÂíåÊó†Â∫èÂàóË°®Êó†Â∫èÂàóË°®Ê†áËÆ∞Á¨¶Âè∑ÂèØ‰ª•ÊòØ‚Äú* + -‚ÄùÔºåÊúâÂ∫èÁ¨¶Âè∑ÊòØÊï∞Â≠óÂä†Ëã±ÊñáÁÇπ‚Äú1. ‚Äù 123456789* red* green* blue+ red+ green- red1.good2.name3.learn red green blue red green red good name learn ‰ª£Á†ÅÂå∫ÂùóË¶ÅÂú® Markdown ‰∏≠Âª∫Á´ã‰ª£Á†ÅÂå∫ÂùóÂæàÁÆÄÂçïÔºåÂè™Ë¶ÅÁÆÄÂçïÂú∞Áº©Ëøõ 4 ‰∏™Á©∫Ê†ºÊàñÊòØ 1 ‰∏™Âà∂Ë°®Á¨¶Â∞±ÂèØ‰ª•Ôºå‰æãÂ¶ÇÔºå‰∏ãÈù¢ÁöÑËæìÂÖ•ÔºöËøôÊòØ‰∏Ä‰∏™ÊôÆÈÄöÊÆµËêΩÔºö 123456789 //ËøôÊòØ‰∏Ä‰∏™‰ª£Á†ÅÂå∫Âùó„ÄÇ#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main()&#123; print("Hello word!\n"); return 0;&#125; ÂàÜÂâ≤Á∫ø‰∏â‰∏™ËøûÁª≠ÁöÑ - _ ** ÈìæÊé•ÈìæÊé•ÊñáÂ≠óÁî®[ÊñπÊã¨Âè∑]Ê†áËÆ∞Ë¶ÅÂª∫Á´ã‰∏Ä‰∏™ÂÜÖË°åÂºèÈìæÊé•ÔºåÂè™Ë¶ÅÂú®ÊñπÊã¨Âè∑ÂêéÈù¢Á¥ßÊé•ÁùÄÂÖÉÊã¨Âè∑Âπ∂ÊèíÂÖ•ÁΩëÂùÄÈìæÊé• This is [an example](http://example.com/ &quot;Title&quot;) inline link. [This link](http://example.net/) has no title attribute. ÁôæÂ∫¶‰∏Ä‰∏ãThis is an example inline link.This link has no title attribute. ‰ª£Á†ÅÊ†áËÆ∞ÊÆµË°åÂÜÖ‰ª£Á†ÅÔºåÁî®ÂèçÂºïÂè∑ÂåÖËµ∑Êù•Ôºà‚ÄôÔºâ use the &apos;printf()&apos; function Use the printf() function. ÂõæÁâáÂíåÈìæÊé•‰∏ÄÊ†∑12![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg "Optional title") Alt text ËØ¶ÁªÜÂèôËø∞Â¶Ç‰∏ãÔºö ‰∏Ä‰∏™ÊÉäÂèπÂè∑ !Êé•ÁùÄ‰∏Ä‰∏™ÊñπÊã¨Âè∑ÔºåÈáåÈù¢Êîæ‰∏äÂõæÁâáÁöÑÊõø‰ª£ÊñáÂ≠óÊé•ÁùÄ‰∏Ä‰∏™ÊôÆÈÄöÊã¨Âè∑ÔºåÈáåÈù¢Êîæ‰∏äÂõæÁâáÁöÑÁΩëÂùÄÔºåÊúÄÂêéËøòÂèØ‰ª•Áî®ÂºïÂè∑ÂåÖ‰ΩèÂπ∂Âä†‰∏ä ÈÄâÊã©ÊÄßÁöÑ ‚Äòtitle‚Äô ÊñáÂ≠ó„ÄÇ ÂÖ∂‰ªñÂèçÊñúÊù†Âú®‰∏Ä‰∏ãÁ¨¶Âè∑ÂâçÈù¢Âä†ÂÖ•ÂèçÊñúÊù†Êù•ÊèíÂÖ•ÊôÆÈÄöÁ¨¶Âè∑Ôºö 123456789101112\ ÂèçÊñúÁ∫ø` ÂèçÂºïÂè∑* ÊòüÂè∑_ Â∫ïÁ∫ø&#123;&#125; Ëä±Êã¨Âè∑[] ÊñπÊã¨Âè∑() Êã¨Âºß# ‰∫ïÂ≠óÂè∑+ Âä†Âè∑- ÂáèÂè∑. Ëã±ÊñáÂè•ÁÇπ! ÊÉäÂèπÂè∑ Ëá™Âä®ÈìæÊé•Â§ÑÁêÜÁü≠ÈìæÊé•Áî®&lt;&gt;Êã¨‰ΩèËÉΩÂ§üËá™Âä®ËΩ¨Êç¢ÊàêÈìæÊé•http://www.baidu.com&#x77;&#x78;&#x6a;&#x35;&#54;&#53;&#56;&#64;&#x68;&#x6f;&#116;&#x6d;&#97;&#x69;&#x2e;&#x63;&#111;&#109; ÁºñËæëËΩØ‰ª∂windowsÂπ≥Âè∞ Markdownpad ÊøÄÊ¥ªÔºö 12345678Ê≥®ÂÜå‰ø°ÊÅØÈÇÆÁÆ±Âú∞ÂùÄÔºöSoar360@live.comÊéàÊùÉÂØÜÈí•ÔºöGBPduHjWfJU1mZqcPM3BikjYKF6xKhlKIys3i1MU2eJHqWGImDHzWdD6xhMNLGVpbP2M5SN6bnxn2kSE8qHqNY5QaaRxmO3YSMHxlv2EYpjdwLcPwfeTG7kUdnhKE0vVy4RidP6Y2wZ0q74f47fzsZo45JE2hfQBFi2O9Jldjp1mW8HUpTtLA2a5/sQytXJUQl/QKO0jUQY4pa5CCx20sV1ClOTZtAGngSOJtIOFXK599sBr5aIEFyH0K7H4BoNMiiDMnxt1rD8Vb/ikJdhGMMQr0R4B+L3nWU97eaVPTRKfWGDE8/eAgKzpGwrQQoDh+nzX1xoVQ8NAuH+s4UcSeQ== Âú®windows 10 Á≥ªÁªü‰∏ãÔºåwindows10 MarkdownPad html‰ºö‰∫ßÁîü‰∏Ä‰∏™ Ê∏≤ÊüìÈîôËØØ awesomiumÔºà This view has crashed ÔºâÔºåÊ≠§Êó∂Â∞±ÈúÄË¶Å‰∏ãËΩΩ‰∏Ä‰∏™ HTML UI ENGINEÔºàawesomium_v1.6.6_sdk_winÔºâÂéªËß£ÂÜ≥ËØ•ÈîôËØØÔºåËØ•ÁªÑ‰ª∂ÁöÑ‰∏ãËΩΩÂú∞ÂùÄÔºö http://markdownpad.com/download/awesomium_v1.6.6_sdk_win.exe]]></content>
      <categories>
        <category>Â≠¶‰π†Á¨îËÆ∞</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[„ÄêËΩ¨„Äë‰ªéÊú∫Âô®Â≠¶‰π†Ë∞àËµ∑]]></title>
    <url>%2F2018%2F03%2F21%2F%E4%BB%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B0%88%E8%B5%B7%2F</url>
    <content type="text"><![CDATA[‰ªéÂÜ≥ÂÆöÂêëAIÊñπÂêëËΩ¨Â∑≤ÁªèËøá‰∫ÜÂçäÂπ¥‰∫ÜÔºå‰π¶‰π∞‰∫ÜÂ•ΩÂ§öÔºåËøòÊ≤°ÊúâÊãÜÂ∞ÅÔºåÂõõÊúà‰∫ÜÔºåËøôÊ¨°ÊòØÂøÖÈ°ª‰∏ãÂÜ≥ÂøÉ‰∫ÜÔºå‰ªéÂçöÂÆ¢Êê≠Âª∫ÂºÄÂßãÔºåËÆ∞ÂΩïÂ≠¶‰π†ËøáÁ®ãÔºåÈ¶ñÂÖà‰ªéËøôÈáåÂºÄÂßãÔºåÊòØÊúÄÂàùÁúã‰∫ÜËøôÁØáÂçöÂÆ¢ÔºåÂºÄÂßã‰∫ÜËß£Êú∫Âô®Â≠¶‰π†ÔºåÊÑüË∞¢Âçö‰∏ªÁöÑÂ∏ÆÂä© ÂçöÂÆ¢ÂéüÂú∞ÂùÄÔºöhttps://www.cnblogs.com/subconscious/p/4107357.html#first ‰ΩúËÄÖÔºöËÆ°ÁÆóÊú∫ÁöÑÊΩúÊÑèËØÜ ‰ªéÊú∫Âô®Â≠¶‰π†Ë∞àËµ∑ Âú®Êú¨ÁØáÊñáÁ´†‰∏≠ÔºåÊàëÂ∞ÜÂØπÊú∫Âô®Â≠¶‰π†ÂÅö‰∏™Ê¶ÇË¶ÅÁöÑ‰ªãÁªç„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØËÉΩËÆ©Âç≥‰æøÂÆåÂÖ®‰∏ç‰∫ÜËß£Êú∫Âô®Â≠¶‰π†ÁöÑ‰∫∫‰πüËÉΩ‰∫ÜËß£Êú∫Âô®Â≠¶‰π†ÔºåÂπ∂‰∏î‰∏äÊâãÁõ∏ÂÖ≥ÁöÑÂÆûË∑µ„ÄÇËøôÁØáÊñáÊ°£‰πüÁÆóÊòØEasyPRÂºÄÂèëÁöÑÁï™Â§ñÁØáÔºå‰ªéËøôÈáåÂºÄÂßãÔºåÂøÖÈ°ªÂØπÊú∫Âô®Â≠¶‰π†‰∫ÜËß£ÊâçËÉΩËøõ‰∏ÄÊ≠•‰ªãÁªçEasyPRÁöÑÂÜÖÊ†∏„ÄÇÂΩìÁÑ∂ÔºåÊú¨Êñá‰πüÈù¢ÂØπ‰∏ÄËà¨ËØªËÄÖÔºå‰∏ç‰ºöÂØπÈòÖËØªÊúâÁõ∏ÂÖ≥ÁöÑÂâçÊèêË¶ÅÊ±Ç„ÄÇ Âú®ËøõÂÖ•Ê≠£È¢òÂâçÔºåÊàëÊÉ≥ËØªËÄÖÂøÉ‰∏≠ÂèØËÉΩ‰ºöÊúâ‰∏Ä‰∏™ÁñëÊÉëÔºöÊú∫Âô®Â≠¶‰π†Êúâ‰ªÄ‰πàÈáçË¶ÅÊÄßÔºå‰ª•Ëá≥‰∫éË¶ÅÈòÖËØªÂÆåËøôÁØáÈùûÂ∏∏ÈïøÁöÑÊñáÁ´†Âë¢Ôºü ÊàëÂπ∂‰∏çÁõ¥Êé•ÂõûÁ≠îËøô‰∏™ÈóÆÈ¢òÂâç„ÄÇÁõ∏ÂèçÔºåÊàëÊÉ≥ËØ∑Â§ßÂÆ∂Áúã‰∏§Âº†ÂõæÔºå‰∏ãÂõæÊòØÂõæ‰∏ÄÔºö&nbsp;Âõæ1 Êú∫Âô®Â≠¶‰π†ÁïåÁöÑÊâßÁâõËÄ≥ËÄÖ‰∏é‰∫íËÅîÁΩëÁïåÁöÑÂ§ßÈ≥ÑÁöÑËÅîÂßª ËøôÂπÖÂõæ‰∏ä‰∏äÁöÑ‰∏â‰∫∫ÊòØÂΩì‰ªäÊú∫Âô®Â≠¶‰π†ÁïåÁöÑÊâßÁâõËÄ≥ËÄÖ„ÄÇ‰∏≠Èó¥ÁöÑÊòØGeoffrey Hinton, Âä†ÊãøÂ§ßÂ§ö‰º¶Â§öÂ§ßÂ≠¶ÁöÑÊïôÊéàÔºåÂ¶Ç‰ªäË¢´ËÅò‰∏∫&ldquo;GoogleÂ§ßËÑë&rdquo;ÁöÑË¥üË¥£‰∫∫„ÄÇÂè≥ËæπÁöÑÊòØYann LeCun, Á∫ΩÁ∫¶Â§ßÂ≠¶ÊïôÊéàÔºåÂ¶Ç‰ªäÊòØFacebook‰∫∫Â∑•Êô∫ËÉΩÂÆûÈ™åÂÆ§ÁöÑ‰∏ª‰ªª„ÄÇËÄåÂ∑¶ËæπÁöÑÂ§ßÂÆ∂ÈÉΩÂæàÁÜüÊÇâÔºåAndrew NgÔºå‰∏≠ÊñáÂêçÂê¥ÊÅ©ËææÔºåÊñØÂù¶Á¶èÂ§ßÂ≠¶ÂâØÊïôÊéàÔºåÂ¶Ç‰ªä‰πüÊòØ&ldquo;ÁôæÂ∫¶Â§ßËÑë&rdquo;ÁöÑË¥üË¥£‰∫∫‰∏éÁôæÂ∫¶È¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂„ÄÇËøô‰∏â‰ΩçÈÉΩÊòØÁõÆÂâç‰∏öÁïåÁÇôÊâãÂèØÁÉ≠ÁöÑÂ§ßÁâõÔºåË¢´‰∫íËÅîÁΩëÁïåÂ§ßÈ≥ÑÊ±ÇË¥§Ëã•Ê∏¥ÁöÑËÅòËØ∑ÔºåË∂≥ËßÅ‰ªñ‰ª¨ÁöÑÈáçË¶ÅÊÄß„ÄÇËÄå‰ªñ‰ª¨ÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂàôÂÖ®ÈÉ®ÈÉΩÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÂ≠êÁ±ª‚ÄìÊ∑±Â∫¶Â≠¶‰π†„ÄÇ ‰∏ãÂõæÊòØÂõæ‰∫åÔºöÂõæ2 ËØ≠Èü≥Âä©Êâã‰∫ßÂìÅ ËøôÂπÖÂõæ‰∏äÊèèËø∞ÁöÑÊòØ‰ªÄ‰πàÔºüWindows Phone‰∏äÁöÑËØ≠Èü≥Âä©ÊâãCortanaÔºåÂêçÂ≠óÊù•Ê∫ê‰∫é„ÄäÂÖâÁéØ„Äã‰∏≠Â£´ÂÆòÈïøÁöÑÂä©Êâã„ÄÇÁõ∏ÊØîÂÖ∂‰ªñÁ´û‰∫âÂØπÊâãÔºåÂæÆËΩØÂæàËøüÊâçÊé®Âá∫Ëøô‰∏™ÊúçÂä°„ÄÇCortanaËÉåÂêéÁöÑÊ†∏ÂøÉÊäÄÊúØÊòØ‰ªÄ‰πàÔºå‰∏∫‰ªÄ‰πàÂÆÉËÉΩÂ§üÂê¨ÊáÇ‰∫∫ÁöÑËØ≠Èü≥Ôºü‰∫ãÂÆû‰∏äÔºåËøô‰∏™ÊäÄÊúØÊ≠£ÊòØÊú∫Âô®Â≠¶‰π†„ÄÇÊú∫Âô®Â≠¶‰π†ÊòØÊâÄÊúâËØ≠Èü≥Âä©Êâã‰∫ßÂìÅ(ÂåÖÊã¨AppleÁöÑsiri‰∏éGoogleÁöÑNow)ËÉΩÂ§üË∑ü‰∫∫‰∫§‰∫íÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇ ÈÄöËøá‰∏äÈù¢‰∏§ÂõæÔºåÊàëÁõ∏‰ø°Â§ßÂÆ∂ÂèØ‰ª•ÁúãÂá∫Êú∫Âô®Â≠¶‰π†‰ºº‰πéÊòØ‰∏Ä‰∏™ÂæàÈáçË¶ÅÁöÑÔºåÊúâÂæàÂ§öÊú™Áü•ÁâπÊÄßÁöÑÊäÄÊúØ„ÄÇÂ≠¶‰π†ÂÆÉ‰ºº‰πéÊòØ‰∏Ä‰ª∂ÊúâË∂£ÁöÑ‰ªªÂä°„ÄÇÂÆûÈôÖ‰∏äÔºåÂ≠¶‰π†Êú∫Âô®Â≠¶‰π†‰∏ç‰ªÖÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨‰∫ÜËß£‰∫íËÅîÁΩëÁïåÊúÄÊñ∞ÁöÑË∂ãÂäøÔºåÂêåÊó∂‰πüÂèØ‰ª•Áü•ÈÅì‰º¥ÈöèÊàë‰ª¨ÁöÑ‰æøÂà©ÊúçÂä°ÁöÑÂÆûÁé∞ÊäÄÊúØ„ÄÇ Êú∫Âô®Â≠¶‰π†ÊòØ‰ªÄ‰πàÔºå‰∏∫‰ªÄ‰πàÂÆÉËÉΩÊúâËøô‰πàÂ§ßÁöÑÈ≠îÂäõÔºåËøô‰∫õÈóÆÈ¢òÊ≠£ÊòØÊú¨ÊñáË¶ÅÂõûÁ≠îÁöÑ„ÄÇÂêåÊó∂ÔºåÊú¨ÊñáÂè´ÂÅö&ldquo;‰ªéÊú∫Âô®Â≠¶‰π†Ë∞àËµ∑&rdquo;ÔºåÂõ†Ê≠§‰ºö‰ª•Êº´Ë∞àÁöÑÂΩ¢Âºè‰ªãÁªçË∑üÊú∫Âô®Â≠¶‰π†Áõ∏ÂÖ≥ÁöÑÊâÄÊúâÂÜÖÂÆπÔºåÂåÖÊã¨Â≠¶Áßë(Â¶ÇÊï∞ÊçÆÊåñÊéò„ÄÅËÆ°ÁÆóÊú∫ËßÜËßâÁ≠â)ÔºåÁÆóÊ≥ï(Á•ûÁªèÁΩëÁªúÔºåsvm)Á≠âÁ≠â„ÄÇÊú¨ÊñáÁöÑ‰∏ªË¶ÅÁõÆÂΩïÂ¶Ç‰∏ãÔºö 1.‰∏Ä‰∏™ÊïÖ‰∫ãËØ¥Êòé‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π† 2.Êú∫Âô®Â≠¶‰π†ÁöÑÂÆö‰πâ 3.Êú∫Âô®Â≠¶‰π†ÁöÑËåÉÂõ¥ 4.Êú∫Âô®Â≠¶‰π†ÁöÑÊñπÊ≥ï 5.Êú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®‚ÄìÂ§ßÊï∞ÊçÆ 6.Êú∫Âô®Â≠¶‰π†ÁöÑÂ≠êÁ±ª‚ÄìÊ∑±Â∫¶Â≠¶‰π† 7.Êú∫Âô®Â≠¶‰π†ÁöÑÁà∂Á±ª‚Äì‰∫∫Â∑•Êô∫ËÉΩ 8.Êú∫Âô®Â≠¶‰π†ÁöÑÊÄùËÄÉ‚ÄìËÆ°ÁÆóÊú∫ÁöÑÊΩúÊÑèËØÜ 9.ÊÄªÁªì 10.ÂêéËÆ∞1.‰∏Ä‰∏™ÊïÖ‰∫ãËØ¥Êòé‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π† Êú∫Âô®Â≠¶‰π†Ëøô‰∏™ËØçÊòØËÆ©‰∫∫ÁñëÊÉëÁöÑÔºåÈ¶ñÂÖàÂÆÉÊòØËã±ÊñáÂêçÁß∞Machine Learning(ÁÆÄÁß∞ML)ÁöÑÁõ¥ËØëÔºåÂú®ËÆ°ÁÆóÁïåMachine‰∏ÄËà¨ÊåáËÆ°ÁÆóÊú∫„ÄÇËøô‰∏™ÂêçÂ≠ó‰ΩøÁî®‰∫ÜÊãü‰∫∫ÁöÑÊâãÊ≥ïÔºåËØ¥Êòé‰∫ÜËøôÈó®ÊäÄÊúØÊòØËÆ©Êú∫Âô®&ldquo;Â≠¶‰π†&rdquo;ÁöÑÊäÄÊúØ„ÄÇ‰ΩÜÊòØËÆ°ÁÆóÊú∫ÊòØÊ≠ªÁöÑÔºåÊÄé‰πàÂèØËÉΩÂÉè‰∫∫Á±ª‰∏ÄÊ†∑&ldquo;Â≠¶‰π†&rdquo;Âë¢Ôºü ‰º†Áªü‰∏äÂ¶ÇÊûúÊàë‰ª¨ÊÉ≥ËÆ©ËÆ°ÁÆóÊú∫Â∑•‰ΩúÔºåÊàë‰ª¨ÁªôÂÆÉ‰∏Ä‰∏≤Êåá‰ª§ÔºåÁÑ∂ÂêéÂÆÉÈÅµÁÖßËøô‰∏™Êåá‰ª§‰∏ÄÊ≠•Ê≠•ÊâßË°å‰∏ãÂéª„ÄÇÊúâÂõ†ÊúâÊûúÔºåÈùûÂ∏∏ÊòéÁ°Æ„ÄÇ‰ΩÜËøôÊ†∑ÁöÑÊñπÂºèÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Ë°å‰∏çÈÄö„ÄÇÊú∫Âô®Â≠¶‰π†Ê†πÊú¨‰∏çÊé•Âèó‰Ω†ËæìÂÖ•ÁöÑÊåá‰ª§ÔºåÁõ∏ÂèçÔºåÂÆÉÊé•Âèó‰Ω†ËæìÂÖ•ÁöÑÊï∞ÊçÆ! ‰πüÂ∞±ÊòØËØ¥ÔºåÊú∫Âô®Â≠¶‰π†ÊòØ‰∏ÄÁßçËÆ©ËÆ°ÁÆóÊú∫Âà©Áî®Êï∞ÊçÆËÄå‰∏çÊòØÊåá‰ª§Êù•ËøõË°åÂêÑÁßçÂ∑•‰ΩúÁöÑÊñπÊ≥ï„ÄÇËøôÂê¨Ëµ∑Êù•ÈùûÂ∏∏‰∏çÂèØÊÄùËÆÆÔºå‰ΩÜÁªìÊûú‰∏äÂç¥ÊòØÈùûÂ∏∏ÂèØË°åÁöÑ„ÄÇ&ldquo;ÁªüËÆ°&rdquo;ÊÄùÊÉ≥Â∞ÜÂú®‰Ω†Â≠¶‰π†&ldquo;Êú∫Âô®Â≠¶‰π†&rdquo;Áõ∏ÂÖ≥ÁêÜÂøµÊó∂Êó†Êó∂Êó†Âàª‰∏ç‰º¥ÈöèÔºåÁõ∏ÂÖ≥ËÄå‰∏çÊòØÂõ†ÊûúÁöÑÊ¶ÇÂøµÂ∞ÜÊòØÊîØÊíëÊú∫Âô®Â≠¶‰π†ËÉΩÂ§üÂ∑•‰ΩúÁöÑÊ†∏ÂøÉÊ¶ÇÂøµ„ÄÇ‰Ω†‰ºöÈ¢†Ë¶ÜÂØπ‰Ω†‰ª•ÂâçÊâÄÊúâÁ®ãÂ∫è‰∏≠Âª∫Á´ãÁöÑÂõ†ÊûúÊó†Â§Ñ‰∏çÂú®ÁöÑÊ†πÊú¨ÁêÜÂøµ„ÄÇ ‰∏ãÈù¢ÊàëÈÄöËøá‰∏Ä‰∏™ÊïÖ‰∫ãÊù•ÁÆÄÂçïÂú∞ÈòêÊòé‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π†„ÄÇËøô‰∏™ÊïÖ‰∫ãÊØîËæÉÈÄÇÂêàÁî®Âú®Áü•‰πé‰∏ä‰Ωú‰∏∫‰∏Ä‰∏™Ê¶ÇÂøµÁöÑÈòêÊòé„ÄÇÂú®ËøôÈáåÔºåËøô‰∏™ÊïÖ‰∫ãÊ≤°ÊúâÂ±ïÂºÄÔºå‰ΩÜÁõ∏ÂÖ≥ÂÜÖÂÆπ‰∏éÊ†∏ÂøÉÊòØÂ≠òÂú®ÁöÑ„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥ÁÆÄÂçïÁöÑ‰∫ÜËß£‰∏Ä‰∏ã‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π†ÔºåÈÇ£‰πàÁúãÂÆåËøô‰∏™ÊïÖ‰∫ãÂ∞±Ë∂≥Â§ü‰∫Ü„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥‰∫ÜËß£Êú∫Âô®Â≠¶‰π†ÁöÑÊõ¥Â§öÁü•ËØÜ‰ª•Âèä‰∏éÂÆÉÂÖ≥ËÅîÁ¥ßÂØÜÁöÑÂΩì‰ª£ÊäÄÊúØÔºåÈÇ£‰πàËØ∑‰Ω†ÁªßÁª≠ÂæÄ‰∏ãÁúãÔºåÂêéÈù¢ÊúâÊõ¥Â§öÁöÑ‰∏∞ÂØåÁöÑÂÜÖÂÆπ„ÄÇ Ëøô‰∏™‰æãÂ≠êÊù•Ê∫ê‰∫éÊàëÁúüÂÆûÁöÑÁîüÊ¥ªÁªèÈ™åÔºåÊàëÂú®ÊÄùËÄÉËøô‰∏™ÈóÆÈ¢òÁöÑÊó∂ÂÄôÁ™ÅÁÑ∂ÂèëÁé∞ÂÆÉÁöÑËøáÁ®ãÂèØ‰ª•Ë¢´Êâ©ÂÖÖÂåñ‰∏∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÊú∫Âô®Â≠¶‰π†ÁöÑËøáÁ®ãÔºåÂõ†Ê≠§ÊàëÂÜ≥ÂÆö‰ΩøÁî®Ëøô‰∏™‰æãÂ≠ê‰Ωú‰∏∫ÊâÄÊúâ‰ªãÁªçÁöÑÂºÄÂßã„ÄÇËøô‰∏™ÊïÖ‰∫ãÁß∞‰∏∫&ldquo;Á≠â‰∫∫ÈóÆÈ¢ò&rdquo;„ÄÇ ÊàëÁõ∏‰ø°Â§ßÂÆ∂ÈÉΩÊúâË∑üÂà´‰∫∫Áõ∏Á∫¶ÔºåÁÑ∂ÂêéÁ≠â‰∫∫ÁöÑÁªèÂéÜ„ÄÇÁé∞ÂÆû‰∏≠‰∏çÊòØÊØè‰∏™‰∫∫ÈÉΩÈÇ£‰πàÂÆàÊó∂ÁöÑÔºå‰∫éÊòØÂΩì‰Ω†Á¢∞Âà∞‰∏Ä‰∫õÁà±ËøüÂà∞ÁöÑ‰∫∫Ôºå‰Ω†ÁöÑÊó∂Èó¥‰∏çÂèØÈÅøÂÖçÁöÑË¶ÅÊµ™Ë¥π„ÄÇÊàëÂ∞±Á¢∞Âà∞ËøáËøôÊ†∑ÁöÑ‰∏Ä‰∏™‰æãÂ≠ê„ÄÇ ÂØπÊàëÁöÑ‰∏Ä‰∏™ÊúãÂèãÂ∞èYËÄåË®ÄÔºå‰ªñÂ∞±‰∏çÊòØÈÇ£‰πàÂÆàÊó∂ÔºåÊúÄÂ∏∏ËßÅÁöÑË°®Áé∞ÊòØ‰ªñÁªèÂ∏∏ËøüÂà∞„ÄÇÂΩìÊúâ‰∏ÄÊ¨°ÊàëË∑ü‰ªñÁ∫¶Â•Ω3ÁÇπÈíüÂú®Êüê‰∏™È∫¶ÂΩìÂä≥ËßÅÈù¢Êó∂ÔºåÂú®ÊàëÂá∫Èó®ÁöÑÈÇ£‰∏ÄÂàªÊàëÁ™ÅÁÑ∂ÊÉ≥Âà∞‰∏Ä‰∏™ÈóÆÈ¢òÔºöÊàëÁé∞Âú®Âá∫ÂèëÂêàÈÄÇ‰πàÔºüÊàë‰ºö‰∏ç‰ºöÂèàÂà∞‰∫ÜÂú∞ÁÇπÂêéÔºåËä±‰∏ä30ÂàÜÈíüÂéªÁ≠â‰ªñÔºüÊàëÂÜ≥ÂÆöÈááÂèñ‰∏Ä‰∏™Á≠ñÁï•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇ Ë¶ÅÊÉ≥Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊúâÂ•ΩÂá†ÁßçÊñπÊ≥ï„ÄÇÁ¨¨‰∏ÄÁßçÊñπÊ≥ïÊòØÈááÁî®Áü•ËØÜÔºöÊàëÊêúÂØªËÉΩÂ§üËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÁöÑÁü•ËØÜ„ÄÇ‰ΩÜÂæàÈÅóÊÜæÔºåÊ≤°Êúâ‰∫∫‰ºöÊääÂ¶Ç‰ΩïÁ≠â‰∫∫Ëøô‰∏™ÈóÆÈ¢ò‰Ωú‰∏∫Áü•ËØÜ‰º†ÊéàÔºåÂõ†Ê≠§Êàë‰∏çÂèØËÉΩÊâæÂà∞Â∑≤ÊúâÁöÑÁü•ËØÜËÉΩÂ§üËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢ò„ÄÇÁ¨¨‰∫åÁßçÊñπÊ≥ïÊòØÈóÆ‰ªñ‰∫∫ÔºöÊàëÂéªËØ¢ÈóÆ‰ªñ‰∫∫Ëé∑ÂæóËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÁöÑËÉΩÂäõ„ÄÇ‰ΩÜÊòØÂêåÊ†∑ÁöÑÔºåËøô‰∏™ÈóÆÈ¢òÊ≤°Êúâ‰∫∫ËÉΩÂ§üËß£Á≠îÔºåÂõ†‰∏∫ÂèØËÉΩÊ≤°‰∫∫Á¢∞‰∏äË∑üÊàë‰∏ÄÊ†∑ÁöÑÊÉÖÂÜµ„ÄÇÁ¨¨‰∏âÁßçÊñπÊ≥ïÊòØÂáÜÂàôÊ≥ïÔºöÊàëÈóÆËá™Â∑±ÁöÑÂÜÖÂøÉÔºåÊàëÊúâÂê¶ËÆæÁ´ãËøá‰ªÄ‰πàÂáÜÂàôÂéªÈù¢ÂØπËøô‰∏™ÈóÆÈ¢òÔºü‰æãÂ¶ÇÔºåÊó†ËÆ∫Âà´‰∫∫Â¶Ç‰ΩïÔºåÊàëÈÉΩ‰ºöÂÆàÊó∂Âà∞Ëææ„ÄÇ‰ΩÜÊàë‰∏çÊòØ‰∏™Ê≠ªÊùøÁöÑ‰∫∫ÔºåÊàëÊ≤°ÊúâËÆæÁ´ãËøáËøôÊ†∑ÁöÑËßÑÂàô„ÄÇ ‰∫ãÂÆû‰∏äÔºåÊàëÁõ∏‰ø°ÊúâÁßçÊñπÊ≥ïÊØî‰ª•‰∏ä‰∏âÁßçÈÉΩÂêàÈÄÇ„ÄÇÊàëÊääËøáÂæÄË∑üÂ∞èYÁõ∏Á∫¶ÁöÑÁªèÂéÜÂú®ËÑëÊµ∑‰∏≠ÈáçÁé∞‰∏Ä‰∏ãÔºåÁúãÁúãË∑ü‰ªñÁõ∏Á∫¶ÁöÑÊ¨°Êï∞‰∏≠ÔºåËøüÂà∞Âç†‰∫ÜÂ§öÂ§ßÁöÑÊØî‰æã„ÄÇËÄåÊàëÂà©Áî®ËøôÊù•È¢ÑÊµã‰ªñËøôÊ¨°ËøüÂà∞ÁöÑÂèØËÉΩÊÄß„ÄÇÂ¶ÇÊûúËøô‰∏™ÂÄºË∂ÖÂá∫‰∫ÜÊàëÂøÉÈáåÁöÑÊüê‰∏™ÁïåÈôêÔºåÈÇ£ÊàëÈÄâÊã©Á≠â‰∏Ä‰ºöÂÜçÂá∫Âèë„ÄÇÂÅáËÆæÊàëË∑üÂ∞èYÁ∫¶Ëøá5Ê¨°Ôºå‰ªñËøüÂà∞ÁöÑÊ¨°Êï∞ÊòØ1Ê¨°ÔºåÈÇ£‰πà‰ªñÊåâÊó∂Âà∞ÁöÑÊØî‰æã‰∏∫80%ÔºåÊàëÂøÉ‰∏≠ÁöÑÈòàÂÄº‰∏∫70%ÔºåÊàëËÆ§‰∏∫ËøôÊ¨°Â∞èYÂ∫îËØ•‰∏ç‰ºöËøüÂà∞ÔºåÂõ†Ê≠§ÊàëÊåâÊó∂Âá∫Èó®„ÄÇÂ¶ÇÊûúÂ∞èYÂú®5Ê¨°ËøüÂà∞ÁöÑÊ¨°Êï∞‰∏≠Âç†‰∫Ü4Ê¨°Ôºå‰πüÂ∞±ÊòØ‰ªñÊåâÊó∂Âà∞ËææÁöÑÊØî‰æã‰∏∫20%ÔºåÁî±‰∫éËøô‰∏™ÂÄº‰Ωé‰∫éÊàëÁöÑÈòàÂÄºÔºåÂõ†Ê≠§ÊàëÈÄâÊã©Êé®ËøüÂá∫Èó®ÁöÑÊó∂Èó¥„ÄÇËøô‰∏™ÊñπÊ≥ï‰ªéÂÆÉÁöÑÂà©Áî®Â±ÇÈù¢Êù•ÁúãÔºåÂèàÁß∞‰∏∫ÁªèÈ™åÊ≥ï„ÄÇÂú®ÁªèÈ™åÊ≥ïÁöÑÊÄùËÄÉËøáÁ®ã‰∏≠ÔºåÊàë‰∫ãÂÆû‰∏äÂà©Áî®‰∫Ü‰ª•ÂæÄÊâÄÊúâÁõ∏Á∫¶ÁöÑÊï∞ÊçÆ„ÄÇÂõ†Ê≠§‰πüÂèØ‰ª•Áß∞‰πã‰∏∫‰æùÊçÆÊï∞ÊçÆÂÅöÁöÑÂà§Êñ≠„ÄÇ ‰æùÊçÆÊï∞ÊçÆÊâÄÂÅöÁöÑÂà§Êñ≠Ë∑üÊú∫Âô®Â≠¶‰π†ÁöÑÊÄùÊÉ≥Ê†πÊú¨‰∏äÊòØ‰∏ÄËá¥ÁöÑ„ÄÇ ÂàöÊâçÁöÑÊÄùËÄÉËøáÁ®ãÊàëÂè™ËÄÉËôë&ldquo;È¢ëÊ¨°&rdquo;ËøôÁßçÂ±ûÊÄß„ÄÇÂú®ÁúüÂÆûÁöÑÊú∫Âô®Â≠¶‰π†‰∏≠ÔºåËøôÂèØËÉΩÈÉΩ‰∏çÁÆóÊòØ‰∏Ä‰∏™Â∫îÁî®„ÄÇ‰∏ÄËà¨ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãËá≥Â∞ëËÄÉËôë‰∏§‰∏™ÈáèÔºö‰∏Ä‰∏™ÊòØÂõ†ÂèòÈáèÔºå‰πüÂ∞±ÊòØÊàë‰ª¨Â∏åÊúõÈ¢ÑÊµãÁöÑÁªìÊûúÔºåÂú®Ëøô‰∏™‰æãÂ≠êÈáåÂ∞±ÊòØÂ∞èYËøüÂà∞‰∏éÂê¶ÁöÑÂà§Êñ≠„ÄÇÂè¶‰∏Ä‰∏™ÊòØËá™ÂèòÈáèÔºå‰πüÂ∞±ÊòØÁî®Êù•È¢ÑÊµãÂ∞èYÊòØÂê¶ËøüÂà∞ÁöÑÈáè„ÄÇÂÅáËÆæÊàëÊääÊó∂Èó¥‰Ωú‰∏∫Ëá™ÂèòÈáèÔºåË≠¨Â¶ÇÊàëÂèëÁé∞Â∞èYÊâÄÊúâËøüÂà∞ÁöÑÊó•Â≠êÂü∫Êú¨ÈÉΩÊòØÊòüÊúü‰∫îÔºåËÄåÂú®ÈùûÊòüÊúü‰∫îÊÉÖÂÜµ‰∏ã‰ªñÂü∫Êú¨‰∏çËøüÂà∞„ÄÇ‰∫éÊòØÊàëÂèØ‰ª•Âª∫Á´ã‰∏Ä‰∏™Ê®°ÂûãÔºåÊù•Ê®°ÊãüÂ∞èYËøüÂà∞‰∏éÂê¶Ë∑üÊó•Â≠êÊòØÂê¶ÊòØÊòüÊúü‰∫îÁöÑÊ¶ÇÁéá„ÄÇËßÅ‰∏ãÂõæÔºö&nbsp;Âõæ3 ÂÜ≥Á≠ñÊ†ëÊ®°Âûã ËøôÊ†∑ÁöÑÂõæÂ∞±ÊòØ‰∏Ä‰∏™ÊúÄÁÆÄÂçïÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºåÁß∞‰πã‰∏∫ÂÜ≥Á≠ñÊ†ë„ÄÇ ÂΩìÊàë‰ª¨ËÄÉËôëÁöÑËá™ÂèòÈáèÂè™Êúâ‰∏Ä‰∏™Êó∂ÔºåÊÉÖÂÜµËæÉ‰∏∫ÁÆÄÂçï„ÄÇÂ¶ÇÊûúÊääÊàë‰ª¨ÁöÑËá™ÂèòÈáèÂÜçÂ¢ûÂä†‰∏Ä‰∏™„ÄÇ‰æãÂ¶ÇÂ∞èYËøüÂà∞ÁöÑÈÉ®ÂàÜÊÉÖÂÜµÊó∂ÊòØÂú®‰ªñÂºÄËΩ¶ËøáÊù•ÁöÑÊó∂ÂÄô(‰Ω†ÂèØ‰ª•ÁêÜËß£‰∏∫‰ªñÂºÄËΩ¶Ê∞¥Âπ≥ËæÉËá≠ÔºåÊàñËÄÖË∑ØËæÉÂ†µ)„ÄÇ‰∫éÊòØÊàëÂèØ‰ª•ÂÖ≥ËÅîËÄÉËôëËøô‰∫õ‰ø°ÊÅØ„ÄÇÂª∫Á´ã‰∏Ä‰∏™Êõ¥Â§çÊùÇÁöÑÊ®°ÂûãÔºåËøô‰∏™Ê®°ÂûãÂåÖÂê´‰∏§‰∏™Ëá™ÂèòÈáè‰∏é‰∏Ä‰∏™Âõ†ÂèòÈáè„ÄÇ ÂÜçÊõ¥Â§çÊùÇ‰∏ÄÁÇπÔºåÂ∞èYÁöÑËøüÂà∞Ë∑üÂ§©Ê∞î‰πüÊúâ‰∏ÄÂÆöÁöÑÂéüÂõ†Ôºå‰æãÂ¶Ç‰∏ãÈõ®ÁöÑÊó∂ÂÄôÔºåËøôÊó∂ÂÄôÊàëÈúÄË¶ÅËÄÉËôë‰∏â‰∏™Ëá™ÂèòÈáè„ÄÇ Â¶ÇÊûúÊàëÂ∏åÊúõËÉΩÂ§üÈ¢ÑÊµãÂ∞èYËøüÂà∞ÁöÑÂÖ∑‰ΩìÊó∂Èó¥ÔºåÊàëÂèØ‰ª•Êää‰ªñÊØèÊ¨°ËøüÂà∞ÁöÑÊó∂Èó¥Ë∑üÈõ®ÈáèÁöÑÂ§ßÂ∞è‰ª•ÂèäÂâçÈù¢ËÄÉËôëÁöÑËá™ÂèòÈáèÁªü‰∏ÄÂª∫Á´ã‰∏Ä‰∏™Ê®°Âûã„ÄÇ‰∫éÊòØÊàëÁöÑÊ®°ÂûãÂèØ‰ª•È¢ÑÊµãÂÄºÔºå‰æãÂ¶Ç‰ªñÂ§ßÊ¶Ç‰ºöËøüÂà∞Âá†ÂàÜÈíü„ÄÇËøôÊ†∑ÂèØ‰ª•Â∏ÆÂä©ÊàëÊõ¥Â•ΩÁöÑËßÑÂàíÊàëÂá∫Èó®ÁöÑÊó∂Èó¥„ÄÇÂú®ËøôÊ†∑ÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÜ≥Á≠ñÊ†ëÂ∞±Êó†Ê≥ïÂæàÂ•ΩÂú∞ÊîØÊíë‰∫ÜÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÊ†ëÂè™ËÉΩÈ¢ÑÊµãÁ¶ªÊï£ÂÄº„ÄÇÊàë‰ª¨ÂèØ‰ª•Áî®ËäÇ2ÊâÄ‰ªãÁªçÁöÑÁ∫øÂûãÂõûÂΩíÊñπÊ≥ïÂª∫Á´ãËøô‰∏™Ê®°Âûã„ÄÇ Â¶ÇÊûúÊàëÊääËøô‰∫õÂª∫Á´ãÊ®°ÂûãÁöÑËøáÁ®ã‰∫§ÁªôÁîµËÑë„ÄÇÊØîÂ¶ÇÊääÊâÄÊúâÁöÑËá™ÂèòÈáèÂíåÂõ†ÂèòÈáèËæìÂÖ•ÔºåÁÑ∂ÂêéËÆ©ËÆ°ÁÆóÊú∫Â∏ÆÊàëÁîüÊàê‰∏Ä‰∏™Ê®°ÂûãÔºåÂêåÊó∂ËÆ©ËÆ°ÁÆóÊú∫Ê†πÊçÆÊàëÂΩìÂâçÁöÑÊÉÖÂÜµÔºåÁªôÂá∫ÊàëÊòØÂê¶ÈúÄË¶ÅËøüÂá∫Èó®ÔºåÈúÄË¶ÅËøüÂá†ÂàÜÈíüÁöÑÂª∫ËÆÆ„ÄÇÈÇ£‰πàËÆ°ÁÆóÊú∫ÊâßË°åËøô‰∫õËæÖÂä©ÂÜ≥Á≠ñÁöÑËøáÁ®ãÂ∞±ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑËøáÁ®ã„ÄÇ Êú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÊòØËÆ°ÁÆóÊú∫Âà©Áî®Â∑≤ÊúâÁöÑÊï∞ÊçÆ(ÁªèÈ™å)ÔºåÂæóÂá∫‰∫ÜÊüêÁßçÊ®°Âûã(ËøüÂà∞ÁöÑËßÑÂæã)ÔºåÂπ∂Âà©Áî®Ê≠§Ê®°ÂûãÈ¢ÑÊµãÊú™Êù•(ÊòØÂê¶ËøüÂà∞)ÁöÑ‰∏ÄÁßçÊñπÊ≥ï„ÄÇ ÈÄöËøá‰∏äÈù¢ÁöÑÂàÜÊûêÔºåÂèØ‰ª•ÁúãÂá∫Êú∫Âô®Â≠¶‰π†‰∏é‰∫∫Á±ªÊÄùËÄÉÁöÑÁªèÈ™åËøáÁ®ãÊòØÁ±ª‰ººÁöÑÔºå‰∏çËøáÂÆÉËÉΩËÄÉËôëÊõ¥Â§öÁöÑÊÉÖÂÜµÔºåÊâßË°åÊõ¥Âä†Â§çÊùÇÁöÑËÆ°ÁÆó„ÄÇ‰∫ãÂÆû‰∏äÔºåÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™‰∏ªË¶ÅÁõÆÁöÑÂ∞±ÊòØÊää‰∫∫Á±ªÊÄùËÄÉÂΩíÁ∫≥ÁªèÈ™åÁöÑËøáÁ®ãËΩ¨Âåñ‰∏∫ËÆ°ÁÆóÊú∫ÈÄöËøáÂØπÊï∞ÊçÆÁöÑÂ§ÑÁêÜËÆ°ÁÆóÂæóÂá∫Ê®°ÂûãÁöÑËøáÁ®ã„ÄÇÁªèËøáËÆ°ÁÆóÊú∫ÂæóÂá∫ÁöÑÊ®°ÂûãËÉΩÂ§ü‰ª•Ëøë‰ºº‰∫é‰∫∫ÁöÑÊñπÂºèËß£ÂÜ≥ÂæàÂ§öÁÅµÊ¥ªÂ§çÊùÇÁöÑÈóÆÈ¢ò„ÄÇ ‰∏ãÈù¢ÔºåÊàë‰ºöÂºÄÂßãÂØπÊú∫Âô®Â≠¶‰π†ÁöÑÊ≠£Âºè‰ªãÁªçÔºåÂåÖÊã¨ÂÆö‰πâ„ÄÅËåÉÂõ¥ÔºåÊñπÊ≥ï„ÄÅÂ∫îÁî®Á≠âÁ≠âÔºåÈÉΩÊúâÊâÄÂåÖÂê´„ÄÇ&nbsp;2.Êú∫Âô®Â≠¶‰π†ÁöÑÂÆö‰πâ ‰ªéÂπø‰πâ‰∏äÊù•ËØ¥ÔºåÊú∫Âô®Â≠¶‰π†ÊòØ‰∏ÄÁßçËÉΩÂ§üËµã‰∫àÊú∫Âô®Â≠¶‰π†ÁöÑËÉΩÂäõ‰ª•Ê≠§ËÆ©ÂÆÉÂÆåÊàêÁõ¥Êé•ÁºñÁ®ãÊó†Ê≥ïÂÆåÊàêÁöÑÂäüËÉΩÁöÑÊñπÊ≥ï„ÄÇ‰ΩÜ‰ªéÂÆûË∑µÁöÑÊÑè‰πâ‰∏äÊù•ËØ¥ÔºåÊú∫Âô®Â≠¶‰π†ÊòØ‰∏ÄÁßçÈÄöËøáÂà©Áî®Êï∞ÊçÆÔºåËÆ≠ÁªÉÂá∫Ê®°ÂûãÔºåÁÑ∂Âêé‰ΩøÁî®Ê®°ÂûãÈ¢ÑÊµãÁöÑ‰∏ÄÁßçÊñπÊ≥ï„ÄÇ ËÆ©Êàë‰ª¨ÂÖ∑‰ΩìÁúã‰∏Ä‰∏™‰æãÂ≠ê„ÄÇÂõæ4 Êàø‰ª∑ÁöÑ‰æãÂ≠ê ÊãøÂõΩÊ∞ëËØùÈ¢òÁöÑÊàøÂ≠êÊù•ËØ¥„ÄÇÁé∞Âú®ÊàëÊâãÈáåÊúâ‰∏ÄÊ†ãÊàøÂ≠êÈúÄË¶ÅÂîÆÂçñÔºåÊàëÂ∫îËØ•ÁªôÂÆÉÊ†á‰∏äÂ§öÂ§ßÁöÑ‰ª∑Ê†ºÔºüÊàøÂ≠êÁöÑÈù¢ÁßØÊòØ100Âπ≥ÊñπÁ±≥Ôºå‰ª∑Ê†ºÊòØ100‰∏áÔºå120‰∏áÔºåËøòÊòØ140‰∏áÔºü ÂæàÊòæÁÑ∂ÔºåÊàëÂ∏åÊúõËé∑ÂæóÊàø‰ª∑‰∏éÈù¢ÁßØÁöÑÊüêÁßçËßÑÂæã„ÄÇÈÇ£‰πàÊàëËØ•Â¶Ç‰ΩïËé∑ÂæóËøô‰∏™ËßÑÂæãÔºüÁî®Êä•Á∫∏‰∏äÁöÑÊàø‰ª∑Âπ≥ÂùáÊï∞ÊçÆ‰πàÔºüËøòÊòØÂèÇËÄÉÂà´‰∫∫Èù¢ÁßØÁõ∏‰ººÁöÑÔºüÊó†ËÆ∫Âì™ÁßçÔºå‰ºº‰πéÈÉΩÂπ∂‰∏çÊòØÂ§™Èù†Ë∞±„ÄÇ ÊàëÁé∞Âú®Â∏åÊúõËé∑Âæó‰∏Ä‰∏™ÂêàÁêÜÁöÑÔºåÂπ∂‰∏îËÉΩÂ§üÊúÄÂ§ßÁ®ãÂ∫¶ÁöÑÂèçÊò†Èù¢ÁßØ‰∏éÊàø‰ª∑ÂÖ≥Á≥ªÁöÑËßÑÂæã„ÄÇ‰∫éÊòØÊàëË∞ÉÊü•‰∫ÜÂë®Ëæπ‰∏éÊàëÊàøÂûãÁ±ª‰ººÁöÑ‰∏Ä‰∫õÊàøÂ≠êÔºåËé∑Âæó‰∏ÄÁªÑÊï∞ÊçÆ„ÄÇËøôÁªÑÊï∞ÊçÆ‰∏≠ÂåÖÂê´‰∫ÜÂ§ßÂ§ßÂ∞èÂ∞èÊàøÂ≠êÁöÑÈù¢ÁßØ‰∏é‰ª∑Ê†ºÔºåÂ¶ÇÊûúÊàëËÉΩ‰ªéËøôÁªÑÊï∞ÊçÆ‰∏≠ÊâæÂá∫Èù¢ÁßØ‰∏é‰ª∑Ê†ºÁöÑËßÑÂæãÔºåÈÇ£‰πàÊàëÂ∞±ÂèØ‰ª•ÂæóÂá∫ÊàøÂ≠êÁöÑ‰ª∑Ê†º„ÄÇ ÂØπËßÑÂæãÁöÑÂØªÊâæÂæàÁÆÄÂçïÔºåÊãüÂêàÂá∫‰∏ÄÊù°Áõ¥Á∫øÔºåËÆ©ÂÆÉ&ldquo;Á©øËøá&rdquo;ÊâÄÊúâÁöÑÁÇπÔºåÂπ∂‰∏î‰∏éÂêÑ‰∏™ÁÇπÁöÑË∑ùÁ¶ªÂ∞ΩÂèØËÉΩÁöÑÂ∞è„ÄÇ ÈÄöËøáËøôÊù°Áõ¥Á∫øÔºåÊàëËé∑Âæó‰∫Ü‰∏Ä‰∏™ËÉΩÂ§üÊúÄ‰Ω≥ÂèçÊò†Êàø‰ª∑‰∏éÈù¢ÁßØËßÑÂæãÁöÑËßÑÂæã„ÄÇËøôÊù°Áõ¥Á∫øÂêåÊó∂‰πüÊòØ‰∏Ä‰∏™‰∏ãÂºèÊâÄË°®ÊòéÁöÑÂáΩÊï∞Ôºö Êàø‰ª∑ = Èù¢ÁßØ a + b ‰∏äËø∞‰∏≠ÁöÑa„ÄÅbÈÉΩÊòØÁõ¥Á∫øÁöÑÂèÇÊï∞„ÄÇËé∑ÂæóËøô‰∫õÂèÇÊï∞‰ª•ÂêéÔºåÊàëÂ∞±ÂèØ‰ª•ËÆ°ÁÆóÂá∫ÊàøÂ≠êÁöÑ‰ª∑Ê†º„ÄÇ ÂÅáËÆæa = 0.75,b = 50ÔºåÂàôÊàø‰ª∑ = 100 0.75 + 50 = 125‰∏á„ÄÇËøô‰∏™ÁªìÊûú‰∏éÊàëÂâçÈù¢ÊâÄÂàóÁöÑ100‰∏áÔºå120‰∏áÔºå140‰∏áÈÉΩ‰∏ç‰∏ÄÊ†∑„ÄÇÁî±‰∫éËøôÊù°Áõ¥Á∫øÁªºÂêàËÄÉËôë‰∫ÜÂ§ßÈÉ®ÂàÜÁöÑÊÉÖÂÜµÔºåÂõ†Ê≠§‰ªé&ldquo;ÁªüËÆ°&rdquo;ÊÑè‰πâ‰∏äÊù•ËØ¥ÔºåËøôÊòØ‰∏Ä‰∏™ÊúÄÂêàÁêÜÁöÑÈ¢ÑÊµã„ÄÇ Âú®Ê±ÇËß£ËøáÁ®ã‰∏≠ÈÄèÈú≤Âá∫‰∫Ü‰∏§‰∏™‰ø°ÊÅØÔºö 1.Êàø‰ª∑Ê®°ÂûãÊòØÊ†πÊçÆÊãüÂêàÁöÑÂáΩÊï∞Á±ªÂûãÂÜ≥ÂÆöÁöÑ„ÄÇÂ¶ÇÊûúÊòØÁõ¥Á∫øÔºåÈÇ£‰πàÊãüÂêàÂá∫ÁöÑÂ∞±ÊòØÁõ¥Á∫øÊñπÁ®ã„ÄÇÂ¶ÇÊûúÊòØÂÖ∂‰ªñÁ±ªÂûãÁöÑÁ∫øÔºå‰æãÂ¶ÇÊäõÁâ©Á∫øÔºåÈÇ£‰πàÊãüÂêàÂá∫ÁöÑÂ∞±ÊòØÊäõÁâ©Á∫øÊñπÁ®ã„ÄÇÊú∫Âô®Â≠¶‰π†Êúâ‰ºóÂ§öÁÆóÊ≥ïÔºå‰∏Ä‰∫õÂº∫ÂäõÁÆóÊ≥ïÂèØ‰ª•ÊãüÂêàÂá∫Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÊ®°ÂûãÔºåÁî®Êù•ÂèçÊò†‰∏Ä‰∫õ‰∏çÊòØÁõ¥Á∫øÊâÄËÉΩË°®ËææÁöÑÊÉÖÂÜµ„ÄÇ 2.Â¶ÇÊûúÊàëÁöÑÊï∞ÊçÆË∂äÂ§öÔºåÊàëÁöÑÊ®°ÂûãÂ∞±Ë∂äËÉΩÂ§üËÄÉËôëÂà∞Ë∂äÂ§öÁöÑÊÉÖÂÜµÔºåÁî±Ê≠§ÂØπ‰∫éÊñ∞ÊÉÖÂÜµÁöÑÈ¢ÑÊµãÊïàÊûúÂèØËÉΩÂ∞±Ë∂äÂ•Ω„ÄÇËøôÊòØÊú∫Âô®Â≠¶‰π†Áïå&ldquo;Êï∞ÊçÆ‰∏∫Áéã&rdquo;ÊÄùÊÉ≥ÁöÑ‰∏Ä‰∏™‰ΩìÁé∞„ÄÇ‰∏ÄËà¨Êù•ËØ¥(‰∏çÊòØÁªùÂØπ)ÔºåÊï∞ÊçÆË∂äÂ§öÔºåÊúÄÂêéÊú∫Âô®Â≠¶‰π†ÁîüÊàêÁöÑÊ®°ÂûãÈ¢ÑÊµãÁöÑÊïàÊûúË∂äÂ•Ω„ÄÇ ÈÄöËøáÊàëÊãüÂêàÁõ¥Á∫øÁöÑËøáÁ®ãÔºåÊàë‰ª¨ÂèØ‰ª•ÂØπÊú∫Âô®Â≠¶‰π†ËøáÁ®ãÂÅö‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÂõûÈ°æ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅÂú®ËÆ°ÁÆóÊú∫‰∏≠Â≠òÂÇ®ÂéÜÂè≤ÁöÑÊï∞ÊçÆ„ÄÇÊé•ÁùÄÔºåÊàë‰ª¨Â∞ÜËøô‰∫õ Êï∞ÊçÆÈÄöËøáÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïËøõË°åÂ§ÑÁêÜÔºåËøô‰∏™ËøáÁ®ãÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Âè´ÂÅö&ldquo;ËÆ≠ÁªÉ&rdquo;ÔºåÂ§ÑÁêÜÁöÑÁªìÊûúÂèØ‰ª•Ë¢´Êàë‰ª¨Áî®Êù•ÂØπÊñ∞ÁöÑÊï∞ÊçÆËøõË°åÈ¢ÑÊµãÔºåËøô‰∏™ÁªìÊûú‰∏ÄËà¨Áß∞‰πã‰∏∫&ldquo;Ê®°Âûã&rdquo;„ÄÇÂØπÊñ∞Êï∞ÊçÆ ÁöÑÈ¢ÑÊµãËøáÁ®ãÂú®Êú∫Âô®Â≠¶‰π†‰∏≠Âè´ÂÅö&ldquo;È¢ÑÊµã&rdquo;„ÄÇ&ldquo;ËÆ≠ÁªÉ&rdquo;‰∏é&ldquo;È¢ÑÊµã&rdquo;ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏§‰∏™ËøáÁ®ãÔºå&ldquo;Ê®°Âûã&rdquo;ÂàôÊòØËøáÁ®ãÁöÑ‰∏≠Èó¥ËæìÂá∫ÁªìÊûúÔºå&ldquo;ËÆ≠ÁªÉ&rdquo;‰∫ßÁîü&ldquo;Ê®°Âûã&rdquo;Ôºå&ldquo;Ê®°Âûã&rdquo;ÊåáÂØº &ldquo;È¢ÑÊµã&rdquo;„ÄÇ ËÆ©Êàë‰ª¨ÊääÊú∫Âô®Â≠¶‰π†ÁöÑËøáÁ®ã‰∏é‰∫∫Á±ªÂØπÂéÜÂè≤ÁªèÈ™åÂΩíÁ∫≥ÁöÑËøáÁ®ãÂÅö‰∏™ÊØîÂØπ„ÄÇÂõæ5 Êú∫Âô®Â≠¶‰π†‰∏é‰∫∫Á±ªÊÄùËÄÉÁöÑÁ±ªÊØî ‰∫∫Á±ªÂú®ÊàêÈïø„ÄÅÁîüÊ¥ªËøáÁ®ã‰∏≠ÁßØÁ¥Ø‰∫ÜÂæàÂ§öÁöÑÂéÜÂè≤‰∏éÁªèÈ™å„ÄÇ‰∫∫Á±ªÂÆöÊúüÂú∞ÂØπËøô‰∫õÁªèÈ™åËøõË°å&ldquo;ÂΩíÁ∫≥&rdquo;ÔºåËé∑Âæó‰∫ÜÁîüÊ¥ªÁöÑ&ldquo;ËßÑÂæã&rdquo;„ÄÇÂΩì‰∫∫Á±ªÈÅáÂà∞Êú™Áü•ÁöÑÈóÆÈ¢òÊàñËÄÖÈúÄË¶ÅÂØπÊú™Êù•ËøõË°å&ldquo;Êé®Êµã&rdquo;ÁöÑÊó∂ÂÄôÔºå‰∫∫Á±ª‰ΩøÁî®Ëøô‰∫õ&ldquo;ËßÑÂæã&rdquo;ÔºåÂØπÊú™Áü•ÈóÆÈ¢ò‰∏éÊú™Êù•ËøõË°å&ldquo;Êé®Êµã&rdquo;Ôºå‰ªéËÄåÊåáÂØºËá™Â∑±ÁöÑÁîüÊ¥ªÂíåÂ∑•‰Ωú„ÄÇ Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑ&ldquo;ËÆ≠ÁªÉ&rdquo;‰∏é&ldquo;È¢ÑÊµã&rdquo;ËøáÁ®ãÂèØ‰ª•ÂØπÂ∫îÂà∞‰∫∫Á±ªÁöÑ&ldquo;ÂΩíÁ∫≥&rdquo;Âíå&ldquo;Êé®Êµã&rdquo;ËøáÁ®ã„ÄÇÈÄöËøáËøôÊ†∑ÁöÑÂØπÂ∫îÔºåÊàë‰ª¨ÂèØ‰ª•ÂèëÁé∞ÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÊÄùÊÉ≥Âπ∂‰∏çÂ§çÊùÇÔºå‰ªÖ‰ªÖÊòØÂØπ‰∫∫Á±ªÂú®ÁîüÊ¥ª‰∏≠Â≠¶‰π†ÊàêÈïøÁöÑ‰∏Ä‰∏™Ê®°Êãü„ÄÇÁî±‰∫éÊú∫Âô®Â≠¶‰π†‰∏çÊòØÂü∫‰∫éÁºñÁ®ãÂΩ¢ÊàêÁöÑÁªìÊûúÔºåÂõ†Ê≠§ÂÆÉÁöÑÂ§ÑÁêÜËøáÁ®ã‰∏çÊòØÂõ†ÊûúÁöÑÈÄªËæëÔºåËÄåÊòØÈÄöËøáÂΩíÁ∫≥ÊÄùÊÉ≥ÂæóÂá∫ÁöÑÁõ∏ÂÖ≥ÊÄßÁªìËÆ∫„ÄÇ&nbsp; Ëøô‰πüÂèØ‰ª•ËÅîÊÉ≥Âà∞‰∫∫Á±ª‰∏∫‰ªÄ‰πàË¶ÅÂ≠¶‰π†ÂéÜÂè≤ÔºåÂéÜÂè≤ÂÆûÈôÖ‰∏äÊòØ‰∫∫Á±ªËøáÂæÄÁªèÈ™åÁöÑÊÄªÁªì„ÄÇÊúâÂè•ËØùËØ¥ÂæóÂæàÂ•ΩÔºå&ldquo;ÂéÜÂè≤ÂæÄÂæÄ‰∏ç‰∏ÄÊ†∑Ôºå‰ΩÜÂéÜÂè≤ÊÄªÊòØÊÉä‰∫∫ÁöÑÁõ∏‰ºº&rdquo;„ÄÇÈÄöËøáÂ≠¶‰π†ÂéÜÂè≤ÔºåÊàë‰ª¨‰ªéÂéÜÂè≤‰∏≠ÂΩíÁ∫≥Âá∫‰∫∫Áîü‰∏éÂõΩÂÆ∂ÁöÑËßÑÂæãÔºå‰ªéËÄåÊåáÂØºÊàë‰ª¨ÁöÑ‰∏ã‰∏ÄÊ≠•Â∑•‰ΩúÔºåËøôÊòØÂÖ∑ÊúâËé´Â§ß‰ª∑ÂÄºÁöÑ„ÄÇÂΩì‰ª£‰∏Ä‰∫õ‰∫∫ÂøΩËßÜ‰∫ÜÂéÜÂè≤ÁöÑÊú¨Êù•‰ª∑ÂÄºÔºåËÄåÊòØÊääÂÖ∂‰Ωú‰∏∫‰∏ÄÁßçÂÆ£Êâ¨ÂäüÁª©ÁöÑÊâãÊÆµÔºåËøôÂÖ∂ÂÆûÊòØÂØπÂéÜÂè≤ÁúüÂÆû‰ª∑ÂÄºÁöÑ‰∏ÄÁßçËØØÁî®„ÄÇ 3.Êú∫Âô®Â≠¶‰π†ÁöÑËåÉÂõ¥ ‰∏äÊñáËôΩÁÑ∂ËØ¥Êòé‰∫ÜÊú∫Âô®Â≠¶‰π†ÊòØ‰ªÄ‰πàÔºå‰ΩÜÊòØÂπ∂Ê≤°ÊúâÁªôÂá∫Êú∫Âô®Â≠¶‰π†ÁöÑËåÉÂõ¥„ÄÇ ÂÖ∂ÂÆûÔºåÊú∫Âô®Â≠¶‰π†Ë∑üÊ®°ÂºèËØÜÂà´ÔºåÁªüËÆ°Â≠¶‰π†ÔºåÊï∞ÊçÆÊåñÊéòÔºåËÆ°ÁÆóÊú∫ËßÜËßâÔºåËØ≠Èü≥ËØÜÂà´ÔºåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ≠âÈ¢ÜÂüüÊúâÁùÄÂæàÊ∑±ÁöÑËÅîÁ≥ª„ÄÇ ‰ªéËåÉÂõ¥‰∏äÊù•ËØ¥ÔºåÊú∫Âô®Â≠¶‰π†Ë∑üÊ®°ÂºèËØÜÂà´ÔºåÁªüËÆ°Â≠¶‰π†ÔºåÊï∞ÊçÆÊåñÊéòÊòØÁ±ª‰ººÁöÑÔºåÂêåÊó∂ÔºåÊú∫Âô®Â≠¶‰π†‰∏éÂÖ∂‰ªñÈ¢ÜÂüüÁöÑÂ§ÑÁêÜÊäÄÊúØÁöÑÁªìÂêàÔºåÂΩ¢Êàê‰∫ÜËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÅËØ≠Èü≥ËØÜÂà´„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ≠â‰∫§ÂèâÂ≠¶Áßë„ÄÇÂõ†Ê≠§Ôºå‰∏ÄËà¨ËØ¥Êï∞ÊçÆÊåñÊéòÊó∂ÔºåÂèØ‰ª•Á≠âÂêå‰∫éËØ¥Êú∫Âô®Â≠¶‰π†„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨Âπ≥Â∏∏ÊâÄËØ¥ÁöÑÊú∫Âô®Â≠¶‰π†Â∫îÁî®ÔºåÂ∫îËØ•ÊòØÈÄöÁî®ÁöÑÔºå‰∏ç‰ªÖ‰ªÖÂ±ÄÈôêÂú®ÁªìÊûÑÂåñÊï∞ÊçÆÔºåËøòÊúâÂõæÂÉèÔºåÈü≥È¢ëÁ≠âÂ∫îÁî®„ÄÇ Âú®ËøôËäÇÂØπÊú∫Âô®Â≠¶‰π†Ëøô‰∫õÁõ∏ÂÖ≥È¢ÜÂüüÁöÑ‰ªãÁªçÊúâÂä©‰∫éÊàë‰ª¨ÁêÜÊ∏ÖÊú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®Âú∫ÊôØ‰∏éÁ†îÁ©∂ËåÉÂõ¥ÔºåÊõ¥Â•ΩÁöÑÁêÜËß£ÂêéÈù¢ÁöÑÁÆóÊ≥ï‰∏éÂ∫îÁî®Â±ÇÊ¨°„ÄÇ ‰∏ãÂõæÊòØÊú∫Âô®Â≠¶‰π†ÊâÄÁâµÊâØÁöÑ‰∏Ä‰∫õÁõ∏ÂÖ≥ËåÉÂõ¥ÁöÑÂ≠¶Áßë‰∏éÁ†îÁ©∂È¢ÜÂüü„ÄÇÂõæ6 Êú∫Âô®Â≠¶‰π†‰∏éÁõ∏ÂÖ≥Â≠¶Áßë Ê®°ÂºèËØÜÂà´ Ê®°ÂºèËØÜÂà´=Êú∫Âô®Â≠¶‰π†„ÄÇ‰∏§ËÄÖÁöÑ‰∏ªË¶ÅÂå∫Âà´Âú®‰∫éÂâçËÄÖÊòØ‰ªéÂ∑•‰∏öÁïåÂèëÂ±ïËµ∑Êù•ÁöÑÊ¶ÇÂøµÔºåÂêéËÄÖÂàô‰∏ªË¶ÅÊ∫êËá™ËÆ°ÁÆóÊú∫Â≠¶Áßë„ÄÇÂú®ËëóÂêçÁöÑ„ÄäPattern Recognition And Machine Learning„ÄãËøôÊú¨‰π¶‰∏≠ÔºåChristopher M. BishopÂú®ÂºÄÂ§¥ÊòØËøôÊ†∑ËØ¥ÁöÑ&ldquo;Ê®°ÂºèËØÜÂà´Ê∫êËá™Â∑•‰∏öÁïåÔºåËÄåÊú∫Âô®Â≠¶‰π†Êù•Ëá™‰∫éËÆ°ÁÆóÊú∫Â≠¶Áßë„ÄÇ‰∏çËøáÔºåÂÆÉ‰ª¨‰∏≠ÁöÑÊ¥ªÂä®ÂèØ‰ª•Ë¢´ËßÜ‰∏∫Âêå‰∏Ä‰∏™È¢ÜÂüüÁöÑ‰∏§‰∏™ÊñπÈù¢ÔºåÂêåÊó∂Âú®ËøáÂéªÁöÑ10Âπ¥Èó¥ÔºåÂÆÉ‰ª¨ÈÉΩÊúâ‰∫ÜÈïøË∂≥ÁöÑÂèëÂ±ï&rdquo;„ÄÇ Êï∞ÊçÆÊåñÊéò Êï∞ÊçÆÊåñÊéò=Êú∫Âô®Â≠¶‰π†+Êï∞ÊçÆÂ∫ì„ÄÇËøôÂá†Âπ¥Êï∞ÊçÆÊåñÊéòÁöÑÊ¶ÇÂøµÂÆûÂú®ÊòØÂ§™ËÄ≥ÁÜüËÉΩËØ¶„ÄÇÂá†‰πéÁ≠âÂêå‰∫éÁÇí‰Ωú„ÄÇ‰ΩÜÂá°ËØ¥Êï∞ÊçÆÊåñÊéòÈÉΩ‰ºöÂêπÂòòÊï∞ÊçÆÊåñÊéòÂ¶Ç‰ΩïÂ¶Ç‰ΩïÔºå‰æãÂ¶Ç‰ªéÊï∞ÊçÆ‰∏≠ÊåñÂá∫ÈáëÂ≠êÔºå‰ª•ÂèäÂ∞ÜÂ∫üÂºÉÁöÑÊï∞ÊçÆËΩ¨Âåñ‰∏∫‰ª∑ÂÄºÁ≠âÁ≠â„ÄÇ‰ΩÜÊòØÔºåÊàëÂ∞ΩÁÆ°ÂèØËÉΩ‰ºöÊåñÂá∫ÈáëÂ≠êÔºå‰ΩÜÊàë‰πüÂèØËÉΩÊåñÁöÑÊòØ&ldquo;Áü≥Â§¥&rdquo;Âïä„ÄÇËøô‰∏™ËØ¥Ê≥ïÁöÑÊÑèÊÄùÊòØÔºåÊï∞ÊçÆÊåñÊéò‰ªÖ‰ªÖÊòØ‰∏ÄÁßçÊÄùËÄÉÊñπÂºèÔºåÂëäËØâÊàë‰ª¨Â∫îËØ•Â∞ùËØï‰ªéÊï∞ÊçÆ‰∏≠ÊåñÊéòÂá∫Áü•ËØÜÔºå‰ΩÜ‰∏çÊòØÊØè‰∏™Êï∞ÊçÆÈÉΩËÉΩÊåñÊéòÂá∫ÈáëÂ≠êÁöÑÔºåÊâÄ‰ª•‰∏çË¶ÅÁ•ûËØùÂÆÉ„ÄÇ‰∏Ä‰∏™Á≥ªÁªüÁªùÂØπ‰∏ç‰ºöÂõ†‰∏∫‰∏ä‰∫Ü‰∏Ä‰∏™Êï∞ÊçÆÊåñÊéòÊ®°ÂùóÂ∞±ÂèòÂæóÊó†ÊâÄ‰∏çËÉΩ(ËøôÊòØIBMÊúÄÂñúÊ¨¢ÂêπÂòòÁöÑ)ÔºåÊÅ∞ÊÅ∞Áõ∏ÂèçÔºå‰∏Ä‰∏™Êã•ÊúâÊï∞ÊçÆÊåñÊéòÊÄùÁª¥ÁöÑ‰∫∫ÂëòÊâçÊòØÂÖ≥ÈîÆÔºåËÄå‰∏î‰ªñËøòÂøÖÈ°ªÂØπÊï∞ÊçÆÊúâÊ∑±ÂàªÁöÑËÆ§ËØÜÔºåËøôÊ†∑ÊâçÂèØËÉΩ‰ªéÊï∞ÊçÆ‰∏≠ÂØºÂá∫Ê®°ÂºèÊåáÂºï‰∏öÂä°ÁöÑÊîπÂñÑ„ÄÇÂ§ßÈÉ®ÂàÜÊï∞ÊçÆÊåñÊéò‰∏≠ÁöÑÁÆóÊ≥ïÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÁÆóÊ≥ïÂú®Êï∞ÊçÆÂ∫ì‰∏≠ÁöÑ‰ºòÂåñ„ÄÇ ÁªüËÆ°Â≠¶‰π† ÁªüËÆ°Â≠¶‰π†Ëøë‰ººÁ≠â‰∫éÊú∫Âô®Â≠¶‰π†„ÄÇÁªüËÆ°Â≠¶‰π†ÊòØ‰∏™‰∏éÊú∫Âô®Â≠¶‰π†È´òÂ∫¶ÈáçÂè†ÁöÑÂ≠¶Áßë„ÄÇÂõ†‰∏∫Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÂ§ßÂ§öÊï∞ÊñπÊ≥ïÊù•Ëá™ÁªüËÆ°Â≠¶ÔºåÁîöËá≥ÂèØ‰ª•ËÆ§‰∏∫ÔºåÁªüËÆ°Â≠¶ÁöÑÂèëÂ±ï‰øÉËøõÊú∫Âô®Â≠¶‰π†ÁöÑÁπÅËç£ÊòåÁõõ„ÄÇ‰æãÂ¶ÇËëóÂêçÁöÑÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÔºåÂ∞±ÊòØÊ∫êËá™ÁªüËÆ°Â≠¶Áßë„ÄÇ‰ΩÜÊòØÂú®ÊüêÁßçÁ®ãÂ∫¶‰∏ä‰∏§ËÄÖÊòØÊúâÂàÜÂà´ÁöÑÔºåËøô‰∏™ÂàÜÂà´Âú®‰∫éÔºöÁªüËÆ°Â≠¶‰π†ËÄÖÈáçÁÇπÂÖ≥Ê≥®ÁöÑÊòØÁªüËÆ°Ê®°ÂûãÁöÑÂèëÂ±ï‰∏é‰ºòÂåñÔºåÂÅèÊï∞Â≠¶ÔºåËÄåÊú∫Âô®Â≠¶‰π†ËÄÖÊõ¥ÂÖ≥Ê≥®ÁöÑÊòØËÉΩÂ§üËß£ÂÜ≥ÈóÆÈ¢òÔºåÂÅèÂÆûË∑µÔºåÂõ†Ê≠§Êú∫Âô®Â≠¶‰π†Á†îÁ©∂ËÄÖ‰ºöÈáçÁÇπÁ†îÁ©∂Â≠¶‰π†ÁÆóÊ≥ïÂú®ËÆ°ÁÆóÊú∫‰∏äÊâßË°åÁöÑÊïàÁéá‰∏éÂáÜÁ°ÆÊÄßÁöÑÊèêÂçá„ÄÇ ËÆ°ÁÆóÊú∫ËßÜËßâ ËÆ°ÁÆóÊú∫ËßÜËßâ=ÂõæÂÉèÂ§ÑÁêÜ+Êú∫Âô®Â≠¶‰π†„ÄÇÂõæÂÉèÂ§ÑÁêÜÊäÄÊúØÁî®‰∫éÂ∞ÜÂõæÂÉèÂ§ÑÁêÜ‰∏∫ÈÄÇÂêàËøõÂÖ•Êú∫Âô®Â≠¶‰π†Ê®°Âûã‰∏≠ÁöÑËæìÂÖ•ÔºåÊú∫Âô®Â≠¶‰π†ÂàôË¥üË¥£‰ªéÂõæÂÉè‰∏≠ËØÜÂà´Âá∫Áõ∏ÂÖ≥ÁöÑÊ®°Âºè„ÄÇËÆ°ÁÆóÊú∫ËßÜËßâÁõ∏ÂÖ≥ÁöÑÂ∫îÁî®ÈùûÂ∏∏ÁöÑÂ§öÔºå‰æãÂ¶ÇÁôæÂ∫¶ËØÜÂõæ„ÄÅÊâãÂÜôÂ≠óÁ¨¶ËØÜÂà´„ÄÅËΩ¶ÁâåËØÜÂà´Á≠âÁ≠âÂ∫îÁî®„ÄÇËøô‰∏™È¢ÜÂüüÊòØÂ∫îÁî®ÂâçÊôØÈùûÂ∏∏ÁÅ´ÁÉ≠ÁöÑÔºåÂêåÊó∂‰πüÊòØÁ†îÁ©∂ÁöÑÁÉ≠Èó®ÊñπÂêë„ÄÇÈöèÁùÄÊú∫Âô®Â≠¶‰π†ÁöÑÊñ∞È¢ÜÂüüÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂèëÂ±ïÔºåÂ§ßÂ§ß‰øÉËøõ‰∫ÜËÆ°ÁÆóÊú∫ÂõæÂÉèËØÜÂà´ÁöÑÊïàÊûúÔºåÂõ†Ê≠§Êú™Êù•ËÆ°ÁÆóÊú∫ËßÜËßâÁïåÁöÑÂèëÂ±ïÂâçÊôØ‰∏çÂèØ‰º∞Èáè„ÄÇ ËØ≠Èü≥ËØÜÂà´ ËØ≠Èü≥ËØÜÂà´=ËØ≠Èü≥Â§ÑÁêÜ+Êú∫Âô®Â≠¶‰π†„ÄÇËØ≠Èü≥ËØÜÂà´Â∞±ÊòØÈü≥È¢ëÂ§ÑÁêÜÊäÄÊúØ‰∏éÊú∫Âô®Â≠¶‰π†ÁöÑÁªìÂêà„ÄÇËØ≠Èü≥ËØÜÂà´ÊäÄÊúØ‰∏ÄËà¨‰∏ç‰ºöÂçïÁã¨‰ΩøÁî®Ôºå‰∏ÄËà¨‰ºöÁªìÂêàËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁöÑÁõ∏ÂÖ≥ÊäÄÊúØ„ÄÇÁõÆÂâçÁöÑÁõ∏ÂÖ≥Â∫îÁî®ÊúâËãπÊûúÁöÑËØ≠Èü≥Âä©ÊâãsiriÁ≠â„ÄÇ Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ=ÊñáÊú¨Â§ÑÁêÜ+Êú∫Âô®Â≠¶‰π†„ÄÇËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊäÄÊúØ‰∏ªË¶ÅÊòØËÆ©Êú∫Âô®ÁêÜËß£‰∫∫Á±ªÁöÑËØ≠Ë®ÄÁöÑ‰∏ÄÈó®È¢ÜÂüü„ÄÇÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊäÄÊúØ‰∏≠ÔºåÂ§ßÈáè‰ΩøÁî®‰∫ÜÁºñËØëÂéüÁêÜÁõ∏ÂÖ≥ÁöÑÊäÄÊúØÔºå‰æãÂ¶ÇËØçÊ≥ïÂàÜÊûêÔºåËØ≠Ê≥ïÂàÜÊûêÁ≠âÁ≠âÔºåÈô§Ê≠§‰πãÂ§ñÔºåÂú®ÁêÜËß£Ëøô‰∏™Â±ÇÈù¢ÔºåÂàô‰ΩøÁî®‰∫ÜËØ≠‰πâÁêÜËß£ÔºåÊú∫Âô®Â≠¶‰π†Á≠âÊäÄÊúØ„ÄÇ‰Ωú‰∏∫ÂîØ‰∏ÄÁî±‰∫∫Á±ªËá™Ë∫´ÂàõÈÄ†ÁöÑÁ¨¶Âè∑ÔºåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏ÄÁõ¥ÊòØÊú∫Âô®Â≠¶‰π†Áïå‰∏çÊñ≠Á†îÁ©∂ÁöÑÊñπÂêë„ÄÇÊåâÁÖßÁôæÂ∫¶Êú∫Âô®Â≠¶‰π†‰∏ìÂÆ∂‰ΩôÂáØÁöÑËØ¥Ê≥ï&ldquo;Âê¨‰∏éÁúãÔºåËØ¥ÁôΩ‰∫ÜÂ∞±ÊòØÈòøÁå´ÂíåÈòøÁãóÈÉΩ‰ºöÁöÑÔºåËÄåÂè™ÊúâËØ≠Ë®ÄÊâçÊòØ‰∫∫Á±ªÁã¨ÊúâÁöÑ&rdquo;„ÄÇÂ¶Ç‰ΩïÂà©Áî®Êú∫Âô®Â≠¶‰π†ÊäÄÊúØËøõË°åËá™ÁÑ∂ËØ≠Ë®ÄÁöÑÁöÑÊ∑±Â∫¶ÁêÜËß£Ôºå‰∏ÄÁõ¥ÊòØÂ∑•‰∏öÂíåÂ≠¶ÊúØÁïåÂÖ≥Ê≥®ÁöÑÁÑ¶ÁÇπ„ÄÇ ÂèØ‰ª•ÁúãÂá∫Êú∫Âô®Â≠¶‰π†Âú®‰ºóÂ§öÈ¢ÜÂüüÁöÑÂ§ñÂª∂ÂíåÂ∫îÁî®„ÄÇÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁöÑÂèëÂ±ï‰øÉ‰Ωø‰∫ÜÂæàÂ§öÊô∫ËÉΩÈ¢ÜÂüüÁöÑËøõÊ≠•ÔºåÊîπÂñÑÁùÄÊàë‰ª¨ÁöÑÁîüÊ¥ª„ÄÇ&nbsp;4.Êú∫Âô®Â≠¶‰π†ÁöÑÊñπÊ≥ï ÈÄöËøá‰∏äËäÇÁöÑ‰ªãÁªçÊàë‰ª¨Áü•Êôì‰∫ÜÊú∫Âô®Â≠¶‰π†ÁöÑÂ§ßËá¥ËåÉÂõ¥ÔºåÈÇ£‰πàÊú∫Âô®Â≠¶‰π†ÈáåÈù¢Á©∂Á´üÊúâÂ§öÂ∞ëÁªèÂÖ∏ÁöÑÁÆóÊ≥ïÂë¢ÔºüÂú®Ëøô‰∏™ÈÉ®ÂàÜÊàë‰ºöÁÆÄË¶Å‰ªãÁªç‰∏Ä‰∏ãÊú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÁªèÂÖ∏‰ª£Ë°®ÊñπÊ≥ï„ÄÇËøôÈÉ®ÂàÜ‰ªãÁªçÁöÑÈáçÁÇπÊòØËøô‰∫õÊñπÊ≥ïÂÜÖÊ∂µÁöÑÊÄùÊÉ≥ÔºåÊï∞Â≠¶‰∏éÂÆûË∑µÁªÜËäÇ‰∏ç‰ºöÂú®ËøôËÆ®ËÆ∫„ÄÇ 1„ÄÅÂõûÂΩíÁÆóÊ≥ï Âú®Â§ßÈÉ®ÂàÜÊú∫Âô®Â≠¶‰π†ËØæÁ®ã‰∏≠ÔºåÂõûÂΩíÁÆóÊ≥ïÈÉΩÊòØ‰ªãÁªçÁöÑÁ¨¨‰∏Ä‰∏™ÁÆóÊ≥ï„ÄÇÂéüÂõ†Êúâ‰∏§‰∏™Ôºö‰∏Ä.ÂõûÂΩíÁÆóÊ≥ïÊØîËæÉÁÆÄÂçïÔºå‰ªãÁªçÂÆÉÂèØ‰ª•ËÆ©‰∫∫Âπ≥ÊªëÂú∞‰ªéÁªüËÆ°Â≠¶ËøÅÁßªÂà∞Êú∫Âô®Â≠¶‰π†‰∏≠„ÄÇ‰∫å.ÂõûÂΩíÁÆóÊ≥ïÊòØÂêéÈù¢Ëã•Âπ≤Âº∫Â§ßÁÆóÊ≥ïÁöÑÂü∫Áü≥ÔºåÂ¶ÇÊûú‰∏çÁêÜËß£ÂõûÂΩíÁÆóÊ≥ïÔºåÊó†Ê≥ïÂ≠¶‰π†ÈÇ£‰∫õÂº∫Â§ßÁöÑÁÆóÊ≥ï„ÄÇÂõûÂΩíÁÆóÊ≥ïÊúâ‰∏§‰∏™ÈáçË¶ÅÁöÑÂ≠êÁ±ªÔºöÂç≥Á∫øÊÄßÂõûÂΩíÂíåÈÄªËæëÂõûÂΩí„ÄÇ Á∫øÊÄßÂõûÂΩíÂ∞±ÊòØÊàë‰ª¨ÂâçÈù¢ËØ¥ËøáÁöÑÊàø‰ª∑Ê±ÇËß£ÈóÆÈ¢ò„ÄÇÂ¶Ç‰ΩïÊãüÂêàÂá∫‰∏ÄÊù°Áõ¥Á∫øÊúÄ‰Ω≥ÂåπÈÖçÊàëÊâÄÊúâÁöÑÊï∞ÊçÆÔºü‰∏ÄËà¨‰ΩøÁî®&ldquo;ÊúÄÂ∞è‰∫å‰πòÊ≥ï&rdquo;Êù•Ê±ÇËß£„ÄÇ&ldquo;ÊúÄÂ∞è‰∫å‰πòÊ≥ï&rdquo;ÁöÑÊÄùÊÉ≥ÊòØËøôÊ†∑ÁöÑÔºåÂÅáËÆæÊàë‰ª¨ÊãüÂêàÂá∫ÁöÑÁõ¥Á∫ø‰ª£Ë°®Êï∞ÊçÆÁöÑÁúüÂÆûÂÄºÔºåËÄåËßÇÊµãÂà∞ÁöÑÊï∞ÊçÆ‰ª£Ë°®Êã•ÊúâËØØÂ∑ÆÁöÑÂÄº„ÄÇ‰∏∫‰∫ÜÂ∞ΩÂèØËÉΩÂáèÂ∞èËØØÂ∑ÆÁöÑÂΩ±ÂìçÔºåÈúÄË¶ÅÊ±ÇËß£‰∏ÄÊù°Áõ¥Á∫ø‰ΩøÊâÄÊúâËØØÂ∑ÆÁöÑÂπ≥ÊñπÂíåÊúÄÂ∞è„ÄÇÊúÄÂ∞è‰∫å‰πòÊ≥ïÂ∞ÜÊúÄ‰ºòÈóÆÈ¢òËΩ¨Âåñ‰∏∫Ê±ÇÂáΩÊï∞ÊûÅÂÄºÈóÆÈ¢ò„ÄÇÂáΩÊï∞ÊûÅÂÄºÂú®Êï∞Â≠¶‰∏äÊàë‰ª¨‰∏ÄËà¨‰ºöÈááÁî®Ê±ÇÂØºÊï∞‰∏∫0ÁöÑÊñπÊ≥ï„ÄÇ‰ΩÜËøôÁßçÂÅöÊ≥ïÂπ∂‰∏çÈÄÇÂêàËÆ°ÁÆóÊú∫ÔºåÂèØËÉΩÊ±ÇËß£‰∏çÂá∫Êù•Ôºå‰πüÂèØËÉΩËÆ°ÁÆóÈáèÂ§™Â§ß„ÄÇ ËÆ°ÁÆóÊú∫ÁßëÂ≠¶Áïå‰∏ìÈó®Êúâ‰∏Ä‰∏™Â≠¶ÁßëÂè´&ldquo;Êï∞ÂÄºËÆ°ÁÆó&rdquo;Ôºå‰∏ìÈó®Áî®Êù•ÊèêÂçáËÆ°ÁÆóÊú∫ËøõË°åÂêÑÁ±ªËÆ°ÁÆóÊó∂ÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÈóÆÈ¢ò„ÄÇ‰æãÂ¶ÇÔºåËëóÂêçÁöÑ&ldquo;Ê¢ØÂ∫¶‰∏ãÈôç&rdquo;‰ª•Âèä&ldquo;ÁâõÈ°øÊ≥ï&rdquo;Â∞±ÊòØÊï∞ÂÄºËÆ°ÁÆó‰∏≠ÁöÑÁªèÂÖ∏ÁÆóÊ≥ïÔºå‰πüÈùûÂ∏∏ÈÄÇÂêàÊù•Â§ÑÁêÜÊ±ÇËß£ÂáΩÊï∞ÊûÅÂÄºÁöÑÈóÆÈ¢ò„ÄÇÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÊòØËß£ÂÜ≥ÂõûÂΩíÊ®°Âûã‰∏≠ÊúÄÁÆÄÂçï‰∏îÊúâÊïàÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇ‰ªé‰∏•Ê†ºÊÑè‰πâ‰∏äÊù•ËØ¥ÔºåÁî±‰∫éÂêéÊñá‰∏≠ÁöÑÁ•ûÁªèÁΩëÁªúÂíåÊé®ËçêÁÆóÊ≥ï‰∏≠ÈÉΩÊúâÁ∫øÊÄßÂõûÂΩíÁöÑÂõ†Â≠êÔºåÂõ†Ê≠§Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÂú®ÂêéÈù¢ÁöÑÁÆóÊ≥ïÂÆûÁé∞‰∏≠‰πüÊúâÂ∫îÁî®„ÄÇ ÈÄªËæëÂõûÂΩíÊòØ‰∏ÄÁßç‰∏éÁ∫øÊÄßÂõûÂΩíÈùûÂ∏∏Á±ª‰ººÁöÑÁÆóÊ≥ïÔºå‰ΩÜÊòØÔºå‰ªéÊú¨Ë¥®‰∏äËÆ≤ÔºåÁ∫øÂûãÂõûÂΩíÂ§ÑÁêÜÁöÑÈóÆÈ¢òÁ±ªÂûã‰∏éÈÄªËæëÂõûÂΩí‰∏ç‰∏ÄËá¥„ÄÇÁ∫øÊÄßÂõûÂΩíÂ§ÑÁêÜÁöÑÊòØÊï∞ÂÄºÈóÆÈ¢òÔºå‰πüÂ∞±ÊòØÊúÄÂêéÈ¢ÑÊµãÂá∫ÁöÑÁªìÊûúÊòØÊï∞Â≠óÔºå‰æãÂ¶ÇÊàø‰ª∑„ÄÇËÄåÈÄªËæëÂõûÂΩíÂ±û‰∫éÂàÜÁ±ªÁÆóÊ≥ïÔºå‰πüÂ∞±ÊòØËØ¥ÔºåÈÄªËæëÂõûÂΩíÈ¢ÑÊµãÁªìÊûúÊòØÁ¶ªÊï£ÁöÑÂàÜÁ±ªÔºå‰æãÂ¶ÇÂà§Êñ≠ËøôÂ∞ÅÈÇÆ‰ª∂ÊòØÂê¶ÊòØÂûÉÂúæÈÇÆ‰ª∂Ôºå‰ª•ÂèäÁî®Êà∑ÊòØÂê¶‰ºöÁÇπÂáªÊ≠§ÂπøÂëäÁ≠âÁ≠â„ÄÇ ÂÆûÁé∞ÊñπÈù¢ÁöÑËØùÔºåÈÄªËæëÂõûÂΩíÂè™ÊòØÂØπÂØπÁ∫øÊÄßÂõûÂΩíÁöÑËÆ°ÁÆóÁªìÊûúÂä†‰∏ä‰∫Ü‰∏Ä‰∏™SigmoidÂáΩÊï∞ÔºåÂ∞ÜÊï∞ÂÄºÁªìÊûúËΩ¨Âåñ‰∏∫‰∫Ü0Âà∞1‰πãÈó¥ÁöÑÊ¶ÇÁéá(SigmoidÂáΩÊï∞ÁöÑÂõæÂÉè‰∏ÄËà¨Êù•ËØ¥Âπ∂‰∏çÁõ¥ËßÇÔºå‰Ω†Âè™ÈúÄË¶ÅÁêÜËß£ÂØπÊï∞ÂÄºË∂äÂ§ßÔºåÂáΩÊï∞Ë∂äÈÄºËøë1ÔºåÊï∞ÂÄºË∂äÂ∞èÔºåÂáΩÊï∞Ë∂äÈÄºËøë0)ÔºåÊé•ÁùÄÊàë‰ª¨Ê†πÊçÆËøô‰∏™Ê¶ÇÁéáÂèØ‰ª•ÂÅöÈ¢ÑÊµãÔºå‰æãÂ¶ÇÊ¶ÇÁéáÂ§ß‰∫é0.5ÔºåÂàôËøôÂ∞ÅÈÇÆ‰ª∂Â∞±ÊòØÂûÉÂúæÈÇÆ‰ª∂ÔºåÊàñËÄÖËÇøÁò§ÊòØÂê¶ÊòØÊÅ∂ÊÄßÁöÑÁ≠âÁ≠â„ÄÇ‰ªéÁõ¥ËßÇ‰∏äÊù•ËØ¥ÔºåÈÄªËæëÂõûÂΩíÊòØÁîªÂá∫‰∫Ü‰∏ÄÊù°ÂàÜÁ±ªÁ∫øÔºåËßÅ‰∏ãÂõæ„ÄÇ Âõæ7 ÈÄªËæëÂõûÂΩíÁöÑÁõ¥ËßÇËß£Èáä ÂÅáËÆæÊàë‰ª¨Êúâ‰∏ÄÁªÑËÇøÁò§ÊÇ£ËÄÖÁöÑÊï∞ÊçÆÔºåËøô‰∫õÊÇ£ËÄÖÁöÑËÇøÁò§‰∏≠Êúâ‰∫õÊòØËâØÊÄßÁöÑ(Âõæ‰∏≠ÁöÑËìùËâ≤ÁÇπ)ÔºåÊúâ‰∫õÊòØÊÅ∂ÊÄßÁöÑ(Âõæ‰∏≠ÁöÑÁ∫¢Ëâ≤ÁÇπ)„ÄÇËøôÈáåËÇøÁò§ÁöÑÁ∫¢ËìùËâ≤ÂèØ‰ª•Ë¢´Áß∞‰ΩúÊï∞ÊçÆÁöÑ&ldquo;Ê†áÁ≠æ&rdquo;„ÄÇÂêåÊó∂ÊØè‰∏™Êï∞ÊçÆÂåÖÊã¨‰∏§‰∏™&ldquo;ÁâπÂæÅ&rdquo;ÔºöÊÇ£ËÄÖÁöÑÂπ¥ÈæÑ‰∏éËÇøÁò§ÁöÑÂ§ßÂ∞è„ÄÇÊàë‰ª¨Â∞ÜËøô‰∏§‰∏™ÁâπÂæÅ‰∏éÊ†áÁ≠æÊò†Â∞ÑÂà∞Ëøô‰∏™‰∫åÁª¥Á©∫Èó¥‰∏äÔºåÂΩ¢Êàê‰∫ÜÊàë‰∏äÂõæÁöÑÊï∞ÊçÆ„ÄÇ ÂΩìÊàëÊúâ‰∏Ä‰∏™ÁªøËâ≤ÁöÑÁÇπÊó∂ÔºåÊàëËØ•Âà§Êñ≠Ëøô‰∏™ËÇøÁò§ÊòØÊÅ∂ÊÄßÁöÑËøòÊòØËâØÊÄßÁöÑÂë¢ÔºüÊ†πÊçÆÁ∫¢ËìùÁÇπÊàë‰ª¨ËÆ≠ÁªÉÂá∫‰∫Ü‰∏Ä‰∏™ÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºå‰πüÂ∞±ÊòØÂõæ‰∏≠ÁöÑÂàÜÁ±ªÁ∫ø„ÄÇËøôÊó∂ÔºåÊ†πÊçÆÁªøÁÇπÂá∫Áé∞Âú®ÂàÜÁ±ªÁ∫øÁöÑÂ∑¶‰æßÔºåÂõ†Ê≠§Êàë‰ª¨Âà§Êñ≠ÂÆÉÁöÑÊ†áÁ≠æÂ∫îËØ•ÊòØÁ∫¢Ëâ≤Ôºå‰πüÂ∞±ÊòØËØ¥Â±û‰∫éÊÅ∂ÊÄßËÇøÁò§„ÄÇ ÈÄªËæëÂõûÂΩíÁÆóÊ≥ïÂàíÂá∫ÁöÑÂàÜÁ±ªÁ∫øÂü∫Êú¨ÈÉΩÊòØÁ∫øÊÄßÁöÑ(‰πüÊúâÂàíÂá∫ÈùûÁ∫øÊÄßÂàÜÁ±ªÁ∫øÁöÑÈÄªËæëÂõûÂΩíÔºå‰∏çËøáÈÇ£Ê†∑ÁöÑÊ®°ÂûãÂú®Â§ÑÁêÜÊï∞ÊçÆÈáèËæÉÂ§ßÁöÑÊó∂ÂÄôÊïàÁéá‰ºöÂæà‰Ωé)ÔºåËøôÊÑèÂë≥ÁùÄÂΩì‰∏§Á±ª‰πãÈó¥ÁöÑÁïåÁ∫ø‰∏çÊòØÁ∫øÊÄßÊó∂ÔºåÈÄªËæëÂõûÂΩíÁöÑË°®ËææËÉΩÂäõÂ∞±‰∏çË∂≥„ÄÇ‰∏ãÈù¢ÁöÑ‰∏§‰∏™ÁÆóÊ≥ïÊòØÊú∫Âô®Â≠¶‰π†ÁïåÊúÄÂº∫Â§ß‰∏îÈáçË¶ÅÁöÑÁÆóÊ≥ïÔºåÈÉΩÂèØ‰ª•ÊãüÂêàÂá∫ÈùûÁ∫øÊÄßÁöÑÂàÜÁ±ªÁ∫ø„ÄÇ 2„ÄÅÁ•ûÁªèÁΩëÁªú Á•ûÁªèÁΩëÁªú(‰πüÁß∞‰πã‰∏∫‰∫∫Â∑•Á•ûÁªèÁΩëÁªúÔºåANN)ÁÆóÊ≥ïÊòØ80Âπ¥‰ª£Êú∫Âô®Â≠¶‰π†ÁïåÈùûÂ∏∏ÊµÅË°åÁöÑÁÆóÊ≥ïÔºå‰∏çËøáÂú®90Âπ¥‰ª£‰∏≠ÈÄîË°∞ËêΩ„ÄÇÁé∞Âú®ÔºåÊê∫ÁùÄ&ldquo;Ê∑±Â∫¶Â≠¶‰π†&rdquo;‰πãÂäøÔºåÁ•ûÁªèÁΩëÁªúÈáçË£ÖÂΩíÊù•ÔºåÈáçÊñ∞Êàê‰∏∫ÊúÄÂº∫Â§ßÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ï‰πã‰∏Ä„ÄÇ Á•ûÁªèÁΩëÁªúÁöÑËØûÁîüËµ∑Ê∫ê‰∫éÂØπÂ§ßËÑëÂ∑•‰ΩúÊú∫ÁêÜÁöÑÁ†îÁ©∂„ÄÇÊó©ÊúüÁîüÁâ©ÁïåÂ≠¶ËÄÖ‰ª¨‰ΩøÁî®Á•ûÁªèÁΩëÁªúÊù•Ê®°ÊãüÂ§ßËÑë„ÄÇÊú∫Âô®Â≠¶‰π†ÁöÑÂ≠¶ËÄÖ‰ª¨‰ΩøÁî®Á•ûÁªèÁΩëÁªúËøõË°åÊú∫Âô®Â≠¶‰π†ÁöÑÂÆûÈ™åÔºåÂèëÁé∞Âú®ËßÜËßâ‰∏éËØ≠Èü≥ÁöÑËØÜÂà´‰∏äÊïàÊûúÈÉΩÁõ∏ÂΩìÂ•Ω„ÄÇÂú®BPÁÆóÊ≥ï(Âä†ÈÄüÁ•ûÁªèÁΩëÁªúËÆ≠ÁªÉËøáÁ®ãÁöÑÊï∞ÂÄºÁÆóÊ≥ï)ËØûÁîü‰ª•ÂêéÔºåÁ•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïËøõÂÖ•‰∫Ü‰∏Ä‰∏™ÁÉ≠ÊΩÆ„ÄÇBPÁÆóÊ≥ïÁöÑÂèëÊòé‰∫∫‰πã‰∏ÄÊòØÂâçÈù¢‰ªãÁªçÁöÑÊú∫Âô®Â≠¶‰π†Â§ßÁâõGeoffrey Hinton(Âõæ1‰∏≠ÁöÑ‰∏≠Èó¥ËÄÖ)„ÄÇ ÂÖ∑‰ΩìËØ¥Êù•ÔºåÁ•ûÁªèÁΩëÁªúÁöÑÂ≠¶‰π†Êú∫ÁêÜÊòØ‰ªÄ‰πàÔºüÁÆÄÂçïÊù•ËØ¥ÔºåÂ∞±ÊòØÂàÜËß£‰∏éÊï¥Âêà„ÄÇÂú®ËëóÂêçÁöÑHubel-WieselËØïÈ™å‰∏≠ÔºåÂ≠¶ËÄÖ‰ª¨Á†îÁ©∂Áå´ÁöÑËßÜËßâÂàÜÊûêÊú∫ÁêÜÊòØËøôÊ†∑ÁöÑ„ÄÇ &nbsp;Âõæ8 Hubel-WieselËØïÈ™å‰∏éÂ§ßËÑëËßÜËßâÊú∫ÁêÜ ÊØîÊñπËØ¥Ôºå‰∏Ä‰∏™Ê≠£ÊñπÂΩ¢ÔºåÂàÜËß£‰∏∫Âõõ‰∏™ÊäòÁ∫øËøõÂÖ•ËßÜËßâÂ§ÑÁêÜÁöÑ‰∏ã‰∏ÄÂ±Ç‰∏≠„ÄÇÂõõ‰∏™Á•ûÁªèÂÖÉÂàÜÂà´Â§ÑÁêÜ‰∏Ä‰∏™ÊäòÁ∫ø„ÄÇÊØè‰∏™ÊäòÁ∫øÂÜçÁªßÁª≠Ë¢´ÂàÜËß£‰∏∫‰∏§Êù°Áõ¥Á∫øÔºåÊØèÊù°Áõ¥Á∫øÂÜçË¢´ÂàÜËß£‰∏∫ÈªëÁôΩ‰∏§‰∏™Èù¢„ÄÇ‰∫éÊòØÔºå‰∏Ä‰∏™Â§çÊùÇÁöÑÂõæÂÉèÂèòÊàê‰∫ÜÂ§ßÈáèÁöÑÁªÜËäÇËøõÂÖ•Á•ûÁªèÂÖÉÔºåÁ•ûÁªèÂÖÉÂ§ÑÁêÜ‰ª•ÂêéÂÜçËøõË°åÊï¥ÂêàÔºåÊúÄÂêéÂæóÂá∫‰∫ÜÁúãÂà∞ÁöÑÊòØÊ≠£ÊñπÂΩ¢ÁöÑÁªìËÆ∫„ÄÇËøôÂ∞±ÊòØÂ§ßËÑëËßÜËßâËØÜÂà´ÁöÑÊú∫ÁêÜÔºå‰πüÊòØÁ•ûÁªèÁΩëÁªúÂ∑•‰ΩúÁöÑÊú∫ÁêÜ„ÄÇ ËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ•ûÁªèÁΩëÁªúÁöÑÈÄªËæëÊû∂ÊûÑ„ÄÇÂú®Ëøô‰∏™ÁΩëÁªú‰∏≠ÔºåÂàÜÊàêËæìÂÖ•Â±ÇÔºåÈöêËóèÂ±ÇÔºåÂíåËæìÂá∫Â±Ç„ÄÇËæìÂÖ•Â±ÇË¥üË¥£Êé•Êî∂‰ø°Âè∑ÔºåÈöêËóèÂ±ÇË¥üË¥£ÂØπÊï∞ÊçÆÁöÑÂàÜËß£‰∏éÂ§ÑÁêÜÔºåÊúÄÂêéÁöÑÁªìÊûúË¢´Êï¥ÂêàÂà∞ËæìÂá∫Â±Ç„ÄÇÊØèÂ±Ç‰∏≠ÁöÑ‰∏Ä‰∏™ÂúÜ‰ª£Ë°®‰∏Ä‰∏™Â§ÑÁêÜÂçïÂÖÉÔºåÂèØ‰ª•ËÆ§‰∏∫ÊòØÊ®°Êãü‰∫Ü‰∏Ä‰∏™Á•ûÁªèÂÖÉÔºåËã•Âπ≤‰∏™Â§ÑÁêÜÂçïÂÖÉÁªÑÊàê‰∫Ü‰∏Ä‰∏™Â±ÇÔºåËã•Âπ≤‰∏™Â±ÇÂÜçÁªÑÊàê‰∫Ü‰∏Ä‰∏™ÁΩëÁªúÔºå‰πüÂ∞±ÊòØ‚ÄùÁ•ûÁªèÁΩëÁªú‚Äù„ÄÇÂõæ9 Á•ûÁªèÁΩëÁªúÁöÑÈÄªËæëÊû∂ÊûÑ Âú®Á•ûÁªèÁΩëÁªú‰∏≠ÔºåÊØè‰∏™Â§ÑÁêÜÂçïÂÖÉ‰∫ãÂÆû‰∏äÂ∞±ÊòØ‰∏Ä‰∏™ÈÄªËæëÂõûÂΩíÊ®°ÂûãÔºåÈÄªËæëÂõûÂΩíÊ®°ÂûãÊé•Êî∂‰∏äÂ±ÇÁöÑËæìÂÖ•ÔºåÊääÊ®°ÂûãÁöÑÈ¢ÑÊµãÁªìÊûú‰Ωú‰∏∫ËæìÂá∫‰º†ËæìÂà∞‰∏ã‰∏Ä‰∏™Â±ÇÊ¨°„ÄÇÈÄöËøáËøôÊ†∑ÁöÑËøáÁ®ãÔºåÁ•ûÁªèÁΩëÁªúÂèØ‰ª•ÂÆåÊàêÈùûÂ∏∏Â§çÊùÇÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ª„ÄÇ ‰∏ãÂõæ‰ºöÊºîÁ§∫Á•ûÁªèÁΩëÁªúÂú®ÂõæÂÉèËØÜÂà´È¢ÜÂüüÁöÑ‰∏Ä‰∏™ËëóÂêçÂ∫îÁî®ÔºåËøô‰∏™Á®ãÂ∫èÂè´ÂÅöLeNetÔºåÊòØ‰∏Ä‰∏™Âü∫‰∫éÂ§ö‰∏™ÈöêÂ±ÇÊûÑÂª∫ÁöÑÁ•ûÁªèÁΩëÁªú„ÄÇÈÄöËøáLeNetÂèØ‰ª•ËØÜÂà´Â§öÁßçÊâãÂÜôÊï∞Â≠óÔºåÂπ∂‰∏îËææÂà∞ÂæàÈ´òÁöÑËØÜÂà´Á≤æÂ∫¶‰∏éÊã•ÊúâËæÉÂ•ΩÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂõæ10 LeNetÁöÑÊïàÊûúÂ±ïÁ§∫ Âè≥‰∏ãÊñπÁöÑÊñπÂΩ¢‰∏≠ÊòæÁ§∫ÁöÑÊòØËæìÂÖ•ËÆ°ÁÆóÊú∫ÁöÑÂõæÂÉèÔºåÊñπÂΩ¢‰∏äÊñπÁöÑÁ∫¢Ëâ≤Â≠óÊ†∑&ldquo;answer&rdquo;ÂêéÈù¢ÊòæÁ§∫ÁöÑÊòØËÆ°ÁÆóÊú∫ÁöÑËæìÂá∫„ÄÇÂ∑¶ËæπÁöÑ‰∏âÊù°Á´ñÁõ¥ÁöÑÂõæÂÉèÂàóÊòæÁ§∫ÁöÑÊòØÁ•ûÁªèÁΩëÁªú‰∏≠‰∏â‰∏™ÈöêËóèÂ±ÇÁöÑËæìÂá∫ÔºåÂèØ‰ª•ÁúãÂá∫ÔºåÈöèÁùÄÂ±ÇÊ¨°ÁöÑ‰∏çÊñ≠Ê∑±ÂÖ•ÔºåË∂äÊ∑±ÁöÑÂ±ÇÊ¨°Â§ÑÁêÜÁöÑÁªÜËäÇË∂ä‰ΩéÔºå‰æãÂ¶ÇÂ±Ç3Âü∫Êú¨Â§ÑÁêÜÁöÑÈÉΩÂ∑≤ÁªèÊòØÁ∫øÁöÑÁªÜËäÇ‰∫Ü„ÄÇLeNetÁöÑÂèëÊòé‰∫∫Â∞±ÊòØÂâçÊñá‰ªãÁªçËøáÁöÑÊú∫Âô®Â≠¶‰π†ÁöÑÂ§ßÁâõYann LeCun(Âõæ1Âè≥ËÄÖ)„ÄÇ ËøõÂÖ•90Âπ¥‰ª£ÔºåÁ•ûÁªèÁΩëÁªúÁöÑÂèëÂ±ïËøõÂÖ•‰∫Ü‰∏Ä‰∏™Áì∂È¢àÊúü„ÄÇÂÖ∂‰∏ªË¶ÅÂéüÂõ†ÊòØÂ∞ΩÁÆ°ÊúâBPÁÆóÊ≥ïÁöÑÂä†ÈÄüÔºåÁ•ûÁªèÁΩëÁªúÁöÑËÆ≠ÁªÉËøáÁ®ã‰ªçÁÑ∂ÂæàÂõ∞Èöæ„ÄÇÂõ†Ê≠§90Âπ¥‰ª£ÂêéÊúüÊîØÊåÅÂêëÈáèÊú∫(SVM)ÁÆóÊ≥ïÂèñ‰ª£‰∫ÜÁ•ûÁªèÁΩëÁªúÁöÑÂú∞‰Ωç„ÄÇ 3„ÄÅSVMÔºàÊîØÊåÅÂêëÈáèÊú∫Ôºâ ÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÊòØËØûÁîü‰∫éÁªüËÆ°Â≠¶‰π†ÁïåÔºåÂêåÊó∂Âú®Êú∫Âô®Â≠¶‰π†ÁïåÂ§ßÊîæÂÖâÂΩ©ÁöÑÁªèÂÖ∏ÁÆóÊ≥ï„ÄÇ ÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ï‰ªéÊüêÁßçÊÑè‰πâ‰∏äÊù•ËØ¥ÊòØÈÄªËæëÂõûÂΩíÁÆóÊ≥ïÁöÑÂº∫ÂåñÔºöÈÄöËøáÁªô‰∫àÈÄªËæëÂõûÂΩíÁÆóÊ≥ïÊõ¥‰∏•Ê†ºÁöÑ‰ºòÂåñÊù°‰ª∂ÔºåÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÂèØ‰ª•Ëé∑ÂæóÊØîÈÄªËæëÂõûÂΩíÊõ¥Â•ΩÁöÑÂàÜÁ±ªÁïåÁ∫ø„ÄÇ‰ΩÜÊòØÂ¶ÇÊûúÊ≤°ÊúâÊüêÁ±ªÂáΩÊï∞ÊäÄÊúØÔºåÂàôÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÊúÄÂ§öÁÆóÊòØ‰∏ÄÁßçÊõ¥Â•ΩÁöÑÁ∫øÊÄßÂàÜÁ±ªÊäÄÊúØ„ÄÇ ‰ΩÜÊòØÔºåÈÄöËøáË∑üÈ´òÊñØ&ldquo;Ê†∏&rdquo;ÁöÑÁªìÂêàÔºåÊîØÊåÅÂêëÈáèÊú∫ÂèØ‰ª•Ë°®ËææÂá∫ÈùûÂ∏∏Â§çÊùÇÁöÑÂàÜÁ±ªÁïåÁ∫øÔºå‰ªéËÄåËææÊàêÂæàÂ•ΩÁöÑÁöÑÂàÜÁ±ªÊïàÊûú„ÄÇ&ldquo;Ê†∏&rdquo;‰∫ãÂÆû‰∏äÂ∞±ÊòØ‰∏ÄÁßçÁâπÊÆäÁöÑÂáΩÊï∞ÔºåÊúÄÂÖ∏ÂûãÁöÑÁâπÂæÅÂ∞±ÊòØÂèØ‰ª•Â∞Ü‰ΩéÁª¥ÁöÑÁ©∫Èó¥Êò†Â∞ÑÂà∞È´òÁª¥ÁöÑÁ©∫Èó¥„ÄÇ ‰æãÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;Âõæ11 ÊîØÊåÅÂêëÈáèÊú∫Âõæ‰æã Êàë‰ª¨Â¶Ç‰ΩïÂú®‰∫åÁª¥Âπ≥Èù¢ÂàíÂàÜÂá∫‰∏Ä‰∏™ÂúÜÂΩ¢ÁöÑÂàÜÁ±ªÁïåÁ∫øÔºüÂú®‰∫åÁª¥Âπ≥Èù¢ÂèØËÉΩ‰ºöÂæàÂõ∞ÈöæÔºå‰ΩÜÊòØÈÄöËøá&ldquo;Ê†∏&rdquo;ÂèØ‰ª•Â∞Ü‰∫åÁª¥Á©∫Èó¥Êò†Â∞ÑÂà∞‰∏âÁª¥Á©∫Èó¥ÔºåÁÑ∂Âêé‰ΩøÁî®‰∏Ä‰∏™Á∫øÊÄßÂπ≥Èù¢Â∞±ÂèØ‰ª•ËææÊàêÁ±ª‰ººÊïàÊûú„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰∫åÁª¥Âπ≥Èù¢ÂàíÂàÜÂá∫ÁöÑÈùûÁ∫øÊÄßÂàÜÁ±ªÁïåÁ∫øÂèØ‰ª•Á≠â‰ª∑‰∫é‰∏âÁª¥Âπ≥Èù¢ÁöÑÁ∫øÊÄßÂàÜÁ±ªÁïåÁ∫ø„ÄÇ‰∫éÊòØÔºåÊàë‰ª¨ÂèØ‰ª•ÈÄöËøáÂú®‰∏âÁª¥Á©∫Èó¥‰∏≠ËøõË°åÁÆÄÂçïÁöÑÁ∫øÊÄßÂàíÂàÜÂ∞±ÂèØ‰ª•ËææÂà∞Âú®‰∫åÁª¥Âπ≥Èù¢‰∏≠ÁöÑÈùûÁ∫øÊÄßÂàíÂàÜÊïàÊûú„ÄÇ&nbsp;Âõæ12 ‰∏âÁª¥Á©∫Èó¥ÁöÑÂàáÂâ≤ ÊîØÊåÅÂêëÈáèÊú∫ÊòØ‰∏ÄÁßçÊï∞Â≠¶ÊàêÂàÜÂæàÊµìÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºàÁõ∏ÂØπÁöÑÔºåÁ•ûÁªèÁΩëÁªúÂàôÊúâÁîüÁâ©ÁßëÂ≠¶ÊàêÂàÜÔºâ„ÄÇÂú®ÁÆóÊ≥ïÁöÑÊ†∏ÂøÉÊ≠•È™§‰∏≠ÔºåÊúâ‰∏ÄÊ≠•ËØÅÊòéÔºåÂç≥Â∞ÜÊï∞ÊçÆ‰ªé‰ΩéÁª¥Êò†Â∞ÑÂà∞È´òÁª¥‰∏ç‰ºöÂ∏¶Êù•ÊúÄÂêéËÆ°ÁÆóÂ§çÊùÇÊÄßÁöÑÊèêÂçá„ÄÇ‰∫éÊòØÔºåÈÄöËøáÊîØÊåÅÂêëÈáèÊú∫ÁÆóÊ≥ïÔºåÊó¢ÂèØ‰ª•‰øùÊåÅËÆ°ÁÆóÊïàÁéáÔºåÂèàÂèØ‰ª•Ëé∑ÂæóÈùûÂ∏∏Â•ΩÁöÑÂàÜÁ±ªÊïàÊûú„ÄÇÂõ†Ê≠§ÊîØÊåÅÂêëÈáèÊú∫Âú®90Âπ¥‰ª£ÂêéÊúü‰∏ÄÁõ¥Âç†ÊçÆÁùÄÊú∫Âô®Â≠¶‰π†‰∏≠ÊúÄÊ†∏ÂøÉÁöÑÂú∞‰ΩçÔºåÂü∫Êú¨Âèñ‰ª£‰∫ÜÁ•ûÁªèÁΩëÁªúÁÆóÊ≥ï„ÄÇÁõ¥Âà∞Áé∞Âú®Á•ûÁªèÁΩëÁªúÂÄüÁùÄÊ∑±Â∫¶Â≠¶‰π†ÈáçÊñ∞ÂÖ¥Ëµ∑Ôºå‰∏§ËÄÖ‰πãÈó¥ÊâçÂèàÂèëÁîü‰∫ÜÂæÆÂ¶ôÁöÑÂπ≥Ë°°ËΩ¨Âèò„ÄÇ 4„ÄÅËÅöÁ±ªÁÆóÊ≥ï ÂâçÈù¢ÁöÑÁÆóÊ≥ï‰∏≠ÁöÑ‰∏Ä‰∏™ÊòæËëóÁâπÂæÅÂ∞±ÊòØÊàëÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÂåÖÂê´‰∫ÜÊ†áÁ≠æÔºåËÆ≠ÁªÉÂá∫ÁöÑÊ®°ÂûãÂèØ‰ª•ÂØπÂÖ∂‰ªñÊú™Áü•Êï∞ÊçÆÈ¢ÑÊµãÊ†áÁ≠æ„ÄÇÂú®‰∏ãÈù¢ÁöÑÁÆóÊ≥ï‰∏≠ÔºåËÆ≠ÁªÉÊï∞ÊçÆÈÉΩÊòØ‰∏çÂê´Ê†áÁ≠æÁöÑÔºåËÄåÁÆóÊ≥ïÁöÑÁõÆÁöÑÂàôÊòØÈÄöËøáËÆ≠ÁªÉÔºåÊé®ÊµãÂá∫Ëøô‰∫õÊï∞ÊçÆÁöÑÊ†áÁ≠æ„ÄÇËøôÁ±ªÁÆóÊ≥ïÊúâ‰∏Ä‰∏™ÁªüÁß∞ÔºåÂç≥Êó†ÁõëÁù£ÁÆóÊ≥ï(ÂâçÈù¢ÊúâÊ†áÁ≠æÁöÑÊï∞ÊçÆÁöÑÁÆóÊ≥ïÂàôÊòØÊúâÁõëÁù£ÁÆóÊ≥ï)„ÄÇÊó†ÁõëÁù£ÁÆóÊ≥ï‰∏≠ÊúÄÂÖ∏ÂûãÁöÑ‰ª£Ë°®Â∞±ÊòØËÅöÁ±ªÁÆóÊ≥ï„ÄÇ ËÆ©Êàë‰ª¨ËøòÊòØÊãø‰∏Ä‰∏™‰∫åÁª¥ÁöÑÊï∞ÊçÆÊù•ËØ¥ÔºåÊüê‰∏Ä‰∏™Êï∞ÊçÆÂåÖÂê´‰∏§‰∏™ÁâπÂæÅ„ÄÇÊàëÂ∏åÊúõÈÄöËøáËÅöÁ±ªÁÆóÊ≥ïÔºåÁªô‰ªñ‰ª¨‰∏≠‰∏çÂêåÁöÑÁßçÁ±ªÊâì‰∏äÊ†áÁ≠æÔºåÊàëËØ•ÊÄé‰πàÂÅöÂë¢ÔºüÁÆÄÂçïÊù•ËØ¥ÔºåËÅöÁ±ªÁÆóÊ≥ïÂ∞±ÊòØËÆ°ÁÆóÁßçÁæ§‰∏≠ÁöÑË∑ùÁ¶ªÔºåÊ†πÊçÆË∑ùÁ¶ªÁöÑËøúËøëÂ∞ÜÊï∞ÊçÆÂàíÂàÜ‰∏∫Â§ö‰∏™ÊóèÁæ§„ÄÇ ËÅöÁ±ªÁÆóÊ≥ï‰∏≠ÊúÄÂÖ∏ÂûãÁöÑ‰ª£Ë°®Â∞±ÊòØK-MeansÁÆóÊ≥ï„ÄÇ 5„ÄÅÈôçÁª¥ÁÆóÊ≥ï ÈôçÁª¥ÁÆóÊ≥ï‰πüÊòØ‰∏ÄÁßçÊó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåÂÖ∂‰∏ªË¶ÅÁâπÂæÅÊòØÂ∞ÜÊï∞ÊçÆ‰ªéÈ´òÁª¥Èôç‰ΩéÂà∞‰ΩéÁª¥Â±ÇÊ¨°„ÄÇÂú®ËøôÈáåÔºåÁª¥Â∫¶ÂÖ∂ÂÆûË°®Á§∫ÁöÑÊòØÊï∞ÊçÆÁöÑÁâπÂæÅÈáèÁöÑÂ§ßÂ∞èÔºå‰æãÂ¶ÇÔºåÊàø‰ª∑ÂåÖÂê´ÊàøÂ≠êÁöÑÈïø„ÄÅÂÆΩ„ÄÅÈù¢ÁßØ‰∏éÊàøÈó¥Êï∞ÈáèÂõõ‰∏™ÁâπÂæÅÔºå‰πüÂ∞±ÊòØÁª¥Â∫¶‰∏∫4Áª¥ÁöÑÊï∞ÊçÆ„ÄÇÂèØ‰ª•ÁúãÂá∫Êù•ÔºåÈïø‰∏éÂÆΩ‰∫ãÂÆû‰∏ä‰∏éÈù¢ÁßØË°®Á§∫ÁöÑ‰ø°ÊÅØÈáçÂè†‰∫ÜÔºå‰æãÂ¶ÇÈù¢ÁßØ=Èïø &times; ÂÆΩ„ÄÇÈÄöËøáÈôçÁª¥ÁÆóÊ≥ïÊàë‰ª¨Â∞±ÂèØ‰ª•ÂéªÈô§ÂÜó‰Ωô‰ø°ÊÅØÔºåÂ∞ÜÁâπÂæÅÂáèÂ∞ë‰∏∫Èù¢ÁßØ‰∏éÊàøÈó¥Êï∞Èáè‰∏§‰∏™ÁâπÂæÅÔºåÂç≥‰ªé4Áª¥ÁöÑÊï∞ÊçÆÂéãÁº©Âà∞2Áª¥„ÄÇ‰∫éÊòØÊàë‰ª¨Â∞ÜÊï∞ÊçÆ‰ªéÈ´òÁª¥Èôç‰ΩéÂà∞‰ΩéÁª¥Ôºå‰∏ç‰ªÖÂà©‰∫éË°®Á§∫ÔºåÂêåÊó∂Âú®ËÆ°ÁÆó‰∏ä‰πüËÉΩÂ∏¶Êù•Âä†ÈÄü„ÄÇ ÂàöÊâçËØ¥ÁöÑÈôçÁª¥ËøáÁ®ã‰∏≠ÂáèÂ∞ëÁöÑÁª¥Â∫¶Â±û‰∫éËÇâÁúºÂèØËßÜÁöÑÂ±ÇÊ¨°ÔºåÂêåÊó∂ÂéãÁº©‰πü‰∏ç‰ºöÂ∏¶Êù•‰ø°ÊÅØÁöÑÊçüÂ§±(Âõ†‰∏∫‰ø°ÊÅØÂÜó‰Ωô‰∫Ü)„ÄÇÂ¶ÇÊûúËÇâÁúº‰∏çÂèØËßÜÔºåÊàñËÄÖÊ≤°ÊúâÂÜó‰ΩôÁöÑÁâπÂæÅÔºåÈôçÁª¥ÁÆóÊ≥ï‰πüËÉΩÂ∑•‰ΩúÔºå‰∏çËøáËøôÊ†∑‰ºöÂ∏¶Êù•‰∏Ä‰∫õ‰ø°ÊÅØÁöÑÊçüÂ§±„ÄÇ‰ΩÜÊòØÔºåÈôçÁª¥ÁÆóÊ≥ïÂèØ‰ª•‰ªéÊï∞Â≠¶‰∏äËØÅÊòéÔºå‰ªéÈ´òÁª¥ÂéãÁº©Âà∞ÁöÑ‰ΩéÁª¥‰∏≠ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞‰øùÁïô‰∫ÜÊï∞ÊçÆÁöÑ‰ø°ÊÅØ„ÄÇÂõ†Ê≠§Ôºå‰ΩøÁî®ÈôçÁª¥ÁÆóÊ≥ï‰ªçÁÑ∂ÊúâÂæàÂ§öÁöÑÂ•ΩÂ§Ñ„ÄÇ ÈôçÁª¥ÁÆóÊ≥ïÁöÑ‰∏ªË¶Å‰ΩúÁî®ÊòØÂéãÁº©Êï∞ÊçÆ‰∏éÊèêÂçáÊú∫Âô®Â≠¶‰π†ÂÖ∂‰ªñÁÆóÊ≥ïÁöÑÊïàÁéá„ÄÇÈÄöËøáÈôçÁª¥ÁÆóÊ≥ïÔºåÂèØ‰ª•Â∞ÜÂÖ∑ÊúâÂá†ÂçÉ‰∏™ÁâπÂæÅÁöÑÊï∞ÊçÆÂéãÁº©Ëá≥Ëã•Âπ≤‰∏™ÁâπÂæÅ„ÄÇÂè¶Â§ñÔºåÈôçÁª¥ÁÆóÊ≥ïÁöÑÂè¶‰∏Ä‰∏™Â•ΩÂ§ÑÊòØÊï∞ÊçÆÁöÑÂèØËßÜÂåñÔºå‰æãÂ¶ÇÂ∞Ü5Áª¥ÁöÑÊï∞ÊçÆÂéãÁº©Ëá≥2Áª¥ÔºåÁÑ∂ÂêéÂèØ‰ª•Áî®‰∫åÁª¥Âπ≥Èù¢Êù•ÂèØËßÜ„ÄÇÈôçÁª¥ÁÆóÊ≥ïÁöÑ‰∏ªË¶Å‰ª£Ë°®ÊòØPCAÁÆóÊ≥ï(Âç≥‰∏ªÊàêÂàÜÂàÜÊûêÁÆóÊ≥ï)„ÄÇ 6„ÄÅÊé®ËçêÁÆóÊ≥ï Êé®ËçêÁÆóÊ≥ïÊòØÁõÆÂâç‰∏öÁïåÈùûÂ∏∏ÁÅ´ÁöÑ‰∏ÄÁßçÁÆóÊ≥ïÔºåÂú®ÁîµÂïÜÁïåÔºåÂ¶Ç‰∫öÈ©¨ÈÄäÔºåÂ§©Áå´Ôºå‰∫¨‰∏úÁ≠âÂæóÂà∞‰∫ÜÂπøÊ≥õÁöÑËøêÁî®„ÄÇÊé®ËçêÁÆóÊ≥ïÁöÑ‰∏ªË¶ÅÁâπÂæÅÂ∞±ÊòØÂèØ‰ª•Ëá™Âä®ÂêëÁî®Êà∑Êé®Ëçê‰ªñ‰ª¨ÊúÄÊÑüÂÖ¥Ë∂£ÁöÑ‰∏úË•øÔºå‰ªéËÄåÂ¢ûÂä†Ë¥≠‰π∞ÁéáÔºåÊèêÂçáÊïàÁõä„ÄÇÊé®ËçêÁÆóÊ≥ïÊúâ‰∏§‰∏™‰∏ªË¶ÅÁöÑÁ±ªÂà´Ôºö ‰∏ÄÁ±ªÊòØÂü∫‰∫éÁâ©ÂìÅÂÜÖÂÆπÁöÑÊé®ËçêÔºåÊòØÂ∞Ü‰∏éÁî®Êà∑Ë¥≠‰π∞ÁöÑÂÜÖÂÆπËøë‰ººÁöÑÁâ©ÂìÅÊé®ËçêÁªôÁî®Êà∑ÔºåËøôÊ†∑ÁöÑÂâçÊèêÊòØÊØè‰∏™Áâ©ÂìÅÈÉΩÂæóÊúâËã•Âπ≤‰∏™Ê†áÁ≠æÔºåÂõ†Ê≠§ÊâçÂèØ‰ª•ÊâæÂá∫‰∏éÁî®Êà∑Ë¥≠‰π∞Áâ©ÂìÅÁ±ª‰ººÁöÑÁâ©ÂìÅÔºåËøôÊ†∑Êé®ËçêÁöÑÂ•ΩÂ§ÑÊòØÂÖ≥ËÅîÁ®ãÂ∫¶ËæÉÂ§ßÔºå‰ΩÜÊòØÁî±‰∫éÊØè‰∏™Áâ©ÂìÅÈÉΩÈúÄË¶ÅË¥¥Ê†áÁ≠æÔºåÂõ†Ê≠§Â∑•‰ΩúÈáèËæÉÂ§ß„ÄÇ Âè¶‰∏ÄÁ±ªÊòØÂü∫‰∫éÁî®Êà∑Áõ∏‰ººÂ∫¶ÁöÑÊé®ËçêÔºåÂàôÊòØÂ∞Ü‰∏éÁõÆÊ†áÁî®Êà∑ÂÖ¥Ë∂£Áõ∏ÂêåÁöÑÂÖ∂‰ªñÁî®Êà∑Ë¥≠‰π∞ÁöÑ‰∏úË•øÊé®ËçêÁªôÁõÆÊ†áÁî®Êà∑Ôºå‰æãÂ¶ÇÂ∞èAÂéÜÂè≤‰∏ä‰π∞‰∫ÜÁâ©ÂìÅBÂíåCÔºåÁªèËøáÁÆóÊ≥ïÂàÜÊûêÔºåÂèëÁé∞Âè¶‰∏Ä‰∏™‰∏éÂ∞èAËøë‰ººÁöÑÁî®Êà∑Â∞èDË¥≠‰π∞‰∫ÜÁâ©ÂìÅEÔºå‰∫éÊòØÂ∞ÜÁâ©ÂìÅEÊé®ËçêÁªôÂ∞èA„ÄÇ ‰∏§Á±ªÊé®ËçêÈÉΩÊúâÂêÑËá™ÁöÑ‰ºòÁº∫ÁÇπÔºåÂú®‰∏ÄËà¨ÁöÑÁîµÂïÜÂ∫îÁî®‰∏≠Ôºå‰∏ÄËà¨ÊòØ‰∏§Á±ªÊ∑∑Âêà‰ΩøÁî®„ÄÇÊé®ËçêÁÆóÊ≥ï‰∏≠ÊúÄÊúâÂêçÁöÑÁÆóÊ≥ïÂ∞±ÊòØÂçèÂêåËøáÊª§ÁÆóÊ≥ï„ÄÇ 7„ÄÅÂÖ∂‰ªñ Èô§‰∫Ü‰ª•‰∏äÁÆóÊ≥ï‰πãÂ§ñÔºåÊú∫Âô®Â≠¶‰π†ÁïåËøòÊúâÂÖ∂‰ªñÁöÑÂ¶ÇÈ´òÊñØÂà§Âà´ÔºåÊú¥Á¥†Ë¥ùÂè∂ÊñØÔºåÂÜ≥Á≠ñÊ†ëÁ≠âÁ≠âÁÆóÊ≥ï„ÄÇ‰ΩÜÊòØ‰∏äÈù¢ÂàóÁöÑÂÖ≠‰∏™ÁÆóÊ≥ïÊòØ‰ΩøÁî®ÊúÄÂ§öÔºåÂΩ±ÂìçÊúÄÂπøÔºåÁßçÁ±ªÊúÄÂÖ®ÁöÑÂÖ∏Âûã„ÄÇÊú∫Âô®Â≠¶‰π†ÁïåÁöÑ‰∏Ä‰∏™ÁâπËâ≤Â∞±ÊòØÁÆóÊ≥ï‰ºóÂ§öÔºåÂèëÂ±ïÁôæËä±ÈΩêÊîæ„ÄÇ ‰∏ãÈù¢ÂÅö‰∏Ä‰∏™ÊÄªÁªìÔºåÊåâÁÖßËÆ≠ÁªÉÁöÑÊï∞ÊçÆÊúâÊó†Ê†áÁ≠æÔºåÂèØ‰ª•Â∞Ü‰∏äÈù¢ÁÆóÊ≥ïÂàÜ‰∏∫ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÂíåÊó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºå‰ΩÜÊé®ËçêÁÆóÊ≥ïËæÉ‰∏∫ÁâπÊÆäÔºåÊó¢‰∏çÂ±û‰∫éÁõëÁù£Â≠¶‰π†Ôºå‰πü‰∏çÂ±û‰∫éÈùûÁõëÁù£Â≠¶‰π†ÔºåÊòØÂçïÁã¨ÁöÑ‰∏ÄÁ±ª„ÄÇ ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºö Á∫øÊÄßÂõûÂΩíÔºåÈÄªËæëÂõûÂΩíÔºåÁ•ûÁªèÁΩëÁªúÔºåSVM Êó†ÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºö ËÅöÁ±ªÁÆóÊ≥ïÔºåÈôçÁª¥ÁÆóÊ≥ï ÁâπÊÆäÁÆóÊ≥ïÔºö Êé®ËçêÁÆóÊ≥ï Èô§‰∫ÜËøô‰∫õÁÆóÊ≥ï‰ª•Â§ñÔºåÊúâ‰∏Ä‰∫õÁÆóÊ≥ïÁöÑÂêçÂ≠óÂú®Êú∫Âô®Â≠¶‰π†È¢ÜÂüü‰∏≠‰πüÁªèÂ∏∏Âá∫Áé∞„ÄÇ‰ΩÜ‰ªñ‰ª¨Êú¨Ë∫´Âπ∂‰∏çÁÆóÊòØ‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåËÄåÊòØ‰∏∫‰∫ÜËß£ÂÜ≥Êüê‰∏™Â≠êÈóÆÈ¢òËÄåËØûÁîüÁöÑ„ÄÇ‰Ω†ÂèØ‰ª•ÁêÜËß£‰ªñ‰ª¨‰∏∫‰ª•‰∏äÁÆóÊ≥ïÁöÑÂ≠êÁÆóÊ≥ïÔºåÁî®‰∫éÂ§ßÂπÖÂ∫¶ÊèêÈ´òËÆ≠ÁªÉËøáÁ®ã„ÄÇÂÖ∂‰∏≠ÁöÑ‰ª£Ë°®ÊúâÔºöÊ¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºå‰∏ªË¶ÅËøêÁî®Âú®Á∫øÂûãÂõûÂΩíÔºåÈÄªËæëÂõûÂΩíÔºåÁ•ûÁªèÁΩëÁªúÔºåÊé®ËçêÁÆóÊ≥ï‰∏≠ÔºõÁâõÈ°øÊ≥ïÔºå‰∏ªË¶ÅËøêÁî®Âú®Á∫øÂûãÂõûÂΩí‰∏≠ÔºõBPÁÆóÊ≥ïÔºå‰∏ªË¶ÅËøêÁî®Âú®Á•ûÁªèÁΩëÁªú‰∏≠ÔºõSMOÁÆóÊ≥ïÔºå‰∏ªË¶ÅËøêÁî®Âú®SVM‰∏≠„ÄÇ5.Êú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®‚ÄìÂ§ßÊï∞ÊçÆ ËØ¥ÂÆåÊú∫Âô®Â≠¶‰π†ÁöÑÊñπÊ≥ïÔºå‰∏ãÈù¢Ë¶ÅË∞à‰∏ÄË∞àÊú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®‰∫Ü„ÄÇÊó†ÁñëÔºåÂú®2010Âπ¥‰ª•ÂâçÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÂ∫îÁî®Âú®Êüê‰∫õÁâπÂÆöÈ¢ÜÂüüÂèëÊå•‰∫ÜÂ∑®Â§ßÁöÑ‰ΩúÁî®ÔºåÂ¶ÇËΩ¶ÁâåËØÜÂà´ÔºåÁΩëÁªúÊîªÂáªÈò≤ËåÉÔºåÊâãÂÜôÂ≠óÁ¨¶ËØÜÂà´Á≠âÁ≠â„ÄÇ‰ΩÜÊòØÔºå‰ªé2010Âπ¥‰ª•ÂêéÔºåÈöèÁùÄÂ§ßÊï∞ÊçÆÊ¶ÇÂøµÁöÑÂÖ¥Ëµ∑ÔºåÊú∫Âô®Â≠¶‰π†Â§ßÈáèÁöÑÂ∫îÁî®ÈÉΩ‰∏éÂ§ßÊï∞ÊçÆÈ´òÂ∫¶ËÄ¶ÂêàÔºåÂá†‰πéÂèØ‰ª•ËÆ§‰∏∫Â§ßÊï∞ÊçÆÊòØÊú∫Âô®Â≠¶‰π†Â∫îÁî®ÁöÑÊúÄ‰Ω≥Âú∫ÊôØ„ÄÇ Ë≠¨Â¶ÇÔºå‰ΩÜÂá°‰Ω†ËÉΩÊâæÂà∞ÁöÑ‰ªãÁªçÂ§ßÊï∞ÊçÆÈ≠îÂäõÁöÑÊñáÁ´†ÔºåÈÉΩ‰ºöËØ¥Â§ßÊï∞ÊçÆÂ¶Ç‰ΩïÂáÜÁ°ÆÂáÜÁ°ÆÈ¢ÑÊµãÂà∞‰∫ÜÊüê‰∫õ‰∫ã„ÄÇ‰æãÂ¶ÇÁªèÂÖ∏ÁöÑGoogleÂà©Áî®Â§ßÊï∞ÊçÆÈ¢ÑÊµã‰∫ÜH1N1Âú®ÁæéÂõΩÊüêÂ∞èÈïáÁöÑÁàÜÂèë„ÄÇ Âõæ13 GoogleÊàêÂäüÈ¢ÑÊµãH1N1 ÁôæÂ∫¶È¢ÑÊµã2014Âπ¥‰∏ñÁïåÊùØÔºå‰ªéÊ∑òÊ±∞ËµõÂà∞ÂÜ≥ËµõÂÖ®ÈÉ®È¢ÑÊµãÊ≠£Á°Æ„ÄÇÂõæ14 ÁôæÂ∫¶‰∏ñÁïåÊùØÊàêÂäüÈ¢ÑÊµã‰∫ÜÊâÄÊúâÊØîËµõÁªìÊûú Ëøô‰∫õÂÆûÂú®Â§™Á•ûÂ•á‰∫ÜÔºåÈÇ£‰πàÁ©∂Á´üÊòØ‰ªÄ‰πàÂéüÂõ†ÂØºËá¥Â§ßÊï∞ÊçÆÂÖ∑ÊúâËøô‰∫õÈ≠îÂäõÁöÑÂë¢ÔºüÁÆÄÂçïÊù•ËØ¥ÔºåÂ∞±ÊòØÊú∫Âô®Â≠¶‰π†ÊäÄÊúØ„ÄÇÊ≠£ÊòØÂü∫‰∫éÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁöÑÂ∫îÁî®ÔºåÊï∞ÊçÆÊâçËÉΩÂèëÊå•ÂÖ∂È≠îÂäõ„ÄÇ Â§ßÊï∞ÊçÆÁöÑÊ†∏ÂøÉÊòØÂà©Áî®Êï∞ÊçÆÁöÑ‰ª∑ÂÄºÔºåÊú∫Âô®Â≠¶‰π†ÊòØÂà©Áî®Êï∞ÊçÆ‰ª∑ÂÄºÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºåÂØπ‰∫éÂ§ßÊï∞ÊçÆËÄåË®ÄÔºåÊú∫Âô®Â≠¶‰π†ÊòØ‰∏çÂèØÊàñÁº∫ÁöÑ„ÄÇÁõ∏ÂèçÔºåÂØπ‰∫éÊú∫Âô®Â≠¶‰π†ËÄåË®ÄÔºåË∂äÂ§öÁöÑÊï∞ÊçÆ‰ºöË∂ä ÂèØËÉΩÊèêÂçáÊ®°ÂûãÁöÑÁ≤æÁ°ÆÊÄßÔºåÂêåÊó∂ÔºåÂ§çÊùÇÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑËÆ°ÁÆóÊó∂Èó¥‰πüËø´ÂàáÈúÄË¶ÅÂàÜÂ∏ÉÂºèËÆ°ÁÆó‰∏éÂÜÖÂ≠òËÆ°ÁÆóËøôÊ†∑ÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇÂõ†Ê≠§ÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÂÖ¥Áõõ‰πüÁ¶ª‰∏çÂºÄÂ§ßÊï∞ÊçÆÁöÑÂ∏ÆÂä©„ÄÇ Â§ßÊï∞ÊçÆ‰∏éÊú∫Âô®Â≠¶‰π†‰∏§ËÄÖÊòØ‰∫íÁõ∏‰øÉËøõÔºåÁõ∏‰æùÁõ∏Â≠òÁöÑÂÖ≥Á≥ª„ÄÇ Êú∫Âô®Â≠¶‰π†‰∏éÂ§ßÊï∞ÊçÆÁ¥ßÂØÜËÅîÁ≥ª„ÄÇ‰ΩÜÊòØÔºåÂøÖÈ°ªÊ∏ÖÈÜíÁöÑËÆ§ËØÜÂà∞ÔºåÂ§ßÊï∞ÊçÆÂπ∂‰∏çÁ≠âÂêå‰∫éÊú∫Âô®Â≠¶‰π†ÔºåÂêåÁêÜÔºåÊú∫Âô®Â≠¶‰π†‰πü‰∏çÁ≠âÂêå‰∫éÂ§ßÊï∞ÊçÆ„ÄÇÂ§ßÊï∞ÊçÆ‰∏≠ÂåÖÂê´ÊúâÂàÜÂ∏ÉÂºèËÆ°ÁÆóÔºåÂÜÖÂ≠òÊï∞ÊçÆÂ∫ìÔºåÂ§öÁª¥ÂàÜÊûêÁ≠âÁ≠âÂ§öÁßçÊäÄÊúØ„ÄÇÂçï‰ªéÂàÜÊûêÊñπÊ≥ïÊù•ÁúãÔºåÂ§ßÊï∞ÊçÆ‰πüÂåÖÂê´‰ª•‰∏ãÂõõÁßçÂàÜÊûêÊñπÊ≥ïÔºö 1.Â§ßÊï∞ÊçÆÔºåÂ∞èÂàÜÊûêÔºöÂç≥Êï∞ÊçÆ‰ªìÂ∫ìÈ¢ÜÂüüÁöÑOLAPÂàÜÊûêÊÄùË∑ØÔºå‰πüÂ∞±ÊòØÂ§öÁª¥ÂàÜÊûêÊÄùÊÉ≥„ÄÇ 2.Â§ßÊï∞ÊçÆÔºåÂ§ßÂàÜÊûêÔºöËøô‰∏™‰ª£Ë°®ÁöÑÂ∞±ÊòØÊï∞ÊçÆÊåñÊéò‰∏éÊú∫Âô®Â≠¶‰π†ÂàÜÊûêÊ≥ï„ÄÇ 3.ÊµÅÂºèÂàÜÊûêÔºöËøô‰∏™‰∏ªË¶ÅÊåáÁöÑÊòØ‰∫ã‰ª∂È©±Âä®Êû∂ÊûÑ„ÄÇ 4.Êü•ËØ¢ÂàÜÊûêÔºöÁªèÂÖ∏‰ª£Ë°®ÊòØNoSQLÊï∞ÊçÆÂ∫ì„ÄÇ ‰πüÂ∞±ÊòØËØ¥ÔºåÊú∫Âô®Â≠¶‰π†‰ªÖ‰ªÖÊòØÂ§ßÊï∞ÊçÆÂàÜÊûê‰∏≠ÁöÑ‰∏ÄÁßçËÄåÂ∑≤„ÄÇÂ∞ΩÁÆ°Êú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∫õÁªìÊûúÂÖ∑ÊúâÂæàÂ§ßÁöÑÈ≠îÂäõÔºåÂú®ÊüêÁßçÂú∫Âêà‰∏ãÊòØÂ§ßÊï∞ÊçÆ‰ª∑ÂÄºÊúÄÂ•ΩÁöÑËØ¥Êòé„ÄÇ‰ΩÜËøôÂπ∂‰∏ç‰ª£Ë°®Êú∫Âô®Â≠¶‰π†ÊòØÂ§ßÊï∞ÊçÆ‰∏ãÁöÑÂîØ‰∏ÄÁöÑÂàÜÊûêÊñπÊ≥ï„ÄÇ Êú∫Âô®Â≠¶‰π†‰∏éÂ§ßÊï∞ÊçÆÁöÑÁªìÂêà‰∫ßÁîü‰∫ÜÂ∑®Â§ßÁöÑ‰ª∑ÂÄº„ÄÇÂü∫‰∫éÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÊï∞ÊçÆËÉΩÂ§ü&ldquo;È¢ÑÊµã&rdquo;„ÄÇÂØπ‰∫∫Á±ªËÄåË®ÄÔºåÁßØÁ¥ØÁöÑÁªèÈ™åË∂ä‰∏∞ÂØåÔºåÈòÖÂéÜ‰πüÂπøÊ≥õÔºåÂØπÊú™Êù•ÁöÑÂà§Êñ≠Ë∂äÂáÜÁ°Æ„ÄÇ‰æãÂ¶ÇÂ∏∏ËØ¥ÁöÑ&ldquo;ÁªèÈ™å‰∏∞ÂØå&rdquo;ÁöÑ‰∫∫ÊØî&ldquo;ÂàùÂá∫ËåÖÂ∫ê&rdquo;ÁöÑÂ∞è‰ºôÂ≠êÊõ¥ÊúâÂ∑•‰Ωú‰∏äÁöÑ‰ºòÂäøÔºåÂ∞±Âú®‰∫éÁªèÈ™å‰∏∞ÂØåÁöÑ‰∫∫Ëé∑ÂæóÁöÑËßÑÂæãÊØî‰ªñ‰∫∫Êõ¥ÂáÜÁ°Æ„ÄÇËÄåÂú®Êú∫Âô®Â≠¶‰π†È¢ÜÂüüÔºåÊ†πÊçÆËëóÂêçÁöÑ‰∏Ä‰∏™ÂÆûÈ™åÔºåÊúâÊïàÁöÑËØÅÂÆû‰∫ÜÊú∫Âô®Â≠¶‰π†Áïå‰∏Ä‰∏™ÁêÜËÆ∫ÔºöÂç≥Êú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑÊï∞ÊçÆË∂äÂ§öÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÈ¢ÑÊµãÁöÑÊïàÁéáÂ∞±Ë∂äÂ•Ω„ÄÇËßÅ‰∏ãÂõæÔºöÂõæ15 Êú∫Âô®Â≠¶‰π†ÂáÜÁ°ÆÁéá‰∏éÊï∞ÊçÆÁöÑÂÖ≥Á≥ª ÈÄöËøáËøôÂº†ÂõæÂèØ‰ª•ÁúãÂá∫ÔºåÂêÑÁßç‰∏çÂêåÁÆóÊ≥ïÂú®ËæìÂÖ•ÁöÑÊï∞ÊçÆÈáèËææÂà∞‰∏ÄÂÆöÁ∫ßÊï∞ÂêéÔºåÈÉΩÊúâÁõ∏ËøëÁöÑÈ´òÂáÜÁ°ÆÂ∫¶„ÄÇ‰∫éÊòØËØûÁîü‰∫ÜÊú∫Âô®Â≠¶‰π†ÁïåÁöÑÂêçË®ÄÔºöÊàêÂäüÁöÑÊú∫Âô®Â≠¶‰π†Â∫îÁî®‰∏çÊòØÊã•ÊúâÊúÄÂ•ΩÁöÑÁÆóÊ≥ïÔºåËÄåÊòØÊã•ÊúâÊúÄÂ§öÁöÑÊï∞ÊçÆÔºÅ Âú®Â§ßÊï∞ÊçÆÁöÑÊó∂‰ª£ÔºåÊúâÂ•ΩÂ§ö‰ºòÂäø‰øÉ‰ΩøÊú∫Âô®Â≠¶‰π†ËÉΩÂ§üÂ∫îÁî®Êõ¥ÂπøÊ≥õ„ÄÇ‰æãÂ¶ÇÈöèÁùÄÁâ©ËÅîÁΩëÂíåÁßªÂä®ËÆæÂ§áÁöÑÂèëÂ±ïÔºåÊàë‰ª¨Êã•ÊúâÁöÑÊï∞ÊçÆË∂äÊù•Ë∂äÂ§öÔºåÁßçÁ±ª‰πüÂåÖÊã¨ÂõæÁâá„ÄÅÊñáÊú¨„ÄÅËßÜÈ¢ëÁ≠âÈùûÁªìÊûÑÂåñÊï∞ÊçÆÔºåËøô‰ΩøÂæóÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂèØ‰ª•Ëé∑ÂæóË∂äÊù•Ë∂äÂ§öÁöÑÊï∞ÊçÆ„ÄÇÂêåÊó∂Â§ßÊï∞ÊçÆÊäÄÊúØ‰∏≠ÁöÑÂàÜÂ∏ÉÂºèËÆ°ÁÆóMap-Reduce‰ΩøÂæóÊú∫Âô®Â≠¶‰π†ÁöÑÈÄüÂ∫¶Ë∂äÊù•Ë∂äÂø´ÔºåÂèØ‰ª•Êõ¥Êñπ‰æøÁöÑ‰ΩøÁî®„ÄÇÁßçÁßç‰ºòÂäø‰ΩøÂæóÂú®Â§ßÊï∞ÊçÆÊó∂‰ª£ÔºåÊú∫Âô®Â≠¶‰π†ÁöÑ‰ºòÂäøÂèØ‰ª•ÂæóÂà∞ÊúÄ‰Ω≥ÁöÑÂèëÊå•„ÄÇ6.Êú∫Âô®Â≠¶‰π†ÁöÑÂ≠êÁ±ª‚ÄìÊ∑±Â∫¶Â≠¶‰π† ËøëÊù•ÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÂèëÂ±ï‰∫ßÁîü‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÊñπÂêëÔºåÂç≥&ldquo;Ê∑±Â∫¶Â≠¶‰π†&rdquo;„ÄÇ ËôΩÁÑ∂Ê∑±Â∫¶Â≠¶‰π†ËøôÂõõÂ≠óÂê¨Ëµ∑Êù•È¢á‰∏∫È´òÂ§ß‰∏äÔºå‰ΩÜÂÖ∂ÁêÜÂøµÂç¥ÈùûÂ∏∏ÁÆÄÂçïÔºåÂ∞±ÊòØ‰º†ÁªüÁöÑÁ•ûÁªèÁΩëÁªúÂèëÂ±ïÂà∞‰∫ÜÂ§öÈöêËóèÂ±ÇÁöÑÊÉÖÂÜµ„ÄÇ Âú®‰∏äÊñá‰ªãÁªçËøáÔºåËá™‰ªé90Âπ¥‰ª£‰ª•ÂêéÔºåÁ•ûÁªèÁΩëÁªúÂ∑≤ÁªèÊ∂àÂØÇ‰∫Ü‰∏ÄÊÆµÊó∂Èó¥„ÄÇ‰ΩÜÊòØBPÁÆóÊ≥ïÁöÑÂèëÊòé‰∫∫Geoffrey Hinton‰∏ÄÁõ¥Ê≤°ÊúâÊîæÂºÉÂØπÁ•ûÁªèÁΩëÁªúÁöÑÁ†îÁ©∂„ÄÇÁî±‰∫éÁ•ûÁªèÁΩëÁªúÂú®ÈöêËóèÂ±ÇÊâ©Â§ßÂà∞‰∏§‰∏™‰ª•‰∏äÔºåÂÖ∂ËÆ≠ÁªÉÈÄüÂ∫¶Â∞±‰ºöÈùûÂ∏∏ÊÖ¢ÔºåÂõ†Ê≠§ÂÆûÁî®ÊÄß‰∏ÄÁõ¥‰Ωé‰∫éÊîØÊåÅÂêëÈáèÊú∫„ÄÇ2006Âπ¥ÔºåGeoffrey HintonÂú®ÁßëÂ≠¶ÊùÇÂøó„ÄäScience„Äã‰∏äÂèëË°®‰∫Ü‰∏ÄÁØáÊñáÁ´†ÔºåËÆ∫ËØÅ‰∫Ü‰∏§‰∏™ËßÇÁÇπÔºö 1.Â§öÈöêÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªúÂÖ∑Êúâ‰ºòÂºÇÁöÑÁâπÂæÅÂ≠¶‰π†ËÉΩÂäõÔºåÂ≠¶‰π†ÂæóÂà∞ÁöÑÁâπÂæÅÂØπÊï∞ÊçÆÊúâÊõ¥Êú¨Ë¥®ÁöÑÂàªÁîªÔºå‰ªéËÄåÊúâÂà©‰∫éÂèØËßÜÂåñÊàñÂàÜÁ±ªÔºõ 2.Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂú®ËÆ≠ÁªÉ‰∏äÁöÑÈöæÂ∫¶ÔºåÂèØ‰ª•ÈÄöËøá&ldquo;ÈÄêÂ±ÇÂàùÂßãÂåñ&rdquo; Êù•ÊúâÊïàÂÖãÊúç„ÄÇÂõæ16 Geoffrey Hinton‰∏é‰ªñÁöÑÂ≠¶ÁîüÂú®Science‰∏äÂèëË°®ÊñáÁ´† ÈÄöËøáËøôÊ†∑ÁöÑÂèëÁé∞Ôºå‰∏ç‰ªÖËß£ÂÜ≥‰∫ÜÁ•ûÁªèÁΩëÁªúÂú®ËÆ°ÁÆó‰∏äÁöÑÈöæÂ∫¶ÔºåÂêåÊó∂‰πüËØ¥Êòé‰∫ÜÊ∑±Â±ÇÁ•ûÁªèÁΩëÁªúÂú®Â≠¶‰π†‰∏äÁöÑ‰ºòÂºÇÊÄß„ÄÇ‰ªéÊ≠§ÔºåÁ•ûÁªèÁΩëÁªúÈáçÊñ∞Êàê‰∏∫‰∫ÜÊú∫Âô®Â≠¶‰π†Áïå‰∏≠ÁöÑ‰∏ªÊµÅÂº∫Â§ßÂ≠¶‰π†ÊäÄÊúØ„ÄÇÂêåÊó∂ÔºåÂÖ∑ÊúâÂ§ö‰∏™ÈöêËóèÂ±ÇÁöÑÁ•ûÁªèÁΩëÁªúË¢´Áß∞‰∏∫Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÔºåÂü∫‰∫éÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÁöÑÂ≠¶‰π†Á†îÁ©∂Áß∞‰πã‰∏∫Ê∑±Â∫¶Â≠¶‰π†„ÄÇ Áî±‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÈáçË¶ÅÊÄßË¥®ÔºåÂú®ÂêÑÊñπÈù¢ÈÉΩÂèñÂæóÊûÅÂ§ßÁöÑÂÖ≥Ê≥®ÔºåÊåâÁÖßÊó∂Èó¥ËΩ¥ÊéíÂ∫èÔºåÊúâ‰ª•‰∏ãÂõõ‰∏™Ê†áÂøóÊÄß‰∫ã‰ª∂ÂÄºÂæó‰∏ÄËØ¥Ôºö 2012Âπ¥6ÊúàÔºå„ÄäÁ∫ΩÁ∫¶Êó∂Êä•„ÄãÊä´Èú≤‰∫ÜGoogle BrainÈ°πÁõÆÔºåËøô‰∏™È°πÁõÆÊòØÁî±Andrew NgÂíåMap-ReduceÂèëÊòé‰∫∫Jeff DeanÂÖ±Âêå‰∏ªÂØºÔºåÁî®16000‰∏™CPU CoreÁöÑÂπ∂Ë°åËÆ°ÁÆóÂπ≥Âè∞ËÆ≠ÁªÉ‰∏ÄÁßçÁß∞‰∏∫&ldquo;Ê∑±Â±ÇÁ•ûÁªèÁΩëÁªú&rdquo;ÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºåÂú®ËØ≠Èü≥ËØÜÂà´ÂíåÂõæÂÉèËØÜÂà´Á≠âÈ¢ÜÂüüËé∑Âæó‰∫ÜÂ∑®Â§ßÁöÑÊàêÂäü„ÄÇAndrew NgÂ∞±ÊòØÊñáÁ´†ÂºÄÂßãÊâÄ‰ªãÁªçÁöÑÊú∫Âô®Â≠¶‰π†ÁöÑÂ§ßÁâõ(Âõæ1‰∏≠Â∑¶ËÄÖ)„ÄÇ 2012Âπ¥11ÊúàÔºåÂæÆËΩØÂú®‰∏≠ÂõΩÂ§©Ê¥•ÁöÑ‰∏ÄÊ¨°Ê¥ªÂä®‰∏äÂÖ¨ÂºÄÊºîÁ§∫‰∫Ü‰∏Ä‰∏™ÂÖ®Ëá™Âä®ÁöÑÂêåÂ£∞‰º†ËØëÁ≥ªÁªüÔºåËÆ≤ÊºîËÄÖÁî®Ëã±ÊñáÊºîËÆ≤ÔºåÂêéÂè∞ÁöÑËÆ°ÁÆóÊú∫‰∏ÄÊ∞îÂëµÊàêËá™Âä®ÂÆåÊàêËØ≠Èü≥ËØÜÂà´„ÄÅËã±‰∏≠Êú∫Âô®ÁøªËØëÔºå‰ª•Âèä‰∏≠ÊñáËØ≠Èü≥ÂêàÊàêÔºåÊïàÊûúÈùûÂ∏∏ÊµÅÁïÖÔºåÂÖ∂‰∏≠ÊîØÊíëÁöÑÂÖ≥ÈîÆÊäÄÊúØÊòØÊ∑±Â∫¶Â≠¶‰π†Ôºõ 2013Âπ¥1ÊúàÔºåÂú®ÁôæÂ∫¶ÁöÑÂπ¥‰ºö‰∏äÔºåÂàõÂßã‰∫∫ÂÖºCEOÊùéÂΩ¶ÂÆèÈ´òË∞ÉÂÆ£Â∏ÉË¶ÅÊàêÁ´ãÁôæÂ∫¶Á†îÁ©∂Èô¢ÔºåÂÖ∂‰∏≠Á¨¨‰∏Ä‰∏™ÈáçÁÇπÊñπÂêëÂ∞±ÊòØÊ∑±Â∫¶Â≠¶‰π†ÔºåÂπ∂‰∏∫Ê≠§ËÄåÊàêÁ´ãÊ∑±Â∫¶Â≠¶‰π†Á†îÁ©∂Èô¢(IDL)„ÄÇ 2013Âπ¥4ÊúàÔºå„ÄäÈ∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢ÊäÄÊúØËØÑËÆ∫„ÄãÊùÇÂøóÂ∞ÜÊ∑±Â∫¶Â≠¶‰π†Âàó‰∏∫2013Âπ¥ÂçÅÂ§ßÁ™ÅÁ†¥ÊÄßÊäÄÊúØ(Breakthrough Technology)‰πãÈ¶ñ„ÄÇÂõæ17 Ê∑±Â∫¶Â≠¶‰π†ÁöÑÂèëÂ±ïÁÉ≠ÊΩÆ ÊñáÁ´†ÂºÄÂ§¥ÊâÄÂàóÁöÑ‰∏â‰ΩçÊú∫Âô®Â≠¶‰π†ÁöÑÂ§ßÁâõÔºå‰∏ç‰ªÖÈÉΩÊòØÊú∫Âô®Â≠¶‰π†ÁïåÁöÑ‰∏ìÂÆ∂ÔºåÊõ¥ÊòØÊ∑±Â∫¶Â≠¶‰π†Á†îÁ©∂È¢ÜÂüüÁöÑÂÖàÈ©±„ÄÇÂõ†Ê≠§Ôºå‰Ωø‰ªñ‰ª¨ÊãÖ‰ªªÂêÑ‰∏™Â§ßÂûã‰∫íËÅîÁΩëÂÖ¨Âè∏ÊäÄÊúØÊéåËàµËÄÖÁöÑÂéüÂõ†‰∏ç‰ªÖÂú®‰∫é‰ªñ‰ª¨ÁöÑÊäÄÊúØÂÆûÂäõÔºåÊõ¥Âú®‰∫é‰ªñ‰ª¨Á†îÁ©∂ÁöÑÈ¢ÜÂüüÊòØÂâçÊôØÊó†ÈôêÁöÑÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØ„ÄÇ ÁõÆÂâç‰∏öÁïåËÆ∏Â§öÁöÑÂõæÂÉèËØÜÂà´ÊäÄÊúØ‰∏éËØ≠Èü≥ËØÜÂà´ÊäÄÊúØÁöÑËøõÊ≠•ÈÉΩÊ∫ê‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂèëÂ±ïÔºåÈô§‰∫ÜÊú¨ÊñáÂºÄÂ§¥ÊâÄÊèêÁöÑCortanaÁ≠âËØ≠Èü≥Âä©ÊâãÔºåËøòÂåÖÊã¨‰∏Ä‰∫õÂõæÂÉèËØÜÂà´Â∫îÁî®ÔºåÂÖ∂‰∏≠ÂÖ∏ÂûãÁöÑ‰ª£Ë°®Â∞±ÊòØ‰∏ãÂõæÁöÑÁôæÂ∫¶ËØÜÂõæÂäüËÉΩ„ÄÇÂõæ18 ÁôæÂ∫¶ËØÜÂõæ Ê∑±Â∫¶Â≠¶‰π†Â±û‰∫éÊú∫Âô®Â≠¶‰π†ÁöÑÂ≠êÁ±ª„ÄÇÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂèëÂ±ïÊûÅÂ§ßÁöÑ‰øÉËøõ‰∫ÜÊú∫Âô®Â≠¶‰π†ÁöÑÂú∞‰ΩçÊèêÈ´òÔºåÊõ¥Ëøõ‰∏ÄÊ≠•Âú∞ÔºåÊé®Âä®‰∫Ü‰∏öÁïåÂØπÊú∫Âô®Â≠¶‰π†Áà∂Á±ª‰∫∫Â∑•Êô∫ËÉΩÊ¢¶ÊÉ≥ÁöÑÂÜçÊ¨°ÈáçËßÜ„ÄÇ&nbsp;7.Êú∫Âô®Â≠¶‰π†ÁöÑÁà∂Á±ª‚Äì‰∫∫Â∑•Êô∫ËÉΩ ‰∫∫Â∑•Êô∫ËÉΩÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÁà∂Á±ª„ÄÇÊ∑±Â∫¶Â≠¶‰π†ÂàôÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÂ≠êÁ±ª„ÄÇÂ¶ÇÊûúÊää‰∏âËÄÖÁöÑÂÖ≥Á≥ªÁî®ÂõæÊù•Ë°®ÊòéÁöÑËØùÔºåÂàôÊòØ‰∏ãÂõæÔºöÂõæ19 Ê∑±Â∫¶Â≠¶‰π†„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅ‰∫∫Â∑•Êô∫ËÉΩ‰∏âËÄÖÂÖ≥Á≥ª ÊØ´Êó†ÁñëÈóÆÔºå‰∫∫Â∑•Êô∫ËÉΩ(AI)ÊòØ‰∫∫Á±ªÊâÄËÉΩÊÉ≥Ë±°ÁöÑÁßëÊäÄÁïåÊúÄÁ™ÅÁ†¥ÊÄßÁöÑÂèëÊòé‰∫ÜÔºåÊüêÁßçÊÑè‰πâ‰∏äÊù•ËØ¥Ôºå‰∫∫Â∑•Êô∫ËÉΩÂ∞±ÂÉèÊ∏∏ÊàèÊúÄÁªàÂπªÊÉ≥ÁöÑÂêçÂ≠ó‰∏ÄÊ†∑ÔºåÊòØ‰∫∫Á±ªÂØπ‰∫éÁßëÊäÄÁïåÁöÑÊúÄÁªàÊ¢¶ÊÉ≥„ÄÇ‰ªé50Âπ¥‰ª£ÊèêÂá∫‰∫∫Â∑•Êô∫ËÉΩÁöÑÁêÜÂøµ‰ª•ÂêéÔºåÁßëÊäÄÁïåÔºå‰∫ß‰∏öÁïå‰∏çÊñ≠Âú®Êé¢Á¥¢ÔºåÁ†îÁ©∂„ÄÇËøôÊÆµÊó∂Èó¥ÂêÑÁßçÂ∞èËØ¥„ÄÅÁîµÂΩ±ÈÉΩÂú®‰ª•ÂêÑÁßçÊñπÂºèÂ±ïÁé∞ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÊÉ≥Ë±°„ÄÇ‰∫∫Á±ªÂèØ‰ª•ÂèëÊòéÁ±ª‰ºº‰∫é‰∫∫Á±ªÁöÑÊú∫Âô®ÔºåËøôÊòØÂ§ö‰πà‰ºüÂ§ßÁöÑ‰∏ÄÁßçÁêÜÂøµÔºÅ‰ΩÜ‰∫ãÂÆû‰∏äÔºåËá™‰ªé50Âπ¥‰ª£‰ª•ÂêéÔºå‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ïÂ∞±Á£ïÁ£ïÁ¢∞Á¢∞ÔºåÊú™ÊúâËßÅÂà∞Ë∂≥Â§üÈúáÊíºÁöÑÁßëÂ≠¶ÊäÄÊúØÁöÑËøõÊ≠•„ÄÇ ÊÄªÁªìËµ∑Êù•Ôºå‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ïÁªèÂéÜ‰∫ÜÂ¶Ç‰∏ãËã•Âπ≤Èò∂ÊÆµÔºå‰ªéÊó©ÊúüÁöÑÈÄªËæëÊé®ÁêÜÔºåÂà∞‰∏≠ÊúüÁöÑ‰∏ìÂÆ∂Á≥ªÁªüÔºåËøô‰∫õÁßëÁ†îËøõÊ≠•Á°ÆÂÆû‰ΩøÊàë‰ª¨Á¶ªÊú∫Âô®ÁöÑÊô∫ËÉΩÊúâÁÇπÊé•Ëøë‰∫ÜÔºå‰ΩÜËøòÊúâ‰∏ÄÂ§ßÊÆµË∑ùÁ¶ª„ÄÇÁõ¥Âà∞Êú∫Âô®Â≠¶‰π†ËØûÁîü‰ª•ÂêéÔºå‰∫∫Â∑•Êô∫ËÉΩÁïåÊÑüËßâÁªà‰∫éÊâæÂØπ‰∫ÜÊñπÂêë„ÄÇÂü∫‰∫éÊú∫Âô®Â≠¶‰π†ÁöÑÂõæÂÉèËØÜÂà´ÂíåËØ≠Èü≥ËØÜÂà´Âú®Êüê‰∫õÂûÇÁõ¥È¢ÜÂüüËææÂà∞‰∫ÜË∑ü‰∫∫Áõ∏Â™≤ÁæéÁöÑÁ®ãÂ∫¶„ÄÇÊú∫Âô®Â≠¶‰π†‰Ωø‰∫∫Á±ªÁ¨¨‰∏ÄÊ¨°Â¶ÇÊ≠§Êé•Ëøë‰∫∫Â∑•Êô∫ËÉΩÁöÑÊ¢¶ÊÉ≥„ÄÇ ‰∫ãÂÆû‰∏äÔºåÂ¶ÇÊûúÊàë‰ª¨Êää‰∫∫Â∑•Êô∫ËÉΩÁõ∏ÂÖ≥ÁöÑÊäÄÊúØ‰ª•ÂèäÂÖ∂‰ªñ‰∏öÁïåÁöÑÊäÄÊúØÂÅö‰∏Ä‰∏™Á±ªÊØîÔºåÂ∞±ÂèØ‰ª•ÂèëÁé∞Êú∫Âô®Â≠¶‰π†Âú®‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÁöÑÈáçË¶ÅÂú∞‰Ωç‰∏çÊòØÊ≤°ÊúâÁêÜÁî±ÁöÑ„ÄÇ ‰∫∫Á±ªÂå∫Âà´‰∫éÂÖ∂‰ªñÁâ©‰ΩìÔºåÊ§çÁâ©ÔºåÂä®Áâ©ÁöÑÊúÄ‰∏ªË¶ÅÂå∫Âà´Ôºå‰ΩúËÄÖËÆ§‰∏∫ÊòØ&ldquo;Êô∫ÊÖß&rdquo;„ÄÇËÄåÊô∫ÊÖßÁöÑÊúÄ‰Ω≥‰ΩìÁé∞ÊòØ‰ªÄ‰πàÔºü ÊòØËÆ°ÁÆóËÉΩÂäõ‰πàÔºåÂ∫îËØ•‰∏çÊòØÔºåÂøÉÁÆóÈÄüÂ∫¶Âø´ÁöÑ‰∫∫Êàë‰ª¨‰∏ÄËà¨Áß∞‰πã‰∏∫Â§©Êâç„ÄÇ ÊòØÂèçÂ∫îËÉΩÂäõ‰πàÔºå‰πü‰∏çÊòØÔºåÂèçÂ∫îÂø´ÁöÑ‰∫∫Êàë‰ª¨Áß∞‰πã‰∏∫ÁÅµÊïè„ÄÇ ÊòØËÆ∞ÂøÜËÉΩÂäõ‰πàÔºå‰πü‰∏çÊòØÔºåËÆ∞ÂøÜÂ•ΩÁöÑ‰∫∫Êàë‰ª¨‰∏ÄËà¨Áß∞‰πã‰∏∫ËøáÁõÆ‰∏çÂøò„ÄÇ ÊòØÊé®ÁêÜËÉΩÂäõ‰πàÔºåËøôÊ†∑ÁöÑ‰∫∫Êàë‰πüËÆ∏‰ºöÁß∞‰ªñÊô∫ÂäõÂæàÈ´òÔºåÁ±ª‰ºº&ldquo;Á¶èÂ∞îÊë©ÊñØ&rdquo;Ôºå‰ΩÜ‰∏ç‰ºöÁß∞‰ªñÊã•ÊúâÊô∫ÊÖß„ÄÇ ÊòØÁü•ËØÜËÉΩÂäõ‰πàÔºåËøôÊ†∑ÁöÑ‰∫∫Êàë‰ª¨Áß∞‰πã‰∏∫ÂçöÈóªÂπøÔºå‰πü‰∏ç‰ºöÁß∞‰ªñÊã•ÊúâÊô∫ÊÖß„ÄÇ ÊÉ≥ÊÉ≥ÁúãÊàë‰ª¨‰∏ÄËà¨ÂΩ¢ÂÆπË∞ÅÊúâÂ§ßÊô∫ÊÖßÔºüÂú£‰∫∫ÔºåËØ∏Â¶ÇÂ∫ÑÂ≠êÔºåËÄÅÂ≠êÁ≠â„ÄÇÊô∫ÊÖßÊòØÂØπÁîüÊ¥ªÁöÑÊÑüÊÇüÔºåÊòØÂØπ‰∫∫ÁîüÁöÑÁßØÊ∑Ä‰∏éÊÄùËÄÉÔºåËøô‰∏éÊàë‰ª¨Êú∫Âô®Â≠¶‰π†ÁöÑÊÄùÊÉ≥‰ΩïÂÖ∂Áõ∏‰ººÔºüÈÄöËøáÁªèÈ™åËé∑ÂèñËßÑÂæãÔºåÊåáÂØº‰∫∫Áîü‰∏éÊú™Êù•„ÄÇÊ≤°ÊúâÁªèÈ™åÂ∞±Ê≤°ÊúâÊô∫ÊÖß„ÄÇ&nbsp;Âõæ20 Êú∫Âô®Â≠¶‰π†‰∏éÊô∫ÊÖß ÈÇ£‰πàÔºå‰ªéËÆ°ÁÆóÊú∫Êù•ÁúãÔºå‰ª•‰∏äÁöÑÁßçÁßçËÉΩÂäõÈÉΩÊúâÁßçÁßçÊäÄÊúØÂéªÂ∫îÂØπ„ÄÇ ‰æãÂ¶ÇËÆ°ÁÆóËÉΩÂäõÊàë‰ª¨ÊúâÂàÜÂ∏ÉÂºèËÆ°ÁÆóÔºåÂèçÂ∫îËÉΩÂäõÊàë‰ª¨Êúâ‰∫ã‰ª∂È©±Âä®Êû∂ÊûÑÔºåÊ£ÄÁ¥¢ËÉΩÂäõÊàë‰ª¨ÊúâÊêúÁ¥¢ÂºïÊìéÔºåÁü•ËØÜÂ≠òÂÇ®ËÉΩÂäõÊàë‰ª¨ÊúâÊï∞ÊçÆ‰ªìÂ∫ìÔºåÈÄªËæëÊé®ÁêÜËÉΩÂäõÊàë‰ª¨Êúâ‰∏ìÂÆ∂Á≥ªÁªüÔºå‰ΩÜÊòØÔºåÂîØÊúâÂØπÂ∫îÊô∫ÊÖß‰∏≠ÊúÄÊòæËëóÁâπÂæÅÁöÑÂΩíÁ∫≥‰∏éÊÑüÊÇüËÉΩÂäõÔºåÂè™ÊúâÊú∫Âô®Â≠¶‰π†‰∏é‰πãÂØπÂ∫î„ÄÇËøô‰πüÊòØÊú∫Âô®Â≠¶‰π†ËÉΩÂäõÊúÄËÉΩË°®ÂæÅÊô∫ÊÖßÁöÑÊ†πÊú¨ÂéüÂõ†„ÄÇ ËÆ©Êàë‰ª¨ÂÜçÁúã‰∏Ä‰∏ãÊú∫Âô®‰∫∫ÁöÑÂà∂ÈÄ†ÔºåÂú®Êàë‰ª¨ÂÖ∑Êúâ‰∫ÜÂº∫Â§ßÁöÑËÆ°ÁÆóÔºåÊµ∑ÈáèÁöÑÂ≠òÂÇ®ÔºåÂø´ÈÄüÁöÑÊ£ÄÁ¥¢ÔºåËøÖÈÄüÁöÑÂèçÂ∫îÔºå‰ºòÁßÄÁöÑÈÄªËæëÊé®ÁêÜÂêéÊàë‰ª¨Â¶ÇÊûúÂÜçÈÖçÂêà‰∏ä‰∏Ä‰∏™Âº∫Â§ßÁöÑÊô∫ÊÖßÂ§ßËÑëÔºå‰∏Ä‰∏™ÁúüÊ≠£ÊÑè‰πâ‰∏äÁöÑ‰∫∫Â∑•Êô∫ËÉΩ‰πüËÆ∏Â∞±‰ºöËØûÁîüÔºåËøô‰πüÊòØ‰∏∫‰ªÄ‰πàËØ¥Âú®Êú∫Âô®Â≠¶‰π†Âø´ÈÄüÂèëÂ±ïÁöÑÁé∞Âú®Ôºå‰∫∫Â∑•Êô∫ËÉΩÂèØËÉΩ‰∏çÂÜçÊòØÊ¢¶ÊÉ≥ÁöÑÂéüÂõ†„ÄÇ ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ïÂèØËÉΩ‰∏ç‰ªÖÂèñÂÜ≥‰∫éÊú∫Âô®Â≠¶‰π†ÔºåÊõ¥ÂèñÂÜ≥‰∫éÂâçÈù¢ÊâÄ‰ªãÁªçÁöÑÊ∑±Â∫¶Â≠¶‰π†ÔºåÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÁî±‰∫éÊ∑±Â∫¶Ê®°Êãü‰∫Ü‰∫∫Á±ªÂ§ßËÑëÁöÑÊûÑÊàêÔºåÂú®ËßÜËßâËØÜÂà´‰∏éËØ≠Èü≥ËØÜÂà´‰∏äÊòæËëóÊÄßÁöÑÁ™ÅÁ†¥‰∫ÜÂéüÊúâÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁöÑÁïåÈôêÔºåÂõ†Ê≠§ÊûÅÊúâÂèØËÉΩÊòØÁúüÊ≠£ÂÆûÁé∞‰∫∫Â∑•Êô∫ËÉΩÊ¢¶ÊÉ≥ÁöÑÂÖ≥ÈîÆÊäÄÊúØ„ÄÇÊó†ËÆ∫ÊòØË∞∑Ê≠åÂ§ßËÑëËøòÊòØÁôæÂ∫¶Â§ßËÑëÔºåÈÉΩÊòØÈÄöËøáÊµ∑ÈáèÂ±ÇÊ¨°ÁöÑÊ∑±Â∫¶Â≠¶‰π†ÁΩëÁªúÊâÄÊûÑÊàêÁöÑ„ÄÇ‰πüËÆ∏ÂÄüÂä©‰∫éÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÔºåÂú®‰∏çËøúÁöÑÂ∞ÜÊù•Ôºå‰∏Ä‰∏™ÂÖ∑Êúâ‰∫∫Á±ªÊô∫ËÉΩÁöÑËÆ°ÁÆóÊú∫ÁúüÁöÑÊúâÂèØËÉΩÂÆûÁé∞„ÄÇ ÊúÄÂêéÂÜçËØ¥‰∏Ä‰∏ãÈ¢òÂ§ñËØùÔºåÁî±‰∫é‰∫∫Â∑•Êô∫ËÉΩÂÄüÂä©‰∫éÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÁöÑÂø´ÈÄüÂèëÂ±ïÔºåÂ∑≤ÁªèÂú®Êüê‰∫õÂú∞ÊñπÂºïËµ∑‰∫Ü‰º†ÁªüÊäÄÊúØÁïåËææ‰∫∫ÁöÑÊãÖÂøß„ÄÇÁúüÂÆû‰∏ñÁïåÁöÑ&ldquo;Èí¢ÈìÅ‰æ†&rdquo;ÔºåÁâπÊñØÊãâCEOÈ©¨ÊñØÂÖãÂ∞±ÊòØÂÖ∂‰∏≠‰πã‰∏Ä„ÄÇÊúÄËøëÈ©¨ÊñØÂÖãÂú®ÂèÇÂä†MITËÆ®ËÆ∫‰ºöÊó∂ÔºåÂ∞±Ë°®Ëææ‰∫ÜÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÊãÖÂøß„ÄÇ&ldquo;‰∫∫Â∑•Êô∫ËÉΩÁöÑÁ†îÁ©∂Â∞±Á±ª‰ºº‰∫éÂè¨Âî§ÊÅ∂È≠îÔºåÊàë‰ª¨ÂøÖÈ°ªÂú®Êüê‰∫õÂú∞ÊñπÂä†Âº∫Ê≥®ÊÑè„ÄÇ&rdquo;&nbsp;Âõæ21 È©¨ÊñØÂÖã‰∏é‰∫∫Â∑•Êô∫ËÉΩ Â∞ΩÁÆ°È©¨ÊñØÂÖãÁöÑÊãÖÂøÉÊúâ‰∫õÂç±Ë®ÄËÄ∏Âê¨Ôºå‰ΩÜÊòØÈ©¨ÊñØÂÖãÁöÑÊé®ÁêÜ‰∏çÊó†ÈÅìÁêÜ„ÄÇ&ldquo;Â¶ÇÊûú‰∫∫Â∑•Êô∫ËÉΩÊÉ≥Ë¶ÅÊ∂àÈô§ÂûÉÂúæÈÇÆ‰ª∂ÁöÑËØùÔºåÂèØËÉΩÂÆÉÊúÄÂêéÁöÑÂÜ≥ÂÆöÂ∞±ÊòØÊ∂àÁÅ≠‰∫∫Á±ª„ÄÇ&rdquo;È©¨ÊñØÂÖãËÆ§‰∏∫È¢ÑÈò≤Ê≠§Á±ªÁé∞Ë±°ÁöÑÊñπÊ≥ïÊòØÂºïÂÖ•ÊîøÂ∫úÁöÑÁõëÁÆ°„ÄÇÂú®ËøôÈáå‰ΩúËÄÖÁöÑËßÇÁÇπ‰∏éÈ©¨ÊñØÂÖãÁ±ª‰ººÔºåÂú®‰∫∫Â∑•Êô∫ËÉΩËØûÁîü‰πãÂàùÂ∞±ÁªôÂÖ∂Âä†‰∏äËã•Âπ≤ËßÑÂàôÈôêÂà∂ÂèØËÉΩÊúâÊïàÔºå‰πüÂ∞±ÊòØ‰∏çÂ∫îËØ•‰ΩøÁî®ÂçïÁ∫ØÁöÑÊú∫Âô®Â≠¶‰π†ÔºåËÄåÂ∫îËØ•ÊòØÊú∫Âô®Â≠¶‰π†‰∏éËßÑÂàôÂºïÊìéÁ≠âÁ≥ªÁªüÁöÑÁªºÂêàËÉΩÂ§üËæÉÂ•ΩÁöÑËß£ÂÜ≥ËøôÁ±ªÈóÆÈ¢ò„ÄÇÂõ†‰∏∫Â¶ÇÊûúÂ≠¶‰π†Ê≤°ÊúâÈôêÂà∂ÔºåÊûÅÊúâÂèØËÉΩËøõÂÖ•Êüê‰∏™ËØØÂå∫ÔºåÂøÖÈ°ªË¶ÅÂä†‰∏äÊüê‰∫õÂºïÂØº„ÄÇÊ≠£Â¶Ç‰∫∫Á±ªÁ§æ‰ºö‰∏≠ÔºåÊ≥ïÂæãÂ∞±ÊòØ‰∏Ä‰∏™ÊúÄÂ•ΩÁöÑËßÑÂàôÔºåÊùÄ‰∫∫ËÄÖÊ≠ªÂ∞±ÊòØÂØπ‰∫é‰∫∫Á±ªÂú®Êé¢Á¥¢ÊèêÈ´òÁîü‰∫ßÂäõÊó∂‰∏çÂèØÈÄæË∂äÁöÑÁïåÈôê„ÄÇ Âú®ËøôÈáåÔºåÂøÖÈ°ªÊèê‰∏Ä‰∏ãËøôÈáåÁöÑËßÑÂàô‰∏éÊú∫Âô®Â≠¶‰π†ÂºïÂá∫ÁöÑËßÑÂæãÁöÑ‰∏çÂêåÔºåËßÑÂæã‰∏çÊòØ‰∏Ä‰∏™‰∏•Ê†ºÊÑè‰πâÁöÑÂáÜÂàôÔºåÂÖ∂‰ª£Ë°®ÁöÑÊõ¥Â§öÊòØÊ¶ÇÁéá‰∏äÁöÑÊåáÂØºÔºåËÄåËßÑÂàôÂàôÊòØÁ•ûÂú£‰∏çÂèØ‰æµÁäØÔºå‰∏çÂèØ‰øÆÊîπÁöÑ„ÄÇËßÑÂæãÂèØ‰ª•Ë∞ÉÊï¥Ôºå‰ΩÜËßÑÂàôÊòØ‰∏çËÉΩÊîπÂèòÁöÑ„ÄÇÊúâÊïàÁöÑÁªìÂêàËßÑÂæã‰∏éËßÑÂàôÁöÑÁâπÁÇπÔºåÂèØ‰ª•ÂºïÂØºÂá∫‰∏Ä‰∏™ÂêàÁêÜÁöÑÔºåÂèØÊéßÁöÑÂ≠¶‰π†Âûã‰∫∫Â∑•Êô∫ËÉΩ„ÄÇ&nbsp;8.Êú∫Âô®Â≠¶‰π†ÁöÑÊÄùËÄÉ‚ÄìËÆ°ÁÆóÊú∫ÁöÑÊΩúÊÑèËØÜ ÊúÄÂêéÔºå‰ΩúËÄÖÊÉ≥Ë∞à‰∏ÄË∞àÂÖ≥‰∫éÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∫õÊÄùËÄÉ„ÄÇ‰∏ªË¶ÅÊòØ‰ΩúËÄÖÂú®Êó•Â∏∏ÁîüÊ¥ªÊÄªÁªìÂá∫Êù•ÁöÑ‰∏Ä‰∫õÊÑüÊÇü„ÄÇ ÂõûÊÉ≥‰∏Ä‰∏ãÊàëÂú®ËäÇ1ÈáåÊâÄËØ¥ÁöÑÊïÖ‰∫ãÔºåÊàëÊääÂ∞èYËøáÂæÄË∑üÊàëÁõ∏Á∫¶ÁöÑÁªèÂéÜÂÅö‰∫Ü‰∏Ä‰∏™ÁΩóÂàó„ÄÇ‰ΩÜÊòØËøôÁßçÁΩóÂàó‰ª•ÂæÄÊâÄÊúâÁªèÂéÜÁöÑÊñπÊ≥ïÂè™ÊúâÂ∞ëÊï∞‰∫∫‰ºöËøô‰πàÂÅöÔºåÂ§ßÈÉ®ÂàÜÁöÑ‰∫∫ÈááÁî®ÁöÑÊòØÊõ¥Áõ¥Êé•ÁöÑÊñπÊ≥ïÔºåÂç≥Âà©Áî®Áõ¥Ëßâ„ÄÇÈÇ£‰πàÔºåÁõ¥ËßâÊòØ‰ªÄ‰πàÔºüÂÖ∂ÂÆûÁõ¥Ëßâ‰πüÊòØ‰Ω†Âú®ÊΩúÊÑèËØÜÁä∂ÊÄÅ‰∏ãÊÄùËÄÉÁªèÈ™åÂêéÂæóÂá∫ÁöÑËßÑÂæã„ÄÇÂ∞±ÂÉè‰Ω†ÈÄöËøáÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÂæóÂà∞‰∫Ü‰∏Ä‰∏™Ê®°ÂûãÔºåÈÇ£‰πà‰Ω†‰∏ãÊ¨°Âè™Ë¶ÅÁõ¥Êé•‰ΩøÁî®Â∞±Ë°å‰∫Ü„ÄÇÈÇ£‰πàËøô‰∏™ËßÑÂæã‰Ω†ÊòØ‰ªÄ‰πàÊó∂ÂÄôÊÄùËÄÉÁöÑÔºüÂèØËÉΩÊòØÂú®‰Ω†Êó†ÊÑèËØÜÁöÑÊÉÖÂÜµ‰∏ãÔºå‰æãÂ¶ÇÁù°ËßâÔºåËµ∞Ë∑ØÁ≠âÊÉÖÂÜµ„ÄÇËøôÁßçÊó∂ÂÄôÔºåÂ§ßËÑëÂÖ∂ÂÆû‰πüÂú®ÈªòÈªòÂú∞ÂÅö‰∏Ä‰∫õ‰Ω†ÂØüËßâ‰∏çÂà∞ÁöÑÂ∑•‰Ωú„ÄÇ ËøôÁßçÁõ¥Ëßâ‰∏éÊΩúÊÑèËØÜÔºåÊàëÊääÂÆÉ‰∏éÂè¶‰∏ÄÁßç‰∫∫Á±ªÊÄùËÄÉÁªèÈ™åÁöÑÊñπÂºèÂÅö‰∫ÜÂå∫ÂàÜ„ÄÇÂ¶ÇÊûú‰∏Ä‰∏™‰∫∫Âã§‰∫éÊÄùËÄÉÔºå‰æãÂ¶Ç‰ªñ‰ºöÊØèÂ§©ÂÅö‰∏Ä‰∏™Â∞èÁªìÔºåË≠¨Â¶Ç&ldquo;ÂêæÊó•‰∏âÁúÅÂêæË∫´&rdquo;ÔºåÊàñËÄÖ‰ªñÁªèÂ∏∏‰∏éÂêå‰º¥ËÆ®ËÆ∫ÊúÄËøëÂ∑•‰ΩúÁöÑÂæóÂ§±ÔºåÈÇ£‰πà‰ªñËøôÁßçËÆ≠ÁªÉÊ®°ÂûãÁöÑÊñπÂºèÊòØÁõ¥Êé•ÁöÑÔºåÊòéÊÑèËØÜÁöÑÊÄùËÄÉ‰∏éÂΩíÁ∫≥„ÄÇËøôÊ†∑ÁöÑÊïàÊûúÂæàÂ•ΩÔºåËÆ∞ÂøÜÊÄßÂº∫ÔºåÂπ∂‰∏îÊõ¥ËÉΩÂæóÂá∫ÊúâÊïàÂèçÂ∫îÁé∞ÂÆûÁöÑËßÑÂæã„ÄÇ‰ΩÜÊòØÂ§ßÈÉ®ÂàÜÁöÑ‰∫∫ÂèØËÉΩÂæàÂ∞ëÂÅöËøôÊ†∑ÁöÑÊÄªÁªìÔºåÈÇ£‰πà‰ªñ‰ª¨ÂæóÂá∫ÁîüÊ¥ª‰∏≠ËßÑÂæãÁöÑÊñπÊ≥ï‰ΩøÁî®ÁöÑÂ∞±ÊòØÊΩúÊÑèËØÜÊ≥ï„ÄÇ ‰∏æ‰∏Ä‰∏™‰ΩúËÄÖÊú¨‰∫∫ÂÖ≥‰∫éÊΩúÊÑèËØÜÁöÑ‰æãÂ≠ê„ÄÇ‰ΩúËÄÖÊú¨‰∫∫‰ª•ÂâçÊ≤°ÂºÄËøáËΩ¶ÔºåÊúÄËøë‰∏ÄÊÆµÊó∂Èó¥‰π∞‰∫ÜËΩ¶ÂêéÔºåÂ§©Â§©ÂºÄËΩ¶‰∏äÁè≠„ÄÇÊàëÊØèÂ§©ÈÉΩËµ∞Âõ∫ÂÆöÁöÑË∑ØÁ∫ø„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂú®‰∏ÄÂºÄÂßãÁöÑÂá†Â§©ÔºåÊàëÈùûÂ∏∏Á¥ßÂº†ÁöÑÊ≥®ÊÑèÁùÄÂâçÊñπÁöÑË∑ØÂÜµÔºåËÄåÁé∞Âú®ÊàëÂ∑≤ÁªèÂú®Êó†ÊÑèËØÜ‰∏≠Â∞±ÊääËΩ¶ÂºÄÂà∞‰∫ÜÁõÆÊ†á„ÄÇËøô‰∏™ËøáÁ®ã‰∏≠ÊàëÁöÑÁúºÁùõÊòØÊ≥®ËßÜÁùÄÂâçÊñπÁöÑÔºåÊàëÁöÑÂ§ßËÑëÊòØÊ≤°ÊúâÊÄùËÄÉÔºå‰ΩÜÊòØÊàëÊâãÊè°ÁùÄÁöÑÊñπÂêëÁõò‰ºöËá™Âä®ÁöÑË∞ÉÊï¥ÊñπÂêë„ÄÇ‰πüÂ∞±ÊòØËØ¥„ÄÇÈöèÁùÄÊàëÂºÄËΩ¶Ê¨°Êï∞ÁöÑÂ¢ûÂ§öÔºåÊàëÂ∑≤ÁªèÊääÊàëÂºÄËΩ¶ÁöÑÂä®‰Ωú‰∫§Áªô‰∫ÜÊΩúÊÑèËØÜ„ÄÇËøôÊòØÈùûÂ∏∏ÊúâË∂£ÁöÑ‰∏Ä‰ª∂‰∫ã„ÄÇÂú®ËøôÊÆµËøáÁ®ã‰∏≠ÔºåÊàëÁöÑÂ§ßËÑëÂ∞ÜÂâçÊñπË∑ØÂÜµÁöÑÂõæÂÉèËÆ∞ÂΩï‰∫Ü‰∏ãÊù•ÔºåÂêåÊó∂Â§ßËÑë‰πüËÆ∞ÂøÜ‰∫ÜÊàëËΩ¨Âä®ÊñπÂêëÁõòÁöÑÂä®‰Ωú„ÄÇÁªèËøáÂ§ßËÑëËá™Â∑±ÁöÑÊΩúÊÑèËØÜÊÄùËÄÉÔºåÊúÄÂêéÁîüÊàêÁöÑÊΩúÊÑèËØÜÂèØ‰ª•Áõ¥Êé•Ê†πÊçÆÂâçÊñπÁöÑÂõæÂÉèË∞ÉÊï¥ÊàëÊâãÁöÑÂä®‰Ωú„ÄÇÂÅáËÆæÊàë‰ª¨Â∞ÜÂâçÊñπÁöÑÂΩïÂÉè‰∫§ÁªôËÆ°ÁÆóÊú∫ÔºåÁÑ∂ÂêéËÆ©ËÆ°ÁÆóÊú∫ËÆ∞ÂΩï‰∏éÂõæÂÉèÂØπÂ∫îÁöÑÈ©æÈ©∂ÂëòÁöÑÂä®‰Ωú„ÄÇÁªèËøá‰∏ÄÊÆµÊó∂Èó¥ÁöÑÂ≠¶‰π†ÔºåËÆ°ÁÆóÊú∫ÁîüÊàêÁöÑÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÂ∞±ÂèØ‰ª•ËøõË°åËá™Âä®È©æÈ©∂‰∫Ü„ÄÇËøôÂæàÁ•ûÂ•áÔºå‰∏çÊòØ‰πà„ÄÇÂÖ∂ÂÆûÂåÖÊã¨Google„ÄÅÁâπÊñØÊãâÂú®ÂÜÖÁöÑËá™Âä®È©æÈ©∂Ê±ΩËΩ¶ÊäÄÊúØÁöÑÂéüÁêÜÂ∞±ÊòØËøôÊ†∑„ÄÇ Èô§‰∫ÜËá™Âä®È©æÈ©∂Ê±ΩËΩ¶‰ª•Â§ñÔºåÊΩúÊÑèËØÜÁöÑÊÄùÊÉ≥ËøòÂèØ‰ª•Êâ©Â±ïÂà∞‰∫∫ÁöÑ‰∫§ÈôÖ„ÄÇË≠¨Â¶ÇËØ¥ÊúçÂà´‰∫∫Ôºå‰∏Ä‰∏™ÊúÄ‰Ω≥ÁöÑÊñπÊ≥ïÂ∞±ÊòØÁªô‰ªñÂ±ïÁ§∫‰∏Ä‰∫õ‰ø°ÊÅØÔºåÁÑ∂ÂêéËÆ©‰ªñËá™Â∑±ÂéªÂΩíÁ∫≥ÂæóÂá∫Êàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÁªìËÆ∫„ÄÇËøôÂ∞±Â•ΩÊØîÂú®ÈòêËø∞‰∏Ä‰∏™ËßÇÁÇπÊó∂ÔºåÁî®‰∏Ä‰∏™‰∫ãÂÆûÔºåÊàñËÄÖ‰∏Ä‰∏™ÊïÖ‰∫ãÔºåÊØîÂ§ßÊÆµÁöÑÈÅìÁêÜË¶ÅÂ•ΩÂæàÂ§ö„ÄÇÂè§ÂæÄ‰ªäÊù•Ôºå‰ΩÜÂá°‰ºòÁßÄÁöÑËØ¥ÂÆ¢ÔºåÊó†‰∏çÈááÁî®ÁöÑÊòØËøôÁßçÊñπÊ≥ï„ÄÇÊò•ÁßãÊàòÂõΩÊó∂ÊúüÔºåÂêÑÂõΩÂêàÁ∫µËøûÊ®™ÔºåÁªèÂ∏∏ÊúâÂêÑÁßçËØ¥ÂÆ¢ÂéªË∑ü‰∏ÄÂõΩ‰πãÂêõ‰∫§ÊµÅÔºåÁõ¥Êé•ÂëäËØâÂêõ‰∏ªËØ•ÂÅö‰ªÄ‰πàÔºåÊó†ÂºÇ‰∫éËá™ÂØªÊ≠ªË∑ØÔºå‰ΩÜÊòØË∑üÂêõ‰∏ªËÆ≤ÊïÖ‰∫ãÔºåÈÄöËøáËøô‰∫õÊïÖ‰∫ãËÆ©Âêõ‰∏ªÊÅçÁÑ∂Â§ßÊÇüÔºåÂ∞±ÊòØ‰∏ÄÁßçÊ≠£Á°ÆÁöÑËøáÁ®ã„ÄÇËøôÈáåÈù¢ÊúâËÆ∏Â§öÊù∞Âá∫ÁöÑ‰ª£Ë°®ÔºåÂ¶ÇÂ¢®Â≠êÔºåËãèÁß¶Á≠âÁ≠â„ÄÇ Âü∫Êú¨‰∏äÊâÄÊúâÁöÑ‰∫§ÊµÅËøáÁ®ãÔºå‰ΩøÁî®ÊïÖ‰∫ãËØ¥ÊòéÁöÑÊïàÊûúÈÉΩË¶ÅËøúËÉú‰∫éÈòêËø∞ÈÅì‰πâ‰πãÁ±ªÁöÑÊïàÊûúÂ•ΩÂæàÂ§ö„ÄÇ‰∏∫‰ªÄ‰πàÁî®ÊïÖ‰∫ãÁöÑÊñπÊ≥ïÊØîÈÅìÁêÜÊàñËÄÖÂÖ∂‰ªñÁöÑÊñπÊ≥ïÂ•ΩÂæàÂ§öÔºåËøôÊòØÂõ†‰∏∫Âú®‰∫∫ÊàêÈïøÁöÑËøáÁ®ãÔºåÁªèËøáËá™Â∑±ÁöÑÊÄùËÄÉÔºåÂ∑≤ÁªèÂΩ¢Êàê‰∫ÜÂæàÂ§öËßÑÂæã‰∏éÊΩúÊÑèËØÜ„ÄÇÂ¶ÇÊûú‰Ω†ÂëäËØâÁöÑËßÑÂæã‰∏éÂØπÊñπÁöÑ‰∏çÁõ∏Á¨¶ÔºåÂæàÊúâÂèØËÉΩÂá∫‰∫é‰øùÊä§Ôºå‰ªñ‰ª¨‰ºöÊú¨ËÉΩÁöÑÊãíÁªù‰Ω†ÁöÑÊñ∞ËßÑÂæãÔºå‰ΩÜÊòØÂ¶ÇÊûú‰Ω†Ë∑ü‰ªñËÆ≤‰∏Ä‰∏™ÊïÖ‰∫ãÔºå‰º†ÈÄí‰∏Ä‰∫õ‰ø°ÊÅØÔºåËæìÈÄÅ‰∏Ä‰∫õÊï∞ÊçÆÁªô‰ªñÔºå‰ªñ‰ºöÊÄùËÄÉÂπ∂Ëá™ÊàëÊîπÂèò„ÄÇ‰ªñÁöÑÊÄùËÄÉËøáÁ®ãÂÆûÈôÖ‰∏äÂ∞±ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑËøáÁ®ãÔºå‰ªñÊääÊñ∞ÁöÑÊï∞ÊçÆÁ∫≥ÂÖ•Âà∞‰ªñÁöÑÊóßÊúâÁöÑËÆ∞ÂøÜ‰∏éÊï∞ÊçÆ‰∏≠ÔºåÁªèËøáÈáçÊñ∞ËÆ≠ÁªÉ„ÄÇÂ¶ÇÊûú‰Ω†ÁªôÂá∫ÁöÑÊï∞ÊçÆÁöÑ‰ø°ÊÅØÈáèÈùûÂ∏∏Â§ßÔºåÂ§ßÂà∞Ë∞ÉÊï¥‰∫Ü‰ªñÁöÑÊ®°ÂûãÔºåÈÇ£‰πà‰ªñÂ∞±‰ºöÊåâÁÖß‰Ω†Â∏åÊúõÁöÑËßÑÂæãÂéªÂÅö‰∫ã„ÄÇÊúâÁöÑÊó∂ÂÄôÔºå‰ªñ‰ºöÊú¨ËÉΩÁöÑÊãíÁªùÊâßË°åËøô‰∏™ÊÄùËÄÉËøáÁ®ãÔºå‰ΩÜÊòØÊï∞ÊçÆ‰∏ÄÊó¶ËæìÂÖ•ÔºåÊó†ËÆ∫‰ªñÂ∏åÊúõ‰∏éÂê¶Ôºå‰ªñÁöÑÂ§ßËÑëÈÉΩ‰ºöÂú®ÊΩúÊÑèËØÜÁä∂ÊÄÅ‰∏ãÊÄùËÄÉÔºåÂπ∂‰∏îÂèØËÉΩÊîπÂèò‰ªñÁöÑÁúãÊ≥ï„ÄÇ Â¶ÇÊûúËÆ°ÁÆóÊú∫‰πüÊã•ÊúâÊΩúÊÑèËØÜ(Ê≠£Â¶ÇÊú¨ÂçöÂÆ¢ÁöÑÂêçÁß∞‰∏ÄÊ†∑)ÔºåÈÇ£‰πà‰ºöÊÄé‰πàÊ†∑ÔºüË≠¨Â¶ÇËÆ©ËÆ°ÁÆóÊú∫Âú®Â∑•‰ΩúÁöÑËøáÁ®ã‰∏≠ÔºåÈÄêÊ∏ê‰∫ßÁîü‰∫ÜËá™Ë∫´ÁöÑÊΩúÊÑèËØÜÔºå‰∫éÊòØÁîöËá≥ÂèØ‰ª•Âú®‰Ω†‰∏çÈúÄË¶ÅÂëäËØâÂÆÉÂÅö‰ªÄ‰πàÊó∂ÂÆÉÂ∞±‰ºöÂÆåÊàêÈÇ£‰ª∂‰∫ã„ÄÇËøôÊòØ‰∏™ÈùûÂ∏∏ÊúâÊÑèÊÄùÁöÑËÆæÊÉ≥ÔºåËøôÈáåÁïôÁªôÂêÑ‰ΩçËØªËÄÖÂéªÂèëÊï£ÊÄùËÄÉÂêß„ÄÇ9.ÊÄªÁªì Êú¨ÊñáÈ¶ñÂÖà‰ªãÁªç‰∫Ü‰∫íËÅîÁΩëÁïå‰∏éÊú∫Âô®Â≠¶‰π†Â§ßÁâõÁªìÂêàÁöÑË∂ãÂäøÔºå‰ª•Âèä‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÁöÑÁõ∏ÂÖ≥Â∫îÁî®ÔºåÊé•ÁùÄ‰ª•‰∏Ä‰∏™&ldquo;Á≠â‰∫∫ÊïÖ‰∫ã&rdquo;Â±ïÂºÄÂØπÊú∫Âô®Â≠¶‰π†ÁöÑ‰ªãÁªç„ÄÇ‰ªãÁªç‰∏≠È¶ñÂÖàÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÊ¶ÇÂøµ‰∏éÂÆö‰πâÔºåÁÑ∂ÂêéÊòØÊú∫Âô®Â≠¶‰π†ÁöÑÁõ∏ÂÖ≥Â≠¶ÁßëÔºåÊú∫Âô®Â≠¶‰π†‰∏≠ÂåÖÂê´ÁöÑÂêÑÁ±ªÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊé•ÁùÄ‰ªãÁªçÊú∫Âô®Â≠¶‰π†‰∏éÂ§ßÊï∞ÊçÆÁöÑÂÖ≥Á≥ªÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÊñ∞Â≠êÁ±ªÊ∑±Â∫¶Â≠¶‰π†ÔºåÊúÄÂêéÊé¢ËÆ®‰∫Ü‰∏Ä‰∏ãÊú∫Âô®Â≠¶‰π†‰∏é‰∫∫Â∑•Êô∫ËÉΩÂèëÂ±ïÁöÑËÅîÁ≥ª‰ª•ÂèäÊú∫Âô®Â≠¶‰π†‰∏éÊΩúÊÑèËØÜÁöÑÂÖ≥ËÅî„ÄÇÁªèËøáÊú¨ÊñáÁöÑ‰ªãÁªçÔºåÁõ∏‰ø°Â§ßÂÆ∂ÂØπÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÊúâ‰∏ÄÂÆöÁöÑ‰∫ÜËß£Ôºå‰æãÂ¶ÇÊú∫Âô®Â≠¶‰π†ÊòØ‰ªÄ‰πàÔºåÂÆÉÁöÑÂÜÖÊ†∏ÊÄùÊÉ≥ÊòØ‰ªÄ‰πà(Âç≥ÁªüËÆ°ÂíåÂΩíÁ∫≥)ÔºåÈÄöËøá‰∫ÜËß£Êú∫Âô®Â≠¶‰π†‰∏é‰∫∫Á±ªÊÄùËÄÉÁöÑËøë‰ººËÅîÁ≥ªÂèØ‰ª•Áü•ÊôìÊú∫Âô®Â≠¶‰π†‰∏∫‰ªÄ‰πàÂÖ∑ÊúâÊô∫ÊÖßËÉΩÂäõÁöÑÂéüÂõ†Á≠âÁ≠â„ÄÇÂÖ∂Ê¨°ÔºåÊú¨ÊñáÊº´Ë∞à‰∫ÜÊú∫Âô®Â≠¶‰π†‰∏éÂ§ñÂª∂Â≠¶ÁßëÁöÑÂÖ≥Á≥ªÔºåÊú∫Âô®Â≠¶‰π†‰∏éÂ§ßÊï∞ÊçÆÁõ∏‰∫í‰øÉËøõÁõ∏ÂæóÁõäÂΩ∞ÁöÑËÅîÁ≥ªÔºåÊú∫Âô®Â≠¶‰π†ÁïåÊúÄÊñ∞ÁöÑÊ∑±Â∫¶Â≠¶‰π†ÁöÑËøÖÁåõÂèëÂ±ïÔºå‰ª•ÂèäÂØπ‰∫é‰∫∫Á±ªÂü∫‰∫éÊú∫Âô®Â≠¶‰π†ÂºÄÂèëÊô∫ËÉΩÊú∫Âô®‰∫∫ÁöÑ‰∏ÄÁßçÂ±ïÊúõ‰∏éÊÄùËÄÉÔºåÊúÄÂêé‰ΩúËÄÖÁÆÄÂçïË∞à‰∫Ü‰∏ÄÁÇπÂÖ≥‰∫éËÆ©ËÆ°ÁÆóÊú∫Êã•ÊúâÊΩúÊÑèËØÜÁöÑËÆæÊÉ≥„ÄÇ Êú∫Âô®Â≠¶‰π†ÊòØÁõÆÂâç‰∏öÁïåÊúÄ‰∏∫Amazing‰∏éÁÅ´ÁÉ≠ÁöÑ‰∏ÄÈ°πÊäÄÊúØÔºå‰ªéÁΩë‰∏äÁöÑÊØè‰∏ÄÊ¨°Ê∑òÂÆùÁöÑË¥≠‰π∞‰∏úË•øÔºåÂà∞Ëá™Âä®È©æÈ©∂Ê±ΩËΩ¶ÊäÄÊúØÔºå‰ª•ÂèäÁΩëÁªúÊîªÂáªÊäµÂæ°Á≥ªÁªüÁ≠âÁ≠âÔºåÈÉΩÊúâÊú∫Âô®Â≠¶‰π†ÁöÑÂõ†Â≠êÂú®ÂÜÖÔºåÂêåÊó∂Êú∫Âô®Â≠¶‰π†‰πüÊòØÊúÄÊúâÂèØËÉΩ‰Ωø‰∫∫Á±ªÂÆåÊàêAI dreamÁöÑ‰∏ÄÈ°πÊäÄÊúØÔºåÂêÑÁßç‰∫∫Â∑•Êô∫ËÉΩÁõÆÂâçÁöÑÂ∫îÁî®ÔºåÂ¶ÇÂæÆËΩØÂ∞èÂÜ∞ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂà∞ËÆ°ÁÆóÊú∫ËßÜËßâÊäÄÊúØÁöÑËøõÊ≠•ÔºåÈÉΩÊúâÊú∫Âô®Â≠¶‰π†Âä™ÂäõÁöÑÊàêÂàÜ„ÄÇ‰Ωú‰∏∫‰∏ÄÂêçÂΩì‰ª£ÁöÑËÆ°ÁÆóÊú∫È¢ÜÂüüÁöÑÂºÄÂèëÊàñÁÆ°ÁêÜ‰∫∫ÂëòÔºå‰ª•ÂèäË∫´Â§ÑËøô‰∏™‰∏ñÁïåÔºå‰ΩøÁî®ËÄÖITÊäÄÊúØÂ∏¶Êù•‰æøÂà©ÁöÑ‰∫∫‰ª¨ÔºåÊúÄÂ•ΩÈÉΩÂ∫îËØ•‰∫ÜËß£‰∏Ä‰∫õÊú∫Âô®Â≠¶‰π†ÁöÑÁõ∏ÂÖ≥Áü•ËØÜ‰∏éÊ¶ÇÂøµÔºåÂõ†‰∏∫ËøôÂèØ‰ª•Â∏Æ‰Ω†Êõ¥Â•ΩÁöÑÁêÜËß£‰∏∫‰Ω†Â∏¶Êù•Ëé´Â§ß‰æøÂà©ÊäÄÊúØÁöÑËÉåÂêéÂéüÁêÜÔºå‰ª•ÂèäËÆ©‰Ω†Êõ¥Â•ΩÁöÑÁêÜËß£ÂΩì‰ª£ÁßëÊäÄÁöÑËøõÁ®ã„ÄÇ10.ÂêéËÆ∞ ËøôÁØáÊñáÊ°£Ëä±‰∫Ü‰ΩúËÄÖ‰∏§‰∏™ÊúàÁöÑÊó∂Èó¥ÔºåÁªà‰∫éÂú®2014Âπ¥ÁöÑÊúÄÂêé‰∏ÄÂ§©ÁöÑÂâç‰∏ÄÂ§©Âü∫Êú¨ÂÆåÊàê„ÄÇÈÄöËøáËøôÁØáÊñáÁ´†Ôºå‰ΩúËÄÖÂ∏åÊúõÂØπÊú∫Âô®Â≠¶‰π†Âú®ÂõΩÂÜÖÁöÑÊôÆÂèäÂÅö‰∏ÄÁÇπË¥°ÁåÆÔºåÂêåÊó∂‰πüÊòØ‰ΩúËÄÖÊú¨‰∫∫Ëá™Â∑±ÂØπ‰∫éÊâÄÂ≠¶Êú∫Âô®Â≠¶‰π†Áü•ËØÜÁöÑ‰∏Ä‰∏™ËûçÊ±áË¥ØÈÄöÔºåÊï¥‰ΩìÂΩíÁ∫≥ÁöÑÊèêÈ´òËøáÁ®ã„ÄÇ‰ΩúËÄÖÊääËøô‰πàÂ§öÁöÑÁü•ËØÜÁªèËøáËá™Â∑±ÁöÑÂ§ßËÑëÊÄùËÄÉÔºåËÆ≠ÁªÉÂá∫‰∫Ü‰∏Ä‰∏™Ê®°ÂûãÔºåÂΩ¢Êàê‰∫ÜËøôÁØáÊñáÊ°£ÔºåÂèØ‰ª•ËØ¥Ëøô‰πüÊòØ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†ÁöÑËøáÁ®ãÂêß(Á¨ë)„ÄÇ ‰ΩúËÄÖÊâÄÂú®ÁöÑË°å‰∏ö‰ºöÊé•Ëß¶Âà∞Â§ßÈáèÁöÑÊï∞ÊçÆÔºåÂõ†Ê≠§ÂØπ‰∫éÊï∞ÊçÆÁöÑÂ§ÑÁêÜÂíåÂàÜÊûêÊòØÂπ≥Â∏∏ÈùûÂ∏∏ÈáçË¶ÅÁöÑÂ∑•‰ΩúÔºåÊú∫Âô®Â≠¶‰π†ËØæÁ®ãÁöÑÊÄùÊÉ≥ÂíåÁêÜÂøµÂØπ‰∫é‰ΩúËÄÖÊó•Â∏∏ÁöÑÂ∑•‰ΩúÊåáÂºï‰ΩúÁî®ÊûÅÂ§ßÔºåÂá†‰πéÂØºËá¥‰∫Ü‰ΩúËÄÖÂØπ‰∫éÊï∞ÊçÆ‰ª∑ÂÄºÁöÑÈáçÊñ∞ËÆ§ËØÜ„ÄÇÊÉ≥ÊÉ≥ÂçäÂπ¥ÂâçÔºå‰ΩúËÄÖËøòÂØπÊú∫Âô®Â≠¶‰π†‰ººÊáÇÈùûÊáÇÔºåÂ¶Ç‰ªä‰πüÂèØ‰ª•ÁÆóÊòØ‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†ÁöÑExpert‰∫Ü(Á¨ë)„ÄÇ‰ΩÜ‰ΩúËÄÖÂßãÁªàËÆ§‰∏∫ÔºåÊú∫Âô®Â≠¶‰π†ÁöÑÁúüÊ≠£Â∫îÁî®‰∏çÊòØÈÄöËøáÊ¶ÇÂøµÊàñËÄÖÊÄùÊÉ≥ÁöÑÊñπÂºèÔºåËÄåÊòØÈÄöËøáÂÆûË∑µ„ÄÇÂè™ÊúâÂΩìÊääÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁúüÊ≠£Â∫îÁî®Êó∂ÔºåÊâçÂèØÁÆóÊòØÂØπÊú∫Âô®Â≠¶‰π†ÁöÑÁêÜËß£ËøõÂÖ•‰∫Ü‰∏Ä‰∏™Â±ÇÊ¨°„ÄÇÊ≠£ÊâÄË∞ìÂÜç&ldquo;Èò≥Êò•ÁôΩÈõ™&rdquo;ÁöÑÊäÄÊúØÔºå‰πüÂøÖÈ°ªËêΩÂà∞&ldquo;‰∏ãÈáåÂ∑¥‰∫∫&rdquo;ÁöÑÂú∫ÊôØ‰∏ãËøêÁî®„ÄÇÁõÆÂâçÊúâ‰∏ÄÁßçÈ£éÊ∞îÔºåÂõΩÂÜÖÂ§ñÁ†îÁ©∂Êú∫Âô®Â≠¶‰π†ÁöÑÊüê‰∫õÂ≠¶ËÄÖÔºåÊúâ‰∏ÄÁßçÈ´òË¥µÁöÑÈÄºÊ†ºÔºåËÆ§‰∏∫Ëá™Â∑±ÁöÑÁ†îÁ©∂ÊòØÊôÆÈÄö‰∫∫Êó†Ê≥ïÁêÜËß£ÁöÑÔºå‰ΩÜÊòØËøôÊ†∑ÁöÑÁêÜÂøµÊòØÊ†πÊú¨ÈîôËØØÁöÑÔºåÊ≤°ÊúâÂú®ÁúüÊ≠£ÂÆûÈôÖÁöÑÂú∞ÊñπÂèëÊå•‰ΩúÁî®ÔºåÂá≠‰ªÄ‰πàËØÅÊòé‰Ω†ÁöÑÁ†îÁ©∂ÊúâÊâÄ‰ª∑ÂÄºÂë¢Ôºü‰ΩúËÄÖËÆ§‰∏∫ÂøÖÈ°ªÂ∞ÜÈ´òÂ§ß‰∏äÁöÑÊäÄÊúØÁî®Âú®ÊîπÂèòÊôÆÈÄö‰∫∫ÁöÑÁîüÊ¥ª‰∏äÔºåÊâçËÉΩÂèëÊå•ÂÖ∂Ê†πÊú¨ÁöÑ‰ª∑ÂÄº„ÄÇ‰∏Ä‰∫õÁÆÄÂçïÁöÑÂú∫ÊôØÔºåÊÅ∞ÊÅ∞ÊòØÂÆûË∑µÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁöÑÊúÄÂ•ΩÂú∞Êñπ„ÄÇ]]></content>
      <categories>
        <category>ËΩ¨ËΩΩ</category>
      </categories>
      <tags>
        <tag>Êú∫Âô®Â≠¶‰π†</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ËôöÊãüÊú∫Êê≠Âª∫HadoopÂÆûÈ™å]]></title>
    <url>%2F2017%2F09%2F14%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%90%AD%E5%BB%BAHadoop%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[Âú®Â≠¶‰π†Â§ßÊï∞ÊçÆÁöÑËøáÁ®ã‰∏≠Êê≠Âª∫Áî±‰∏âÂè∞ËôöÊãüÊú∫ÊûÑÊàêÁöÑHadoopÊ®°Âûã ÂàõÂª∫‰∏âÂè∞ËôöÊãüÊú∫‰ΩøÁî®ËΩØ‰ª∂ÔºöVmware12 Centos7ÊúÄÂ∞èÈïúÂÉè ÂÆâË£Ö‰∏ÄÂè∞ËôöÊãüÊú∫ÔºåÈÖçÁΩÆÂ•ΩÁΩëÁªú‰∏éjdkÔºåÂ§çÂà∂Âá∫‰∏§Âè∞ÂêåÊ†∑ÁöÑ ÊñπÊ≥ï/Ê≠•È™§ È¶ñÂÖàÊàë‰ª¨ÂÆâË£ÖÂêécentos7ÊúÄÂ∞èÂåñÁ≥ªÁªüÂêéÔºåÂπ∂ËøõÂÖ•Á≥ªÁªüÊâßË°åÂëΩ‰ª§ifconfigÔºå‰ºöÂèëÁé∞Á≥ªÁªüÊèêÁ§∫ÂëΩ‰ª§Êú™ÊâæÂà∞„ÄÇÂÖ∑‰ΩìÂ±ïÁ§∫ÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÁÑ∂ÂêéËæìÂÖ•ÂëΩ‰ª§Êü•ÁúãÊú¨Êú∫ÊòØÂê¶ÂàÜÈÖçIP,ÊâßË°åÂëΩ‰ª§ip addr ÔºåÂèØ‰ª•ÂèëÁé∞Á≥ªÁªüÁöÑÁΩëÂç°Ê≤°ÊúâÂàÜÈÖçIPÂú∞ÂùÄÔºåÂú®Ê≠§Êàë‰ª¨ÈúÄË¶ÅËÆ∞‰ΩèÊú¨Êú∫ÁΩëÂç°ÁöÑÂêçÁß∞ÔºåÁî®‰∫é‰∏ã‰∏ÄÊ≠•‰ΩøÁî®ÔºåÊú¨ÁØá‰∏≠Êàë‰ª¨ÁöÑÁΩëÂç°‰∏∫Ôºöeno16777736„ÄÇÂÖ∑‰ΩìÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ËøõÂÖ•ÁΩëÂç°ÈÖçÁΩÆÊñá‰ª∂ÁöÑÁõÆÂΩï„ÄÇÊâßË°åÂëΩ‰ª§ cd /etc/sysconfig/network-scripts/ ÁÑ∂ÂêéÊü•Áúã‰∏ãÈù¢ÁöÑÁΩëÂç°Êñá‰ª∂„ÄÇÂÖ∑‰ΩìÊïàÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ÊâæÂà∞ÂØπÂ∫îÁöÑÁΩëÂç°Êñá‰ª∂ÊâßË°åÂëΩ‰ª§ vi ifcfg-eno16777736„ÄÇËøõË°å‰øÆÊîπÁΩëÂç°Êñá‰ª∂Ôºå‰∏çÂêåÊú∫Âô®ÁΩëÂç°‰∏çÂêåÔºåÊú¨ÁØá‰ª•Ëá™Â∑±ÁîµËÑë‰∏∫‰æãÂ±ïÁ§∫„ÄÇ Êàë‰ª¨ÈúÄË¶ÅÈ¶ñÂÖàÊâæÂà∞ONBOOT=no ÔºåÈúÄË¶Å‰øÆÊîπ‰∏∫ONBOOT=yesÁÑ∂Âêé‰øùÂ≠òÈÄÄÂá∫„ÄÇ ÁÑ∂ÂêéÊâßË°åÂëΩ‰ª§ service network restart ÈáçÂêØÁΩëÂç°ÊúçÂä°„ÄÇÂÖ∑‰ΩìÊìç‰ΩúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÊâßË°åÂÆåÊàêÂêéÔºåÊàë‰ª¨ÂÜçÊ¨°ÊâßË°åÂëΩ‰ª§ ip addr Êü•ÁúãÊòØÂê¶ÂàÜÈÖçÂà∞IPÂú∞ÂùÄÔºåÂèØ‰ª•ÁúãÂà∞Â∑≤ÁªèÂàÜÈÖçÂà∞IPÂú∞ÂùÄ„ÄÇÂÖ∑‰ΩìÊìç‰ΩúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ÊâßË°åÂëΩ‰ª§yum provides ifconfig Êü•ÁúãÂì™‰∏™ÂåÖÊèê‰æõ‰∫ÜifconfigÂëΩ‰ª§ÔºåÁÑ∂ÂêéÂèØ‰ª•ÁúãÂà∞net-toolsÂåÖÊèê‰æõifconfigÂåÖÔºå ÂÖ∑‰ΩìÊìç‰ΩúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ÊâßË°åÂëΩ‰ª§ÂÆâË£Önet-toolsÂåÖÔºåÊâßË°åÂëΩ‰ª§Ôºöyum install net-tools„ÄÇÂÖ∑‰ΩìÊìç‰ΩúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ ÁÑ∂ÂêéÊàë‰ª¨ÊâßË°åÂëΩ‰ª§ifconfigÔºåÂèØ‰ª•ÁúãÂà∞ÂèØ‰ª•‰ΩøÁî®‰∫ÜÔºåËÄå‰∏îÂ±ïÁ§∫‰∫ÜÁ≥ªÁªüÁöÑÁΩëÂç°‰ø°ÊÅØ„ÄÇÂÖ∑‰ΩìÊìç‰ΩúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫„ÄÇ 123456789101112131415161718192021222324252627282930313233343536373839404142ÂÆâË£ÖjdkÔºö1.Êü•ÁúãyumÂ∫ì‰∏≠ÈÉΩÊúâÂì™‰∫õjdkÁâàÊú¨(ÊöÇÊó∂Âè™ÂèëÁé∞‰∫Üopenjdk)[root@localhost ~]# yum search java|grep jdkldapjdk-javadoc.x86_64 : Javadoc for ldapjdkjava-1.6.0-openjdk.x86_64 : OpenJDK Runtime Environmentjava-1.6.0-openjdk-demo.x86_64 : OpenJDK Demosjava-1.6.0-openjdk-devel.x86_64 : OpenJDK Development Environmentjava-1.6.0-openjdk-javadoc.x86_64 : OpenJDK API Documentationjava-1.6.0-openjdk-src.x86_64 : OpenJDK Source Bundlejava-1.7.0-openjdk.x86_64 : OpenJDK Runtime Environmentjava-1.7.0-openjdk-demo.x86_64 : OpenJDK Demosjava-1.7.0-openjdk-devel.x86_64 : OpenJDK Development Environmentjava-1.7.0-openjdk-javadoc.noarch : OpenJDK API Documentationjava-1.7.0-openjdk-src.x86_64 : OpenJDK Source Bundlejava-1.8.0-openjdk.x86_64 : OpenJDK Runtime Environmentjava-1.8.0-openjdk-demo.x86_64 : OpenJDK Demosjava-1.8.0-openjdk-devel.x86_64 : OpenJDK Development Environmentjava-1.8.0-openjdk-headless.x86_64 : OpenJDK Runtime Environmentjava-1.8.0-openjdk-javadoc.noarch : OpenJDK API Documentationjava-1.8.0-openjdk-src.x86_64 : OpenJDK Source Bundleldapjdk.x86_64 : The Mozilla LDAP Java SDK2.ÈÄâÊã©ÁâàÊú¨,ËøõË°åÂÆâË£Ö//ÈÄâÊã©1.7ÁâàÊú¨ËøõË°åÂÆâË£Ö[root@localhost ~]# yum install java-1.7.0-openjdk//ÂÆâË£ÖÂÆå‰πãÂêéÔºåÈªòËÆ§ÁöÑÂÆâË£ÖÁõÆÂΩïÊòØÂú®: /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.75.x86_643.ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè ÔºàÂ¶ÇÊûúÂ∑≤ÁªèÊúâjavaÂëΩ‰ª§‰∏çÁî®ËÆæÁΩÆÔºâ[root@localhost ~]# vi /etc/profileÂú®profileÊñá‰ª∂‰∏≠Ê∑ªÂä†Â¶Ç‰∏ãÂÜÖÂÆπ#set java environmentJAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.75.x86_64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH4.ËÆ©‰øÆÊîπÁîüÊïà[root@localhost java]# source /etc/profile5.Êü•ÁúãÂàöÂÆâË£ÖÁöÑJavaÁâàÊú¨‰ø°ÊÅØ„ÄÇ‚óÜËæìÂÖ•Ôºöjava -version ÂèØÊü•ÁúãJavaÁâàÊú¨Ôºõ ÈÖçÁΩÆhosts vi /etc/hosts ËØ¥ÊòéÔºöslaver217,slaver214‰Ωú‰∏∫datanodeËäÇÁÇπÔºåmaster204‰Ωú‰∏∫namenodeËäÇÁÇπ„ÄÇÂè¶Â§ñÔºåÂêÑdatanodeËäÇÁÇπ‰∏ªÊú∫‰∏äÂè™ÈúÄÈÖçÁΩÆÂ¶ÇÔºö172.16.51.214 slaver214„ÄÇ]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>BigData</tag>
      </tags>
  </entry>
</search>
