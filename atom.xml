<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Voidmort</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xvjie.wang/"/>
  <updated>2020-06-13T07:32:41.842Z</updated>
  <id>https://xvjie.wang/</id>
  
  <author>
    <name>Voidmort</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习实战（十四）</title>
    <link href="https://xvjie.wang/2020/06/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/06/08/机器学习实战（十四）/</id>
    <published>2020-06-08T08:20:50.000Z</published>
    <updated>2020-06-13T07:32:41.842Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;利用SVD简化数据&quot;&gt;&lt;a href=&quot;#利用SVD简化数据&quot; class=&quot;headerlink&quot; title=&quot;利用SVD简化数据&quot;&gt;&lt;/a&gt;利用SVD简化数据&lt;/h1&gt;&lt;p&gt;奇异值分解（singular value
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="SVD" scheme="https://xvjie.wang/tags/SVD/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（十三）</title>
    <link href="https://xvjie.wang/2020/06/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/06/04/机器学习实战（十三）/</id>
    <published>2020-06-04T08:20:50.000Z</published>
    <updated>2020-06-13T07:29:55.042Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;利用PCA来简化数据&quot;&gt;&lt;a href=&quot;#利用PCA来简化数据&quot; class=&quot;headerlink&quot; title=&quot;利用PCA来简化数据&quot;&gt;&lt;/a&gt;利用PCA来简化数据&lt;/h1&gt;&lt;p&gt;降维（dimensionality
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="PCA" scheme="https://xvjie.wang/tags/PCA/"/>
    
      <category term="降维" scheme="https://xvjie.wang/tags/%E9%99%8D%E7%BB%B4/"/>
    
      <category term="主成分分析" scheme="https://xvjie.wang/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（十二）</title>
    <link href="https://xvjie.wang/2020/06/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/06/02/机器学习实战（十二）/</id>
    <published>2020-06-02T01:20:50.000Z</published>
    <updated>2020-06-13T07:39:28.598Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;使用FP-growth算法来高效发现频繁项集&quot;&gt;&lt;a href=&quot;#使用FP-growth算法来高效发现频繁项集&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="FP-growth" scheme="https://xvjie.wang/tags/FP-growth/"/>
    
  </entry>
  
  <entry>
    <title>文本转Emoji</title>
    <link href="https://xvjie.wang/2020/06/01/EmojiAnalysis/"/>
    <id>https://xvjie.wang/2020/06/01/EmojiAnalysis/</id>
    <published>2020-06-01T01:20:50.000Z</published>
    <updated>2020-06-14T08:42:03.469Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;分析微博中的emoji&quot;&gt;&lt;a href=&quot;#分析微博中的emoji&quot; class=&quot;headerlink&quot; title=&quot;分析微博中的emoji&quot;&gt;&lt;/a&gt;分析微博中的emoji&lt;/h1&gt;&lt;figure class=&quot;highlight
        
      
    
    </summary>
    
      <category term="LSTM" scheme="https://xvjie.wang/categories/LSTM/"/>
    
    
      <category term="深度学习" scheme="https://xvjie.wang/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="LSTM" scheme="https://xvjie.wang/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（十一）</title>
    <link href="https://xvjie.wang/2020/05/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/05/28/机器学习实战（十一）/</id>
    <published>2020-05-28T01:20:50.000Z</published>
    <updated>2020-06-13T07:25:37.475Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;使用Apriori算法进行关联分析&quot;&gt;&lt;a href=&quot;#使用Apriori算法进行关联分析&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="关联分析" scheme="https://xvjie.wang/tags/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90/"/>
    
      <category term="Apriori算法" scheme="https://xvjie.wang/tags/Apriori%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（十）</title>
    <link href="https://xvjie.wang/2020/05/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%8D%81%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/05/15/机器学习实战（十）/</id>
    <published>2020-05-15T01:20:50.000Z</published>
    <updated>2020-05-31T02:39:24.748Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;利用K-均值聚类算法对未标注数据分组&quot;&gt;&lt;a href=&quot;#利用K-均值聚类算法对未标注数据分组&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="聚类" scheme="https://xvjie.wang/tags/%E8%81%9A%E7%B1%BB/"/>
    
      <category term="K-均值" scheme="https://xvjie.wang/tags/K-%E5%9D%87%E5%80%BC/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战中的函数学习记录</title>
    <link href="https://xvjie.wang/2020/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    <id>https://xvjie.wang/2020/05/01/机器学习实战中的函数学习记录/</id>
    <published>2020-05-01T01:20:50.000Z</published>
    <updated>2020-06-13T07:37:25.941Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;记录机器学习实战中遇到的函数&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="python函数" scheme="https://xvjie.wang/tags/python%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（九）</title>
    <link href="https://xvjie.wang/2020/05/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B9%9D%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/05/01/机器学习实战（九）/</id>
    <published>2020-05-01T01:20:50.000Z</published>
    <updated>2020-05-31T02:34:14.457Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;数回归&quot;&gt;&lt;a href=&quot;#数回归&quot; class=&quot;headerlink&quot; title=&quot;数回归&quot;&gt;&lt;/a&gt;数回归&lt;/h1&gt;&lt;p&gt;分类回归树 Classification And Regression Trees
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="树回归" scheme="https://xvjie.wang/tags/%E6%A0%91%E5%9B%9E%E5%BD%92/"/>
    
      <category term="CSRT算法" scheme="https://xvjie.wang/tags/CSRT%E7%AE%97%E6%B3%95/"/>
    
      <category term="树剪枝算法" scheme="https://xvjie.wang/tags/%E6%A0%91%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（八）</title>
    <link href="https://xvjie.wang/2020/04/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%85%AB%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/04/20/机器学习实战（八）/</id>
    <published>2020-04-20T01:20:50.000Z</published>
    <updated>2020-04-30T07:43:02.824Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;预测数值型数据：回归&quot;&gt;&lt;a href=&quot;#预测数值型数据：回归&quot; class=&quot;headerlink&quot; title=&quot;预测数值型数据：回归&quot;&gt;&lt;/a&gt;预测数值型数据：回归&lt;/h1&gt;&lt;p&gt;分类的目标变量是标称型数据，而回归是对连续性数据做出预测。&lt;/p&gt;
&lt;h1
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="线性回归" scheme="https://xvjie.wang/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="岭回归" scheme="https://xvjie.wang/tags/%E5%B2%AD%E5%9B%9E%E5%BD%92/"/>
    
      <category term="最小二乘法" scheme="https://xvjie.wang/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（七）</title>
    <link href="https://xvjie.wang/2020/04/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%83%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/04/07/机器学习实战（七）/</id>
    <published>2020-04-07T01:20:50.000Z</published>
    <updated>2020-04-09T09:02:35.889Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;利用AdaBoost元算法提高分类性能&quot;&gt;&lt;a href=&quot;#利用AdaBoost元算法提高分类性能&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="AdaBoost" scheme="https://xvjie.wang/tags/AdaBoost/"/>
    
      <category term="bagging" scheme="https://xvjie.wang/tags/bagging/"/>
    
      <category term="boosting" scheme="https://xvjie.wang/tags/boosting/"/>
    
      <category term="ROC" scheme="https://xvjie.wang/tags/ROC/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（六）</title>
    <link href="https://xvjie.wang/2020/04/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%85%AD%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/04/04/机器学习实战（六）/</id>
    <published>2020-04-04T02:15:50.000Z</published>
    <updated>2020-04-06T09:31:17.034Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;这一章的内容非常多，在神经网络大火前，SVM是最优秀的机器学习算法，尽管现在已经很少用了，但作为一本七年前的书还是很详细的讲解了，所以这里简单的记录下。&lt;/p&gt;
&lt;h1 id=&quot;基于最大间隔分隔数据&quot;&gt;&lt;a href=&quot;#基于最大间隔分隔数据&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="SVM" scheme="https://xvjie.wang/tags/SVM/"/>
    
      <category term="SMO" scheme="https://xvjie.wang/tags/SMO/"/>
    
      <category term="支持向量机" scheme="https://xvjie.wang/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（五）</title>
    <link href="https://xvjie.wang/2020/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%94%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/04/01/机器学习实战（五）/</id>
    <published>2020-04-01T01:15:50.000Z</published>
    <updated>2020-04-04T02:28:26.201Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;Logistic回归是一个最优化算法，比如如何在最短时间从A点到达B点？&lt;/p&gt;
&lt;p&gt;回归：假设我们有一些数据点，我们用一条直线对这些点进行拟合（该线称为最佳拟合直线），这个拟合过程就叫做回归。&lt;/p&gt;
&lt;p&gt;根据现有的数据对分类边界线建立回归公式，依次进行分类。这里的“
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="逻辑回归" scheme="https://xvjie.wang/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（四）</title>
    <link href="https://xvjie.wang/2020/03/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E5%9B%9B%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/03/21/机器学习实战（四）/</id>
    <published>2020-03-21T02:15:50.000Z</published>
    <updated>2020-03-24T05:57:28.787Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;前两章的分类器只能给出分类结果，而不能给出概率，这一章将学习一个最简单的概率分类器，朴素贝叶斯分类器。之所以称为朴素，是因为整个形式化过程只做最原始，最简单的假设。&lt;/p&gt;
&lt;h1 id=&quot;基于贝叶斯决策理论的分类方法&quot;&gt;&lt;a href=&quot;#基于贝叶斯决策理论的分类方法&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="朴素贝叶斯" scheme="https://xvjie.wang/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（三）</title>
    <link href="https://xvjie.wang/2020/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/03/06/机器学习实战（三）/</id>
    <published>2020-03-06T02:15:50.000Z</published>
    <updated>2020-03-15T06:43:28.902Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;决策树的简介&quot;&gt;&lt;a href=&quot;#决策树的简介&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="决策树" scheme="https://xvjie.wang/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
      <category term="ID3" scheme="https://xvjie.wang/tags/ID3/"/>
    
  </entry>
  
  <entry>
    <title>Python虚拟环境的搭建</title>
    <link href="https://xvjie.wang/2020/02/19/Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA/"/>
    <id>https://xvjie.wang/2020/02/19/Python虚拟环境的搭建/</id>
    <published>2020-02-19T03:03:50.000Z</published>
    <updated>2020-03-06T09:01:06.144Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;我使用的Ubuntu18已经自带了pyhon3.6，现在我想用pip安装一些其它的应用的版本和现有的有冲突，为了防止冲突，我需要另一个python环境。&lt;/p&gt;
&lt;h1 id=&quot;python的安装&quot;&gt;&lt;a href=&quot;#python的安装&quot;
        
      
    
    </summary>
    
      <category term="virtualenv" scheme="https://xvjie.wang/categories/virtualenv/"/>
    
    
  </entry>
  
  <entry>
    <title>机器学习实战（一）</title>
    <link href="https://xvjie.wang/2020/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/02/18/机器学习实战（一）/</id>
    <published>2020-02-18T03:20:50.000Z</published>
    <updated>2020-03-04T08:21:18.713Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;此blog是机器学习实战这本书的读书笔记&lt;/p&gt;
&lt;h1 id=&quot;机器学习基础&quot;&gt;&lt;a href=&quot;#机器学习基础&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="机器学习" scheme="https://xvjie.wang/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战（二）</title>
    <link href="https://xvjie.wang/2020/02/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>https://xvjie.wang/2020/02/18/机器学习实战（二）/</id>
    <published>2020-02-18T03:20:50.000Z</published>
    <updated>2020-03-04T08:15:36.274Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;k-邻近算法概述&quot;&gt;&lt;a href=&quot;#k-邻近算法概述&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="机器学习实战" scheme="https://xvjie.wang/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
    
      <category term="k-邻近算法" scheme="https://xvjie.wang/tags/k-%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%95/"/>
    
      <category term="KNN" scheme="https://xvjie.wang/tags/KNN/"/>
    
  </entry>
  
  <entry>
    <title>Django</title>
    <link href="https://xvjie.wang/2020/02/05/Django/"/>
    <id>https://xvjie.wang/2020/02/05/Django/</id>
    <published>2020-02-04T16:00:00.000Z</published>
    <updated>2020-03-06T08:59:00.615Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;Python下有许多款不同的 Web
        
      
    
    </summary>
    
      <category term="Django" scheme="https://xvjie.wang/categories/Django/"/>
    
    
      <category term="Django" scheme="https://xvjie.wang/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>Aerial Cactus Identification</title>
    <link href="https://xvjie.wang/2020/01/10/AerialCactusIdentification/"/>
    <id>https://xvjie.wang/2020/01/10/AerialCactusIdentification/</id>
    <published>2020-01-09T16:00:00.000Z</published>
    <updated>2020-06-13T08:54:53.620Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;仙人掌识别&quot;&gt;&lt;a href=&quot;#仙人掌识别&quot; class=&quot;headerlink&quot; title=&quot;仙人掌识别&quot;&gt;&lt;/a&gt;仙人掌识别&lt;/h1&gt;&lt;p&gt;To assess the impact of climate change on Earth’s flora
        
      
    
    </summary>
    
      <category term="Kaggle" scheme="https://xvjie.wang/categories/Kaggle/"/>
    
    
      <category term="Kaggle" scheme="https://xvjie.wang/tags/Kaggle/"/>
    
      <category term="keras" scheme="https://xvjie.wang/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>埃及分数</title>
    <link href="https://xvjie.wang/2019/12/23/%E5%9F%83%E5%8F%8A%E5%88%86%E6%95%B0/"/>
    <id>https://xvjie.wang/2019/12/23/埃及分数/</id>
    <published>2019-12-22T16:00:00.000Z</published>
    <updated>2020-01-29T03:41:04.000Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;在看科普视频的时候学到了埃及分数和贪婪算法，这里用code实现一下。&lt;/p&gt;
&lt;h1 id=&quot;埃及分数&quot;&gt;&lt;a href=&quot;#埃及分数&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="算法练习" scheme="https://xvjie.wang/categories/%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0/"/>
    
    
      <category term="python" scheme="https://xvjie.wang/tags/python/"/>
    
  </entry>
  
</feed>
